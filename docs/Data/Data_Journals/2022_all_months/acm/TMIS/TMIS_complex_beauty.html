<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmis---24">TMIS - 24</h2>
<ul>
<li><details>
<summary>
(2022). Heterogeneous energy-aware load balancing for industry 4.0
and IoT environments. <em>TMIS</em>, <em>13</em>(4), 46:1–23. (<a
href="https://doi.org/10.1145/3543859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the improvement of global infrastructure, Cyber-Physical Systems (CPS) have become an important component of Industry 4.0. Both the application as well as the machine work together to improve the task of interdependencies. Machine learning methods in CPS require the monitoring of computational algorithms, including adopting optimizations, fine-tuning cyber systems, improving resource utilization, as well as reducing vulnerability and also computation time. By leveraging the tremendous parallelism provided by General-Purpose Graphics Processing Units (GPGPU) as well as OpenCL, it is possible to dramatically reduce the execution time of data-parallel programs. However, when running an application with tiny amounts of data on a GPU, GPU resources are wasted because the program may not be able to fully utilize the GPU cores. This is because there is no mechanism for kernels to share a GPU due to the lack of OS support for GPUs. Optimal device selection is required to reduce the high power of the GPU. In this paper, we propose an energy reduction method for heterogeneous clustering. This study focuses on load balancing; resource-aware processor selection based on machine learning is performed using code features. The proposed method identifies energy-efficient kernel candidates (from the employment pool). Then, it selects a pair of kernel candidates from all possibilities that lead to a reduction in both energy consumption as well as execution time. Experimental results show that the proposed kernel approach reduces execution time by 2.23 times compared to a baseline scheduling system. Experiments have also shown that the execution time is 1.2 times faster than state-of-the-art approaches.},
  archive      = {J_TMIS},
  author       = {Usman Ahmed and Jerry Chun-Wei Lin and Gautam Srivastava},
  doi          = {10.1145/3543859},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {46:1–23},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Heterogeneous energy-aware load balancing for industry 4.0 and IoT environments},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Allocation of resources for cloud survivability in smart
manufacturing. <em>TMIS</em>, <em>13</em>(4), 45:1–11. (<a
href="https://doi.org/10.1145/3533701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of virtualization technology, cloud computing has emerged as a powerful and flexible platform for various services such as online trading. However, there are concerns about the survivability of cloud services in smart manufacturing. Most existing solutions provide a standby Virtual Machine (VM) for each running VM. However, this often leads to huge resource waste because VMs do not always run at full capacity. To reduce resource waste, we propose a smart survivability framework to efficiently allocate resources to standby VMs. Our framework contains two novel aspects: (1) a prediction mechanism to predict the resource utilization of each VM in order to reduce the number of standby VMs; and (2) a nested virtualization technology to refine the granularity of standby VMs. We will use an open-source cloud simulation platform named cloudsim, with real-world data, to verify the feasibility of the proposed framework and evaluate its performance. The proposed Smart Survivable Usable Virtual Machine (SSUVM) will predict resource utilization of VMs on Rack1 periodically. When errors happen in VMs, the framework will allocate standby resources according to the predicted result. The SSUVM will receive the latest running status of the failed VM and its mirror image to recover the VM&#39;s work.},
  archive      = {J_TMIS},
  author       = {Mengxin Nong and Lingfeng Huang and Mingtao Liu},
  doi          = {10.1145/3533701},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {45:1–11},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Allocation of resources for cloud survivability in smart manufacturing},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User-empowered privacy-preserving authentication protocol
for electric vehicle charging based on decentralized identity and
verifiable credential. <em>TMIS</em>, <em>13</em>(4), 44:1–21. (<a
href="https://doi.org/10.1145/3532869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Electric Vehicles (EVs) has been gaining traction in recent years due to various reasons. While charging their EVs, users expose their identity and personal details, and an adversary being able to identify and track where users charge their EVs is a potential privacy threat. In this article, we propose a user-empowered privacy-preserving authentication protocol for EV charging based on Decentralized Identifier (DID) and Verifiable Credential (VC) to provide Zero-Knowledge Proof (ZKP)-security. The proposed method gives users full control over their identities and allows them to remain anonymous while charging from any station. Giving control over their identities empowers users. At the same time, by making use of the concept of VC, other parties can verify that a user is legitimate and authenticate the user before providing charging services. Hence, the proposed protocol makes the charging service available in a secure way, while empowering users and preserving their privacy.},
  archive      = {J_TMIS},
  author       = {Rohini Poolat Parameswarath and Prosanta Gope and Biplab Sikdar},
  doi          = {10.1145/3532869},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {44:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {User-empowered privacy-preserving authentication protocol for electric vehicle charging based on decentralized identity and verifiable credential},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scientific workflows in IoT environments: A data placement
strategy based on heterogeneous edge-cloud computing. <em>TMIS</em>,
<em>13</em>(4), 42:1–26. (<a
href="https://doi.org/10.1145/3531327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Industry 4.0 and Internet of Things (IoT) environments, the heterogeneous edge-cloud computing paradigm can provide a more proper solution to deploy scientific workflows compared to cloud computing or other traditional distributed computing. Owing to the different sizes of scientific datasets and the privacy issue concerning some of these datasets, it is essential to find a data placement strategy that can minimize data transmission time. Some state-of-the-art data placement strategies combine edge computing and cloud computing to distribute scientific datasets. However, the dynamic distribution of newly generated datasets to appropriate datacenters and exiting the spent datasets are still a challenge during workflows execution. To address this challenge, this study not only constructs a data placement model that includes shared datasets within the individual and among multiple workflows across various geographical regions, but also proposes a data placement strategy (DYM-RL-DPS) based on algorithms of two stages. First, during the build-time stage of workflows, we use the discrete particle swarm optimization algorithm with differential evolution to pre-allocate initial datasets to proper datacenters. Then, we reformulate the dynamic datasets distribution problem as a Markov decision process and provide a reinforcement learning–based approach to learn the data placement strategy in the runtime stage of scientific workflows. Through using the heterogeneous edge-cloud computing architecture to simulate IoT environments, we designed comprehensive experiments to demonstrate the superiority of DYM-RL-DPS. The results of our strategy can effectively reduce the data transmission time as compared to other strategies.},
  archive      = {J_TMIS},
  author       = {Xin Du and Songtao Tang and Zhihui Lu and Keke Gai and Jie Wu and Patrick C. K. Hung},
  doi          = {10.1145/3531327},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {42:1–26},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Scientific workflows in IoT environments: A data placement strategy based on heterogeneous edge-cloud computing},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-stage competitive particle swarm optimization based
timing-driven x-routing for IC design under smart manufacturing.
<em>TMIS</em>, <em>13</em>(4), 41:1–26. (<a
href="https://doi.org/10.1145/3531328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As timing delay becomes a critical issue in chip performance, there is a burning desire for IC design under smart manufacturing to optimize the delay. As the best connection model for multi-terminal nets, the wirelength and the maximum source-to-sink pathlength of the Steiner minimum tree are the decisive factors of timing delay for routing. In addition, considering that X-routing can get the utmost out of routing resources, this article proposes a Timing-Driven X-routing Steiner Minimum Tree (TD-XSMT) algorithm based on two-stage competitive particle swarm optimization. This work utilizes the multi-objective particle swarm optimization algorithm and redesigns its framework, thus improving its performance. First, a two-stage learning strategy is presented, which balances the exploration and exploitation capabilities of the particle by learning edge structures and pseudo-Steiner point choices. Especially in the second stage, a hybrid crossover strategy is designed to guarantee convergence quality. Second, the competition mechanism is adopted to select particle learning objects and enhance diversity. Finally, according to the characteristics of the discrete TD-XSMT problem, the mutation and crossover operators of the genetic algorithm are used to effectively discretize the proposed algorithm. Experimental results reveal that TSCPSO-TD-XSMT can obtain a smooth trade-off between wirelength and maximum source-to-sink pathlength, and achieve distinguished timing delay optimization.},
  archive      = {J_TMIS},
  author       = {Genggeng Liu and Ruping Zhou and Saijuan Xu and Yuhan Zhu and Wenzhong Guo and Yeh-Cheng Chen and Guolong Chen},
  doi          = {10.1145/3531328},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {41:1–26},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Two-stage competitive particle swarm optimization based timing-driven X-routing for IC design under smart manufacturing},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational intelligence in security of digital twins big
graphic data in cyber-physical systems of smart cities. <em>TMIS</em>,
<em>13</em>(4), 39:1–17. (<a
href="https://doi.org/10.1145/3522760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation focuses on the application of computational intelligence to the security of Digital Twins (DTs) graphic data of the Cyber-physical System (CPS). The intricate and diverse physical space of CPS in the smart city is mapped in virtual space to construct the DTs CPS in the smart city. Besides, Differential Privacy Frequent Subgraph-Big Multigraph (DPFS-BM) is employed to ensure data privacy security. Moreover, the analysis and prediction model for the DTs big graphic data (BGD) in the CPS is built based on Differential Privacy-AlexNet (DP-AlexNet). Alexnet successfully solves the gradient dispersion problem of the Sigmoid function of deep network structures. Finally, the comparative analysis approach is utilized to verify the performance of the model reported here by comparing it with Long Short-Term Memory, Convolutional Neural Network, Recurrent Neural Network, original AlexNet, and Multi-Layer Perceptron in a simulation experiment. Through the comparison in the root mean square error, the mean absolute error, the mean absolute percentage error, training time, and test time, the model proposed here outperforms other models regarding errors, time delay, and time consumption. In the same environment, the system performs better with multi-hop paths, extra relays, and a high fading index; in that case, the outage probability is minimal. Therefore, the DP-AlexNet model is suitable for processing BGD. Moreover, its speed acceleration is more apparent than that of other models, with a higher SpeedUp indicator. The research effectively combines data mining and data security, which is of significant value for optimizing the privacy protection technology of frequent subgraph mining on a single multi-graph. Besides, the constructed DTs of CPS can provide excellent accuracy and a prominent acceleration effect on the premise of low errors. In addition, the model reported here can provide reference for the intelligent and digital development of smart cities.},
  archive      = {J_TMIS},
  author       = {Zhihan Lv and Dongliang Chen and Hailin Feng and Amit Kumar Singh and Wei Wei and Haibin Lv},
  doi          = {10.1145/3522760},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {39:1–17},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Computational intelligence in security of digital twins big graphic data in cyber-physical systems of smart cities},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance-driven x-architecture routing algorithm for
artificial intelligence chip design in smart manufacturing.
<em>TMIS</em>, <em>13</em>(4), 38:1–20. (<a
href="https://doi.org/10.1145/3519422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The new 7-nm Artificial Intelligence (AI) chip is an important milestone recently announced by the IBM research team, with a very important optimization goal of performance. This chip technology can be extended to various business scenarios in the Internet of Things. As the basic model for very large scale integration routing, the Steiner minimal tree can be used in various practical problems, such as wirelength optimization and timing closure. Further considering the X-architecture and the routing resources within obstacles, an effective performance-driven X-architecture routing algorithm for AI chip design in smart manufacturing is proposed to improve the delay performance of the chip. First, a special particle swarm optimization algorithm is presented to solve the discrete length-restricted X-architecture Steiner minimum tree problem in combination with genetic operations, and a particle encoding scheme is presented to encode each particle into an initial routing tree. Second, two lookup tables based on pins and obstacles are established to provide a fast information query for the whole algorithm flow. Third, a strategy of candidate point selection is designed to make the particles satisfy the constraints. Finally, a refinement strategy is implemented to further improve the quality of the final routing tree. Compared with other state-of-the-art algorithms, the proposed algorithm achieves a better total wirelength, which is an important index of performance, thus better satisfying the demand for delay performance of AI chip design in smart manufacturing.},
  archive      = {J_TMIS},
  author       = {Genggeng Liu and Yuhan Zhu and Saijuan Xu and Hao Tang and Yeh-Cheng Chen},
  doi          = {10.1145/3519422},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {38:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Performance-driven X-architecture routing algorithm for artificial intelligence chip design in smart manufacturing},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integration of DevOps practices on a noise monitor system
with CircleCI and terraform. <em>TMIS</em>, <em>13</em>(4), 36:1–24. (<a
href="https://doi.org/10.1145/3505228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lowering pollution levels is one of the main principles of Sustainable Development goals dictated by the United Nations. Consequently, developments on noise monitoring contribute in great manner to this purpose, since they give the opportunity to governments and institutions to maintain track on the matter. While developing a software product for this purpose, with the growth in terms of functional and non-functional requirements, elements such as infrastructure, source code, and others also scale up. Consequently if there are not good practices to face the new challenges of the software product, then it could become more complex to refactor, maintain, and scale, causing a decrease on delivery rate and the quality of the product. DevOps is an emerging concept but still hazy, which involves a set of practices that helps organizations to speed up delivery time, improve software quality and collaboration between teams. The aim of this article is to document the implementation of some DevOps practices such as IaC, continuous integration and deployment, code quality control, and collaboration on a noise monitor system to increase the product quality and automation of deployment. The final result is a set of automated pipelines that represents the entire integration and deployment cycle of the software integrated with platforms to improve quality and maintainability of the software components.},
  archive      = {J_TMIS},
  author       = {Esteban Elias Romero and Carlos David Camacho and Carlos Enrique Montenegro and Óscar Esneider Acosta and Rubén González Crespo and Elvis Eduardo Gaona and Marcelo Herrera Martínez},
  doi          = {10.1145/3505228},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {36:1–24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Integration of DevOps practices on a noise monitor system with CircleCI and terraform},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrating behavioral, economic, and technical insights to
understand and address algorithmic bias: A human-centric perspective.
<em>TMIS</em>, <em>13</em>(3), 34:1–27. (<a
href="https://doi.org/10.1145/3519420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many important decisions are increasingly being made with the help of information systems that use artificial intelligence and machine learning models. These computational models are designed to discover useful patterns from large amounts of data, which augment human capabilities to make decisions in various application domains. However, there are growing concerns regarding the ethics challenges faced by these automated decision-making (ADM) models, most notably on the issue of algorithmic bias , in which the models systematically produce less favorable (i.e., unfair) decisions for certain groups of people. In this commentary, we argue that algorithmic bias is not just a technical (e.g., computational or statistical) problem, and its successful resolution requires deep insights into individual and organizational behavior, economic incentives, as well as complex dynamics of the sociotechnical systems in which the ADM models are embedded. We discuss a human-centric, fairness-aware ADM framework that highlights the holistic involvement of human decision makers in each step of ADM. We review the emerging literature on fairness-aware machine learning and then discuss various strategic decisions that humans need to make, such as formulating proper fairness objectives, recognizing fairness-induced trade-offs and implications, utilizing machine learning model outputs, and managing/governing the decisions of ADM models. We further illustrate how these strategic decisions are jointly informed by behavioral, economic, and design sciences. Our discussions reveal a number of future research opportunities uniquely suitable for Management Information Systems (MIS) researchers to pursue.},
  archive      = {J_TMIS},
  author       = {Gediminas Adomavicius and Mochen Yang},
  doi          = {10.1145/3519420},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {34:1–27},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Integrating behavioral, economic, and technical insights to understand and address algorithmic bias: A human-centric perspective},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social media event prediction using DNN with feedback
mechanism. <em>TMIS</em>, <em>13</em>(3), 33:1–24. (<a
href="https://doi.org/10.1145/3522759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks (OSNs) are a rich source of information, and the data (including user-generated content) can be mined to facilitate real-world event prediction. However, the dynamic nature of OSNs and the fast-pace nature of social events or hot topics compound the challenge of event prediction. This is a key limitation in many existing approaches. For example, our evaluations of six baseline approaches (i.e., logistic regression latent Dirichlet allocation (LDA)-based logistic regression (LR), multi-task learning (MTL), long short-term memory (LSTM) and convolutional neural networks, and transformer-based model) on three datasets collected as part of this research (two from Twitter and one from a news collection site 1 ), reveal that the accuracy of these approaches is between 50\% and 60\%, and they are not capable of utilizing new events in event predictions. Hence, in this article, we develop a novel DNN-based framework (hereafter referred to as event prediction with feedback mechanism— EPFM . Specifically, EPFM makes use of a feedback mechanism based on emerging events detection to improve the performance of event prediction. The feedback mechanism ensembles three outlier detection processes and returns a list of new events. Some of the events will then be chosen by analysts to feed into the fine-tuning process to update the predictive model. To evaluate EPFM, we conduct a series of experiments on the same three datasets, whose findings show that EPFM achieves 80\% accuracy in event detection and outperforms the six baseline approaches.We also validate EPFM’s capability of detecting new events by empirically analyzing the feedback mechanism under different thresholds.},
  archive      = {J_TMIS},
  author       = {Wanlun Ma and Xiangyu Hu and Chao Chen and Sheng Wen and Kkwang Raymond Choo and Yang Xiang},
  doi          = {10.1145/3522759},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {33:1–24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Social media event prediction using DNN with feedback mechanism},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How customer demand reactions impact technology innovation
and security. <em>TMIS</em>, <em>13</em>(3), 32:1–17. (<a
href="https://doi.org/10.1145/3505227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovation is a very important concern for both managers and governmental policy makers. There is an important interplay between security and technology innovation that is largely unrecognized in the literature. This research considers the case where technology innovation in the form of additional product features increases demand through greater functionality. However, the likelihood of a security breach increases with the number of product features as the features interact in unintended ways, thereby increasing the attack surface. Using a two-stage game, we demonstrate how potential demand changes (from direct risk or externalities) impact firm technology innovation strategy. The analysis shows that the type and extent of customer demand reaction has a significant impact on innovative feature development. This research identifies two potential impacts on the level of innovation that can be strategically managed - the impact of externalities on demand and industry risk - explaining how these forces alter the level of innovation in the product ecosystem. Additionally, high-security development is disincentivized, and leads to a type of competitive behavior where the opportunity window for high-security development for all firms is small.},
  archive      = {J_TMIS},
  author       = {M. Lisa Yeo and Erik Rolland and Jacquelyn Rees Ulmer and Raymond A. Patterson},
  doi          = {10.1145/3505227},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {32:1–17},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {How customer demand reactions impact technology innovation and security},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Engineering trustable and auditable choreography-based
systems using blockchain. <em>TMIS</em>, <em>13</em>(3), 31:1–53. (<a
href="https://doi.org/10.1145/3505225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge in engineering distributed systems consists in the integration into their development of a decentralised infrastructure allowing the system participants to trust each other. In this article, we face such a challenge by proposing a model-driven methodology and a related framework to support the engineering of trustable and auditable systems. The approach is based on choreography diagrams specified in the Business Process Model and Notation standard, describing the interactions that should occur among the distributed components of systems. We support the whole lifecycle of choreographies, from their modelling to their distributed execution and auditing. The framework, based on blockchain technology, is named ChorChain. More specifically, ChorChain takes as input a BPMN choreography model and automatically translates it into a Solidity smart contract. The smart contract permits us to enforce the interactions among the cooperating components as prescribed by the choreography model. By leveraging on the auditability of blockchain, ChorChain also supports the activity of auditors continuously. In such a way, ChorChain enables auditors to get some degree of assurance on what happens simultaneously with, or shortly after, information disclosure. We assess the feasibility and effectiveness of the proposed methodology and framework through experiments conducted on the Rinkeby Ethereum Testnet.},
  archive      = {J_TMIS},
  author       = {Flavio Corradini and Alessandro Marcelletti and Andrea Morichetta and Andrea Polini and Barbara Re and Francesco Tiezzi},
  doi          = {10.1145/3505225},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {31:1–53},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Engineering trustable and auditable choreography-based systems using blockchain},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evolutive frequent pattern tree-based incremental
knowledge discovery algorithm. <em>TMIS</em>, <em>13</em>(3), 30:1–20.
(<a href="https://doi.org/10.1145/3495213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To understand current situation in specific scenarios, valuable knowledge should be mined from both historical data and emerging new data. However, most existing algorithms take the historical data and the emerging data as a whole and periodically repeat to analyze all of them, which results in heavy computation overhead. It is also challenging to accurately discover new knowledge in time, because the emerging data are usually small compared to the historical data. To address these challenges, we propose a novel knowledge discovery algorithm based on double evolving frequent pattern trees that can trace the dynamically evolving data by an incremental sliding window. One tree is used to record frequent patterns from the historical data, and the other one records incremental frequent items. The structures of the double frequent pattern trees and their relationships are updated periodically according to the emerging data and a sliding window. New frequent patterns are mined from the incremental data and new knowledge can be obtained from pattern changes. Evaluations show that this algorithm can discover new knowledge from evolving data with good performance and high accuracy.},
  archive      = {J_TMIS},
  author       = {Xin Liu and Liang Zheng and Weishan Zhang and Jiehan Zhou and Shuai Cao and Shaowen Yu},
  doi          = {10.1145/3495213},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {30:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {An evolutive frequent pattern tree-based incremental knowledge discovery algorithm},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection in cybersecurity datasets via cooperative
co-evolution-based feature selection. <em>TMIS</em>, <em>13</em>(3),
29:1–39. (<a href="https://doi.org/10.1145/3495165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection from Big Cybersecurity Datasets is very important; however, this is a very challenging and computationally expensive task. Feature selection (FS) is an approach to remove irrelevant and redundant features and select a subset of features, which can improve the machine learning algorithms’ performance. In fact, FS is an effective preprocessing step of anomaly detection techniques. This article’s main objective is to improve and quantify the accuracy and scalability of both supervised and unsupervised anomaly detection techniques. In this effort, a novel anomaly detection approach using FS, called Anomaly Detection Using Feature Selection (ADUFS), has been introduced. Experimental analysis was performed on five different benchmark cybersecurity datasets with and without feature selection and the performance of both supervised and unsupervised anomaly detection techniques were investigated. The experimental results indicate that instead of using the original dataset, a dataset with a reduced number of features yields better performance in terms of true positive rate (TPR) and false positive rate (FPR) than the existing techniques for anomaly detection. For example, with FS, a supervised anomaly detection technique, multilayer perception increased the TPR by over 200\% and decreased the FPR by about 97\% for the KDD99 dataset. Similarly, with FS, an unsupervised anomaly detection technique, local outlier factor increased the TPR by more than 40\% and decreased the FPR by 15\% and 36\% for Windows 7 and NSL-KDD datasets, respectively. In addition, all anomaly detection techniques require less computational time when using datasets with a suitable subset of features rather than entire datasets. Furthermore, the performance results have been compared with six other state-of-the-art techniques based on a decision tree (J48).},
  archive      = {J_TMIS},
  author       = {A. N. M. Bazlur Rashid and Mohiuddin Ahmed and Leslie F. Sikos and Paul Haskell-Dowland},
  doi          = {10.1145/3495165},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {29:1–39},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Anomaly detection in cybersecurity datasets via cooperative co-evolution-based feature selection},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Configurable batch-processing discovery from event logs.
<em>TMIS</em>, <em>13</em>(3), 28:1–25. (<a
href="https://doi.org/10.1145/3490394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Batch processing is used in many production and service processes and can help achieve efficiencies of scale; however, it can also increase inventories and introduce process delays. Before organizations can develop good understanding about the effects of batch processing on process performance, they should be able to identify potential batch-processing behavior in business processes. However, in many cases such behavior may not be known; for example, batch processing may be occasionally performed during certain time frames, by specific employees, and/or for particular customers. This article presents a novel approach for the identification of batching behavior from process execution data recorded in event logs. The approach can discover different types of batch-processing behaviors and allows users to configure batch-processing characteristics they are interested in. The approach is implemented and evaluated through experiments with synthetic event logs and case studies with real-life event logs. The evaluation demonstrates that the approach can identify various batch-processing behaviors in the context of business processes.},
  archive      = {J_TMIS},
  author       = {Anastasiia Pika and Chun Ouyang and Arthur H. M. ter Hofstede},
  doi          = {10.1145/3490394},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {28:1–25},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Configurable batch-processing discovery from event logs},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decision framework to recommend cruising locations for
taxi drivers under the constraint of booking information. <em>TMIS</em>,
<em>13</em>(3), 27:1–30. (<a
href="https://doi.org/10.1145/3490687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for taxi reservation services has increased, increasing the income of taxi drivers with advanced services has attracted attention. In this article, we propose a path decision framework that considers real-time spatial-temporal predictions and traffic network information. The goal is to optimize a taxi driver&#39;s profit when considering a reservation. Our framework contains four components. First, we build a grid-based road network graph for modeling traffic network information for speeding up the search process. Next, we conduct two prediction modules that adopt advanced deep learning techniques to guide proper search directions for recommending cruising locations. One module of the taxi demand prediction is used to estimate the pick-up probabilities of passengers in the city. Another one is destination prediction, which can predict the distribution of drop-off probabilities and capture the flow of potential passengers. Finally, we propose the H* (Heuristic-star) algorithm, which jointly considers pick-up probabilities, drop-off distribution, road network, distance, and time factors based on the attentive heuristic function to dynamically recommend next cruising locations. Compared with existing route planning methods, the experimental results on a real-world dataset have shown that our proposed approach is more effective and robust. Moreover, our designed search scheme in H* can decrease the computing time and allow the search process to be more efficient. To the best of our knowledge, this is the first work that focuses on guiding a route, which can increase the income of taxi drivers under the constraint of booking information.},
  archive      = {J_TMIS},
  author       = {Hsun-Ping Hsieh and Fandel Lin and Nai-Yu Chen and Tzu-Hsin Yang},
  doi          = {10.1145/3490687},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {27:1–30},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A decision framework to recommend cruising locations for taxi drivers under the constraint of booking information},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature extraction of high-dimensional data based on j-HOSVD
for cyber-physical-social systems. <em>TMIS</em>, <em>13</em>(3),
26:1–21. (<a href="https://doi.org/10.1145/3483448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the further integration of Cyber-Physical-Social systems (CPSSs), there is explosive growth of the data in CPSSs. How to discover effective information or knowledge from CPSSs big data and provide support for subsequent learning tasks has become a core issue. Moreover, modern applications in CPSSs increasingly rely on the processing and analysis of high-dimensional data; the correlation and internal structure of these high-dimensional data are gradually becoming more complex, which further makes traditional machine learning algorithms a little inadequate in processing these data. In this article, we propose two general dimension reduction and feature extraction methods for high-dimensional data based on joint tensor decomposition, namely core feature extraction methods and factor feature extraction methods, which can effectively mine out the common components and hidden patterns of high-dimensional data by joint analysis while maintaining the original data structure. We also verified the effectiveness of the methods from both theoretical and practical aspects. Furthermore, we extend the two feature extraction methods to the tensor distance scenario and illustrate that the compressed features extracted by our models can keep the global information of original data well. Finally, we evaluated proposed methods on two benchmark datasets through classification tasks, and experimental results show that the low-dimensional features extracted by the proposed models have higher classification accuracy than the direct classification of the original data, which further verifies the effectiveness and robustness of our methods.},
  archive      = {J_TMIS},
  author       = {Yuan Gao and Laurence T. Yang and Yaliang Zhao and Jing Yang},
  doi          = {10.1145/3483448},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {26:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Feature extraction of high-dimensional data based on J-HOSVD for cyber-physical-social systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). OWSP-miner: Self-adaptive one-off weak-gap strong pattern
mining. <em>TMIS</em>, <em>13</em>(3), 25:1–23. (<a
href="https://doi.org/10.1145/3476247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gap constraint sequential pattern mining (SPM), as a kind of repetitive SPM, can avoid mining too many useless patterns. However, this method is difficult for users to set a suitable gap without prior knowledge and each character is considered to have the same effects. To tackle these issues, this article addresses a self-adaptive One-off Weak-gap Strong Pattern (OWSP) mining, which has three characteristics. First, it determines the gap constraint adaptively according to the sequence. Second, all characters are divided into two groups: strong and weak characters, and the pattern is composed of strong characters, while weak characters are allowed in the gaps. Third, each character can be used at most once in the process of support (the frequency of pattern) calculation. To handle this problem, this article presents OWSP-Miner, which equips with two key steps: support calculation and candidate pattern generation. A reverse-order filling strategy is employed to calculate the support of a candidate pattern, which reduces the time complexity. OWSP-Miner generates candidate patterns using pattern join strategy, which effectively reduces the candidate patterns. For clarification, time series is employed in the experiments and the results show that OWSP-Miner is not only more efficient but also is easier to mine valuable patterns. In the experiment of stock application, we also employ OWSP-Miner to mine OWSPs and the results show that OWSPs mining is more meaningful in real life. The algorithms and data can be downloaded at https://github.com/wuc567/Pattern-Mining/tree/master/OWSP-Miner.},
  archive      = {J_TMIS},
  author       = {Youxi Wu and Xiaohui Wang and Yan Li and Lei Guo and Zhao Li and Ji Zhang and Xindong Wu},
  doi          = {10.1145/3476247},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {25:1–23},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {OWSP-miner: Self-adaptive one-off weak-gap strong pattern mining},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A quantitative comparative study of data-oriented trust
management schemes in internet of things. <em>TMIS</em>, <em>13</em>(3),
24:1–30. (<a href="https://doi.org/10.1145/3476248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of Things (IoT) paradigm, all entities in the IoT network, whether home users or industrial things, receive data from other things to make decisions. However, in the decentralized, heterogeneous, and rapidly changing IoT network with billions of devices, deciding about where to get the services or information from is critical, especially because malicious entities can exist in such an unmanaged network. Security provisioning alone cannot solve the issue of service quality or reliability. One way to elevate security and reliability in the IoT network is to bridge the gap of trust between objects, and also between humans and objects, while taking into account the IoT network characteristics. Therefore, a proper trust management system must be established on top of the IoT network service architecture. Trust is related to the manner expected from objects in providing services and recommendations. Recommendations are the basis of decision making in every trust management system. Since trust management ideas in the IoT are still immature, the purpose of this article is to survey, analyze, and compare the approaches that have been taken in building trust management systems for the IoT. We break down the features of such systems by analysis and also do quantitative comparisons by simulation. This article is organized into two main parts. First, studies and approaches in this field are compared from four perspectives: (1) trust computation method, (2) resistance to attacks (3) adherence to the limitations of IoT networks and devices, and (4) performance of the trust management scheme. The second part is quantitative and simulates four major methods in this field and measures their performance. We also make extensive analytical comparisons to demonstrate the similarities and discrepancies of current IoT trust management schemes and extract the essence of a resilient trust management framework.},
  archive      = {J_TMIS},
  author       = {Maryam Ebrahimi and Mohammad Hesam Tadayon and Mohammad Sayad Haghighi and Alireza Jolfaei},
  doi          = {10.1145/3476248},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {24:1–30},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A quantitative comparative study of data-oriented trust management schemes in internet of things},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction to the special issue on pattern-driven mining,
analytics, and prediction for decision making, part II. <em>TMIS</em>,
<em>13</em>(3), 23:1–3. (<a
href="https://doi.org/10.1145/3512468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TMIS},
  author       = {Jerry Chun-Wei Lin and Nachiketa Sahoo and Gautam Srivastava and Weiping Ding},
  doi          = {10.1145/3512468},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {23:1–3},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Introduction to the special issue on pattern-driven mining, analytics, and prediction for decision making, part II},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Establishing data provenance for responsible artificial
intelligence systems. <em>TMIS</em>, <em>13</em>(2), 22:1–23. (<a
href="https://doi.org/10.1145/3503488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data provenance, a record that describes the origins and processing of data, offers new promises in the increasingly important role of artificial intelligence (AI)-based systems in guiding human decision making. To avoid disastrous outcomes that can result from bias-laden AI systems, responsible AI builds on four important characteristics: fairness, accountability, transparency, and explainability. To stimulate further research on data provenance that enables responsible AI, this study outlines existing biases and discusses possible implementations of data provenance to mitigate them. We first review biases stemming from the data&#39;s origins and pre-processing. We then discuss the current state of practice, the challenges it presents, and corresponding recommendations to address them. We present a summary highlighting how our recommendations can help establish data provenance and thereby mitigate biases stemming from the data&#39;s origins and pre-processing to realize responsible AI-based systems. We conclude with a research agenda suggesting further research avenues.},
  archive      = {J_TMIS},
  author       = {Karl Werder and Balasubramaniam Ramesh and Rongen (Sophia) Zhang},
  doi          = {10.1145/3503488},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {22:1–23},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Establishing data provenance for responsible artificial intelligence systems},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Counteracting dark web text-based CAPTCHA with generative
adversarial learning for proactive cyber threat intelligence.
<em>TMIS</em>, <em>13</em>(2), 21:1–21. (<a
href="https://doi.org/10.1145/3505226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated monitoring of dark web (DW) platforms on a large scale is the first step toward developing proactive Cyber Threat Intelligence (CTI). While there are efficient methods for collecting data from the surface web, large-scale dark web data collection is often hindered by anti-crawling measures. In particular, text-based CAPTCHA serves as the most prevalent and prohibiting type of these measures in the dark web. Text-based CAPTCHA identifies and blocks automated crawlers by forcing the user to enter a combination of hard-to-recognize alphanumeric characters. In the dark web, CAPTCHA images are meticulously designed with additional background noise and variable character length to prevent automated CAPTCHA breaking. Existing automated CAPTCHA breaking methods have difficulties in overcoming these dark web challenges. As such, solving dark web text-based CAPTCHA has been relying heavily on human involvement, which is labor-intensive and time-consuming. In this study, we propose a novel framework for automated breaking of dark web CAPTCHA to facilitate dark web data collection. This framework encompasses a novel generative method to recognize dark web text-based CAPTCHA with noisy background and variable character length. To eliminate the need for human involvement, the proposed framework utilizes Generative Adversarial Network (GAN) to counteract dark web background noise and leverages an enhanced character segmentation algorithm to handle CAPTCHA images with variable character length. Our proposed framework, DW-GAN, was systematically evaluated on multiple dark web CAPTCHA testbeds. DW-GAN significantly outperformed the state-of-the-art benchmark methods on all datasets, achieving over 94.4\% success rate on a carefully collected real-world dark web dataset. We further conducted a case study on an emergent Dark Net Marketplace (DNM) to demonstrate that DW-GAN eliminated human involvement by automatically solving CAPTCHA challenges with no more than three attempts. Our research enables the CTI community to develop advanced, large-scale dark web monitoring. We make DW-GAN code available to the community as an open-source tool in GitHub.},
  archive      = {J_TMIS},
  author       = {Ning Zhang and Mohammadreza Ebrahimi and Weifeng Li and Hsinchun Chen},
  doi          = {10.1145/3505226},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {21:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Counteracting dark web text-based CAPTCHA with generative adversarial learning for proactive cyber threat intelligence},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The evolution of search: Three computing paradigms.
<em>TMIS</em>, <em>13</em>(2), 20:1–20. (<a
href="https://doi.org/10.1145/3495214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search is probably the most common activity that humans conduct all the time. A search target can be a concrete item (with a yes or no answer and location information), an abstract concept (such as the most important information on the Web about Xindong Wu), or a plan/path for a specific target with an objective function (like flight scheduling with a minimal travel time), among others. In this article, we propose a Universal Connection Theorem (UCT) to suggest that all physical objects/items in the universe are connected through explicit or implicit relationships. Search is to explore the relationships, using different computing methods, to retrieve relevant objects. Under the UCT theorem, we summarize mainstream search approaches into two categories from the user perspective, deterministic search vs. abstract search, and further distinguish them into three computing paradigms: planning based search, data driven search, and knowledge enhanced search. The planning based paradigm explores search as a planning process in a large search space, by graph traversing with heuristic principles to locate optimal solutions. The data driven paradigm seeks to find objects matching the user&#39;s query from a large data repository. Indexing, hashing, information retrieval, and recommendations are typical strategies to tackle the data volumes and select the best answers for users’ queries. The knowledge enhanced search does not aim to find matching objects, but to discover and then meet user&#39;s search requirements through knowledge mining. The evolution of these three search paradigms, from planning to data engineering and knowledge engineering, provides increasing levels of challenges and opportunities. This article elaborates the respective principles of these paradigms.},
  archive      = {J_TMIS},
  author       = {Xindong Wu and Xingquan Zhu and Minghui Wu},
  doi          = {10.1145/3495214},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {20:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {The evolution of search: Three computing paradigms},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying the big shots—a quantile-matching way in the big
data context. <em>TMIS</em>, <em>13</em>(2), 19:1–30. (<a
href="https://doi.org/10.1145/3490395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of big data has raised significant epistemological concerns in information systems research. This study addresses two of them—the deflated p -value problem and the role of explanation and prediction. To address the deflated p -value problem, we propose a multivariate effect size method that uses the log-likelihood ratio test. This method measures the joint effect of all variables used to operationalize one factor, thus overcoming the drawback of the traditional effect size method (θ), which can only be applied at the single variable level. However, because factors can be operationalized as different numbers of variables, direct comparison of multivariate effect size is not possible. A quantile-matching method is proposed to address this issue. This method provides consistent comparison results with the classic quantile method. But it is more flexible and can be applied to scenarios where the quantile method fails. Furthermore, an absolute multivariate effect size statistic is developed to facilitate concluding without comparison. We have tested our method using three different datasets and have found that it can effectively differentiate factors with various effect sizes. We have also compared it with prediction analysis and found consistent results: explanatorily influential factors are usually also predictively influential in a large sample scenario.},
  archive      = {J_TMIS},
  author       = {Guangrui (Kayla) Li and Mike K. P. So and Kar Yan Tam},
  doi          = {10.1145/3490395},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {19:1–30},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Identifying the big Shots—A quantile-matching way in the big data context},
  volume       = {13},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
