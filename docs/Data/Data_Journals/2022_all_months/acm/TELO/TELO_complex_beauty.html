<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TELO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="telo---11">TELO - 11</h2>
<ul>
<li><details>
<summary>
(2022). Multi-donor neural transfer learning for genetic
programming. <em>ACM Transactions on Evolutionary Learning</em>,
<em>2</em>(4), 12:1–40. (<a
href="https://doi.org/10.1145/3563043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Genetic programming (GP), for the synthesis of brand new programs, continues to demonstrate increasingly capable results towards increasingly complex problems. A key challenge in GP is how to learn from the past so that the successful synthesis of simple programs can feed into more challenging unsolved problems. Transfer Learning (TL) in the literature has yet to demonstrate an automated mechanism to identify existing donor programs with high-utility genetic material for new problems, instead relying on human guidance. In this article we present a transfer learning mechanism for GP which fills this gap: we use a Turing-complete language for synthesis, and demonstrate how a neural network (NN) can be used to guide automated code fragment extraction from previously solved problems for injection into future problems. Using a framework which synthesises code from just 10 input-output examples, we first study NN ability to recognise the presence of code fragments in a larger program, then present an end-to-end system which takes only input-output examples and generates code fragments as it solves easier problems, then deploys selected high-utility fragments to solve harder ones. The use of NN-guided genetic material selection shows significant performance increases, on average doubling the percentage of programs that can be successfully synthesised when tested on two different problem corpora, compared with a non-transfer-learning GP baseline.},
  archive  = {J},
  author   = {Alexander Wild and Barry Porter},
  doi      = {10.1145/3563043},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {4},
  pages    = {12:1–40},
  title    = {Multi-donor neural transfer learning for genetic programming},
  volume   = {2},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of evolutionary diversity optimization for
permutation problems. <em>ACM Transactions on Evolutionary
Learning</em>, <em>2</em>(3), 11:1–27. (<a
href="https://doi.org/10.1145/3561974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Generating diverse populations of high-quality solutions has gained interest as a promising extension to the traditional optimization tasks. This work contributes to this line of research with an investigation on evolutionary diversity optimization for three of the most well-studied permutation problems: the Traveling Salesperson Problem (TSP), both symmetric and asymmetric variants, and the Quadratic Assignment Problem (QAP). It includes an analysis of the worst-case performance of a simple mutation-only evolutionary algorithm with different mutation operators, using an established diversity measure. Theoretical results show that many mutation operators for these problems guarantee convergence to maximally diverse populations of sufficiently small size within cubic to quartic expected runtime. On the other hand, the results regarding QAP suggest that strong mutations give poor worst-case performance, as mutation strength contributes exponentially to the expected runtime. Additionally, experiments are carried out on QAPLIB and synthetic instances in unconstrained and constrained settings, and reveal much more optimistic practical performances while corroborating the theoretical findings regarding mutation strength. These results should serve as a baseline for future studies.},
  archive  = {J},
  author   = {Anh Do and Mingyu Guo and Aneta Neumann and Frank Neumann},
  doi      = {10.1145/3561974},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {3},
  pages    = {11:1–27},
  title    = {Analysis of evolutionary diversity optimization for permutation problems},
  volume   = {2},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AutoML loss landscapes. <em>ACM Transactions on Evolutionary
Learning</em>, <em>2</em>(3), 10:1–30. (<a
href="https://doi.org/10.1145/3558774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {As interest in machine learning and its applications becomes more widespread, how to choose the best models and hyper-parameter settings becomes more important. This problem is known to be challenging for human experts, and consequently, a growing number of methods have been proposed for solving it, giving rise to the area of automated machine learning (AutoML). Many of the most popular AutoML methods are based on Bayesian optimization, which makes only weak assumptions about how modifying hyper-parameters effects the loss of a model. This is a safe assumption that yields robust methods, as the AutoML loss landscapes that relate hyper-parameter settings to loss are poorly understood. We build on recent work on the study of one-dimensional slices of algorithm configuration landscapes by introducing new methods that test n -dimensional landscapes for statistical deviations from uni-modality and convexity, and we use them to show that a diverse set of AutoML loss landscapes are highly structured. We introduce a method for assessing the significance of hyper-parameter partial derivatives, which reveals that most (but not all) AutoML loss landscapes only have a small number of hyper-parameters that interact strongly. To further assess hyper-parameter interactions, we introduce a simplistic optimization procedure that assumes each hyper-parameter can be optimized independently, a single time in sequence, and we show that it obtains configurations that are statistically tied with optimal in all of the n -dimensional AutoML loss landscapes that we studied. Our results suggest many possible new directions for substantially improving the state of the art in AutoML.},
  archive  = {J},
  author   = {Yasha Pushak and Holger Hoos},
  doi      = {10.1145/3558774},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {3},
  pages    = {10:1–30},
  title    = {AutoML loss landscapes},
  volume   = {2},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the design of a matrix adaptation evolution strategy for
optimization on general quadratic manifolds. <em>ACM Transactions on
Evolutionary Learning</em>, <em>2</em>(3), 9:1–32. (<a
href="https://doi.org/10.1145/3551394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {An evolution strategy design is presented that allows for an evolution on general quadratic manifolds. That is, it covers elliptic, parabolic, and hyperbolic equality constraints. The peculiarity of the presented algorithm design is that it is an interior point method. It evaluates the objective function only for feasible search parameter vectors and it evolves itself on the nonlinear constraint manifold. Such a characteristic is particularly important in situations where it is not possible to evaluate infeasible parameter vectors, e.g., in simulation-based optimization. This is achieved by a closed form transformation of an individual’s parameter vector, which is in contrast to iterative repair mechanisms. This constraint handling approach is incorporated into a matrix adaptation evolution strategy making such algorithms capable of handling problems containing the constraints considered. Results of different experiments are presented. A test problem consisting of a spherical objective function and a single hyperbolic/parabolic equality constraint is used. It is designed to be scalable in the dimension. As a further benchmark, the Thomson problem is used. Both problems are used to compare the performance of the developed algorithm with other optimization methods supporting constraints. The experiments show the effectiveness of the proposed algorithm on the considered problems. Additionally, an idea for handling multiple constraints is discussed. And for a better understanding of the dynamical behavior of the proposed algorithm, single run dynamics are presented.},
  archive  = {J},
  author   = {Patrick Spettel and Hans-Georg Beyer},
  doi      = {10.1145/3551394},
  journal  = {ACM Transactions on Evolutionary Learning},
  number   = {3},
  pages    = {9:1–32},
  title    = {On the design of a matrix adaptation evolution strategy for optimization on general quadratic manifolds},
  volume   = {2},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on high-dimensional gaussian process modeling with
application to bayesian optimization. <em>TELO</em>, <em>2</em>(2),
8:1–26. (<a href="https://doi.org/10.1145/3545611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Optimization (BO), the application of Bayesian function approximation to finding optima of expensive functions, has exploded in popularity in recent years. In particular, much attention has been paid to improving its efficiency on problems with many parameters to optimize. This attention has trickled down to the workhorse of high-dimensional BO, high-dimensional Gaussian process regression, which is also of independent interest. The great flexibility that the Gaussian process prior implies is a boon when modeling complicated, low-dimensional surfaces but simply says too little when dimension grows too large. A variety of structural model assumptions have been tested to tame high dimensions, from variable selection and additive decomposition to low-dimensional embeddings and beyond. Most of these approaches in turn require modifications of the acquisition function optimization strategy as well. Here, we review the defining structural model assumptions and discuss the benefits and drawbacks of these approaches in practice.},
  archive      = {J_TELO},
  author       = {Mickaël Binois and Nathan Wycoff},
  doi          = {10.1145/3545611},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {8:1–26},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {A survey on high-dimensional gaussian process modeling with application to bayesian optimization},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Code and data synthesis for genetic improvement in emergent
software systems. <em>TELO</em>, <em>2</em>(2), 7:1–35. (<a
href="https://doi.org/10.1145/3542823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergent software systems are assembled from a collection of small code blocks, where some of those blocks have alternative implementation variants; they optimise at run-time by learning which compositions of alternative blocks best suit each deployment environment encountered. In this paper we study the automated synthesis of new implementation variants for a running system using genetic improvement (GI) . Typical GI approaches, however, rely on large amounts of data for accurate training and large code bases from which to source genetic material. In emergent systems we have neither asset, with sparsely sampled runtime data and small code volumes in each building block. We therefore examine two approaches to more effective GI under these constraints: the synthesis of data from sparse samples to construct statistically representative larger training corpora; and the synthesis of code to counter the relative lack of genetic material in our starting population members. Our results demonstrate that a mixture of synthesised and existing code is a viable optimisation strategy, and that phases of increased synthesis can make GI more robust to deleterious mutations. On synthesised data, we find that we can produce equivalent optimisation compared to GI methods using larger data sets, and that this optimisation can produce both useful specialists and generalists.},
  archive      = {J_TELO},
  author       = {Penny Faulkner Rainford and Barry Porter},
  doi          = {10.1145/3542823},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {7:1–35},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Code and data synthesis for genetic improvement in emergent software systems},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep genetic programming trees are robust. <em>TELO</em>,
<em>2</em>(2), 6:1–34. (<a
href="https://doi.org/10.1145/3539738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We sample the genetic programming tree search space and show it is smooth, since many mutations on many test cases have little or no fitness impact. We generate uniformly at random high-order polynomials composed of 12,500 and 750,000 additions and multiplications and follow the impact of small changes to them. From information theory, 32 bit floating point arithmetic is dissipative, and even with 1,501 test cases, deep mutations seldom have any impact on fitness. Absolute difference between parent and child evaluation can grow as well as fall further from the code change location, but the number of disrupted fitness tests falls monotonically. In many cases, deeply nested expressions are robust to crossover syntax changes, bugs, errors, run time glitches, perturbations, and so on, because their disruption falls to zero, and so it fails to propagate beyond the program.},
  archive      = {J_TELO},
  author       = {William B. Langdon},
  doi          = {10.1145/3539738},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {6:1–34},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Deep genetic programming trees are robust},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of evolved response thresholds for decentralized
dynamic task allocation. <em>TELO</em>, <em>2</em>(2), 5:1–30. (<a
href="https://doi.org/10.1145/3530821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the application of a multi-objective genetic algorithm to the problem of task allocation in a self-organizing, decentralized, threshold-based swarm. We use a multi-objective genetic algorithm to evolve response thresholds for a simulated swarm engaged in dynamic task allocation problems: two-dimensional and three-dimensional collective tracking. We show that evolved thresholds not only outperform uniformly distributed thresholds and dynamic thresholds but achieve nearly optimal performance on a variety of tracking problem instances (target paths). More importantly, we demonstrate that thresholds evolved for some problem instances generalize to all other problem instances, eliminating the need to evolve new thresholds for each problem instance to be solved. We analyze the properties that allow these paths to serve as universal training instances and show that they are quite natural. After a priori evolution, the response thresholds in our system are static. The problem instances solved by the swarms are highly dynamic, with schedules of task demands that change over time with significant differences in rate and magnitude of change. That the swarm is able to achieve nearly optimal results refutes the common assumption that a swarm must be dynamic to perform well in a dynamic environment.},
  archive      = {J_TELO},
  author       = {H. David Mathias and Annie S. Wu and Daniel Dang},
  doi          = {10.1145/3530821},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {2},
  pages        = {5:1–30},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Analysis of evolved response thresholds for decentralized dynamic task allocation},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reusability and transferability of macro actions for
reinforcement learning. <em>TELO</em>, <em>2</em>(1), 4:1–16. (<a
href="https://doi.org/10.1145/3514260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional reinforcement learning (RL) typically determines an appropriate primitive action at each timestep. However, by using a proper macro action, defined as a sequence of primitive actions, an RL agent is able to bypass intermediate states to a farther state and facilitate its learning procedure. The problem we would like to investigate is what associated beneficial properties that macro actions may possess. In this article, we unveil the properties of reusability and transferability of macro actions. The first property, reusability , means that a macro action derived along with one RL method can be reused by another RL method for training, while the second one, transferability , indicates that a macro action can be utilized for training agents in similar environments with different reward settings. In our experiments, we first derive macro actions along with RL methods. We then provide a set of analyses to reveal the properties of reusability and transferability of the derived macro actions.},
  archive      = {J_TELO},
  author       = {Yi-Hsiang Chang and Kuan-Yu Chang and Henry Kuo and Chun-Yi Lee},
  doi          = {10.1145/3514260},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {4:1–16},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Reusability and transferability of macro actions for reinforcement learning},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IOHanalyzer: Detailed performance analyses for iterative
optimization heuristics. <em>TELO</em>, <em>2</em>(1), 3:1–29. (<a
href="https://doi.org/10.1145/3510426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benchmarking and performance analysis play an important role in understanding the behaviour of iterative optimization heuristics (IOHs) such as local search algorithms, genetic and evolutionary algorithms, Bayesian optimization algorithms, etc. This task, however, involves manual setup, execution, and analysis of the experiment on an individual basis, which is laborious and can be mitigated by a generic and well-designed platform. For this purpose, we propose IOHanalyzer, a new user-friendly tool for the analysis, comparison, and visualization of performance data of IOHs. Implemented in R and C++ , IOHanalyzer is fully open source. It is available on CRAN and GitHub. IOHanalyzer provides detailed statistics about fixed-target running times and about fixed-budget performance of the benchmarked algorithms with a real-valued codomain, single-objective optimization tasks. Performance aggregation over several benchmark problems is possible, for example in the form of empirical cumulative distribution functions. Key advantages of IOHanalyzer over other performance analysis packages are its highly interactive design, which allows users to specify the performance measures, ranges, and granularity that are most useful for their experiments, and the possibility to analyze not only performance traces, but also the evolution of dynamic state parameters. IOHanalyzer can directly process performance data from the main benchmarking platforms, including the COCO platform, Nevergrad, the SOS platform, and IOHexperimenter. An R programming interface is provided for users preferring to have a finer control over the implemented functionalities.},
  archive      = {J_TELO},
  author       = {Hao Wang and Diederick Vermetten and Furong Ye and Carola Doerr and Thomas Bäck},
  doi          = {10.1145/3510426},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {3:1–29},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {IOHanalyzer: Detailed performance analyses for iterative optimization heuristics},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Saddle point optimization with approximate minimization
oracle and its application to robust berthing control. <em>TELO</em>,
<em>2</em>(1), 2:1–32. (<a
href="https://doi.org/10.1145/3510425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an approach to saddle point optimization relying only on oracles that solve minimization problems approximately. We analyze its convergence property on a strongly convex–concave problem and show its linear convergence toward the global min–max saddle point. Based on the convergence analysis, we develop a heuristic approach to adapt the learning rate. An implementation of the developed approach using the (1+1)-CMA-ES as the minimization oracle, namely, Adversarial-CMA-ES, is shown to outperform several existing approaches on test problems. Numerical evaluation confirms the tightness of the theoretical convergence rate bound as well as the efficiency of the learning rate adaptation mechanism. As an example of real-world problems, the suggested optimization method is applied to automatic berthing control problems under model uncertainties, showing its usefulness in obtaining solutions robust to uncertainty.},
  archive      = {J_TELO},
  author       = {Youhei Akimoto and Yoshiki Miyauchi and Atsuo Maki},
  doi          = {10.1145/3510425},
  journal      = {ACM Transactions on Evolutionary Learning and Optimization},
  number       = {1},
  pages        = {2:1–32},
  shortjournal = {ACM Trans. Evol. Learn. Optim.},
  title        = {Saddle point optimization with approximate minimization oracle and its application to robust berthing control},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
