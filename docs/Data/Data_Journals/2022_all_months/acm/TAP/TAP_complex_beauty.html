<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tap---19">TAP - 19</h2>
<ul>
<li><details>
<summary>
(2022). Tactile texture display combining vibrotactile and
electrostatic-friction stimuli: Substantial effects on realism and
moderate effects on behavioral responses. <em>TAP</em>, <em>19</em>(4),
1–18. (<a href="https://doi.org/10.1145/3539733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is increasing demand for tactile feedback functions for touch panels. We investigated whether virtual roughness texture quality can be improved through simultaneous use of vibrotactile and electrostatic-friction stimuli. This conjunctive use is expected to improve the perceptual quality of texture stimuli, because vibrotactile and electrostatic-friction stimuli have complementary characteristics. Our previous studies confirmed that these conjunct stimuli yield enhanced realism for simple grating roughness. In this study, we conducted experiments using simple and complex sinusoidal surface profiles consisting of one or two spatial wave components. Three different evaluation criteria were employed. The first criterion concerned the subjective realism, i.e., similarity with actual roughness textures, of virtual roughness textures. Participants compared the following three stimulus conditions: vibrotactile stimuli only, electrostatic-friction stimuli only, and their conjunct stimuli. The conjunct stimuli yielded the greatest realism. The second criterion concerned roughness texture identification under each of the three stimulus conditions for five different roughness textures. The highest identification accuracy rate was achieved under the conjunct stimulus condition; however, the performance difference was marginal. The third criterion concerned the discrimination threshold of the grating-scale spatial wavelength. There were no marked differences among the results for the three conditions. The findings of this study will improve virtual texture quality for touch-panel-type surface tactile displays.},
  archive      = {J_TAP},
  doi          = {10.1145/3539733},
  journal      = {ACM Transactions on Applied Perception},
  month        = {11},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Tactile texture display combining vibrotactile and electrostatic-friction stimuli: Substantial effects on realism and moderate effects on behavioral responses},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Perceptual guidelines for optimizing field of view in
stereoscopic augmented reality displays. <em>TAP</em>, <em>19</em>(4),
1–23. (<a href="https://doi.org/10.1145/3554921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Near-eye display systems for augmented reality (AR) aim to seamlessly merge virtual content with the user’s view of the real-world. A substantial limitation of current systems is that they only present virtual content over a limited portion of the user’s natural field of view (FOV). This limitation reduces the immersion and utility of these systems. Thus, it is essential to quantify FOV coverage in AR systems and understand how to maximize it. It is straightforward to determine the FOV coverage for monocular AR systems based on the system architecture. However, stereoscopic AR systems that present 3D virtual content create a more complicated scenario because the two eyes’ views do not always completely overlap. The introduction of partial binocular overlap in stereoscopic systems can potentially expand the perceived horizontal FOV coverage, but it can also introduce perceptual nonuniformity artifacts. In this arrticle, we first review the principles of binocular FOV overlap for natural vision and for stereoscopic display systems. We report the results of a set of perceptual studies that examine how different amounts and types of horizontal binocular overlap in stereoscopic AR systems influence the perception of nonuniformity across the FOV. We then describe how to quantify the horizontal FOV in stereoscopic AR when taking 3D content into account. We show that all stereoscopic AR systems result in a variable horizontal FOV coverage and variable amounts of binocular overlap depending on fixation distance. Taken together, these results provide a framework for optimizing perceived FOV coverage and minimizing perceptual artifacts in stereoscopic AR systems for different use cases.},
  archive      = {J_TAP},
  doi          = {10.1145/3554921},
  journal      = {ACM Transactions on Applied Perception},
  month        = {11},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Perceptual guidelines for optimizing field of view in stereoscopic augmented reality displays},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating a combination of input modalities, canvas
geometries, and inking triggers on on-air handwriting in virtual
reality. <em>TAP</em>, <em>19</em>(4), 1–19. (<a
href="https://doi.org/10.1145/3560817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans communicate by writing, often taking notes that assist thinking. With the growing popularity of collaborative Virtual Reality (VR) applications, it is imperative that we better understand aspects that affect writing in these virtual experiences. On-air writing in VR is a popular writing paradigm due to its simplicity in implementation without any explicit needs for specialized hardware. A host of factors can affect the efficacy of this writing paradigm and in this work, we delved into investigating the same. Along these lines, we investigated the effects of a combination of factors on users’ on-air writing performance, aiming to understand the circumstances under which users can both effectively and efficiently write in VR. We were interested in studying the effects of the following factors: (1) input modality: brush vs. near-field raycast vs. pointing gesture, (2) inking trigger method: haptic feedback vs. button based trigger, and (3) canvas geometry: plane vs. hemisphere. To evaluate the writing performance, we conducted an empirical evaluation with thirty participants, requiring them to write the words we indicated under different combinations of these factors. Dependent measures including the writing speed, accuracy rates, perceived workloads, and so on, were analyzed. Results revealed that the brush based input modality produced the best results in writing performance, that haptic feedback was not always effective over button based triggering, and that there are trade-offs associated with the different types of canvas geometries used. This work attempts at laying a foundation for future investigations that seek to understand and further improve the on-air writing experience in immersive virtual environments.},
  archive      = {J_TAP},
  doi          = {10.1145/3560817},
  journal      = {ACM Transactions on Applied Perception},
  month        = {11},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Investigating a combination of input modalities, canvas geometries, and inking triggers on on-air handwriting in virtual reality},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Experience matters: Longitudinal changes in sensitivity to
rotational gains in virtual reality. <em>TAP</em>, <em>19</em>(4), 1–18.
(<a href="https://doi.org/10.1145/3560818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Redirected walking techniques use rotational gains to guide users away from physical obstacles as they walk in a virtual world, effectively creating the illusion of a larger virtual space than is physically present. Designers often want to keep users unaware of this manipulation, which is made possible by limitations in human perception that render rotational gains imperceptible below a certain threshold. Many aspects of these thresholds have been studied; however, no research has yet considered whether these thresholds may change over time as users gain more experience with them. To study this, we recruited 20 novice VR users (no more than 1 hour of prior experience with an HMD) and provided them with an Oculus Quest to use for 4 weeks on their own time. They were tasked to complete an activity assessing their sensitivity to rotational gain once each week, in addition to whatever other activities they wanted to perform. No feedback was provided to participants about their performance during each activity, minimizing the possibility of learning effects accounting for any observed changes over time. We observed that participants became significantly more sensitive to rotation gains over time, underscoring the importance of considering prior user experience in applications involving rotational gain, as well as how prior user experience may affect other, broader applications of VR.},
  archive      = {J_TAP},
  doi          = {10.1145/3560818},
  journal      = {ACM Transactions on Applied Perception},
  month        = {11},
  number       = {4},
  pages        = {1-18},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Experience matters: Longitudinal changes in sensitivity to rotational gains in virtual reality},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sensitivity to hand offsets and related behavior in virtual
environments over time. <em>TAP</em>, <em>19</em>(4), 1–15. (<a
href="https://doi.org/10.1145/3561055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explored how users’ sensitivity to offsets in their avatars’ virtual hands changes as they gain exposure to virtual reality. We conducted an experiment using a two-alternative forced choice (2-AFC) design over the course of 4 weeks, split into four sessions. The trials in each session had a variety of eight offset distances paired with eight offset directions (across a two-dimensional plane). While we did not find evidence that users became more sensitive to the offsets over time, we did find evidence of behavioral changes. Specifically, participants’ head–hand coordination and completion time varied significantly as the sessions went on. We discuss the implications of both results and how they could influence our understanding of long-term calibration for perception-action coordination in virtual environments.},
  archive      = {J_TAP},
  doi          = {10.1145/3561055},
  journal      = {ACM Transactions on Applied Perception},
  month        = {11},
  number       = {4},
  pages        = {1-15},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Sensitivity to hand offsets and related behavior in virtual environments over time},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introduction to the special issue on SAP 2022. <em>TAP</em>,
<em>19</em>(4), 1–2. (<a href="https://doi.org/10.1145/3563136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TAP},
  doi          = {10.1145/3563136},
  journal      = {ACM Transactions on Applied Perception},
  month        = {11},
  number       = {4},
  pages        = {1-2},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Introduction to the special issue on SAP 2022},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring sonification mapping strategies for spatial
auditory guidance in immersive virtual environments. <em>ACM
Transactions on Applied Perceptions (TAP)</em>, <em>19</em>(3), 1–21.
(<a href="https://doi.org/10.1145/3528171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Spatial auditory cues are important for many tasks in immersive virtual environments, especially guidance tasks. However, due to the limited fidelity of spatial sounds rendered by generic Head-Related Transfer Functions (HRTFs), sound localization usually has a limited accuracy, especially in elevation, which can potentially impact the effectiveness of auditory guidance. To address this issue, we explored whether integrating sonification with spatial audio can enhance the perceptions of auditory guidance cues so user performance in auditory guidance tasks can be improved. Specifically, we investigated the effects of sonification mapping strategy using a controlled experiment that compared four elevation sonification mapping strategies: absolute elevation mapping, unsigned relative elevation mapping, signed relative elevation mapping, and binary relative elevation mapping. In addition, we examined whether azimuth sonification mapping can further benefit the perception of spatial sounds. The results demonstrate that spatial auditory cues can be effectively enhanced by integrating elevation and azimuth sonification, where the accuracy and speed of guidance tasks can be significantly improved. In particular, the overall results suggest that binary relative elevation mapping is generally the most effective strategy among four elevation sonification mapping strategies, which indicates that auditory cues with clear directional information are key to efficient auditory guidance.},
  archive  = {J},
  doi      = {10.1145/3528171},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {9},
  number   = {3},
  pages    = {1-21},
  title    = {Exploring sonification mapping strategies for spatial auditory guidance in immersive virtual environments},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vibrotactile threshold measurements at the wrist using
parallel vibration actuators. <em>ACM Transactions on Applied
Perceptions (TAP)</em>, <em>19</em>(3), 1–11. (<a
href="https://doi.org/10.1145/3529259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article presents an investigation into the perceptual vibrotactile thresholds for a range of frequencies on both the inside and outside areas of the wrist when exciting the skin with parallel vibrations, realized using the L5 actuator made by Lofelt GmbH. The vibrotactile threshold of 30 participants was measured using a modified audiometry test for the frequency range of 25–1,000 Hz. The average threshold across the respective frequencies was then ultimately determined from acceleration minima. The results show that maximum sensitivity lies in the range of 100–275 Hz (peaking at 200 Hz) for the inside and 75–250 Hz (peaking at 125 Hz) for the outside of the wrist and that thresholds are overall higher for the hairy skin on the outside of the wrist than for the glabrous skin on the inside. The results also show that the vibrotactile thresholds varied highly between individuals. Hence, personalized threshold measurements at the actuator locations will be required to fine-tune a device for the user. This study is a part of an ongoing research and development project where the aim is to develop a tactile display device and a music encoding scheme with the purpose of augmenting the musical enjoyment of cochlear implant recipients. These results, along with results from planned follow-up experiments, will be used to determine the appropriate frequency range and to cast light on the dynamic range on offer for the tactile device.},
  archive  = {J},
  doi      = {10.1145/3529259},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {9},
  number   = {3},
  pages    = {1-11},
  title    = {Vibrotactile threshold measurements at the wrist using parallel vibration actuators},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating realism in example-based terrain synthesis.
<em>ACM Transactions on Applied Perceptions (TAP)</em>, <em>19</em>(3),
1–18. (<a href="https://doi.org/10.1145/3531526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We report two studies that investigate the use of subjective believability in the assessment of objective realism of terrain. The first demonstrates that there is a clear subjective feature bias that depends on the types of terrain being evaluated: Our participants found certain natural terrains to be more believable than others. This confounding factor means that any comparison experiment must not ask participants to compare terrains with different types of features. Our second experiment assesses four methods of example-based terrain synthesis, comparing them against each other and against real terrain. Our results show that, while all tested methods can produce terrain that is indistinguishable from reality, all also can produce poor terrain; that there is no one method that is consistently better than the others; and that those who have professional expertise in geology, cartography, or image analysis are better able to distinguish real terrain from synthesized terrain than the general population, but those who have professional expertise in the visual arts are not.},
  archive  = {J},
  doi      = {10.1145/3531526},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {9},
  number   = {3},
  pages    = {1-18},
  title    = {Evaluating realism in example-based terrain synthesis},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning–based modeling and prediction of the
intrinsic relationship between human emotion and music. <em>ACM
Transactions on Applied Perceptions (TAP)</em>, <em>19</em>(3), 1–12.
(<a href="https://doi.org/10.1145/3534966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Human emotion is one of the most complex psychophysiological phenomena and has been reported to be affected significantly by music listening. It is supposed that there is an intrinsic relationship between human emotion and music, which can be modeled and predicted quantitatively in a supervised manner. Here, a heuristic clustering analysis is carried out on large-scale free music archive to derive a genre-diverse music library, to which the emotional response of participants is measured using a standard protocol, consequently resulting in a systematic emotion-to-music profile. Eight machine learning methods are employed to statistically correlate the basic sound features of music audio tracks in the library with the measured emotional response of tested people to the music tracks in a training set and to blindly predict the emotional response from sound features in a test set. This study found that nonlinear methods are more robust and predictable but considerably more time-consuming than linear approaches. The neural networks have strong internal fittability but are associated with a significant overfitting issue. The support vector machine and Gaussian process exhibit both high internal stability and satisfactory external predictability in all used methods; they are considered as promising tools to model, predict, and explain the intrinsic relationship between human emotion and music. The psychological basis and perceptional implication underlying the built machine learning models are also discussed to find out the key music factors that affect human emotion.},
  archive  = {J},
  doi      = {10.1145/3534966},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {9},
  number   = {3},
  pages    = {1-12},
  title    = {Machine learning–based modeling and prediction of the intrinsic relationship between human emotion and music},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Creating word paintings jointly considering semantics,
attention, and aesthetics. <em>ACM Transactions on Applied Perceptions
(TAP)</em>, <em>19</em>(3), 1–21. (<a
href="https://doi.org/10.1145/3539610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this article, we present a content-aware method for generating a word painting. Word painting is a composite artwork made from the assemblage of words extracted from a given text, which carries similar semantics and visual features to a given source image. However, word painting, usually created by skilled artists, involves tedious manual processes, especially when generating streamlines and laying out text. Hence, we provide an easy method to create word paintings for users. How to design textural layout that simultaneously conveys the input image and enables easy access to the semantic theme is the key challenge to generating a visually pleasing word painting. To address this issue, given an image and its content-related text, we first decompose the input image into several regions and approximate each region with a smooth vector field. At the same time, by analyzing the input text, we extract some weighted keywords as the graphic elements. Then, to measure the likelihood of positions in the input image that attract the observers’ attention, we generate a saliency map with our trained visual attention model. Finally, jointly considering visual attention and aesthetic rules, we propose an energy-based optimization framework to arrange extracted keywords into the decomposed regions and synthesize a word painting. Experimental results and user studies show that this method is able to generate a fashionable and appealing word painting.},
  archive  = {J},
  doi      = {10.1145/3539610},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {9},
  number   = {3},
  pages    = {1-21},
  title    = {Creating word paintings jointly considering semantics, attention, and aesthetics},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Display-size dependent effects of 3D viewing on subjective
impressions. <em>ACM Transactions on Applied Perceptions (TAP)</em>,
<em>19</em>(2), 1–15. (<a
href="https://doi.org/10.1145/3510461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper describes how the screen size of 3D displays affect the subjective impressions of 3D-visualized content. The key requirement for 3D displays is the presentation of depth cues comprising binocular disparities and/or motion parallax; however, the development of displays and production of content that include these cues leads to an increase in costs. Given the variety of screen sizes, it is expected that 3D characteristics are experienced differently by viewers depending on the screen size. We asked 48 participants to evaluate the 3D experience when using three different-sized stereoscopic displays (11.5, 55, and 200 inches) with head trackers. The participants were asked to score presented stimuli on 20 opposite-term pairs based on the semantic differential method after viewing each of six stimuli. Using factor analysis, we extracted three principal factors: power , related to strong three-dimensionality, real, etc.; visibility , related to stable, natural, etc.; and space , related to agile, open, etc., which had proportions of variances of 0.317, 0.277, and 0.251, respectively; their cumulation was 0.844. We confirmed that the three different-sized displays did not produce the same subjective impressions of the 3D characteristics. In particular, on the small-sized display, we found larger effects on power and space impressions from motion parallax (η 2 = 0.133 and 0.161, respectively) than for the other two sizes. We found degradation of the visibility impressions from binocular disparities, which might be caused by artifacts from stereoscopy. The effects of 3D viewing on subjective impression depends on the display size, and small-sized displays offer the largest benefits by adding 3D characteristics to 2D visualization.},
  archive  = {J},
  doi      = {10.1145/3510461},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {7},
  number   = {2},
  pages    = {1-15},
  title    = {Display-size dependent effects of 3D viewing on subjective impressions},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PTRM: Perceived terrain realism metric. <em>ACM Transactions
on Applied Perceptions (TAP)</em>, <em>19</em>(2), 1–22. (<a
href="https://doi.org/10.1145/3514244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Terrains are visually prominent and commonly needed objects in many computer graphics applications. While there are many algorithms for synthetic terrain generation, it is rather difficult to assess the realism of a generated output. This article presents a first step toward the direction of perceptual evaluation for terrain models. We gathered and categorized several classes of real terrains, and we generated synthetic terrain models using computer graphics methods. The terrain geometries were rendered by using the same texturing, lighting, and camera position. Two studies on these image sets were conducted, ranking the terrains perceptually, and showing that the synthetic terrains are perceived as lacking realism compared to the real ones. We provide insight into the features that affect the perceived realism by a quantitative evaluation based on localized geomorphology-based landform features (geomorphons) that categorize terrain structures such as valleys, ridges, hollows, and so forth. We show that the presence or absence of certain features has a significant perceptual effect. The importance and presence of the terrain features were confirmed by using a generative deep neural network that transferred the features between the geometric models of the real terrains and the synthetic ones. The feature transfer was followed by another perceptual experiment that further showed their importance and effect on perceived realism. We then introduce Perceived Terrain Realism Metrics (PTRM), which estimates human-perceived realism of a terrain represented as a digital elevation map by relating the distribution of terrain features with their perceived realism. This metric can be used on a synthetic terrain, and it will output an estimated level of perceived realism. We validated the proposed metrics on real and synthetic data and compared them to the perceptual studies.},
  archive  = {J},
  doi      = {10.1145/3514244},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {7},
  number   = {2},
  pages    = {1-22},
  title    = {PTRM: Perceived terrain realism metric},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the immersive properties of high dynamic range video.
<em>ACM Transactions on Applied Perceptions (TAP)</em>, <em>19</em>(2),
1–15. (<a href="https://doi.org/10.1145/3524692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents the results from two studies which used a dual-task methodology to measure an audience&#39;s experience of immersion while watching video under typical television viewing conditions. Immersion was measured while participants watched either a high dynamic range, wide color gamut video or a standard dynamic range, standard color gamut video, in high definition or ultra-high definition. Other video parameters were carefully measured and controlled. The study found that high dynamic range, wide color gamut video is significantly more immersive than standard dynamic range, standard color gamut video in the chosen configuration. However, there was no evidence of significant differences in immersion between high-definition and ultra-high-definition resolutions.},
  archive  = {J},
  doi      = {10.1145/3524692},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {7},
  number   = {2},
  pages    = {1-15},
  title    = {On the immersive properties of high dynamic range video},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The duration of an auditory icon can affect how the listener
interprets its meaning. <em>ACM Transactions on Applied Perceptions
(TAP)</em>, <em>19</em>(2), 1–16. (<a
href="https://doi.org/10.1145/3527269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Initially introduced in the field of informatics, an auditory icon consists of a short sound that is present in everyday life, used to represent a specific event, object, function, or action. Auditory icons have been studied in various fields, and overall, compared to other types of auditory alarms, they can be very efficient in informing the listener about a situation or event. So far, auditory icons have been used with a wide range of durations, ranging from a few hundreds of milliseconds up to several seconds. Still little is known, however, about whether and how icon duration influences its interpretation. In the present study, we therefore asked listeners to rate 12 auditory icons, divided into four different sound categories (nonverbal human sounds, machine sounds, human activities, and animal vocalizations), in five different durations (200, 400, 800, 1,600, and 3,200 ms). They rated (1) how appropriately the icon sound itself represented the icon&#39;s referent and (2) how appropriately each duration of the icon sound represented the icon&#39;s referent. Overall, results demonstrate that the duration of the auditory icons in this stimulus set can directly affect how the icon represents the referent. Auditory icons in the test set characterized by human activities represented their referent most appropriately in a relatively shorter duration (400 or 800 ms). The majority of the auditory icons in the set consisting of machine sounds, nonverbal human sounds , and animal vocalizations , however, were considered as more appropriately representing their referent in longer durations (800 ms and 1,600 ms). Further systematic research is necessary to determine whether the duration effects shown here may generalize to other stimulus sets.},
  archive  = {J},
  doi      = {10.1145/3527269},
  journal  = {ACM Transactions on Applied Perceptions},
  month    = {7},
  number   = {2},
  pages    = {1-16},
  title    = {The duration of an auditory icon can affect how the listener interprets its meaning},
  volume   = {19},
  year     = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The perceptual consistency and association of the LMA effort
elements. <em>TAP</em>, <em>19</em>(1), 1–17. (<a
href="https://doi.org/10.1145/3473041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laban Movement Analysis (LMA) and its Effort element provide a conceptual framework through which we can observe, describe, and interpret the intention of movement. Effort attributes provide a link between how people move and how their movement communicates to others. It is crucial to investigate the perceptual characteristics of Effort to validate whether it can serve as an effective framework to support a wide range of applications in animation and robotics that require a system for creating or perceiving expressive variation in motion. To this end, we first constructed an Effort motion database of short video clips of five different motions: walk, sit down, pass, put, wave performed in eight ways corresponding to the extremes of the Effort elements. We then performed a perceptual evaluation to examine the perceptual consistency and perceived associations among Effort elements: Space (Indirect/Direct), Time (Sustained/Sudden), Weight (Light/Strong), and Flow (Free/Bound) that appeared in the motion stimuli. The results of the perceptual consistency evaluation indicate that although the observers do not perceive the LMA Effort element 100% as intended, true response rates of seven Effort elements are higher than false response rates except for light Effort. The perceptual consistency results showed varying tendencies by motion. The perceptual association between LMA Effort elements showed that a single LMA Effort element tends to co-occur with the elements of other factors, showing significant correlation with one or two factors (e.g., indirect and free, light and free).},
  archive      = {J_TAP},
  doi          = {10.1145/3473041},
  journal      = {ACM Transactions on Applied Perception},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {The perceptual consistency and association of the LMA effort elements},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Motor variability in complex gesture learning: Effects of
movement sonification and musical background. <em>TAP</em>,
<em>19</em>(1), 1–21. (<a
href="https://doi.org/10.1145/3482967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing interest in movement sonification and expressive gesture-based interaction, it is important to understand which factors contribute to movement learning and how. We explore the effects of movement sonification and users’ musical background on motor variability in complex gesture learning. We contribute an empirical study in which musicians and non-musicians learn two gesture sequences over three days, with and without movement sonification. Results show the interlaced interaction effects of these factors and how they unfold in the three-day learning process. For gesture 1, which is fast and dynamic with a direct “action-sound” sonification, movement sonification induces higher variability for both musicians and non-musicians on day 1. While musicians reduce this variability to a similar level as no auditory feedback condition on day 2 and day 3, non-musicians remain to have significantly higher variability. Across three days, musicians also have significantly lower variability than non-musicians. For gesture 2, which is slow and smooth with an “action-music” metaphor, there are virtually no effects. Based on these findings, we recommend future studies to take into account participants’ musical background, consider longitudinal study to examine these effects on complex gestures, and use awareness when interpreting the results given a specific design of gesture and sound.},
  archive      = {J_TAP},
  doi          = {10.1145/3482967},
  journal      = {ACM Transactions on Applied Perception},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {Motor variability in complex gesture learning: Effects of movement sonification and musical background},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The effects on driving behavior when using a head-mounted
display in a dynamic driving simulator. <em>TAP</em>, <em>19</em>(1),
1–18. (<a href="https://doi.org/10.1145/3483793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving simulators are established tools used during automotive development and research. Most simulators use either monitors or projectors as their primary display system. However, the emergence of a new generation of head-mounted displays has triggered interest in using these as the primary display type. The general benefits and drawbacks of head-mounted displays are well researched, but their effect on driving behavior in a simulator has not been sufficiently quantified. This article presents a study of driving behavior differences between projector-based graphics and head-mounted display in a large dynamic driving simulator. This study has selected five specific driving maneuvers suspected of affecting driving behavior differently depending on the choice of display technology. Some of these maneuvers were chosen to reveal changes in lateral and longitudinal driving behavior. Others were picked for their ability to highlight the benefits and drawbacks of head-mounted displays in a driving context. The results show minor changes in lateral and longitudinal driver behavior changes when comparing projectors and a head-mounted display. The most noticeable difference in favor of projectors was seen when the display resolution is critical to the driving task. The choice of display type did not affect simulator sickness nor the realism rated by the subjects.},
  archive      = {J_TAP},
  doi          = {10.1145/3483793},
  journal      = {ACM Transactions on Applied Perception},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {The effects on driving behavior when using a head-mounted display in a dynamic driving simulator},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A virtual reality application of the rubber hand illusion
induced by ultrasonic mid-air haptic stimulation. <em>TAP</em>,
<em>19</em>(1), 1–19. (<a
href="https://doi.org/10.1145/3487563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonic mid-air haptic technologies, which provide haptic feedback through airwaves produced using ultrasound, could be employed to investigate the sense of body ownership and immersion in virtual reality (VR) by inducing the virtual hand illusion (VHI). Ultrasonic mid-air haptic perception has solely been investigated for glabrous (hairless) skin, which has higher tactile sensitivity than hairy skin. In contrast, the VHI paradigm typically targets hairy skin without comparisons to glabrous skin. The aim of this article was to investigate illusory body ownership, the applicability of ultrasonic mid-air haptics, and perceived immersion in VR using the VHI. Fifty participants viewed a virtual hand being stroked by a feather synchronously and asynchronously with the ultrasonic stimulation applied to the glabrous skin on the palmar surface and the hairy skin on the dorsal surface of their hands. Questionnaire responses revealed that synchronous stimulation induced a stronger VHI than asynchronous stimulation. In synchronous conditions, the VHI was stronger for palmar stimulation than dorsal stimulation. The ultrasonic stimulation was also perceived as more intense on the palmar surface compared to the dorsal surface. Perceived immersion was not related to illusory body ownership per se but was enhanced by the provision of synchronous stimulation.},
  archive      = {J_TAP},
  doi          = {10.1145/3487563},
  journal      = {ACM Transactions on Applied Perception},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {ACM Trans. Appl. Perc.},
  title        = {A virtual reality application of the rubber hand illusion induced by ultrasonic mid-air haptic stimulation},
  volume       = {19},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
