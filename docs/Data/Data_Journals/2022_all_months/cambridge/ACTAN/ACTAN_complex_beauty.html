<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ACTAN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="actan---6">ACTAN - 6</h2>
<ul>
<li><details>
<summary>
(2022). ANU volume 31 cover and back matter. <em>ACTAN</em>,
<em>31</em>, b1. (<a
href="https://doi.org/10.1017/S0962492922000071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ACTAN},
  doi          = {10.1017/S0962492922000071},
  journal      = {Acta Numerica},
  month        = {5},
  pages        = {b1},
  shortjournal = {Acta Numer.},
  title        = {ANU volume 31 cover and back matter},
  volume       = {31},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotic-preserving schemes for multiscale physical
problems. <em>ACTAN</em>, <em>31</em>, 415–489. (<a
href="https://doi.org/10.1017/S0962492922000010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the asymptotic transitions from microscopic to macroscopic physics, their computational challenges and the asymptotic-preserving (AP) strategies to compute multiscale physical problems efficiently. Specifically, we will first study the asymptotic transition from quantum to classical mechanics, from classical mechanics to kinetic theory, and then from kinetic theory to hydrodynamics. We then review some representative AP schemes that mimic these asymptotic transitions at the discrete level, and hence can be used crossing scales and, in particular, capture the macroscopic behaviour without resolving the microscopic physical scale numerically.},
  archive      = {J_ACTAN},
  author       = {Shi Jin},
  doi          = {10.1017/S0962492922000010},
  journal      = {Acta Numerica},
  month        = {5},
  pages        = {415-489},
  shortjournal = {Acta Numer.},
  title        = {Asymptotic-preserving schemes for multiscale physical problems},
  volume       = {31},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mixed precision algorithms in numerical linear algebra.
<em>ACTAN</em>, <em>31</em>, 347–414. (<a
href="https://doi.org/10.1017/S0962492922000022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s floating-point arithmetic landscape is broader than ever. While scientific computing has traditionally used single precision and double precision floating-point arithmetics, half precision is increasingly available in hardware and quadruple precision is supported in software. Lower precision arithmetic brings increased speed and reduced communication and energy costs, but it produces results of correspondingly low accuracy. Higher precisions are more expensive but can potentially provide great benefits, even if used sparingly. A variety of mixed precision algorithms have been developed that combine the superior performance of lower precisions with the better accuracy of higher precisions. Some of these algorithms aim to provide results of the same quality as algorithms running in a fixed precision but at a much lower cost; others use a little higher precision to improve the accuracy of an algorithm. This survey treats a broad range of mixed precision algorithms in numerical linear algebra, both direct and iterative, for problems including matrix multiplication, matrix factorization, linear systems, least squares, eigenvalue decomposition and singular value decomposition. We identify key algorithmic ideas, such as iterative refinement, adapting the precision to the data, and exploiting mixed precision block fused multiply–add operations. We also describe the possible performance benefits and explain what is known about the numerical stability of the algorithms. This survey should be useful to a wide community of researchers and practitioners who wish to develop or benefit from mixed precision numerical linear algebra algorithms.},
  archive      = {J_ACTAN},
  author       = {Nicholas J. Higham and Theo Mary},
  doi          = {10.1017/S0962492922000022},
  journal      = {Acta Numerica},
  month        = {5},
  pages        = {347-414},
  shortjournal = {Acta Numer.},
  title        = {Mixed precision algorithms in numerical linear algebra},
  volume       = {31},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reduced basis methods for time-dependent problems.
<em>ACTAN</em>, <em>31</em>, 265–345. (<a
href="https://doi.org/10.1017/S0962492922000058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical simulation of parametrized differential equations is of crucial importance in the study of real-world phenomena in applied science and engineering. Computational methods for real-time and many-query simulation of such problems often require prohibitively high computational costs to achieve sufficiently accurate numerical solutions. During the last few decades, model order reduction has proved successful in providing low-complexity high-fidelity surrogate models that allow rapid and accurate simulations under parameter variation, thus enabling the numerical simulation of increasingly complex problems. However, many challenges remain to secure the robustness and efficiency needed for the numerical simulation of nonlinear time-dependent problems. The purpose of this article is to survey the state of the art of reduced basis methods for time-dependent problems and draw together recent advances in three main directions. First, we discuss structure-preserving reduced order models designed to retain key physical properties of the continuous problem. Second, we survey localized and adaptive methods based on nonlinear approximations of the solution space. Finally, we consider data-driven techniques based on non-intrusive reduced order models in which an approximation of the map between parameter space and coefficients of the reduced basis is learned. Within each class of methods, we describe different approaches and provide a comparative discussion that lends insights to advantages, disadvantages and potential open questions.},
  archive      = {J_ACTAN},
  author       = {Jan S. Hesthaven and Cecilia Pagliantini and Gianluigi Rozza},
  doi          = {10.1017/S0962492922000058},
  journal      = {Acta Numerica},
  month        = {5},
  pages        = {265-345},
  shortjournal = {Acta Numer.},
  title        = {Reduced basis methods for time-dependent problems},
  volume       = {31},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Turnpike in optimal control of PDEs, ResNets, and beyond.
<em>ACTAN</em>, <em>31</em>, 135–263. (<a
href="https://doi.org/10.1017/S0962492922000046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The turnpike property in contemporary macroeconomics asserts that if an economic planner seeks to move an economy from one level of capital to another, then the most efficient path, as long as the planner has enough time, is to rapidly move stock to a level close to the optimal stationary or constant path, then allow for capital to develop along that path until the desired term is nearly reached, at which point the stock ought to be moved to the final target. Motivated in part by its nature as a resource allocation strategy, over the past decade, the turnpike property has also been shown to hold for several classes of partial differential equations arising in mechanics. When formalized mathematically, the turnpike theory corroborates insights from economics: for an optimal control problem set in a finite-time horizon, optimal controls and corresponding states are close (often exponentially) most of the time, except near the initial and final times, to the optimal control and the corresponding state for the associated stationary optimal control problem. In particular, the former are mostly constant over time. This fact provides a rigorous meaning to the asymptotic simplification that some optimal control problems appear to enjoy over long time intervals, allowing the consideration of the corresponding stationary problem for computing and applications. We review a slice of the theory developed over the past decade – the controllability of the underlying system is an important ingredient, and can even be used to devise simple turnpike-like strategies which are nearly optimal – and present several novel applications, including, among many others, the characterization of Hamilton–Jacobi–Bellman asymptotics, and stability estimates in deep learning via residual neural networks.},
  archive      = {J_ACTAN},
  author       = {Borjan Geshkovski and Enrique Zuazua},
  doi          = {10.1017/S0962492922000046},
  journal      = {Acta Numerica},
  month        = {5},
  pages        = {135-263},
  shortjournal = {Acta Numer.},
  title        = {Turnpike in optimal control of PDEs, ResNets, and beyond},
  volume       = {31},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Schwarz methods by domain truncation. <em>ACTAN</em>,
<em>31</em>, 1–134. (<a
href="https://doi.org/10.1017/S0962492922000034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schwarz methods use a decomposition of the computational domain into subdomains and need to impose boundary conditions on the subdomain boundaries. In domain truncation one restricts the unbounded domain to a bounded computational domain and must also put boundary conditions on the computational domain boundaries. In both fields there are vast bodies of literature and research is very active and ongoing. It turns out to be fruitful to think of the domain decomposition in Schwarz methods as a truncation of the domain onto subdomains. Seminal precursors of this fundamental idea are papers by Hagstrom, Tewarson and Jazcilevich (1988), Després (1990) and Lions (1990). The first truly optimal Schwarz method that converges in a finite number of steps was proposed by Nataf (1993), and used precisely transparent boundary conditions as transmission conditions between subdomains. Approximating these transparent boundary conditions for fast convergence of Schwarz methods led to the development of optimized Schwarz methods – a name that has become common for Schwarz methods based on domain truncation. Compared to classical Schwarz methods, which use simple Dirichlet transmission conditions and have been successfully used in a wide range of applications, optimized Schwarz methods are much less well understood, mainly due to their more sophisticated transmission conditions. A key application of Schwarz methods with such sophisticated transmission conditions turned out to be time-harmonic wave propagation problems, because classical Schwarz methods simply do not work in this case. The past decade has given us many new Schwarz methods based on domain truncation. One review from an algorithmic perspective (Gander and Zhang 2019) showed the equivalence of many of these new methods to optimized Schwarz methods. The analysis of optimized Schwarz methods, however, is lagging behind their algorithmic development. The general abstract Schwarz framework cannot be used for the analysis of these methods, and thus there are many open theoretical questions about their convergence. Just as for practical multigrid methods, Fourier analysis has been instrumental for understanding the convergence of optimized Schwarz methods and for tuning their transmission conditions. Similar to local Fourier mode analysis in multigrid, the unbounded two-subdomain case is used as a model for Fourier analysis of optimized Schwarz methods due to its simplicity. Many aspects of the actual situation, e.g. boundary conditions of the original problem and the number of subdomains, were thus neglected in the unbounded two-subdomain analysis. While this gave important insight, new phenomena beyond the unbounded two-subdomain models were discovered. This present situation is the motivation for our survey: to give a comprehensive review and precise exploration of convergence behaviours of optimized Schwarz methods based on Fourier analysis, taking into account the original boundary conditions, many-subdomain decompositions and layered media. We consider as our model problem the operator $-\Delta + \eta $ in the diffusive case $\eta&gt;0$ (screened Laplace equation) or the oscillatory case $\eta &lt;0$ (Helmholtz equation), in order to show the fundamental difference in behaviour of Schwarz solvers for these problems. The transmission conditions we study include the lowest-order absorbing conditions (Robin), and also more advanced perfectly matched layers (PMLs), both developed first for domain truncation. Our intensive work over the last two years on this review has led to several new results presented here for the first time: in the bounded two-subdomain analysis for the Helmholtz equation, we see strong influence of the original boundary conditions imposed on the global problem on the convergence factor of the Schwarz methods, and the asymptotic convergence factors with small overlap can differ from the unbounded two-subdomain analysis. In the many-subdomain analysis, we find the scaling with the number of subdomains, e.g. when the subdomain size is fixed, robust convergence of the double-sweep Schwarz method for the free-space wave problem, either with fixed overlap and zeroth-order Taylor conditions or with a logarithmically growing PML, and we find that Schwarz methods with PMLs work like smoothers that converge faster for higher Fourier frequencies; in particular, for the free-space wave problem, plane waves (in the error) passing through interfaces at a right angle converge more slowly. In addition to our main focus on analysis in Sections 2 and 3, we start in Section 1 with an expository historical introduction to Schwarz methods, and in Section 4 we give a brief interpretation of the recently proposed optimal Schwarz methods for decompositions with cross-points from the viewpoint of transmission conditions. We conclude in Section 5 with a summary of open research problems. In Appendix A we provide a Matlab program for a block LU form of an optimal Schwarz method with cross-points, and in Appendix B we give the Maple program for the two-subdomain Fourier analysis.},
  archive      = {J_ACTAN},
  author       = {Martin J. Gander and Hui Zhang},
  doi          = {10.1017/S0962492922000034},
  journal      = {Acta Numerica},
  month        = {5},
  pages        = {1-134},
  shortjournal = {Acta Numer.},
  title        = {Schwarz methods by domain truncation},
  volume       = {31},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
