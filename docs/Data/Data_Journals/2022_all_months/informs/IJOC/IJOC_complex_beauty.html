<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJOC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijoc---144">IJOC - 144</h2>
<ul>
<li><details>
<summary>
(2022). Reference vector assisted candidate search with aggregated
surrogate for computationally expensive many objective optimization
problems. <em>IJOC</em>, <em>35</em>(2), 318–334. (<a
href="https://doi.org/10.1287/ijoc.2022.1260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pareto-optimal sets of multiobjective optimization problems with black-box and computationally expensive objective functions are generally hard to locate within a limited computational budget, and this situation gets even worse when more than three objectives are involved. To this end, we present a novel surrogate-assisted many-objective optimization algorithm RECAS. Unlike most prior studies, the proposed algorithm is a non–evolutionary-based method, and it iteratively determines new points for expensive evaluation via a series of independent reference vector assisted candidate searches. Furthermore, to make the number of surrogates to be maintained independent of the number of objectives, in each candidate search, RECAS constructs a surrogate model in an aggregated manner to approximate the quality assessment indicator of each point rather than a certain objective function. Under some mild assumptions, this study proves that RECAS converges almost surely to the Pareto-optimal front. In the numerical experiments, the effectiveness and reliability of RECAS are examined on both DTLZ and WFG test suites with the number of objectives varying from 2 to 10. Compared with six state-of-the-art many-objective optimization algorithms, RECAS generally performs better in maintaining convergent and well-spread approximation of the Pareto-optimal front. Finally, the good performance of RECAS on two watershed simulation model calibration problems indicates its great potential in handling real-world applications.},
  archive      = {J_IJOC},
  author       = {Wenyu Wang and Christine A. Shoemaker},
  doi          = {10.1287/ijoc.2022.1260},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {318-334},
  shortjournal = {INFORMS J. Comput.},
  title        = {Reference vector assisted candidate search with aggregated surrogate for computationally expensive many objective optimization problems},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing the expected maximum of two linear functions
defined on a multivariate gaussian distribution. <em>IJOC</em>,
<em>35</em>(2), 304–317. (<a
href="https://doi.org/10.1287/ijoc.2022.1259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study stochastic optimization problems with objective function given by the expectation of the maximum of two linear functions defined on the component random variables of a multivariate Gaussian distribution. We consider random variables that are arbitrarily correlated, and we show that the problem is NP-hard even if the space of feasible solutions is unconstrained. We exploit a closed-form expression for the objective function from the literature to construct a cutting-plane algorithm for a highly nonlinear function, which includes the evaluation of the cumulative distribution function and probability density function of a standard normal random variable with decision variables as part of the arguments. To exhibit the model’s applicability, we consider two featured applications. The first is daily fantasy sports, where the algorithm identifies entries with positive returns during the 2018–2019 National Football League season. The second is a special case of makespan minimization for two parallel machines and jobs with uncertain processing times; for the special case where the jobs are uncorrelated, we prove the equivalence between its deterministic and stochastic versions and show that our algorithm can deliver a constant-factor approximation guarantee for the problem. The results of our computational evaluation involving synthetic and real-world data suggest that our discretization and upper bounding techniques lead to significant computational improvements and that the proposed algorithm outperforms suboptimal solutions approaches.},
  archive      = {J_IJOC},
  author       = {David Bergman and Carlos Cardonha and Jason Imbrogno and Leonardo Lozano},
  doi          = {10.1287/ijoc.2022.1259},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {304-317},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimizing the expected maximum of two linear functions defined on a multivariate gaussian distribution},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multiobjective approach for sector duration optimization
in stereotactic radiosurgery treatment planning. <em>IJOC</em>,
<em>35</em>(1), 248–264. (<a
href="https://doi.org/10.1287/ijoc.2022.1252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sector duration optimization (SDO) is a problem arising in treatment planning for stereotactic radiosurgery on Gamma Knife. Given a set of isocenter locations, SDO aims to select collimator size configurations and irradiation times thereof such that target tissues receive prescribed doses in a reasonable amount of treatment time and healthy tissues nearby are spared. We present a multiobjective linear programming model for SDO to generate a diverse collection of solutions so that clinicians can select the most appropriate treatment. We develop a generic two-phase solution strategy based on the ε-constraint method for solving multiobjective optimization models, 2phasε, which aims to systematically increase the number of high-quality solutions obtained, instead of conducting a traditional uniform search. To improve solution quality further and to accelerate the procedure, we incorporate some general and problem-specific enhancements. Moreover, we propose an alternative version of 2phasε, which makes use of machine learning tools to reduce the computational effort. In our computational study on eight previously treated real test cases, a significant portion of 2phasε solutions outperformed clinical results and those from a single-objective model from the literature. In addition to significant benefits of the algorithmic enhancements, our experiments illustrate the usefulness of machine learning strategies to reduce the overall run times nearly by half while maintaining or besting the clinical practice.},
  archive      = {J_IJOC},
  author       = {Oylum S¸eker and Mucahit Cevik and Merve Bodur and Young Lee and Mark Ruschin},
  doi          = {10.1287/ijoc.2022.1252},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {248-264},
  shortjournal = {INFORMS J. Comput.},
  title        = {A multiobjective approach for sector duration optimization in stereotactic radiosurgery treatment planning},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel power system restoration. <em>IJOC</em>,
<em>35</em>(1), 233–247. (<a
href="https://doi.org/10.1287/ijoc.2022.1258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After a blackout event, power system restoration is an essential activity for grid resilience; operators restart generators, re-establish transmission paths, and restore loads. With a goal of restoring electric service in the shortest time, the core decisions in restoration planning are to partition the grid into subnetworks, each of which has an initial power source for black-start (called sectionalization problem), and then restart all generators in each network (called generator startup sequencing (GSS) problem) as soon as possible. Due to their complexity, the sectionalization and GSS problems are usually solved separately, often resulting in a suboptimal solution. Our paper develops models and computational methods to solve the two problems simultaneously. We first study the computational complexity of the GSS problem and develop an efficient integer linear programming formulation. We then integrate the GSS problem with the sectionalization problem and develop an integer linear programming formulation for the parallel power system restoration (PPSR) problem to find exact optimal solutions. To solve larger systems, we then develop bounding approaches that find good upper and lower bounds efficiently. Finally, to address computational challenges for very large power grids, we develop a randomized approach to find a high-quality feasible solution quickly. Our computational experiments demonstrate that the proposed approaches are able to find good solutions for PPSR in up to 2,000-bus systems.},
  archive      = {J_IJOC},
  author       = {Sunil Chopra and Feng Qiu and Sangho Shim},
  doi          = {10.1287/ijoc.2022.1258},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {233-247},
  shortjournal = {INFORMS J. Comput.},
  title        = {Parallel power system restoration},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The value of randomized strategies in distributionally
robust risk-averse network interdiction problems. <em>IJOC</em>,
<em>35</em>(1), 216–232. (<a
href="https://doi.org/10.1287/ijoc.2022.1257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional value at risk (CVaR) is widely used to account for the preferences of a risk-averse agent in extreme loss scenarios. To study the effectiveness of randomization in interdiction problems with an interdictor that is both risk- and ambiguity-averse, we introduce a distributionally robust maximum flow network interdiction problem in which the interdictor randomizes over the feasible interdiction plans in order to minimize the worst case CVaR of the maximum flow with respect to both the unknown distribution of the capacity of the arcs and the interdictor’s own randomized strategy. Using the size of the uncertainty set, we control the degree of conservatism in the model and reformulate the interdictor’s distributionally robust optimization problem as a bilinear optimization problem. For solving this problem to any given optimality level, we devise a spatial branch-and-bound algorithm that uses the McCormick inequalities and reduced reformulation linearization technique to obtain a convex relaxation of the problem. We also develop a column-generation algorithm to identify the optimal support of the convex relaxation, which is then used in the coordinate descent algorithm to determine the upper bounds. The efficiency and convergence of the spatial branch-and-bound algorithm is established in numerical experiments. Further, our numerical experiments show that randomized strategies can have significantly better performance than optimal deterministic ones.},
  archive      = {J_IJOC},
  author       = {Utsav Sadana and Erick Delage},
  doi          = {10.1287/ijoc.2022.1257},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {216-232},
  shortjournal = {INFORMS J. Comput.},
  title        = {The value of randomized strategies in distributionally robust risk-averse network interdiction problems},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-scale inventory optimization: A recurrent neural
networks–inspired simulation approach. <em>IJOC</em>, <em>35</em>(1),
196–215. (<a href="https://doi.org/10.1287/ijoc.2022.1253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many large-scale production networks include thousands of types of final products and tens to hundreds of thousands of types of raw materials and intermediate products. These networks face complicated inventory management decisions, which are often too complicated for inventory models and too large for simulation models. In this paper, by combining efficient computational tools of recurrent neural networks (RNNs) and the structural information of production networks, we propose an RNN-inspired simulation approach that may be thousands of times faster than the existing simulation approach and is capable of solving large-scale inventory optimization problems in a reasonable amount of time.},
  archive      = {J_IJOC},
  author       = {Tan Wang and L. Jeff Hong},
  doi          = {10.1287/ijoc.2022.1253},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {196-215},
  shortjournal = {INFORMS J. Comput.},
  title        = {Large-scale inventory optimization: A recurrent neural Networks–Inspired simulation approach},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust sourcing under multilevel supply risks: Analysis of
random yield and capacity. <em>IJOC</em>, <em>35</em>(1), 178–195. (<a
href="https://doi.org/10.1287/ijoc.2022.1254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the optimal sourcing problem when the available suppliers are subject to ambiguously correlated supply risks. This problem is motivated by the increasing severity of supply risks and difficulty evaluating common sources of vulnerability in upstream supply chains, which are problems reported by many surveys of goods-producing firms. We propose a distributionally robust model that accommodates (i) multiple levels of supply disruption, not just full delivery or no delivery, and (ii) can use data-driven estimates of the underlying correlation to develop sourcing strategies in situations where the true correlation structure is ambiguous. Using this framework, we provide analytical results regarding the form of a worst-case supply distribution and show that taking such a worst-case perspective is appealing due to severe consequences associated with supply chain risks. Moreover, we show how our distributionally robust model may be used to offer guidance to firms considering whether to exert additional effort in attempt to better understanding the prevailing correlation structure. Extensive computational experiments further demonstrate the performance of our distributionally robust approach and show how supplier characteristics and the type of supply uncertainty affect the optimal sourcing decision.},
  archive      = {J_IJOC},
  author       = {Ming Zhao and Nickolas Freeman and Kai Pan},
  doi          = {10.1287/ijoc.2022.1254},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {178-195},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust sourcing under multilevel supply risks: Analysis of random yield and capacity},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning methods for data-driven demand estimation
and assortment planning considering cross-selling and substitutions.
<em>IJOC</em>, <em>35</em>(1), 158–177. (<a
href="https://doi.org/10.1287/ijoc.2022.1251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops machine learning methods for the data-driven demand estimation and assortment planning problem by addressing three subproblems, that is, demand forecasting simultaneously considering cross-selling and substitutions, estimation of the cross-selling and substitution effects, and assortment optimization. These three subproblems are transformed into three sequentially related machine learning problems: collective demand forecasting, demand inference for cross-selling and substitutions, and assortment rule mining. For collective demand forecasting, related product features are introduced to consider both the cross-selling and substitution effects, and a collaborative coordinate descent method with a good convergence property is developed to make distributed demand forecasting and a global update of related product features. Using the results, demand inference adopts transfer and semisupervised learning methods to tackle the challenge of missing data in quantifying the cross-selling and substitution effects. For assortment rule mining, the assortment rules bridge the gap between prediction and optimization, and the developed heuristics obtain the best assortment using the prior knowledge discovered in demand inference. The computational results on a real-world database and a semisynthetic database show that collective demand forecasting obtained far better results than the standard demand forecasting methods and some popular graph learning methods, and the developed heuristics identified much better assortments than those obtained with the baseline methods.},
  archive      = {J_IJOC},
  author       = {Zhen-Yu Chen and Zhi-Ping Fan and Minghe Sun},
  doi          = {10.1287/ijoc.2022.1251},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {158-177},
  shortjournal = {INFORMS J. Comput.},
  title        = {Machine learning methods for data-driven demand estimation and assortment planning considering cross-selling and substitutions},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost-effective social media influencer marketing.
<em>IJOC</em>, <em>35</em>(1), 138–157. (<a
href="https://doi.org/10.1287/ijoc.2022.1246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is becoming more and more promising that marketers hire influencers to launch campaigns for spreading items (e.g., articles or videos about products) over social media platforms. Such social media influencer marketing may generate tremendous utility if the influencers persuade their followers to adopt the recommended items. This could further spur extensive spontaneous item propagation on social media. Although prior studies mainly focus on influencer-selection strategies by the influencers’ traits, marketers with a number of items are often requested to determine both influencers and marketing items. The appropriateness between influencers and items is critical, but rarely considered in prior influencer-identification methods. We thus formulate and solve a novel cost-effective social media influencer marketing problem to maximize marketers’ utility by selecting appropriate pairwise combinations of influencers and items (i.e., item-influencer pairs). In particular, we first model utility functions and propose a simulation-based method to estimate the appropriateness of arbitrarily given item-influencer pairs by their potential utility. With the estimated utility, we devise an algorithm to iteratively select appropriate item-influencer pairs under various realistic conditions, including marketers’ budget, influencers’ payments, item-user fitness, social propagation, and influencers’ marketing slots. We theoretically prove that the marketing utility achieved by our method is near-optimal. We also conduct extensive empirical experiments with three real-world data sets to verify the superiority of our method in terms of cost-effectiveness and computational efficiency. Lastly, we discuss insightful theoretical and practical implications.},
  archive      = {J_IJOC},
  author       = {Xiao Han and Leye Wang and Weiguo Fan},
  doi          = {10.1287/ijoc.2022.1246},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {138-157},
  shortjournal = {INFORMS J. Comput.},
  title        = {Cost-effective social media influencer marketing},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unmanned aerial vehicle information collection missions with
uncertain characteristics. <em>IJOC</em>, <em>35</em>(1), 120–137. (<a
href="https://doi.org/10.1287/ijoc.2022.1245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the unmanned aerial vehicle (UAV) route planning problem for information collection missions performed in terrains with stochastic attributes. Uncertainty is associated with the availability of information, the effectiveness of the search and collection sensors the UAV carries, and the flight time required to travel between target regions in the mission terrain. Additionally, uncertainties in flight duration vary the detection threat exposed in missions performed in nonfriendly terrains. We develop a mixed integer programming model to maximize the expected information collection while limiting the risks of not completing the mission on time and of being detected and restricting the variance imposed on flight duration. The model allows multiple path alternatives between target pairs and revisits to the same target regions. Computational experiments are performed on randomly generated instances to investigate the impact of problem parameters and mission restrictions. We also develop a case study with a military and a civilian application, each of which with different specifications. In addition, we validate that the actual performance of the optimal solution of the model is close to the result reported by the solver via a simulation study. We conclude that the developed model is robust and can be used for practical-sized missions, and the failure rate of its optimal routes in actual missions is negligibly small.},
  archive      = {J_IJOC},
  author       = {Michael D. Moskal II and Erdi Dasdemir and Rajan Batta},
  doi          = {10.1287/ijoc.2022.1245},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {120-137},
  shortjournal = {INFORMS J. Comput.},
  title        = {Unmanned aerial vehicle information collection missions with uncertain characteristics},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A splicing approach to best subset of groups selection.
<em>IJOC</em>, <em>35</em>(1), 104–119. (<a
href="https://doi.org/10.1287/ijoc.2022.1241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Best subset of groups selection (BSGS) is the process of selecting a small part of nonoverlapping groups to achieve the best interpretability on the response variable. It has attracted increasing attention and has far-reaching applications in practice. However, due to the computational intractability of BSGS in high-dimensional settings, developing efficient algorithms for solving BSGS remains a research hotspot. In this paper, we propose a group-splicing algorithm that iteratively detects the relevant groups and excludes the irrelevant ones. Moreover, coupled with a novel group information criterion, we develop an adaptive algorithm to determine the optimal model size. Under certain conditions, it is certifiable that our algorithm can identify the optimal subset of groups in polynomial time with high probability. Finally, we demonstrate the efficiency and accuracy of our methods by comparing them with several state-of-the-art algorithms on both synthetic and real-world data sets.},
  archive      = {J_IJOC},
  author       = {Yanhang Zhang and Junxian Zhu and Jin Zhu and Xueqin Wang},
  doi          = {10.1287/ijoc.2022.1241},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {104-119},
  shortjournal = {INFORMS J. Comput.},
  title        = {A splicing approach to best subset of groups selection},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust minimum-cost flow problems under multiple ripple
effect disruptions. <em>IJOC</em>, <em>35</em>(1), 83–103. (<a
href="https://doi.org/10.1287/ijoc.2022.1243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of adversarial minimum-cost flow problems where the arcs are subject to multiple ripple effect disruptions that increase their usage cost. The locations of the disruptions’ epicenters are uncertain, and the decision maker seeks a flow that minimizes cost assuming the worst-case realization of the disruptions. We evaluate the damage to each arc using a linear model, where the damage is the cumulative damage of all disruptions affecting the arc; and a maximum model, where the damage is given by the most destructive disruption affecting the arc. For both models, the arcs’ costs after disruptions are represented with a mixed-integer feasible region, resulting in a robust optimization problem with a mixed-integer uncertainty set. The main challenge to solve the problem comes from a subproblem that evaluates the worst-case cost for a given flow plan. We show that for the linear model the uncertainty set can be decomposed into a series of single disruption problems, which leads to a polynomial time algorithm for the subproblem. The uncertainty set of the maximum model, however, cannot be decomposed, and we show that the subproblem under this model is NP-hard. For this case, we further present a big-M free binary reformulation of the uncertainty set based on conflict constraints that results in a significantly smaller formulation with tighter linear programming relaxations. We extend the models by considering a less conservative approach where only a subset of the disruptions can occur and show that the properties of the linear and maximum models also hold in this case. We test our proposed approaches over real road networks and synthetics instances and show that our methods achieve orders of magnitude improvements over a standard approach from the literature.},
  archive      = {J_IJOC},
  author       = {Mehdi Ansari and Juan S. Borrero and Leonardo Lozano},
  doi          = {10.1287/ijoc.2022.1243},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {83-103},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust minimum-cost flow problems under multiple ripple effect disruptions},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Policy optimization in dynamic bayesian network hybrid
models of biomanufacturing processes. <em>IJOC</em>, <em>35</em>(1),
66–82. (<a href="https://doi.org/10.1287/ijoc.2022.1232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biopharmaceutical manufacturing is a rapidly growing industry with impact in virtually all branches of medicine. Biomanufacturing processes require close monitoring and control, in the presence of complex bioprocess dynamics with many interdependent factors, as well as extremely limited data due to the high cost of experiments and the novelty of personalized bio-drugs. We develop a new model-based reinforcement learning framework that can achieve human-level control in low-data environments. A dynamic Bayesian network is used to capture causal interdependencies between factors and predict how the effects of different inputs propagate through the pathways of the bioprocess mechanisms. This model is interpretable and enables the design of process control policies that are robust against model risk. We present a computationally efficient, provably convergent stochastic gradient method for optimizing such policies. Validation is conducted on a realistic application with a multidimensional, continuous state variable.},
  archive      = {J_IJOC},
  author       = {Hua Zheng and Wei Xie and Ilya O. Ryzhov and Dongming Xie},
  doi          = {10.1287/ijoc.2022.1232},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {66-82},
  shortjournal = {INFORMS J. Comput.},
  title        = {Policy optimization in dynamic bayesian network hybrid models of biomanufacturing processes},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial dominance in branch-price-and-cut for the basic
multicompartment vehicle-routing problem. <em>IJOC</em>, <em>35</em>(1),
50–65. (<a href="https://doi.org/10.1287/ijoc.2022.1255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the exact solution of the basic version of the multiple-compartment vehicle-routing problem, which consists of clustering customers into groups, routing a vehicle for each group, and packing the demand of each visited customer into one of the vehicle’s compartments. Compartments have a fixed size, and there are no incompatibilities between the transported items or between items and compartments. The objective is to minimize the total length of all vehicle routes such that all customers are visited. We study the shortest-path subproblem that arises when solving the problem with a branch-price-and-cut algorithm exactly. For this subproblem, we compare a standard dynamic-programming labeling approach with a new one that uses a partial dominance. The algorithm with standard labeling already struggles with relatively small instances, whereas the one with partial dominance can cope with much larger instances.},
  archive      = {J_IJOC},
  author       = {Katrin Heßler and Stefan Irnich},
  doi          = {10.1287/ijoc.2022.1255},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {50-65},
  shortjournal = {INFORMS J. Comput.},
  title        = {Partial dominance in branch-price-and-cut for the basic multicompartment vehicle-routing problem},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new exact algorithm for single-commodity vehicle routing
with split pickups and deliveries. <em>IJOC</em>, <em>35</em>(1), 31–49.
(<a href="https://doi.org/10.1287/ijoc.2022.1249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new exact algorithm to solve a challenging vehicle routing problem with split pickups and deliveries, named as the single-commodity split-pickup and split-delivery vehicle routing problem (SPDVRP). In the SPDVRP, any amount of a product collected from a pickup customer can be supplied to any delivery customer, and the demand of each customer can be collected or delivered multiple times by the same or different vehicles. The vehicle fleet is homogeneous with limited capacity and maximum route duration. This problem arises regularly in inventory and routing rebalancing applications, such as in bike-sharing systems, where bikes must be rebalanced over time such that the appropriate number of bikes and open docks are available to users. The solution of the SPDVRP requires determining the number of visits to each customer, the relevant portions of the demands to be collected from or delivered to the customers, and the routing of the vehicles. These three decisions are intertwined, contributing to the hardness of the problem. Our new exact algorithm for the SPDVRP is a branch-price-and-cut algorithm based on a pattern-based mathematical formulation. The SPDVRP relies on a novel label-setting algorithm used to solve the pricing problem associated with the pattern-based formulation, where the label components embed reduced cost functions, unlike those classical components that embed delivered or collected quantities, thus significantly reducing the dimension of the corresponding state space. Extensive computational results on different classes of benchmark instances illustrate that the newly proposed exact algorithm solves several open SPDVRP instances and significantly improves the running times of state-of-the-art algorithms.},
  archive      = {J_IJOC},
  author       = {Jiliu Li and Zhixing Luo and Roberto Baldacci and Hu Qin and Zhou Xu},
  doi          = {10.1287/ijoc.2022.1249},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {31-49},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new exact algorithm for single-commodity vehicle routing with split pickups and deliveries},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Branch-cut-and-price for the time-dependent green vehicle
routing problem with time windows. <em>IJOC</em>, <em>35</em>(1), 14–30.
(<a href="https://doi.org/10.1287/ijoc.2022.1195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by rising concerns regarding global warming and traffic congestion effects, we study the time-dependent green vehicle routing problem with time windows (TDGVRPTW), aiming to minimize carbon emissions. The TDGVRPTW is a variant of the time-dependent vehicle routing problem (TDVRP) in which, in addition to the time window constraints, the minimization of carbon emissions requires determination of the optimal departure times for vehicles, from both the depot and customer location(s). Accordingly, the first exact method based on a branch-cut-and-price (BCP) algorithm is proposed for solving the TDGVRPTW. We introduce the notation of a time-dependent (TD) arc and describe how to identify the nondominated TD arcs in terms of arc departure times. In this way, we reduce infinitely many TD arcs to a finite set of nondominated TD arcs. We design a state-of-the-art BCP algorithm for the TDGVRPTW with labeling and limited memory subset row cuts, together with effective dominance rules for eliminating dominated TD arcs. The exact method is tested on a set of test instances derived from benchmark instances proposed in the literature. The results show the effectiveness of the proposed exact method in solving TDGVRPTW instances involving up to 100 customers.},
  archive      = {J_IJOC},
  author       = {Yiming Liu and Yang Yu and Yu Zhang and Roberto Baldacci and Jiafu Tang and Xinggang Luo and Wei Sun},
  doi          = {10.1287/ijoc.2022.1195},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {14-30},
  shortjournal = {INFORMS J. Comput.},
  title        = {Branch-cut-and-price for the time-dependent green vehicle routing problem with time windows},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Py-irt: A scalable item response theory library for python.
<em>IJOC</em>, <em>35</em>(1), 5–13. (<a
href="https://doi.org/10.1287/ijoc.2022.1250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {py-irt is a Python library for fitting Bayesian item response theory (IRT) models. At present, there is no Python package for fitting large-scale IRT models. py-irt estimates latent traits of subjects and items, making it appropriate for use in IRT tasks as well as in ideal point models. py-irt is built on top of the Pyro and PyTorch frameworks and uses GPU-accelerated training to scale to large data sets. It is the first Python package for large-scale IRT model fitting. py-irt is easy to use for practitioners and also allows for researchers to build and fit custom IRT models. py-irt is available as open-source software and can be installed from GitHub or the Python Package Index.},
  archive      = {J_IJOC},
  author       = {John Patrick Lalor and Pedro Rodriguez},
  doi          = {10.1287/ijoc.2022.1250},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {5-13},
  shortjournal = {INFORMS J. Comput.},
  title        = {Py-irt: A scalable item response theory library for python},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cutting planes from the branch-and-bound tree: Challenges
and opportunities. <em>IJOC</em>, <em>35</em>(1), 2–4. (<a
href="https://doi.org/10.1287/ijoc.2022.1248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this short paper, we argue that the standard approach adopted by modern mixed-integer linear programming solvers of using very little cutting plane generation in the branch-and-bound tree can be too conservative and lead to the loss of significant opportunities. Our observation is motivated by some relatively simple computational investigation on a couple of instances in the MIPlib 2010 collection for which the benefit of generating globally valid cuts in the tree is significant.},
  archive      = {J_IJOC},
  author       = {Claudio Contardo and Andrea Lodi and Andrea Tramontani},
  doi          = {10.1287/ijoc.2022.1248},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {2-4},
  shortjournal = {INFORMS J. Comput.},
  title        = {Cutting planes from the branch-and-bound tree: Challenges and opportunities},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Note from the editor. <em>IJOC</em>, <em>35</em>(1), 1. (<a
href="https://doi.org/10.1287/ijoc.2022.1262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice Smith},
  doi          = {10.1287/ijoc.2022.1262},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {1},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {35},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Editorial board. <em>IJOC</em>, <em>34</em>(6), C2. (<a
href="https://doi.org/10.1287/ijoc.2022.eb.v3406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.eb.v3406},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Appreciation to reviewers. <em>IJOC</em>, <em>34</em>(6),
3344–3350. (<a href="https://doi.org/10.1287/ijoc.2022.1244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On behalf of the Editorial Board, I would like to thank the following people who acted as reviewers during the past year. Reviewers are the cornerstone of the peer review system and give their time and expertise unselfishly. IJOC reviewers, please know you are greatly appreciated!},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.1244},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3344-3350},
  shortjournal = {INFORMS J. Comput.},
  title        = {Appreciation to reviewers},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stability representations of many-to-one matching problems:
An integer optimization approach. <em>IJOC</em>, <em>34</em>(6),
3325–3343. (<a href="https://doi.org/10.1287/ijoc.2022.1237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider integer optimization models for finding stable solutions to many-to-one, utility-weighted matching problems with incomplete preference lists and ties. Whereas traditional algorithmic approaches for the stable many-to-one matching problem, such as the deferred acceptance algorithm, offer efficient performance for the strict problem setting, adaptation to alternative settings often requires careful customization. Optimization-based approaches are free of the need to create customized algorithms for each unique context and can readily accommodate such extensions as (incomplete) preference lists with ties, alternative and nontraditional objective functions, and side constraints including those that ensure stable matching outcomes free of waste. We explore the flexibility of optimization-based approaches in several ways. First, we introduce four new constraint sets that prevent justified envy and a new system of constraints that prevents waste; taken together, they jointly ensure stable matching outcomes. Second, we create two algorithms to accelerate the generation of our proposed constraints. Third, we construct aggregate objective functions to reflect multiple hierarchical emphases by imposing a strict lexicographical order on the individual components. Fourth, we conduct comprehensive experiments to study the computational performance of our proposed optimization models and compare them with models from the extant literature under a variety of problem attributes. Our experiments reveal the circumstances under which each stability representation excels in terms of optimality criteria and computational efficiency on a variety of real and synthetic data sets. One such setting in which our proposed stability representations excel includes the important context of when sufficient seats exist for applicants, such as school choice problems and hospital residency matching.},
  archive      = {J_IJOC},
  author       = {Pitchaya Wiratchotisatian and Hoda Atef Yekta and Andrew C. Trapp},
  doi          = {10.1287/ijoc.2022.1237},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3325-3343},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stability representations of many-to-one matching problems: An integer optimization approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A polyhedral study on fuel-constrained unit commitment.
<em>IJOC</em>, <em>34</em>(6), 3309–3324. (<a
href="https://doi.org/10.1287/ijoc.2022.1235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electricity production of a thermal generator is often constrained by the available fuel supply. These fuel constraints impose a maximum bound on the energy output over multiple time periods. Fuel constraints are increasingly important in electricity markets because of two main reasons. First, as more natural gas-fired generators join the deregulated market, there is often competition for natural gas supply from other sectors (e.g., residential and manufacturing heating). Second, as more environmental and emission regulations are being placed on fossil fuel-fired generators, fuel supply is becoming more limited. However, there are few studies that consider the fuel constraints in the unit commitment problem from the perspective of computational analysis. To address the challenge faced by an independent power producer with a limited fuel supply, we study a fuel-constrained self-scheduling unit commitment (FSUC) problem where the production decisions are coupled across multiple time periods. We provide a complexity analysis of the FSUC problem and conduct a comprehensive polyhedral study by deriving strong valid inequalities. We demonstrate the effectiveness of our proposed inequalities as cutting planes in solving various multistage stochastic FSUC problems.},
  archive      = {J_IJOC},
  author       = {Kai Pan and Ming Zhao and Chung-Lun Li and Feng Qiu},
  doi          = {10.1287/ijoc.2022.1235},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3309-3324},
  shortjournal = {INFORMS J. Comput.},
  title        = {A polyhedral study on fuel-constrained unit commitment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic programming for the time-dependent traveling
salesman problem with time windows. <em>IJOC</em>, <em>34</em>(6),
3292–3308. (<a href="https://doi.org/10.1287/ijoc.2022.1236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time-dependent traveling salesman problem with time windows (TDTSPTW) is a variant of the well-known traveling salesman problem with time windows, in which travel times are not assumed to be constant. The TDTSPTW accounts for the effects of congestion at the planning level, being particularly suited for distribution problems in large cities. In this paper we develop a labeling-based algorithm for the TDTSPTW that incorporates partial dominance and generalizes several state-of-the-art components from the time-independent related literature. We propose a framework general enough to be applied to the TDTSPTW and its variant without time windows, with the objective of minimizing the duration or the makespan. As part of the framework, we introduce a new state-space relaxation specifically designed for the time-dependent context. Extensive computational experiments show the effectiveness of the overall approach and the impact of the new relaxation, outperforming several recent algorithms proposed for these variants on more than 9,000 benchmark instances. In addition, we frame the minimum tour duration problem within the time-dependent literature and include it as a benchmark for our algorithm, obtaining improved computation times and 31 new optimal solutions.},
  archive      = {J_IJOC},
  author       = {Gonzalo Lera-Romero and Juan José Miranda Bront and Francisco J. Soulignac},
  doi          = {10.1287/ijoc.2022.1236},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3292-3308},
  shortjournal = {INFORMS J. Comput.},
  title        = {Dynamic programming for the time-dependent traveling salesman problem with time windows},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust adaptive submodular maximization. <em>IJOC</em>,
<em>34</em>(6), 3277–3291. (<a
href="https://doi.org/10.1287/ijoc.2022.1239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of a sequential decision-making problem is to design an interactive policy that adaptively selects a group of items, each selection is based on the feedback from the past, to maximize the expected utility of selected items. It has been shown that the utility functions of many real-world applications are adaptive submodular. However, most of existing studies on adaptive submodular optimization focus on the average-case, that is, their objective is to find a policy that maximizes the expected utility over a known distribution of realizations. Unfortunately, a policy that has a good average-case performance may have very poor performance under the worst-case realization. In this study, we propose to study two variants of adaptive submodular optimization problems, namely, worst-case adaptive submodular maximization and robust submodular maximization. The first problem aims to find a policy that maximizes the worst-case utility and the latter one aims to find a policy, if any, that achieves both near optimal average-case utility and worst-case utility simultaneously. We introduce a new class of stochastic functions, called worst-case submodular function. For the worst-case adaptive submodular maximization problem subject to a p-system constraint, we develop an adaptive worst-case greedy policy that achieves a 1p+1 approximation ratio against the optimal worst-case utility if the utility function is worst-case submodular. For the robust adaptive submodular maximization problem subject to cardinality constraints (respectively, partition matroid constraints), if the utility function is both worst-case submodular and adaptive submodular, we develop a hybrid adaptive policy that achieves an approximation close to 1−e−12 (respectively, 1/3) under both worst- and average-case settings simultaneously. We also describe several applications of our theoretical results, including pool-base active learning, stochastic submodular set cover, and adaptive viral marketing.},
  archive      = {J_IJOC},
  author       = {Shaojie Tang},
  doi          = {10.1287/ijoc.2022.1239},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3277-3291},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust adaptive submodular maximization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Disjunctive rule lists. <em>IJOC</em>, <em>34</em>(6),
3259–3276. (<a href="https://doi.org/10.1287/ijoc.2022.1242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present an interpretable model, disjunctive rule list (DisRL) for regression. This research is motivated by the increasing need for model interpretability, especially in high-stakes decisions such as medicine, where decisions are made on or related to humans. DisRL is a generalized form of rule lists. A DisRL model consists of a list of disjunctive rules embedded in an if-else logic structure that stratifies the data space. Compared with traditional decision trees and other rule list models in the literature that stratify the feature space with single itemsets (an itemset is a conjunction of conditions), each disjunctive rule in DisRL uses a set of itemsets to collectively cover a subregion in the feature space. In addition, a DisRL model is constructed under a global objective that balances the predictive performance and model complexity. To train a DisRL model, we devise a hierarchical stochastic local search algorithm that exploits the properties of DisRL’s unique structure to improve search efficiency. The algorithm adopts the main structure of simulated annealing and customizes the proposing strategy for faster convergence. Meanwhile, the algorithm uses a prefix bound to locate a subset of the search area, effectively pruning the search space at each iteration. An ablation study shows the effectiveness of this strategy in pruning the search space. Experiments on public benchmark datasets demonstrate that DisRL outperforms baseline interpretable models, including decision trees and other rule-based regressors.},
  archive      = {J_IJOC},
  author       = {Ronilo Ragodos and Tong Wang},
  doi          = {10.1287/ijoc.2022.1242},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3259-3276},
  shortjournal = {INFORMS J. Comput.},
  title        = {Disjunctive rule lists},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated backup rolling stock allocation and timetable
rescheduling with uncertain time-variant passenger demand under
disruptive events. <em>IJOC</em>, <em>34</em>(6), 3234–3258. (<a
href="https://doi.org/10.1287/ijoc.2022.1233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway traffic management focuses on regulating train movements and delivering improved service quality to passengers; however, such efforts are subject to many uncertainties in terms of disruptions and passenger demand on a rail transit line. In contrast to most existing studies, which focus on the rescheduling of passenger timetables in a deterministic framework, this study proposes a two-stage stochastic optimization model for allocating backup rolling stocks (BRS) to storage lines to reschedule the timetable and serve passengers delayed by disruptions. The first stage is an assignment problem to determine the optimal plan for the allocation of BRS to storage lines to achieve a good trade-off between the investment cost for the BRS and the expected travel time of delayed passengers across different stochastic scenarios. The second stage is explicitly formulated as a network flow model to optimize the timetable of the delayed trains on the tracks and the BRS from the storage lines such that the passenger travel time is minimized under each stochastic scenario. To improve the efficiency of convergence, we develop an improved L-shaped method with several accelerating techniques. Among these, we show that the classical integer L-shaped cut can be tightened given the property of the second-stage problem, which can also be generalized to other two-stage integer stochastic programs. Real-world case studies based on historical data from the Beijing metro verify the effectiveness of the proposed approach in reducing the travel time for passengers.},
  archive      = {J_IJOC},
  author       = {Jiateng Yin and Lixing Yang and Andrea D’Ariano and Tao Tang and Ziyou Gao},
  doi          = {10.1287/ijoc.2022.1233},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3234-3258},
  shortjournal = {INFORMS J. Comput.},
  title        = {Integrated backup rolling stock allocation and timetable rescheduling with uncertain time-variant passenger demand under disruptive events},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust team orienteering problem with decreasing profits.
<em>IJOC</em>, <em>34</em>(6), 3215–3233. (<a
href="https://doi.org/10.1287/ijoc.2022.1240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a robust variant of the team orienteering problem with decreasing profits, where a fleet of vehicles are dispatched to serve customers with decreasing profits in a limited time horizon. The service times at customers are assumed to be uncertain, which are characterized by a budgeted uncertainty set. Our goal is to determine the set of customers to be served and the routes for the vehicles such that the collected profit is maximized; meanwhile, all the planned routes remain feasible for any realization of service times within the uncertainty set. We propose a two-index robust formulation for the problem, which is defined using constraints based on dynamic programming recursive equations and can be directly solved by a general-purpose optimization solver. We also present a route-based formulation for the problem, which is solved by a tailored branch-and-price (B&amp;amp;P) algorithm. To tackle large-size instances efficiently, we further implement a tabu search (TS) algorithm. Numerical tests show that our B&amp;amp;P algorithm can solve most instances with 100 customers to optimality within 30 minutes and that the TS algorithm can find high-quality solutions within a few seconds. Moreover, we find that in most cases, the robust solutions can significantly reduce the probability of deadline violations in simulation tests with only a slight compromise of profit compared with the solutions generated by the deterministic model.},
  archive      = {J_IJOC},
  author       = {Qinxiao Yu and Chun Cheng and Ning Zhu},
  doi          = {10.1287/ijoc.2022.1240},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3215-3233},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust team orienteering problem with decreasing profits},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An algorithm for maximizing a convex function based on its
minimum. <em>IJOC</em>, <em>34</em>(6), 3200–3214. (<a
href="https://doi.org/10.1287/ijoc.2022.1238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an algorithm for maximizing a convex function over a convex feasible set is proposed. The algorithm, called CoMax, consists of two phases: in phase 1, a feasible starting point is obtained that is used in a gradient ascent algorithm in phase 2. The main contribution of the paper is connected to phase 1; five different methods are used to approximate the original NP-hard problem of maximizing a convex function (MCF) by a tractable convex optimization problem. All the methods use the minimizer of the convex objective function in their construction. In phase 2, the gradient ascent algorithm yields stationary points to the MCF problem. The performance of CoMax is tested on a wide variety of MCF problems, demonstrating its efficiency.},
  archive      = {J_IJOC},
  author       = {Aharon Ben-Tal and Ernst Roos},
  doi          = {10.1287/ijoc.2022.1238},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3200-3214},
  shortjournal = {INFORMS J. Comput.},
  title        = {An algorithm for maximizing a convex function based on its minimum},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On fault-tolerant low-diameter clusters in graphs.
<em>IJOC</em>, <em>34</em>(6), 3181–3199. (<a
href="https://doi.org/10.1287/ijoc.2022.1231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cliques and their generalizations are frequently used to model “tightly knit” clusters in graphs and identifying such clusters is a popular technique used in graph-based data mining. One such model is the s-club, which is a vertex subset that induces a subgraph of diameter at most s. This model has found use in a variety of fields because low-diameter clusters have practical significance in many applications. As this property is not hereditary on vertex-induced subgraphs, the diameter of a subgraph could increase upon the removal of some vertices and the subgraph could even become disconnected. For example, star graphs have diameter two but can be disconnected by removing the central vertex. The pursuit of a fault-tolerant extension of the s-club model has spawned two variants that we study in this article: robust s-clubs and hereditary s-clubs. We analyze the complexity of the verification and optimization problems associated with these variants. Then, we propose cut-like integer programming formulations for both variants whenever possible and investigate the separation complexity of the cut-like constraints. We demonstrate through our extensive computational experiments that the algorithmic ideas we introduce enable us to solve the problems to optimality on benchmark instances with several thousand vertices. This work lays the foundations for effective mathematical programming approaches for finding fault-tolerant s-clubs in large-scale networks.},
  archive      = {J_IJOC},
  author       = {Yajun Lu and Hosseinali Salemi and Balabhaskar Balasundaram and Austin Buchanan},
  doi          = {10.1287/ijoc.2022.1231},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3181-3199},
  shortjournal = {INFORMS J. Comput.},
  title        = {On fault-tolerant low-diameter clusters in graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmenting markov cohort analysis to compute (co)variances:
Implications for strength of cost-effectiveness. <em>IJOC</em>,
<em>34</em>(6), 3170–3180. (<a
href="https://doi.org/10.1287/ijoc.2022.1234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Markov cohort analysis is a popular deterministic method in medical decision making for calculating mean outcomes in a Markov model by following a cohort of individuals through time. At present, obtaining outcome variances requires either forsaking cohort analysis in favor of a Markov decision process model or using Monte Carlo simulation (microsimulation), a more computationally demanding procedure that provides only statistical estimates. Here we derive an augmented version of cohort analysis that allows exact computation (not merely estimation) of (co)variances. In second-order models that incorporate parameter uncertainty, augmented cohort analysis can replace the “inner loop” required in Monte Carlo simulation, resulting in quicker and more accurate estimates.},
  archive      = {J_IJOC},
  author       = {Gordon B. Hazen},
  doi          = {10.1287/ijoc.2022.1234},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3170-3180},
  shortjournal = {INFORMS J. Comput.},
  title        = {Augmenting markov cohort analysis to compute (Co)Variances: Implications for strength of cost-effectiveness},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic dual dynamic programming for multiechelon lot
sizing with component substitution. <em>IJOC</em>, <em>34</em>(6),
3151–3169. (<a href="https://doi.org/10.1287/ijoc.2022.1215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates lot sizing with component substitution under demand uncertainty. The integration of component substitution with lot sizing in an uncertain demand context is important because the consolidation of the demand for components naturally allows risk-pooling and reduces operating costs. The considered problem is relevant not only in a production context, but also in the context of distribution planning. We propose a stochastic programming formulation for the static–dynamic type of uncertainty, in which the setup decisions are frozen but the production and consumption quantities are decided dynamically. To tackle the scalability issues commonly encountered in multistage stochastic optimization, this paper investigates the use of stochastic dual dynamic programming (SDDP). In addition, we consider various improvements of SDDP, including the use of strong cuts, the fast generation of cuts by solving the linear relaxation of the problem, and retaining the average demand scenarios. Finally, we propose two heuristics, namely, a hybrid of progressive hedging with SDDP and a heuristic version of SDDP. Computational experiments conducted on well-known instances from the literature show that the heuristic version of SDDP outperforms other methods. The proposed method can plan with up to 10 decision stages and 20 scenarios per stage, which results in 2010 scenario paths in total. Moreover, as the heuristic version of SDDP can replan to account for new information in less than a second, it is convenient in a dynamic context.},
  archive      = {J_IJOC},
  author       = {Simon Thevenin and Yossiri Adulyasak and Jean-François Cordeau},
  doi          = {10.1287/ijoc.2022.1215},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3151-3169},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stochastic dual dynamic programming for multiechelon lot sizing with component substitution},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A branch-and-price algorithm for the multiple knapsack
problem. <em>IJOC</em>, <em>34</em>(6), 3134–3150. (<a
href="https://doi.org/10.1287/ijoc.2022.1223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiple knapsack problem is a well-studied combinatorial optimization problem with several practical and theoretical applications. It consists of packing some subset of n items into m knapsacks such that the total profit of the chosen items is maximum. A new formulation of the problem is presented, where a Lagrangian relaxation is derived, and we prove that it dominates the commonly used relaxations for this problem. We also present a Dantzig-Wolfe decomposition of the new formulation that we solve to optimality using a branch-and-price algorithm, where its main advantage comes from the fact that it is possible to control whether an item is included in some knapsack or not. An improved algorithm for solving the resulting packing subproblems is also introduced. Computational experiments then show that the new approach achieves state-of-the-art results.},
  archive      = {J_IJOC},
  author       = {Olivier Lalonde and Jean-François Côté and Bernard Gendron},
  doi          = {10.1287/ijoc.2022.1223},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3134-3150},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-and-price algorithm for the multiple knapsack problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A penalty branch-and-bound method for mixed binary linear
complementarity problems. <em>IJOC</em>, <em>34</em>(6), 3117–3133. (<a
href="https://doi.org/10.1287/ijoc.2022.1216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear complementarity problems (LCPs) are an important modeling tool for many practically relevant situations and also have many important applications in mathematics itself. Although the continuous version of the problem is extremely well-studied, much less is known about mixed-integer LCPs (MILCPs) in which some variables have to be integer-valued in a solution. In particular, almost no tailored algorithms are known besides reformulations of the problem that allow us to apply general purpose mixed integer linear programming solvers. In this paper, we present, theoretically analyze, enhance, and test a novel branch-and-bound method for MILCPs. The main property of this method is that we do not “branch” on constraints as usual but by adding suitably chosen penalty terms to the objective function. By doing so, we can either provably compute an MILCP solution if one exists or compute an approximate solution that minimizes an infeasibility measure combining integrality and complementarity conditions. We enhance the method by MILCP-tailored valid inequalities, node selection strategies, branching rules, and warm-starting techniques. The resulting algorithm is shown to clearly outperform two benchmark approaches from the literature.},
  archive      = {J_IJOC},
  author       = {Marianna De Santis and Sven de Vries and Martin Schmidt and Lukas Winkel},
  doi          = {10.1287/ijoc.2022.1216},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3117-3133},
  shortjournal = {INFORMS J. Comput.},
  title        = {A penalty branch-and-bound method for mixed binary linear complementarity problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward efficient ensemble learning with structure
constraints: Convergent algorithms and applications. <em>IJOC</em>,
<em>34</em>(6), 3096–3116. (<a
href="https://doi.org/10.1287/ijoc.2022.1224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning methods, such as boosting, focus on producing a strong classifier based on numerous weak classifiers. In this paper, we develop a novel ensemble learning method called rescaled boosting with truncation (ReBooT) for binary classification by combining well-known rescaling and regularization ideas in boosting. Theoretically, we present some sufficient conditions for the convergence of ReBooT, derive an almost optimal numerical convergence rate, and deduce fast-learning rates in the framework of statistical learning theory. Experimentally, we conduct both toy simulations and four real-world data runs to show the power of ReBooT. Our results show that, compared with the existing boosting algorithms, ReBooT possesses better learning performance and interpretability in terms of solid theoretical guarantees, perfect structure constraints, and good prediction performance.},
  archive      = {J_IJOC},
  author       = {Shao-Bo Lin and Shaojie Tang and Yao Wang and Di Wang},
  doi          = {10.1287/ijoc.2022.1224},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3096-3116},
  shortjournal = {INFORMS J. Comput.},
  title        = {Toward efficient ensemble learning with structure constraints: Convergent algorithms and applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finding feasible systems for subjective constraints using
recycled observations. <em>IJOC</em>, <em>34</em>(6), 3080–3095. (<a
href="https://doi.org/10.1287/ijoc.2022.1227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of finding a set of feasible or near-feasible systems among a finite number of simulated systems in the presence of stochastic constraints. When the constraints are subjective, a decision maker may want to test multiple threshold values for the constraints. Or the decision maker may simply want to determine how a set of feasible systems changes as constraints become more strict with the objective of pruning systems or finding the system with the best performance. When only the constraint thresholds change for the same set of underlying systems, it is natural to reuse observations collected from the feasibility check with a different threshold value. We present an indifference-zone procedure that recycles observations and provide an overall probability of correct decision for all threshold values. Our numerical experiments show that the proposed procedure performs well in reducing the required number of observations while providing a statistical guarantee on the probability of correct decision.},
  archive      = {J_IJOC},
  author       = {Yuwei Zhou and Sigrún Andradóttir and Seong-Hee Kim and Chuljin Park},
  doi          = {10.1287/ijoc.2022.1227},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3080-3095},
  shortjournal = {INFORMS J. Comput.},
  title        = {Finding feasible systems for subjective constraints using recycled observations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel machine scheduling under uncertainty: Models and
exact algorithms. <em>IJOC</em>, <em>34</em>(6), 3059–3079. (<a
href="https://doi.org/10.1287/ijoc.2022.1229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study parallel machine scheduling for makespan minimization with uncertain job processing times. To incorporate uncertainty and generate solutions that are, in some way, insensitive to unfolding information, three different modeling paradigms are adopted: a robust model, a chance-constrained model, and a distributionally robust chance-constrained model. We focus on devising generic solution methods that can efficiently handle these different models. We develop two general solution procedures: a cutting-plane method that leverages the submodularity in the models and a customized dichotomic search procedure with a decision version of a bin packing variant under uncertainty solved in each iteration. A branch-and-price algorithm is designed to solve the bin packing problems. The efficiency of our methods is shown through extensive computational tests. We compare the solutions from the different models and report the general lessons learned regarding the choice between different frameworks for planning under uncertainty.},
  archive      = {J_IJOC},
  author       = {Guopeng Song and Roel Leus},
  doi          = {10.1287/ijoc.2022.1229},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3059-3079},
  shortjournal = {INFORMS J. Comput.},
  title        = {Parallel machine scheduling under uncertainty: Models and exact algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization strategies for resource-constrained project
scheduling problems in underground mining. <em>IJOC</em>,
<em>34</em>(6), 3042–3058. (<a
href="https://doi.org/10.1287/ijoc.2022.1222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective computational methods are important for practitioners and researchers working in strategic underground mine planning. We consider a class of problems that can be modeled as a resource-constrained project scheduling problem with optional activities; the objective maximizes net present value. We provide a computational review of math programming and constraint programming techniques for this problem, describe and implement novel problem-size reductions, and introduce an aggregated linear program that guides a list scheduling algorithm running over unaggregated instances. Practical, large-scale planning problems cannot be processed using standard optimization approaches. However, our strategies allow us to solve them to within about 5\% of optimality in several hours, even for the most difficult instances.},
  archive      = {J_IJOC},
  author       = {Alessandro Hill and Andrea J. Brickey and Italo Cipriano and Marcos Goycoolea and Alexandra Newman},
  doi          = {10.1287/ijoc.2022.1222},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3042-3058},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimization strategies for resource-constrained project scheduling problems in underground mining},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computational framework for solving nonlinear binary
optimization problems in robust causal inference. <em>IJOC</em>,
<em>34</em>(6), 3023–3041. (<a
href="https://doi.org/10.1287/ijoc.2022.1226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying cause-effect relations among variables is a key step in the decision-making process. Whereas causal inference requires randomized experiments, researchers and policy makers are increasingly using observational studies to test causal hypotheses due to the wide availability of data and the infeasibility of experiments. The matching method is the most used technique to make causal inference from observational data. However, the pair assignment process in one-to-one matching creates uncertainty in the inference because of different choices made by the experimenter. Recently, discrete optimization models have been proposed to tackle such uncertainty; however, they produce 0-1 nonlinear problems and lack scalability. In this work, we investigate this emerging data science problem and develop a unique computational framework to solve the robust causal inference test instances from observational data with continuous outcomes. In the proposed framework, we first reformulate the nonlinear binary optimization problems as feasibility problems. By leveraging the structure of the feasibility formulation, we develop greedy schemes that are efficient in solving robust test problems. In many cases, the proposed algorithms achieve a globally optimal solution. We perform experiments on real-world data sets to demonstrate the effectiveness of the proposed algorithms and compare our results with the state-of-the-art solver. Our experiments show that the proposed algorithms significantly outperform the exact method in terms of computation time while achieving the same conclusion for causal tests. Both numerical experiments and complexity analysis demonstrate that the proposed algorithms ensure the scalability required for harnessing the power of big data in the decision-making process. Finally, the proposed framework not only facilitates robust decision making through big-data causal inference, but it can also be utilized in developing efficient algorithms for other nonlinear optimization problems such as quadratic assignment problems.},
  archive      = {J_IJOC},
  author       = {Md Saiful Islam and Md Sarowar Morshed and Md. Noor-E-Alam},
  doi          = {10.1287/ijoc.2022.1226},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3023-3041},
  shortjournal = {INFORMS J. Comput.},
  title        = {A computational framework for solving nonlinear binary optimization problems in robust causal inference},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bifidelity surrogate modelling: Showcasing the need for new
test instances. <em>IJOC</em>, <em>34</em>(6), 3007–3022. (<a
href="https://doi.org/10.1287/ijoc.2022.1217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multifidelity expensive black-box (Mf-EBB) methods have received increasing attention due to their strong applicability to industrial design problems. The challenge, however, is that knowledge of the relationship between decisions and objective values is limited to a small set of sample observations of variable quality. In the field of Mf-EBB, a problem instance consists of an expensive yet accurate source of information, and one or more cheap yet less accurate sources of information. The field aims to provide techniques either to accurately explain how decisions affect design outcome, or to find the best decisions to optimise design outcomes. Many techniques that use surrogate models have been developed to provide solutions to both aims. Only in recent years, however, have researchers begun to explore the conditions under which these new techniques are reliable, often focusing on problems with a single low-fidelity function, known as bifidelity expensive black-box (Bf-EBB) problems. This study extends the existing Bf-EBB test instances found in the literature, as well as the features used to determine when the low-fidelity information source should be used. A literature test suite is constructed and augmented with new instances to demonstrate the potentially misleading results that could be reached using only the instances currently found in the literature, and to expose the criticality of a more heterogeneous test suite for algorithm assessment. Addressing the shortcomings of the existing literature, a new set of features is presented, as well as a new instance creation procedure, and a study of their impact on algorithm assessment is conducted. The low-fidelity information source is shown to be valuable if it is often locally accurate, even when its overall accuracy is relatively low. This contradicts the existing literature guidelines, which indicate the low-fidelity information is only useful if it has a high overall accuracy.},
  archive      = {J_IJOC},
  author       = {Nicolau Andrés-Thió and Mario Andrés Muñoz and Kate Smith-Miles},
  doi          = {10.1287/ijoc.2022.1217},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {3007-3022},
  shortjournal = {INFORMS J. Comput.},
  title        = {Bifidelity surrogate modelling: Showcasing the need for new test instances},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving stochastic optimization with expectation constraints
efficiently by a stochastic augmented lagrangian-type algorithm.
<em>IJOC</em>, <em>34</em>(6), 2989–3006. (<a
href="https://doi.org/10.1287/ijoc.2022.1228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of minimizing a convex expectation function with a set of inequality convex expectation constraints. We propose a stochastic augmented Lagrangian-type algorithm—namely, the stochastic linearized proximal method of multipliers—to solve this convex stochastic optimization problem. This algorithm can be roughly viewed as a hybrid of stochastic approximation and the traditional proximal method of multipliers. Under mild conditions, we show that this algorithm exhibits O(K−1/2) expected convergence rates for both objective reduction and constraint violation if parameters in the algorithm are properly chosen, where K denotes the number of iterations. Moreover, we show that, with high probability, the algorithm has a O(log (K)K−1/2) constraint violation bound and O(log 3/2(K)K−1/2) objective bound. Numerical results demonstrate that the proposed algorithm is efficient.},
  archive      = {J_IJOC},
  author       = {Liwei Zhang and Yule Zhang and Jia Wu and Xiantao Xiao},
  doi          = {10.1287/ijoc.2022.1228},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2989-3006},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving stochastic optimization with expectation constraints efficiently by a stochastic augmented lagrangian-type algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An alternating method for cardinality-constrained
optimization: A computational study for the best subset selection and
sparse portfolio problems. <em>IJOC</em>, <em>34</em>(6), 2968–2988. (<a
href="https://doi.org/10.1287/ijoc.2022.1211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardinality-constrained optimization problems are notoriously hard to solve in both theory and practice. However, as famous examples, such as the sparse portfolio optimization and best subset selection problems, show, this class is extremely important in real-world applications. In this paper, we apply a penalty alternating direction method to these problems. The key idea is to split the problem along its discrete-continuous structure to obtain two subproblems that are much easier to solve than the original problem. In addition, the coupling between these subproblems is achieved via a classic penalty framework. The method can be seen as a primal heuristic for which convergence results are readily available from the literature. In our extensive computational study, we first show that the method is competitive to a commercial mixed-integer program solver for the portfolio optimization problem. On these instances, we also test a variant of our approach that uses a perspective reformulation of the problem. Regarding the best subset selection problem, it turns out that our method significantly outperforms commercial solvers and it is at least competitive to state-of-the-art methods from the literature.},
  archive      = {J_IJOC},
  author       = {Carina Moreira Costa and Dennis Kreber and Martin Schmidt},
  doi          = {10.1287/ijoc.2022.1211},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2968-2988},
  shortjournal = {INFORMS J. Comput.},
  title        = {An alternating method for cardinality-constrained optimization: A computational study for the best subset selection and sparse portfolio problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Setting reserve prices in second-price auctions with
unobserved bids. <em>IJOC</em>, <em>34</em>(6), 2950–2967. (<a
href="https://doi.org/10.1287/ijoc.2022.1199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider a seller who sells an item via second-price auctions with a reserve price. By controlling the reserve price, the seller can influence the revenue from the auction, and in this paper, we propose a method for learning optimal reserve prices. We study a limited information setting where the probability distribution of the bids from bidders is unknown and the values of the bids are not revealed to the seller. Furthermore, we do not assume that the seller has access to a historical data set with bids. Our main contribution is a method that incorporates knowledge about the rules of second-price auctions into a multiarmed bandit framework for optimizing reserve prices in our limited information setting. The proposed method can be applied in both stationary and nonstationary environments. Experiments show that the proposed method outperforms state-of-the-art bandit algorithms. In stationary environments, our method outperforms these algorithms when the horizon is short and performs as good as they do for longer horizons. Our method is especially useful if there is a high number of potential reserve prices. In addition, our method adapts quickly to changing environments and outperforms state-of-the-art bandit algorithms designed for nonstationary environments.},
  archive      = {J_IJOC},
  author       = {Jason Rhuggenaath and Alp Akcay and Yingqian Zhang and Uzay Kaymak},
  doi          = {10.1287/ijoc.2022.1199},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2950-2967},
  shortjournal = {INFORMS J. Comput.},
  title        = {Setting reserve prices in second-price auctions with unobserved bids},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving large-scale fixed-budget ranking and selection
problems. <em>IJOC</em>, <em>34</em>(6), 2930–2949. (<a
href="https://doi.org/10.1287/ijoc.2022.1221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of computing technology, developing parallel procedures to solve large-scale ranking and selection (R&amp;amp;S) problems has attracted a lot of research attention. In this paper, we take fixed-budget R&amp;amp;S procedure as an example to investigate potential issues of developing parallel procedures. We argue that to measure the performance of a fixed-budget R&amp;amp;S procedure in solving large-scale problems, it is important to quantify the minimal growth rate of the total sampling budget such that as the number of alternatives increases, the probability of correct selection (PCS) would not decrease to zero. We call such a growth rate of the total sampling budget the rate for maintaining correct selection (RMCS). We show that a tight lower bound for the RMCS of a broad class of existing fixed-budget procedures is in the order of klog k, where k is the number of alternatives. Then, we propose a new type of fixed-budget procedure, namely the fixed-budget knockout-tournament (FBKT) procedure. We prove that, in terms of the RMCS, our procedure outperforms existing fixed-budget procedures and achieves the optimal order, that is, the order of k. Moreover, we demonstrate that our procedure can be easily implemented in parallel computing environments with almost no nonparallelizable calculations. Last, a comprehensive numerical study shows that our procedure is indeed suitable for solving large-scale problems in parallel computing environments.},
  archive      = {J_IJOC},
  author       = {L. Jeff Hong and Guangxin Jiang and Ying Zhong},
  doi          = {10.1287/ijoc.2022.1221},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2930-2949},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving large-scale fixed-budget ranking and selection problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bsnsing: A decision tree induction method based on recursive
optimal boolean rule composition. <em>IJOC</em>, <em>34</em>(6),
2908–2929. (<a href="https://doi.org/10.1287/ijoc.2022.1225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new mixed-integer programming (MIP) formulation to optimize split rule selection in the decision tree induction process and develops an efficient search algorithm that is able to solve practical instances of the MIP model faster than commercial solvers. The formulation is novel for it directly maximizes the Gini reduction, an effective split selection criterion that has never been modeled in a mathematical program for its nonconvexity. The proposed approach differs from other optimal classification tree models in that it does not attempt to optimize the whole tree; therefore, the flexibility of the recursive partitioning scheme is retained, and the optimization model is more amenable. The approach is implemented in an open-source R package named bsnsing. Benchmarking experiments on 75 open data sets suggest that bsnsing trees are the most capable of discriminating new cases compared with trees trained by other decision tree codes including the rpart, C50, party, and tree packages in R. Compared with other optimal decision tree packages, including DL8.5, OSDT, GOSDT, and indirectly more, bsnsing stands out in its training speed, ease of use, and broader applicability without losing in prediction accuracy.},
  archive      = {J_IJOC},
  author       = {Yanchao Liu},
  doi          = {10.1287/ijoc.2022.1225},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2908-2929},
  shortjournal = {INFORMS J. Comput.},
  title        = {Bsnsing: A decision tree induction method based on recursive optimal boolean rule composition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A stochastic approximation method for simulation-based
quantile optimization. <em>IJOC</em>, <em>34</em>(6), 2889–2907. (<a
href="https://doi.org/10.1287/ijoc.2022.1214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a gradient-based algorithm for solving a class of simulation optimization problems in which the objective function is the quantile of a simulation output random variable. In contrast with existing quantile (quantile derivative) estimation techniques, which aim to eliminate the estimator bias by gradually increasing the simulation sample size, our algorithm incorporates a novel recursive procedure that only requires a single simulation sample at each step to simultaneously obtain quantile and quantile derivative estimators that are asymptotically unbiased. We show that these estimators, when coupled with the standard gradient descent method, lead to a multitime-scale stochastic approximation type of algorithm that converges to an optimal quantile value with probability one. In our numerical experiments, the proposed algorithm is applied to optimal investment portfolio problems, resulting in new solutions that complement those obtained under the classical Markowitz mean-variance framework.},
  archive      = {J_IJOC},
  author       = {Jiaqiao Hu and Yijie Peng and Gongbo Zhang and Qi Zhang},
  doi          = {10.1287/ijoc.2022.1214},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2889-2907},
  shortjournal = {INFORMS J. Comput.},
  title        = {A stochastic approximation method for simulation-based quantile optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ROC++: Robust optimization in c++. <em>IJOC</em>,
<em>34</em>(6), 2873–2888. (<a
href="https://doi.org/10.1287/ijoc.2022.1209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last two decades, robust optimization has emerged as a popular means to address decision-making problems affected by uncertainty. This includes single-stage and multi-stage problems involving real-valued and/or binary decisions and affected by exogenous (decision-independent) and/or endogenous (decision-dependent) uncertain parameters. Robust optimization techniques rely on duality theory potentially augmented with approximations to transform a (semi-)infinite optimization problem to a finite program, the robust counterpart. Whereas writing down the model for a robust optimization problem is usually a simple task, obtaining the robust counterpart requires expertise. To date, very few solutions are available that can facilitate the modeling and solution of such problems. This has been a major impediment to their being put to practical use. In this paper, we propose ROC++, an open-source C++ based platform for automatic robust optimization, applicable to a wide array of single-stage and multi-stage robust problems with both exogenous and endogenous uncertain parameters, that is easy to both use and extend. It also applies to certain classes of stochastic programs involving continuously distributed uncertain parameters and endogenous uncertainty. Our platform naturally extends existing off-the-shelf deterministic optimization platforms and offers ROPy, a Python interface in the form of a callable library, and the ROB file format for storing and sharing robust problems. We showcase the modeling power of ROC++ on several decision-making problems of practical interest. Our platform can help streamline the modeling and solution of stochastic and robust optimization problems for both researchers and practitioners. It comes with detailed documentation to facilitate its use and expansion. The latest version of ROC++ can be downloaded from https://sites.google.com/usc.edu/robust-opt-cpp/.},
  archive      = {J_IJOC},
  author       = {Phebe Vayanos and Qing Jin and George Elissaios},
  doi          = {10.1287/ijoc.2022.1209},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2873-2888},
  shortjournal = {INFORMS J. Comput.},
  title        = {ROC++: Robust optimization in c++},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational and theoretical challenges for computing the
minimum rank of a graph. <em>IJOC</em>, <em>34</em>(6), 2868–2872. (<a
href="https://doi.org/10.1287/ijoc.2022.1219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum rank of a graph G is the minimum of the ranks of all symmetric adjacency matrices of G. We present a new combinatorial bound for the minimum rank of an arbitrary graph G based on enumerating certain subsets of vertices of G satisfying matroid theoretic properties. We also present some computational and theoretical challenges associated with computing the minimum rank. This includes a conjecture that this bound on the minimum rank actually holds with equality for all graphs.},
  archive      = {J_IJOC},
  author       = {Illya V. Hicks and Boris Brimkov and Louis Deaett and Ruth Haas and Derek Mikesell and David Roberson and Logan Smith},
  doi          = {10.1287/ijoc.2022.1219},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2868-2872},
  shortjournal = {INFORMS J. Comput.},
  title        = {Computational and theoretical challenges for computing the minimum rank of a graph},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Note from the editor. <em>IJOC</em>, <em>34</em>(6), 2867.
(<a href="https://doi.org/10.1287/ijoc.2022.1247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice Smith},
  doi          = {10.1287/ijoc.2022.1247},
  journal      = {INFORMS Journal on Computing},
  number       = {6},
  pages        = {2867},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Editorial board. <em>IJOC</em>, <em>34</em>(5), C2. (<a
href="https://doi.org/10.1287/ijoc.2022.eb.v3405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.eb.v3405},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simulation optimization approach for the appointment
scheduling problem with decision-dependent uncertainties. <em>IJOC</em>,
<em>34</em>(5), 2845–2865. (<a
href="https://doi.org/10.1287/ijoc.2022.1212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The appointment scheduling problem (ASP) studies how to manage patient arrivals to a healthcare system to improve system performance. An important challenge occurs when some patients may not show up for an appointment. Although the ASP is well studied in the literature, the vast majority of the existing work does not consider the well-observed phenomenon that patient no-show is influenced by the appointment time, the usual decision variable in the ASP. This paper studies the ASP with random service time (exogenous uncertainty) with known distribution and patient decision-dependent no-show behavior (endogenous uncertainty). This problem belongs to the class of stochastic optimization with decision-dependent uncertainties. Such problems are notoriously difficult as they are typically nonconvex. We propose a stochastic projected gradient path (SPGP) method to solve the problem, which requires the development of a gradient estimator of the objective function—a nontrivial task, as the literature on gradient-based optimization algorithms for problems with decision-dependent uncertainty is very scarce and unsuitable for our model. Our method can solve the ASP problem under arbitrarily smooth show-up probability functions. We present solutions under different patterns of no-show behavior and demonstrate that breaking the assumption of constant show-up probability substantially changes the scheduling solutions. We conduct numerical experiments in a variety of settings to compare our results with those obtained with a distributionally robust optimization method developed in the literature. The cost reduction obtained with our method, which we call the value of distribution information, can be interpreted as how much the system performance can be improved by knowing the distribution of the service times, compared to not knowing it. We observe that the value of distribution information is up to 31\% of the baseline cost, and that such value is higher when the system is crowded or/and the waiting time cost is relatively high.},
  archive      = {J_IJOC},
  author       = {Tito Homem-de-Mello and Qingxia Kong and Rodrigo Godoy-Barba},
  doi          = {10.1287/ijoc.2022.1212},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2845-2865},
  shortjournal = {INFORMS J. Comput.},
  title        = {A simulation optimization approach for the appointment scheduling problem with decision-dependent uncertainties},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Managing product transitions: A bilevel programming
approach. <em>IJOC</em>, <em>34</em>(5), 2828–2844. (<a
href="https://doi.org/10.1287/ijoc.2022.1210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model the hierarchical and decentralized nature of product transitions using a mixed-integer bilevel program with two followers, a manufacturing unit and an engineering unit. The leader, corporate management, seeks to maximize revenue over a finite planning horizon. The manufacturing unit uses factory capacity to satisfy the demand for current products. The demand for new products, however, cannot be fulfilled until the engineering unit completes their development, which, in turn, requires factory capacity for prototype fabrication. We model this interdependency between the engineering and manufacturing units as a generalized Nash equilibrium game at the lower level of the proposed bilevel model. We present a reformulation where the interdependency between the followers is resolved through the leader’s coordination, and we derive a solution method based on constraint and column generation. Our computational experiments show that the proposed approach can solve realistic instances to optimality in a reasonable time. We provide managerial insights into how the allocation of decision authority between corporate leadership and functional units affects the objective function performance. This paper presents the first exact solution algorithm to mixed-integer bilevel programs with interdependent followers, providing a flexible framework to study decentralized, hierarchical decision-making problems.},
  archive      = {J_IJOC},
  author       = {Rahman Khorramfar and Osman Y. Özaltın and Karl G. Kempf and Reha Uzsoy},
  doi          = {10.1287/ijoc.2022.1210},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2828-2844},
  shortjournal = {INFORMS J. Comput.},
  title        = {Managing product transitions: A bilevel programming approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A closest benders cut selection scheme for accelerating the
benders decomposition algorithm. <em>IJOC</em>, <em>34</em>(5),
2804–2827. (<a href="https://doi.org/10.1287/ijoc.2022.1207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Benders decomposition algorithm often shows poor convergence. To improve the convergence of the Benders decomposition algorithm. Recently, it was proposed the use of feasibility cuts closest to a solution in the set defined by all feasibility cuts. We extend this feasibility cut selection scheme to a new cut selection scheme for optimality cuts and propose a new Benders separation framework that a single linear programming problem can solve. We show that optimality cuts generated by this scheme are Pareto optimal when some conditions are satisfied. Theoretical connections to the existing Benders cut generation methods are also identified. Extensive computational experiments on the multiple classes of benchmark problems demonstrate that the proposed algorithm improves the convergence speed and computational time.},
  archive      = {J_IJOC},
  author       = {Kiho Seo and Seulgi Joung and Chungmok Lee and Sungsoo Park},
  doi          = {10.1287/ijoc.2022.1207},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2804-2827},
  shortjournal = {INFORMS J. Comput.},
  title        = {A closest benders cut selection scheme for accelerating the benders decomposition algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust stochastic facility location: Sensitivity analysis
and exact solution. <em>IJOC</em>, <em>34</em>(5), 2776–2803. (<a
href="https://doi.org/10.1287/ijoc.2022.1206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on a broad class of facility location problems in the context of adaptive robust stochastic optimization under the state-dependent demand uncertainty. The demand is assumed to be significantly affected by related state information, such as the seasonal or socio-economic information. In particular, a state-wise ambiguity set is adopted for modeling the distributional uncertainty associated with the demand in different states. The conditional distributional characteristics in each state are described by a support, as well as by mean and dispersion measures, which are assumed to be conic representable. A robust sensitivity analysis is performed, in which, on the one hand, we analyze the impact of the change in ambiguity-set parameters (e.g., state probabilities, mean value abounds, and dispersion bounds in different states) onto the optimal worst-case expected total cost using the ambiguity dual variables. On the other hand, we analyze the impact of the change in location design onto the worst-case expected second-stage cost and show that the sensitivity bounds are fully described as the worst-case expected shadow-capacity cost. As for the solution approach, we propose a nested Benders decomposition algorithm for solving the model exactly, which leverages the subgradients of the worst-case expected second-stage cost at the location decisions formed insightfully by the associated worst-case distributions. The nested Benders decomposition approach ensures a finite-step convergence, which can also be regarded as an extension of the classic L-shaped algorithm for two-stage stochastic programming to our state-wise, robust stochastic facility location problem with conic representable ambiguity. Finally, the results of a series of numerical experiments are presented that justify the value of the state-wise distributional information incorporated in our robust stochastic facility location model, the robustness of the model, and the performance of the exact solution approach.},
  archive      = {J_IJOC},
  author       = {Tianqi Liu and Francisco Saldanha-da-Gama and Shuming Wang and Yuchen Mao},
  doi          = {10.1287/ijoc.2022.1206},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2776-2803},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust stochastic facility location: Sensitivity analysis and exact solution},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). L0-regularized learning for high-dimensional additive
hazards regression. <em>IJOC</em>, <em>34</em>(5), 2762–2775. (<a
href="https://doi.org/10.1287/ijoc.2022.1208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse learning in high-dimensional survival analysis is of great practical importance, as exemplified by modern applications in credit risk analysis and high-throughput genomic data analysis. In this article, we consider the L0-regularized learning for simultaneous variable selection and estimation under the framework of additive hazards models and utilize the idea of primal dual active sets to develop an algorithm targeted at solving the traditionally nonpolynomial time optimization problem. Under interpretable conditions, comprehensive statistical properties, including model selection consistency, oracle inequalities under various estimation losses, and the oracle property, are established for the global optimizer of the proposed approach. Moreover, our theoretical analysis for the algorithmic solution reveals that the proposed L0-regularized learning can be more efficient than other regularization methods in that it requests a smaller sample size as well as a lower minimum signal strength to identify the significant features. The effectiveness of the proposed method is evidenced by simulation studies and real-data analysis.},
  archive      = {J_IJOC},
  author       = {Zemin Zheng and Jie Zhang and Yang Li},
  doi          = {10.1287/ijoc.2022.1208},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2762-2775},
  shortjournal = {INFORMS J. Comput.},
  title        = {L0-regularized learning for high-dimensional additive hazards regression},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A software package and data set for the personal protective
equipment matching problem during COVID-19. <em>IJOC</em>,
<em>34</em>(5), 2754–2761. (<a
href="https://doi.org/10.1287/ijoc.2022.1203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the COVID-19 pandemic, Get Us PPE provided a platform aimed at connecting prospective donors of personal protective equipment (PPE) to prospective recipients of PPE. Requests by donors and recipients were collected over time, and periodically, the PPE matching problem was solved in order to instruct each donor to ship a certain quantity of PPE to a given recipient. The objectives of the PPE matching problem include maximizing the recipients’ fill rate, minimizing the total shipping distance, minimizing the holding time of PPE, and minimizing the number of shipments of each donor. This paper presents a software framework to facilitate the development of methodologies to solve the PPE matching problem and their testing on a real-world data set collected by Get Us PPE during the COVID-19 pandemic. Both software and data set are available on GitHub.},
  archive      = {J_IJOC},
  author       = {Michele Samorani and Ram Bala and Rohit Jacob and Shuhan He},
  doi          = {10.1287/ijoc.2022.1203},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2754-2761},
  shortjournal = {INFORMS J. Comput.},
  title        = {A software package and data set for the personal protective equipment matching problem during COVID-19},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Projective cutting-planes for robust linear programming and
cutting stock problems. <em>IJOC</em>, <em>34</em>(5), 2736–2753. (<a
href="https://doi.org/10.1287/ijoc.2022.1160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the Projective Cutting-Planes algorithm proposed in Porumbel (2020) from new angles by applying it to two new problems, that is, to robust linear programming and to a cutting-stock problem with multiple lengths. Projective Cutting-Planes is a generalization of the widely used Cutting-Planes, and it aims at optimizing a linear function over a polytope P with prohibitively many constraints. The main new idea is to replace the well-known separation subproblem with the following projection subproblem: given an interior point x∈P and a direction d, find the maximum steplength t such that x+td∈P. This enables one to generate a feasible solution at each iteration, a feature that does not exist built-in in a standard Cutting-Planes algorithm. The practical success of this new algorithm does not mainly come from the higher level ideas already presented in Porumbel (2020). Its success is significantly more dependent on the computation time needed to solve the projection subproblem in practice. Thus, the main challenge addressed by the current paper is the design of new techniques for solving this subproblem very efficiently for different polytopes P. We first address a well-known robust linear programming problem in which P is defined as a primal polytope. We then solve a multiple-length cutting stock problem in which P is a dual polytope defined in a column generation model. Numerical experiments on both these new problems confirm the potential of the proposed ideas. This enables us to draw conclusions supported by numerical results from both the current paper and Porumbel (2020) while also gaining more insight into the dynamics of the algorithm.},
  archive      = {J_IJOC},
  author       = {Daniel Porumbel},
  doi          = {10.1287/ijoc.2022.1160},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2736-2753},
  shortjournal = {INFORMS J. Comput.},
  title        = {Projective cutting-planes for robust linear programming and cutting stock problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decomposition and adaptive sampling for data-driven inverse
linear optimization. <em>IJOC</em>, <em>34</em>(5), 2720–2735. (<a
href="https://doi.org/10.1287/ijoc.2022.1162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses inverse linear optimization, where the goal is to infer the unknown cost vector of a linear program. Specifically, we consider the data-driven setting in which the available data are noisy observations of optimal solutions that correspond to different instances of the linear program. We introduce a new formulation of the problem that, compared with other existing methods, allows the recovery of a less restrictive and generally more appropriate admissible set of cost estimates. It can be shown that this inverse optimization problem yields a finite number of solutions, and we develop an exact two-phase algorithm to determine all such solutions. Moreover, we propose an efficient decomposition algorithm to solve large instances of the problem. The algorithm extends naturally to an online learning environment where it can be used to provide quick updates of the cost estimate as new data become available over time. For the online setting, we further develop an effective adaptive sampling strategy that guides the selection of the next samples. The efficacy of the proposed methods is demonstrated in computational experiments involving two applications: customer preference learning and cost estimation for production planning. The results show significant reductions in computation and sampling efforts.},
  archive      = {J_IJOC},
  author       = {Rishabh Gupta and Qi Zhang},
  doi          = {10.1287/ijoc.2022.1162},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2720-2735},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decomposition and adaptive sampling for data-driven inverse linear optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic RWA and lightpath rerouting in WDM networks.
<em>IJOC</em>, <em>34</em>(5), 2700–2719. (<a
href="https://doi.org/10.1287/ijoc.2022.1179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a telecommunication network, routing and wavelength assignment (RWA) is the problem of finding lightpaths for incoming connection requests. When facing a dynamic traffic, greedy assignment of lightpaths to incoming requests based on predefined deterministic policies leads to a fragmented network that cannot make use of its full capacity because of stranded bandwidth. At this point, service providers try to recover the capacity via a defragmentation process. We study this setting from two perspectives: (i) while granting the connection requests via the RWA problem and (ii) during the defragmentation process by lightpath rerouting. For both problems, we present the first two-stage stochastic integer programming model incorporating incoming request uncertainty to maximize the expected grade of service. We develop a decomposition-based solution approach, which uses various relaxations of the problem and a newly developed problem-specific cut family. Simulation of two-stage policies for a variety of instances in a rolling-horizon framework of 52 stages shows that our stochastic models provide high-quality solutions when compared with traditionally used deterministic ones. Specifically, the proposed provisioning policies yield improvements of up to 19\% in overall grade of service and 20\% in spectrum saving, while the stochastic lightpath rerouting policies grant up to 36\% more requests, using up to just 4\% more bandwidth spectrum.},
  archive      = {J_IJOC},
  author       = {Maryam Daryalal and Merve Bodur},
  doi          = {10.1287/ijoc.2022.1179},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2700-2719},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stochastic RWA and lightpath rerouting in WDM networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving natural conic formulations with hypatia.jl.
<em>IJOC</em>, <em>34</em>(5), 2686–2699. (<a
href="https://doi.org/10.1287/ijoc.2022.1202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many convex optimization problems can be represented through conic extended formulations (EFs) using only the small number of standard cones recognized by advanced conic solvers such as MOSEK 9. However, EFs are often significantly larger and more complex than equivalent conic natural formulations (NFs) represented using the much broader class of exotic cones. We define an exotic cone as a proper cone for which we can implement easily computable logarithmically homogeneous self-concordant barrier oracles for either the cone or its dual cone. Our goal is to establish whether a generic conic interior point solver supporting NFs can outperform an advanced conic solver specialized for EFs across a variety of applied problems. We introduce Hypatia, a highly configurable open-source conic primal-dual interior point solver written in Julia and accessible through JuMP. Hypatia has a generic interface for exotic cones, some of which we define here. For seven applied problems, we introduce NFs using these cones and construct EFs that are necessarily larger and more complex. Our computational experiments demonstrate the advantages, especially in terms of solve time and memory usage, of solving the NFs with Hypatia compared with solving the EFs with either Hypatia or MOSEK 9.},
  archive      = {J_IJOC},
  author       = {Chris Coey and Lea Kapelevich and Juan Pablo Vielma},
  doi          = {10.1287/ijoc.2022.1202},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2686-2699},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving natural conic formulations with hypatia.jl},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constant approximation for the lifetime scheduling problem
of p-percent coverage. <em>IJOC</em>, <em>34</em>(5), 2675–2685. (<a
href="https://doi.org/10.1287/ijoc.2022.1201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been an open question for some time whether there exists a polynomial-time constant approximation for the lifetime scheduling problem of p-percent coverage. In this paper, we give a positive answer to this question.},
  archive      = {J_IJOC},
  author       = {Zhao Zhang and Wei Liang and Hongmin W. Du and Siwen Liu},
  doi          = {10.1287/ijoc.2022.1201},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2675-2685},
  shortjournal = {INFORMS J. Comput.},
  title        = {Constant approximation for the lifetime scheduling problem of p-percent coverage},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A catalog of formulations for the network pricing problem.
<em>IJOC</em>, <em>34</em>(5), 2658–2674. (<a
href="https://doi.org/10.1287/ijoc.2022.1198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the network pricing problem where the leader maximizes revenue by determining the optimal amounts of tolls to charge on a set of arcs, under the assumption that the followers will react rationally and choose the shortest paths to travel. Many distinct single-level reformulations of this bilevel optimization program have been proposed; however, their relationship has not been established. In this paper, we aim to build a connection between those reformulations and explore the combination of the path representation with various modeling options, allowing us to generate 12 different reformulations of the problem. Moreover, we propose a new path enumeration scheme, path-based preprocessing, and hybrid framework to further improve performance and robustness when solving the final model. We provide numerical results, comparing all the derived reformulations and confirming the efficiency of the novel dimensionality reduction procedures.},
  archive      = {J_IJOC},
  author       = {Quang Minh Bui and Bernard Gendron and Margarida Carvalho},
  doi          = {10.1287/ijoc.2022.1198},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2658-2674},
  shortjournal = {INFORMS J. Comput.},
  title        = {A catalog of formulations for the network pricing problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A branch-and-cut algorithm for submodular interdiction
games. <em>IJOC</em>, <em>34</em>(5), 2634–2657. (<a
href="https://doi.org/10.1287/ijoc.2022.1196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many relevant applications from diverse areas such as marketing, wildlife conservation, and defending critical infrastructure can be modeled as interdiction games. In this work, we introduce interdiction games whose objective is a monotone and submodular set function. Given a ground set of items, the leader interdicts the usage of some of the items of the follower in order to minimize the objective value achievable by the follower, who seeks to maximize a submodular set function over the uninterdicted items subject to knapsack constraints. We propose an exact branch-and-cut algorithm for this kind of interdiction game. The algorithm is based on interdiction cuts, which allow the leader to capture the follower’s objective function value for a given interdiction decision of the leader and exploit the submodularity of the objective function. We also present extensions and liftings of these cuts and discuss additional preprocessing procedures. We test our solution framework on the weighted maximal covering interdiction game and the bipartite inference interdiction game. For both applications, the improved variants of our interdiction cut perform significantly better than the basic version. For the weighted maximal covering interdiction game for which a mixed-integer bilevel linear programming (MIBLP) formulation is available, we compare the results with those of a state-of-the-art MIBLP solver. Whereas the MIBLP solver yields a minimum of 54\% optimality gap within one hour, our best branch-and-cut setting solves all but four of 108 instances to optimality with a maximum of 3\% gap among unsolved ones.},
  archive      = {J_IJOC},
  author       = {Kübra Tanınmış and Markus Sinnl},
  doi          = {10.1287/ijoc.2022.1196},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2634-2657},
  shortjournal = {INFORMS J. Comput.},
  title        = {A branch-and-cut algorithm for submodular interdiction games},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convexification of queueing formulas by mixed-integer
second-order cone programming: An application to a discrete location
problem with congestion. <em>IJOC</em>, <em>34</em>(5), 2621–2633. (<a
href="https://doi.org/10.1287/ijoc.2021.1125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed-integer second-order cone programs (MISOCPs) form a novel class of mixed-integer convex programs, which can be solved very efficiently as a result of the recent advances in optimization solvers. This paper shows how various performance metrics of M/G/1 queues can be modeled by different MISOCPs. To motivate the reformulation method, it is first applied to a challenging stochastic location problem with congestion, which is broadly used to design socially optimal service systems. Three different MISOCPs are developed and compared on different sets of benchmark test problems. The new formulations efficiently solve very large-size test problems that cannot be solved by the two existing methods developed based on linear programming within reasonable time. The superiority of the conic reformulation method is next shown over a state-space decomposition method recently used to solve an assignment problem in queueing systems. Finally, the general applicability of the method is shown for similar optimization problems that use queue-theoretic performance measures to address customer satisfaction and service quality.},
  archive      = {J_IJOC},
  author       = {Amir Ahmadi-Javid and Pooya Hoseinpour},
  doi          = {10.1287/ijoc.2021.1125},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2621-2633},
  shortjournal = {INFORMS J. Comput.},
  title        = {Convexification of queueing formulas by mixed-integer second-order cone programming: An application to a discrete location problem with congestion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FrankWolfe.jl: A high-performance and flexible toolbox for
frank–wolfe algorithms and conditional gradients. <em>IJOC</em>,
<em>34</em>(5), 2611–2620. (<a
href="https://doi.org/10.1287/ijoc.2022.1191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present FrankWolfe.jl, an open-source implementation of several popular Frank–Wolfe and conditional gradients variants for first-order constrained optimization. The package is designed with flexibility and high performance in mind, allowing for easy extension and relying on few assumptions regarding the user-provided functions. It supports Julia’s unique multiple dispatch feature, and it interfaces smoothly with generic linear optimization formulations using MathOptInterface.jl.},
  archive      = {J_IJOC},
  author       = {Mathieu Besançon and Alejandro Carderera and Sebastian Pokutta},
  doi          = {10.1287/ijoc.2022.1191},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2611-2620},
  shortjournal = {INFORMS J. Comput.},
  title        = {FrankWolfe.jl: A high-performance and flexible toolbox for Frank–Wolfe algorithms and conditional gradients},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal frameworks for detecting anomalies in
sensor-intensive heterogeneous networks. <em>IJOC</em>, <em>34</em>(5),
2583–2610. (<a href="https://doi.org/10.1287/ijoc.2022.1192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many network/graph structures are continuously monitored by various sensors that are placed at a subset of nodes and edges. The multidimensional data collected from these sensors over time create large-scale graph data in which the data points are highly dependent. Monitoring large-scale attributed networks with thousands of nodes and heterogeneous sensor data to detect anomalies and unusual events is a complex and computationally expensive process. This paper introduces a new generic approach inspired by state-space models for network anomaly detection that can utilize the information from the network topology, the node attributes (sensor data), and the anomaly propagation sets in an integrated manner to analyze the entire network all at once. This article presents how heterogeneous network sensor data can be analyzed to locate the sources of anomalies as well as the anomalous regions in a network, which can be impacted by one or multiple anomalies at any time instance. Experimental results demonstrate the superior performance of our proposed framework in detecting anomalies in attributed graphs.},
  archive      = {J_IJOC},
  author       = {Ramin Moghaddass and Yongtao Guan},
  doi          = {10.1287/ijoc.2022.1192},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2583-2610},
  shortjournal = {INFORMS J. Comput.},
  title        = {Optimal frameworks for detecting anomalies in sensor-intensive heterogeneous networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network design with service requirements: Scaling-up the
size of solvable problems. <em>IJOC</em>, <em>34</em>(5), 2571–2582. (<a
href="https://doi.org/10.1287/ijoc.2022.1200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network design, a cornerstone of mathematical optimization, is about defining the main characteristics of a network satisfying requirements on connectivity, capacity, and level-of-service. It finds applications in logistics and transportation, telecommunications, data sharing, energy distribution, and distributed computing. In multicommodity network design, one is required to design a network minimizing the installation cost of its arcs and the operational cost to serve a set of point-to-point connections. The definition of this prototypical problem was recently enriched by additional constraints imposing that each origin-destination of a connection is served by a single path satisfying one or more level-of-service requirements, thus defining the Network Design with Service Requirements. These constraints are crucial, for example, in telecommunications and computer networks to ensure reliable and low-latency communication. In this paper we provide a new formulation for the problem, where variables are associated with paths satisfying the end-to-end service requirements. We present a fast algorithm for enumerating all the exponentially many feasible paths, and when this is not viable, we provide a column generation scheme that is embedded into a branch-and-cut-and-price algorithm. Extensive computational experiments on a large set of instances show that our approach can move a step further in the solution of the network design with service requirements compared with the current state-of-the-art.},
  archive      = {J_IJOC},
  author       = {Naga V. C. Gudapati and Enrico Malaguti and Michele Monaci},
  doi          = {10.1287/ijoc.2022.1200},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2571-2582},
  shortjournal = {INFORMS J. Comput.},
  title        = {Network design with service requirements: Scaling-up the size of solvable problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving variable orderings of approximate decision
diagrams using reinforcement learning. <em>IJOC</em>, <em>34</em>(5),
2552–2570. (<a href="https://doi.org/10.1287/ijoc.2022.1194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prescriptive analytics provides organizations with scalable solutions for large-scale, automated decision making. At the core of prescriptive analytics methodology is optimization, a field devoted to the study of algorithms that solve complex decision-making problems. Optimization algorithms rely heavily on generic methods for identifying tight bounds, which provide both solutions to problems and optimality guarantees. In the last decade, decision diagrams (DDs) have demonstrated significant advantages in obtaining bounds compared with the standard linear relaxation commonly used by commercial solvers. However, the quality of the bounds computed by DDs depends heavily on the variable ordering chosen for the construction. Besides, the problem of finding an ordering that optimizes a given metric is generally NP-hard. This paper studies how machine learning, specifically deep reinforcement learning (DRL), can be used to improve bounds provided by DDs, in particular through learning a good variable ordering. The introduced DRL models improve primal and dual bounds, even over standard linear programming relaxations, and are integrated in a full-fledged branch-and-bound algorithm. This paper, therefore, provides a novel mechanism for utilizing machine learning to tighten bounds, adding to recent research on using machine learning to obtain high-quality heuristic solutions and, for the first time, using machine learning to improve relaxation bounds through a generic bounding method. We apply the methods on a classic optimization problem, the maximum independent set, and demonstrate through computational testing that optimization bounds can be significantly improved through DRL. We provide the code to replicate the results obtained on the maximum independent set.},
  archive      = {J_IJOC},
  author       = {Quentin Cappart and David Bergman and Louis-Martin Rousseau and Isabeau Prémont-Schwarz and Augustin Parjadis},
  doi          = {10.1287/ijoc.2022.1194},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2552-2570},
  shortjournal = {INFORMS J. Comput.},
  title        = {Improving variable orderings of approximate decision diagrams using reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Play like the pros? Solving the game of darts as a dynamic
zero-sum game. <em>IJOC</em>, <em>34</em>(5), 2540–2551. (<a
href="https://doi.org/10.1287/ijoc.2022.1197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The game of darts has enjoyed great growth over the past decade with the perception of darts moving from that of a pub game to a game that is regularly scheduled on prime-time television in many countries such as the United Kingdom, Germany, the Netherlands, and Australia, among others. It involves strategic interactions between two players, but to date, the literature has ignored these interactions. In this paper, we formulate and solve the game of darts as a dynamic zero-sum game (ZSG), and to the best of our knowledge, we are the first to do so. We also estimate individual skill models using a novel data set based on darts matches that were played by the top 16 professional players in the world during the 2019 season. Using the fitted skill models and our ZSG problem formulation, we quantify the importance of playing strategically—that is, taking into account the score and strategy of one’s opponent—when computing an optimal strategy. For top professionals, we find that playing strategically results in an increase in win probability of just 0.2\%–0.6\% over a single leg but as much as 2.2\% over a best-of-31-legs match.},
  archive      = {J_IJOC},
  author       = {Martin B. Haugh and Chun Wang},
  doi          = {10.1287/ijoc.2022.1197},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2540-2551},
  shortjournal = {INFORMS J. Comput.},
  title        = {Play like the pros? solving the game of darts as a dynamic zero-sum game},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An iterated dual substitution approach for binary integer
programming problems under the min-max regret criterion. <em>IJOC</em>,
<em>34</em>(5), 2523–2539. (<a
href="https://doi.org/10.1287/ijoc.2022.1189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider binary integer programming problems with the min-max regret objective function under interval objective coefficients. We propose a heuristic framework, the iterated dual substitution (iDS) algorithm, which iteratively invokes a dual substitution heuristic and excludes from the search space any solution already checked in previous iterations. In iDS, we use a best scenario–based lemma to improve performance. We apply iDS to four typical combinatorial optimization problems: the knapsack problem, the multidimensional knapsack problem, the generalized assignment problem, and the set covering problem. For the multidimensional knapsack problem, we compare the iDS approach with two algorithms widely used for problems with the min-max regret criterion: a fixed-scenario approach, and a branch-and-cut approach. The results of computational experiments on a broad set of benchmark instances show that the proposed iDS approach performs best on most tested instances. For the knapsack problem, the generalized assignment problem, and the set covering problem, we compare iDS with state-of-the-art results. The iDS algorithm successfully updates best-known records for a number of benchmark instances.},
  archive      = {J_IJOC},
  author       = {Wei Wu and Manuel Iori and Silvano Martello and Mutsunori Yagiura},
  doi          = {10.1287/ijoc.2022.1189},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2523-2539},
  shortjournal = {INFORMS J. Comput.},
  title        = {An iterated dual substitution approach for binary integer programming problems under the min-max regret criterion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exactly solving hard permutation flowshop scheduling
problems on peta-scale GPU-accelerated supercomputers. <em>IJOC</em>,
<em>34</em>(5), 2502–2522. (<a
href="https://doi.org/10.1287/ijoc.2022.1193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Makespan minimization in permutation flow-shop scheduling is a well-known hard combinatorial optimization problem. Among the 120 standard benchmark instances proposed by E. Taillard in 1993, 23 have remained unsolved for almost three decades. In this paper, we present our attempts to solve these instances to optimality using parallel Branch-and-Bound (BB) on the GPU-accelerated Jean Zay supercomputer. We report the exact solution of 11 previously unsolved problem instances and improved upper bounds for eight instances. The solution of these problems requires both algorithmic improvements and leveraging the computing power of peta-scale high-performance computing platforms. The challenge consists in efficiently performing parallel depth-first traversal of a highly irregular and fine-grained search tree on distributed systems composed of hundreds of massively parallel accelerator devices and multicore processors. We present and discuss the design and implementation of our permutation-based BB and experimentally evaluate its parallel performance on up to 384 V100 GPUs (2 million CUDA cores) and 3840 CPU cores. The optimality proof for the largest solved instance requires about 64 CPU-years of computation—using 256 GPUs and over 4 million parallel search agents, the traversal of the search tree is completed in 13 hours, exploring 339×1012 nodes.},
  archive      = {J_IJOC},
  author       = {Jan Gmys},
  doi          = {10.1287/ijoc.2022.1193},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2502-2522},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exactly solving hard permutation flowshop scheduling problems on peta-scale GPU-accelerated supercomputers},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Features selection as a nash-bargaining solution:
Applications in online advertising and information systems.
<em>IJOC</em>, <em>34</em>(5), 2485–2501. (<a
href="https://doi.org/10.1287/ijoc.2022.1190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a fundamental problem in online advertising, as features usually need to be purchased from third parties, and they are costly. Although many feature selection techniques can be used in online advertising and the general information systems (IS) domain, their performance is often context specific. Therefore, the literature of IS is suffering from a lack of adequate and generic methods. In this study, we address this issue by proposing a novel approach that employs ideas from the field of cooperative game theory. We derive a (continuous) second-order cone program that any convex programming solver can solve for determining the best subset of features. We show the efficacy of our proposed method on a real-life online advertising case study. We demonstrate that our proposed approach performs better in accuracy, precision, recall, and F-1 score than the best of the other approaches with much fewer features. Also, to illustrate that our method’s benefits are not limited to the context of online advertising, we perform an extensive set of simulations and consider a well-established real-life data set drawn from the UCI Machine Learning Repository at the University of California, Irvine.},
  archive      = {J_IJOC},
  author       = {Kimia Keshanian and Daniel Zantedeschi and Kaushik Dutta},
  doi          = {10.1287/ijoc.2022.1190},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2485-2501},
  shortjournal = {INFORMS J. Comput.},
  title        = {Features selection as a nash-bargaining solution: Applications in online advertising and information systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ExpertRNA: A new framework for RNA secondary structure
prediction. <em>IJOC</em>, <em>34</em>(5), 2464–2484. (<a
href="https://doi.org/10.1287/ijoc.2022.1188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ribonucleic acid (RNA) is a fundamental biological molecule that is essential to all living organisms, performing a versatile array of cellular tasks. The function of many RNA molecules is strongly related to the structure it adopts. As a result, great effort is being dedicated to the design of efficient algorithms that solve the “folding problem”—given a sequence of nucleotides, return a probable list of base pairs, referred to as the secondary structure prediction. Early algorithms largely rely on finding the structure with minimum free energy. However, the predictions rely on effective simplified free energy models that may not correctly identify the correct structure as the one with the lowest free energy. In light of this, new, data-driven approaches that not only consider free energy, but also use machine learning techniques to learn motifs are also investigated and recently been shown to outperform free energy–based algorithms on several experimental data sets. In this work, we introduce the new ExpertRNA algorithm that provides a modular framework that can easily incorporate an arbitrary number of rewards (free energy or nonparametric/data driven) and secondary structure prediction algorithms. We argue that this capability of ExpertRNA has the potential to balance out different strengths and weaknesses of state-of-the-art folding tools. We test ExpertRNA on several RNA sequence-structure data sets, and we compare the performance of ExpertRNA against a state-of-the-art folding algorithm. We find that ExpertRNA produces, on average, more accurate predictions of nonpseudoknotted secondary structures than the structure prediction algorithm used, thus validating the promise of the approach.},
  archive      = {J_IJOC},
  author       = {Menghan Liu and Erik Poppleton and Giulia Pedrielli and Petr Šulc and Dimitri P. Bertsekas},
  doi          = {10.1287/ijoc.2022.1188},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2464-2484},
  shortjournal = {INFORMS J. Comput.},
  title        = {ExpertRNA: A new framework for RNA secondary structure prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-grained job salary benchmarking with a nonparametric
dirichlet process–based latent factor model. <em>IJOC</em>,
<em>34</em>(5), 2443–2463. (<a
href="https://doi.org/10.1287/ijoc.2022.1182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key decision-making process in compensation and benefits (C&amp;amp;B) in human resource management, job salary benchmarking (JSB) plays an indispensable role in attracting, motivating, and retaining talent. Whereas the existing research mainly focuses on revealing the essential impacts of personal and organizational characteristics and economic factors on labor costs (e.g., C&amp;amp;B), few studies target optimizing JSB from a practical, data-driven perspective. Traditional approaches suffer from issues that result from using small and sparse data as well as from the limitations of linear statistical models in practice. Furthermore, there are also important technical issues that need to be addressed in the small number of machine learning–based JSB approaches, such as “cold start” issues when considering a brand-new type of company or job or model interpretability issues. To this end, we propose to address the JSB problem with data-driven techniques from a fine-grained perspective by modeling large-scale, real-world online recruitment data. Specifically, we develop a nonparametric Dirichlet process–based latent factor model (NDP-JSB) to jointly model the latent representations of both company and job position and then apply the model to predict salaries based on company and position information. Our model strengthens the usage of data-driven approaches in JSB optimization by addressing the aforementioned issues in existing models. For evaluation, extensive experiments are conducted on two large-scale, real-world data sets. Our results validate the effectiveness of the NDP-JSB and demonstrate its strength in providing interpretable salary benchmarking to benefit complex decision-making processes in talent management.},
  archive      = {J_IJOC},
  author       = {Qingxin Meng and Keli Xiao and Dazhong Shen and Hengshu Zhu and Hui Xiong},
  doi          = {10.1287/ijoc.2022.1182},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2443-2463},
  shortjournal = {INFORMS J. Comput.},
  title        = {Fine-grained job salary benchmarking with a nonparametric dirichlet Process–Based latent factor model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic planning and scheduling with logic-based benders
decomposition. <em>IJOC</em>, <em>34</em>(5), 2428–2442. (<a
href="https://doi.org/10.1287/ijoc.2022.1184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We apply logic-based Benders decomposition (LBBD) to two-stage stochastic planning and scheduling problems in which the second stage is a scheduling task. We solve the master problem with mixed integer/linear programming and the subproblem with constraint programming. As Benders cuts, we use simple no-good cuts as well as analytic logic-based cuts we develop for this application. We find that LBBD is computationally superior to the integer L-shaped method. In particular, a branch-and-check variant of LBBD can be faster by several orders of magnitude, allowing significantly larger instances to be solved. This is due primarily to computational overhead incurred by the integer L-shaped method while generating classic Benders cuts from a continuous relaxation of an integer programming subproblem. To our knowledge, this is the first application of LBBD to two-stage stochastic optimization with a scheduling second-stage problem and the first comparison of LBBD with the integer L-shaped method. The results suggest that LBBD could be a promising approach to other stochastic and robust optimization problems with integer or combinatorial recourse.},
  archive      = {J_IJOC},
  author       = {Özgün Elçi and John Hooker},
  doi          = {10.1287/ijoc.2022.1184},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2428-2442},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stochastic planning and scheduling with logic-based benders decomposition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Disjoint bilinear optimization: A two-stage robust
optimization perspective. <em>IJOC</em>, <em>34</em>(5), 2410–2427. (<a
href="https://doi.org/10.1287/ijoc.2022.1163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on a subclass of quadratic optimization problems, that is, disjoint bilinear optimization problems. We first show that disjoint bilinear optimization problems can be cast as two-stage robust linear optimization problems with fixed-recourse and right-hand-side uncertainty, which enables us to apply robust optimization techniques to solve the resulting problems. To this end, a solution scheme based on a blending of three popular robust optimization techniques is proposed. For disjoint bilinear optimization problems with a polyhedral feasible region and a general convex feasible region, we show that, under mild regularity conditions, the convex relaxations of the original bilinear formulation and its two-stage robust reformulation obtained from a reformulation-linearization-based technique and linear decision rules, respectively, are equivalent. For generic bilinear optimization problems, the convex relaxations from the reformulation-linearization-based technique are generally tighter than the one from linear decision rules. Numerical experiments on bimatrix games, synthetic disjoint bilinear problem instances, and convex maximization problems demonstrate the efficiency and effectiveness of the proposed solution scheme.},
  archive      = {J_IJOC},
  author       = {Jianzhe Zhen and Ahmadreza Marandi and Danique de Moor and Dick den Hertog and Lieven Vandenberghe},
  doi          = {10.1287/ijoc.2022.1163},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2410-2427},
  shortjournal = {INFORMS J. Comput.},
  title        = {Disjoint bilinear optimization: A two-stage robust optimization perspective},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic cutting planes for data-driven optimization.
<em>IJOC</em>, <em>34</em>(5), 2400–2409. (<a
href="https://doi.org/10.1287/ijoc.2022.1205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a stochastic version of the cutting plane method for a large class of data-driven mixed-integer nonlinear optimization (MINLO) problems. We show that under very weak assumptions, the stochastic algorithm can converge to an ϵ-optimal solution with high probability. Numerical experiments on several problems show that stochastic cutting planes is able to deliver a multiple order-of-magnitude speedup compared with the standard cutting plane method. We further experimentally explore the lower limits of sampling for stochastic cutting planes and show that, for many problems, a sampling size of O(n3) appears to be sufficient for high-quality solutions.},
  archive      = {J_IJOC},
  author       = {Dimitris Bertsimas and Michael Lingzhi Li},
  doi          = {10.1287/ijoc.2022.1205},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2400-2409},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stochastic cutting planes for data-driven optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous multi-resource allocation with subset demand
requests. <em>IJOC</em>, <em>34</em>(5), 2389–2399. (<a
href="https://doi.org/10.1287/ijoc.2022.1204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of allocating multiple heterogeneous resources geographically and over time to meet demands that require some subset of the available resource types simultaneously at a specified time, location, and duration. The objective is to maximize the total reward accrued from meeting (a subset of) demands. We model this problem as an integer program, show that it is NP-hard, and analyze the complexity of various special cases. We introduce approximation algorithms and an extension to our problem that considers travel costs. Finally, we test the performance of the integer programming model in an extensive computational study.},
  archive      = {J_IJOC},
  author       = {Arden Baxter and Pinar Keskinocak and Mohit Singh},
  doi          = {10.1287/ijoc.2022.1204},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2389-2399},
  shortjournal = {INFORMS J. Comput.},
  title        = {Heterogeneous multi-resource allocation with subset demand requests},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finite difference gradient approximation: To randomize or
not? <em>IJOC</em>, <em>34</em>(5), 2384–2388. (<a
href="https://doi.org/10.1287/ijoc.2022.1218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss two classes of methods of approximating gradients of noisy black box functions—the classical finite difference method and recently popular randomized finite difference methods. Despite of the popularity of the latter, we argue that it is unclear whether the randomized schemes have an advantage over the traditional methods when employed inside an optimization method. We point to theoretical and practical evidence that show that the opposite is true at least in a general optimization setting. We then pose the question of whether a particular setting exists when the advantage of the new method may be clearly shown, at least numerically. The larger underlying challenge is a development of black box optimization methods that scale well with the problem dimension.},
  archive      = {J_IJOC},
  author       = {Katya Scheinberg},
  doi          = {10.1287/ijoc.2022.1218},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2384-2388},
  shortjournal = {INFORMS J. Comput.},
  title        = {Finite difference gradient approximation: To randomize or not?},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Note from the editor. <em>IJOC</em>, <em>34</em>(5), 2383.
(<a href="https://doi.org/10.1287/ijoc.2022.1230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2022.1230},
  journal      = {INFORMS Journal on Computing},
  number       = {5},
  pages        = {2383},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Editorial board. <em>IJOC</em>, <em>34</em>(4), C2. (<a
href="https://doi.org/10.1287/ijoc.2022.eb.v3404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.eb.v3404},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reducing and calibrating for input model bias in computer
simulation. <em>IJOC</em>, <em>34</em>(4), 2368–2382. (<a
href="https://doi.org/10.1287/ijoc.2022.1183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input model bias is the bias found in the output performance measures of a simulation model caused by estimating the input distributions/processes used to drive it. When the simulation response is a nonlinear function of its inputs, as is usually the case when simulating complex systems, input modelling bias is amongst the errors that arise. In this paper, we introduce a method that recalibrates the input parameters of parametric input models to reduce the bias in the simulation output. The proposed method is based on sequential quadratic programming with a closed form analytical solution at each step. An algorithm with guidance on how to practically implement the method is presented. The method is shown to be successful in reducing input modelling bias and the total mean squared error caused by input modelling error.},
  archive      = {J_IJOC},
  author       = {Lucy E. Morgan and Luke Rhodes-Leader and Russell R. Barton},
  doi          = {10.1287/ijoc.2022.1183},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2368-2382},
  shortjournal = {INFORMS J. Comput.},
  title        = {Reducing and calibrating for input model bias in computer simulation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust simulation with likelihood-ratio constrained input
uncertainty. <em>IJOC</em>, <em>34</em>(4), 2350–2367. (<a
href="https://doi.org/10.1287/ijoc.2022.1169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To use simulation models to study the behaviors of stochastic systems, one needs to specify the distribution of the input random variables. However, specifying this distribution precisely is typically difficult and even impossible in practice. The issue is known as input uncertainty in the simulation literature, and it has been considered and studied extensively in recent years. In this paper, we model the uncertainty by an ambiguity set that is defined based on the likelihood ratio between the true (unknown) distribution and the nominal distribution (i.e., the best estimate), and develop a robust simulation (RS) approach that estimates the worst-case values of performance measures of the random simulation output when the true distribution varies in the ambiguity set. We show that the RS approach is computationally tractable, and the corresponding results reveal important information of the stochastic systems and help decision makers make better decisions.},
  archive      = {J_IJOC},
  author       = {Zhaolin Hu and L. Jeff Hong},
  doi          = {10.1287/ijoc.2022.1169},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2350-2367},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust simulation with likelihood-ratio constrained input uncertainty},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On generating lagrangian cuts for two-stage stochastic
integer programs. <em>IJOC</em>, <em>34</em>(4), 2332–2349. (<a
href="https://doi.org/10.1287/ijoc.2022.1185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate new methods for generating Lagrangian cuts to solve two-stage stochastic integer programs. Lagrangian cuts can be added to a Benders reformulation and are derived from solving single scenario integer programming subproblems identical to those used in the nonanticipative Lagrangian dual of a stochastic integer program. Although Lagrangian cuts have the potential to significantly strengthen the Benders relaxation, generating Lagrangian cuts can be computationally demanding. We investigate new techniques for generating Lagrangian cuts with the goal of obtaining methods that provide significant improvements to the Benders relaxation quickly. Computational results demonstrate that our proposed method improves the Benders relaxation significantly faster than previous methods for generating Lagrangian cuts and, when used within a branch-and-cut algorithm, significantly reduces the size of the search tree for three classes of test problems.},
  archive      = {J_IJOC},
  author       = {Rui Chen and James Luedtke},
  doi          = {10.1287/ijoc.2022.1185},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2332-2349},
  shortjournal = {INFORMS J. Comput.},
  title        = {On generating lagrangian cuts for two-stage stochastic integer programs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integral column generation for set partitioning problems
with side constraints. <em>IJOC</em>, <em>34</em>(4), 2313–2331. (<a
href="https://doi.org/10.1287/ijoc.2022.1174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integral column generation algorithm (ICG) was recently introduced to solve set partitioning problems involving a very large number of variables. This primal algorithm generates a sequence of integer solutions with decreasing costs, leading to an optimal or near-optimal solution. ICG combines the well-known column generation algorithm and a primal algorithm called the integral simplex using decomposition algorithm (ISUD). In this paper, we develop a generalized version of ICG, denoted I2CG, that can solve efficiently large-scale set partitioning problems with side constraints. This new algorithm can handle the side constraints in the reduced problem of ISUD, in its complementary problem, or in both components. Computational experiments on instances of the airline crew pairing problem (CPP) and the multidepot vehicle routing problem with time windows show that the latter strategy is the most efficient one and I2CG significantly outperforms basic variants of two popular column generation heuristics, namely, a restricted master heuristic and a diving heuristic. For the largest tested CPP instance with 1,761 constraints, I2CG can produce in less than one hour of computational time more than 500 integer solutions leading to an optimal or near-optimal solution.},
  archive      = {J_IJOC},
  author       = {Adil Tahir and Guy Desaulniers and Issmail El Hallaoui},
  doi          = {10.1287/ijoc.2022.1174},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2313-2331},
  shortjournal = {INFORMS J. Comput.},
  title        = {Integral column generation for set partitioning problems with side constraints},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A scalable lower bound for the worst-case relay attack
problem on the transmission grid. <em>IJOC</em>, <em>34</em>(4),
2296–2312. (<a href="https://doi.org/10.1287/ijoc.2022.1178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a bilevel attacker–defender problem to find the worst-case attack on the relays that control transmission grid components. The attacker infiltrates some number of relays and renders all of the components connected to them inoperable with the goal of maximizing load shed. The defender responds by minimizing the resulting load shed, redispatching using a DC optimal power flow (DCOPF) problem on the remaining network. Though worst-case interdiction problems on the transmission grid have been studied for years, there remains a need for exact and scalable methods. Methods based on using duality on the inner problem rely on the bounds of the dual variables of the defender problem in order to reformulate the bilevel problem as a mixed integer linear problem. Valid dual bounds tend to be large, resulting in weak linear programming relaxations and, hence, making the problem more difficult to solve at scale. Often smaller heuristic bounds are used, resulting in a lower bound. In this work, we also consider a lower bound, but instead of bounding the dual variables, we drop the constraints corresponding to Ohm’s law, relaxing DCOPF to capacitated network flow. We present theoretical results showing that, for uncongested networks, approximating DCOPF with network flow yields the same set of injections and, thus, the same load shed, which suggests that this restriction likely gives a high-quality lower bound in the uncongested case. Furthermore, we show that, in the network flow relaxation of the defender problem, the duals are bounded by one, so we can solve our restriction exactly. Finally, because the big-M values in the linearization are equal to one and network flow has a well-known structure, we see empirically that this formulation scales well computationally with increased network size. Through empirical experiments on 16 networks with up to 6,468 buses, we find that this bound is almost always as tight as we can get from guessing the dual bounds even for congested networks in which the theoretical results do not hold. In addition, calculating the bound is approximately 150 times faster than achieving the same bound with the reformulation guessing the dual bounds.},
  archive      = {J_IJOC},
  author       = {Emma S. Johnson and Santanu Subhas Dey},
  doi          = {10.1287/ijoc.2022.1178},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2296-2312},
  shortjournal = {INFORMS J. Comput.},
  title        = {A scalable lower bound for the worst-case relay attack problem on the transmission grid},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decision diagrams for discrete optimization: A survey of
recent advances. <em>IJOC</em>, <em>34</em>(4), 2271–2295. (<a
href="https://doi.org/10.1287/ijoc.2022.1170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, decision diagrams (DDs) have been the basis for a large array of novel approaches for modeling and solving optimization problems. Many techniques now use DDs as a key tool to achieve state-of-the-art performance within other optimization paradigms, such as integer programming and constraint programming. This paper provides a survey of the use of DDs in discrete optimization, particularly focusing on recent developments. We classify these works into two groups based on the type of diagram (i.e., exact or approximate) and present a thorough description of their use. We discuss the main advantages of DDs, point out major challenges, and provide directions for future work.},
  archive      = {J_IJOC},
  author       = {Margarita P. Castro and Andre A. Cire and J. Christopher Beck},
  doi          = {10.1287/ijoc.2022.1170},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2271-2295},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decision diagrams for discrete optimization: A survey of recent advances},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bin packing problem with time lags. <em>IJOC</em>,
<em>34</em>(4), 2249–2270. (<a
href="https://doi.org/10.1287/ijoc.2022.1165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and motivate several variants of the bin packing problem where bins are assigned to time slots, and minimum and maximum lags are required between some pairs of items. We suggest two integer programming formulations for the general problem: a compact one and a stronger formulation with an exponential number of variables and constraints. We propose a branch-cut-and-price approach that exploits the latter formulation. For this purpose, we devise separation algorithms based on a mathematical characterization of feasible assignments for two important special cases of the problem: when the number of possible bins available at each period is infinite and when this number is limited to one and time lags are nonnegative. Computational experiments are reported for instances inspired from a real-case application of chemical treatment planning in vineyards, as well as for literature instances for special cases of the problem. The experimental results show the efficiency of our branch-cut-and-price approach, as it outperforms the compact formulation on newly proposed instances and is able to obtain improved lower and upper bounds for literature instances.},
  archive      = {J_IJOC},
  author       = {Orlando Rivera Letelier and François Clautiaux and Ruslan Sadykov},
  doi          = {10.1287/ijoc.2022.1165},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2249-2270},
  shortjournal = {INFORMS J. Comput.},
  title        = {Bin packing problem with time lags},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online mixed-integer optimization in milliseconds.
<em>IJOC</em>, <em>34</em>(4), 2229–2248. (<a
href="https://doi.org/10.1287/ijoc.2022.1181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a method to approximate the solution of online mixed-integer optimization (MIO) problems at very high speed using machine learning. By exploiting the repetitive nature of online optimization, we can greatly speed up the solution time. Our approach encodes the optimal solution into a small amount of information denoted as strategy using the voice of optimization framework. In this way, the core part of the optimization routine becomes a multiclass classification problem that can be solved very quickly. In this work, we extend that framework to real-time and high-speed applications focusing on parametric mixed-integer quadratic optimization. We propose an extremely fast online optimization method consisting of a feedforward neural network evaluation and a linear system solution where the matrix has already been factorized. Therefore, this online approach does not require any solver or iterative algorithm. We show the speed of the proposed method both in terms of total computations required and measured execution time. We estimate the number of floating point operations required to completely recover the optimal solution as a function of the problem dimensions. Compared with state-of-the-art MIO routines, the online running time of our method is very predictable and can be lower than a single matrix factorization time. We benchmark our method against the state-of-the-art solver Gurobi obtaining up to two to three orders of magnitude speedups on examples from fuel cell energy management, sparse portfolio optimization, and motion planning with obstacle avoidance.},
  archive      = {J_IJOC},
  author       = {Dimitris Bertsimas and Bartolomeo Stellato},
  doi          = {10.1287/ijoc.2022.1181},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2229-2248},
  shortjournal = {INFORMS J. Comput.},
  title        = {Online mixed-integer optimization in milliseconds},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Min-sup-min robust combinatorial optimization with few
recourse solutions. <em>IJOC</em>, <em>34</em>(4), 2212–2228. (<a
href="https://doi.org/10.1287/ijoc.2021.1156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a variant of adaptive robust combinatorial optimization problems where the decision maker can prepare K solutions and choose the best among them upon knowledge of the true data realizations. We suppose that the uncertainty may affect the objective and the constraints through functions that are not necessarily linear. We propose a new exact algorithm for solving these problems when the feasible set of the nominal optimization problem does not contain too many good solutions. Our algorithm enumerates these good solutions, generates dynamically a set of scenarios from the uncertainty set, and assigns the solutions to the generated scenarios using a vertex p-center formulation, solved by a binary search algorithm. Our numerical results on adaptive shortest path and knapsack with conflicts problems show that our algorithm compares favorably with the methods proposed in the literature. We additionally propose a heuristic extension of our method to handle problems where it is prohibitive to enumerate all good solutions. This heuristic is shown to provide good solutions within a reasonable solution time limit on the adaptive knapsack with conflicts problem. Finally, we illustrate how our approach handles nonlinear functions on an all-or-nothing subset problem taken from the literature.},
  archive      = {J_IJOC},
  author       = {Ayşe N. Arslan and Michael Poss and Marco Silva},
  doi          = {10.1287/ijoc.2021.1156},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2212-2228},
  shortjournal = {INFORMS J. Comput.},
  title        = {Min-sup-min robust combinatorial optimization with few recourse solutions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Branch-and-price approaches for real-time vehicle routing
with picking, loading, and soft time windows. <em>IJOC</em>,
<em>34</em>(4), 2192–2211. (<a
href="https://doi.org/10.1287/ijoc.2021.1151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and evaluate branch-and-price approaches for vehicle routing problems with picking, loading, and soft time windows. This general type of vehicle routing problem is of particular relevance in the same-day delivery context, in which fast routing algorithms are required because of the commitment to real-time delivery in the presence of high customer order frequencies. To boost the performance of the branch-and-price algorithms, we introduce the new method of tree-compatible labeling with nondominance trees. This method represents cost functions by a fixed number of breakpoints and uses a specialized tree-based data structure to store Pareto-optimal labels. We prove the theoretical soundness of the new method and evaluate its performance numerically with respect to pricing, column generation, and branch-and-price. Our numerical results show that the method yields substantial performance gains. In particular, we show that, with the new method, branch-and-price is able to reliably generate within a few minutes close to optimal solutions for problem instances with 50 customers. By additional experiments with classic vehicle routing problems with hard time windows, we show that the performance gains of our method result from its ability to handle cost functions in the pricing step. Our approach is the first branch-and-price approach for vehicle routing with picking, loading, and soft time windows. As such, it represents an exact routing algorithm that is able to reliably satisfy the runtime requirements of real-time delivery services.},
  archive      = {J_IJOC},
  author       = {Martin Wölck and Stephan Meisel},
  doi          = {10.1287/ijoc.2021.1151},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2192-2211},
  shortjournal = {INFORMS J. Comput.},
  title        = {Branch-and-price approaches for real-time vehicle routing with picking, loading, and soft time windows},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Logic-based benders decomposition for integrated process
configuration and production planning problems. <em>IJOC</em>,
<em>34</em>(4), 2177–2191. (<a
href="https://doi.org/10.1287/ijoc.2021.1079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general logic-based Benders decomposition (LBBD) for production planning problems with process configuration decisions. This family of problems appears in contexts where the machines are set up according to specific patterns, templates, or, in general, process configurations that allow for simultaneously producing products of different types. The problem requires determining feasible configurations for the machines and their corresponding production levels to fulfill the demand at the minimum total cost. The structure of this problem contains nonlinear constraints that link the number of units produced of each product with the used configurations and their production levels. We decompose the original problem into a master problem, where the configurations are determined, and a subproblem, where the production amounts are determined. This allows us to apply the LBBD technique to solve the problem using a standard LBBD implementation and a branch-and-check algorithm. LBBD enhancements through logic-based inequalities generated for subsets of products with common characteristics are proposed. Such inequalities represent a form of the subproblem relaxation added to the master problem during its resolution. In our computational experiments, we apply the proposed LBBD approaches to two different applications from the literature: cutting stock problems in the steel industry and a printing problem. Results show that the LBBD methods find optimal solutions much faster than the solution approaches in the literature and have a superior performance with respect to the number of instances solved to optimality and the solution quality.},
  archive      = {J_IJOC},
  author       = {Karim Pérez Martínez and Yossiri Adulyasak and Raf Jans},
  doi          = {10.1287/ijoc.2021.1079},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2177-2191},
  shortjournal = {INFORMS J. Comput.},
  title        = {Logic-based benders decomposition for integrated process configuration and production planning problems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing optimized path integrals for knapsack feasibility.
<em>IJOC</em>, <em>34</em>(4), 2163–2176. (<a
href="https://doi.org/10.1287/ijoc.2021.1142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A generating function technique for solving integer programs via the evaluation of complex path integrals is discussed from a theoretical and computational perspective. Applying the method to knapsack feasibility problems, it is demonstrated how the presented numerical integration algorithm benefits from a preoptimized path of integration. After discussing the algorithmic setup in detail, a numerical study is implemented to evaluate the computational performance of the preoptimized integration method, and the algorithmic parameters are tuned to a set of knapsack instances. The goal is to highlight the method’s computational advantage for hard knapsack instances.},
  archive      = {J_IJOC},
  author       = {Endric Daues and Ulf Friedrich},
  doi          = {10.1287/ijoc.2021.1142},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2163-2176},
  shortjournal = {INFORMS J. Comput.},
  title        = {Computing optimized path integrals for knapsack feasibility},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SOS-SDP: An exact solver for minimum sum-of-squares
clustering. <em>IJOC</em>, <em>34</em>(4), 2144–2162. (<a
href="https://doi.org/10.1287/ijoc.2022.1166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum sum-of-squares clustering problem (MSSC) consists of partitioning n observations into k clusters in order to minimize the sum of squared distances from the points to the centroid of their cluster. In this paper, we propose an exact algorithm for the MSSC problem based on the branch-and-bound technique. The lower bound is computed by using a cutting-plane procedure in which valid inequalities are iteratively added to the Peng–Wei semidefinite programming (SDP) relaxation. The upper bound is computed with the constrained version of k-means in which the initial centroids are extracted from the solution of the SDP relaxation. In the branch-and-bound procedure, we incorporate instance-level must-link and cannot-link constraints to express knowledge about which data points should or should not be grouped together. We manage to reduce the size of the problem at each level, preserving the structure of the SDP problem itself. To the best of our knowledge, the obtained results show that the approach allows us to successfully solve, for the first time, real-world instances up to 4,000 data points.},
  archive      = {J_IJOC},
  author       = {Veronica Piccialli and Antonio M. Sudoso and Angelika Wiegele},
  doi          = {10.1287/ijoc.2022.1166},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2144-2162},
  shortjournal = {INFORMS J. Comput.},
  title        = {SOS-SDP: An exact solver for minimum sum-of-squares clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A restricted dual peaceman-rachford splitting method for a
strengthened DNN relaxation for QAP. <em>IJOC</em>, <em>34</em>(4),
2125–2143. (<a href="https://doi.org/10.1287/ijoc.2022.1161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Splitting methods in optimization arise when one can divide an optimization problem into two or more simpler subproblems. They have proven particularly successful for relaxations of problems involving discrete variables. We revisit and strengthen splitting methods for solving doubly nonnegative relaxations of the particularly difficult, NP-hard quadratic assignment problem. We use a modified restricted contractive splitting method approach. In particular, we show how to exploit redundant constraints in the subproblems. Our strengthened bounds exploit these new subproblems and new dual multiplier estimates to improve on the bounds and convergence results in the literature.},
  archive      = {J_IJOC},
  author       = {Naomi Graham and Hao Hu and Jiyoung Im and Xinxin Li and Henry Wolkowicz},
  doi          = {10.1287/ijoc.2022.1161},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2125-2143},
  shortjournal = {INFORMS J. Comput.},
  title        = {A restricted dual peaceman-rachford splitting method for a strengthened DNN relaxation for QAP},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive bundle methods for nonlinear robust optimization.
<em>IJOC</em>, <em>34</em>(4), 2106–2124. (<a
href="https://doi.org/10.1287/ijoc.2021.1122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, there are few theoretical or practical approaches available for general nonlinear robust optimization. Moreover, the approaches that do exist impose restrictive assumptions on the problem structure. We present an adaptive bundle method for nonlinear and nonconvex robust optimization problems with a suitable notion of inexactness in function values and subgradients. As the worst-case evaluation requires a global solution to the adversarial problem, it is a main challenge in a general nonconvex nonlinear setting. Moreover, computing elements of an ε-perturbation of the Clarke subdifferential in the ℓ2-norm sense is in general prohibitive for this class of problems. In this article, instead of developing an entirely new bundle concept, we demonstrate how existing approaches, such as Noll’s bundle method for nonconvex minimization with inexact information [Noll D (2013) Bundle method for non-convex minimization with inexact subgradients and function values. Computational and Analytical Mathematics, Springer Proceedings Mathematics, vol. 50 (Springer, New York), 555–592.] can be modified to be able to cope with this situation. Extending the nonconvex bundle concept to the case of robust optimization in this way, we prove convergence under two assumptions: first, that the objective function is lower C1 and, second, that approximately optimal solutions to the adversarial maximization problem are available. The proposed method is, hence, applicable to a rather general setting of nonlinear robust optimization problems. In particular, we do not rely on a specific structure of the adversary’s constraints. The considered class of robust optimization problems covers the case that the worst-case adversary only needs to be evaluated up to a certain precision. One possibility to evaluate the worst case with the desired degree of precision is the use of techniques from mixed-integer linear programming. We investigate the procedure on some analytic examples. As applications, we study the gas transport problem under uncertainties in demand and in physical parameters that affect pressure losses in the pipes. Computational results for examples in large realistic gas network instances demonstrate the applicability as well as the efficiency of the method.},
  archive      = {J_IJOC},
  author       = {Martina Kuchlbauer and Frauke Liers and Michael Stingl},
  doi          = {10.1287/ijoc.2021.1122},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2106-2124},
  shortjournal = {INFORMS J. Comput.},
  title        = {Adaptive bundle methods for nonlinear robust optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convex maximization via adjustable robust optimization.
<em>IJOC</em>, <em>34</em>(4), 2091–2105. (<a
href="https://doi.org/10.1287/ijoc.2021.1134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing a convex function over convex constraints is an NP-hard problem in general. We prove that such a problem can be reformulated as an adjustable robust optimization (ARO) problem in which each adjustable variable corresponds to a unique constraint of the original problem. We use ARO techniques to obtain approximate solutions to the convex maximization problem. In order to demonstrate the complete approximation scheme, we distinguish the cases in which we have just one nonlinear constraint and multiple linear constraints. Concerning the first case, we give three examples in which one can analytically eliminate the adjustable variable and approximately solve the resulting static robust optimization problem efficiently. More specifically, we show that the norm constrained log-sum-exp (geometric) maximization problem can be approximated by (convex) exponential cone optimization techniques. Concerning the second case of multiple linear constraints, the equivalent ARO problem can be represented as an adjustable robust linear optimization problem. Using linear decision rules then returns a safe approximation of the constraints. The resulting problem is a convex optimization problem, and solving this problem gives an upper bound on the global optimum value of the original problem. By using the optimal linear decision rule, we obtain a lower bound solution as well. We derive the approximation problems explicitly for quadratic maximization, geometric maximization, and sum-of-max-linear-terms maximization problems with multiple linear constraints. Numerical experiments show that, contrary to the state-of-the-art solvers, we can approximate large-scale problems swiftly with tight bounds. In several cases, we have equal upper and lower bounds, which concludes that we have global optimality guarantees in these cases.},
  archive      = {J_IJOC},
  author       = {Aras Selvi and Aharon Ben-Tal and Ruud Brekelmans and Dick den Hertog},
  doi          = {10.1287/ijoc.2021.1134},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2091-2105},
  shortjournal = {INFORMS J. Comput.},
  title        = {Convex maximization via adjustable robust optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable bound tightening and valid constraints for
multiperiod blending. <em>IJOC</em>, <em>34</em>(4), 2073–2090. (<a
href="https://doi.org/10.1287/ijoc.2021.1140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiperiod blending has a number of important applications in a range of industrial sectors. It is typically formulated as a nonconvex mixed integer nonlinear program (MINLP), which involves binary variables and bilinear terms. In this study, we first propose a reformulation of the constraints involving bilinear terms using lifting. We introduce a method for calculating tight bounds on the lifted variables calculated by aggregating multiple constraints. We propose valid constraints derived from the reformulation-linearization technique (RLT) that use the bounds on the lifted variables to further tighten the formulation. Computational results indicate our method can substantially reduce the solution time and optimality gap.},
  archive      = {J_IJOC},
  author       = {Yifu Chen and Christos T. Maravelias},
  doi          = {10.1287/ijoc.2021.1140},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2073-2090},
  shortjournal = {INFORMS J. Comput.},
  title        = {Variable bound tightening and valid constraints for multiperiod blending},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Target-oriented distributionally robust optimization and its
applications to surgery allocation. <em>IJOC</em>, <em>34</em>(4),
2058–2072. (<a href="https://doi.org/10.1287/ijoc.2021.1145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a decision criterion that characterizes an enveloping bound on monetary risk measures and is computationally friendly. We start by extending the classical value at risk (VaR) measure. Whereas VaR evaluates the threshold loss value such that the loss from the risk position exceeding that threshold is at a given probability level, it fails to indicate a performance guarantee at other probability levels. We define the probabilistic enveloping measure (PEM) to establish the bound information for the tail probability of the loss at all levels. Using a set of normative properties, we then generalize the PEM to the risk enveloping measure (REM) such that the bound on the general monetary risk measures at all levels of risk aversion are captured. The coherent version of the REM (CREM) is also investigated. We demonstrate its applicability by showing how the coherent REM can be incorporated in distributionally robust optimization. Specifically, we apply the CREM criterion in surgery block allocation problems and provide a formulation that can be efficiently solved. Based on this application, we report favorable computational results from optimizing over the CREM criterion.},
  archive      = {J_IJOC},
  author       = {Vincent Tsz Fai Chow and Zheng Cui and Daniel Zhuoyu Long},
  doi          = {10.1287/ijoc.2021.1145},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2058-2072},
  shortjournal = {INFORMS J. Comput.},
  title        = {Target-oriented distributionally robust optimization and its applications to surgery allocation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A machine learning–enabled partially observable markov
decision process framework for early sepsis prediction. <em>IJOC</em>,
<em>34</em>(4), 2039–2057. (<a
href="https://doi.org/10.1287/ijoc.2022.1176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a life-threatening condition, caused by the body’s extreme response to an infection. In the United States, 1.7 million cases of sepsis occur annually, resulting in 265,000 deaths. Delayed diagnosis and treatment are associated with higher mortality rates. An exponential rise in the availability of medical data has allowed for the development of sophisticated machine learning algorithms to predict sepsis earlier than the onset. However, these models often underperform, as the training data are retrospective and do not fully capture the uncertain future. In this study, we develop a novel framework, which we refer to as MLePOMDP, to leverage and combine the underlying, high-level knowledge about sepsis progression and machine learning (ML) for classification. Specifically, we use a hidden Markov model to describe sepsis development at a high level, where the ML model makes the higher-order “observations” from temporal data. Consequently, a partially observable Markov decision process (POMDP) model is developed to make classification decisions. We analytically establish that the optimal policy is of threshold-type, which we exploit to efficiently optimize MLePOMDP. MLePOMDP is calibrated and tested using high-frequency physiological data collected from bedside monitors. Different from past POMDP-based frameworks, MLePOMDP is developed for a prediction task using a very small state definition, produces highly interpretable results, and accounts for a novel and clinically meaningful action space. Our results show that MLePOMDP outperforms machine learning–based benchmarks by up to 8\% in precision. Importantly, MLePOMDP is able to reduce false alarms by up to 28\%. An additional experiment is conducted to show the generalizability of MLePOMDP to different patient cohorts.},
  archive      = {J_IJOC},
  author       = {Zeyu Liu and Anahita Khojandi and Xueping Li and Akram Mohammed and Robert L Davis and Rishikesan Kamaleswaran},
  doi          = {10.1287/ijoc.2022.1176},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2039-2057},
  shortjournal = {INFORMS J. Comput.},
  title        = {A machine Learning–Enabled partially observable markov decision process framework for early sepsis prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust direct aperture optimization for radiation therapy
treatment planning. <em>IJOC</em>, <em>34</em>(4), 2017–2038. (<a
href="https://doi.org/10.1287/ijoc.2022.1167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intensity-modulated radiation therapy (IMRT) allows for the design of customized, highly conformal treatments for cancer patients. Creating IMRT treatment plans, however, is a mathematically complex process, which is often tackled in multiple, simpler stages. This sequential approach typically separates radiation dose requirements from mechanical deliverability considerations, which may result in suboptimal treatment quality. For patient health to be considered paramount, holistic models must address these plan elements concurrently, eliminating quality loss between stages. This combined direct aperture optimization (DAO) approach is rarely paired with uncertainty mitigation techniques, such as robust optimization, because of the inherent complexity of both parts. This paper outlines a robust DAO (RDAO) model and discusses novel methodologies for efficiently integrating salient constraints. Because the highly complex RDAO model is difficult to solve, an original candidate plan generation (CPG) heuristic is proposed. The CPG produces rapid, high-quality, feasible plans, which are immediately clinically viable and can also be used to generate a feasible incumbent solution for warm-starting the RDAO model. Computational results obtained using clinical patient data sets with motion uncertainty show the benefit of incorporating the CPG, in terms of both the first incumbent solution and final output plan quality.},
  archive      = {J_IJOC},
  author       = {Danielle A. Ripsman and Thomas G. Purdie and Timothy C. Y. Chan and Houra Mahmoudzadeh},
  doi          = {10.1287/ijoc.2022.1167},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2017-2038},
  shortjournal = {INFORMS J. Comput.},
  title        = {Robust direct aperture optimization for radiation therapy treatment planning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The capacitated and economic districting problem.
<em>IJOC</em>, <em>34</em>(4), 2003–2016. (<a
href="https://doi.org/10.1287/ijoc.2022.1180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the capacitated and economic districting problem (CEDP), which searches for the best edge partition defining connected, capacitated, and balanced districts in an undirected connected graph, weighing the economic value of each district. This problem provides a comprehensive description of the decision making on service networks districting, where the order by which the districts are serviced plays a role in the profit. This is observed in the arrangement of districts for meter reading, as the day in which each district is read impacts the revenue. Two integer linear programming formulations are proposed for CEDP, accompanied by a proof of NP-hardness. To tackle large instances, a greedy randomized adaptive search procedure (GRASP) metaheuristic, embedded with reactive parameter tuning, statistical filtering of solutions subjected to intensification, and a set of solution repairing procedures, is proposed. The GRASP is hybridized to each model to evaluate the outcomes of combining their individual merits. Computational experiments were performed on a new benchmark composed of 144 instances of different sizes, edge densities, network topologies, balance tolerances, and district capacities. The results show the effectiveness of the exact methodologies in solving the models and providing optimal solutions for the set of small instances. The GRASP was capable of tackling large networks, achieving feasible solutions to almost all instances. The results also show that the hybridized methodologies outperformed their standalone counterparts with respect to the attained primal and dual bounds.},
  archive      = {J_IJOC},
  author       = {Luis Henrique Pauleti Mendes and Fábio Luiz Usberti and Celso Cavellucci},
  doi          = {10.1287/ijoc.2022.1180},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {2003-2016},
  shortjournal = {INFORMS J. Comput.},
  title        = {The capacitated and economic districting problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exact algorithms for maximum lifetime data-gathering tree in
wireless sensor networks. <em>IJOC</em>, <em>34</em>(4), 1987–2002. (<a
href="https://doi.org/10.1287/ijoc.2022.1175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle an optimization problem arising in the design of sensor networks: given a set of sensors, only one being connected to a backbone, to establish connection routes from each of them to the sink. Under a shortest path routing protocol, the set of connections form a spanning tree. Energy is required to transmit and receive data, and sensors have limited battery capacity: as soon as one sensor runs out of battery, a portion of the network is disconnected. We, therefore, search for the spanning tree maximizing the time elapsed before such a disconnection occurs, and therefore, maintenance is required. We propose new mathematical formulations for the problem, proving and exploiting theoretical results on its combinatorial structure. On that basis, we design algorithms offering a priori guarantees of global optimality. We undertake an extensive experimental campaign, showing our algorithms to outperform previous ones from the literature by orders of magnitude. We also identify which instance features have higher impact on network lifetime.},
  archive      = {J_IJOC},
  author       = {Marco Casazza and Alberto Ceselli},
  doi          = {10.1287/ijoc.2022.1175},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1987-2002},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact algorithms for maximum lifetime data-gathering tree in wireless sensor networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exact solution algorithms for the chordless cycle problem.
<em>IJOC</em>, <em>34</em>(4), 1970–1986. (<a
href="https://doi.org/10.1287/ijoc.2022.1164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A formulation, a heuristic, and branch-and-cut algorithms are investigated for the chordless cycle problem. This is the problem of finding a largest simple cycle for a given graph so that no edge between nonimmediately subsequent cycle vertices is contained in the graph. Leaving aside procedures based on complete enumeration, no previous exact solution algorithm appears to exist for the problem, which is relevant both in theoretical and practical terms. Extensive computational results are reported here for randomly generated graphs and for graphs originating from the literature. Under acceptable CPU times, certified optimal solutions are presented for graphs with as many as 100 vertices.},
  archive      = {J_IJOC},
  author       = {Dilson Lucas Pereira and Abilio Lucena and Alexandre Salles da Cunha and Luidi Simonetti},
  doi          = {10.1287/ijoc.2022.1164},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1970-1986},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact solution algorithms for the chordless cycle problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distinguishing homophily from peer influence through network
representation learning. <em>IJOC</em>, <em>34</em>(4), 1958–1969. (<a
href="https://doi.org/10.1287/ijoc.2022.1171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peer influence and homophily are two entangled forces underlying social influences. However, distinguishing homophily from peer influence is difficult, particularly when there is latent homophily caused by unobservable features. This paper proposes a novel data-driven framework that combines the advantages of latent homophily identification and causal inference. Specifically, the approach first utilizes scalable network representation learning algorithms to obtain node embeddings, which are extracted from social network structures. Then, the embeddings are used to control latent homophily in a quasi-experimental design for causal inference. The simulation experiments show that the proposed approach can estimate peer influence more accurately than existing parameterized approaches and data-driven methods. We applied the proposed framework in an empirical study of players’ online gaming behaviors. First, our approach can achieve improved model fitness for estimating peer influence in online games. Second, we discover a heterogeneous effect of peer influence: players with higher tenure and playing levels receive stronger peer influence. Finally, our results suggest that the homophily effect has a stronger influence on players’ behavior than peer influence.},
  archive      = {J_IJOC},
  author       = {Xi Chen and Yan Liu and Cheng Zhang},
  doi          = {10.1287/ijoc.2022.1171},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1958-1969},
  shortjournal = {INFORMS J. Comput.},
  title        = {Distinguishing homophily from peer influence through network representation learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inductive representation learning on dynamic stock
co-movement graphs for stock predictions. <em>IJOC</em>, <em>34</em>(4),
1940–1957. (<a href="https://doi.org/10.1287/ijoc.2022.1172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-movement among individual firms’ stock prices can reflect complex interfirm relationships. This paper proposes a novel method to leverage such relationships for stock price predictions by adopting inductive graph representation learning on dynamic stock graphs constructed based on historical stock price co-movement. To learn node representations from such dynamic graphs for better stock predictions, we propose the hybrid-attention dynamic graph neural network, an inductive graph representation learning method. We also extended mini-batch gradient descent to inductive representation learning on dynamic stock graphs so that the model can update parameters over mini-batch stock graphs with higher training efficiency. Extensive experiments on stocks from different markets and trading simulations demonstrate that the proposed method significantly improves stock predictions. The proposed method can have important implications for the management of financial portfolios and investment risk.},
  archive      = {J_IJOC},
  author       = {Hu Tian and Xiaolong Zheng and Kang Zhao and Maggie Wenjing Liu and Daniel Dajun Zeng},
  doi          = {10.1287/ijoc.2022.1172},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1940-1957},
  shortjournal = {INFORMS J. Comput.},
  title        = {Inductive representation learning on dynamic stock co-movement graphs for stock predictions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nested cross decomposition algorithm for power system
capacity expansion with multiscale uncertainties. <em>IJOC</em>,
<em>34</em>(4), 1919–1939. (<a
href="https://doi.org/10.1287/ijoc.2022.1177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern electric power systems have witnessed rapidly increasing penetration of renewable energy, storage, electrical vehicles, and various demand response resources. The electric infrastructure planning is thus facing more challenges as a result of the variability and uncertainties arising from the diverse new resources. This study aims to develop a multistage and multiscale stochastic mixed integer programming (MM-SMIP) model to capture both the coarse-temporal-scale uncertainties, such as investment cost and long-run demand stochasticity, and fine-temporal-scale uncertainties, such as hourly renewable energy output and electricity demand uncertainties, for the power system capacity expansion problem. To be applied to a real power system, the resulting model will lead to extremely large-scale mixed integer programming problems, which suffer not only the well-known curse of dimensionality but also computational difficulties with a vast number of integer variables at each stage. In addressing such challenges associated with the MM-SMIP model, we propose a nested cross decomposition algorithm that consists of two layers of decomposition—that is, the Dantzig–Wolfe decomposition and L-shaped decomposition. The algorithm exhibits promising computational performance under our numerical study and is especially amenable to parallel computing, which will also be demonstrated through the computational results.},
  archive      = {J_IJOC},
  author       = {Zhouchun Huang and Qipeng P. Zheng and Andrew L. Liu},
  doi          = {10.1287/ijoc.2022.1177},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1919-1939},
  shortjournal = {INFORMS J. Comput.},
  title        = {A nested cross decomposition algorithm for power system capacity expansion with multiscale uncertainties},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new scenario reduction method based on higher-order
moments. <em>IJOC</em>, <em>34</em>(4), 1903–1918. (<a
href="https://doi.org/10.1287/ijoc.2021.1155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scenario reduction is an effective method to ease the computational burden of stochastic programming problems, which aims at choosing a subset of scenarios that can better represent a large number of possible scenarios. Higher-order moments are critical in the scenario reduction process, especially for stochastic programming problems that are greatly affected by the moments. From this idea, we construct a mixed integer linear programming model to improve the reduction accuracy of traditional methods by minimizing the moments’ information loss between the original and reduced scenarios. An improved Benders decomposition algorithm is then designed to find an optimal solution for the model. Finally, the resulting scenarios are examined on an international portfolio selection problem. Empirical and comparative studies are also carried out to reveal the superiority of our proposed scenario reduction method over other existing approaches or models, together with the superior performance of the algorithm.},
  archive      = {J_IJOC},
  author       = {Weiguo Zhang and Xiaolei He},
  doi          = {10.1287/ijoc.2021.1155},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1903-1918},
  shortjournal = {INFORMS J. Comput.},
  title        = {A new scenario reduction method based on higher-order moments},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient stochastic programming in julia. <em>IJOC</em>,
<em>34</em>(4), 1885–1902. (<a
href="https://doi.org/10.1287/ijoc.2022.1158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present StochasticPrograms.jl, a user-friendly and powerful open-source framework for stochastic programming written in the Julia language. The framework includes both modeling tools and structure-exploiting optimization algorithms. Stochastic programming models can be efficiently formulated using an expressive syntax, and models can be instantiated, inspected, and analyzed interactively. The framework scales seamlessly to distributed environments. Small instances of a model can be run locally to ensure correctness, whereas larger instances are automatically distributed in a memory-efficient way onto supercomputers or clouds and solved using parallel optimization algorithms. These structure-exploiting solvers are based on variations of the classical L-shaped, progressive-hedging, and quasi-gradient algorithms. We provide a concise mathematical background for the various tools and constructs available in the framework along with code listings exemplifying their usage. Both software innovations related to the implementation of the framework and algorithmic innovations related to the structured solvers are highlighted. We conclude by demonstrating strong scaling properties of the distributed algorithms on numerical benchmarks in a multinode setup.},
  archive      = {J_IJOC},
  author       = {Martin Biel and Mikael Johansson},
  doi          = {10.1287/ijoc.2022.1158},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1885-1902},
  shortjournal = {INFORMS J. Comput.},
  title        = {Efficient stochastic programming in julia},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic relaxations for online bipartite matching.
<em>IJOC</em>, <em>34</em>(4), 1871–1884. (<a
href="https://doi.org/10.1287/ijoc.2022.1168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online bipartite matching (OBM) is a fundamental model underpinning many important applications, including search engine advertisement, website banner and pop-up ads, and ride hailing. We study the independent and identically distributed (i.i.d.) OBM problem, in which one side of the bipartition is fixed and known in advance, whereas nodes from the other side appear sequentially as i.i.d. realizations of an underlying distribution and must immediately be matched or discarded. We introduce dynamic relaxations of the set of achievable matching probabilities; show how they theoretically dominate lower dimensional, static relaxations from previous work; and perform a polyhedral study to theoretically examine the new relaxations’ strength. We also discuss how to derive heuristic policies from the relaxations’ dual prices in a similar fashion to dynamic resource prices used in network revenue management. We finally present a computational study to demonstrate the empirical quality of the new relaxations and policies.},
  archive      = {J_IJOC},
  author       = {Alfredo Torrico and Alejandro Toriello},
  doi          = {10.1287/ijoc.2022.1168},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1871-1884},
  shortjournal = {INFORMS J. Comput.},
  title        = {Dynamic relaxations for online bipartite matching},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An image-based approach to detecting structural similarity
among mixed integer programs. <em>IJOC</em>, <em>34</em>(4), 1849–1870.
(<a href="https://doi.org/10.1287/ijoc.2021.1117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operations researchers have long drawn insight from the structure of constraint coefficient matrices (CCMs) for mixed integer programs (MIPs). We propose a new question: Can pictorial representations of CCM structure be used to identify similar MIP models and instances? In this paper, CCM structure is visualized using digital images, and computer vision techniques are used to detect latent structural features therein. The resulting feature vectors are used to measure similarity between images and, consequently, MIPs. An introductory analysis examines a subset of the instances from strIPlib and MIPLIB 2017, two online repositories for MIP instances. Results indicate that structure-based comparisons may allow for relationships to be identified between MIPs from disparate application areas. Additionally, image-based comparisons reveal that ostensibly similar variations of an MIP model may yield instances with markedly different mathematical structures.},
  archive      = {J_IJOC},
  author       = {Zachary Steever and Chase Murray and Junsong Yuan and Mark Karwan and Marco Lübbecke},
  doi          = {10.1287/ijoc.2021.1117},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1849-1870},
  shortjournal = {INFORMS J. Comput.},
  title        = {An image-based approach to detecting structural similarity among mixed integer programs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VeRoViz: A vehicle routing visualization toolkit.
<em>IJOC</em>, <em>34</em>(4), 1842–1848. (<a
href="https://doi.org/10.1287/ijoc.2022.1159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {VeRoViz is an open-source vehicle routing visualization package consisting of both Python and web-based components. It was developed to streamline the workflow for vehicle routing researchers by simplifying and automating many of the tedious tasks associated with generating realistic test problems. VeRoViz also provides new functionality to produce customizable visualizations of complex vehicle routing problems. These visualization tools—including Gantt charts, static maps, and dynamic 3-D videos—assist researchers in validating models and communicating results. Additionally, a comprehensive collection of utility functions within VeRoViz provides researchers with useful tools to assess features of their problems. This paper provides an overview of VeRoViz and highlights the flexibility and ease-of-use of the toolkit.},
  archive      = {J_IJOC},
  author       = {Lan Peng and Chase Murray},
  doi          = {10.1287/ijoc.2022.1159},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1842-1848},
  shortjournal = {INFORMS J. Comput.},
  title        = {VeRoViz: A vehicle routing visualization toolkit},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Note from the editor. <em>IJOC</em>, <em>34</em>(4), 1841.
(<a href="https://doi.org/10.1287/ijoc.2022.1213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2022.1213},
  journal      = {INFORMS Journal on Computing},
  number       = {4},
  pages        = {1841},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Editorial board. <em>IJOC</em>, <em>34</em>(3), C2. (<a
href="https://doi.org/10.1287/ijoc.2022.eb.v3403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.eb.v3403},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated stochastic optimal self-scheduling for
two-settlement electricity markets. <em>IJOC</em>, <em>34</em>(3),
1819–1840. (<a href="https://doi.org/10.1287/ijoc.2021.1150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of current electricity wholesale markets and the increased volatility of electricity prices because of the intermittent nature of renewable generation make independent power producers (IPPs) face significant challenges to submit offers. This challenge increases for those owning traditional coal-fired thermal generators and renewable generation. In this paper, an integrated stochastic optimal strategy is proposed for an IPP using the self-scheduling approach through its participation in both day-ahead and real-time markets (i.e., two-settlement electricity markets) as a price taker. In the proposed approach, the IPP submits an offer for all periods to the day-ahead market for which a multistage stochastic programming setting is explored for providing real-time market offers for each period as a recourse. This strategy has the advantage of achieving overall maximum profits for both markets in the given operational time horizon. Such a strategy is theoretically proved to be more profitable than alternative self-scheduling strategies as it takes advantage of the continuously realized scenario information of the renewable energy output and real-time prices over time. To improve computational efficiency, we explore polyhedral structures to derive strong valid inequalities, including convex hull descriptions for certain special cases, thus strengthening the formulation of our proposed model. Polynomial-time separation algorithms are then established for the derived exponential-sized inequalities to speed up the branch-and-cut process. Finally, both numerical and real case studies demonstrate the potential of the proposed strategy.},
  archive      = {J_IJOC},
  author       = {Kai Pan and Yongpei Guan},
  doi          = {10.1287/ijoc.2021.1150},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1819-1840},
  shortjournal = {INFORMS J. Comput.},
  title        = {Integrated stochastic optimal self-scheduling for two-settlement electricity markets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk-averse stochastic programming vs. Adaptive robust
optimization: A virtual power plant application. <em>IJOC</em>,
<em>34</em>(3), 1795–1818. (<a
href="https://doi.org/10.1287/ijoc.2022.1157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper compares risk-averse optimization methods to address the self-scheduling and market involvement of a virtual power plant (VPP). The decision-making problem of the VPP involves uncertainty in the wind speed and electricity price forecast. We focus on two methods: risk-averse two-stage stochastic programming (SP) and two-stage adaptive robust optimization (ARO). We investigate both methods concerning formulations, uncertainty and risk, decomposition algorithms, and their computational performance. To quantify the risk in SP, we use the conditional value at risk (CVaR) because it can resemble a worst-case measure, which naturally links to ARO. We use two efficient implementations of the decomposition algorithms for SP and ARO; we assess (1) the operational results regarding first-stage decision variables, estimate of expected profit, and estimate of the CVaR of the profit and (2) their performance taking into consideration different sample sizes and risk management parameters. The results show that similar first-stage solutions are obtained depending on the risk parameterizations used in each formulation. Computationally, we identified three cases: (1) SP with a sample of 500 elements is competitive with ARO; (2) SP performance degrades comparing to the first case and ARO fails to converge in four out of five risk parameters; (3) SP fails to converge, whereas ARO converges in three out of five risk parameters. Overall, these performance cases depend on the combined effect of deterministic and uncertain data and risk parameters.},
  archive      = {J_IJOC},
  author       = {Ricardo M. Lima and Antonio J. Conejo and Loïc Giraldi and Olivier Le Maître and Ibrahim Hoteit and Omar M. Knio},
  doi          = {10.1287/ijoc.2022.1157},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1795-1818},
  shortjournal = {INFORMS J. Comput.},
  title        = {Risk-averse stochastic programming vs. adaptive robust optimization: A virtual power plant application},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computationally efficient approximations for
distributionally robust optimization under moment and wasserstein
ambiguity. <em>IJOC</em>, <em>34</em>(3), 1768–1794. (<a
href="https://doi.org/10.1287/ijoc.2021.1123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributionally robust optimization (DRO) is a modeling framework in decision making under uncertainty in which the probability distribution of a random parameter is unknown although its partial information (e.g., statistical properties) is available. In this framework, the unknown probability distribution is assumed to lie in an ambiguity set consisting of all distributions that are compatible with the available partial information. Although DRO bridges the gap between stochastic programming and robust optimization, one of its limitations is that its models for large-scale problems can be significantly difficult to solve, especially when the uncertainty is of high dimension. In this paper, we propose computationally efficient inner and outer approximations for DRO problems under a piecewise linear objective function and with a moment-based ambiguity set and a combined ambiguity set including Wasserstein distance and moment information. In these approximations, we split a random vector into smaller pieces, leading to smaller matrix constraints. In addition, we use principal component analysis to shrink uncertainty space dimensionality. We quantify the quality of the developed approximations by deriving theoretical bounds on their optimality gap. We display the practical applicability of the proposed approximations in a production–transportation problem and a multiproduct newsvendor problem. The results demonstrate that these approximations dramatically reduce the computational time while maintaining high solution quality. The approximations also help construct an interval that is tight for most cases and includes the (unknown) optimal value for a large-scale DRO problem, which usually cannot be solved to optimality (or even feasibility in most cases).},
  archive      = {J_IJOC},
  author       = {Meysam Cheramin and Jianqiang Cheng and Ruiwei Jiang and Kai Pan},
  doi          = {10.1287/ijoc.2021.1123},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1768-1794},
  shortjournal = {INFORMS J. Comput.},
  title        = {Computationally efficient approximations for distributionally robust optimization under moment and wasserstein ambiguity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Benders subproblem decomposition for bilevel problems with
convex follower. <em>IJOC</em>, <em>34</em>(3), 1749–1767. (<a
href="https://doi.org/10.1287/ijoc.2021.1128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel optimization formulates hierarchical decision-making processes that arise in many real-world applications, such as pricing, network design, and infrastructure defense planning. In this paper, we consider a class of bilevel optimization problems in which the upper level problem features some integer variables and the lower level problem enjoys strong duality. We propose a dedicated Benders decomposition method for solving this class of bilevel problems, which decomposes the Benders subproblem into two more tractable, sequentially solvable problems that can be interpreted as the upper and lower level problems. We show that the Benders subproblem decomposition carries over to an interesting extension of bilevel problems, which connects the upper level solution with the lower level dual solution, and discuss some special cases of bilevel problems that allow sequence-independent subproblem decomposition. Several novel schemes for generating numerically stable cuts, finding a good incumbent solution, and accelerating the search tree are discussed. A computational study demonstrates the computational benefits of the proposed method over a state-of-the-art, bilevel-tailored, branch-and-cut method; a commercial solver; and the standard Benders method on standard test cases and the motivating applications in sequential energy markets.},
  archive      = {J_IJOC},
  author       = {Geunyeong Byeon and Pascal Van Hentenryck},
  doi          = {10.1287/ijoc.2021.1128},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1749-1767},
  shortjournal = {INFORMS J. Comput.},
  title        = {Benders subproblem decomposition for bilevel problems with convex follower},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monte carlo and quasi–monte carlo density estimation via
conditioning. <em>IJOC</em>, <em>34</em>(3), 1729–1748. (<a
href="https://doi.org/10.1287/ijoc.2021.1135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the unknown density from which a given independent sample originates is more difficult than estimating the mean in the sense that, for the best popular nonparametric density estimators, the mean integrated square error converges more slowly than at the canonical rate of O(1/n). When the sample is generated from a simulation model and we have control over how this is done, we can do better. We examine an approach in which conditional Monte Carlo yields, under certain conditions, a random conditional density that is an unbiased estimator of the true density at any point. By averaging independent replications, we obtain a density estimator that converges at a faster rate than the usual ones. Moreover, combining this new type of estimator with randomized quasi–Monte Carlo to generate the samples typically brings a larger improvement on the error and convergence rate than for the usual estimators because the new estimator is smoother as a function of the underlying uniform random numbers.},
  archive      = {J_IJOC},
  author       = {Pierre L’Ecuyer and Florian Puchhammer and Amal Ben Abdellah},
  doi          = {10.1287/ijoc.2021.1135},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1729-1748},
  shortjournal = {INFORMS J. Comput.},
  title        = {Monte carlo and Quasi–Monte carlo density estimation via conditioning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Posterior-based stopping rules for bayesian
ranking-and-selection procedures. <em>IJOC</em>, <em>34</em>(3),
1711–1728. (<a href="https://doi.org/10.1287/ijoc.2021.1132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential ranking-and-selection procedures deliver Bayesian guarantees by repeatedly computing a posterior quantity of interest—for example, the posterior probability of good selection or the posterior expected opportunity cost—and terminating when this quantity crosses some threshold. Computing these posterior quantities entails nontrivial numerical computation. Thus, rather than exactly check such posterior-based stopping rules, it is common practice to use cheaply computable bounds on the posterior quantity of interest, for example, those based on Bonferroni’s or Slepian’s inequalities. The result is a conservative procedure that samples more simulation replications than are necessary. We explore how the time spent simulating these additional replications might be better spent computing the posterior quantity of interest via numerical integration, with the potential for terminating the procedure sooner. To this end, we develop several methods for improving the computational efficiency of exactly checking the stopping rules. Simulation experiments demonstrate that the proposed methods can, in some instances, significantly reduce a procedure’s total sample size. We further show these savings can be attained with little added computational effort by making effective use of a Monte Carlo estimate of the posterior quantity of interest.},
  archive      = {J_IJOC},
  author       = {David J. Eckman and Shane G. Henderson},
  doi          = {10.1287/ijoc.2021.1132},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1711-1728},
  shortjournal = {INFORMS J. Comput.},
  title        = {Posterior-based stopping rules for bayesian ranking-and-selection procedures},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Algorithms for queueing systems with reneging and priorities
modeled as quasi-birth-death processes. <em>IJOC</em>, <em>34</em>(3),
1693–1710. (<a href="https://doi.org/10.1287/ijoc.2021.1141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a Markovian multiserver queueing system with two customer classes, preemptive priorities, and reneging. We formulate this system as an infinite level-dependent quasi-birth-death process (LDQBD). We introduce an algorithm that endogenously truncates the level and calculates lower and upper bounds on stationary probabilities of this LDQBD such that the gap between the bounds can be any desired amount. Our algorithm can be applied to any LDQBD for which the rate matrices become elementwise nonincreasing above some level. This appears to be the first algorithm that provides bounds on stationary probabilities for an infinite-level LDQBD. To obtain these bounds, the algorithm first obtains lower and upper bounds on the rate matrices of the LDQBD using a novel method, which can be applied to any LDQBD. We then extend this algorithm to approximate performance measures of the system of interest and calculate exact lower and upper bounds for those that can be expressed as probabilities, such as the probability that an incoming low-priority customer will wait. We generate a wide range of instances with up to 100 servers and compare the solution times and accuracy of our algorithm with two existing algorithms. These numerical experiments indicate that our algorithm is faster than the other two algorithms for a given accuracy requirement. We investigate the impact of changing service rates on the proportion of low-priority customers served and their wait time, and we demonstrate how ignoring one of these measures can possibly mislead decision makers.},
  archive      = {J_IJOC},
  author       = {Amir Rastpour and Armann Ingolfsson and Burhaneddin Sandıkçı},
  doi          = {10.1287/ijoc.2021.1141},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1693-1710},
  shortjournal = {INFORMS J. Comput.},
  title        = {Algorithms for queueing systems with reneging and priorities modeled as quasi-birth-death processes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAD dispersion measure makes extremal queue analysis simple.
<em>IJOC</em>, <em>34</em>(3), 1681–1692. (<a
href="https://doi.org/10.1287/ijoc.2021.1130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A notorious problem in queueing theory is to compute the worst possible performance of the GI/G/1 queue under mean-dispersion constraints for the interarrival- and service-time distributions. We address this extremal queue problem by measuring dispersion in terms of mean absolute deviation (MAD) instead of the more conventional variance, making available methods for distribution-free analysis. Combined with random walk theory, we obtain explicit expressions for the extremal interarrival- and service-time distributions and, hence, the best possible upper bounds for all moments of the waiting time. We also obtain tight lower bounds that, together with the upper bounds, provide robust performance intervals. We show that all bounds are computationally tractable and remain sharp also when the mean and MAD are not known precisely but are estimated based on available data instead.},
  archive      = {J_IJOC},
  author       = {Wouter van Eekelen and Dick den Hertog and Johan S.H. van Leeuwaarden},
  doi          = {10.1287/ijoc.2021.1130},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1681-1692},
  shortjournal = {INFORMS J. Comput.},
  title        = {MAD dispersion measure makes extremal queue analysis simple},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncovering characteristic response paths of a population.
<em>IJOC</em>, <em>34</em>(3), 1661–1680. (<a
href="https://doi.org/10.1287/ijoc.2021.1121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an approach for uncovering characteristic response paths of a population from an individual-level multivariate time series data set. The approach is based on a model that accommodates a set of arbitrary distributions for endogenous variables and interstep intervals and variables. The model enables reliable estimation of individual-level parameters by uncovering and statistically pooling clusters of similar individuals. We show that using such a model one can distribute the response of an outcome variable to an impulse over all possible preceding activity sequences. When a few such sequences explain most of the response, they describe the population’s characteristic response paths from the impulse to the outcome. We apply the proposed approach to a customer touchpoint data set from a large multichannel specialty retailer. This application uncovers six customer segments, each with unique characteristic paths to purchase. These paths provide insights into the behavior of customers and the optimal over-time communication strategy for different customer segments.},
  archive      = {J_IJOC},
  author       = {Yicheng Song and Nachiketa Sahoo and Shuba Srinivasan and Chrysanthos Dellarocas},
  doi          = {10.1287/ijoc.2021.1121},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1661-1680},
  shortjournal = {INFORMS J. Comput.},
  title        = {Uncovering characteristic response paths of a population},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving sales forecasting accuracy: A tensor factorization
approach with demand awareness. <em>IJOC</em>, <em>34</em>(3),
1644–1660. (<a href="https://doi.org/10.1287/ijoc.2021.1147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the accessibility of big data collections from consumers, products, and stores, advanced sales forecasting capabilities have drawn great attention from many businesses, especially those in retail, because of the importance of forecasting in decision making. Improvement of forecasting accuracy, even by a small percentage, may have a substantial impact on companies’ production and financial planning, marketing strategies, inventory controls, and supply chain management. Specifically, our research goal is to forecast the sales of each product in each store in the near future. Motivated by tensor factorization methodologies for context-aware recommender systems, we propose a novel approach called the advanced temporal latent factor approach to sales forecasting, or ATLAS for short, which achieves accurate and individualized predictions for sales by building a single tensor factorization model across multiple stores and products. Our contribution is a combination of a tensor framework (to leverage information across stores and products), a new regularization function (to incorporate demand dynamics), and extrapolation of the tensor into future time periods using state-of-the-art statistical (seasonal autoregressive integrated moving-average models) and machine-learning (recurrent neural networks) models. The advantages of ATLAS are demonstrated on eight product category data sets collected by Information Resources, Inc., where we analyze a total of 165 million weekly sales transactions of over 15,560 products from more than 1,500 grocery stores.},
  archive      = {J_IJOC},
  author       = {Xuan Bi and Gediminas Adomavicius and William Li and Annie Qu},
  doi          = {10.1287/ijoc.2021.1147},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1644-1660},
  shortjournal = {INFORMS J. Comput.},
  title        = {Improving sales forecasting accuracy: A tensor factorization approach with demand awareness},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal rule sets for identifying subgroups with enhanced
treatment effects. <em>IJOC</em>, <em>34</em>(3), 1626–1643. (<a
href="https://doi.org/10.1287/ijoc.2021.1143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key question in causal inference analyses is how to find subgroups with elevated treatment effects. This paper takes a machine learning approach and introduces a generative model, causal rule sets (CRS), for interpretable subgroup discovery. A CRS model uses a small set of short decision rules to capture a subgroup in which the average treatment effect is elevated. We present a Bayesian framework for learning a causal rule set. The Bayesian model consists of a prior that favors simple models for better interpretability as well as avoiding overfitting and a Bayesian logistic regression that captures the likelihood of data, characterizing the relation between outcomes, attributes, and subgroup membership. The Bayesian model has tunable parameters that can characterize subgroups with various sizes, providing users with more flexible choices of models from the treatment-efficient frontier. We find maximum a posteriori models using iterative discrete Monte Carlo steps in the joint solution space of rules sets and parameters. To improve search efficiency, we provide theoretically grounded heuristics and bounding strategies to prune and confine the search space. Experiments show that the search algorithm can efficiently recover true underlying subgroups. We apply CRS on public and real-world data sets from domains in which interpretability is indispensable. We compare CRS with state-of-the-art rule-based subgroup discovery models. Results show that CRS achieves consistently competitive performance on data sets from various domains, represented by high treatment-efficient frontiers.},
  archive      = {J_IJOC},
  author       = {Tong Wang and Cynthia Rudin},
  doi          = {10.1287/ijoc.2021.1143},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1626-1643},
  shortjournal = {INFORMS J. Comput.},
  title        = {Causal rule sets for identifying subgroups with enhanced treatment effects},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the estimation of discrete choice models to capture
irrational customer behaviors. <em>IJOC</em>, <em>34</em>(3), 1606–1625.
(<a href="https://doi.org/10.1287/ijoc.2021.1154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The randomutility maximization model is by far the most adopted framework to estimate consumer choice behavior. However, behavioral economics has provided strong empirical evidence of irrational choice behaviors, such as halo effects, that are incompatible with this framework. Models belonging to the random utility maximization family may therefore not accurately capture such irrational behavior. Hence, more general choice models, overcoming such limitations, have been proposed. However, the flexibility of such models comes at the price of increased risk of overfitting. As such, estimating such models remains a challenge. In this work, we propose an estimation method for the recently proposed generalized stochastic preference choice model, which subsumes the family of random utility maximization models and is capable of capturing halo effects. In particular, we propose a column-generation method to gradually refine the discrete choice model based on partially ranked preference sequences. Extensive computational experiments indicate that our model, explicitly accounting for irrational preferences, can significantly boost the predictive accuracy on both synthetic and real-world data instances.},
  archive      = {J_IJOC},
  author       = {Sanjay Dominik Jena and Andrea Lodi and Claudio Sole},
  doi          = {10.1287/ijoc.2021.1154},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1606-1625},
  shortjournal = {INFORMS J. Comput.},
  title        = {On the estimation of discrete choice models to capture irrational customer behaviors},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient algebraic multigrid methods for multilevel
overlapping coclustering of user-item relationships. <em>IJOC</em>,
<em>34</em>(3), 1587–1605. (<a
href="https://doi.org/10.1287/ijoc.2021.1137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various digital data sets that encode user-item relationships contain a multilevel overlapping cluster structure. The user-item relation can be encoded in a weighted bipartite graph and uncovering these overlapping coclusters of users and items at multiple levels in the bipartite graph can play an important role in analyzing user-item data in many applications. For example, for effective online marketing, such as placing online ads or deploying smart online marketing strategies, identifying co-occurring clusters of users and items can lead to accurately targeted advertisements and better marketing outcomes. In this paper, we propose fast algorithms inspired by algebraic multigrid methods for finding multilevel overlapping cocluster structures of feature matrices that encode user-item relations. Starting from the weighted bipartite graph structure of the feature matrix, the algorithms use agglomeration procedures to recursively coarsen the bipartite graphs that represent the relations between the coclusters on increasingly coarser levels. New fast coarsening routines are described that circumvent the bottleneck of all-to-all similarity computations by exploiting measures of direct connection strength between row and column variables in the feature matrix. Providing accurate coclusters at multiple levels in a manner that can scale to large data sets is a challenging task. In this paper, we propose heuristic algorithms that approximately and recursively minimize normalized cuts to obtain coclusters in the aggregated bipartite graphs on multiple levels of resolution. Whereas the main novelty and focus of the paper lies in algorithmic aspects of reducing computational complexity to obtain scalable methods specifically for large rectangular user-item matrices, the algorithmic variants also define several new models for determining multilevel coclusters that we justify intuitively by relating them to principles that underlie collaborative filtering methods for user-item relationships. Experimental results show that the proposed algorithms successfully uncover the multilevel overlapping cluster structure for artificial and real data sets.},
  archive      = {J_IJOC},
  author       = {Haifeng Xu and Rasha F. Kashef and Hans De Sterck and Geoffrey Sanders},
  doi          = {10.1287/ijoc.2021.1137},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1587-1605},
  shortjournal = {INFORMS J. Comput.},
  title        = {Efficient algebraic multigrid methods for multilevel overlapping coclustering of user-item relationships},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A general branch-and-cut framework for rotating workforce
scheduling. <em>IJOC</em>, <em>34</em>(3), 1548–1564. (<a
href="https://doi.org/10.1287/ijoc.2021.1149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a general algorithmic framework for rotating workforce scheduling. We develop a graph representation that allows to model a schedule as a Eulerian cycle of stints, which we then use to derive a problem formulation that is compact toward the number of employees. We develop a general branch-and-cut framework that solves rotating workforce scheduling in its basic variant, as well as several additional problem variants that are relevant in practice. These variants comprise, among others, objectives for the maximization of free weekends and the minimization of employees. Our computational studies show that the developed framework constitutes a new state of the art for rotating workforce scheduling. For the first time, we solve all 6,000 instances of the status quo benchmark for rotating workforce scheduling to optimality with an average computational time of 0.07 seconds and a maximum computational time of 2.53 seconds. These results reduce average computational times by more than 99\% compared with existing methods. Our algorithmic framework shows consistent computational performance, which is robust across all studied problem variants.},
  archive      = {J_IJOC},
  author       = {Tristan Becker and Maximilian Schiffer and Grit Walther},
  doi          = {10.1287/ijoc.2021.1149},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1548-1564},
  shortjournal = {INFORMS J. Comput.},
  title        = {A general branch-and-cut framework for rotating workforce scheduling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building load control using distributionally robust
chance-constrained programs with right-hand side uncertainty and the
risk-adjustable variants. <em>IJOC</em>, <em>34</em>(3), 1531–1547. (<a
href="https://doi.org/10.1287/ijoc.2021.1152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregation of heating, ventilation, and air conditioning (HVAC) loads can provide reserves to absorb volatile renewable energy, especially solar photo-voltaic (PV) generation. In this paper, we decide HVAC control schedules under uncertain PV generation, using a distributionally robust chance-constrained (DRCC) building load control model under two typical ambiguity sets: the moment-based and Wasserstein ambiguity sets. We derive mixed integer linear programming (MILP) reformulations for DRCC problems under both sets. Especially, for the Wasserstein ambiguity set, we use the right-hand side (RHS) uncertainty to derive a more compact MILP reformulation than the commonly known MILP reformulations with big-M constants. All the results also apply to general individual chance constraints with RHS uncertainty. Furthermore, we propose an adjustable chance-constrained variant to achieve tradeoff between the operational risk and costs. We derive MILP reformulations under the Wasserstein ambiguity set and second-order conic programming (SOCP) reformulations under the moment-based set. Using real-world data, we conduct computational studies to demonstrate the efficiency of the solution approaches and the effectiveness of the solutions.},
  archive      = {J_IJOC},
  author       = {Yiling Zhang and Jin Dong},
  doi          = {10.1287/ijoc.2021.1152},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1531-1547},
  shortjournal = {INFORMS J. Comput.},
  title        = {Building load control using distributionally robust chance-constrained programs with right-hand side uncertainty and the risk-adjustable variants},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exact approaches for single machine total weighted tardiness
batch scheduling. <em>IJOC</em>, <em>34</em>(3), 1512–1530. (<a
href="https://doi.org/10.1287/ijoc.2021.1133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a single machine total weighted tardiness (TWT) batch-scheduling problem in which jobs have release dates, nonidentical sizes, and are compatible between each other. We propose two integer linear programming models: the first one is a time-indexed formulation (TIF), and the second is an innovative time-size-indexed formulation (TSIF). Although TIF clearly outperforms the existing formulation for the problem, TSIF is capable of producing much stronger bounds in practice. The latter also enables us to develop an efficient column-generation (CG) algorithm. The pricing subproblem corresponds to a resource-constrained shortest path problem that is solved using a bucket graph–based labeling algorithm. The solutions of such a subproblem may contain cycles (reprocessing of jobs), and thus, a memory mechanism called dynamic arc-based ng-sets is employed in the labeling with a view toward avoiding some of them. Moreover, we also implement a preprocessing scheme based on Lagrangian relaxation to perform variable fixing. Extensive computational experiments were carried out in 810 benchmark instances. The proposed CG algorithm is capable of solving instances with up to 100 jobs to optimality. In addition, we believe that this is the first exact approach for a TWT batch-scheduling variant capable of systematically solving instances with up to 50 jobs. High-quality results are also reported for three special cases of the problem—more precisely, when (i) the penalty weights are unitary, (ii) there are no release dates, and (iii) all due dates are set to zero and, hence, the objective becomes equivalent to minimizing the weighted completion time.},
  archive      = {J_IJOC},
  author       = {Artur Alves Pessoa and Teobaldo Bulhões and Vitor Nesello and Anand Subramanian},
  doi          = {10.1287/ijoc.2021.1133},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1512-1530},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact approaches for single machine total weighted tardiness batch scheduling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A scalable algorithm for sparse portfolio selection.
<em>IJOC</em>, <em>34</em>(3), 1489–1511. (<a
href="https://doi.org/10.1287/ijoc.2021.1127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse portfolio selection problem is one of the most famous and frequently studied problems in the optimization and financial economics literatures. In a universe of risky assets, the goal is to construct a portfolio with maximal expected return and minimum variance, subject to an upper bound on the number of positions, linear inequalities, and minimum investment constraints. Existing certifiably optimal approaches to this problem have not been shown to converge within a practical amount of time at real-world problem sizes with more than 400 securities. In this paper, we propose a more scalable approach. By imposing a ridge regularization term, we reformulate the problem as a convex binary optimization problem, which is solvable via an efficient outer-approximation procedure. We propose various techniques for improving the performance of the procedure, including a heuristic that supplies high-quality warm-starts, and a second heuristic for generating additional cuts that strengthens the root relaxation. We also study the problem’s continuous relaxation, establish that it is second-order cone representable, and supply a sufficient condition for its tightness. In numerical experiments, we establish that a conjunction of the imposition of ridge regularization and the use of the outer-approximation procedure gives rise to dramatic speedups for sparse portfolio selection problems.},
  archive      = {J_IJOC},
  author       = {Dimitris Bertsimas and Ryan Cory-Wright},
  doi          = {10.1287/ijoc.2021.1127},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1489-1511},
  shortjournal = {INFORMS J. Comput.},
  title        = {A scalable algorithm for sparse portfolio selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse mixed integer optimization: Polyhedral insights and
trust region methods. <em>IJOC</em>, <em>34</em>(3), 1471–1488. (<a
href="https://doi.org/10.1287/ijoc.2021.1138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse optimization—determining parameters of an optimization problem that render a given solution optimal—has received increasing attention in recent years. Although significant inverse optimization literature exists for convex optimization problems, there have been few advances for discrete problems, despite the ubiquity of applications that fundamentally rely on discrete decision making. In this paper, we present a new set of theoretical insights and algorithms for the general class of inverse mixed integer linear optimization problems. Specifically, a general characterization of optimality conditions is established and leveraged to design new cutting plane solution algorithms. Through an extensive set of computational experiments, we show that our methods provide substantial improvements over existing methods in solving the largest and most difficult instances to date.},
  archive      = {J_IJOC},
  author       = {Merve Bodur and Timothy C. Y. Chan and Ian Yihang Zhu},
  doi          = {10.1287/ijoc.2021.1138},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1471-1488},
  shortjournal = {INFORMS J. Comput.},
  title        = {Inverse mixed integer optimization: Polyhedral insights and trust region methods},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A criterion space branch-and-cut algorithm for mixed integer
bilinear maximum multiplicative programs. <em>IJOC</em>, <em>34</em>(3),
1453–1470. (<a href="https://doi.org/10.1287/ijoc.2021.1097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a branch-and-bound algorithm to solve mixed-integer bilinear maximum multiplicative programs (MIBL-MMPs). This class of optimization problems arises in many applications, such as finding a Nash bargaining solution (Nash social welfare optimization), capacity allocation markets, reliability optimization, etc. The proposed algorithm applies multiobjective optimization principles to solve MIBL-MMPs exploiting a special characteristic in these problems. That is, taking each multiplicative term in the objective function as a dummy objective function, the projection of an optimal solution of MIBL-MMPs is a nondominated point in the space of dummy objectives. Moreover, several enhancements are applied and adjusted to tighten the bounds and improve the performance of the algorithm. The performance of the algorithm is investigated by 400 randomly generated sample instances of MIBL-MMPs. The obtained result is compared against the outputs of the mixed-integer second order cone programming (SOCP) solver in CPLEX and a state-of-the-art algorithm in the literature for this problem. Our analysis on this comparison shows that the proposed algorithm outperforms the fastest existing method, that is, the SOCP solver, by a factor of 6.54 on average.},
  archive      = {J_IJOC},
  author       = {Vahid Mahmoodian and Iman Dayarian and Payman Ghasemi Saghand and Yu Zhang and Hadi Charkhgard},
  doi          = {10.1287/ijoc.2021.1097},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1453-1470},
  shortjournal = {INFORMS J. Comput.},
  title        = {A criterion space branch-and-cut algorithm for mixed integer bilinear maximum multiplicative programs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An interior-point differentiable path-following method to
compute stationary equilibria in stochastic games. <em>IJOC</em>,
<em>34</em>(3), 1403–1418. (<a
href="https://doi.org/10.1287/ijoc.2021.1139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subgame perfect equilibrium in stationary strategies (SSPE) is the most important solution concept in applications of stochastic games, making it imperative to develop efficient methods to compute an SSPE. For this purpose, this paper develops an interior-point differentiable path-following method (IPM), which establishes a connection between an artificial logarithmic barrier game and the stochastic game of interest by adding a homotopy variable. IPM brings several advantages over the existing methods for stochastic games. On the one hand, IPM provides a bridge between differentiable path-following methods and interior-point methods and remedies several issues of an existing homotopy method called the stochastic linear tracing procedure (SLTP). First, the starting stationary strategy profile can be arbitrarily chosen. Second, IPM does not need switching between different systems of equations. Third, the use of a perturbation term makes IPM applicable to all stochastic games rather than generic games only. Moreover, a well-chosen transformation of variables reduces the number of equations and variables by roughly one half. Numerical results show that the proposed method is more than three times as efficient as SLTP. On the other hand, the stochastic game can be reformulated as a mixed complementarity problem and solved by the PATH solver. We employ the proposed IPM and the PATH solver to compute SSPEs. Numerical results evince that for some stochastic games the PATH solver may fail to find an SSPE, whereas IPM is successful in doing so for all stochastic games, which confirms the reliability and stability of the proposed method.},
  archive      = {J_IJOC},
  author       = {Chuangyin Dang and P. Jean-Jacques Herings and Peixuan Li},
  doi          = {10.1287/ijoc.2021.1139},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1403-1418},
  shortjournal = {INFORMS J. Comput.},
  title        = {An interior-point differentiable path-following method to compute stationary equilibria in stochastic games},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nonconvex optimization approach to IMRT planning with
dose–volume constraints. <em>IJOC</em>, <em>34</em>(3), 1366–1386. (<a
href="https://doi.org/10.1287/ijoc.2021.1129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluence map optimization for intensity-modulated radiation therapy planning can be formulated as a large-scale inverse problem with competing objectives and constraints associated with the tumors and organs at risk. Unfortunately, clinically relevant dose–volume constraints are nonconvex, so standard algorithms for convex problems cannot be directly applied. Although prior work focuses on convex approximations for these constraints, we propose a novel relaxation approach to handle nonconvex dose–volume constraints. We develop efficient, provably convergent algorithms based on partial minimization, and show how to adapt them to handle maximum-dose constraints and infeasible problems. We demonstrate our approach using the CORT data set and show that it is easily adaptable to radiation treatment planning with dose–volume constraints for multiple tumors and organs at risk.},
  archive      = {J_IJOC},
  author       = {Kelsey Maass and Minsun Kim and Aleksandr Aravkin},
  doi          = {10.1287/ijoc.2021.1129},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1366-1386},
  shortjournal = {INFORMS J. Comput.},
  title        = {A nonconvex optimization approach to IMRT planning with Dose–Volume constraints},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rapid influence maximization on social networks: The
positive influence dominating set problem. <em>IJOC</em>,
<em>34</em>(3), 1345–1365. (<a
href="https://doi.org/10.1287/ijoc.2021.1144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by applications arising on social networks, we study a generalization of the celebrated dominating set problem called the Positive Influence Dominating Set (PIDS). Given a graph G with a set V of nodes and a set E of edges, each node i in V has a weight bi, and a threshold requirement gi. We seek a minimum weight subset T of V, so that every node i not in T is adjacent to at least gi members of T. When gi is one for all nodes, we obtain the weighted dominating set problem. First, we propose a strong and compact extended formulation for the PIDS problem. We then project the extended formulation onto the space of the natural node-selection variables to obtain an equivalent formulation with an exponential number of valid inequalities. Restricting our attention to trees, we show that the extended formulation is the strongest possible formulation, and its projection (onto the space of the node variables) gives a complete description of the PIDS polytope on trees. We derive the necessary and sufficient facet-dening conditions for the valid inequalities in the projection and discuss their polynomial time separation. We embed this (exponential size) formulation in a branch-and-cut framework and conduct computational experiments using real-world graph instances, with up to approximately 2.5 million nodes and 8 million edges. On a test-bed of 100 real-world graph instances, our approach finds solutions that are on average 0.2\% from optimality and solves 51 out of the 100 instances to optimality.},
  archive      = {J_IJOC},
  author       = {S. Raghavan and Rui Zhang},
  doi          = {10.1287/ijoc.2021.1144},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1345-1365},
  shortjournal = {INFORMS J. Comput.},
  title        = {Rapid influence maximization on social networks: The positive influence dominating set problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extended graph formulation for the inequity aversion pricing
problem on social networks. <em>IJOC</em>, <em>34</em>(3), 1327–1344.
(<a href="https://doi.org/10.1287/ijoc.2021.1148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inequity aversion pricing problem aims to maximize revenue while providing prices to people connected in a social network such that connected people receive prices that are not too different. This problem is known to be NP-hard even when the number of prices offered is three. This paper provides an extended graph formulation for the problem whose LP-relaxation is shown to be very strong. We show that the extended graph relaxation is integral on a network without any cycle. We develop extended cycle inequalities and show that the extended cycle inequalities cut off all the fractional extreme points of the extended graph relaxation on a cycle. We generalize cycle inequalities to zero half cuts performing a Chvátal–Gomory procedure on a cycle. Computational experiments show that the extended graph relaxation results in an integer solution for most problem instances with very small gaps (less than 3\%) from optimality for the remaining instances. The addition of zero half cuts reduces the integrality gap significantly on the few difficult instances.},
  archive      = {J_IJOC},
  author       = {Sunil Chopra and Hyunwoo Park and Sangho Shim},
  doi          = {10.1287/ijoc.2021.1148},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1327-1344},
  shortjournal = {INFORMS J. Comput.},
  title        = {Extended graph formulation for the inequity aversion pricing problem on social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solving the distance-based critical node problem.
<em>IJOC</em>, <em>34</em>(3), 1309–1326. (<a
href="https://doi.org/10.1287/ijoc.2021.1136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In critical node problems, the task is to identify a small subset of so-called critical nodes whose deletion maximally degrades a network’s “connectivity” (however that is measured). Problems of this type have been widely studied, for example, for limiting the spread of infectious diseases. However, existing approaches for solving them have typically been limited to networks having fewer than 1,000 nodes. In this paper, we consider a variant of this problem in which the task is to delete b nodes so as to minimize the number of node pairs that remain connected by a path of length at most k. With the techniques developed in this paper, instances with up to 17,000 nodes can be solved exactly. We introduce two integer programming formulations for this problem (thin and path-like) and compare them with an existing recursive formulation. Although the thin formulation generally has an exponential number of constraints, it admits an efficient separation routine. Also helpful is a new, more general preprocessing procedure that, on average, fixes three times as many variables than before.},
  archive      = {J_IJOC},
  author       = {Hosseinali Salemi and Austin Buchanan},
  doi          = {10.1287/ijoc.2021.1136},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1309-1326},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving the distance-based critical node problem},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unforeseen consequences of “tabu” choices—a retrospective.
<em>IJOC</em>, <em>34</em>(3), 1306–1308. (<a
href="https://doi.org/10.1287/ijoc.2022.1187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Fred W. Glover},
  doi          = {10.1287/ijoc.2022.1187},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1306-1308},
  shortjournal = {INFORMS J. Comput.},
  title        = {Unforeseen consequences of “Tabu” Choices—A retrospective},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Note from the editor. <em>IJOC</em>, <em>34</em>(3), 1305.
(<a href="https://doi.org/10.1287/ijoc.2022.1186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2022.1186},
  journal      = {INFORMS Journal on Computing},
  number       = {3},
  pages        = {1305},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022e). Editorial board. <em>IJOC</em>, <em>34</em>(2), C2. (<a
href="https://doi.org/10.1287/ijoc.2022.eb.v3402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.eb.v3402},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022d). Note from the editor. <em>IJOC</em>, <em>34</em>(2), 671.
(<a href="https://doi.org/10.1287/ijoc.2022.1173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {Alice E. Smith},
  doi          = {10.1287/ijoc.2022.1173},
  journal      = {INFORMS Journal on Computing},
  number       = {2},
  pages        = {671},
  shortjournal = {INFORMS J. Comput.},
  title        = {Note from the editor},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022f). Editorial board. <em>IJOC</em>, <em>34</em>(1), C2. (<a
href="https://doi.org/10.1287/ijoc.2022.eb.v3401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.eb.v3401},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {C2},
  shortjournal = {INFORMS J. Comput.},
  title        = {Editorial board},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special issue of INFORMS journal on computing—scalable
reinforcement learning algorithms. <em>IJOC</em>, <em>34</em>(1), 2–3.
(<a href="https://doi.org/10.1287/ijoc.2021.1153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  author       = {J. Paul Brooks and Ted Ralphs and Nicola Secomandi},
  doi          = {10.1287/ijoc.2021.1153},
  journal      = {INFORMS Journal on Computing},
  number       = {1},
  pages        = {2-3},
  shortjournal = {INFORMS J. Comput.},
  title        = {Special issue of INFORMS journal on Computing—Scalable reinforcement learning algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
