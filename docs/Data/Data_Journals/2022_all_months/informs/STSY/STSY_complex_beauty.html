<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>STSY_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="stsy---18">STSY - 18</h2>
<ul>
<li><details>
<summary>
(2022). The exploration-exploitation trade-off in the newsvendor
problem. <em>STSY</em>, <em>12</em>(4), 319–430. (<a
href="https://doi.org/10.1287/stsy.2022.0093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When an inventory manager attempts to construct probabilistic models of demand based on past data, demand samples are almost never available: only sales data can be used. This demand censoring introduces an exploration-exploitation trade-off as the ordering decisions impact the information collected. Much of the literature has sought to understand how operational decisions should be modified to incorporate this trade-off. We ask an even more basic question: When does the exploration-exploitation trade-off matter? To what extent should one deviate from a myopic policy that takes the optimal decision for the current period without consideration for future periods? We analyze these questions in the context of a well-studied stationary multiperiod newsvendor problem in which the decision maker starts with a prior on parameters characterizing the demand distribution. We show that, under very general conditions in both perishable and nonperishable settings, the myopic policy will almost surely learn the optimal decision one would have taken with knowledge of the unknown parameters. Furthermore, in the perishable setting, we analyze finite time performance for a broad family of tractable cases. Through a combination of analytical parametric bounds and exhaustive exact analysis, we show that the myopic optimality gap is negligible for many practical instances. Funding: The third author was partially supported by the National Science Foundation [Grant CMMI-1235023]. Supplemental Material: The online supplement is available at https://doi.org/10.1287/stsy.2022.0093 .},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2022.0093},
  journal      = {Stochastic Systems},
  number       = {4},
  pages        = {319-430},
  shortjournal = {Stoch. Syst.},
  title        = {The exploration-exploitation trade-off in the newsvendor problem},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel server systems with cancel-on-completion
redundancy. <em>STSY</em>, <em>12</em>(4), 319–430. (<a
href="https://doi.org/10.1287/stsy.2022.0094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a parallel server system with so-called cancel-on-completion redundancy. There are n servers and multiple job classes j . An arriving class j job consists of d j components placed on a randomly selected subset of servers; the job service is complete as soon as k j components out of d j (with k j ≤ d j ) complete their service, at which point the unfinished service of all remaining d j − k j components is canceled. The system is in general non-work-conserving in the sense that the average amount of new workload added to the system by an arriving class j job is not defined a priori—it depends on the system state at the time of arrival. This poses the main challenge for the system analysis. For the system with a fixed number of servers n , our main results include: the stability properties; the property that the stationary distributions of the relative server workloads remain tight uniformly in the system load. We also consider the mean-field asymptotic regime when n → ∞ while each job class arrival rate per server remains constant. The main question we address here is: under which conditions the steady-state asymptotic independence (SSAI) of server workloads holds and, in particular, when the SSAI for the full range of loads (SSAI-FRL) holds. (Informally, SSAI-FRL means that SSAI holds for any system load less than one.) We obtain sufficient conditions for SSAI and SSAI-FRL. In particular, we prove that SSAI-FRL holds in the important special case when job components of each class j are independent and identically distributed with an increasing-hazard-rate distribution.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2022.0094},
  journal      = {Stochastic Systems},
  number       = {4},
  pages        = {319-430},
  shortjournal = {Stoch. Syst.},
  title        = {Parallel server systems with cancel-on-completion redundancy},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smoothed variable sample-size accelerated proximal methods
for nonsmooth stochastic convex programs. <em>STSY</em>, <em>12</em>(4),
319–430. (<a href="https://doi.org/10.1287/stsy.2022.0095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the unconstrained minimization of the function F , where F = f + g , f is an expectation-valued nonsmooth convex or strongly convex function, and g is a closed, convex, and proper function. (I) Strongly convex f . When f is μ -strongly convex in x , traditional stochastic subgradient schemes ( SSG ) often display poor behavior, arising in part from noisy subgradients and diminishing steplengths. Instead, we apply a variable sample-size accelerated proximal scheme (VS-APM) on F , the Moreau envelope of F ; we term such a scheme as ( mVS-APM ) and in contrast with ( SSG ) schemes, ( mVS-APM ) utilizes constant steplengths and increasingly exact gradients. We consider two settings. (a) Bounded domains. In this setting, ( mVS-APM ) displays linear convergence in inexact gradient steps, each of which requires utilizing an inner ( prox-SSG ) scheme. Specically, ( mVS-APM ) achieves an optimal oracle complexity in prox-SSG steps of O ( 1 / ϵ ) with an iteration complexity of O ( log ( 1 / ϵ ) ) in inexact (outer) gradients of F to achieve an ϵ-accurate solution in mean-squared error, computed via an increasing number of inner (stochastic) subgradient steps; (b) Unbounded domains. In this regime, under an assumption of state-dependent bounds on subgradients, an unaccelerated variant ( mVS-APM ) is linearly convergent where increasingly exact gradients ∇ x F ( x ) are approximated with increasing accuracy via ( SSG ) schemes. Notably, ( mVS-APM ) also displays an optimal oracle complexity of O ( 1 / ϵ ) ; (II) Convex f . When f is merely convex but smoothable, by suitable choices of the smoothing, steplength, and batch-size sequences, smoothed (VS-APM) (or sVS-APM) achieves an optimal oracle complexity of O ( 1 / ϵ 2 ) to obtain an ϵ-optimal solution. Our results can be specialized to two important cases: (a) Smooth f . Since smoothing is no longer required, we observe that (VS-APM) admits the optimal rate and oracle complexity, matching prior ndings; (b) Deterministic nonsmooth f . In the nonsmooth deterministic regime, (sVS-APM) reduces to a smoothed accelerated proximal method (s-APM) that is both asymptotically convergent and optimal in that it displays a complexity of O ( 1 / ϵ ) , matching the bound provided by Nesterov in 2005 for producing ϵ-optimal solutions. Finally, (sVS-APM) and (VS-APM) produce sequences that converge almost surely to a solution of the original problem. Funding: The first and second authors would like to acknowledge support from NSF CMMI-1538605, DOE ARPA-E award DE-AR0001076, and the Gary and Sheila Bello Chair funds.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2022.0095},
  journal      = {Stochastic Systems},
  number       = {4},
  pages        = {319-430},
  shortjournal = {Stoch. Syst.},
  title        = {Smoothed variable sample-size accelerated proximal methods for nonsmooth stochastic convex programs},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Concentration of contractive stochastic approximation and
reinforcement learning. <em>STSY</em>, <em>12</em>(4), 319–430. (<a
href="https://doi.org/10.1287/stsy.2022.0097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a martingale concentration inequality, concentration bounds “from time n 0 on” are derived for stochastic approximation algorithms with contractive maps and both martingale difference and Markov noises. These are applied to reinforcement learning algorithms, in particular to asynchronous Q-learning and TD(0). Funding: V. S. Borkar was supported in part by a S. S. Bhatnagar Fellowship from the Council of Scientific and Industrial Research, Government of India.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2022.0097},
  journal      = {Stochastic Systems},
  number       = {4},
  pages        = {319-430},
  shortjournal = {Stoch. Syst.},
  title        = {Concentration of contractive stochastic approximation and reinforcement learning},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A theory of auto-scaling for resource reservation in cloud
services. <em>STSY</em>, <em>12</em>(3), 227–317. (<a
href="https://doi.org/10.1287/stsy.2021.0091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a distributed server system consisting of a large number of servers, each with limited capacity on multiple resources (CPU, memory, etc.). Jobs with different rewards arrive over time and require certain amounts of resources for the duration of their service. When a job arrives, the system must decide whether to admit it or reject it, and if admitted, in which server to schedule it. The objective is to maximize the expected total reward received by the system. This problem is motivated by control of cloud computing clusters, in which jobs are requests for virtual machines (VMs) or containers that reserve resources for various services, and rewards represent service priority of requests or price paid per time unit of service. We study this problem in an asymptotic regime where the number of servers and jobs’ arrival rates scale by a factor L , as L becomes large. We propose a resource reservation policy that asymptotically achieves at least 1/2, and under certain monotone property on jobs’ rewards and resources, at least 1 − 1 / e of the optimal expected reward. The policy automatically scales the number of VM slots for each job type as the demand changes and decides in which servers the slots should be created in advance , without the knowledge of traffic rates.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0091},
  journal      = {Stochastic Systems},
  number       = {3},
  pages        = {227-317},
  shortjournal = {Stoch. Syst.},
  title        = {A theory of auto-scaling for resource reservation in cloud services},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Delay-join the shortest queue routing for a parallel
queueing system with removable servers. <em>STSY</em>, <em>12</em>(3),
227–317. (<a href="https://doi.org/10.1287/stsy.2021.0090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new class of policies called “delay-join the shortest queue (delay-JSQ)” for use in parallel processing networks with removable servers. When jobs arrive to the system while all servers are on, jobs should be routed to the shortest queue. However, when servers are off, they take a random time to turn back on, which we allow to occur only when the number of jobs in each of the nonempty queues exceeds a fixed threshold. This new class of policies balances the load among all servers that are currently on and balances the capacity by keeping servers off until they are needed. A detailed numerical study shows that at moderate loads (where server farms and increasingly manufacturing facilities operate), delay-JSQ outperforms JSQ by up to 80\%. In addition, it does so without precise knowledge of the input parameters and even when the input process is nonstationary.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0090},
  journal      = {Stochastic Systems},
  number       = {3},
  pages        = {227-317},
  shortjournal = {Stoch. Syst.},
  title        = {Delay-join the shortest queue routing for a parallel queueing system with removable servers},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for studying decentralized bayesian learning
with strategic agents. <em>STSY</em>, <em>12</em>(3), 227–317. (<a
href="https://doi.org/10.1287/stsy.2021.0092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of Bayesian learning in a dynamical system involving strategic agents with asymmetric information. In a series of seminal papers in the literature, this problem has been investigated under a simplifying model where selfish players appear sequentially and act once in the game. It has been shown that there exist information cascades where users discard their private information and mimic the action of their predecessor. In this paper, we provide a framework for studying Bayesian learning dynamics in a more general setting than the one just described. In particular, our model incorporates cases where players can act repeatedly and there is strategic interaction in that each agent’s payoff may also depend on other players’ actions. The proposed framework hinges on a sequential decomposition methodology for finding structured perfect Bayesian equilibria of a general class of dynamic games with asymmetric information. Using this methodology, we study a specific dynamic learning model where players make decisions about public investment based on their estimates of everyone’s states. We characterize a set of informational cascades for this problem where learning stops for the team as a whole. Moreover, we show that such cascades occur almost surely.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0092},
  journal      = {Stochastic Systems},
  number       = {3},
  pages        = {227-317},
  shortjournal = {Stoch. Syst.},
  title        = {A framework for studying decentralized bayesian learning with strategic agents},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extreme value analysis for a markov additive process driven
by a nonirreducible background chain. <em>STSY</em>, <em>12</em>(3),
227–317. (<a href="https://doi.org/10.1287/stsy.2021.0086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common assumption in the vast literature on the extremes of spectrally one-sided Markov additive processes (MAPs) is that the continuous-time Markov chain that serves as the background process is irreducible. In the present paper, we consider, motivated by, for example, applications in credit risk, the case in which the irreducibility condition has been lifted, thus allowing the presence of one or more transient classes. More specifically, we consider the distribution of the maximum when the MAP under study has only positive jumps (the spectrally positive case) or negative jumps (the spectrally negative case). The methodology used relies on two crucial previous results: (i) the Wiener–Hopf decomposition for Lévy processes and, in particular, its explicit form in spectrally one-sided cases and (ii) a result on the number of singularities of the matrix exponent of a spectrally one-sided MAP. In both the spectrally positive and negative cases, we derive a system of linear equations of which the solution characterizes the distribution of the maximum of the process. As a by-product of our results, we develop a procedure for calculating the maximum of a spectrally one-sided Lévy process over a phase-type distributed time interval.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0086},
  journal      = {Stochastic Systems},
  number       = {3},
  pages        = {227-317},
  shortjournal = {Stoch. Syst.},
  title        = {Extreme value analysis for a markov additive process driven by a nonirreducible background chain},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Greedy matching in bipartite random graphs. <em>STSY</em>,
<em>12</em>(2), 133–225. (<a
href="https://doi.org/10.1287/stsy.2021.0082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the performance of greedy matching algorithms on bipartite graphs G = ( J , D , E ) . We focus primarily on three classical algorithms: RANDOM-EDGE , which sequentially selects random edges from E ; RANDOM-VERTEX , which sequentially matches random vertices in J to random neighbors; and RANKING , which generates a random priority order over vertices in D and then sequentially matches random vertices in J to their highest-priority remaining neighbor. Prior work has focused on identifying the worst-case approximation ratio for each algorithm. This guarantee is highest for RANKING and lowest for RANDOM-EDGE . Our work instead studies the average performance of these algorithms when the edge set E is random. Our first result compares RANDOM-VERTEX and RANDOM-EDGE and shows that on average, RANDOM-VERTEX produces more matches. This result holds for finite graphs (in contrast to previous asymptotic results) and also applies to “many to one” matching in which each vertex in D can match with multiple vertices in J . Our second result compares RANDOM-VERTEX and RANKING and shows that the better worst-case guarantee of RANKING does not translate into better average performance. In “one to one” settings where each vertex in D can match with only one vertex in J , the algorithms result in the same number of matches. When each vertex in D can match with two vertices in J , RANDOM-VERTEX produces more matches than RANKING .},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0082},
  journal      = {Stochastic Systems},
  number       = {2},
  pages        = {133-225},
  shortjournal = {Stoch. Syst.},
  title        = {Greedy matching in bipartite random graphs},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fluid model of an electric vehicle charging network.
<em>STSY</em>, <em>12</em>(2), 133–225. (<a
href="https://doi.org/10.1287/stsy.2021.0084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop and analyze a measure-valued fluid model keeping track of parking and charging requirements of electric vehicles in a local distribution grid. We show how this model arises as an accumulation point of an appropriately scaled sequence of stochastic network models. Our analysis incorporates load-flow models that describe the laws of electricity. Specifically, we consider the alternating current (AC) and the linearized Distflow power flow models and show a continuity property of the associated power allocation functions.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0084},
  journal      = {Stochastic Systems},
  number       = {2},
  pages        = {133-225},
  shortjournal = {Stoch. Syst.},
  title        = {A fluid model of an electric vehicle charging network},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The prelimit generator comparison approach of stein’s
method. <em>STSY</em>, <em>12</em>(2), 133–225. (<a
href="https://doi.org/10.1287/stsy.2021.0085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper uses the generator comparison approach of Stein’s method to analyze the gap between steady-state distributions of Markov chains and diffusion processes. The “standard” generator comparison approach starts with the Poisson equation for the diffusion, and the main technical difficulty is to obtain bounds on the derivatives of the solution to the Poisson equation, also known as Stein factor bounds. In this paper we propose starting with the Poisson equation of the Markov chain; we term this the prelimit approach . Although one still needs Stein factor bounds, they now correspond to finite differences of the Markov chain Poisson equation solution rather than the derivatives of the solution to the diffusion Poisson equation. In certain cases, the former are easier to obtain. We use the M / M / 1 model as a simple working example to illustrate our approach.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0085},
  journal      = {Stochastic Systems},
  number       = {2},
  pages        = {133-225},
  shortjournal = {Stoch. Syst.},
  title        = {The prelimit generator comparison approach of stein’s method},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximations and optimal control for state-dependent
limited processor sharing queues. <em>STSY</em>, <em>12</em>(2),
133–225. (<a href="https://doi.org/10.1287/stsy.2021.0087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper studies approximations and control of a processor sharing (PS) server where the service rate depends on the number of jobs occupying the server. The control of such a system is implemented by imposing a limit on the number of jobs that can share the server concurrently, with the rest of the jobs waiting in a first-in-first-out (FIFO) buffer. A desirable control scheme should strike the right balance between efficiency (operating at a high service rate) and parallelism (preventing small jobs from getting stuck behind large ones). We use the framework of heavy-traffic diffusion analysis to devise near optimal control heuristics for such a queueing system. However, although the literature on diffusion control of state-dependent queueing systems begins with a sequence of systems and an exogenously defined drift function, we begin with a finite discrete PS server and propose an axiomatic recipe to explicitly construct a sequence of state-dependent PS servers that then yields a drift function. We establish diffusion approximations and use them to obtain insightful and closed-form approximations for the original system under a static concurrency limit control policy. We extend our study to control policies that dynamically adjust the concurrency limit. We provide two novel numerical algorithms to solve the associated diffusion control problem. Our algorithms can be viewed as “average cost” iteration: The first algorithm uses binary-search on the average cost, while the second faster algorithm uses Newton-Raphson method for root finding. Numerical experiments demonstrate the accuracy of our approximation for choosing optimal or near-optimal static and dynamic concurrency control heuristics.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0087},
  journal      = {Stochastic Systems},
  number       = {2},
  pages        = {133-225},
  shortjournal = {Stoch. Syst.},
  title        = {Approximations and optimal control for state-dependent limited processor sharing queues},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Call for papers: Service science/stochastic systems joint
special issue. <em>STSY</em>, <em>12</em>(1), 1–131. (<a
href="https://doi.org/10.1287/stsy.2021.0088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0088},
  journal      = {Stochastic Systems},
  number       = {1},
  pages        = {1-131},
  shortjournal = {Stoch. Syst.},
  title        = {Call for papers: Service Science/Stochastic systems joint special issue},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotics of reinforcement learning with neural networks.
<em>STSY</em>, <em>12</em>(1), 1–131. (<a
href="https://doi.org/10.1287/stsy.2021.0072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that a single-layer neural network trained with the Q-learning algorithm converges in distribution to a random ordinary differential equation as the size of the model and the number of training steps become large. Analysis of the limit differential equation shows that it has a unique stationary solution that is the solution of the Bellman equation, thus giving the optimal control for the problem. In addition, we study the convergence of the limit differential equation to the stationary solution. As a by-product of our analysis, we obtain the limiting behavior of single-layer neural networks when trained on independent and identically distributed data with stochastic gradient descent under the widely used Xavier initialization.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0072},
  journal      = {Stochastic Systems},
  number       = {1},
  pages        = {1-131},
  shortjournal = {Stoch. Syst.},
  title        = {Asymptotics of reinforcement learning with neural networks},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Queueing network controls via deep reinforcement learning.
<em>STSY</em>, <em>12</em>(1), 1–131. (<a
href="https://doi.org/10.1287/stsy.2021.0081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel advanced policy gradient (APG) methods, such as trust region policy optimization and proximal policy optimization (PPO), have become the dominant reinforcement learning algorithms because of their ease of implementation and good practical performance. A conventional setup for notoriously difficult queueing network control problems is a Markov decision problem (MDP) that has three features: infinite state space, unbounded costs, and long-run average cost objective. We extend the theoretical framework of these APG methods for such MDP problems. The resulting PPO algorithm is tested on a parallel-server system and large-size multiclass queueing networks. The algorithm consistently generates control policies that outperform state-of-art heuristics in literature in a variety of load conditions from light to heavy traffic. These policies are demonstrated to be near optimal when the optimal policy can be computed. A key to the successes of our PPO algorithm is the use of three variance reduction techniques in estimating the relative value function via sampling. First, we use a discounted relative value function as an approximation of the relative value function. Second, we propose regenerative simulation to estimate the discounted relative value function. Finally, we incorporate the approximating martingale-process method into the regenerative estimator.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0081},
  journal      = {Stochastic Systems},
  number       = {1},
  pages        = {1-131},
  shortjournal = {Stoch. Syst.},
  title        = {Queueing network controls via deep reinforcement learning},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Customer-server population dynamics in heavy traffic.
<em>STSY</em>, <em>12</em>(1), 1–131. (<a
href="https://doi.org/10.1287/stsy.2021.0079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a many-server queueing model with server vacations, where the population size dynamics of servers and customers are coupled: a server may leave for vacation only when no customers await, and the capacity available to customers is directly affected by the number of servers on vacation. We focus on scaling regimes in which server dynamics and queue dynamics fluctuate at matching time scales so that their limiting dynamics are coupled. Specifically, we argue that interesting coupled dynamics occur in (a) the Halfin–Whitt regime, (b) the nondegenerate slowdown regime, and (c) the intermediate near Halfin–Whitt regime, whereas the dynamics asymptotically decouple in the other heavy-traffic regimes. We characterize the limiting dynamics, which are different for each scaling regime. We consider relevant respective performance measures for regimes (a) and (b)—namely, the probability of wait and the slowdown. Although closed-form formulas for these performance measures have been derived for models that do not accommodate server vacations, it is difficult to obtain closed-form formulas for these performance measures in the setting with server vacations. Instead, we propose formulas that approximate these performance measures and depend on the steady-state mean number of available servers and previously derived formulas for models without server vacations. We test the accuracy of these formulas numerically.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0079},
  journal      = {Stochastic Systems},
  number       = {1},
  pages        = {1-131},
  shortjournal = {Stoch. Syst.},
  title        = {Customer-server population dynamics in heavy traffic},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anonymous stochastic routing. <em>STSY</em>, <em>12</em>(1),
1–131. (<a href="https://doi.org/10.1287/stsy.2021.0074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a recipient-anonymous stochastic routing model to study a fundamental trade-off between anonymity and routing delay. An agent wants to quickly reach a goal vertex in a network through a sequence of routing actions, whereas an overseeing adversary observes the agent’s entire trajectory and tries to identify the agent’s goal among those vertices traversed. We are interested in understanding the probability that the adversary can correctly identify the agent’s goal (anonymity) as a function of the time it takes the agent to reach it (delay). A key feature of our model is the presence of intrinsic uncertainty in the environment, so that each of the agent’s intended steps is subject to random perturbation and thus may not materialize as planned. Using large-network asymptotics, our main results provide near-optimal characterization of the anonymity–delay trade-off under a number of network topologies. Our main technical contributions are centered on a new class of “noise-harnessing” routing strategies that adaptively combine intrinsic uncertainty from the environment with additional artificial randomization to achieve provably efficient obfuscation.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0074},
  journal      = {Stochastic Systems},
  number       = {1},
  pages        = {1-131},
  shortjournal = {Stoch. Syst.},
  title        = {Anonymous stochastic routing},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Erratum: “Transform methods for heavy-traffic analysis.”
<em>STSY</em>, <em>12</em>(1), 1–131. (<a
href="https://doi.org/10.1287/stsy.2021.0089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Hurtado-Lange and Maguluri (2020) [Transform methods for heavy-traffic analysis. Stochastic Systems 10(4):275–309], the statement of Claim 4 has a typo; it should say that the expression therein is bounded by a constant. The statement of Lemma 11, and Lemma 14 is incorrect. The lemmas should show the existence of the moment generating function in an interval around the origin with the length being independent of the heavy-traffic parameter. The correct statements and proofs are provided.},
  archive      = {J_STSY},
  doi          = {10.1287/stsy.2021.0089},
  journal      = {Stochastic Systems},
  number       = {1},
  pages        = {1-131},
  shortjournal = {Stoch. Syst.},
  title        = {Erratum: “Transform methods for heavy-traffic analysis”},
  volume       = {12},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
