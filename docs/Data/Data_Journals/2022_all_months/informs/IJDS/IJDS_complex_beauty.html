<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJDS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijds---17">IJDS - 17</h2>
<ul>
<li><details>
<summary>
(2022). Compressed smooth sparse decomposition. <em>IJDS</em>,
<em>2</em>(1), 60–80. (<a
href="https://doi.org/10.1287/ijds.2022.0023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based anomaly detection systems are of vital importance in various manufacturing applications. The resolution and acquisition rate of such systems are increasing significant in recent years under the fast development of image sensing technology. This enables the detection of tiny anomalies in real time. However, such a high resolution and a high acquisition rate of image data not only slow down the speed of image processing algorithms but also, increase data storage and transmission cost. To tackle this problem, we propose a fast and data-efficient method with theoretical performance guarantee that is suitable for sparse anomaly detection in images with a smooth background (smooth plus sparse signal). The proposed method, named compressed smooth sparse decomposition (CSSD), is a one-step method that unifies the compressive image acquisition- and decomposition-based image processing techniques. To further enhance its performance in a high-dimensional scenario, a Kronecker compressed smooth sparse decomposition (KronCSSD) method is proposed. Compared with traditional smooth and sparse decomposition algorithms, significant transmission cost reduction and computational speed boost can be achieved with negligible performance loss. Simulation examples and several case studies in various applications illustrate the effectiveness of the proposed framework.},
  archive      = {J_IJDS},
  author       = {Shancong Mou and Jianjun Shi},
  doi          = {10.1287/ijds.2022.0023},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {60-80},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Compressed smooth sparse decomposition},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GIFAIR-FL: A framework for group and individual fairness in
federated learning. <em>IJDS</em>, <em>2</em>(1), 10–23. (<a
href="https://doi.org/10.1287/ijds.2022.0022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose GIFAIR-FL, a framework that imposes group and individual fairness (GIFAIR) to federated learning (FL) settings. By adding a regularization term, our algorithm penalizes the spread in the loss of client groups to drive the optimizer to fair solutions. Our framework GIFAIR-FL can accommodate both global and personalized settings. Theoretically, we show convergence in nonconvex and strongly convex settings. Our convergence guarantees hold for both independent and identically distributed (i.i.d.) and non-i.i.d. data. To demonstrate the empirical performance of our algorithm, we apply our method to image classification and text prediction tasks. Compared with existing algorithms, our method shows improved fairness results while retaining superior or similar prediction accuracy.},
  archive      = {J_IJDS},
  author       = {Xubo Yue and Maher Nouiehed and Raed Al Kontar},
  doi          = {10.1287/ijds.2022.0022},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {10-23},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {GIFAIR-FL: A framework for group and individual fairness in federated learning},
  volume       = {2},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Commentary on “visualization in operations management
research.” <em>IJDS</em>, <em>1</em>(2), 194–195. (<a
href="https://doi.org/10.1287/ijds.2022.0014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This commentary paper highlights the merits of appropriate use of visualization tools in the original paper and summarizes potential research topics of visualization for operations management problems.},
  archive      = {J_IJDS},
  author       = {Ran Jin},
  doi          = {10.1287/ijds.2022.0014},
  journal      = {INFORMS Journal on Data Science},
  number       = {2},
  pages        = {194-195},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Commentary on “Visualization in operations management research”},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Commentary on “visualization in operations management
research”: Incorporating statistical thinking into visualization
practices for decision making in operational management. <em>IJDS</em>,
<em>1</em>(2), 188–191. (<a
href="https://doi.org/10.1287/ijds.2021.0008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supplemental Material: The software that supports this study and helped produce the figures are available within the paper at https://doi.org/10.1287/ijds.2021.0008 or are supplied at https://emitanaka.org/supp-visOM/, or the same version at Code Ocean available here http://doi.org/10.24433/CO.2743770.v1.},
  archive      = {J_IJDS},
  author       = {Emi Tanaka and Jessica Wai Yin Leung and Dianne Cook},
  doi          = {10.1287/ijds.2021.0008},
  journal      = {INFORMS Journal on Data Science},
  number       = {2},
  pages        = {188-191},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Commentary on “Visualization in operations management research”: Incorporating statistical thinking into visualization practices for decision making in operational management},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust approach to quantifying uncertainty in matching
problems of causal inference. <em>IJDS</em>, <em>1</em>(2), 156–171. (<a
href="https://doi.org/10.1287/ijds.2022.0020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unquantified sources of uncertainty in observational causal analyses can break the integrity of the results. One would never want another analyst to repeat a calculation with the same data set, using a seemingly identical procedure, only to find a different conclusion. However, as we show in this work, there is a typical source of uncertainty that is essentially never considered in observational causal studies: the choice of match assignment for matched groups—that is, which unit is matched to which other unit before a hypothesis test is conducted. The choice of match assignment is anything but innocuous and can have a surprisingly large influence on the causal conclusions. Given that a vast number of causal inference studies test hypotheses on treatment effects after treatment cases are matched with similar control cases, we should find a way to quantify how much this extra source of uncertainty impacts results. What we would really like to be able to report is that no matter which match assignment is made, as long as the match is sufficiently good, then the hypothesis test results are still informative. In this paper, we provide methodology based on discrete optimization to create robust tests that explicitly account for this possibility. We formulate robust tests for binary and continuous data based on common test statistics as integer linear programs solvable with common methodologies. We study the finite-sample behavior of our test statistic in the discrete-data case. We apply our methods to simulated and real-world data sets and show that they can produce useful results in practical applied settings.},
  archive      = {J_IJDS},
  author       = {Marco Morucci and Md. Noor-E-Alam and Cynthia Rudin},
  doi          = {10.1287/ijds.2022.0020},
  journal      = {INFORMS Journal on Data Science},
  number       = {2},
  pages        = {156-171},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {A robust approach to quantifying uncertainty in matching problems of causal inference},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Achieving reliable causal inference with data-mined
variables: A random forest approach to the measurement error problem.
<em>IJDS</em>, <em>1</em>(2), 138–155. (<a
href="https://doi.org/10.1287/ijds.2022.0019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining machine learning with econometric analysis is becoming increasingly prevalent in both research and practice. A common empirical strategy uses predictive modeling techniques to “mine” variables of interest from available data and then includes those variables into an econometric framework to estimate causal effects. However, because the predictions from machine learning models are inevitably imperfect, econometric analyses based on the predicted variables likely suffer from bias due to measurement error. We propose a novel approach to mitigate these biases, leveraging the random forest technique. We propose using random forest not just for prediction but also for generating instrumental variables for bias correction. The random forest algorithm performs best when comprised of a set of trees that are individually accurate in their predictions, yet which also make “different” mistakes, that is, have weakly correlated prediction errors. A key observation is that these properties are closely related to the relevance and exclusion requirements of valid instrumental variables. We design a data-driven procedure to select tuples of individual trees from a random forest, in which one tree serves as the endogenous covariate and the others serve as its instruments. Simulation experiments demonstrate its efficacy in mitigating estimation biases and its superior performance over alternative methods.},
  archive      = {J_IJDS},
  author       = {Mochen Yang and Edward McFowland, III and Gordon Burtch and Gediminas Adomavicius},
  doi          = {10.1287/ijds.2022.0019},
  journal      = {INFORMS Journal on Data Science},
  number       = {2},
  pages        = {138-155},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Achieving reliable causal inference with data-mined variables: A random forest approach to the measurement error problem},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weakly supervised multi-output regression via correlated
gaussian processes. <em>IJDS</em>, <em>1</em>(2), 115–137. (<a
href="https://doi.org/10.1287/ijds.2022.0018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-output regression seeks to borrow strength and leverage commonalities across different but related outputs in order to enhance learning and prediction accuracy. A fundamental assumption is that the output/group membership labels for all observations are known. This assumption is often violated in real applications. For instance, in healthcare data sets, sensitive attributes such as ethnicity are often missing or unreported. To this end, we introduce a weakly supervised multi-output model based on dependent Gaussian processes. Our approach is able to leverage data without complete group labels or possibly only prior belief on group memberships to enhance accuracy across all outputs. Through intensive simulations and case studies on insulin, testosterone and body fat data sets, we show that our model excels in multi-output settings with missing labels while being competitive in traditional fully labeled settings. We end by highlighting the possible use of our approach in fair inference and sequential decision making.},
  archive      = {J_IJDS},
  author       = {Seokhyun Chung and Raed Al Kontar and Zhenke Wu},
  doi          = {10.1287/ijds.2022.0018},
  journal      = {INFORMS Journal on Data Science},
  number       = {2},
  pages        = {115-137},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Weakly supervised multi-output regression via correlated gaussian processes},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial board. <em>IJDS</em>, <em>1</em>(1), C2. (<a
href="https://doi.org/10.1287/ijds.2022.eb.v1n1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDS},
  doi          = {10.1287/ijds.2022.eb.v1n1},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {C2},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Editorial board},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HeBERT and HebEMO: A hebrew BERT model and a tool for
polarity analysis and emotion recognition. <em>IJDS</em>, <em>1</em>(1),
81–95. (<a href="https://doi.org/10.1287/ijds.2022.0016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis of user-generated content (UGC) can provide valuable information across numerous domains, including marketing, psychology, and public health. Currently, there are very few Hebrew models for natural language processing in general, and for sentiment analysis in particular; indeed, it is not straightforward to develop such models because Hebrew is a morphologically rich language (MRL) with challenging characteristics. Moreover, the only available Hebrew sentiment analysis model, based on a recurrent neural network, was developed for polarity analysis (classifying text as positive, negative, or neutral) and was not used for detection of finer-grained emotions (e.g., anger, fear, or joy). To address these gaps, this paper introduces HeBERT and HebEMO. HeBERT is a transformer-based model for modern Hebrew text, which relies on a BERT (bidirectional encoder representations from transformers) architecture. BERT has been shown to outperform alternative architectures in sentiment analysis and is suggested to be particularly appropriate for MRLs. Analyzing multiple BERT specifications, we find that whereas model complexity correlates with high performance on language tasks that aim to understand terms in a sentence, a more parsimonious model better captures the sentiment of an entire sentence. Notably, regardless of the complexity of the BERT specification, our BERT-based language model outperforms all existing Hebrew alternatives on all language tasks examined. HebEMO is a tool that uses HeBERT to detect polarity and extract emotions from Hebrew UGC. HebEMO is trained on a unique COVID-19-related UGC data set that we collected and annotated for this study. Data collection and annotation followed an active learning procedure that aimed to maximize predictability. We show that HebEMO yields a better performance accuracy for polarity classification. Emotion detection reaches high performance for various target emotions, with the exception of surprise, which the model failed to capture. These results are better than the best reported performance, even among English-language models of emotion detection.},
  archive      = {J_IJDS},
  author       = {Avihay Chriqui and Inbal Yahav},
  doi          = {10.1287/ijds.2022.0016},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {81-95},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {HeBERT and HebEMO: A hebrew BERT model and a tool for polarity analysis and emotion recognition},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing prediction intervals using the likelihood ratio
statistic. <em>IJDS</em>, <em>1</em>(1), 63–80. (<a
href="https://doi.org/10.1287/ijds.2021.0007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical prediction plays an important role in many decision processes, such as university budgeting (depending on the number of students who will enroll), capital budgeting (depending on the remaining lifetime of a fleet of systems), the needed amount of cash reserves for warranty expenses (depending on the number of warranty returns), and whether a product recall is needed (depending on the number of potentially life-threatening product failures). In statistical inference, likelihood ratios have a long history of use for decision making relating to model parameters (e.g., in evidence-based medicine and forensics). We propose a general prediction method, based on a likelihood ratio (LR) involving both the data and a future random variable. This general approach provides a way to identify prediction interval methods that have excellent statistical properties. For example, if a prediction method can be based on a pivotal quantity, our LR-based method will often identify it. For applications where a pivotal quantity does not exist, the LR-based method provides a procedure with good coverage properties for both continuous or discrete-data prediction applications.},
  archive      = {J_IJDS},
  author       = {Qinglong Tian and Daniel J. Nordman and William Q. Meeker},
  doi          = {10.1287/ijds.2021.0007},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {63-80},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Constructing prediction intervals using the likelihood ratio statistic},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adapting reinforcement learning treatment policies using
limited data to personalize critical care. <em>IJDS</em>, <em>1</em>(1),
27–49. (<a href="https://doi.org/10.1287/ijds.2022.0015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) demonstrates promise for developing effective treatment policies in critical care settings. However, existing RL methods often require large and comprehensive patient data sets and do not readily lend themselves to settings in which certain patient subpopulations are severely underrepresented. In this study, we develop a new method, noisy Bayesian policy updates (NBPU), for selecting high-performing reinforcement learning–based treatment policies for underrepresented patient subpopulations using limited observations. Our method uses variational inference to learn a probability distribution over treatment policies based on a reference patient subpopulation for which sufficient data are available. It then exploits limited data from an underrepresented patient subpopulation to update this probability distribution and adapts its recommendations to this subpopulation. We demonstrate our method’s utility on a data set of ICU patients receiving intravenous blood anticoagulant medication. Our results show that NBPU outperforms state-of-the-art methods in terms of both selecting effective treatment policies for patients with nontypical clinical characteristics and predicting the corresponding policies’ performance for these patients.},
  archive      = {J_IJDS},
  author       = {Matt Baucum and Anahita Khojandi and Rama Vasudevan and Robert Davis},
  doi          = {10.1287/ijds.2022.0015},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {27-49},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Adapting reinforcement learning treatment policies using limited data to personalize critical care},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Rejoinder to “causal decision making and causal effect
estimation are not the same…and why it matters.” <em>IJDS</em>,
<em>1</em>(1), 23–26. (<a
href="https://doi.org/10.1287/ijds.2022.0013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We thank Dean Eckles, Edward McFowland III, and Uri Shalit for their valuable commentaries (Eckles 2022, McFowland 2022, Shalit 2022). This note takes a closer look at several of the main points they raised, especially those related to future research on data science for businesses and other organizations.},
  archive      = {J_IJDS},
  author       = {Carlos Fernández-Loría and Foster Provost},
  doi          = {10.1287/ijds.2022.0013},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {23-26},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Rejoinder to “Causal decision making and causal effect estimation are not the same…and why it matters”},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Commentary on “causal decision making and causal effect
estimation are not the same… and why it matters.” <em>IJDS</em>,
<em>1</em>(1), 21–22. (<a
href="https://doi.org/10.1287/ijds.2021.0010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDS},
  author       = {Edward McFowland III},
  doi          = {10.1287/ijds.2021.0010},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {21-22},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Commentary on “Causal decision making and causal effect estimation are not the same… and why it matters”},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Commentary on “causal decision making and causal effect
estimation are not the same…and why it matters.” <em>IJDS</em>,
<em>1</em>(1), 19–20. (<a
href="https://doi.org/10.1287/ijds.2022.0011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDS},
  author       = {Uri Shalit},
  doi          = {10.1287/ijds.2022.0011},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {19-20},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Commentary on “Causal decision making and causal effect estimation are not the same…and why it matters”},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Commentary on “causal decision making and causal effect
estimation are not the same…and why it matters”: On loss functions and
bias–variance tradeoffs in causal estimation and decisions.
<em>IJDS</em>, <em>1</em>(1), 17–18. (<a
href="https://doi.org/10.1287/ijds.2022.0012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDS},
  author       = {Dean Eckles},
  doi          = {10.1287/ijds.2022.0012},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {17-18},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Commentary on “Causal decision making and causal effect estimation are not the same…and why it matters”: On loss functions and Bias–Variance tradeoffs in causal estimation and decisions},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Causal decision making and causal effect estimation are not
the same…and why it matters. <em>IJDS</em>, <em>1</em>(1), 4–16. (<a
href="https://doi.org/10.1287/ijds.2021.0006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal decision making (CDM) at scale has become a routine part of business, and increasingly, CDM is based on statistical models and machine learning algorithms. Businesses algorithmically target offers, incentives, and recommendations to affect consumer behavior. Recently, we have seen an acceleration of research related to CDM and causal effect estimation (CEE) using machine-learned models. This article highlights an important perspective: CDM is not the same as CEE, and counterintuitively, accurate CEE is not necessary for accurate CDM. Our experience is that this is not well understood by practitioners or most researchers. Technically, the estimand of interest is different, and this has important implications both for modeling and for the use of statistical models for CDM. We draw on recent research to highlight three implications. (1) We should carefully consider the objective function of the causal machine learning, and if possible, optimize for accurate “treatment assignment” rather than for accurate effect-size estimation. (2) Confounding affects CDM and CEE differently. The upshot here is that for supporting CDM it may be just as good or even better to learn with confounded data as with unconfounded data. (3) Causal statistical modeling may not be necessary at all to support CDM because a proxy target for statistical modeling might do as well or better. This third observation helps to explain at least one broad common CDM practice that seems “wrong” at first blush—the widespread use of noncausal models for targeting interventions. The last two implications are particularly important in practice, as acquiring (unconfounded) data on both “sides” of the counterfactual for modeling can be quite costly and often impracticable. These observations open substantial research ground. We hope to facilitate research in this area by pointing to related articles from multiple contributing fields, most of them written in the last five years.},
  archive      = {J_IJDS},
  author       = {Carlos Fernández-Loría and Foster Provost},
  doi          = {10.1287/ijds.2021.0006},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {4-16},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Causal decision making and causal effect estimation are not the same…and why it matters},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Congratulations, it’s our inaugural issue! <em>IJDS</em>,
<em>1</em>(1), 1–3. (<a
href="https://doi.org/10.1287/ijds.2022.0017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDS},
  author       = {Galit Shmueli},
  doi          = {10.1287/ijds.2022.0017},
  journal      = {INFORMS Journal on Data Science},
  number       = {1},
  pages        = {1-3},
  shortjournal = {INFORMS J. Data Sci.},
  title        = {Congratulations, it’s our inaugural issue!},
  volume       = {1},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
