<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JBES_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jbes---169">JBES - 169</h2>
<ul>
<li><details>
<summary>
(2022). Factor and factor loading augmented estimators for panel
regression with possibly nonstrong factors. <em>JBES</em>,
<em>41</em>(1), 270–281. (<a
href="https://doi.org/10.1080/07350015.2021.2011300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers linear panel data models where the dependence of the regressors and the unobservables is modeled through a factor structure. The number of time periods and the sample size both go to infinity. Unlike in most existing methods for the estimation of this type of models, nonstrong factors are allowed and the number of factors can grow to infinity with the sample size. We study a class of two-step estimators of the regression coefficients. In the first step, factors and factor loadings are estimated. Then, the second step corresponds to the panel regression of the outcome on the regressors and the estimates of the factors and the factor loadings from the first step. The estimators enjoy double robustness. Different methods can be used in the first step while the second step is unique. We derive sufficient conditions on the first-step estimator and the data generating process under which the two-step estimator is asymptotically normal. Assumptions under which using an approach based on principal components analysis in the first step yields an asymptotically normal estimator are also given. The two-step procedure exhibits good finite sample properties in simulations. The approach is illustrated by an empirical application on fiscal policy.},
  archive      = {J_JBES},
  author       = {Jad Beyhum and Eric Gautier},
  doi          = {10.1080/07350015.2021.2011300},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {270-281},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Factor and factor loading augmented estimators for panel regression with possibly nonstrong factors},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extreme value estimation for heterogeneous data.
<em>JBES</em>, <em>41</em>(1), 255–269. (<a
href="https://doi.org/10.1080/07350015.2021.2008408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a universal econometric formulation of empirical power laws possibly driven by parameter heterogeneity. Our approach extends classical extreme value theory to specifying the tail behavior of the empirical distribution of a general dataset with possibly heterogeneous marginal distributions. We discuss several model examples that satisfy our conditions and demonstrate in simulations how heterogeneity may generate empirical power laws. We observe a cross-sectional power law for the U.S. stock losses and show that this tail behavior is largely driven by the heterogeneous volatilities of the individual assets.},
  archive      = {J_JBES},
  author       = {John H. J. Einmahl and Yi He},
  doi          = {10.1080/07350015.2021.2008408},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {255-269},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Extreme value estimation for heterogeneous data},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bootstrap tests for high-dimensional white-noise.
<em>JBES</em>, <em>41</em>(1), 241–254. (<a
href="https://doi.org/10.1080/07350015.2021.2008407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The testing of white-noise (WN) is an essential step in time series analysis. In a high dimensional set-up, most existing methods either are computationally infeasible, or suffer from highly distorted Type-I errors, or both. We propose an easy-to-implement bootstrap method for high-dimensional WN test and prove its consistency for a variety of test statistics. Its power properties as well as extensions to WN tests based on fitted residuals are also considered. Simulation results show that compared to the existing methods, the new approach possesses much better power, while maintaining a proper control over the Type-I error. They also provide proofs that even in cases where our method is expected to suffer from lack of theoretical justification, it continues to outperform its competitors. The proposed method is applied to the analysis of the daily stock returns of the top 50 companies by market capitalization listed on the NYSE, and we find strong evidence that the common market factor is the main cause of cross-correlation between stocks.},
  archive      = {J_JBES},
  author       = {Lengyang Wang and Efang Kong and Yingcun Xia},
  doi          = {10.1080/07350015.2021.2008407},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {241-254},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bootstrap tests for high-dimensional white-noise},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for structural change of predictive regression model
to threshold predictive regression model. <em>JBES</em>, <em>41</em>(1),
228–240. (<a
href="https://doi.org/10.1080/07350015.2021.2008406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates two test statistics for testing structural changes and thresholds in predictive regression models. The generalized likelihood ratio (GLR) test is proposed for the stationary predictor and the generalized F test is suggested for the persistent predictor. Under the null hypothesis of no structural change and threshold, it is shown that the GLR test statistic converges to a function of a centered Gaussian process, and the generalized F test statistic converges to a function of Brownian motions. A Bootstrap method is proposed to obtain the critical values of test statistics. Simulation studies and a real example are given to assess the performances of the proposed tests.},
  archive      = {J_JBES},
  author       = {Fukang Zhu and Mengya Liu and Shiqing Ling and Zongwu Cai},
  doi          = {10.1080/07350015.2021.2008406},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {228-240},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for structural change of predictive regression model to threshold predictive regression model},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Estimation of sparsity-induced weak factor models.
<em>JBES</em>, <em>41</em>(1), 213–227. (<a
href="https://doi.org/10.1080/07350015.2021.2008405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates estimation of sparsity-induced weak factor (sWF) models, with large cross-sectional and time-series dimensions ( N and T , respectively). It assumes that the k th largest eigenvalue of a data covariance matrix grows proportionally to N α k N α k Nαk with unknown exponents 0 &lt; α k ≤ 1 0 &lt; α k ≤ 1 0&amp;lt;αk≤1 for k = 1 , … , r k = 1 , … , r k=1,…,r . Employing the same rotation of the principal components (PC) estimator, the growth rate α k is linked to the degree of sparsity of k th factor loadings. This is much weaker than the typical assumption on the recent factor models, in which all the r largest eigenvalues diverge proportionally to N . We apply the method of sparse orthogonal factor regression (SOFAR) by Uematsu et al. ( Citation 2019 ) to estimate the sWF models and derive the estimation error bound. Importantly, our method also yields consistent estimation of α k . A finite sample experiment shows that the performance of the new estimator uniformly dominates that of the PC estimator. We apply our method to forecasting bond yields and the results demonstrate that our method outperforms that based on the PC. We also analyze S&amp;P500 firm security returns and find that the first factor is consistently near strong while the others are weak.},
  archive      = {J_JBES},
  author       = {Yoshimasa Uematsu and Takashi Yamagata},
  doi          = {10.1080/07350015.2021.2008405},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {213-227},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimation of sparsity-induced weak factor models},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Survey response behavior as a proxy for unobserved ability:
Theory and evidence. <em>JBES</em>, <em>41</em>(1), 197–212. (<a
href="https://doi.org/10.1080/07350015.2021.2008404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An emerging literature is experimenting with using survey response behavior as a proxy for hard-to-measure abilities. We contribute to this literature by formalizing this idea and evaluating its benefits and risks. Using a standard and nationally representative survey from Australia, we demonstrate that the survey item-response rate (SIRR), a straightforward summary measure of response behavior, varies more with cognitive than with noncognitive ability. We evaluate whether SIRR is a useful proxy to reduce ability-related biases in a standard economic application. We show empirically that SIRR, although a weak and imperfect proxy, leads to omitted-variable bias reductions of up to 20\%, and performs better than other proxy variables derived from paradata. Deriving the necessary and sufficient conditions for a valid proxy, we show that a strong proxy is neither a necessary nor a sufficient condition to reduce estimation biases. A critical consideration is to which degree the proxy introduces a multicollinearity problem, a finding of general interest. We illustrate the theoretical derivations with an empirical application.},
  archive      = {J_JBES},
  author       = {Sonja C. de New and Stefanie Schurer},
  doi          = {10.1080/07350015.2021.2008404},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {197-212},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Survey response behavior as a proxy for unobserved ability: Theory and evidence},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Test for market timing using daily fund returns.
<em>JBES</em>, <em>41</em>(1), 184–196. (<a
href="https://doi.org/10.1080/07350015.2021.2006670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using daily mutual fund returns to estimate market timing, some econometric issues, including heteroscedasticity, correlated errors, and heavy tails, make the traditional least-squares estimate in Treynor–Mazuy and Henriksson–Merton models biased and severely distort the t -test size. Using ARMA-GARCH models, weighted least-squares estimate to ensure a normal limit, and random weighted bootstrap method to quantify uncertainty, we find more funds with positive timing ability than the Newey–West t -test. Empirical evidence indicates that funds with perverse timing ability have high fund turnovers and funds tradeoff between timing and stock picking skills.},
  archive      = {J_JBES},
  author       = {Lei Jiang and Weimin Liu and Liang Peng},
  doi          = {10.1080/07350015.2021.2006670},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {184-196},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Test for market timing using daily fund returns},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time series approach to the evolution of networks:
Prediction and estimation. <em>JBES</em>, <em>41</em>(1), 170–183. (<a
href="https://doi.org/10.1080/07350015.2021.2006669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article analyzes nonnegative multivariate time series which we interpret as weighted networks. We introduce a model where each coordinate of the time series represents a given edge across time. The number of time periods is treated as large compared to the size of the network. The model specifies the temporal evolution of a weighted network that combines classical autoregression with nonnegativity, a positive probability of vanishing, and peer effect interactions between weights assigned to edges in the process. The main results provide criteria for stationarity versus explosiveness of the network evolution process and techniques for estimation of the parameters of the model and for prediction of its future values. Natural applications arise in networks of fixed number of agents, such as countries, large corporations, or small social communities. The article provides an empirical implementation of the approach to monthly trade data in European Union. Overall, the results confirm that incorporating nonnegativity of dependent variables into the model matters and incorporating peer effects leads to the improved prediction power.},
  archive      = {J_JBES},
  author       = {Anna Bykhovskaya},
  doi          = {10.1080/07350015.2021.2006669},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {170-183},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Time series approach to the evolution of networks: Prediction and estimation},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kernel averaging estimators. <em>JBES</em>, <em>41</em>(1),
157–169. (<a
href="https://doi.org/10.1080/07350015.2021.2006668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of bandwidth selection is a fundamental model selection problem stemming from the uncertainty about the smoothness of the regression. In this article, we advocate a model averaging approach to circumvent the problem caused by this uncertainty. Our new approach involves averaging across a series of Nadaraya-Watson kernel estimators each under a different bandwidth, with weights for these different estimators chosen such that a least-squares cross-validation criterion is minimized. We prove that the resultant combined-kernel estimator achieves the smallest possible asymptotic aggregate squared error. The superiority of the new estimator over estimators based on widely accepted conventional bandwidth choices in finite samples is demonstrated in a simulation study and a real data example.},
  archive      = {J_JBES},
  author       = {Rong Zhu and Xinyu Zhang and Alan T. K. Wan and Guohua Zou},
  doi          = {10.1080/07350015.2021.2006668},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {157-169},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Kernel averaging estimators},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal shrinkage-based portfolio selection in high
dimensions. <em>JBES</em>, <em>41</em>(1), 140–156. (<a
href="https://doi.org/10.1080/07350015.2021.2004897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we estimate the mean-variance portfolio in the high-dimensional case using the recent results from the theory of random matrices. We construct a linear shrinkage estimator which is distribution-free and is optimal in the sense of maximizing with probability 1 the asymptotic out-of-sample expected utility, that is, mean-variance objective function for different values of risk aversion coefficient which in particular leads to the maximization of the out-of-sample expected utility and to the minimization of the out-of-sample variance. One of the main features of our estimator is the inclusion of the estimation risk related to the sample mean vector into the high-dimensional portfolio optimization. The asymptotic properties of the new estimator are investigated when the number of assets p and the sample size n tend simultaneously to infinity such that p / n → c ∈ ( 0 , + ∞ ) . The results are obtained under weak assumptions imposed on the distribution of the asset returns, namely the existence of the 4 + ε moments is only required. Thereafter we perform numerical and empirical studies where the small- and large-sample behavior of the derived estimator is investigated. The suggested estimator shows significant improvements over the existent approaches including the nonlinear shrinkage estimator and the three-fund portfolio rule, especially when the portfolio dimension is larger than the sample size. Moreover, it is robust to deviations from normality.},
  archive      = {J_JBES},
  author       = {Taras Bodnar and Yarema Okhrin and Nestor Parolya},
  doi          = {10.1080/07350015.2021.2004897},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {140-156},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Optimal shrinkage-based portfolio selection in high dimensions},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Inference in sparsity-induced weak factor models.
<em>JBES</em>, <em>41</em>(1), 126–139. (<a
href="https://doi.org/10.1080/07350015.2021.2003203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider statistical inference for high-dimensional approximate factor models. We posit a weak factor structure, in which the factor loading matrix can be sparse and the signal eigenvalues may diverge more slowly than the cross-sectional dimension, N . We propose a novel inferential procedure to decide whether each component of the factor loadings is zero or not, and prove that this controls the false discovery rate (FDR) below a preassigned level, while the power tends to unity. This “factor selection” procedure is primarily based on a debiased version of the sparse orthogonal factor regression (SOFAR) estimator; but is also applicable to the principal component (PC) estimator. After the factor selection, the resparsified SOFAR and sparsified PC estimators are proposed and their consistency is established. Finite sample evidence supports the theoretical results. We apply our method to the FRED-MD dataset of macroeconomic variables and the monthly firm-level excess returns which constitute the S&amp;P 500 index. The results give very strong statistical evidence of sparse factor loadings under the identification restrictions and exhibit clear associations of factors and categories of the variables. Furthermore, our method uncovers a very weak but statistically significant factor in the residuals of Fama-French five factor regression.},
  archive      = {J_JBES},
  author       = {Yoshimasa Uematsu and Takashi Yamagata},
  doi          = {10.1080/07350015.2021.2003203},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {126-139},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inference in sparsity-induced weak factor models},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing error distribution by kernelized stein discrepancy
in multivariate time series models. <em>JBES</em>, <em>41</em>(1),
111–125. (<a
href="https://doi.org/10.1080/07350015.2021.2002160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing the error distribution is important in many multivariate time series applications. To alleviate the risk of error distribution mis-specification, testing methodologies are needed to detect whether the chosen error distribution is correct. However, the majority of existing tests only deal with the multivariate normal distribution for some special multivariate time series models, and thus cannot be used for testing the often observed heavy-tailed and skewed error distributions in applications. In this article, we construct a new consistent test for general multivariate time series models, based on the kernelized Stein discrepancy. To account for the estimation uncertainty and unobserved initial values, a bootstrap method is provided to calculate the critical values. Our new test is easy-to-implement for a large scope of multivariate error distributions, and its importance is illustrated by simulated and real data. As an extension, we also show how to test for the error distribution in copula time series models.},
  archive      = {J_JBES},
  author       = {Donghang Luo and Ke Zhu and Huan Gong and Dong Li},
  doi          = {10.1080/07350015.2021.2002160},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {111-125},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing error distribution by kernelized stein discrepancy in multivariate time series models},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal covariate balancing conditions in propensity score
estimation. <em>JBES</em>, <em>41</em>(1), 97–110. (<a
href="https://doi.org/10.1080/07350015.2021.2002159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse probability of treatment weighting (IPTW) is a popular method for estimating the average treatment effect (ATE). However, empirical studies show that the IPTW estimators can be sensitive to the misspecification of the propensity score model. To address this problem, researchers have proposed to estimate propensity score by directly optimizing the balance of pretreatment covariates. While these methods appear to empirically perform well, little is known about how the choice of balancing conditions affects their theoretical properties. To fill this gap, we first characterize the asymptotic bias and efficiency of the IPTW estimator based on the covariate balancing propensity score (CBPS) methodology under local model misspecification. Based on this analysis, we show how to optimally choose the covariate balancing functions and propose an optimal CBPS-based IPTW estimator. This estimator is doubly robust; it is consistent for the ATE if either the propensity score model or the outcome model is correct. In addition, the proposed estimator is locally semiparametric efficient when both models are correctly specified. To further relax the parametric assumptions, we extend our method by using a sieve estimation approach. We show that the resulting estimator is globally efficient under a set of much weaker assumptions and has a smaller asymptotic bias than the existing estimators. Finally, we evaluate the finite sample performance of the proposed estimators via simulation and empirical studies. An open-source software package is available for implementing the proposed methods.},
  archive      = {J_JBES},
  author       = {Jianqing Fan and Kosuke Imai and Inbeom Lee and Han Liu and Yang Ning and Xiaolin Yang},
  doi          = {10.1080/07350015.2021.2002159},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {97-110},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Optimal covariate balancing conditions in propensity score estimation},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Panel stochastic frontier model with endogenous inputs and
correlated random components. <em>JBES</em>, <em>41</em>(1), 80–96. (<a
href="https://doi.org/10.1080/07350015.2021.2001341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider a panel stochastic frontier model in which the composite error term ε i t ε i t εit has four components, that is, ε i t = τ i − η i + v i t − u i t ε i t = τ i − η i + v i t − u i t εit=τi−ηi+vit−uit , where η i and u it are persistent and transient inefficiency components, τ i consists of the random firm effects and v it is the random noise. Two distinguishing features of the proposed model are (i) the inputs are allowed to be correlated with one or more of the error components in the production function; (ii) time-invariant and time-varying components, that is, ( τ i − η i ) and ( v i t − u i t ), are allowed to be correlated. To keep the formulation general, we do not specify whether this correlation comes from the correlations between (i) η i and u it , (ii) τ i and u it , (iii) τ i and v it , (iv) η i and v it , or some other combination of them. Further, we also consider the case when the correlation in the composite error arises from the time dependence of ε i t . To estimate the model parameters and predict (in)efficiency, we propose a two-step procedure. In the first step, either the within or the first difference transformation that eliminates the time-invariant components is proposed. We then use either the 2SLS or the GMM approach to obtain unbiased and consistent estimators of the parameters in the frontier function, except for the intercept. In the second step, the maximum simulated likelihood method is used to estimate the parameters associated with the distributions of τ i and v it , η i and u it as well as the intercept. The copula approach is used in this step to model the dependence between the time-varying and time-invariant components. Formulas to predict transient and persistent (in)efficiency are also derived. Finally, results from both simulated and real data are provided.},
  archive      = {J_JBES},
  author       = {Lai Hung-pin and Subal C. Kumbhakar},
  doi          = {10.1080/07350015.2021.2001341},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {80-96},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Panel stochastic frontier model with endogenous inputs and correlated random components},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Composite index construction with expert opinion.
<em>JBES</em>, <em>41</em>(1), 67–79. (<a
href="https://doi.org/10.1080/07350015.2021.2000418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composite index is a powerful and popularly used tool in providing an overall measure of a subject by summarizing a group of measurements (component indices) of different aspects of the subject. It is widely used in economics, finance, policy evaluation, performance ranking, and many other fields. Effective construction of a composite index has been studied extensively. The most widely used approach is to use a linear combination of the component indices, where the combination weights are determined by optimizing an objective function. To maximize the overall variation of the resulting composite index, the combination weights can be obtained through principal component analysis. In this article, we propose to incorporate expert opinions into the construction of the composite index. It is noted that expert opinion often provides useful information in assessing which of the component indices are more important for the overall measure of the subject. We consider the case that a group of experts have been consulted, each providing a set of importance scores for the component indices, along with a set of confidence scores which reflects the expert’s own confidence in his/her assessment. In addition, the constructor of the composite index can also provide an assessment of the expertise level of each expert. We use linear combinations to construct the composite index, where the combination weights are determined by maximizing the sum of resulting composite index variation and the negative weighted sum of squares of deviation between the combination weights used and the experts’ scores. A data-driven approach is used to find the optimal balance between the two sources of information. Theoretical properties of the procedure are investigated. Simulation examples and an economic application on constructing science and technology development index is carried out to illustrate the proposed method.},
  archive      = {J_JBES},
  author       = {Rong Chen and Yuanyuan Ji and Guolin Jiang and Han Xiao and Ruoqing Xie and Pingfang Zhu},
  doi          = {10.1080/07350015.2021.2000418},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {67-79},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Composite index construction with expert opinion},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Volatility estimation when the zero-process is
nonstationary. <em>JBES</em>, <em>41</em>(1), 53–66. (<a
href="https://doi.org/10.1080/07350015.2021.1999821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial returns are frequently nonstationary due to the nonstationary distribution of zeros. In daily stock returns, for example, the nonstationarity can be due to an upwards trend in liquidity over time, which may lead to a downwards trend in the zero-probability. In intraday returns, the zero-probability may be periodic: It is lower in periods where the opening hours of the main financial centers overlap, and higher otherwise. A nonstationary zero-process invalidates standard estimators of volatility models, since they rely on the assumption that returns are strictly stationary. We propose a GARCH model that accommodates a nonstationary zero-process, derive a zero-adjusted QMLE for the parameters of the model, and prove its consistency and asymptotic normality under mild assumptions. The volatility specification in our model can contain higher order ARCH and GARCH terms, and past zero-indicators as covariates. Simulations verify the asymptotic properties in finite samples, and show that the standard estimator is biased. An empirical study of daily and intradaily returns illustrate our results. They show how a nonstationary zero-process induces time-varying parameters in the conditional variance representation, and that the distribution of zero returns can have a strong impact on volatility predictions.},
  archive      = {J_JBES},
  author       = {Christian Francq and Genaro Sucarrat},
  doi          = {10.1080/07350015.2021.1999821},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {53-66},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Volatility estimation when the zero-process is nonstationary},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting conditional covariance matrices in
high-dimensional time series: A general dynamic factor approach.
<em>JBES</em>, <em>41</em>(1), 40–52. (<a
href="https://doi.org/10.1080/07350015.2021.1996380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on a General Dynamic Factor Model with infinite-dimensional factor space and MGARCH volatility models, we develop new estimation and forecasting procedures for conditional covariance matrices in high-dimensional time series. The finite-sample performance of our approach is evaluated via Monte Carlo experiments and outperforms the most alternative methods. This new approach is also used to construct minimum one-step-ahead variance portfolios for a high-dimensional panel of assets. The results are shown to match the results of recent proposals by Engle, Ledoit, and Wolf and achieve better out-of-sample portfolio performance than alternative procedures proposed in the literature.},
  archive      = {J_JBES},
  author       = {Carlos Trucíos and João H. G. Mazzeu and Marc Hallin and Luiz K. Hotta and Pedro L. Valls Pereira and Mauricio Zevallos},
  doi          = {10.1080/07350015.2021.1996380},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {40-52},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Forecasting conditional covariance matrices in high-dimensional time series: A general dynamic factor approach},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Male earnings volatility in LEHD before, during, and after
the great recession. <em>JBES</em>, <em>41</em>(1), 33–39. (<a
href="https://doi.org/10.1080/07350015.2022.2126479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is part of a coordinated collection of papers on prime-age male earnings volatility. Each paper produces a similar set of statistics for the same reference population using a different primary data source. Our primary data source is the Census Bureau’s Longitudinal Employer-Household Dynamics (LEHD) infrastructure files. Using LEHD data from 1998 to 2016, we create a well-defined population frame to facilitate accurate estimation of temporal changes comparable to designed longitudinal samples of people. We show that earnings volatility, excluding increases during recessions, has declined over the analysis period, a finding robust to various sensitivity analyses.},
  archive      = {J_JBES},
  author       = {Kevin L. McKinney and John M. Abowd},
  doi          = {10.1080/07350015.2022.2126479},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {33-39},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Male earnings volatility in LEHD before, during, and after the great recession},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconciling trends in male earnings volatility: Evidence
from the SIPP survey and administrative data. <em>JBES</em>,
<em>41</em>(1), 26–32. (<a
href="https://doi.org/10.1080/07350015.2022.2126845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As part of a set of papers using the same methods and sample selection criteria to estimate trends in male earnings volatility across survey and administrative datasets, we conduct a new investigation of male earnings volatility using data from the Survey of Income and Program Participation (SIPP) survey and SIPP-linked administrative earnings data (SIPP GSF). We find that the level of volatility is higher in the administrative earnings histories in the SIPP GSF than in the SIPP survey but that the trends are similar. Between 1984 and 2012, volatility in the SIPP survey declines slightly while volatility in the SIPP GSF increases slightly. Including imputations due to unit nonresponse in the SIPP survey data increases both the level and upward trend in volatility and poses a challenge for estimating a consistent series in the SIPP survey data. Because the density of low earnings differs considerably across datasets, and volatility may vary across the earnings distribution, we also estimate trends in volatility where we hold the earnings distribution fixed across the two data sources. Differences in the underlying earnings distribution explain much of the difference in the level of and trends in volatility between the SIPP survey and SIPP GSF.},
  archive      = {J_JBES},
  author       = {Michael D. Carr and Robert A. Moffitt and Emily E. Wiemers},
  doi          = {10.1080/07350015.2022.2126845},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {26-32},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Reconciling trends in male earnings volatility: Evidence from the SIPP survey and administrative data},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating trends in male earnings volatility with the panel
study of income dynamics. <em>JBES</em>, <em>41</em>(1), 20–25. (<a
href="https://doi.org/10.1080/07350015.2022.2102024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Panel Study of Income Dynamics (PSID) has been the workhorse dataset used to estimate trends in U.S. earnings volatility at the individual level. We provide updated estimates for male earnings volatility using additional years of data. The analysis confirms prior work showing upward trends in the 1970s and 1980s, with a near doubling of the level of volatility over that period. The results also confirm prior work showing a resumption of an upward trend starting in the 2000s, but the new years of data available show volatility to be falling in recent years. By 2018, volatility had grown by a modest amount relative to the 1990s, with a growth rate only one-fifth the magnitude of that in the 1970s and 1980s. We show that neither attrition or item nonresponse bias, nor other issues with the PSID, affect these conclusions.},
  archive      = {J_JBES},
  author       = {Robert Moffitt and Sisi Zhang},
  doi          = {10.1080/07350015.2022.2102024},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {20-25},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimating trends in male earnings volatility with the panel study of income dynamics},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trends in earnings volatility using linked administrative
and survey data. <em>JBES</em>, <em>41</em>(1), 12–19. (<a
href="https://doi.org/10.1080/07350015.2022.2102023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We document trends in earnings volatility separately by gender using unique linked survey data from the CPS ASEC and Social Security earnings records for the tax years spanning 1995–2015. The exact data link permits us to focus on differences in measured volatility from earnings nonresponse, survey attrition, and measurement between survey and administrative earnings data reports, while holding constant the sampling frame. Our results for both men and women suggest that the level and trend in volatility is similar in the survey and administrative data, showing substantial business-cycle sensitivity among men but no overall trend among continuous workers, while women demonstrate no change in earnings volatility over the business cycle but a declining trend. A substantive difference emerges with the inclusion of imputed earnings among survey nonrespondents, suggesting that users of the ASEC drop earnings nonrespondents.},
  archive      = {J_JBES},
  author       = {James P. Ziliak and Charles Hokayem and Christopher R. Bollinger},
  doi          = {10.1080/07350015.2022.2102023},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {12-19},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Trends in earnings volatility using linked administrative and survey data},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconciling trends in u.s. Male earnings volatility: Results
from survey and administrative data. <em>JBES</em>, <em>41</em>(1),
1–11. (<a href="https://doi.org/10.1080/07350015.2022.2102020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a large literature on earnings and income volatility in labor economics, household finance, and macroeconomics. One strand of that literature has studied whether individual earnings volatility has risen or fallen in the United States over the last several decades. There are strong disagreements in the empirical literature on this important question, with some studies showing upward trends, some showing downward trends, and some showing no trends. Some studies have suggested that the differences are the result of using flawed survey data instead of more accurate administrative data. This article summarizes the results of a project attempting to reconcile these findings with four different datasets and six different data series—three survey and three administrative data series, including two which match survey respondent data to their administrative data. Using common specifications, measures of volatility, and other treatments of the data, four of the six data series show a lack of any significant long-term trend in male earnings volatility over the last 20-to-30+ years when differences across the datasets are properly accounted for. A fifth data series (the PSID) shows a positive net trend but small in magnitude. A sixth, administrative, dataset, available only since 1998, shows no net trend 1998–2011 and only a small decline thereafter. Many of the remaining differences across data series can be explained by differences in their cross-sectional distribution of earnings, particularly differences in the size of the lower tail. We conclude that the datasets we have analyzed, which include many of the most important available, show little evidence of any significant trend in male earnings volatility since the mid-1980s.},
  archive      = {J_JBES},
  author       = {Robert Moffitt and John Abowd and Christopher Bollinger and Michael Carr and Charles Hokayem and Kevin McKinney and Emily Wiemers and Sisi Zhang and James Ziliak},
  doi          = {10.1080/07350015.2022.2102020},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Reconciling trends in U.S. male earnings volatility: Results from survey and administrative data},
  volume       = {41},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and flexible bayesian inference in time-varying
parameter regression models. <em>JBES</em>, <em>40</em>(4), 1904–1918.
(<a href="https://doi.org/10.1080/07350015.2021.1990772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we write the time-varying parameter (TVP) regression model involving K explanatory variables and T observations as a constant coefficient regression model with KT explanatory variables. In contrast with much of the existing literature which assumes coefficients to evolve according to a random walk, a hierarchical mixture model on the TVPs is introduced. The resulting model closely mimics a random coefficients specification which groups the TVPs into several regimes. These flexible mixtures allow for TVPs that feature a small, moderate or large number of structural breaks. We develop computationally efficient Bayesian econometric methods based on the singular value decomposition of the KT regressors. In artificial data, we find our methods to be accurate and much faster than standard approaches in terms of computation time. In an empirical exercise involving inflation forecasting using a large number of predictors, we find our models to forecast better than alternative approaches and document different patterns of parameter change than are found with approaches which assume random walk evolution of parameters.},
  archive      = {J_JBES},
  author       = {Niko Hauzenberger and Florian Huber and Gary Koop and Luca Onorante},
  doi          = {10.1080/07350015.2021.1990772},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1904-1918},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Fast and flexible bayesian inference in time-varying parameter regression models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature screening for massive data analysis by subsampling.
<em>JBES</em>, <em>40</em>(4), 1892–1903. (<a
href="https://doi.org/10.1080/07350015.2021.1990771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern statistical analysis often encounters massive datasets with ultrahigh-dimensional features. In this work, we develop a subsampling approach for feature screening with massive datasets. The approach is implemented by repeated subsampling of massive data and can be used for analyzing tasks with memory constraints. To conduct the procedure, we first calculate an R -squared screening measure (and related sample moments) based on subsamples. Second, we consider three methods to combine the local statistics. In addition to the simple average method, we design a jackknife debiased screening measure and an aggregated moment screening measure. Both approaches reduce the bias of the subsampling screening measure and therefore increase the accuracy of the feature screening. Last, we consider a novel sequential sampling method, that is more computationally efficient than the traditional random sampling method. The theoretical properties of the three screening measures under both sampling schemes are rigorously discussed. Finally, we illustrate the usefulness of the proposed method with an airline dataset containing 32.7 million records.},
  archive      = {J_JBES},
  author       = {Xuening Zhu and Rui Pan and Shuyuan Wu and Hansheng Wang},
  doi          = {10.1080/07350015.2021.1990771},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1892-1903},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Feature screening for massive data analysis by subsampling},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymptotically valid bootstrap inference for proxy SVARs.
<em>JBES</em>, <em>40</em>(4), 1876–1891. (<a
href="https://doi.org/10.1080/07350015.2021.1990770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proxy structural vector autoregressions identify structural shocks in vector autoregressions with external variables that are correlated with the structural shocks of interest but uncorrelated with all other structural shocks. We provide asymptotic theory for this identification approach under mild α -mixing conditions that cover a large class of uncorrelated, but possibly dependent innovation processes. We prove consistency of a residual-based moving block bootstrap (MBB) for inference on statistics such as impulse response functions and forecast error variance decompositions. The MBB serves as the basis for constructing confidence intervals when the proxy variables are strongly correlated with the structural shocks of interest. For the case of one proxy variable used to identify one structural shock, we show that the MBB can be used to construct confidence sets for normalized impulse responses that are valid regardless of proxy strength based on the inversion of the Anderson and Rubin statistic suggested by Montiel Olea, Stock, and Watson.},
  archive      = {J_JBES},
  author       = {Carsten Jentsch and Kurt G. Lunsford},
  doi          = {10.1080/07350015.2021.1990770},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1876-1891},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Asymptotically valid bootstrap inference for proxy SVARs},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local composite quantile regression for regression
discontinuity. <em>JBES</em>, <em>40</em>(4), 1863–1875. (<a
href="https://doi.org/10.1080/07350015.2021.1990072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the local composite quantile regression (LCQR) to causal inference in regression discontinuity (RD) designs. Kai, Li and Zou study the efficiency property of LCQR, while we show that its nice boundary performance translates to accurate estimation of treatment effects in RD under a variety of data generating processes. Moreover, we propose a bias-corrected and standard error-adjusted t -test for inference, which leads to confidence intervals with good coverage probabilities. A bandwidth selector is also discussed. For illustration, we conduct a simulation study and revisit a classic example from Lee. A companion R package rdcqr is developed.},
  archive      = {J_JBES},
  author       = {Xiao Huang and Zhaoguo Zhan},
  doi          = {10.1080/07350015.2021.1990072},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1863-1875},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Local composite quantile regression for regression discontinuity},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Posterior average effects. <em>JBES</em>, <em>40</em>(4),
1849–1862. (<a
href="https://doi.org/10.1080/07350015.2021.1984928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economists are often interested in estimating averages with respect to distributions of unobservables, such as moments of individual fixed-effects, or average partial effects in discrete choice models. For such quantities, we propose and study posterior average effects (PAE), where the average is computed conditional on the sample, in the spirit of empirical Bayes and shrinkage methods. While the usefulness of shrinkage for prediction is well-understood, a justification of posterior conditioning to estimate population averages is currently lacking. We show that PAE have minimum worst-case specification error under various forms of misspecification of the parametric distribution of unobservables. In addition, we introduce a measure of informativeness of the posterior conditioning, which quantifies the worst-case specification error of PAE relative to parametric model-based estimators. As illustrations, we report PAE estimates of distributions of neighborhood effects in the U.S., and of permanent and transitory components in a model of income dynamics.},
  archive      = {J_JBES},
  author       = {Stéphane Bonhomme and Martin Weidner},
  doi          = {10.1080/07350015.2021.1984928},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1849-1862},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Posterior average effects},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformed estimation for panel interactive effects models.
<em>JBES</em>, <em>40</em>(4), 1831–1848. (<a
href="https://doi.org/10.1080/07350015.2021.1983438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a transformed estimator for the slope coefficients of panel models with interactive effects. The transformed estimation method does not require the prior knowledge of the dimension of factor structure. It is consistent and asymptotically normally distributed under fairly general conditions when N is fixed and T → ∞ T → ∞ T→∞ or T is fixed and N → ∞ , or when both N and T are large and N T → a ≠ 0 &lt; ∞ . Moreover, because the transformation is equivalent to aggregating cross-sectional units or time units before implementing the least-square method over time or across cross-sectional units, it can bypass the issues arising from heteroscedasticity across cross-sectional units or serial correlations over time in the idiosyncratic errors. Furthermore, in the case that the idiosyncratic errors are independent over time, there is no asymptotic bias even the explanatory variables contain lagged dependent variables when N T → a &lt; ∞ as T → ∞ . Extensive Monte Carlo simulations are also conducted to examine the finite sample performance of the transformed estimation method.},
  archive      = {J_JBES},
  author       = {Cheng Hsiao and Zhentao Shi and Qiankun Zhou},
  doi          = {10.1080/07350015.2021.1983438},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1831-1848},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Transformed estimation for panel interactive effects models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework for specification tests of continuous
treatment effect models. <em>JBES</em>, <em>40</em>(4), 1817–1830. (<a
href="https://doi.org/10.1080/07350015.2021.1981915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general framework for the specification testing of continuous treatment effect models. We assume a general residual function, which includes the average and quantile treatment effect models as special cases. The null models are identified under the unconfoundedness condition and contain a nonparametric weighting function. We propose a test statistic for the null model in which the weighting function is estimated by solving an expanding set of moment equations. We establish the asymptotic distributions of our test statistic under the null hypothesis and under fixed and local alternatives. The proposed test statistic is shown to be more efficient than that constructed from the true weighting function and can detect local alternatives deviated from the null models at the rate of O ( N − 1 / 2 ) . A simulation method is provided to approximate the null distribution of the test statistic. Monte-Carlo simulations show that our test exhibits a satisfactory finite-sample performance, and an application shows its practical value.},
  archive      = {J_JBES},
  author       = {Wei Huang and Oliver Linton and Zheng Zhang},
  doi          = {10.1080/07350015.2021.1981915},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1817-1830},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A unified framework for specification tests of continuous treatment effect models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inference in games without equilibrium restriction: An
application to restaurant competition in opening hours. <em>JBES</em>,
<em>40</em>(4), 1803–1816. (<a
href="https://doi.org/10.1080/07350015.2021.1981914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article relaxes the Bayesian Nash equilibrium assumption in the estimation of discrete choice games with incomplete information. Instead of assuming unbiased/correct expectations, the model specifies a player’s belief about the behaviors of other players as an unrestricted unknown function. I then study the joint identification of belief and payoff functions in a game where players have different numbers of actions (e.g., 3 × 2 game). This asymmetry in action sets partially identifies the payoff function of the player with more actions. Moreover, if usual exclusion restrictions are satisfied, the payoff and belief functions are point identified up to a scale, and the restriction of equilibrium beliefs is testable. Finally, under a multiplicative separability condition on payoffs, the above identification results are extended to the player with fewer actions and to games with symmetric action sets. I apply this model and its identification results to study the store hours competition between McDonald’s and Kentucky Fried Chicken in China. The null hypothesis of unbiased beliefs is rejected. If researchers incorrectly impose the equilibrium assumption, then the estimated interactive effect would be biased downward by more than 50\%.},
  archive      = {J_JBES},
  author       = {Erhao Xie},
  doi          = {10.1080/07350015.2021.1981914},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1803-1816},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inference in games without equilibrium restriction: An application to restaurant competition in opening hours},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric spatial autoregressive panel data model with
fixed effects and time-varying coefficients. <em>JBES</em>,
<em>40</em>(4), 1784–1802. (<a
href="https://doi.org/10.1080/07350015.2021.1979564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers a semiparametric spatial autoregressive (SAR) panel data model with fixed effects and time-varying coefficients. The time-varying coefficients are allowed to follow unknown functions of time, while the other parameters are assumed to be unknown constants. We propose a local linear quasi-maximum likelihood estimation method to obtain consistent estimators for the SAR coefficient, the variance of the error term, and the nonparametric time-varying coefficients. The asymptotic properties of the proposed estimators are also established. Monte Carlo simulations are conducted to evaluate the finite sample performance of our proposed method. We apply the proposed model to study labor compensation in Chinese cities. The results show significant spatial dependence among cities and the impacts of capital, investment, and the economy’s structure on labor compensation change over time.},
  archive      = {J_JBES},
  author       = {Xuan Liang and Jiti Gao and Xiaodong Gong},
  doi          = {10.1080/07350015.2021.1979564},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1784-1802},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric spatial autoregressive panel data model with fixed effects and time-varying coefficients},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Markov switching garch models: Higher order moments,
kurtosis measures, and volatility evaluation in recessions and pandemic.
<em>JBES</em>, <em>40</em>(4), 1772–1783. (<a
href="https://doi.org/10.1080/07350015.2021.1974459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we derive neat matrix formulas in closed form for computing higher order moments and kurtosis of univariate Markov switching GARCH models. Then we provide asymptotic theory for sample estimators of higher order moments and kurtosis which can be used for testing normality. We also check our theory statements numerically via Monte Carlo simulations. Finally, we take advantage of our theoretical results to recognize different periods of high volatility stressing the stock markets, such as financial crisis and pandemic.},
  archive      = {J_JBES},
  author       = {Maddalena Cavicchioli},
  doi          = {10.1080/07350015.2021.1974459},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1772-1783},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Markov switching garch models: Higher order moments, kurtosis measures, and volatility evaluation in recessions and pandemic},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Varying coefficient mediation model and application to
analysis of behavioral economics data. <em>JBES</em>, <em>40</em>(4),
1759–1771. (<a
href="https://doi.org/10.1080/07350015.2021.1971089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with causal mediation analysis with varying indirect and direct effects. We propose a varying coefficient mediation model, which can also be viewed as an extension of moderation analysis on a causal diagram. We develop a new estimation procedure for the direct and indirect effects based on B-splines. Under mild conditions, rates of convergence and asymptotic distributions of the resulting estimates are established. We further propose a F -type test for the direct effect. We conduct simulation study to examine the finite sample performance of the proposed methodology, and apply the new procedures for empirical analysis of behavioral economics data.},
  archive      = {J_JBES},
  author       = {Yujie Liao and Jingyuan Liu and Donna L. Coffman and Runze Li},
  doi          = {10.1080/07350015.2021.1971089},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1759-1771},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Varying coefficient mediation model and application to analysis of behavioral economics data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tests of equal forecasting accuracy for nested models with
estimated CCE factors*. <em>JBES</em>, <em>40</em>(4), 1745–1758. (<a
href="https://doi.org/10.1080/07350015.2021.1970576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose new tests of equal predictive ability between nested models when factor-augmented regressions are used to forecast. In contrast to the previous literature, the unknown factors are not estimated by principal components but by the common correlated effects (CCE) approach, which employs cross-sectional averages of blocks of variables. This makes for easy interpretation of the estimated factors, and the resulting tests are easy to implement and they account for the block structure of the data. Assuming that the number of averages is larger than the true number of factors, we establish the limiting distributions of the new tests as the number of time periods and the number of variables within each block jointly go to infinity. The main finding is that the limiting distributions do not depend on the number of factors but only on the number of averages, which is known. The important practical implication of this finding is that one does not need to estimate the number of factors consistently in order to apply our tests.},
  archive      = {J_JBES},
  author       = {Ovidijus Stauskas and Joakim Westerlund},
  doi          = {10.1080/07350015.2021.1970576},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1745-1758},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Tests of equal forecasting accuracy for nested models with estimated CCE factors*},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional model-assisted inference for local average
treatment effects with instrumental variables. <em>JBES</em>,
<em>40</em>(4), 1732–1744. (<a
href="https://doi.org/10.1080/07350015.2021.1970575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of estimating the local average treatment effect with an instrument variable, where the instrument unconfoundedness holds after adjusting for a set of measured covariates. Several unknown functions of the covariates need to be estimated through regression models, such as instrument propensity score and treatment and outcome regression models. We develop a computationally tractable method in high-dimensional settings where the numbers of regression terms are close to or larger than the sample size. Our method exploits regularized calibrated estimation for estimating coefficients in these regression models, and then employs a doubly robust point estimator for the treatment parameter. We provide rigorous theoretical analysis to show that the resulting Wald confidence intervals are valid for the treatment parameter under suitable sparsity conditions if the instrument propensity score model is correctly specified, but the treatment and outcome regression models may be misspecified. In this sense, our confidence intervals are instrument propensity score model based, and treatment and outcome regression models assisted. For existing high-dimensional methods, valid confidence intervals are obtained for the treatment parameter if all three models are correctly specified. We evaluate the proposed method via extensive simulation studies and an empirical application to estimate the returns to education. The methods are implemented in the R package RCAL.},
  archive      = {J_JBES},
  author       = {Baoluo Sun and Zhiqiang Tan},
  doi          = {10.1080/07350015.2021.1970575},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1732-1744},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {High-dimensional model-assisted inference for local average treatment effects with instrumental variables},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust inference for nonstationary time series with possibly
multiple changing periodic structures. <em>JBES</em>, <em>40</em>(4),
1718–1731. (<a
href="https://doi.org/10.1080/07350015.2021.1970574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by two examples concerning global warming and monthly total import and export by China, we study time series that contain a nonparametric periodic component with an unknown period, a nonparametric trending behavior and also additive covariate effects. Further, as the amplitude function may change at some known or unknown change-point(s), we extend our model to take this dynamical periodicity into account and introduce two change-point estimators. To the best of knowledge, this is the first work to study such complex periodic structure. A two-step estimation procedure is proposed to estimate accurately the periodicity, trend and covariate effects. First, we estimate the period with the trend and covariate effects being approximated by B-splines rather than being ignored. To achieve robustness we employ a penalized M-estimation method which uses post model selection inference ideas. Next, given the period estimate, we estimate the amplitude, trend and covariate effects. Asymptotic properties of our estimators are derived, including consistency of the period estimator and asymptotic normality and oracle property of the estimated periodic sequence, trend and covariate effects. Simulation studies confirm superiority of our method and illustrate good performance of our change-point estimators. Applications to the two motivating examples demonstrate utilities of our methods.},
  archive      = {J_JBES},
  author       = {Shouxia Wang and Tao Huang and Jinhong You and Ming-Yen Cheng},
  doi          = {10.1080/07350015.2021.1970574},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1718-1731},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Robust inference for nonstationary time series with possibly multiple changing periodic structures},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LATE with missing or mismeasured treatment. <em>JBES</em>,
<em>40</em>(4), 1701–1717. (<a
href="https://doi.org/10.1080/07350015.2021.1970573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a new estimator, MR-LATE, that consistently estimates local average treatment effects when treatment is missing for some observations, not at random. If instead treatment is mismeasured for some observations, then MR-LATE usually has less bias than the standard LATE estimator. We discuss potential applications where an endogenous binary treatment may be unobserved or mismeasured. We apply MR-LATE to study the impact of women’s control over household resources on health outcomes in Indian families. This application illustrates the use of MR-LATE when treatment is estimated rather than observed. In these situations, treatment mismeasurement may arise from model misspecification and estimation errors.},
  archive      = {J_JBES},
  author       = {Rossella Calvi and Arthur Lewbel and Denni Tommasi},
  doi          = {10.1080/07350015.2021.1970573},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1701-1717},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {LATE with missing or mismeasured treatment},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A note on distributed quantile regression by pilot sampling
and one-step updating. <em>JBES</em>, <em>40</em>(4), 1691–1700. (<a
href="https://doi.org/10.1080/07350015.2021.1961789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile regression is a method of fundamental importance. How to efficiently conduct quantile regression for a large dataset on a distributed system is of great importance. We show that the popularly used one-shot estimation is statistically inefficient if data are not randomly distributed across different workers. To fix the problem, a novel one-step estimation method is developed with the following nice properties. First, the algorithm is communication efficient. That is the communication cost demanded is practically acceptable. Second, the resulting estimator is statistically efficient. That is its asymptotic covariance is the same as that of the global estimator. Third, the estimator is robust against data distribution. That is its consistency is guaranteed even if data are not randomly distributed across different workers. Numerical experiments are provided to corroborate our findings. A real example is also presented for illustration.},
  archive      = {J_JBES},
  author       = {Rui Pan and Tunan Ren and Baishan Guo and Feng Li and Guodong Li and Hansheng Wang},
  doi          = {10.1080/07350015.2021.1961789},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1691-1700},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A note on distributed quantile regression by pilot sampling and one-step updating},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable bayesian estimation in the multinomial probit
model. <em>JBES</em>, <em>40</em>(4), 1678–1690. (<a
href="https://doi.org/10.1080/07350015.2021.1961788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multinomial probit (MNP) model is a popular tool for analyzing choice behavior as it allows for correlation between choice alternatives. Because current model specifications employ a full covariance matrix of the latent utilities for the choice alternatives, they are not scalable to a large number of choice alternatives. This article proposes a factor structure on the covariance matrix, which makes the model scalable to large choice sets. The main challenge in estimating this structure is that the model parameters require identifying restrictions. We identify the parameters by a trace-restriction on the covariance matrix, which is imposed through a reparameterization of the factor structure. We specify interpretable prior distributions on the model parameters and develop an MCMC sampler for parameter estimation. The proposed approach significantly improves performance in large choice sets relative to existing MNP specifications. Applications to purchase data show the economic importance of including a large number of choice alternatives in consumer choice analysis.},
  archive      = {J_JBES},
  author       = {Rubén Loaiza-Maya and Didier Nibbering},
  doi          = {10.1080/07350015.2021.1961788},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1678-1690},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Scalable bayesian estimation in the multinomial probit model},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A synthetic regression model for large portfolio allocation.
<em>JBES</em>, <em>40</em>(4), 1665–1677. (<a
href="https://doi.org/10.1080/07350015.2021.1961787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio allocation is an important topic in financial data analysis. In this article, based on the mean-variance optimization principle, we propose a synthetic regression model for construction of portfolio allocation, and an easy to implement approach to generate the synthetic sample for the model. Compared with the regression approach in existing literature for portfolio allocation, the proposed method of generating the synthetic sample provides more accurate approximation for the synthetic response variable when the number of assets under consideration is large. Due to the embedded leave-one-out idea, the synthetic sample generated by the proposed method has weaker within sample correlation, which makes the resulting portfolio allocation more close to the optimal one. This intuitive conclusion is theoretically confirmed to be true by the asymptotic properties established in this article. We have also conducted intensive simulation studies in this article to compare the proposed method with the existing ones, and found the proposed method works better. Finally, we apply the proposed method to real datasets. The yielded returns look very encouraging.},
  archive      = {J_JBES},
  author       = {Gaorong Li and Lei Huang and Jin Yang and Wenyang Zhang},
  doi          = {10.1080/07350015.2021.1961787},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1665-1677},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A synthetic regression model for large portfolio allocation},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Interpretable sparse proximate factors for large
dimensions. <em>JBES</em>, <em>40</em>(4), 1642–1664. (<a
href="https://doi.org/10.1080/07350015.2021.1961786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes sparse and easy-to-interpret proximate factors to approximate statistical latent factors. Latent factors in a large-dimensional factor model can be estimated by principal component analysis (PCA), but are usually hard to interpret. We obtain proximate factors that are easier to interpret by shrinking the PCA factor weights and setting them to zero except for the largest absolute ones. We show that proximate factors constructed with only 5\%–10\% of the data are usually sufficient to almost perfectly replicate the population and PCA factors without actually assuming a sparse structure in the weights or loadings. Using extreme value theory we explain why sparse proximate factors can be substitutes for non-sparse PCA factors. We derive analytical asymptotic bounds for the correlation of appropriately rotated proximate factors with the population factors. These bounds provide guidance on how to construct the proximate factors. In simulations and empirical analyses of financial portfolio and macroeconomic data, we illustrate that sparse proximate factors are close substitutes for PCA factors with average correlations of around 97.5\%, while being interpretable.},
  archive      = {J_JBES},
  author       = {Markus Pelger and Ruoxuan Xiong},
  doi          = {10.1080/07350015.2021.1961786},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1642-1664},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Interpretable sparse proximate factors for large dimensions},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collaborative filtering with awareness of social networks.
<em>JBES</em>, <em>40</em>(4), 1629–1641. (<a
href="https://doi.org/10.1080/07350015.2021.1954527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present the NetRec method to leverage the social network data of users in collaborative filtering. We formulate two new network-related terms and obtain convex optimization problems that incorporate assumptions regarding users’ social connections and preferences about products. Our theory demonstrates that this procedure leads to a sharper error bound than before, as long as the observed social network is well structured. We point out that the larger the noise magnitude in the observed user preferences, the larger the reduction in the magnitude of the error bound. Moreover, our theory shows that the combination of the network-related term and the previously used term of nuclear norm gives estimates better than those achieved by any of them alone. We provide an algorithm to solve the new optimization problem and prove that it is guaranteed to find a global optimum. Both simulations and real data experiments are carried out to validate our theoretical findings. The application of the NetRec method on the Yelp data demonstrate its superiority over a state-of-the-art social recommendation method.},
  archive      = {J_JBES},
  author       = {Xianshi Yu and Ting Li and Ningchen Ying and Bing-Yi Jing},
  doi          = {10.1080/07350015.2021.1954527},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1629-1641},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Collaborative filtering with awareness of social networks},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inward and outward network influence analysis.
<em>JBES</em>, <em>40</em>(4), 1617–1628. (<a
href="https://doi.org/10.1080/07350015.2021.1953509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring heterogeneous influence across nodes in a network is critical in network analysis. This article proposes an inward and outward network influence (IONI) model to assess nodal heterogeneity. Specifically, we allow for two types of influence parameters; one measures the magnitude of influence that each node exerts on others (outward influence), while we introduce a new parameter to quantify the receptivity of each node to being influenced by others (inward influence). Accordingly, these two types of influence measures naturally classify all nodes into four quadrants (high inward and high outward, low inward and high outward, low inward and low outward, and high inward and low outward). To demonstrate our four-quadrant clustering method in practice, we apply the quasi-maximum likelihood approach to estimate the influence parameters, and we show the asymptotic properties of the resulting estimators. In addition, score tests are proposed to examine the homogeneity of the two types of influence parameters. To improve the accuracy of inferences about nodal influences, we introduce a Bayesian information criterion that selects the optimal influence model. The usefulness of the IONI model and the four-quadrant clustering method is illustrated via simulation studies and an empirical example involving customer segmentation.},
  archive      = {J_JBES},
  author       = {Yujia Wu and Wei Lan and Tao Zou and Chih-Ling Tsai},
  doi          = {10.1080/07350015.2021.1953509},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1617-1628},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Inward and outward network influence analysis},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conditional moments of noncausal alpha-stable processes and
the prediction of bubble crash odds. <em>JBES</em>, <em>40</em>(4),
1596–1616. (<a
href="https://doi.org/10.1080/07350015.2021.1953508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noncausal, or anticipative, heavy-tailed processes generate trajectories featuring locally explosive episodes akin to speculative bubbles in financial time series data. For ( X t ) a two-sided infinite α -stable moving average (MA), conditional moments up to integer order four are shown to exist provided ( X t ) is anticipative enough, despite the process featuring infinite marginal variance. Formulas of these moments at any forecast horizon under any admissible parameterization are provided. Under the assumption of errors with regularly varying tails, closed-form formulas of the predictive distribution during explosive bubble episodes are obtained and expressions of the ex ante crash odds at any horizon are available. It is found that the noncausal autoregression of order 1 (AR(1)) with AR coefficient ρ and tail exponent α generates bubbles whose survival distributions are geometric with parameter ρ α . This property extends to bubbles with arbitrarily shaped collapse after the peak, provided the inflation phase is noncausal AR(1)-like. It appears that mixed causal–noncausal processes generate explosive episodes with dynamics à la Blanchard and Watson which could reconcile rational bubbles with tail exponents greater than 1.},
  archive      = {J_JBES},
  author       = {Sébastien Fries},
  doi          = {10.1080/07350015.2021.1953508},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1596-1616},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Conditional moments of noncausal alpha-stable processes and the prediction of bubble crash odds},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework for estimation in lognormal models.
<em>JBES</em>, <em>40</em>(4), 1583–1595. (<a
href="https://doi.org/10.1080/07350015.2021.1952878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lognormal models have broad applications in various research areas such as economics, actuarial science, biology, environmental science and psychology. In this article, we summarize all the existing estimators for lognormal models, which belong to 12 estimator families. As some estimators were only proposed for the independent and identical distribution setting, we further generalize these estimators to accommodate the general loglinear regression setting. Additionally, we propose 19 new estimators based on different optimization criteria. Mostly importantly, we present a unified framework for all the existing and proposed estimators. The application and comparison of the various estimators using a lognormal linear regression model are demonstrated by simulations and data from the Economic Research Service in the United States Department of Agriculture. A general recommendation for choosing an estimator in practice is discussed. An R package to implement 39 estimators is made available on CRAN.},
  archive      = {J_JBES},
  author       = {Fengqing Zhang and Jiangtao Gou},
  doi          = {10.1080/07350015.2021.1952878},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1583-1595},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A unified framework for estimation in lognormal models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient covariate balancing for the local average
treatment effect. <em>JBES</em>, <em>40</em>(4), 1569–1582. (<a
href="https://doi.org/10.1080/07350015.2021.1946067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops an empirical balancing approach for the estimation of treatment effects under two-sided noncompliance using a binary instrumental variable. The method weighs both treatment and outcome information with inverse probabilities to impose exact finite sample balance across instrument level groups. It is free of functional form assumptions on the outcome or the treatment selection step. By tailoring the loss function for the instrument propensity scores, the resulting treatment effect estimates are automatically weight normalized and exhibit both low bias and reduced variance in finite samples compared to conventional inverse probability weighting methods. We provide conditions for asymptotic normality and semiparametric efficiency and demonstrate how to use additional information about the treatment selection step for bias reduction in finite samples. A doubly robust extension is proposed as well. Monte Carlo simulations suggest that the theoretical advantages translate well to finite samples. The method is illustrated in an empirical example.},
  archive      = {J_JBES},
  author       = {Phillip Heiler},
  doi          = {10.1080/07350015.2021.1946067},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1569-1582},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Efficient covariate balancing for the local average treatment effect},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiple testing and the distributional effects of
accountability incentives in education. <em>JBES</em>, <em>40</em>(4),
1552–1568. (<a
href="https://doi.org/10.1080/07350015.2021.1941055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes bootstrap-based multiple testing procedures for quantile treatment effect (QTE) heterogeneity under the assumption of selection on observables, and shows its asymptotic validity. Our procedure can be used to detect the quantiles and subgroups exhibiting treatment effect heterogeneity. We apply the multiple testing procedures to data from a large-scale Pakistani school report card experiment, and uncover evidence of policy-relevant heterogeneous effects from information provision on child test scores. Furthermore, our analysis reinforces the importance of preventing the inflation of false positive conclusions because 63\% of statistically significant QTEs become insignificant once corrections for multiple testing are applied.},
  archive      = {J_JBES},
  author       = {Steven F. Lehrer and R. Vincent Pohl and Kyungchul Song},
  doi          = {10.1080/07350015.2021.1941055},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1552-1568},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Multiple testing and the distributional effects of accountability incentives in education},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using triples to assess symmetry under weak dependence.
<em>JBES</em>, <em>40</em>(4), 1538–1551. (<a
href="https://doi.org/10.1080/07350015.2021.1939037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of assessing symmetry about an unspecified center of the one-dimensional marginal distribution of a strictly stationary random process is considered. A well-known U -statistic based on data triples is used to detect deviations from symmetry, allowing the underlying process to satisfy suitable mixing or near-epoch dependence conditions. We suggest using subsampling for inference on the target parameter, establish the asymptotic validity of the method in our setting, and discuss data-driven rules for selecting the size of subsamples. The small-sample properties of the proposed inferential procedures are examined by means of Monte Carlo simulations. Applications to time series of output growth and stock returns are also presented.},
  archive      = {J_JBES},
  author       = {Zacharias Psaradakis and Marián Vávra},
  doi          = {10.1080/07350015.2021.1939037},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1538-1551},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Using triples to assess symmetry under weak dependence},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unified principal component analysis for sparse and dense
functional data under spatial dependency. <em>JBES</em>, <em>40</em>(4),
1523–1537. (<a
href="https://doi.org/10.1080/07350015.2021.1938085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider spatially dependent functional data collected under a geostatistics setting, where locations are sampled from a spatial point process. The functional response is the sum of a spatially dependent functional effect and a spatially independent functional nugget effect. Observations on each function are made on discrete time points and contaminated with measurement errors. Under the assumption of spatial stationarity and isotropy, we propose a tensor product spline estimator for the spatio-temporal covariance function. When a coregionalization covariance structure is further assumed, we propose a new functional principal component analysis method that borrows information from neighboring functions. The proposed method also generates nonparametric estimators for the spatial covariance functions, which can be used for functional kriging. Under a unified framework for sparse and dense functional data, infill and increasing domain asymptotic paradigms, we develop the asymptotic convergence rates for the proposed estimators. Advantages of the proposed approach are demonstrated through simulation studies and two real data applications representing sparse and dense functional data, respectively.},
  archive      = {J_JBES},
  author       = {Haozhe Zhang and Yehua Li},
  doi          = {10.1080/07350015.2021.1938085},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1523-1537},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Unified principal component analysis for sparse and dense functional data under spatial dependency},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast bayesian record linkage with record-specific
disagreement parameters. <em>JBES</em>, <em>40</em>(4), 1509–1522. (<a
href="https://doi.org/10.1080/07350015.2021.1934478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are often interested in linking individuals between two datasets that lack a common unique identifier. Matching procedures often struggle to match records with common names, birthplaces, or other field values. Computational feasibility is also a challenge, particularly when linking large datasets. We develop a Bayesian method for automated probabilistic record linkage and show it recovers more than 50\% more true matches, holding accuracy constant, than comparable methods in a matching of military recruitment data to the 1900 U.S. Census for which expert-labeled matches are available. Our approach, which builds on a recent state-of-the-art Bayesian method, refines the modeling of comparison data, allowing disagreement probability parameters conditional on nonmatch status to be record-specific in the smaller of the two datasets. This flexibility significantly improves matching when many records share common field values. We show that our method is computationally feasible in practice, despite the added complexity, with an R/C++ implementation that achieves a significant improvement in speed over comparable recent methods. We also suggest a lightweight method for treatment of very common names and show how to estimate true positive rate and positive predictive value when true match status is unavailable.},
  archive      = {J_JBES},
  author       = {Thomas Stringham},
  doi          = {10.1080/07350015.2021.1934478},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1509-1522},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Fast bayesian record linkage with record-specific disagreement parameters},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient estimation for models with nonlinear
heteroscedasticity. <em>JBES</em>, <em>40</em>(4), 1498–1508. (<a
href="https://doi.org/10.1080/07350015.2021.1933991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study efficient estimation for models with nonlinear heteroscedasticity. In two-step quantile regression for heteroscedastic models, motivated by several undesirable issues caused by the preliminary estimator, we propose an efficient estimator by constrainedly weighting information across quantiles. When the weights are optimally chosen under certain constraints, the new estimator can simultaneously eliminate the effect of preliminary estimator as well as achieve good estimation efficiency. When compared to the Cramér-Rao lower bound, the relative efficiency loss of the new estimator has a conservative upper bound, regardless of the model design structure. The upper bound is close to zero for practical situations. In particular, the new estimator can asymptotically achieve the optimal Cramér-Rao lower bound if the noise has either a symmetric density or the asymmetric Laplace density. Monte Carlo studies show that the proposed method has substantial efficiency gain over existing ones. In an empirical application to GDP and inflation rate modeling, the proposed method has better prediction performance than existing methods.},
  archive      = {J_JBES},
  author       = {Zhanxiong Xu and Zhibiao Zhao},
  doi          = {10.1080/07350015.2021.1933991},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1498-1508},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Efficient estimation for models with nonlinear heteroscedasticity},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian inference in common microeconometric models with
massive datasets by double marginalized subsampling. <em>JBES</em>,
<em>40</em>(4), 1484–1497. (<a
href="https://doi.org/10.1080/07350015.2021.1933502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian inference with a large dataset is computationally intensive, as Markov chain Monte Carlo simulation requires a complete scan of the dataset for each proposed parameter update. To reduce the number of data points evaluated at each iteration of posterior simulation, we develop a double marginalized subsampling method, which is applicable to a wide array of microeconometric models including Tobit, Probit, regressions with non-Gaussian errors, heteroscedasticity and stochastic volatility, hierarchical longitudinal models, time-varying-parameter regressions, Gaussian mixtures, etc. We also provide an extension to double pseudo-marginalized subsampling, which has more applications beyond conditionally conjugate models. With rank-one update of the cumulative statistics, both methods target the exact posterior distribution, from which a parameter draw can be obtained with every single observation. Simulation studies demonstrate the statistical and computational efficiency of the marginalized sampler. The methods are also applied to a real-world massive dataset on the incidentally truncated mortgage rates.},
  archive      = {J_JBES},
  author       = {Hang Qian},
  doi          = {10.1080/07350015.2021.1933502},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1484-1497},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bayesian inference in common microeconometric models with massive datasets by double marginalized subsampling},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional mixed-frequency IV regression.
<em>JBES</em>, <em>40</em>(4), 1470–1483. (<a
href="https://doi.org/10.1080/07350015.2021.1933501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a high-dimensional linear IV regression for the data sampled at mixed frequencies. We show that the high-dimensional slope parameter of a high-frequency covariate can be identified and accurately estimated leveraging on a low-frequency instrumental variable. The distinguishing feature of the model is that it allows handing high-dimensional datasets without imposing the approximate sparsity restrictions. We propose a Tikhonov-regularized estimator and study its large sample properties for time series data. The estimator has a closed-form expression that is easy to compute and demonstrates excellent performance in our Monte Carlo experiments. We also provide the confidence bands and incorporate the exogenous covariates via the double/debiased machine learning approach. In our empirical illustration, we estimate the real-time price elasticity of supply on the Australian electricity spot market. Our estimates suggest that the supply is relatively inelastic throughout the day.},
  archive      = {J_JBES},
  author       = {Andrii Babii},
  doi          = {10.1080/07350015.2021.1933501},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1470-1483},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {High-dimensional mixed-frequency IV regression},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric specification testing of conditional asset
pricing models. <em>JBES</em>, <em>40</em>(4), 1455–1469. (<a
href="https://doi.org/10.1080/07350015.2021.1933500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an adaptive omnibus specification test of asset pricing models where the stochastic discount factor is conditionally affine in the pricing factors. These models provide constraints that conditional moments of returns and pricing factors must satisfy, but most of them do not provide information on the functional form of those moments. Our test is robust to functional form misspecification, and also detects any relationship between pricing errors and conditioning variables. We give special emphasis to the test implementation and calibration, and extensive simulation studies prove the functioning in practice. Our empirical applications show a conditional counterpart of a well-known problem of unconditional models. The lack of rejection of consumption based conditional models seems to be due to a poor conditional correlation between consumption and stock returns.},
  archive      = {J_JBES},
  author       = {Francisco Peñaranda and Juan M. Rodríguez-Poo and Stefan Sperlich},
  doi          = {10.1080/07350015.2021.1933500},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1455-1469},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric specification testing of conditional asset pricing models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hedging with linear regressions and neural networks.
<em>JBES</em>, <em>40</em>(4), 1442–1454. (<a
href="https://doi.org/10.1080/07350015.2021.1931241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study neural networks as nonparametric estimation tools for the hedging of options. To this end, we design a network, named HedgeNet, that directly outputs a hedging strategy. This network is trained to minimize the hedging error instead of the pricing error. Applied to end-of-day and tick prices of S&amp;P 500 and Euro Stoxx 50 options, the network is able to reduce the mean squared hedging error of the Black-Scholes benchmark significantly. However, a similar benefit arises by simple linear regressions that incorporate the leverage effect.},
  archive      = {J_JBES},
  author       = {Johannes Ruf and Weiguan Wang},
  doi          = {10.1080/07350015.2021.1931241},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1442-1454},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Hedging with linear regressions and neural networks},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Narrative restrictions and proxies: rejoinder.
<em>JBES</em>, <em>40</em>(4), 1438–1441. (<a
href="https://doi.org/10.1080/07350015.2022.2115710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This rejoinder addresses the discussants’ specific comments on the article “Narrative Restrictions and Proxies” (Section 2) as well as more general comments on the approach to robust Bayesian inference that we have proposed in previous work (Section 1).},
  archive      = {J_JBES},
  author       = {Raffaella Giacomini and Toru Kitagawa and Matthew Read},
  doi          = {10.1080/07350015.2022.2115710},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1438-1441},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Narrative restrictions and proxies: Rejoinder},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “narrative restrictions and proxies” by
raffaella giacomini, toru kitagawa, and matthew read. <em>JBES</em>,
<em>40</em>(4), 1434–1437. (<a
href="https://doi.org/10.1080/07350015.2022.2096042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Mikkel Plagborg-Møller},
  doi          = {10.1080/07350015.2022.2096042},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1434-1437},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of “Narrative restrictions and proxies” by raffaella giacomini, toru kitagawa, and matthew read},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comment on giacomini, kitagawa, and read’s “narrative
restrictions and proxies.” <em>JBES</em>, <em>40</em>(4), 1429–1433. (<a
href="https://doi.org/10.1080/07350015.2022.2102022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Lutz Kilian},
  doi          = {10.1080/07350015.2022.2102022},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1429-1433},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Comment on giacomini, kitagawa, and read’s “Narrative restrictions and proxies”},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comments on “narrative restrictions and proxies” by
giacomini, kitagawa, and read. <em>JBES</em>, <em>40</em>(4), 1426–1428.
(<a href="https://doi.org/10.1080/07350015.2022.2102021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The views expressed in this paper are solely those of the author and do not necessarily reflect the views of the Federal Reserve Bank of Atlanta or the Federal Reserve System. Any errors or omissions are the responsibility of the author. No statements here should be treated as legal advice. Preliminary and Incomplete. Do not circulate without consent from the author.},
  archive      = {J_JBES},
  author       = {Juan Rubio-Ramírez},
  doi          = {10.1080/07350015.2022.2102021},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1426-1428},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Comments on “Narrative restrictions and proxies” by giacomini, kitagawa, and read},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Narrative restrictions and proxies. <em>JBES</em>,
<em>40</em>(4), 1415–1425. (<a
href="https://doi.org/10.1080/07350015.2022.2115496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We compare two approaches to using information about the signs of structural shocks at specific dates within a structural vector autoregression (SVAR): imposing “narrative restrictions” (NR) on the shock signs in an otherwise set-identified SVAR; and casting the information about the shock signs as a discrete-valued “narrative proxy” (NP) to point-identify the impulse responses. The NP is likely to be “weak” given that the sign of the shock is typically known in a small number of periods, in which case the weak-proxy robust confidence intervals in Montiel Olea, Stock, and Watson are the natural approach to conducting inference. However, we show both theoretically and via Monte Carlo simulations that these confidence intervals have distorted coverage—which may be higher or lower than the nominal level—unless the sign of the shock is known in a large number of periods. Regarding the NR approach, we show that the prior-robust Bayesian credible intervals from Giacomini, Kitagawa, and Read deliver coverage exceeding the nominal level, but which converges toward the nominal level as the number of NR increases.},
  archive      = {J_JBES},
  author       = {Raffaella Giacomini and Toru Kitagawa and Matthew Read},
  doi          = {10.1080/07350015.2022.2115496},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {10},
  number       = {4},
  pages        = {1415-1425},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Narrative restrictions and proxies},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating monotone concave stochastic production frontiers.
<em>JBES</em>, <em>40</em>(3), 1403–1414. (<a
href="https://doi.org/10.1080/07350015.2021.1931240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research shows that the search for Bayesian estimation of concave production functions is a fruitful area of investigation. In this article, we use a flexible cost function that satisfies globally the monotonicity and curvature properties to estimate features of the production function. Specification of a globally monotone concave production function is a difficult task which is avoided here by using the first-order conditions for cost minimization from a globally monotone concave cost function. The problem of unavailable factor prices is bypassed by assuming structure for relative prices in the first-order conditions. The new technique is shown to perform well in a Monte Carlo experiment as well as in an empirical application to rice farming in India.},
  archive      = {J_JBES},
  author       = {Mike G. Tsionas},
  doi          = {10.1080/07350015.2021.1931240},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1403-1414},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimating monotone concave stochastic production frontiers},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The grid bootstrap for continuous time models.
<em>JBES</em>, <em>40</em>(3), 1390–1402. (<a
href="https://doi.org/10.1080/07350015.2021.1930014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes the new grid bootstrap to construct confidence intervals (CI) for the persistence parameter in a class of continuous-time models. It is different from the standard grid bootstrap of Hansen in dealing with the initial condition. The asymptotic validity of the CI is discussed under the in-fill scheme. The modified grid bootstrap leads to uniform inferences on the persistence parameter. Its improvement over in-fill asymptotics is achieved by expanding the coefficient-based statistic around its in-fill asymptotic distribution that is non-pivotal and depends on the initial condition. Monte Carlo studies show that the modified grid bootstrap performs better than Hansen’s grid bootstrap. Empirical applications to the U.S. interest rates and volatilities suggest significant differences between the two bootstrap procedures when the initial condition is large.},
  archive      = {J_JBES},
  author       = {Yiu Lim Lui and Weilin Xiao and Jun Yu},
  doi          = {10.1080/07350015.2021.1930014},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1390-1402},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {The grid bootstrap for continuous time models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A structural model of homophily and clustering in social
networks. <em>JBES</em>, <em>40</em>(3), 1377–1389. (<a
href="https://doi.org/10.1080/07350015.2021.1930013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I develop and estimate a structural model of network formation with heterogeneous players and latent community structure, whose equilibrium homophily and clustering levels match those usually observed in real-world social networks. Players belong to communities unobserved by the econometrician and have community-specific payoffs, allowing preferences to have a bias for similar people. Players meet sequentially and decide whether to form bilateral links, after receiving a random matching shock. The model converges to a hierarchical exponential family random graph. Using school friendship network data from Add Health, I estimate the posterior distribution of parameters and unobserved heterogeneity, detecting high levels of racial homophily and payoff heterogeneity across communities. The posterior predictions of sufficient statistics show that the model is able to replicate the homophily levels and the aggregate clustering of the observed network, in contrast with standard exponential family network models without community structure.},
  archive      = {J_JBES},
  author       = {Angelo Mele},
  doi          = {10.1080/07350015.2021.1930013},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1377-1389},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A structural model of homophily and clustering in social networks},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Standard synthetic control methods: The case of using all
preintervention outcomes together with covariates. <em>JBES</em>,
<em>40</em>(3), 1362–1376. (<a
href="https://doi.org/10.1080/07350015.2021.1930012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is becoming increasingly popular in applications of standard synthetic control methods to include the entire pretreatment path of the outcome variable as economic predictors. We demonstrate both theoretically and empirically that using all outcome lags as separate predictors renders all other covariates irrelevant in such settings. This finding holds irrespective of how important these covariates are for accurately predicting posttreatment values of the outcome, threatening the estimator’s unbiasedness. We show that estimation results and corresponding policy conclusions can change considerably when the usage of outcome lags as predictors is restricted, resulting in other covariates obtaining positive weights. Monte Carlo studies examine potential bias.},
  archive      = {J_JBES},
  author       = {Ashok Kaul and Stefan Klößner and Gregor Pfeifer and Manuel Schieler},
  doi          = {10.1080/07350015.2021.1930012},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1362-1376},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Standard synthetic control methods: The case of using all preintervention outcomes together with covariates},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Realized quantiles*. <em>JBES</em>, <em>40</em>(3),
1346–1361. (<a
href="https://doi.org/10.1080/07350015.2021.1929249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a simple approach to estimate quantiles of daily financial returns directly from high-frequency data. We denote the resulting estimator as realized quantile (RQ) and use it to forecast tail risk measures, such as Value at Risk (VaR) and Expected Shortfall (ES). The RQ estimator is built on the assumption that financial logarithm prices are subordinated self-similar processes in intrinsic time. The intrinsic time dimension stochastically transforms the clock time in order to capture the real “heartbeat” of financial markets in accordance with their trading activity and/or riskiness. The self-similarity assumption allows to compute daily quantiles by simply scaling up their intraday counterparts, while the subordination technique can easily accommodate numerous empirical features of financial returns, such as volatility persistence and fat-tailedness. Our method, which is built on a flexible assumption, is simple to implement and exploits the rich information content of high-frequency data from another time perspective than the classical clock time. In a comprehensive empirical exercise, we show that our forecasts of VaR and ES are more accurate than the ones from a large set of up-to-date comparative models, for both, stocks and foreign exchange rates.},
  archive      = {J_JBES},
  author       = {Timo Dimitriadis and Roxana Halbleib},
  doi          = {10.1080/07350015.2021.1929249},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1346-1361},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Realized quantiles*},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quasi-bayesian inference for production frontiers.
<em>JBES</em>, <em>40</em>(3), 1334–1345. (<a
href="https://doi.org/10.1080/07350015.2021.1927745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes to estimate and infer the production frontier by combining multiple first-stage extreme quantile estimates via the quasi-Bayesian method. We show the asymptotic properties of the proposed estimator and the validity of the inference procedure. The finite sample performance of our method is illustrated through simulations and an empirical application.},
  archive      = {J_JBES},
  author       = {Xiaobin Liu and Thomas Tao Yang and Yichong Zhang},
  doi          = {10.1080/07350015.2021.1927745},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1334-1345},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Quasi-bayesian inference for production frontiers},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). State-varying factor models of large dimensions.
<em>JBES</em>, <em>40</em>(3), 1315–1333. (<a
href="https://doi.org/10.1080/07350015.2021.1927744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops an inferential theory for state-varying factor models of large dimensions. Unlike constant factor models, loadings are general functions of some recurrent state process. We develop an estimator for the latent factors and state-varying loadings under a large cross-section and time dimension. Our estimator combines nonparametric methods with principal component analysis. We derive the rate of convergence and limiting normal distribution for the factors, loadings, and common components. In addition, we develop a statistical test for a change in the factor structure in different states. We apply the estimator to the U.S. Treasury yields and S&amp;P500 stock returns. The systematic factor structure in treasury yields differs in times of booms and recessions as well as in periods of high market volatility. State-varying factors based on the VIX capture significantly more variation and pricing information in individual stocks than constant factor models.},
  archive      = {J_JBES},
  author       = {Markus Pelger and Ruoxuan Xiong},
  doi          = {10.1080/07350015.2021.1927744},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1315-1333},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {State-varying factor models of large dimensions},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synthetic control estimation beyond comparative case
studies: Does the minimum wage reduce employment? <em>JBES</em>,
<em>40</em>(3), 1302–1314. (<a
href="https://doi.org/10.1080/07350015.2021.1927743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Panel data are often used in empirical work to account for fixed additive time and unit effects. The synthetic control estimator relaxes the assumption of additive fixed effects for comparative case studies in which a treated unit adopts a single policy. This article generalizes the synthetic control estimator to estimate parameters associated with multiple discrete or continuous explanatory variables, jointly estimating the parameters and synthetic controls for each unit. I apply the estimator to study the disemployment effects of the minimum wage, estimating that increases in the minimum wage reduce employment.},
  archive      = {J_JBES},
  author       = {David Powell},
  doi          = {10.1080/07350015.2021.1927743},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1302-1314},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Synthetic control estimation beyond comparative case studies: Does the minimum wage reduce employment?},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SVARs identification through bounds on the forecast error
variance. <em>JBES</em>, <em>40</em>(3), 1291–1301. (<a
href="https://doi.org/10.1080/07350015.2021.1927742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article identifies structural vector autoregressions (SVARs) through bound restrictions on the forecast error variance decomposition (FEVD). First, the article shows FEVD bounds correspond to quadratic inequality restrictions on the columns of the rotation matrix transforming reduced-form residuals into structural shocks. Second, the article establishes theoretical conditions such that bounds on the FEVD lead to a reduction in the width of the impulse response identified set relative to only imposing sign restrictions. Third, this article proposes a robust Bayesian approach to inference. Fourth, the article shows that elicitation of the bounds could be based on DSGE models with alternative parameterizations. Finally, an empirical application illustrates the potential usefulness of FEVD restrictions for obtaining informative inference in set-identified monetary SVARs and remove unreasonable implications of models identified through sign restrictions.},
  archive      = {J_JBES},
  author       = {Alessio Volpicella},
  doi          = {10.1080/07350015.2021.1927742},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1291-1301},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {SVARs identification through bounds on the forecast error variance},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imputations for high missing rate data in covariates via
semi-supervised learning approach. <em>JBES</em>, <em>40</em>(3),
1282–1290. (<a
href="https://doi.org/10.1080/07350015.2021.1922120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in data collection techniques and the heterogeneity of data resources can yield high percentages of missing observations on variables, such as block-wise missing data. Under missing-data scenarios, traditional methods such as the simple average, k -nearest neighbor, multiple, and regression imputations may lead to results that are unstable or unable be computed. Motivated by the concept of semi-supervised learning, we propose a novel approach with which to fill in missing values in covariates that have high missing rates. Specifically, we consider the missing and nonmissing subjects in any covariate as the unlabeled and labeled target outputs, respectively, and treat their corresponding responses as the unlabeled and labeled inputs. This innovative setting allows us to impute a large number of missing data without imposing any model assumptions. In addition, the resulting imputation has a closed form for continuous covariates, and it can be calculated efficiently. An analogous procedure is applicable for discrete covariates. We further employ the nonparametric techniques to show the theoretical properties of imputed covariates. Simulation studies and an online consumer finance example are presented to illustrate the usefulness of the proposed method.},
  archive      = {J_JBES},
  author       = {Wei Lan and Xuerong Chen and Tao Zou and Chih-Ling Tsai},
  doi          = {10.1080/07350015.2021.1922120},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1282-1290},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Imputations for high missing rate data in covariates via semi-supervised learning approach},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heteroscedastic proxy vector autoregressions. <em>JBES</em>,
<em>40</em>(3), 1268–1281. (<a
href="https://doi.org/10.1080/07350015.2021.1920962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In proxy vector autoregressive models, the structural shocks of interest are identified by an instrument. Although heteroscedasticity is occasionally allowed for in inference, it is typically taken for granted that the impact effects of the structural shocks are time-invariant despite the change in their variances. We develop a test for this implicit assumption and present evidence that the assumption of time-invariant impact effects may be violated in previously used empirical models.},
  archive      = {J_JBES},
  author       = {Helmut Lütkepohl and Thore Schlaak},
  doi          = {10.1080/07350015.2021.1920962},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1268-1281},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Heteroscedastic proxy vector autoregressions},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local polynomial order in regression discontinuity designs.
<em>JBES</em>, <em>40</em>(3), 1259–1267. (<a
href="https://doi.org/10.1080/07350015.2021.1920961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Treatment effect estimates in regression discontinuity (RD) designs are often sensitive to the choice of bandwidth and polynomial order, the two important ingredients of widely used local regression methods. While Imbens and Kalyanaraman and Calonico, Cattaneo, and Titiunik provided guidance on bandwidth, the sensitivity to polynomial order still poses a conundrum to RD practitioners. It is understood in the econometric literature that applying the argument of bias reduction does not help resolve this conundrum, since it would always lead to preferring higher orders. We therefore extend the frameworks of Imbens and Kalyanaraman and Calonico, Cattaneo, and Titiunik and use the asymptotic mean squared error of the local regression RD estimator as the criterion to guide polynomial order selection. We show in Monte Carlo simulations that the proposed order selection procedure performs well, particularly in large sample sizes typically found in empirical RD applications. This procedure extends easily to fuzzy regression discontinuity and regression kink designs.},
  archive      = {J_JBES},
  author       = {Zhuan Pei and David S. Lee and David Card and Andrea Weber},
  doi          = {10.1080/07350015.2021.1920961},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1259-1267},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Local polynomial order in regression discontinuity designs},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Binary conditional forecasts. <em>JBES</em>, <em>40</em>(3),
1246–1258. (<a
href="https://doi.org/10.1080/07350015.2021.1920960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While conditional forecasting has become prevalent both in the academic literature and in practice (e.g., bank stress testing, scenario forecasting), its applications typically focus on continuous variables. In this article, we merge elements from the literature on the construction and implementation of conditional forecasts with the literature on forecasting binary variables. We use the Qual-VAR, whose joint VAR-probit structure allows us to form conditional forecasts of the latent variable which can then be used to form probabilistic forecasts of the binary variable. We apply the model to forecasting recessions in real-time and investigate the role of monetary and oil shocks on the likelihood of two U.S. recessions.},
  archive      = {J_JBES},
  author       = {Michael W. McCracken and Joseph T. McGillicuddy and Michael T. Owyang},
  doi          = {10.1080/07350015.2021.1920960},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1246-1258},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Binary conditional forecasts},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional interaction detection with false sign rate
control. <em>JBES</em>, <em>40</em>(3), 1234–1245. (<a
href="https://doi.org/10.1080/07350015.2021.1917419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying interaction effects is fundamentally important in many scientific discoveries and contemporary applications, but it is challenging since the number of pairwise interactions increases quadratically with the number of covariates and that of higher-order interactions grows even faster. Although there is a growing literature on interaction detection, little work has been done on the prediction and false sign rate on interaction detection in ultrahigh-dimensional regression models. This article fills such a gap. More specifically, in this article we establish some theoretical results on interaction selection for ultrahigh-dimensional quadratic regression models under random designs. We prove that the examined method enjoys the same oracle inequalities as the lasso estimator and further admits an explicit bound on the false sign rate. Moreover, the false sign rate can be asymptotically vanishing. These new theoretical characterizations are confirmed by simulation studies. The performance of our proposed approach is further illustrated through a real data application.},
  archive      = {J_JBES},
  author       = {Daoji Li and Yinfei Kong and Yingying Fan and Jinchi Lv},
  doi          = {10.1080/07350015.2021.1917419},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1234-1245},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {High-dimensional interaction detection with false sign rate control},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The PCDID approach: Difference-in-differences when trends
are potentially unparallel and stochastic. <em>JBES</em>,
<em>40</em>(3), 1216–1233. (<a
href="https://doi.org/10.1080/07350015.2021.1914636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a class of regression-based estimators, called Principal Components Difference-in-Differences (PCDID) estimators, for treatment effect estimation. Analogous to a control function approach, PCDID uses factor proxies constructed from control units to control for unobserved trends, assuming that the unobservables follow an interactive effects structure. We clarify the conditions under which the estimands in this regression-based approach represent useful causal parameters of interest. We establish consistency and asymptotic normality results of PCDID estimators under minimal assumptions on the specification of time trends. The PCDID approach is illustrated in an empirical exercise that examines the effects of welfare waiver programs on welfare caseloads in the United States.},
  archive      = {J_JBES},
  author       = {Marc K. Chan and Simon S. Kwok},
  doi          = {10.1080/07350015.2021.1914636},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1216-1233},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {The PCDID approach: Difference-in-differences when trends are potentially unparallel and stochastic},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional elliptical sliced inverse regression in
non-gaussian distributions. <em>JBES</em>, <em>40</em>(3), 1204–1215.
(<a href="https://doi.org/10.1080/07350015.2021.1910041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sliced inverse regression (SIR) is the most widely used sufficient dimension reduction method due to its simplicity, generality and computational efficiency. However, when the distribution of covariates deviates from multivariate normal distribution, the estimation efficiency of SIR gets rather low, and the SIR estimator may be inconsistent and misleading, especially in the high-dimensional setting. In this article, we propose a robust alternative to SIR—called elliptical sliced inverse regression (ESIR), to analysis high-dimensional, elliptically distributed data. There are wide applications of elliptically distributed data, especially in finance and economics where the distribution of the data is often heavy-tailed. To tackle the heavy-tailed elliptically distributed covariates, we novelly use the multivariate Kendall’s tau matrix in a framework of generalized eigenvalue problem in sufficient dimension reduction. Methodologically, we present a practical algorithm for our method. Theoretically, we investigate the asymptotic behavior of the ESIR estimator under the high-dimensional setting. Extensive simulation results show ESIR significantly improves the estimation efficiency in heavy-tailed scenarios, compared with other robust SIR methods. Analysis of the Istanbul stock exchange dataset also demonstrates the effectiveness of our proposed method. Moreover, ESIR can be easily extended to other sufficient dimension reduction methods and applied to nonelliptical heavy-tailed distributions.},
  archive      = {J_JBES},
  author       = {Xin Chen and Jia Zhang and Wang Zhou},
  doi          = {10.1080/07350015.2021.1910041},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1204-1215},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {High-dimensional elliptical sliced inverse regression in non-gaussian distributions},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The incidental parameters problem in testing for remaining
cross-section correlation. <em>JBES</em>, <em>40</em>(3), 1191–1203. (<a
href="https://doi.org/10.1080/07350015.2021.1906687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider the properties of the Pesaran CD test for cross-section correlation when applied to residuals obtained from panel data models with many estimated parameters. We show that the presence of period-specific parameters leads the CD test statistic to diverge as the time dimension of the sample grows. This result holds even if cross-section dependence is correctly accounted for and hence constitutes an example of the incidental parameters problem. The relevance of this problem is investigated for both the classical two-way fixed-effects estimator and the Common Correlated Effects estimator of Pesaran. We suggest a weighted CD test statistic which re-establishes standard normal inference under the null hypothesis. Given the widespread use of the CD test statistic to test for remaining cross-section correlation, our results have far reaching implications for empirical researchers.},
  archive      = {J_JBES},
  author       = {Artūras Juodis and Simon Reese},
  doi          = {10.1080/07350015.2021.1906687},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1191-1203},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {The incidental parameters problem in testing for remaining cross-section correlation},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Direct semi-parametric estimation of the state price density
implied in option prices. <em>JBES</em>, <em>40</em>(3), 1179–1190. (<a
href="https://doi.org/10.1080/07350015.2021.1906686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a model for direct semi-parametric estimation of the state price density (SPD) implied by quoted option prices. We treat the observed prices as expected values of possible pay-offs at maturity, weighted by the unknown probability density function. We model the logarithm of the latter as a smooth function, using P-splines, while matching the expected values of the potential pay-offs with the observed prices. This leads to a special case of the penalized composite link model. Our estimates do not rely on any parametric assumption on the underlying asset price dynamics and are consistent with no-arbitrage conditions. The model shows excellent performance in simulations and in applications to real data.},
  archive      = {J_JBES},
  author       = {Gianluca Frasso and Paul H.C. Eilers},
  doi          = {10.1080/07350015.2021.1906686},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1179-1190},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Direct semi-parametric estimation of the state price density implied in option prices},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformation models in high dimensions. <em>JBES</em>,
<em>40</em>(3), 1168–1178. (<a
href="https://doi.org/10.1080/07350015.2021.1906259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformation models are a very important tool for applied statisticians and econometricians. In many applications, the dependent variable is transformed so that homogeneity or normal distribution of the error holds. In this article, we analyze transformation models in a high-dimensional setting, where the set of potential covariates is large. We propose an estimator for the transformation parameter and we show that it is asymptotically normally distributed using an orthogonalized moment condition where the nuisance functions depend on the target parameter. In a simulation study, we show that the proposed estimator works well in small samples. A common practice in labor economics is to transform wage with the log-function. In this study, we test if this transformation holds in American Community Survey (ACS) data from the United States.},
  archive      = {J_JBES},
  author       = {Sven Klaassen and Jannis Kueck and Martin Spindler},
  doi          = {10.1080/07350015.2021.1906259},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1168-1178},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Transformation models in high dimensions},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust inference for diffusion-index forecasts with
cross-sectionally dependent data. <em>JBES</em>, <em>40</em>(3),
1153–1167. (<a
href="https://doi.org/10.1080/07350015.2021.1906258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose the time-series average of spatial HAC estimators for the variance of the estimated common factors under the approximate factor structure. Based on this, we provide the confidence interval for the conditional mean of the diffusion-index forecasting model with cross-sectional heteroscedasticity and dependence of the idiosyncratic errors. We establish the asymptotics under very mild conditions, and no prior information about the dependence structure is needed to implement our procedure. We employ a bootstrap to select the bandwidth parameter. Simulation studies show that our procedure performs well in finite samples. We apply the proposed confidence interval to the problem of forecasting the unemployment rate using data by Ludvigson and Ng.},
  archive      = {J_JBES},
  author       = {Min Seong Kim},
  doi          = {10.1080/07350015.2021.1906258},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1153-1167},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Robust inference for diffusion-index forecasts with cross-sectionally dependent data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Practical methods for modeling weak VARMA processes:
Identification, estimation and specification with a macroeconomic
application. <em>JBES</em>, <em>40</em>(3), 1140–1152. (<a
href="https://doi.org/10.1080/07350015.2021.1904960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of developing practical methods for modelling weak VARMA processes. We first propose new identified VARMA representations, the diagonal MA equation form and the final MA equation form , where the MA operator is either diagonal or scalar. Both these representations have the important feature that they constitute relatively simple modifications of a VAR model (in contrast with the echelon representation). Second, for estimating VARMA models, we develop computationally simple methods which only require linear regressions. The asymptotic properties of the estimator are derived under weak hypotheses on the innovations (uncorrelated and strong mixing), in order to broaden the class of models to which it can be applied. Third, we present a modified information criterion which yields consistent estimates of the orders under the proposed representations. The estimation methods are studied by simulation. To demonstrate the importance of using VARMA models to study multivariate time series, we compare the impulse-response functions and the out-of-sample forecasts generated by VARMA and VAR models. The proposed methodology is applied to a six-variable macroeconomic model of monetary policy, based on the U.S. monthly data over the period 1962–1996. The results demonstrate the advantages of using the VARMA methodology for impulse response estimation and forecasting, in contrast with standard VAR models.},
  archive      = {J_JBES},
  author       = {Jean-Marie Dufour and Denis Pelletier},
  doi          = {10.1080/07350015.2021.1904960},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1140-1152},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Practical methods for modeling weak VARMA processes: Identification, estimation and specification with a macroeconomic application},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation and inference for multi-kink quantile regression.
<em>JBES</em>, <em>40</em>(3), 1123–1139. (<a
href="https://doi.org/10.1080/07350015.2021.1901720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new Multi-Kink Quantile Regression (MKQR) model which assumes different linear quantile regression forms in different regions of the domain of the threshold covariate but are still continuous at kink points. First, we investigate parameter estimation, kink points detection and statistical inference in MKQR models. We propose an iterative segmented quantile regression algorithm for estimating both the regression coefficients and the locations of kink points. The proposed algorithm is much more computationally efficient than the grid search algorithm and not sensitive to the selection of initial values. Second, asymptotic properties, such as selection consistency of the number of kink points and asymptotic normality of the estimators of both regression coefficients and kink effects, are established to justify the proposed method theoretically. Third, a score test based on partial subgradients is developed to verify whether the kink effects exist or not. Test-inversion confidence intervals for kink location parameters are also constructed. Monte Carlo simulations and two real data applications on the secondary industrial structure of China and the triceps skinfold thickness of Gambian females illustrate the excellent finite sample performances of the proposed MKQR model. A new R package MultiKink is developed to easily implement the proposed methods.},
  archive      = {J_JBES},
  author       = {Wei Zhong and Chuang Wan and Wenyang Zhang},
  doi          = {10.1080/07350015.2021.1901720},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1123-1139},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimation and inference for multi-kink quantile regression},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for common trends in nonstationary large datasets.
<em>JBES</em>, <em>40</em>(3), 1107–1122. (<a
href="https://doi.org/10.1080/07350015.2021.1901719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a testing-based procedure to determine the number of common trends in a large nonstationary dataset. Our procedure is based on a factor representation, where we determine whether there are (and how many) common factors (i) with linear trends, and (ii) with stochastic trends. Cointegration among the factors is also permitted. Our analysis is based on the fact that those largest eigenvalues of a suitably scaled covariance matrix of the data corresponding to the common factor part diverge, as the dimension N of the dataset diverges, whilst the others stay bounded. Therefore, we propose a class of randomized test statistics for the null that the p th largest eigenvalue diverges, based directly on the estimated eigenvalue. The tests only requires minimal assumptions on the data-generating process. Monte Carlo evidence shows that our procedure has very good finite sample properties, clearly dominating competing approaches when no common trends are present. We illustrate our methodology through an application to the U.S. bond yields with different maturities observed over the last 30 years.},
  archive      = {J_JBES},
  author       = {Matteo Barigozzi and Lorenzo Trapani},
  doi          = {10.1080/07350015.2021.1901719},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1107-1122},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for common trends in nonstationary large datasets},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning time series regressions with an application
to nowcasting. <em>JBES</em>, <em>40</em>(3), 1094–1106. (<a
href="https://doi.org/10.1080/07350015.2021.1899933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces structured machine learning regressions for high-dimensional time series data potentially sampled at different frequencies. The sparse-group LASSO estimator can take advantage of such time series data structures and outperforms the unstructured LASSO. We establish oracle inequalities for the sparse-group LASSO estimator within a framework that allows for the mixing processes and recognizes that the financial and the macroeconomic data may have heavier than exponential tails. An empirical application to nowcasting US GDP growth indicates that the estimator performs favorably compared to other alternatives and that text data can be a useful addition to more traditional numerical data. Our methodology is implemented in the R package midasml, available from CRAN.},
  archive      = {J_JBES},
  author       = {Andrii Babii and Eric Ghysels and Jonas Striaukas},
  doi          = {10.1080/07350015.2021.1899933},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1094-1106},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Machine learning time series regressions with an application to nowcasting},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantile correlation-based variable selection.
<em>JBES</em>, <em>40</em>(3), 1081–1093. (<a
href="https://doi.org/10.1080/07350015.2021.1899932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with identifying important features in high-dimensional data analysis, especially when there are complex relationships among predictors. Without any specification of an actual model, we first introduce a multiple testing procedure based on the quantile correlation to select important predictors in high dimensionality. The quantile-correlation statistic is able to capture a wide range of dependence. A stepwise procedure is studied for further identifying important variables. Moreover, a sure independent screening based on the quantile correlation is developed in handling ultrahigh dimensional data. It is computationally efficient and easy to implement. We establish the theoretical properties under mild conditions. Numerical studies including simulation studies and real data analysis contain supporting evidence that the proposal performs reasonably well in practical settings.},
  archive      = {J_JBES},
  author       = {Wenlu Tang and Jinhan Xie and Yuanyuan Lin and Niansheng Tang},
  doi          = {10.1080/07350015.2021.1899932},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1081-1093},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Quantile correlation-based variable selection},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A two-step method for testing many moment inequalities.
<em>JBES</em>, <em>40</em>(3), 1070–1080. (<a
href="https://doi.org/10.1080/07350015.2021.1897016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the problem of testing a finite number of moment inequalities. For this problem, Romano, Shaikh, and Wolf proposed a two-step testing procedure. In the first step, the procedure incorporates information about the location of moments using a confidence region. In the second step, the procedure accounts for the use of the confidence region in the first step by adjusting the significance level of the test appropriately. Its justification, however, has so far been limited to settings in which the number of moments is fixed with the sample size. In this article, we provide weak assumptions under which the same procedure remains valid even in settings in which there are “many” moments in the sense that the number of moments grows rapidly with the sample size. We confirm the practical relevance of our theoretical guarantees in a simulation study. We additionally provide both numerical and theoretical evidence that the procedure compares favorably with the method proposed by Chernozhukov, Chetverikov, and Kato, which has also been shown to be valid in such settings.},
  archive      = {J_JBES},
  author       = {Yuehao Bai and Andres Santos and Azeem M. Shaikh},
  doi          = {10.1080/07350015.2021.1897016},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1070-1080},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A two-step method for testing many moment inequalities},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparing predictive accuracy in the presence of a loss
function shape parameter. <em>JBES</em>, <em>40</em>(3), 1057–1069. (<a
href="https://doi.org/10.1080/07350015.2021.1896527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop tests for out-of-sample forecast comparisons based on loss functions that contain shape parameters. Examples include comparisons using average utility across a range of values for the level of risk aversion, comparisons of forecast accuracy using characteristics of a portfolio return across a range of values for the portfolio weight vector, and comparisons using recently-proposed “Murphy diagrams” for classes of consistent scoring rules. An extensive Monte Carlo study verifies that our tests have good size and power properties in realistic sample sizes, particularly when compared with existing methods which break down when then number of values considered for the shape parameter grows. We present three empirical illustrations of the new test.},
  archive      = {J_JBES},
  author       = {Sander Barendse and Andrew J. Patton},
  doi          = {10.1080/07350015.2021.1896527},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1057-1069},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Comparing predictive accuracy in the presence of a loss function shape parameter},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiway cluster robust double/debiased machine learning.
<em>JBES</em>, <em>40</em>(3), 1046–1056. (<a
href="https://doi.org/10.1080/07350015.2021.1895815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates double/debiased machine learning (DML) under multiway clustered sampling environments. We propose a novel multiway cross-fitting algorithm and a multiway DML estimator based on this algorithm. We also develop a multiway cluster robust standard error formula. Simulations indicate that the proposed procedure has favorable finite sample performance. Applying the proposed method to market share data for demand analysis, we obtain larger two-way cluster robust standard errors for the price coefficient than nonrobust ones in the demand model.},
  archive      = {J_JBES},
  author       = {Harold D. Chiang and Kengo Kato and Yukun Ma and Yuya Sasaki},
  doi          = {10.1080/07350015.2021.1895815},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1046-1056},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Multiway cluster robust Double/Debiased machine learning},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric instrumental regression with right censored
duration outcomes. <em>JBES</em>, <em>40</em>(3), 1034–1045. (<a
href="https://doi.org/10.1080/07350015.2021.1895814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article analyzes the effect of a discrete treatment Z on a duration T. The treatment is not randomly assigned. The confounding issue is treated using a discrete instrumental variable explaining the treatment and independent of the error term of the model. Our framework is nonparametric and allows for random right censoring. This specification generates a nonlinear inverse problem and the average treatment effect is derived from its solution. We provide local and global identification properties that rely on a nonlinear system of equations. We propose an estimation procedure to solve this system and derive rates of convergence and conditions under which the estimator is asymptotically normal. When censoring makes identification fail, we develop partial identification results. Our estimators exhibit good finite sample properties in simulations. We also apply our methodology to the Illinois Reemployment Bonus Experiment.},
  archive      = {J_JBES},
  author       = {Jad Beyhum and Jean-Pierre Florens and Ingrid Van Keilegom},
  doi          = {10.1080/07350015.2021.1895814},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1034-1045},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric instrumental regression with right censored duration outcomes},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric quantile models for ascending auctions with
asymmetric bidders. <em>JBES</em>, <em>40</em>(3), 1020–1033. (<a
href="https://doi.org/10.1080/07350015.2021.1895813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article proposes a parsimonious and flexible semiparametric quantile regression specification for asymmetric bidders within the independent private value framework. Asymmetry is parameterized using powers of a parent private value distribution, which is generated by a quantile regression specification. As noted in Cantillon, this covers and extends models used for efficient collusion, joint bidding and mergers among homogeneous bidders. The specification can be estimated for ascending auctions using the winning bids and the winner’s identity. The estimation is in two stage. The asymmetry parameters are estimated from the winner’s identity using a simple maximum likelihood procedure. The parent quantile regression specification can be estimated using simple modifications of Gimenes. Specification testing procedures are also considered. A timber application reveals that weaker bidders have 30\% less chances to win the auction than stronger ones. It is also found that increasing participation in an asymmetric ascending auction may not be as beneficial as using an optimal reserve price as would have been expected from a result of Bulow and Klemperer valid under symmetry.},
  archive      = {J_JBES},
  author       = {Jayeeta Bhattacharya and Nathalie Gimenes and Emmanuel Guerre},
  doi          = {10.1080/07350015.2021.1895813},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1020-1033},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric quantile models for ascending auctions with asymmetric bidders},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Targeting predictors via partial distance correlation with
applications to financial forecasting. <em>JBES</em>, <em>40</em>(3),
1007–1019. (<a
href="https://doi.org/10.1080/07350015.2021.1895812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional time series datasets are becoming increasingly common in various fields of economics and finance. Given the ubiquity of time series data, it is crucial to develop efficient variable screening methods that use the unique features of time series. This article introduces several model-free screening methods based on partial distance correlation and developed specifically to deal with time-dependent data. Methods are developed both for univariate models, such as nonlinear autoregressive models with exogenous predictors (NARX), and multivariate models such as linear or nonlinear VAR models. Sure screening properties are proved for our methods, which depend on the moment conditions, and the strength of dependence in the response and covariate processes, amongst other factors. We show the effectiveness of our methods via extensive simulation studies and an application on forecasting U.S. market returns.},
  archive      = {J_JBES},
  author       = {Kashif Yousuf and Yang Feng},
  doi          = {10.1080/07350015.2021.1895812},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {1007-1019},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Targeting predictors via partial distance correlation with applications to financial forecasting},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring social interaction effects when instruments are
weak. <em>JBES</em>, <em>40</em>(3), 995–1006. (<a
href="https://doi.org/10.1080/07350015.2021.1895811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies that distinguish between exogenous and endogenous peer effects are relatively rare. To separate these effects, De Giorgi, Pellizzari, and Redaelli exploited partially overlapping peer groups where attributes of a student’s peers in one group provide instrumental variables (IV) for endogenous effects in another group. We apply this identification strategy to data from a period of transition at a Chinese university: dormitory roommate assignments were changed as students moved between campuses. This transition allows us to measure the endogenous effects between test scores of current roommates, but the traditional IV method suggests the potential for weak IV. We use weak-IV robust techniques to obtain properly sized tests. The S-test, K-test, and QCLR test all reject the null of zero endogenous effects with p-values between 0.01 and 0.05, as compared with 0.003 implied by the traditional IV estimator. The largest 95\% confidence interval lower bound is 0.154 from the QCLR test, in contrast to 0.244 from traditional IV. Our findings offer unique evidence that endogenous peer effects influence academic outcomes at an empirically relevant magnitude, and an example where weak-IV robust tests are essential to quantify the relationship. Our results are robust to alternative model specifications.},
  archive      = {J_JBES},
  author       = {Stephen L. Ross and Zhentao Shi},
  doi          = {10.1080/07350015.2021.1895811},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {995-1006},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Measuring social interaction effects when instruments are weak},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Testing for the martingale difference hypothesis in
multivariate time series models. <em>JBES</em>, <em>40</em>(3), 980–994.
(<a href="https://doi.org/10.1080/07350015.2021.1889568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a general class of tests to examine whether the error term is a martingale difference sequence in a multivariate time series model with parametric conditional mean. These new tests are formed based on recently developed martingale difference divergence matrix (MDDM), and they provide formal tools to test the multivariate martingale difference hypothesis in the literature for the first time. Under suitable conditions, the asymptotic null distributions of these MDDM-based tests are established. Moreover, these MDDM-based tests are consistent to detect a broad class of fixed alternatives, and have nontrivial power against local alternatives of order n − 1 / 2 , where n is the sample size. Since the asymptotic null distributions depend on the data generating process and the parameter estimation, a wild bootstrap procedure is further proposed to approximate the critical values of these MDDM-based tests, and its theoretical validity is justified. Finally, the usefulness of these MDDM-based tests is illustrated by simulation studies and one real data example.},
  archive      = {J_JBES},
  author       = {Guochang Wang and Ke Zhu and Xiaofeng Shao},
  doi          = {10.1080/07350015.2021.1889568},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {980-994},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing for the martingale difference hypothesis in multivariate time series models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of impulse response functions when shocks are
observed at a higher frequency than outcome variables. <em>JBES</em>,
<em>40</em>(3), 965–979. (<a
href="https://doi.org/10.1080/07350015.2021.1889567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes mixed-frequency distributed-lag (MFDL) estimators of impulse response functions in a setup where (i) the shock of interest is observed, (ii) the impact variable of interest is observed at a lower frequency (as a temporally aggregated or sequentially sampled variable), (iii) the data generating process (DGP) is given by a VAR model at the frequency of the shock, and (iv) the full set of relevant endogenous variables entering the DGP is unknown or unobserved. Consistency and asymptotic normality of the proposed MFDL estimators is established, and their small-sample performance is documented by a set of Monte Carlo experiments. The usefulness of MFDL estimator is then illustrated in three empirical applications: (i) the daily pass-through of shocks to crude oil prices observed at the daily frequency to U.S. gasoline consumer prices observed at the weekly frequency, (ii) the impact of shocks to global investors’ risk appetite on global capital flows, and (iii) the impact of monetary policy shocks on real activity.},
  archive      = {J_JBES},
  author       = {Alexander Chudik and Georgios Georgiadis},
  doi          = {10.1080/07350015.2021.1889567},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {965-979},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimation of impulse response functions when shocks are observed at a higher frequency than outcome variables},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quasi-experimental evaluation of alternative sample
selection corrections. <em>JBES</em>, <em>40</em>(3), 950–964. (<a
href="https://doi.org/10.1080/07350015.2021.1889566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers routinely use datasets where outcomes of interest are unobserved for some cases, potentially creating a sample selection problem. Statisticians and econometricians have proposed many selection correction methods to address this challenge. We use a natural experiment to evaluate different sample selection correction methods’ performance. From 2007, the state of Michigan required that all students take a college entrance exam, increasing the exam-taking rate from 64\% to 99\% and largely eliminating selection into exam-taking. We apply different selection correction methods, using different sets of covariates, to the selected exam score data from before 2007. We compare the estimated coefficients from the selection-corrected models to those from OLS regressions using the complete exam score data from after 2007 as a benchmark. We find that less restrictive semiparametric correction methods typically perform better than parametric correction methods but not better than simple OLS regressions that do not correct for selection. Performance is generally worse for models that use only a few discrete covariates than for models that use more covariates with less coarse distributions.},
  archive      = {J_JBES},
  author       = {Robert Garlick and Joshua Hyman},
  doi          = {10.1080/07350015.2021.1889566},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {950-964},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Quasi-experimental evaluation of alternative sample selection corrections},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evidence of uniform inefficiency in market portfolios based
on dominance tests. <em>JBES</em>, <em>40</em>(3), 937–949. (<a
href="https://doi.org/10.1080/07350015.2021.1888741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We find stochastic uniform inefficiency of many widely held (active) portfolios and fund strategies relative to popular benchmarks. Uniformity provides robust findings over general classes of utility (loss) functions and unknown distribution of returns. Evidence is based on statistical tests for the null of stochastic uniform inefficiency of a given portfolio. The alternative is that there is at least one portfolio that dominates it. We derive an analytical characterization of stochastic uniform inefficiency. We give the limit distribution for the empirical test statistic, and present a practical implementation with block bootstrap for consistent estimation of p -values. Our test is asymptotically exact and performs well in Monte Carlo experiments.},
  archive      = {J_JBES},
  author       = {Sofia Anyfantaki and Esfandiar Maasoumi and Jue Ren and Nikolas Topaloglou},
  doi          = {10.1080/07350015.2021.1888741},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {6},
  number       = {3},
  pages        = {937-949},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Evidence of uniform inefficiency in market portfolios based on dominance tests},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The locally gaussian partial correlation. <em>JBES</em>,
<em>40</em>(2), 924–936. (<a
href="https://doi.org/10.1080/07350015.2021.1886107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known in econometrics and other fields that the dependence structure for jointly Gaussian variables can be fully captured using correlations, and that the conditional dependence structure in the same way can be described using partial correlations. The partial correlation does not, however, characterize conditional dependence in many non-Gaussian populations. This article introduces the local Gaussian partial correlation (LGPC), a new measure of conditional dependence. It is a local version of the partial correlation coefficient that characterizes conditional dependence in a large class of populations. It has some useful and novel properties besides: The LGPC reduces to the ordinary partial correlation for jointly normal variables, and it distinguishes between positive and negative conditional dependence. Furthermore, the LGPC can be used to study departures from conditional independence in specific parts of the distribution. We provide several examples of this, both simulated and real, and derive estimation theory under a local likelihood estimation framework. Finally, we indicate how the LGPC can be used to construct a powerful test for conditional independence, which, for example, can be used to detect nonlinear Granger causality in time series.},
  archive      = {J_JBES},
  author       = {Håkon Otneim and Dag Tjøstheim},
  doi          = {10.1080/07350015.2021.1886107},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {924-936},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {The locally gaussian partial correlation},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The effect of dependence on european market risk. A
nonparametric time varying approach. <em>JBES</em>, <em>40</em>(2),
913–923. (<a
href="https://doi.org/10.1080/07350015.2021.1883439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate dependence measures are crucial for risk management, where variables usually have heavy tails and non-Gaussian distributions. We propose a multivariate time varying Kendall’s tau estimator in a nonparametric context, allowing for local stationary variables. Consistency and asymptotic normality of the estimator are provided. A simulation study is conducted which supports the idea of better performance than other related methods in many complex scenarios. The proposal is used to draw up a daily estimation of the dependence between European financial market indexes. Nonparametric conditional quantiles are estimated to detect any influence of the degree of dependence on the market returns. That dependence emerges as an important factor in the Euro Stoxx distribution. It is noteworthy that the Kendall’s tau only depends on the multivariate copula, so the effect is not due to hidden effects of the marginals. Local Granger causality is tested and evidence is found that the degree of dependence affects the Euro Stoxx returns in the left tail of the distribution. We believe that these results encourage further research into the effect of diversification in quantiles, linked to the factors behind systemic risk. Additionally, there is a noteworthy increase in dependence following the outbreak of COVID-19.},
  archive      = {J_JBES},
  author       = {Jone Ascorbebeitia and Eva Ferreira and Susan Orbe},
  doi          = {10.1080/07350015.2021.1883439},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {913-923},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {The effect of dependence on european market risk. a nonparametric time varying approach},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian approach to lorenz curve using time series grouped
data. <em>JBES</em>, <em>40</em>(2), 897–912. (<a
href="https://doi.org/10.1080/07350015.2021.1883438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study is concerned with estimating the inequality measures associated with the underlying hypothetical income distribution from the times series grouped data on the income proportions. We adopt the Dirichlet likelihood approach where the parameters of the Dirichlet likelihood are set to the differences between the Lorenz curve of the hypothetical income distribution for the consecutive income classes and propose a state-space model which combines the transformed parameters of the Lorenz curve through a time series structure. The present article also studies the possibility of extending the likelihood model by considering a generalized version of the Dirichlet distribution where the mean is modeled based on the Lorenz curve with an additional hierarchical structure. The simulated data and real data on the Japanese monthly income survey confirmed that the proposed approach produces more efficient estimates on the inequality measures than the existing method that estimates the model independently without time series structures.},
  archive      = {J_JBES},
  author       = {Genya Kobayashi and Yuta Yamauchi and Kazuhiko Kakamu and Yuki Kawakubo and Shonosuke Sugasawa},
  doi          = {10.1080/07350015.2021.1883438},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {897-912},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bayesian approach to lorenz curve using time series grouped data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric tests for the order of integration in the
possible presence of level breaks. <em>JBES</em>, <em>40</em>(2),
880–896. (<a
href="https://doi.org/10.1080/07350015.2021.1876712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lobato and Robinson developed semiparametric tests for the null hypothesis that a series is weakly autocorrelated, or I (0), about a constant level, against fractionally integrated alternatives. These tests have the advantage that the user is not required to specify a parametric model for any weak autocorrelation present in the series. We extend this approach in two distinct ways. First, we show that it can be generalized to allow for testing of the null hypothesis that a series is I ( δ ) for any δ lying in the usual stationary and invertible region of the parameter space. The second extension is the more substantive and addresses the well-known issue in the literature that long memory and level breaks can be mistaken for one another, with unmodeled level breaks rendering fractional integration tests highly unreliable. To deal with this inference problem, we extend the Lobato and Robinson approach to allow for the possibility of changes in level at unknown points in the series. We show that the resulting statistics have standard limiting null distributions, and that the tests based on these statistics attain the same asymptotic local power functions as infeasible tests based on the unobserved errors, and hence there is no loss in asymptotic local power from allowing for level breaks, even where none is present. We report results from a Monte Carlo study into the finite-sample behavior of our proposed tests, as well as several empirical examples.},
  archive      = {J_JBES},
  author       = {Fabrizio Iacone and Morten Ørregaard Nielsen and A. M. Robert Taylor},
  doi          = {10.1080/07350015.2021.1876712},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {880-896},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric tests for the order of integration in the possible presence of level breaks},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robust generalization of the rao test. <em>JBES</em>,
<em>40</em>(2), 868–879. (<a
href="https://doi.org/10.1080/07350015.2021.1876711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents new families of Rao-type test statistics based on the minimum density power divergence estimators which provide robust generalizations for testing simple and composite null hypotheses. The asymptotic null distributions of the proposed tests are obtained and their robustness properties are also theoretically studied. Numerical illustrations are provided to substantiate the theory developed. On the whole, the proposed tests are seen to be excellent alternatives to the classical Rao test as well as other well-known tests.},
  archive      = {J_JBES},
  author       = {Ayanendranath Basu and Abhik Ghosh and Nirian Martin and Leandro Pardo},
  doi          = {10.1080/07350015.2021.1876711},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {868-879},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A robust generalization of the rao test},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Risk analysis via generalized pareto distributions.
<em>JBES</em>, <em>40</em>(2), 852–867. (<a
href="https://doi.org/10.1080/07350015.2021.1874390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We compute the value-at-risk of financial losses by fitting a generalized Pareto distribution to exceedances over a threshold. Following the common practice of setting the threshold as high sample quantiles, we show that, for both independent observations and time-series data, the asymptotic variance for the maximum likelihood estimation depends on the choice of threshold, unlike the existing study of using a divergent threshold. We also propose a random weighted bootstrap method for the interval estimation of VaR, with critical values computed by the empirical distribution of the absolute differences between the bootstrapped estimators and the maximum likelihood estimator. While our asymptotic results unify the inference with nondivergent and divergent thresholds, the finite sample studies via simulation and application to real data show that the derived confidence intervals well cover the true VaR in insurance and finance.},
  archive      = {J_JBES},
  author       = {Yi He and Liang Peng and Dabao Zhang and Zifeng Zhao},
  doi          = {10.1080/07350015.2021.1874390},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {852-867},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Risk analysis via generalized pareto distributions},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Locally stationary quantile regression for inflation and
interest rates. <em>JBES</em>, <em>40</em>(2), 838–851. (<a
href="https://doi.org/10.1080/07350015.2021.1874389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the potential time-varying and quantile-specific relation between inflation and interest rates, we propose a locally stationary quantile regression approach to model the inflation and interest rates relation. Large sample theory for estimation and inference of quantile-varying and time-varying coefficients are established. In empirical analysis of inflation and interest rates relation, it is found that the estimated functional coefficients vary with time in a complicated manner. Furthermore, the relation is quantile-specific: not only do the selected orders differ for different quantiles, but also the coefficients corresponding to different quantiles can display completely different patterns.},
  archive      = {J_JBES},
  author       = {Zhuying Xu and Seonjin Kim and Zhibiao Zhao},
  doi          = {10.1080/07350015.2021.1874389},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {838-851},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Locally stationary quantile regression for inflation and interest rates},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed-k inference for conditional extremal quantiles.
<em>JBES</em>, <em>40</em>(2), 829–837. (<a
href="https://doi.org/10.1080/07350015.2020.1870985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new extreme value theory for repeated cross-sectional and longitudinal/panel data to construct asymptotically valid confidence intervals (CIs) for conditional extremal quantiles from a fixed number k of nearest-neighbor tail observations. As a by-product, we also construct CIs for extremal quantiles of coefficients in linear random coefficient models. For any fixed k , the CIs are uniformly valid without parametric assumptions over a set of nonparametric data generating processes associated with various tail indices. Simulation studies show that our CIs exhibit superior small-sample coverage and length properties than alternative nonparametric methods based on asymptotic normality. Applying the proposed method to Natality Vital Statistics, we study factors of extremely low birth weights. We find that signs of major effects are the same as those found in preceding studies based on parametric models, but with different magnitudes.},
  archive      = {J_JBES},
  author       = {Yuya Sasaki and Yulong Wang},
  doi          = {10.1080/07350015.2020.1870985},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {829-837},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Fixed-k inference for conditional extremal quantiles},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural equation model averaging: Methodology and
application. <em>JBES</em>, <em>40</em>(2), 815–828. (<a
href="https://doi.org/10.1080/07350015.2020.1870479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The instrumental variable (IV) methods are attractive since they can lead to a consistent answer to the main question in causal modeling, that is, the estimation of average causal effect of an exposure on the outcome in the presence of unmeasured confounding. However, it is now acknowledged in the literature that using weak IVs might not suit the inference goal satisfactorily. We consider the problem of estimating causal effects in an observational study in this article, allowing some IVs to be weak. In many modern learning jobs, we may face a large number of instruments and their quality could range from poor to strong. To incorporate them in a 2-stage least squares estimation procedure, we consider a model averaging technique. The proposed methods only involve a few layers of least squares estimation with closed-form solutions and thus is easy to implement in practice. Theoretical properties are carefully established, including the consistency and asymptotic normality of the estimated causal parameter. Numerical studies are carried out to assess the performance in low- and high-dimensional settings and comparisons are made between our proposed method and a wide range of existing alternative methods. A real data example on home price is analyzed to illustrate our methodology.},
  archive      = {J_JBES},
  author       = {Loraine Seng and Jialiang Li},
  doi          = {10.1080/07350015.2020.1870479},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {815-828},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Structural equation model averaging: Methodology and application},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multifrequency-band tests for white noise under
heteroscedasticity. <em>JBES</em>, <em>40</em>(2), 799–814. (<a
href="https://doi.org/10.1080/07350015.2020.1870478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new family of multifrequency-band tests for the white noise hypothesis by using the maximum overlap discrete wavelet packet transform. At each scale, the proposed multifrequency-band test has the chi-square asymptotic null distribution under mild conditions, which allow the data to be heteroscedastic. Moreover, an automatic multifrequency-band test is further proposed by using a data-driven method to select the scale, and its asymptotic null distribution is chi-square with one degree of freedom. Both multifrequency-band and automatic multifrequency-band tests are shown to have the desirable size and power performance by simulation studies, and their usefulness is further illustrated by two applications. As an extension, similar tests are given to check the adequacy of linear time series regression models, based on the unobserved model residuals.},
  archive      = {J_JBES},
  author       = {Mengya Liu and Fukang Zhu and Ke Zhu},
  doi          = {10.1080/07350015.2020.1870478},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {799-814},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Multifrequency-band tests for white noise under heteroscedasticity},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model averaging for nonlinear regression models.
<em>JBES</em>, <em>40</em>(2), 785–798. (<a
href="https://doi.org/10.1080/07350015.2020.1870477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the problem of model averaging for regression models that can be nonlinear in their parameters and variables. We consider a nonlinear model averaging (NMA) framework and propose a weight-choosing criterion, the nonlinear information criterion (NIC). We show that up to a constant, NIC is an asymptotically unbiased estimator of the risk function under nonlinear settings with some mild assumptions. We also prove the optimality of NIC and show the convergence of the model averaging weights. Monte Carlo experiments reveal that NMA leads to relatively lower risks compared with alternative model selection and model averaging methods in most situations. Finally, we apply the NMA method to predicting the individual wage, where our approach leads to the lowest prediction errors in most cases.},
  archive      = {J_JBES},
  author       = {Yang Feng and Qingfeng Liu and Qingsong Yao and Guoqing Zhao},
  doi          = {10.1080/07350015.2020.1870477},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {785-798},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Model averaging for nonlinear regression models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A factor-based estimation of integrated covariance matrix
with noisy high-frequency data. <em>JBES</em>, <em>40</em>(2), 770–784.
(<a href="https://doi.org/10.1080/07350015.2020.1868301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies a high-dimensional factor model with sparse idiosyncratic covariance matrix in continuous time, using asynchronous high-frequency financial data contaminated by microstructure noise. We focus on consistent estimations of the number of common factors, the integrated covariance matrix and its inverse, based on the flat-top realized kernels introduced by Varneskov. Simulation results illustrate the satisfactory performance of our estimators in finite samples. We apply our methodology to the high-frequency price data on a large number of stocks traded in Shanghai and Shenzhen stock exchanges, and demonstrate its value for capturing time-varying covariations and portfolio allocation.},
  archive      = {J_JBES},
  author       = {Yucheng Sun and Wen Xu},
  doi          = {10.1080/07350015.2020.1868301},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {770-784},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A factor-based estimation of integrated covariance matrix with noisy high-frequency data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long memory factor model: On estimation of factor memories.
<em>JBES</em>, <em>40</em>(2), 756–769. (<a
href="https://doi.org/10.1080/07350015.2020.1867559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the estimation of the integration orders of the latent factors in an approximate factor model. Both the common factors and idiosyncratic error terms are potentially nonstationary fractionally integrated processes. We propose a two-stage approach to estimate the factor memories. We show the consistency and asymptotic normality of the proposed estimator. Applying the estimator to the log-squared returns of the U.S. financial institutions, we find evidence of long memory in the estimated factor. We also find that the factor becomes more persistent after 2007.},
  archive      = {J_JBES},
  author       = {Ying Lun Cheung},
  doi          = {10.1080/07350015.2020.1867559},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {756-769},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Long memory factor model: On estimation of factor memories},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive testing for cointegration with nonstationary
volatility. <em>JBES</em>, <em>40</em>(2), 744–755. (<a
href="https://doi.org/10.1080/07350015.2020.1867558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a class of adaptive cointegration tests for multivariate time series with nonstationary volatility. Persistent changes in the innovation variance matrix of a vector autoregressive model lead to size distortions in conventional cointegration tests, which may be resolved using the wild bootstrap, as shown in recent work by Cavaliere, Rahbek, and Taylor. We show that it also leads to the possibility of constructing tests with higher power, by taking the time-varying volatilities and correlations into account in the formulation of the likelihood function and the resulting likelihood ratio test statistic. We find that under suitable conditions, adaptation with respect to the volatility process is possible, in the sense that nonparametric volatility matrix estimation does not lead to a loss of asymptotic local power relative to the case where the volatilities are observed. The asymptotic null distribution of the test is nonstandard and depends on the volatility process; we show that various bootstrap implementations may be used to conduct asymptotically valid inference. Monte Carlo simulations show that the resulting test has good size properties, and higher power than existing tests. Empirical analyses of the U.S. term structure of interest rates and purchasing power parity illustrate the applicability of the tests.},
  archive      = {J_JBES},
  author       = {H. Peter Boswijk and Yang Zu},
  doi          = {10.1080/07350015.2020.1867558},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {744-755},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Adaptive testing for cointegration with nonstationary volatility},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing subjective well-being data with misclassification.
<em>JBES</em>, <em>40</em>(2), 730–743. (<a
href="https://doi.org/10.1080/07350015.2020.1865169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use novel nonparametric techniques to test for the presence of nonclassical measurement error in reported life satisfaction (LS) and study the potential effects from ignoring it. Our dataset comes from Wave 3 of the UK Understanding Society that is surveyed from 35,000 British households. Our test finds evidence of measurement error in reported LS for the entire dataset as well as for 26 out of 32 socioeconomic subgroups in the sample. We estimate the joint distribution of reported and latent LS nonparametrically in order to understand the mis-reporting behavior. We show this distribution can then be used to estimate parametric models of latent LS. We find measurement error bias is not severe enough to distort the main drivers of LS. But there is an important difference that is policy relevant. We find women tend to over-report their latent LS relative to men. This may help explain the gender puzzle that questions why women are reportedly happier than men despite being worse off in objective outcomes such as income and employment.},
  archive      = {J_JBES},
  author       = {Ekaterina Oparina and Sorawoot Srisuma},
  doi          = {10.1080/07350015.2020.1865169},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {730-743},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Analyzing subjective well-being data with misclassification},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing causal effects in a longitudinal observational
study with “truncated” outcomes due to unemployment and nonignorable
missing data. <em>JBES</em>, <em>40</em>(2), 718–729. (<a
href="https://doi.org/10.1080/07350015.2020.1862672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Important statistical issues pervade the evaluation of training programs’ effects for unemployed people. In particular, the fact that offered wages are observed and well-defined only for subjects who are employed (truncation by death), and the problem that information on the individuals’ employment status and wage can be lost over time (attrition) raise methodological challenges for causal inference. We present an extended framework for simultaneously addressing the aforementioned problems, and thus answering important substantive research questions, in training evaluation observational studies with covariates, a binary treatment and longitudinal information on employment status and wage, which may be missing due to the lost to follow-up. There are two key features of this framework: we use principal stratification to properly define the causal effects of interest and to deal with nonignorable missingness, and we adopt a Bayesian approach for inference. The proposed framework allows us to answer an open issue in economics: the assessment of the trend of reservation wage over the duration of unemployment. We apply our framework to evaluate causal effects of foreign language training programs in Luxembourg, using administrative data on the labor force (IGSS-ADEM dataset). Our findings might be an incentive for the employment agencies to better design and implement future language training programs.},
  archive      = {J_JBES},
  author       = {Michela Bia and Alessandra Mattei and Andrea Mercatanti},
  doi          = {10.1080/07350015.2020.1862672},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {718-729},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Assessing causal effects in a longitudinal observational study with “Truncated” outcomes due to unemployment and nonignorable missing data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonignorable missing data, single index propensity score and
profile synthetic distribution function. <em>JBES</em>, <em>40</em>(2),
705–717. (<a
href="https://doi.org/10.1080/07350015.2020.1860065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In missing data problems, missing not at random is difficult to handle since the response probability or propensity score is confounded with the outcome data model in the likelihood. Existing works often assume the propensity score is known up to a finite dimensional parameter. We relax this assumption and consider an unspecified single index model for the propensity score. A pseudo-likelihood based on the complete data is constructed by profiling out a synthetic distribution function that involves the unknown propensity score. The pseudo-likelihood gives asymptotically normal estimates. Simulations show the method compares favorably with existing methods.},
  archive      = {J_JBES},
  author       = {Xuerong Chen and Denis Heng-Yan Leung and Jing Qin},
  doi          = {10.1080/07350015.2020.1860065},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {705-717},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonignorable missing data, single index propensity score and profile synthetic distribution function},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling multivariate time series with copula-linked
univariate d-vines. <em>JBES</em>, <em>40</em>(2), 690–704. (<a
href="https://doi.org/10.1080/07350015.2020.1859381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel multivariate time series model named copula-linked univariate D-vines (CuDvine), which enables the simultaneous copula-based modeling of both temporal and cross-sectional dependence for multivariate time series. To construct CuDvine, we first build a semiparametric univariate D-vine time series model (uDvine) based on a D-vine. The uDvine generalizes the existing first-order copula-based Markov chain models to Markov chains of an arbitrary-order. Building upon uDvine, we construct CuDvine by linking multiple uDvines via a parametric copula. As a simple and tractable model, CuDvine provides flexible models for marginal behavior and temporal dependence of time series, and can also incorporate sophisticated cross-sectional dependence such as time-varying and spatio-temporal dependence for high-dimensional applications. Robust and computationally efficient procedures, including a sequential model selection method and a two-stage MLE, are proposed for model estimation and inference, and their statistical properties are investigated. Numerical experiments are conducted to demonstrate the flexibility of CuDvine, and to examine the performance of the sequential model selection procedure and the two-stage MLE. Real data applications on the Australian electricity price data demonstrate the superior performance of CuDvine to traditional multivariate time series models.},
  archive      = {J_JBES},
  author       = {Zifeng Zhao and Peng Shi and Zhengjun Zhang},
  doi          = {10.1080/07350015.2020.1859381},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {690-704},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Modeling multivariate time series with copula-linked univariate D-vines},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A stochastic volatility model with a general leverage
specification. <em>JBES</em>, <em>40</em>(2), 678–689. (<a
href="https://doi.org/10.1080/07350015.2020.1855187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new stochastic volatility model that postulates a general correlation structure between the shocks of the measurement and log volatility equations at different temporal lags. The resulting specification is able to better characterize the leverage effect and propagation in financial time series. Furthermore, it nests other asymmetric volatility models and can be used for testing and diagnostics. We derive the simulated maximum likelihood and quasi maximum likelihood estimators and investigate their finite sample performance in a simulation study. An empirical illustration shows that the postulated correlation structure improves the fit of the leverage propagation and leads to more precise volatility predictions.},
  archive      = {J_JBES},
  author       = {Leopoldo Catania},
  doi          = {10.1080/07350015.2020.1855187},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {678-689},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A stochastic volatility model with a general leverage specification},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric estimation and testing for positive quadrant
dependent bivariate copula. <em>JBES</em>, <em>40</em>(2), 664–677. (<a
href="https://doi.org/10.1080/07350015.2020.1855186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many practical scenarios (e.g., finance, system reliability, etc.), it is often of interest to estimate a bivariate distribution and test for some desired association properties like positive quadrant dependent (PQD) or negative quadrant dependent (NQD). Often estimation and testing for PQD/NQD property are performed using copula models as it then eliminates the need for estimating marginal distributions. Many parametric copula families have been used that allow for controlling the PQD/NQD property by a finite dimensional parameter (often just real-valued) and the problem reduces to the straightforward estimation and testing for fixed dimensional parameter using standard statistical methodologies (e.g., maximum likelihood). This article extends such a line of work by dropping any parametric assumptions and provides a fully data-dependent automated approach to estimate a copula and test for PQD property. The estimator is shown to be large-sample consistent under a set of mild regularity conditions. Numerical illustrations based on simulated data are also provided to compare the performance of the proposed testing procedure with some available methods and applications to real case studies are also provided.},
  archive      = {J_JBES},
  author       = {Lu Lu and Sujit K. Ghosh},
  doi          = {10.1080/07350015.2020.1855186},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {664-677},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric estimation and testing for positive quadrant dependent bivariate copula},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Laplace estimator of integrated volatility when sampling
times are endogenous. <em>JBES</em>, <em>40</em>(2), 651–663. (<a
href="https://doi.org/10.1080/07350015.2020.1855185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of nonparametric volatility estimators based on the Laplace transform, which are robust to the presence of the endogeneity of observation times. Asymptotic properties and feasible central limit theorems are established. In the presence of time endogeneity, our bias-corrected Laplace estimator takes advantage of the informational content of time endogeneity, which leads to narrower confidence bounds. The finite sample properties of the estimator are studied through Monte Carlo simulations. Through the simulation study, we also find that due to the presence of the kernel, Laplace estimator could be adopted in a model with microstructure noise. The performance of the Laplace estimator is compared with other commonly used estimators through forecasting exercises by employing high frequency data. We conclude that the bias-corrected Laplace estimator performs better than most estimators in terms of forecasting equity return volatility in the presence of both time endogeneity and market microstructure noise.},
  archive      = {J_JBES},
  author       = {Wenhao Cui},
  doi          = {10.1080/07350015.2020.1855185},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {651-663},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Laplace estimator of integrated volatility when sampling times are endogenous},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LM tests for joint breaks in the dynamics and level of a
long-memory time series. <em>JBES</em>, <em>40</em>(2), 629–650. (<a
href="https://doi.org/10.1080/07350015.2020.1855184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a single-step Lagrange multiplier (LM) test for joint breaks (at known or unknown dates) in the long memory parameter, the short-run dynamics, and the level of a fractionally integrated time-series process. The regression version of this test is easily implementable and allows to identify the specific sources of the break when the null hypothesis of parameter stability is rejected. However, its size and power properties are sensitive to the correct specification of short-run dynamics under the null. To address this problem, we propose a slight modification of the LM test (labeled LMW-type test) which also makes use of some information under the alternative (in the spirit of a Wald test). This test shares the same limiting distribution as the LM test under the null and local alternatives but achieves higher power by facilitating the correct specification of the short-run dynamics under the null and any alternative (either local or fixed). Monte Carlo simulations provide support for these theoretical results. An empirical application, concerning the origin of shifts in the long-memory properties of forward discount rates in five G7 countries, illustrates the usefulness of the proposed LMW-type test.},
  archive      = {J_JBES},
  author       = {Juan J. Dolado and Heiko Rachinger and Carlos Velasco},
  doi          = {10.1080/07350015.2020.1855184},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {629-650},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {LM tests for joint breaks in the dynamics and level of a long-memory time series},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust estimation of additive boundaries with quantile
regression and shape constraints. <em>JBES</em>, <em>40</em>(2),
615–628. (<a
href="https://doi.org/10.1080/07350015.2020.1847123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the estimation of the boundary of a set when it is known to be sufficiently smooth, to satisfy certain shape constraints and to have an additive structure. Our proposed method is based on spline estimation of a conditional quantile regression and is resistant to outliers and/or extreme values in the data. This work is a desirable extension of existing works in the literature and can also be viewed as an alternative to existing estimators that have been used in empirical analysis. The results of a Monte Carlo study show that the new method outperforms the existing methods when outliers or heterogeneity are present. Our theoretical analysis indicates that our proposed boundary estimator is uniformly consistent under a set of standard assumptions. We illustrate practical use of our method by estimating two production functions using real-world datasets.},
  archive      = {J_JBES},
  author       = {Yan Fang and Lan Xue and Carlos Martins-Filho and Lijian Yang},
  doi          = {10.1080/07350015.2020.1847123},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {615-628},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Robust estimation of additive boundaries with quantile regression and shape constraints},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Instrument validity tests with causal forests.
<em>JBES</em>, <em>40</em>(2), 605–614. (<a
href="https://doi.org/10.1080/07350015.2020.1847122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assumptions that are sufficient to identify local average treatment effects (LATEs) generate necessary conditions that allow instrument validity to be refuted. The degree to which instrument validity is violated, however, probably varies across subpopulations. In this article, we use causal forests to search and test for such local violations of the LATE assumptions in a data-driven way. Unlike previous instrument validity tests, our procedure is able to detect local violations. We evaluate the performance of our procedure in simulations and apply it in two different settings: parental preferences for mixed-sex composition of children and the Vietnam draft lottery.},
  archive      = {J_JBES},
  author       = {Helmut Farbmacher and Raphael Guber and Sven Klaassen},
  doi          = {10.1080/07350015.2020.1847122},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {605-614},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Instrument validity tests with causal forests},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential scaled sparse factor regression. <em>JBES</em>,
<em>40</em>(2), 595–604. (<a
href="https://doi.org/10.1080/07350015.2020.1844212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale association analysis between multivariate responses and predictors is of great practical importance, as exemplified by modern business applications including social media marketing and crisis management. Despite the rapid methodological advances, how to obtain scalable estimators with free tuning of the regularization parameters remains unclear under general noise covariance structures. In this article, we develop a new methodology called sequential scaled sparse factor regression (SESS) based on a new viewpoint that the problem of recovering a jointly low-rank and sparse regression coefficient matrix can be decomposed into several univariate response sparse regressions through regular eigenvalue decomposition. It combines the strengths of sequential estimation and scaled sparse regression, thus sharing the scalability and the tuning free property for sparsity parameters inherited from the two approaches. The stepwise convex formulation, sequential factor regression framework, and tuning insensitiveness make SESS highly scalable for big data applications. Comprehensive theoretical justifications with new insights into high-dimensional multi-response regressions are also provided. We demonstrate the scalability and effectiveness of the proposed method by simulation studies and stock short interest data analysis.},
  archive      = {J_JBES},
  author       = {Zemin Zheng and Yang Li and Jie Wu and Yuchen Wang},
  doi          = {10.1080/07350015.2020.1844212},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {595-604},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Sequential scaled sparse factor regression},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network-based clustering for varying coefficient panel data
models. <em>JBES</em>, <em>40</em>(2), 578–594. (<a
href="https://doi.org/10.1080/07350015.2020.1841648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce a novel varying-coefficient panel-data model with locally stationary regressors and unknown group structure, in which the number of groups and the group membership are left unspecified. We develop a triple-localization approach to estimate the unknown subject-specific coefficient functions and then identify the latent group structure via community detection. To improve the efficiency of the first-stage estimator, we further propose a two-stage estimation method that enables the estimator to achieve optimal rates of convergence. In the theoretical part of the article, we derive the asymptotic theory of the resultant estimators. In the empirical part, we present several simulated examples together with an analysis of real data to illustrate the finite-sample performance of the proposed method.},
  archive      = {J_JBES},
  author       = {Youquan Pei and Tao Huang and Heng Peng and Jinhong You},
  doi          = {10.1080/07350015.2020.1841648},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {578-594},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Network-based clustering for varying coefficient panel data models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic discrete mixtures for high-frequency prices.
<em>JBES</em>, <em>40</em>(2), 559–577. (<a
href="https://doi.org/10.1080/07350015.2020.1840994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tick structure of the financial markets entails discreteness of stock price changes. Based on this empirical evidence, we develop a multivariate model for discrete price changes featuring a mechanism to account for the large share of zero returns at high frequency. We assume that the observed price changes are independent conditional on the realization of two hidden Markov chains determining the dynamics and the distribution of the multivariate time series at hand. We study the properties of the model, which is a dynamic mixture of zero-inflated Skellam distributions. We develop an expectation-maximization algorithm with closed-form M-step that allows us to estimate the model by maximum likelihood. In the empirical application, we study the joint distribution of the price changes of a number of assets traded on NYSE. Particular focus is dedicated to the assessment of the quality of univariate and multivariate density forecasts, and of the precision of the predictions of moments like volatility and correlations. Finally, we look at the predictability of price staleness and its determinants in relation to the trading activity on the financial markets.},
  archive      = {J_JBES},
  author       = {Leopoldo Catania and Roberto Di Mari and Paolo Santucci de Magistris},
  doi          = {10.1080/07350015.2020.1840994},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {559-577},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Dynamic discrete mixtures for high-frequency prices},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian model averaging for spatial autoregressive models
based on convex combinations of different types of connectivity
matrices. <em>JBES</em>, <em>40</em>(2), 547–558. (<a
href="https://doi.org/10.1080/07350015.2020.1840993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a great deal of literature regarding use of nongeographically based connectivity matrices or combinations of geographic and non-geographic structures in spatial econometric models. We focus on convex combinations of weight matrices that result in a single weight matrix reflecting multiple types of connectivity, where coefficients from the convex combination can be used for inference regarding the relative importance of each type of connectivity in the global cross-sectional dependence scheme. We tackle the question of model uncertainty regarding selection of the best convex combination by Bayesian model averaging. We use Metropolis–Hastings guided Monte Carlo integration during MCMC estimation of the models to produce log-marginal likelihoods and associated posterior model probabilities. We focus on MCMC estimation, computation of posterior model probabilities, model averaged estimates of the parameters, scalar summary measures of the non-linear partial derivative impacts, and their associated empirical measures of dispersion.},
  archive      = {J_JBES},
  author       = {Nicolas Debarsy and James P. LeSage},
  doi          = {10.1080/07350015.2020.1840993},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {547-558},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Bayesian model averaging for spatial autoregressive models based on convex combinations of different types of connectivity matrices},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric copula estimation for mixed insurance claim
data. <em>JBES</em>, <em>40</em>(2), 537–546. (<a
href="https://doi.org/10.1080/07350015.2020.1835668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate claim data are common in insurance applications, for example, claims of each policyholder from different types of insurance coverages. Understanding the dependencies among such multivariate risks is critical to the solvency and profitability of insurers. Effectively modeling insurance claim data is challenging due to their special complexities. At the policyholder level, claim outcomes usually follow a two-part mixed distribution: a probability mass at zero corresponding to no claim and an otherwise positive claim from a skewed and long-tailed distribution. To simultaneously accommodate the complex features of the marginal distributions while flexibly quantifying the dependencies among multivariate claims, copula models are commonly used. Although a substantial body of literature focusing on copulas with continuous outcomes has emerged, some key steps do not carry over to mixed data. In particular, existing nonparametric copula estimators are not consistent for mixed data, and thus copula specification and diagnostics for mixed outcomes have been a problem. However, insurance is a closely regulated industry in which model validation is particularly important, and it is essential to develop a baseline nonparametric copula estimator to identify the underlying dependence structure. In this article, we fill in this gap by developing a nonparametric copula estimator for mixed data. We show the uniform convergence of the proposed nonparametric copula estimator. Through simulation studies, we demonstrate that the proportion of zeros plays a key role in the finite sample performance of the proposed estimator. Using the claim data from the Wisconsin Local Government Property Insurance Fund, we illustrate that our nonparametric copula estimator can assist analysts in identifying important features of the underlying dependence structure, revealing how different claims or risks are related to one another.},
  archive      = {J_JBES},
  author       = {Lu Yang},
  doi          = {10.1080/07350015.2020.1835668},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {537-546},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric copula estimation for mixed insurance claim data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of extremal expectile based on regression models
with heteroscedastic extremes. <em>JBES</em>, <em>40</em>(2), 522–536.
(<a href="https://doi.org/10.1080/07350015.2020.1833890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expectile recently receives much attention for its coherence as a tail risk measure. Estimation of conditional expectile at extremal tails is of great interest in quantitative risk management. Regression analysis is a convenient and useful way to quantify the conditional effect of some predictors or risk factors on an interesting response variable. However, when it comes to the estimation of extremal conditional expectile, the traditional inference methods may suffer from considerable variation due to a lack of sufficient samples on tail regions, which makes the prediction inaccurate. In this article, we study the estimation of extremal conditional expectile based on quantile regression and expectile regression models. We propose three methods to make extrapolation based on a second-order condition for a framework of the so-called conditionally heteroscedastic and unconditionally homoscedastic extremes. In addition, we establish the asymptotic properties of the proposed methods and show their empirical behaviors through simulation studies. Finally, data analysis is conducted to illustrate the applications of the proposed methods in real problems.},
  archive      = {J_JBES},
  author       = {Wen Xu and Yanxi Hou and Deyuan Li},
  doi          = {10.1080/07350015.2020.1833890},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {522-536},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Prediction of extremal expectile based on regression models with heteroscedastic extremes},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simple asymptotically f-distributed portmanteau test for
diagnostic checking of time series models with uncorrelated innovations.
<em>JBES</em>, <em>40</em>(2), 505–521. (<a
href="https://doi.org/10.1080/07350015.2020.1832505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simple asymptotically F-distributed portmanteau test for diagnostically checking whether the innovations in a parametric time series model are uncorrelated while allowing them to exhibit higher-order dependence of unknown forms. A transform of sample residual autocovariances removing the influence of parameter estimation uncertainty makes the test simple. Further, by employing the orthonormal series variance estimator, a special sample autocovariances estimator that is asymptotically invariant to parameter estimation uncertainty, we show that the proposed test statistic is asymptotically F-distributed under fixed-smoothing asymptotics. The asymptotic F-theory accounts for the estimation error of the variance estimator that the asymptotic chi-squared theory ignores. Moreover, an extensive Monte Carlo study demonstrates that the F-test has more accurate finite sample size than existing tests with virtually no power loss. An application to S&amp;P 500 returns illustrates the merits of the proposed methodology.},
  archive      = {J_JBES},
  author       = {Xuexin Wang and Yixiao Sun},
  doi          = {10.1080/07350015.2020.1832505},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {505-521},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A simple asymptotically F-distributed portmanteau test for diagnostic checking of time series models with uncorrelated innovations},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Rejoinder: “Co-citation and co-authorship networks of
statisticians.” <em>JBES</em>, <em>40</em>(2), 499–504. (<a
href="https://doi.org/10.1080/07350015.2022.2055358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Pengsheng Ji and Jiashun Jin and Zheng Tracy Ke and Wanshan Li},
  doi          = {10.1080/07350015.2022.2055358},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {499-504},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Rejoinder: “Co-citation and co-authorship networks of statisticians”},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “co-citation and co-authorship networks of
statisticians.” <em>JBES</em>, <em>40</em>(2), 497–498. (<a
href="https://doi.org/10.1080/07350015.2022.2044828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Joshua Daniel Loyal and Yuguo Chen},
  doi          = {10.1080/07350015.2022.2044828},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {497-498},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of “Co-citation and co-authorship networks of statisticians”},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “co-citation and co-authorship networks of
statisticians.” <em>JBES</em>, <em>40</em>(2), 494–496. (<a
href="https://doi.org/10.1080/07350015.2022.2044335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Xiaojing Zhu and Eric D. Kolaczyk},
  doi          = {10.1080/07350015.2022.2044335},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {494-496},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of “Co-citation and co-authorship networks of statisticians”},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “co-citation and co-authorship networks of
statisticians” by pengsheng ji, jiashun jin, zheng tracy ke, and wanshan
li. <em>JBES</em>, <em>40</em>(2), 492–493. (<a
href="https://doi.org/10.1080/07350015.2022.2041423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {Peter W. MacDonald and Elizaveta Levina and Ji Zhu},
  doi          = {10.1080/07350015.2022.2041423},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {492-493},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of “Co-citation and co-authorship networks of statisticians” by pengsheng ji, jiashun jin, zheng tracy ke, and wanshan li},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data come first: Discussion of “co-citation and
co-authorship networks of statisticians.” <em>JBES</em>, <em>40</em>(2),
491. (<a href="https://doi.org/10.1080/07350015.2022.2055356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  author       = {David Donoho},
  doi          = {10.1080/07350015.2022.2055356},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {491},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Data come first: Discussion of “Co-citation and co-authorship networks of statisticians”},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discussion of “cocitation and coauthorship networks of
statisticians.” <em>JBES</em>, <em>40</em>(2), 486–490. (<a
href="https://doi.org/10.1080/07350015.2022.2037432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We congratulate the authors for their stimulating and thought-provoking work on network data analysis. In the article, the authors not only introduce a new large-scale and high-quality publication dataset that will surely become an important benchmark for further network research, but also present novel statistical methods and modeling which lead to very interesting findings about the statistics community. There is much material for thought and exploration. In this discussion, we will focus on the cocitation networks, and discuss a few points for the coauthorship networks toward the end.},
  archive      = {J_JBES},
  author       = {Haolei Weng and Yang Feng},
  doi          = {10.1080/07350015.2022.2037432},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {486-490},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Discussion of “Cocitation and coauthorship networks of statisticians”},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Co-citation and co-authorship networks of statisticians.
<em>JBES</em>, <em>40</em>(2), 469–485. (<a
href="https://doi.org/10.1080/07350015.2021.1978469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We collected and cleaned a large dataset on publications in statistics. The dataset consists of the co-author relationships and citation relationships of 83, 331 articles published in 36 representative journals in statistics, probability, and machine learning, spanning 41 years. The dataset allows us to construct many different networks, and motivates a number of research problems about the research patterns and trends, research impacts, and network topology of the statistics community. In this article we focus on (i) using the citation relationships to estimate the research interests of authors, and (ii) using the co-author relationships to study the network topology. Using co-citation networks we constructed, we discover a “statistics triangle,” reminiscent of the statistical philosophy triangle (Efron Citation 1998 ). We propose new approaches to constructing the “research map” of statisticians, as well as the “research trajectory” for a given author to visualize his/her research interest evolvement. Using co-authorship networks we constructed, we discover a multi-layer community tree and produce a Sankey diagram to visualize the author migrations in different sub-areas. We also propose several new metrics for research diversity of individual authors. We find that “Bayes,” “Biostatistics,” and “Nonparametric” are three primary areas in statistics. We also identify 15 sub-areas, each of which can be viewed as a weighted average of the primary areas, and identify several underlying reasons for the formation of co-authorship communities. We also find that the research interests of statisticians have evolved significantly in the 41-year time window we studied: some areas (e.g., biostatistics, high-dimensional data analysis, etc.) have become increasingly more popular. The research diversity of statisticians may be lower than we might have expected. For example, for the personalized networks of most authors, the p -values of the proposed significance tests are relatively large.},
  archive      = {J_JBES},
  author       = {Pengsheng Ji and Jiashun Jin and Zheng Tracy Ke and Wanshan Li},
  doi          = {10.1080/07350015.2021.1978469},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {4},
  number       = {2},
  pages        = {469-485},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Co-citation and co-authorship networks of statisticians},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correction. <em>JBES</em>, <em>40</em>(1), 467. (<a
href="https://doi.org/10.1080/07350015.2021.1971536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JBES},
  doi          = {10.1080/07350015.2021.1971536},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {467},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Correction},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling tail index with autoregressive conditional pareto
model. <em>JBES</em>, <em>40</em>(1), 458–466. (<a
href="https://doi.org/10.1080/07350015.2020.1832504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an autoregressive conditional Pareto (AcP) model based on the dynamic peaks over threshold method to model a dynamic tail index in the financial markets. Unlike the score-based approach which is widely used in many articles, we use an exponential function to model the tail index process for its intuitiveness and interpretability. Probabilistic properties of the AcP model and the statistical properties of its parameter estimators of maximum likelihood are studied in this article. Real data are used to show the advantages of AcP, especially, compared to the estimation volatility of GARCH model, the result of AcP is more sensitive to turmoil. The estimated tail index of AcP can accurately reflect the risk of the stock and may even play an early warning role to the turmoil of stock market. We also calculate the tail connectedness based on the estimated tail index of AcP and show that tail connectedness increases during period of turmoil, which is consistent with the result of the score-based approach.},
  archive      = {J_JBES},
  author       = {Zhouyu Shen and Yu Chen and Ruxin Shi},
  doi          = {10.1080/07350015.2020.1832504},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {458-466},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Modeling tail index with autoregressive conditional pareto model},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Functional linear regression: Dependence and error
contamination. <em>JBES</em>, <em>40</em>(1), 444–457. (<a
href="https://doi.org/10.1080/07350015.2020.1832503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional linear regression is an important topic in functional data analysis. It is commonly assumed that samples of the functional predictor are independent realizations of an underlying stochastic process, and are observed over a grid of points contaminated by iid measurement errors. In practice, however, the dynamical dependence across different curves may exist and the parametric assumption on the error covariance structure could be unrealistic. In this article, we consider functional linear regression with serially dependent observations of the functional predictor, when the contamination of the predictor by the white noise is genuinely functional with fully nonparametric covariance structure. Inspired by the fact that the autocovariance function of observed functional predictors automatically filters out the impact from the unobservable noise term, we propose a novel autocovariance-based generalized method-of-moments estimate of the slope function. We also develop a nonparametric smoothing approach to handle the scenario of partially observed functional predictors. The asymptotic properties of the resulting estimators under different scenarios are established. Finally, we demonstrate that our proposed method significantly outperforms possible competing methods through an extensive set of simulations and an analysis of a public financial dataset.},
  archive      = {J_JBES},
  author       = {Cheng Chen and Shaojun Guo and Xinghao Qiao},
  doi          = {10.1080/07350015.2020.1832503},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {444-457},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Functional linear regression: Dependence and error contamination},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Direct and indirect effects based on changes-in-changes.
<em>JBES</em>, <em>40</em>(1), 432–443. (<a
href="https://doi.org/10.1080/07350015.2020.1831929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel approach for causal mediation analysis based on changes-in-changes assumptions restricting unobserved heterogeneity over time. This allows disentangling the causal effect of a binary treatment on a continuous outcome into an indirect effect operating through a binary intermediate variable (called mediator) and a direct effect running via other causal mechanisms. We identify average and quantile direct and indirect effects for various subgroups under the condition that the outcome is monotonic in the unobserved heterogeneity and that the distribution of the latter does not change over time conditional on the treatment and the mediator. We also provide a simulation study and two empirical applications regarding a training program evaluation and maternity leave reform.},
  archive      = {J_JBES},
  author       = {Martin Huber and Mark Schelker and Anthony Strittmatter},
  doi          = {10.1080/07350015.2020.1831929},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {432-443},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Direct and indirect effects based on changes-in-changes},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Can GDP measurement be further improved? Data revision and
reconciliation. <em>JBES</em>, <em>40</em>(1), 423–431. (<a
href="https://doi.org/10.1080/07350015.2020.1831928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen many attempts to combine expenditure-side estimates of U.S. real output (GDE) growth with income-side estimates (GDI) to improve estimates of real GDP growth. We show how to incorporate information from multiple releases of noisy data to provide more precise estimates while avoiding some of the identifying assumptions required in earlier work. This relies on a new insight: using multiple data releases allows us to distinguish news and noise measurement errors in situations where a single vintage does not. We find that (a) the data prefer averaging across multiple releases instead of discarding early releases in favor of later ones, and (b) that initial estimates of GDI are quite informative. Our new measure, GDP ++ , undergoes smaller revisions and tracks expenditure measures of GDP growth more closely than either the simple average of the expenditure and income measures published by the BEA or the GDP growth measure of Aruoba et al. published by the Federal Reserve Bank of Philadelphia.},
  archive      = {J_JBES},
  author       = {Jan P. A. M. Jacobs and Samad Sarferaz and Jan-Egbert Sturm and Simon van Norden},
  doi          = {10.1080/07350015.2020.1831928},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {423-431},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Can GDP measurement be further improved? data revision and reconciliation},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Homogeneity and structure identification in semiparametric
factor models. <em>JBES</em>, <em>40</em>(1), 408–422. (<a
href="https://doi.org/10.1080/07350015.2020.1831516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor modeling is an essential tool for exploring intrinsic dependence structures in financial and economic studies through the construction of common latent variables, including the famous Fama–French three factor models for the description of asset returns in finance. However, most of the existing statistical methods for analyzing latent factors have been developed through a linear approach. In this article, we consider a semiparametric factor model and present a regularized estimation procedure for linear component identification on the transformed factor that combines B-spline basis function approximations and the smoothly clipped absolute deviation penalty. In addition, a binary segmentation based algorithm is also developed to identify the homogeneous groups in loading parameters, producing more efficient estimation by pooling information across units within the same group. We carefully derive the asymptotic properties for the proposed procedures. Finally, simulation studies and a real data analysis are conducted to evaluate the finite sample performance of our proposals.},
  archive      = {J_JBES},
  author       = {Chaohui Guo and Jialiang Li},
  doi          = {10.1080/07350015.2020.1831516},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {408-422},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Homogeneity and structure identification in semiparametric factor models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A projective approach to conditional independence test for
dependent processes. <em>JBES</em>, <em>40</em>(1), 398–407. (<a
href="https://doi.org/10.1080/07350015.2020.1826952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional independence is a fundamental concept in many scientific fields. In this article, we propose a projective approach to measuring and testing departure from conditional independence for dependent processes. Through projecting high-dimensional dependent processes on to low-dimensional subspaces, our proposed projective approach is insensitive to the dimensions of the processes. We show that, under the common β -mixing conditions, our proposed projective test statistic is n -consistent if these processes are conditionally independent and root- n -consistent otherwise. We suggest a bootstrap procedure to approximate the asymptotic null distribution of the test statistic. The consistency of this bootstrap procedure is also rigorously established. The finite-sample performance of our proposed projective test is demonstrated through simulations against various alternatives and an economic application to test for Granger causality.},
  archive      = {J_JBES},
  author       = {Yeqing Zhou and Yaowu Zhang and Liping Zhu},
  doi          = {10.1080/07350015.2020.1826952},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {398-407},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A projective approach to conditional independence test for dependent processes},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonlinear predictability of stock returns? Parametric versus
nonparametric inference in predictive regressions. <em>JBES</em>,
<em>40</em>(1), 382–397. (<a
href="https://doi.org/10.1080/07350015.2020.1819821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric test procedures in predictive regressions have χ 2 χ 2 χ2 limiting null distributions under both low and high regressor persistence, but low local power compared to misspecified linear predictive regressions. We argue that IV inference is better suited (in terms of local power) for analyzing additive predictive models with uncertain predictor persistence. Then, a two-step procedure is proposed for out-of-sample predictions. For the current estimation window, one first tests for predictability; in case of a rejection, one predicts using a nonlinear regression model, otherwise the historic average of the stock returns is used. This two-step approach performs better than competitors (though not by a large margin) in a pseudo-out-of-sample prediction exercise for the S&amp;P 500.},
  archive      = {J_JBES},
  author       = {Matei Demetrescu and Benjamin Hillmann},
  doi          = {10.1080/07350015.2020.1819821},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {382-397},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonlinear predictability of stock returns? parametric versus nonparametric inference in predictive regressions},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction in locally stationary time series. <em>JBES</em>,
<em>40</em>(1), 370–381. (<a
href="https://doi.org/10.1080/07350015.2020.1819296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an estimator for the high-dimensional covariance matrix of a locally stationary process with a smoothly varying trend and use this statistic to derive consistent predictors in nonstationary time series. In contrast to the currently available methods for this problem the predictor developed here does not rely on fitting an autoregressive model and does not require a vanishing trend. The finite sample properties of the new methodology are illustrated by means of a simulation study and a financial indices study. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Holger Dette and Weichi Wu},
  doi          = {10.1080/07350015.2020.1819296},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {370-381},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Prediction in locally stationary time series},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Substitution bias in multilateral methods for CPI
construction. <em>JBES</em>, <em>40</em>(1), 355–369. (<a
href="https://doi.org/10.1080/07350015.2020.1816176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of multilateral indexes is increasingly an accepted approach for incorporating scanner data in a consumer price index. The attractiveness stems from the ability to be able to control for chain drift bias. Consensus on two key issues has yet to be achieved: (i) the best multilateral method to use, and (ii) the best way of extending the resulting series when new observations become available. We present theoretical and simulation evidence on the extent of substitution biases in alternative methods. Our results suggest the use of the Caves–Christensen–Diewert–Inklaar index with a new method, the “mean splice,” for updating.},
  archive      = {J_JBES},
  author       = {W. Erwin Diewert and Kevin J. Fox},
  doi          = {10.1080/07350015.2020.1816176},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {355-369},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Substitution bias in multilateral methods for CPI construction},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonparametric estimation and conformal inference of the
sufficient forecasting with a diverging number of factors.
<em>JBES</em>, <em>40</em>(1), 342–354. (<a
href="https://doi.org/10.1080/07350015.2020.1813589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sufficient forecasting (SF) provides a nonparametric procedure to estimate forecasting indices from high-dimensional predictors to forecast a single time series, allowing for the possibly nonlinear forecasting function. This article studies the asymptotic theory of the SF with a diverging number of factors and develops its predictive inference. First, we revisit the SF and explore its connections to Fama–MacBeth regression and partial least squares. Second, with a diverging number of factors, we derive the rate of convergence of the estimated factors and loadings and characterize the asymptotic behavior of the estimated SF directions. Third, we use the local linear regression to estimate the possibly nonlinear forecasting function and obtain the rate of convergence. Fourth, we construct the distribution-free conformal prediction set for the SF that accounts for the serial dependence. Moreover, we demonstrate the finite-sample performance of the proposed nonparametric estimation and conformal inference in simulation studies and a real application to forecast financial time series.},
  archive      = {J_JBES},
  author       = {Xiufan Yu and Jiawei Yao and Lingzhou Xue},
  doi          = {10.1080/07350015.2020.1813589},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {342-354},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonparametric estimation and conformal inference of the sufficient forecasting with a diverging number of factors},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of structural vector autoregressions by
stochastic volatility. <em>JBES</em>, <em>40</em>(1), 328–341. (<a
href="https://doi.org/10.1080/07350015.2020.1813588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose to exploit stochastic volatility for statistical identification of structural vector autoregressive models (SV-SVAR). We discuss full and partial identification of the model and develop efficient EM algorithms for maximum likelihood inference. Simulation evidence suggests that the SV-SVAR works well in identifying structural parameters also under misspecification of the variance process, particularly if compared to alternative heteroscedastic SVARs. We apply the model to study the importance of oil supply shocks for driving oil prices. Since shocks identified by heteroscedasticity may not be economically meaningful, we exploit the framework to test instrumental variable restrictions which are overidentifying in the heteroscedastic model. Our findings suggest that conventional supply shocks are negligible, while news shocks about future supply account for almost all the variation in oil prices.},
  archive      = {J_JBES},
  author       = {Dominik Bertsche and Robin Braun},
  doi          = {10.1080/07350015.2020.1813588},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {328-341},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identification of structural vector autoregressions by stochastic volatility},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of conditional average treatment effects with
high-dimensional data. <em>JBES</em>, <em>40</em>(1), 313–327. (<a
href="https://doi.org/10.1080/07350015.2020.1811102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the unconfoundedness assumption, we propose new nonparametric estimators for the reduced dimensional conditional average treatment effect (CATE) function. In the first stage, the nuisance functions necessary for identifying CATE are estimated by machine learning methods, allowing the number of covariates to be comparable to or larger than the sample size. The second stage consists of a low-dimensional local linear regression, reducing CATE to a function of the covariate(s) of interest. We consider two variants of the estimator depending on whether the nuisance functions are estimated over the full sample or over a hold-out sample. Building on Belloni at al. and Chernozhukov et al., we derive functional limit theory for the estimators and provide an easy-to-implement procedure for uniform inference based on the multiplier bootstrap. The empirical application revisits the effect of maternal smoking on a baby’s birth weight as a function of the mother’s age.},
  archive      = {J_JBES},
  author       = {Qingliang Fan and Yu-Chin Hsu and Robert P. Lieli and Yichong Zhang},
  doi          = {10.1080/07350015.2020.1811102},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {313-327},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimation of conditional average treatment effects with high-dimensional data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-dimensional factor analysis without moment
constraints. <em>JBES</em>, <em>40</em>(1), 302–312. (<a
href="https://doi.org/10.1080/07350015.2020.1811101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-dimensional factor model has drawn much attention in the big-data era, to reduce the dimensionality and extract underlying features using a few latent common factors. Conventional methods for estimating the factor model typically requires finite fourth moment of the data, which ignores the effect of heavy-tailedness and thus may result in unrobust or even inconsistent estimation of the factor space and common components. In this article, we propose to recover the factor space by performing principal component analysis to the spatial Kendall’s tau matrix instead of the sample covariance matrix. In a second step, we estimate the factor scores by the ordinary least square regression. Theoretically, we show that under the elliptical distribution framework the factor loadings and scores as well as the common components can be estimated consistently without any moment constraint. The convergence rates of the estimated factor loadings, scores, and common components are provided. The finite sample performance of the proposed procedure is assessed through thorough simulations. An analysis of a financial dataset of asset returns shows the superiority of the proposed method over the classical principle component analysis method.},
  archive      = {J_JBES},
  author       = {Yong He and Xinbing Kong and Long Yu and Xinsheng Zhang},
  doi          = {10.1080/07350015.2020.1811101},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {302-312},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Large-dimensional factor analysis without moment constraints},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leverage, asymmetry, and heavy tails in the high-dimensional
factor stochastic volatility model. <em>JBES</em>, <em>40</em>(1),
285–301. (<a
href="https://doi.org/10.1080/07350015.2020.1806853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a factor stochastic volatility model that incorporates leverage effects, return asymmetry, and heavy tails across all systematic and idiosyncratic model components. Our model leads to a flexible high-dimensional dependence structure that allows for time-varying correlations, tail dependence, and volatility response to both systematic and idiosyncratic return shocks. We develop an efficient Markov chain Monte Carlo algorithm for posterior estimation based on the particle Gibbs, ancestor sampling, particle efficient importance sampling methods, and interweaving strategy. To obtain parsimonious specifications in practice, we build computationally efficient model selection directly into our estimation algorithm. We validate the performance of our proposed estimation method via simulation studies with different model specifications. An empirical study for a sample of U.S. stocks shows that return asymmetry is a systematic phenomenon and our model outperforms other factor models for value-at-risk evaluation.},
  archive      = {J_JBES},
  author       = {Mengheng Li and Marcel Scharth},
  doi          = {10.1080/07350015.2020.1806853},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {285-301},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Leverage, asymmetry, and heavy tails in the high-dimensional factor stochastic volatility model},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the sources of information in the moment structure of
dynamic macroeconomic models. <em>JBES</em>, <em>40</em>(1), 272–284.
(<a href="https://doi.org/10.1080/07350015.2020.1803079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What features of the data are the key sources of information about the parameters in structural macroeconomic models? As such models grow in size and complexity, the answer to this question has become increasingly difficult. This article shows how to identify the main sources of parameter information across different parts of the moment structure of macroeconomic models. In particular, we propose a measure of the relative contribution of information by a given subset of moments with respect to any parameter of interest. The measure is trivial to compute even for large-scale models with many free parameters and observed variables. We illustrate our method with an application to a news-driven business cycle model developed by Schmitt-Grohé and Uribe. Supplementary materials for this article are available online.},
  archive      = {J_JBES},
  author       = {Nikolay Iskrev},
  doi          = {10.1080/07350015.2020.1803079},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {272-284},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {On the sources of information in the moment structure of dynamic macroeconomic models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Latent dirichlet analysis of categorical survey responses.
<em>JBES</em>, <em>40</em>(1), 256–271. (<a
href="https://doi.org/10.1080/07350015.2020.1802285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beliefs are important determinants of an individual’s choices and economic outcomes, so understanding how they comove and differ across individuals is of considerable interest. Researchers often rely on surveys that report individual beliefs as qualitative data. We propose using a Bayesian hierarchical latent class model to analyze the comovements and observed heterogeneity in categorical survey responses. We show that the statistical model corresponds to an economic structural model of information acquisition, which guides interpretation and estimation of the model parameters. An algorithm based on stochastic optimization is proposed to estimate a model for repeated surveys when responses follow a dynamic structure and conjugate priors are not appropriate. Guidance on selecting the number of belief types is also provided. Two examples are considered. The first shows that there is information in the Michigan survey responses beyond the consumer sentiment index that is officially published. The second shows that belief types constructed from survey responses can be used in a subsequent analysis to estimate heterogeneous returns to education.},
  archive      = {J_JBES},
  author       = {Evan Munro and Serena Ng},
  doi          = {10.1080/07350015.2020.1802285},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {256-271},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Latent dirichlet analysis of categorical survey responses},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Counterfactual treatment effects: Estimation and inference.
<em>JBES</em>, <em>40</em>(1), 240–255. (<a
href="https://doi.org/10.1080/07350015.2020.1800479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes statistical methods to evaluate the quantile counterfactual treatment effect (QCTE) if one were to change the composition of the population targeted by a status quo program. QCTE enables a researcher to carry out an ex-ante assessment of the distributional impact of certain policy interventions or to investigate the possible explanations for treatment effect heterogeneity. Assuming unconfoundedness and invariance of the conditional distributions of the potential outcomes, QCTE is identified and can be nonparametrically estimated by a kernel-based method. Viewed as a random function over the continuum of quantile indices, the estimator converges weakly to a zero mean Gaussian process at the parametric rate. We propose a multiplier bootstrap procedure to construct uniform confidence bands, and provide similar results for average effects and for the counterfactually treated subpopulation. We also present Monte Carlo simulations and two counterfactual exercises that provide insight into the heterogeneous earnings effects of the Job Corps training program in the United States.},
  archive      = {J_JBES},
  author       = {Yu-Chin Hsu and Tsung-Chih Lai and Robert P. Lieli},
  doi          = {10.1080/07350015.2020.1800479},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {240-255},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Counterfactual treatment effects: Estimation and inference},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Counterfactual analysis and inference with nonstationary
data. <em>JBES</em>, <em>40</em>(1), 227–239. (<a
href="https://doi.org/10.1080/07350015.2020.1799814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been growing interest in developing econometric tools to conduct counterfactual analysis with aggregate data when a single “treated” unit suffers an intervention, such as a policy change, and there is no obvious control group. Usually, the proposed methods are based on the construction of an artificial/synthetic counterfactual from a pool of “untreated” peers, organized in a panel data structure. In this article, we investigate the consequences of applying such methodologies when the data comprise integrated processes of order 1, I (1), or are trend-stationary. We find that for I (1) processes without a cointegrating relationship (spurious case) the estimator of the effects of the intervention diverges, regardless of its existence. Although spurious regression is a well-known concept in time-series econometrics, they have been ignored in most of the literature on counterfactual estimation based on artificial/synthetic controls. For the case when at least one cointegration relationship exists, we have consistent estimators for the intervention effect albeit with a nonstandard distribution. Finally, we discuss a test based on resampling which can be applied when there is at least one cointegration relationship or when the data are trend-stationary.},
  archive      = {J_JBES},
  author       = {Ricardo Masini and Marcelo C. Medeiros},
  doi          = {10.1080/07350015.2020.1799814},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {227-239},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Counterfactual analysis and inference with nonstationary data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Community detection in partial correlation network models.
<em>JBES</em>, <em>40</em>(1), 216–226. (<a
href="https://doi.org/10.1080/07350015.2020.1798241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a class of partial correlation network models with a community structure for large panels of time series. In the model, the series are partitioned into latent groups such that correlation is higher within groups than between them. We then propose an algorithm that allows one to detect the communities using the eigenvectors of the sample covariance matrix. We study the properties of the procedure and establish its consistency. The methodology is used to study real activity clustering in the United States.},
  archive      = {J_JBES},
  author       = {Christian Brownlees and Guðmundur Stefán Guðmundsson and Gábor Lugosi},
  doi          = {10.1080/07350015.2020.1798241},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {216-226},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Community detection in partial correlation network models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mean-structure and autocorrelation consistent covariance
matrix estimation. <em>JBES</em>, <em>40</em>(1), 201–215. (<a
href="https://doi.org/10.1080/07350015.2020.1796397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider estimation of the asymptotic covariance matrix in nonstationary time series. A nonparametric estimator that is robust against unknown forms of trends and possibly a divergent number of change points (CPs) is proposed. It is algorithmically fast because neither a search for CPs, estimation of trends, nor cross-validation is required. Together with our proposed automatic optimal bandwidth selector, the resulting estimator is both statistically and computationally efficient. It is, therefore, useful in many statistical procedures, for example, CPs detection and construction of simultaneous confidence bands of trends. Empirical studies on four stock market indices are also discussed.},
  archive      = {J_JBES},
  author       = {Kin Wai Chan},
  doi          = {10.1080/07350015.2020.1796397},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {201-215},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Mean-structure and autocorrelation consistent covariance matrix estimation},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). In search of a job: Forecasting employment growth using
google trends. <em>JBES</em>, <em>40</em>(1), 186–200. (<a
href="https://doi.org/10.1080/07350015.2020.1791133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that Google search activity on relevant terms is a strong out-of-sample predictor for future employment growth in the United States over the period 2004–2019 at both short and long horizons. Starting from an initial search term “ jobs ,” we construct a large panel of 172 variables using Google’s own algorithms to find semantically related search queries. The best Google Trends model achieves an out-of-sample R 2 between 29\% and 62\% at horizons spanning from one month to one year ahead, strongly outperforming benchmarks based on a single search query or a large set of macroeconomic, financial, and sentiment predictors. This strong predictability is due to heterogeneity in search terms and extends to industry-level and state-level employment growth using state-level specific search activity. Encompassing tests indicate that when the Google Trends panel is exploited using a nonlinear model, it fully encompasses the macroeconomic forecasts and provides significant information in excess of those.},
  archive      = {J_JBES},
  author       = {Daniel Borup and Erik Christian Montes Schütte},
  doi          = {10.1080/07350015.2020.1791133},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {186-200},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {In search of a job: Forecasting employment growth using google trends},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nonparametric nonclassical measurement error approach to
estimating intergenerational mobility elasticities. <em>JBES</em>,
<em>40</em>(1), 169–185. (<a
href="https://doi.org/10.1080/07350015.2020.1787176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a framework for estimating intergenerational mobility elasticities (IGEs) of children’s income with respect to parental income. We allow the IGEs to be heterogeneous, by leaving the relationship of parental and child incomes unspecified, while acknowledging and addressing the latent nature of both child and parental permanent incomes and the resulted life-cycle bias. Our framework enables us to test the widely imposed assumption that the intergenerational mobility function is linear. Applying our method to the Panel Studies of Income Dynamics data, we decisively reject the commonly imposed linearity assumption and find substantial heterogeneity in the IGEs across the population. We confirm an important finding that the IGEs with respect to parental income exhibit a U-shape pattern, which is occasionally highlighted in the analysis using transition matrices. Specifically, there is a considerable degree of mobility among the broadly defined middle class, but the children of both high- and low-income parents are more likely to be high- and low-income adults, respectively. This result also provides insights into the (intertemporal) Great Gatsby curve, suggesting that a higher level of inequality within one generation may lead to a higher level of social immobility in the next generation in the United States.},
  archive      = {J_JBES},
  author       = {Yonghong An and Le Wang and Ruli Xiao},
  doi          = {10.1080/07350015.2020.1787176},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {169-185},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A nonparametric nonclassical measurement error approach to estimating intergenerational mobility elasticities},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reliable real-time output gap estimates based on a modified
hamilton filter. <em>JBES</em>, <em>40</em>(1), 152–168. (<a
href="https://doi.org/10.1080/07350015.2020.1784747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simple modification of Hamilton’s time series filter that yields reliable and economically meaningful real-time output gap estimates. The original filter relies on 8 quarter ahead forecast errors of a simple autoregression of real GDP. While this approach yields a cyclical component that is hardly revised with new incoming data due to the one-sided filtering approach, it does not cover typical business cycle frequencies evenly, but mutes short and amplifies medium length cycles. Further, as the estimated trend contains high-frequency noise, it can hardly be interpreted as potential GDP. A simple modification based on the mean of 4 to 12 quarter ahead forecast errors shares the favorable real-time properties of the Hamilton filter, but leads to a much better coverage of typical business cycle frequencies and a smooth estimated trend. Based on output growth and inflation forecasts and a comparison to revised output gap estimates from policy institutions, we find that real-time output gaps based on the modified and the original Hamilton filter are economically much more meaningful measures of the business cycle than those based on other simple statistical trend-cycle decomposition techniques, such as the HP or bandpass filter, and should thus be used preferably.},
  archive      = {J_JBES},
  author       = {Josefine Quast and Maik H. Wolters},
  doi          = {10.1080/07350015.2020.1784747},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {152-168},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Reliable real-time output gap estimates based on a modified hamilton filter},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric estimation of a censored regression model
subject to nonparametric sample selection. <em>JBES</em>,
<em>40</em>(1), 141–151. (<a
href="https://doi.org/10.1080/07350015.2020.1784746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a semiparametric estimation method for a censored regression model subject to nonparametric sample selection without the exclusion restriction. Consistency and asymptotic normality of the proposed estimator are established under mild regularity conditions. A Monte Carlo simulation study indicates that the estimator performs well in various designs and outperforms parametric maximum likelihood estimators. An empirical application to female smoking is provided to illustrate the usefulness of the estimator.},
  archive      = {J_JBES},
  author       = {Zhewen Pan and Xianbo Zhou and Yahong Zhou},
  doi          = {10.1080/07350015.2020.1784746},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {141-151},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric estimation of a censored regression model subject to nonparametric sample selection},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating jump activity using multipower variation.
<em>JBES</em>, <em>40</em>(1), 128–140. (<a
href="https://doi.org/10.1080/07350015.2020.1784745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realized multipower variation, originally introduced to eliminate jumps, can be extremely useful for inference in pure-jump models. This article shows how to build a simple and precise estimator of the jump activity index of a semimartingale observed at a high frequency by comparing different multipowers. The novel methodology allows to infer whether a discretely observed process contains a continuous martingale component. The empirical part of the article undertakes a nonparametric analysis of the jump activity of bitcoin and shows that bitcoin is a pure jump process with high jump activity, which is critically different from conventional currencies that include a Brownian motion component.},
  archive      = {J_JBES},
  author       = {Aleksey Kolokolov},
  doi          = {10.1080/07350015.2020.1784745},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {128-140},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimating jump activity using multipower variation},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Treatment versus regime effects of carrots and sticks.
<em>JBES</em>, <em>40</em>(1), 111–127. (<a
href="https://doi.org/10.1080/07350015.2020.1784744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public employment service (PES) agencies and caseworkers (CWs) often have substantial leeway in the design and implementation of active labor market policies for the unemployed, and they use policies to a varying extent. We estimate regime effects which capture how CW and PES affect outcomes through different policy intensities. These operate potentially on all forward-looking job seekers regardless of actual treatment exposure. We consider regime effects for two sets of programs, supporting (“carrots”) and restricting (“sticks”) programs, and contrast regime and treatment effects on unemployment durations, employment, and post-unemployment earnings using register data that contain PES and caseworker identifiers for about 130,000 job spells. Regime effects are important: earnings are higher in a PES if carrot-type programs are used more intensively and stick-type programs are used less intensively. Actual treatment effects on earnings have a similar order of magnitude as regime effects and are positive for participation in carrot-type programs and negative for stick-type treatments. Regime effects are economically substantial. A modest increase in the intended usage of carrots and sticks reduces the total cost of an unemployed individual by up to 7.5\%.},
  archive      = {J_JBES},
  author       = {Patrick Arni and Gerard J. van den Berg and Rafael Lalive},
  doi          = {10.1080/07350015.2020.1784744},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {111-127},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Treatment versus regime effects of carrots and sticks},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-dimensional dynamic covariance matrices with
homogeneous structure. <em>JBES</em>, <em>40</em>(1), 96–110. (<a
href="https://doi.org/10.1080/07350015.2020.1779079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional covariance matrices appear in many disciplines. Much literature has devoted to the research in high-dimensional constant covariance matrices. However, constant covariance matrices are not sufficient in applications, for example, in portfolio allocation, dynamic covariance matrices would be more appropriate. As argued in this article, there are two difficulties in the introduction of dynamic structures into covariance matrices: (1) simply assuming each entry of a covariance matrix is a function of time to introduce the dynamic needed would not work; (2) there is a risk of having too many unknowns to estimate due to the high dimensionality. In this article, we propose a dynamic structure embedded with a homogeneous structure. We will demonstrate the proposed dynamic structure makes more sense in applications and avoids, in the meantime, too many unknown parameters/functions to estimate, due to the embedded homogeneous structure. An estimation procedure is also proposed to estimate the proposed high-dimensional dynamic covariance matrices, and asymptotic properties are established to justify the proposed estimation procedure. Intensive simulation studies show the proposed estimation procedure works very well when the sample size is finite. Finally, we apply the proposed high-dimensional dynamic covariance matrices to portfolio allocation. It is interesting to see the resulting portfolio yields much better returns than some commonly used ones.},
  archive      = {J_JBES},
  author       = {Yuan Ke and Heng Lian and Wenyang Zhang},
  doi          = {10.1080/07350015.2020.1779079},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {96-110},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {High-dimensional dynamic covariance matrices with homogeneous structure},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semiparametric tail index regression. <em>JBES</em>,
<em>40</em>(1), 82–95. (<a
href="https://doi.org/10.1080/07350015.2020.1775616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract– Understanding why extreme events occur is often of major scientific interest in many fields. The occurrence of these events naturally depends on explanatory variables, but there is a severe lack of flexible models with asymptotic theory for understanding this dependence, especially when variables can affect the outcome nonlinearly. This article proposes a novel semiparametric tail index regression model to fill the gap for this purpose. We construct consistent estimators for both parametric and nonparametric components of the model, establish the corresponding asymptotic normality properties for these components that can be applied for further inference, and illustrate the usefulness of the model via extensive Monte Carlo simulation and the analysis of return on equity data and Alps meteorology data.},
  archive      = {J_JBES},
  author       = {Rui Li and Chenlei Leng and Jinhong You},
  doi          = {10.1080/07350015.2020.1775616},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {82-95},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Semiparametric tail index regression},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new approach to dating the reference cycle. <em>JBES</em>,
<em>40</em>(1), 66–81. (<a
href="https://doi.org/10.1080/07350015.2020.1773834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract– This article proposes a new approach to the analysis of the reference cycle turning points, defined on the basis of the specific turning points of a broad set of coincident economic indicators. Each individual pair of specific peaks and troughs from these indicators is viewed as a realization of a mixture of an unspecified number of separate bivariate Gaussian distributions whose different means are the reference turning points. These dates break the sample into separate reference cycle phases, whose shifts are modeled by a hidden Markov chain. The transition probability matrix is constrained so that the specification is equivalent to a multiple change-point model. Bayesian estimation of finite Markov mixture modeling techniques is suggested to estimate the model. Several Monte Carlo experiments are used to show the accuracy of the model to date reference cycles that suffer from short phases, uncertain turning points, small samples, and asymmetric cycles. In the empirical section, we show the high performance of our approach to identifying the US reference cycle, with little difference from the timing of the turning point dates established by the NBER. In a pseudo real-time analysis, we also show the good performance of this methodology in terms of accuracy and speed of detection of turning point dates.},
  archive      = {J_JBES},
  author       = {Maximo Camacho and María Dolores Gadea and Ana Gómez Loscos},
  doi          = {10.1080/07350015.2020.1773834},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {66-81},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A new approach to dating the reference cycle},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive inference in heteroscedastic fractional time series
models. <em>JBES</em>, <em>40</em>(1), 50–65. (<a
href="https://doi.org/10.1080/07350015.2020.1773275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider estimation and inference in fractionally integrated time series models driven by shocks which can display conditional and unconditional heteroscedasticity of unknown form. Although the standard conditional sum-of-squares (CSS) estimator remains consistent and asymptotically normal in such cases, unconditional heteroscedasticity inflates its variance matrix by a scalar quantity, λ &gt; 1 , thereby inducing a loss in efficiency relative to the unconditionally homoscedastic case, λ = 1. We propose an adaptive version of the CSS estimator, based on nonparametric kernel-based estimation of the unconditional volatility process. We show that adaptive estimation eliminates the factor λ from the variance matrix, thereby delivering the same asymptotic efficiency as that attained by the standard CSS estimator in the unconditionally homoscedastic case and, hence, asymptotic efficiency under Gaussianity. Importantly, the asymptotic analysis is based on a novel proof strategy, which does not require consistent estimation (in the sup norm) of the volatility process. Consequently, we are able to work under a weaker set of assumptions than those employed in the extant literature. The asymptotic variance matrices of both the standard and adaptive CSS (ACSS) estimators depend on any weak parametric autocorrelation present in the fractional model and any conditional heteroscedasticity in the shocks. Consequently, asymptotically pivotal inference can be achieved through the development of confidence regions or hypothesis tests using either heteroscedasticity-robust standard errors and/or a wild bootstrap. Monte Carlo simulations and empirical applications illustrate the practical usefulness of the methods proposed.},
  archive      = {J_JBES},
  author       = {Giuseppe Cavaliere and Morten Ørregaard Nielsen and A. M. Robert Taylor},
  doi          = {10.1080/07350015.2020.1773275},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {50-65},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Adaptive inference in heteroscedastic fractional time series models},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network competition and team chemistry in the NBA.
<em>JBES</em>, <em>40</em>(1), 35–49. (<a
href="https://doi.org/10.1080/07350015.2020.1773273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract– We consider a heterogeneous social interaction model where agents interact with peers within their own network but also interact with agents across other (non-peer) networks. To address potential endogeneity in the networks, we assume that each network has a central planner who makes strategic network decisions based on observable and unobservable characteristics of the peers in her charge. The model forms a simultaneous equation system that can be estimated by quasi-maximum likelihood. We apply a restricted version of our model to data on National Basketball Association games, where agents are players, networks are individual teams organized by coaches, and competition is head-to-head. That is, at any time a player only interacts with two networks: their team and the opposing team. We find significant positive within-team peer-effects and both negative and positive opposing-team competitor-effects in NBA games. The former are interpretable as “team chemistries” which enhance the individual performances of players on the same team. The latter are interpretable as “team rivalries,” which can either enhance or diminish the individual performance of opposing players.},
  archive      = {J_JBES},
  author       = {William C. Horrace and Hyunseok Jung and Shane Sanders},
  doi          = {10.1080/07350015.2020.1773273},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {35-49},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Network competition and team chemistry in the NBA},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autoregressive model with spatial dependence and missing
data. <em>JBES</em>, <em>40</em>(1), 28–34. (<a
href="https://doi.org/10.1080/07350015.2020.1766471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study herein an autoregressive model with spatially correlated error terms and missing data. A logistic regression model with completely observed covariates is used to model the missingness mechanism. An autoregressive model is used to accommodate time series dependence, and a spatial error model is used to capture spatial dependence. To estimate the model, a weighted least squares estimator is developed for the temporal component, and a weighted maximum likelihood estimator is developed for the spatial component. The asymptotic properties for both estimators are investigated. The finite sample performance is assessed through extensive simulation studies. A real data example about Beijing’s PM 2.5 level data is illustrated.},
  archive      = {J_JBES},
  author       = {Jing Zhou and Jin Liu and Feifei Wang and Hansheng Wang},
  doi          = {10.1080/07350015.2020.1766471},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {28-34},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Autoregressive model with spatial dependence and missing data},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian quantile time series model for asset returns.
<em>JBES</em>, <em>40</em>(1), 16–27. (<a
href="https://doi.org/10.1080/07350015.2020.1766470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider jointly modeling a finite collection of quantiles over time. Formal Bayesian inference on quantiles is challenging since we need access to both the quantile function and the likelihood. We propose a flexible Bayesian time-varying transformation model, which allows the likelihood and the quantile function to be directly calculated. We derive conditions for stationarity, discuss suitable priors, and describe a Markov chain Monte Carlo algorithm for inference. We illustrate the usefulness of the model for estimation and forecasting on stock, index, and commodity returns.},
  archive      = {J_JBES},
  author       = {Jim E. Griffin and Gelly Mitrodima},
  doi          = {10.1080/07350015.2020.1766470},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {16-27},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A bayesian quantile time series model for asset returns},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A linear estimator for factor-augmented fixed-t panels with
endogenous regressors. <em>JBES</em>, <em>40</em>(1), 1–15. (<a
href="https://doi.org/10.1080/07350015.2020.1766469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel method-of-moments approach is proposed for the estimation of factor-augmented panel data models with endogenous regressors when T is fixed. The underlying methodology involves approximating the unobserved common factors using observed factor proxies. The resulting moment conditions are linear in the parameters. The proposed approach addresses several issues which arise with existing nonlinear estimators that are available in fixed T panels, such as local minima-related problems, a sensitivity to particular normalization schemes, and a potential lack of global identification. We apply our approach to a large panel of households and estimate the price elasticity of urban water demand. A simulation study confirms that our approach performs well in finite samples.},
  archive      = {J_JBES},
  author       = {Artūras Juodis and Vasilis Sarafidis},
  doi          = {10.1080/07350015.2020.1766469},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A linear estimator for factor-augmented fixed-T panels with endogenous regressors},
  volume       = {40},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
