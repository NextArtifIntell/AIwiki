<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aai---171">AAI - 171</h2>
<ul>
<li><details>
<summary>
(2022). Multi-cue gate-shift networks for mouse behavior
recognition. <em>AAI</em>, <em>36</em>(1), Article: 2151680. (<a
href="https://doi.org/10.1080/08839514.2022.2151680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic identification of mouse behavior plays an important role in the study of disease or treatment, especially regarding the short-term action of mice. Existing three-dimensional (3D) convolutional neural networks (CNNs) and two-dimensional (2D) CNNs have different limitations when addressing the task of mouse behavior recognition. For instance, 3D CNNs require a large calculation cost, while 2D CNNs cannot capture motion information. To solve these problems, a low-computational and efficient multi-cue gate-shift network (MGSN) was developed. First, to capture motion information, a multi-cue feature switching module (MFSM) was designed to utilize RGB and motion information. Second, an adaptive feature fusion module (AFFM) was designed to adaptively fuse the features. Third, we used a 2D network to reduce the amount of computation. Finally, we performed an extensive evaluation of the proposed module to study its effectiveness in mouse behavior recognition, achieving state-of-the-art accuracy results using the Jiang database, and comparable results using the Jhuang database. An absolute improvement of +5.41% over the benchmark gate-shift module was achieved using the Jiang database.},
  archive      = {J_AAI},
  author       = {Longfeng Shen and Yulei Jian and Debao Chen and Fangzheng Ge and Xiangjun Gao and Huaiyu Liu and Qianqian Meng and Yingjie Zhang and Chengzhen Xu},
  doi          = {10.1080/08839514.2022.2151680},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151680},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-cue gate-shift networks for mouse behavior recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Iterative convolutional encoder-decoder network with
multi-scale context learning for liver segmentation. <em>AAI</em>,
<em>36</em>(1), Article: 2151186. (<a
href="https://doi.org/10.1080/08839514.2022.2151186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid and accurate extraction of liver tissue from abdominal computed tomography (CT) and magnetic resonance (MR) images has critical importance for diagnosis and treatment of hepatic diseases. Due to adjacent organs with similar intensities and anatomical variations between different subjects, the performance of segmentation approaches based on deep learning still has room for improvement. In this study, a novel convolutional encoder-decoder network incorporating multi-scale context information is proposed. The probabilistic map from previous classifier is iteratively fed into the encoder layers, which fuses high-level shape context with low-level appearance features in a multi-scale manner. The dense connectivity is adopted to aggregate feature maps of varying scales from the encoder and decoder. We evaluated the proposed method with 2D and 3D application on abdominal CT and MR images of three public datasets. The proposed method generated liver segmentation with significantly higher accuracy ( p &lt;0.05), in comparison to several competing methods. These promising results suggest that the novel model could offer high potential for clinical workflow.},
  archive      = {J_AAI},
  author       = {Feiyan Zhang and Shuhao Yan and Yizhong Zhao and Yuan Gao and Zhi Li and Xuesong Lu},
  doi          = {10.1080/08839514.2022.2151186},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151186},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Iterative convolutional encoder-decoder network with multi-scale context learning for liver segmentation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional neural networks improve radiologists’
performance in breast cancer screening for vietnamese patients.
<em>AAI</em>, <em>36</em>(1), Article: 2151185. (<a
href="https://doi.org/10.1080/08839514.2022.2151185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, breast cancer is one of the leading cancers in Vietnam, and it causes approximately 6000 deaths every year. The rate of breast cancer patients was calculated as 26.4/100000 persons in 2018. There are 21,555 new cases reported in 2020. However, these figures can be reduced with early detection and diagnosis of breast cancer disease in women through mammographic imaging. In many hospitals in Vietnam, there is a lack of experienced breast cancer radiologists. Therefore, it is helpful to develop an intelligent system to improve radiologists’ performance in breast cancer screening for Vietnamese patients. Our research aims to develop a convolutional neural network-based system for classifying breast cancer X-Ray images into three classes of BI-RADS categories as BI-RADS 1 (“normal”), BI-RADS 23 (“benign”) and BI-RADS 045 (“incomplete and malignance”). This classification system is developed based on the convolutional neural network with ResNet 50. The system is trained and tested on a breast cancer image dataset of Vietnamese patients containing 7912 images provided by Hanoi Medical University Hospital radiologists. The system accuracy uses the testing set achieved a macAUC (a macro average of the three AUCs) of 0.754. To validate our model, we performed a reader study with the breast cancer radiologists of the Hanoi Medical University Hospital, reading about 500 random images of the test set. We confirmed the efficacy of our model, which achieved performance comparable to a committee of two radiologists when presented with the same data. Additionally, the system takes only 6 seconds to interpret a breast cancer X-Ray image instead of 450 seconds interpreted by a Vietnamese radiologist. Therefore, our system can be considered as a “second radiologist,” which can improve radiologists’ performance in breast cancer screening for Vietnamese patients.},
  archive      = {J_AAI},
  author       = {Bui My Hanh and Le Tuan Linh and Nguyen Ngoc Cuong and Thanh Binh Nguyen and Luu Tien Doan and Chung Duy Le and Vu Tat Giao and Thi Ly Ly Ngo and Thi Hong Xuyen Hoang and Nguyen Duc Thang and Nguyen Tu Anh and Nguyen Duc Dan and Nguyen Viet Dung and Tran Vinh Duc and Quang H. Nguyen and Anh Nguyen and Nguyen Hoang Phuong},
  doi          = {10.1080/08839514.2022.2151185},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151185},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Convolutional neural networks improve radiologists’ performance in breast cancer screening for vietnamese patients},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emergent behavior in the battle management system.
<em>AAI</em>, <em>36</em>(1), Article: 2151183. (<a
href="https://doi.org/10.1080/08839514.2022.2151183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many countries including Ukraine use battle management systems (BMS) like Delta that enable command to share situation awareness information; this study focuses on the distribution of information across a warfighting network. Similar to natural systems, where autonomous agents, such as ants and bees, follow a set of simple rules, a BMS is a network of bases and electronic warfighting platforms that have military assets as agents within the network, guided by the defense doctrine. The rationale for the workability of such a system is based on each subsystem being reliable when multiple subsystems interact. However, the potential permutations and combinations of interactions can cause unpredictable negative or positive feedback loops, resulting in unpredictable and unwanted outcomes. The results of emergent behavior are unexpected and sometimes unwanted in areas such as intelligence, and wireless networks. Understanding emergent behavior is imperative in understanding complex engineering systems, and to present new insights, and take practical steps toward improving complex systems design and analysis. This paper presents the BMS and networks with examples of user-defined system integration of the network soldier concept. We believe that Ukrainian and other armies can directly benefit from utilising meta cybernetics, meta metasystem model analysis to control emergence.},
  archive      = {J_AAI},
  author       = {Aleksandar Seizovic and David Thorpe and Steven Goh},
  doi          = {10.1080/08839514.2022.2151183},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151183},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Emergent behavior in the battle management system},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An effective tumor detection in MR brain images based on
deep CNN approach: I-YOLOV5. <em>AAI</em>, <em>36</em>(1), Article:
2151180. (<a
href="https://doi.org/10.1080/08839514.2022.2151180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of computer technology, Artificial Intelligence (AI) aids radiologists to diagnosis the Brain Tumor (BT). Early detection of diseases can be increased in health care leads to further treatments, wherein the typical application of AI systems performs a vital role in terms of time and money savings. Magnetic Resonance (MR) images are enhanced with image enhancement techniques to improve contrast and color accuracy. Besides, traditional methods uncompensated for problems with the several types of MR imaging for BT. Deep learning techniques can be extended to help overcome the common problems encountered in conventional tumor detection methods. Therefore, in this work, an improvised YOLOV5 technique have been proposed for BT detection based on MR images. Eventually, the idea of Hyperparameter Optimization (HPO) is applied using Hybrid Grid Search Optimizer Algorithm (HGSOA) to enhance the performance of the tumor detection viz tuning of hyper parameters in proposed deep neural network. To evaluate the effectiveness of proposed model, McCulloch’s algorithm is used to localize images for tumor region segmentation, and the segmentation result is also checked with truth annotated images. Various experiments were conducted to measure the accuracy of proposed fine-tuned model using MW brain test images. Finally, classification metrics including, MSE, PSNR, SSIM, FSIM, and CPU time are compared with existing state-of-the-art techniques to prove the effectiveness of the proposed model. In the taxonomy of MRI-BT, greater precision was achieved by CNN.},
  archive      = {J_AAI},
  author       = {Sivapathi Arunachalam and Gopalakrishnan Sethumathavan},
  doi          = {10.1080/08839514.2022.2151180},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151180},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An effective tumor detection in MR brain images based on deep CNN approach: I-YOLOV5},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Genetic folding (GF) algorithm with minimal kernel operators
to predict stroke patients. <em>AAI</em>, <em>36</em>(1), Article:
2151179. (<a
href="https://doi.org/10.1080/08839514.2022.2151179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A stroke is a medical disorder in which blood arteries in the brain rupture, causing brain damage. Symptoms may appear when the brain’s blood supply and other nutrients are cut off. According to the World Health Organization, Stroke is the leading cause of death and disability globally. Early recognition of the multiple warning signs of a stroke helps reduce the severity of the stroke. The paper presents a modified version of the Genetic Folding algorithm to predict stroke based on symptoms. Considerable Machine Learning models, including Logistic Regression, Decision Tree, Random Forest, Naïve Bayes, Support Vector Machine, and the proposed Minimal Genetic Folding, were compared to forecast the probability of having a stroke in the brain using a variety of physiological characteristics. The proposed minimal Genetic Folding approach has been developed using the open-access Stroke Prediction dataset using minimal kernel operators. The datasets generated and/or analyzed during the current study are available in the Kaggle repository. With an accuracy of 83.2%, the proposed minimal Genetic Folding approach outperformed Logistic Regression by 4.2%, Naïve Bayes by 1.2%, Decision Tree by 17.2%, and Support Vector Machine by 83.2%. The area under the curve of the proposed model is much more significant than earlier research by 7%, demonstrating that this model is more dependable and was the top-performing algorithm.},
  archive      = {J_AAI},
  author       = {Mohammad A. Mezher},
  doi          = {10.1080/08839514.2022.2151179},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151179},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Genetic folding (GF) algorithm with minimal kernel operators to predict stroke patients},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of proposed and traditional boosting algorithm with
standalone classification methods for classifying gene expresssion
microarray data using a reject option. <em>AAI</em>, <em>36</em>(1),
Article: 2151171. (<a
href="https://doi.org/10.1080/08839514.2022.2151171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical field, accurate decisions are very important as they risk human lives. decision support system (DSS) plays important role in making accurate decisions and used for classification/prediction. In gene expression analysis, genes are not only inflated by the external environmental conditions but also the expression values of certain genes are affected (like cancer, obesity etc). in this study, various traditional (Support Vector Machine, Decision Trees, and Linear Discriminant Analysis, naïve Bayes, logistic regression, and multilayer perceptron) and proposed methods (combination of traditional with ensemble and probabilistic classifiers) are used in order to perform the classification and prediction analysis. In this study we used the publicly available datasets comprised of Lymphoid, Leukemia and Colon Cancer. The classification performance on Colon dataset with traditional methods was obtained with accuracy (56%) and proposed probabilistic ensemble methods with accuracy (88%). For dataset, Leukemia, the accuracy was obtained using traditional methods (78%) and proposed methods (92%). Similarly, on Lymphoid dataset, the traditional methods yielded accuracy (75%) and proposed methods (87%). The results revealed that proposed methods yielded the improved detection performance. The proposed methods can be used as a better predictor for early diagnosis and improved diagnosis to improve the healthcare systems.},
  archive      = {J_AAI},
  author       = {Adil Aslam Mir and Lal Hussain and Muhammad Hammad Waseem and Amjad Aldweesh and Saim Rasheed and El Sayed Yousef and Malik Sajjad Ahmed Nadeem and Elsayed Tag Eldin},
  doi          = {10.1080/08839514.2022.2151171},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151171},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Analysis of proposed and traditional boosting algorithm with standalone classification methods for classifying gene expresssion microarray data using a reject option},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning based method for deciding internal value of
talent. <em>AAI</em>, <em>36</em>(1), Article: 2151160. (<a
href="https://doi.org/10.1080/08839514.2022.2151160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a machine-learning-based method for evaluating the internal value of talent in any organization and for evaluating the salary criteria. The study assumes the design and development of a salary predictor, based on artificial intelligence technologies, to help determine the internal value of employees and guarantee internal equity in the organization. The aim of the study is to achieve internal equity, which is a critical element a that directly affects employees’ motivation. We implemented and validated the method with 130 employees and more than 70 talent acquisition cases with a Basque technology research organization during the years 2021 and 2022. The proposed method is based on statistical data assessment and machine-learning-based regression. We found that while most organizations have established variables for job evaluation as well as salary increments for staff according to their contribution to the organization, only a few employ tools to support equitable internal compensation. This study presents a successful real case of artificial intelligence applications where machine learning techniques help managers make the most equitable and least biased salary decisions possible, based on data.},
  archive      = {J_AAI},
  author       = {Edurne Loyarte-López and Igor García-Olaizola},
  doi          = {10.1080/08839514.2022.2151160},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151160},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Machine learning based method for deciding internal value of talent},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of stock return by LSTM neural network.
<em>AAI</em>, <em>36</em>(1), Article: 2151159. (<a
href="https://doi.org/10.1080/08839514.2022.2151159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The role of the stock market in the whole financial market is indispensable. How to obtain the actual trading income and maximize the interests in the trading process has been a problem studied by scholars and financial practitioners for a long time. Deep learning network can extract features from a large number of original data, which has potential advantages for stock market prediction. Based on the Shanghai and Shenzhen stock markets from 2019 to 2021, we use LSTM models, optimized on in-sample period and tested on out-of-sample period, using rolling window approach. We select the right hyperparameters at the beginning of our tests, use RBM preprocessing data, then use LSTM model to obtain expected stock return, to effectively predict future stock market analysis and predictive behavior. Finally, we perform a sensitivity analysis of the main parameters and hyperparameters of the model.},
  archive      = {J_AAI},
  author       = {Risheng Qiao and Weike Chen and Yongsheng Qiao},
  doi          = {10.1080/08839514.2022.2151159},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2151159},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prediction of stock return by LSTM neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning approach for objects detection in underwater
pipeline images. <em>AAI</em>, <em>36</em>(1), Article: 2146853. (<a
href="https://doi.org/10.1080/08839514.2022.2146853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present automatic, deep-learning methods for pipeline detection in underwater environments. Seafloor pipelines are critical infrastructure for oil and gas transport. The inspection of those pipelines is required to verify their integrity and determine the need for maintenance. Underwater conditions present a harsh environment that is challenging for image recognition due to light refraction and absorption, poor visibility, scattering, and attenuation, often causing poor image quality. Modern machine-learning object detectors utilize Convolutional Neural Network (CNN), requiring a training dataset of sufficient quality. In the paper, six different deep-learning CNN detectors for underwater object detection were trained and tested: five are based on the You Only Look Once (YOLO) architectures (YOLOv4, YOLOv4-Tiny, CSP-YOLOv4, YOLOv4@Resnet, YOLOv4@DenseNet), and one on the Faster Region-based CNN (RCNN) architecture. The models’ performances were evaluated in terms of detection accuracy, mean average precision (mAP), and processing speed measured with the Frames Per Second (FPS) on a custom dataset containing underwater pipeline images. In the study, the YOLOv4 outperformed other models for underwater pipeline object detection resulting in an mAP of 94.21% with the ability to detect objects in real-time. Based on the literature review, this is one of the pioneering works in this field.},
  archive      = {J_AAI},
  author       = {Boris Gašparović and Jonatan Lerga and Goran Mauša and Marina Ivašić-Kos},
  doi          = {10.1080/08839514.2022.2146853},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2146853},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep learning approach for objects detection in underwater pipeline images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An online self-adaptive RBF network algorithm based on the
levenberg-marquardt algorithm. <em>AAI</em>, <em>36</em>(1), Article:
2146800. (<a
href="https://doi.org/10.1080/08839514.2022.2146800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem that the Levenberg-Marquardt (LM) algorithm can not train online radial basis function (RBF) neural network and the deficiency in the RBF network structure design methods, this paper proposes an online self-adaptive algorithm for constructing RBF neural network (OSA-RBFNN) based on LM algorithm. Thus, the ideas of the sliding window method and online structure optimization methods are adopted to solve the proposed problems. On the one hand, the sliding window method enables the RBF network to be trained online by the LM algorithm making the RBF network more robust to the changes in the learning parameters and faster convergence compared with the other investigated algorithms. On the other hand, online structure optimization can adjust the structure of the RBF network based on the information of training errors and hidden nodes to track the non-linear time-varying systems, which helps to maintain a compact network and satisfactory generalization ability. Finally, verified by simulation analysis, it is demonstrated that OSA-RBFNN exhibits a compact RBF network.},
  archive      = {J_AAI},
  author       = {ZhaoZhao Zhang and Yue Liu and YingQin Zhu and XiaoFei Zhao},
  doi          = {10.1080/08839514.2022.2146800},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2146800},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An online self-adaptive RBF network algorithm based on the levenberg-marquardt algorithm},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-model prediction method for coal mine gas
concentration with hierarchical structure. <em>AAI</em>, <em>36</em>(1),
Article: 2146296. (<a
href="https://doi.org/10.1080/08839514.2022.2146296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low concentration of gas in the gas blending process is influenced by a number of factors and is characterized by some time variation and non-linearity. Therefore, the gas concentration needs to be predicted. This paper proposes a multi-model forecasting method with a hierarchical structure. First, because the measured gas concentration time-series data contain a lot of noise, the time-series data are decomposed into several independent eigenmode functions by using empirical mode decomposition, adaptively denoising by low-pass filtering, and then using phase space reconstruction technology to obtain a new time-series sample. Then, the training samples are grouped by conditional fuzzy clustering to determine the number of sub-modules. Finally, the maximum membership method is used to select sub-models and sub-sub-models, and then a multi-model time-series prediction model is established. The model can not only select different sub-models to process data in different regions but also can process each data jointly by multiple sub-models in different sub-models. Experiments were carried out on low-concentration measured data extracted from mines. The experimental results show that the proposed prediction model can capture the nonlinear characteristics of gas concentration time series and is superior to other existing prediction models in accuracy.},
  archive      = {J_AAI},
  author       = {ZhaoZhao Zhang and Qiang Dai and YingQin Zhu},
  doi          = {10.1080/08839514.2022.2146296},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2146296},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A multi-model prediction method for coal mine gas concentration with hierarchical structure},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta learning-based dynamic ensemble model for crop
selection. <em>AAI</em>, <em>36</em>(1), Article: 2145646. (<a
href="https://doi.org/10.1080/08839514.2022.2145646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agricultural sector is working for optimal crop yield toward securing a sustainable food supply for the world. Fast growth in precision agriculture helps farmers to increase their yields by extending the era of machine-learning techniques. However, in organic and inorganic farming, predicting yield is an open issue that dominantly depends on the presence of soil nutrients. The lack of knowledge about the richness of land nutrients deals with the crop selection problem. Therefore, the proposed work extended the idea of a dynamic ensemble model for imbalanced multi-class nutrient data. In this work, an attempt is being made to include a novel customized voting strategy for deciding the final class output from the ensemble model. As an initial step, a well-known ranking technique, VIKOR, is applied over land nutrients to extract the most informative land samples. The rationale is to reduce the complexity of the ensemble model by determining only informative land samples for further classification. Furthermore, the meta-learning approach of dynamic ensemble selection accounts for multi-criterion-based competent classifier selection as meta-classifiers. These meta-classifiers decide on ensemble formation with the customized voting strategy to classify the right crop for the test land. To investigate nutrient richness, real-time soil and water nutrient data are collected from the soil testing laboratory, which covers different spatial data. Our experiments on six popular DES algorithms over nutrient data reveal the proposed algorithm’s outperformance in specificity, sensitivity, BCA, Multi-Area under Curve, and precision. Moreover, the lesser computational time of the proposed work indicates the model’s efficiency toward suitable crop selection.},
  archive      = {J_AAI},
  author       = {Bhuvaneswari Swaminathan and Saravanan Palani and Subramaniyaswamy Vairavasundaram},
  doi          = {10.1080/08839514.2022.2145646},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145646},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Meta learning-based dynamic ensemble model for crop selection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence-based prediction of diabetes and
prediabetes using health checkup data in korea. <em>AAI</em>,
<em>36</em>(1), Article: 2145644. (<a
href="https://doi.org/10.1080/08839514.2022.2145644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The economic burden of Type 2 Diabetes (T2D) on society has increased over time. Early prediction of diabetes and prediabetes can reduce treatment cost and improve intervention. The development of (pre)diabetes is associated with various health conditions that can be monitored by routine health checkups. This study aimed to develop amachine learning-based model for predicting (pre)diabetes. Our frameworks were based on 22,722 patient samples collected from 2013 to 2020 in ageneral hospital in Korea. The disease progression was divided into three categories based on fasting blood glucose: normal, prediabetes, and T2D. The risk factors at each stage were identified and compared. Based on the area under the curve, the support vector machine appeared to have optimal performance. At the normal and prediabetes stages, fasting blood glucose and HbA1c are prevalent risk features for the suggested models. Interestingly, HbA1c had the highest odds ratio among the features even in the normal stage (FBG is less than 100). In addition, factors related to liver function, such as gamma-glutamyl transpeptidase can be used to predict progression from normal to prediabetes, while factors related to renal function, such as blood urea nitrogen and creatinine, are prediction factors of T2D development.},
  archive      = {J_AAI},
  author       = {Hyeonseop Yuk and Juhui Gim and Jung Kee Min and Jaesuk Yun and Tae-Young Heo},
  doi          = {10.1080/08839514.2022.2145644},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145644},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence-based prediction of diabetes and prediabetes using health checkup data in korea},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). BERT-log: Anomaly detection for system logs based on
pre-trained language model. <em>AAI</em>, <em>36</em>(1), Article:
2145642. (<a
href="https://doi.org/10.1080/08839514.2022.2145642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logs are primary information resource for fault diagnosis and anomaly detection in large-scale computer systems, but it is hard to classify anomalies from system logs. Recent studies focus on extracting semantic information from unstructured log messages and converting it into word vectors. Therefore, LSTM approach is more suitable for time series data. Word2Vec is the up-to-date encoding method, but the order of words in sequences is not taken into account. In this article, we propose BERT-Log, which regards the log sequence as a natural language sequence, use pre-trained language model to learn the semantic representation of normal and anomalous logs, and a fully connected neural network is utilized to fine-tune the BERT model to detect abnormal. It can capture all the semantic information from log sequence including context and position. It has achieved the highest performance among all the methods on HDFS dataset, with an F1-score of 99.3%. We propose a new log feature extractor on BGL dataset to obtain log sequence by sliding window including node ID, window size and step size. BERT-Log approach detects anomalies on BGL dataset with an F1-score of 99.4%. It gives 19% performance improvement compared to LogRobust and 7% performance improvement compared to HitAnomaly.},
  archive      = {J_AAI},
  author       = {Song Chen and Hai Liao},
  doi          = {10.1080/08839514.2022.2145642},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145642},
  shortjournal = {Appl. Artif. Intell.},
  title        = {BERT-log: Anomaly detection for system logs based on pre-trained language model},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bi-directional CNN-RNN architecture with group-wise
enhancement and attention mechanisms for cryptocurrency sentiment
analysis. <em>AAI</em>, <em>36</em>(1), Article: 2145641. (<a
href="https://doi.org/10.1080/08839514.2022.2145641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the cryptocurrency trading market has grown significantly in recent years, the number of comments related to cryptocurrency has increased tremendously in social media platforms. Due to this, sentiment analysis of the cryptocurrency-related comments has become highly desirable to give a comprehensive picture of peoples’ opinions about the trend of the market. In this regard, we perform cryptocurrency-related text sentiment classification using tweets based on positive and negative sentiments. For increasing the efficacy of the sentiment analysis, we introduce a novel deep neural network hybrid architecture which is composed of an embedding layer, a convolution layer, a group-wise enhancement mechanism, a bidirectional layer, an attention mechanism, and a fully connected layer. Local features are derived using a convolution layer, and weight values associated with intuitive features are developed using the group-wise enhancement mechanism. After feeding the improved context vector to the bidirectional layer to grab global features, the attention mechanism and the fully connected layer have been employed. The experimental findings indicate that the proposed architecture outperforms the state-of-the-art architectures with an accuracy value of 93.77%.},
  archive      = {J_AAI},
  author       = {Gül Cihan Habek and Mansur Alp Toçoğlu and Aytuğ Onan},
  doi          = {10.1080/08839514.2022.2145641},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145641},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bi-directional CNN-RNN architecture with group-wise enhancement and attention mechanisms for cryptocurrency sentiment analysis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pre synthesis and post synthesis power estimation of VLSI
circuits using machine learning approach. <em>AAI</em>, <em>36</em>(1),
Article: 2145640. (<a
href="https://doi.org/10.1080/08839514.2022.2145640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, people need sleeker devices with better functionality and longer battery life. This can be achieved by integrating more components onto smaller chips, resulting in a shift to low-geometry chip design. However, power dissipation due to dynamic and static currents is more prominent in all ICs, resulting in an increase in overall power consumption. Estimating power dissipation early will provide more accurate usage of power pads/strips and help floor plan engineers do power planning efficiently. As you provide more details about your design characteristics, the estimation of power will be accurate. The major focus of this work is to give an alternative solution to predict the power dissipation of integrated circuits using a machine learning approach in both pre and post layout. The proposed work uses supervision models and algorithms like Linear regression, KNN, SVM, and RF for power prediction and a comparative study is made between power estimates made using ML algorithms and by the Cadence EDA tool for a particular technology for various bench circuits. The average error is less than 4% when we compare the estimated power using ML and by using the Cadence EDA tool and shows that for estimation of power in integrated circuits, Random Forest is a well-suited algorithm with an error percentage varying from 2 to 4.},
  archive      = {J_AAI},
  author       = {E Poovannan and S Karthik},
  doi          = {10.1080/08839514.2022.2145640},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145640},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Pre synthesis and post synthesis power estimation of VLSI circuits using machine learning approach},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HR-specific NLP for the homogeneous classification of
declared and inferred skills. <em>AAI</em>, <em>36</em>(1), Article:
2145639. (<a
href="https://doi.org/10.1080/08839514.2022.2145639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of natural language processing in human resource management has become of paramount importance in order to provide support for recruiting and corporate population management. This paper proposes a heuristic algorithm to solve two problems: (i) semantic matching among heterogeneous datasets storing the hard skills possessed by the company’s employees to obtain a homogeneous catalog, according to the O*NET and ESCO competence dictionaries, and (ii) inferring the employee’s soft skills with respect to his/her own declaration of interests, work experience, certifications, etc., given his/her curriculum vitae. Empirical results demonstrate that the proposed approach yields improved performance results by comparison with baseline methods available in the literature.},
  archive      = {J_AAI},
  author       = {Lorenzo Ricciardi Celsi and Jesus Fernando Cevallos Moreno and Federico Kieffer and Valerio Paduano},
  doi          = {10.1080/08839514.2022.2145639},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145639},
  shortjournal = {Appl. Artif. Intell.},
  title        = {HR-specific NLP for the homogeneous classification of declared and inferred skills},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Face mask recognition system using MobileNetV2 with
optimization function. <em>AAI</em>, <em>36</em>(1), Article: 2145638.
(<a href="https://doi.org/10.1080/08839514.2022.2145638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world has experienced a health crisis with the outbreak of the COVID-19 virus. The mask has been identified as the most effective way to prevent the spread of the virus. This has led to the need for a face mask recognition device that not only detects the presence of the mask but also provides the accuracy with which a person is wearing the face mask. In addition, the face mask should also be recognized from all angles. The project aims to create a new and improved real-time face mask recognition tool using image processing and computer vision approaches. A dataset consisting of images with and without a mask was used. For the purposes of this project, a pre-trained MobileNetV2 convolutional neural network was used. The performance of the given model was evaluated. The model presented in this project can detect the face mask with an accuracy of 99.21%. The face mask recognition tool can effectively detect the face mask in the side direction, which makes it more useful. The optimization function which contains the learning loops and the optimization function are also used.},
  archive      = {J_AAI},
  author       = {Atheer Hadi Issa Al-Rammahi},
  doi          = {10.1080/08839514.2022.2145638},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145638},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Face mask recognition system using MobileNetV2 with optimization function},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent grouping method of science and technology
projects based on data augmentation and SMOTE. <em>AAI</em>,
<em>36</em>(1), Article: 2145637. (<a
href="https://doi.org/10.1080/08839514.2022.2145637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current evaluation of science and technology projects is mainly completed by peer review, and in the process of evaluation, dividing projects into different groups is a crucial step. Project grouping is challenging due to the small amounts of data, sparsity of features, broad range of subject areas, and the seriously uneven distribution of categories. In this paper, we propose an intelligent automatic grouping method for science and technology projects based on keywords. We expanded the small dataset with samples generated by Paraphrasing, Mixup, and the GPT3 model. The text feature extraction techniques TF-IDF, Word2Vec, and TF-IDF weighted Word2Vec were utilized to pre-process the keywords of projects, and SVM and XGBoost as the classifier. Besides, we used SMOTE to process imbalanced data to alleviate model bias toward minority classes. Experiments show that the project grouping accuracy was substantially improved after introducing the data augmentation method and SMOTE. The combination of Paraphrasing, TF-IDF, SVM and SMOTE achieved the best performance, and the F1 score reached 96.78%, which proves the feasibility of the proposed method.},
  archive      = {J_AAI},
  author       = {Can Zhou and Mengting Li and Sha Yu},
  doi          = {10.1080/08839514.2022.2145637},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145637},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intelligent grouping method of science and technology projects based on data augmentation and SMOTE},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI-TASFIS: An approach to secure vehicle-to-vehicle
communication. <em>AAI</em>, <em>36</em>(1), Article: 2145636. (<a
href="https://doi.org/10.1080/08839514.2022.2145636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {VANET provides communication between vehicles. VANET nodes are highly dynamic. Therefore, it is essential to increase the stability of the communication between nodes. The cluster head and cluster node provide stable communication between vehicles. Vehicle communications are being challenged by factors such as security, confidential communication, and severe delay. This work proposes an Artificial Intelligence (AI)-based Sugeno fuzzy inference system to overcome these issues. The proposed secure trust-based cluster techniques are less complex, with lesser communication delays, lower overhead, and more efficient in accurately locating trusted nodes for communication. Vehicular Ad hoc Networks (VANET) should send data between vehicles and use traffic safety indicators using an Enhanced Cluster-based routing protocol. AI-TASFIS is Artificial Intelligence-based Trust Authentication Sugeno fuzzy inference system that uses ANFIS-based Sugeno Fuzzy inference systems to calculate the node weights for choosing trusted cluster head and cluster member that reduces malicious attacks like Black Hole Attacks, Wormhole attacks, and Timing Attacks while transferring data packets. Simulation results show that the proposed Artificial Intelligence (AI)-based Sugeno fuzzy inference system provides network security, reduces end-to-end delay, and increases packet delivery ratio and throughput.},
  archive      = {J_AAI},
  author       = {M Gayathri and C. Gomathy},
  doi          = {10.1080/08839514.2022.2145636},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145636},
  shortjournal = {Appl. Artif. Intell.},
  title        = {AI-TASFIS: An approach to secure vehicle-to-vehicle communication},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent SDN architecture with fuzzy neural network and
blockchain for monitoring critical events. <em>AAI</em>, <em>36</em>(1),
Article: 2145634. (<a
href="https://doi.org/10.1080/08839514.2022.2145634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article deals with the creation of an intelligent architecture of the Internet of Things transport environment based on software-defined network (SDN) and blockchain for detecting threats and attacks. The transport environment is created for the monitoring system of critical events in the road transport infrastructure. Blockchain technology is used to authenticate network nodes, store sensor data in a distributed ledger. The network packet clustering method based on a fuzzy neural network is used to detect packets with possible malicious content. The intelligent SDN architecture is a hierarchy of four layers with six levels and includes: a) edge computing layer (sensor nodes and routers level, SDN switches data level), b) fog computing layer (zone server level, control level in SDN controllers), c) a cloud computing layer with data center servers, d) a layer for presenting monitoring results on user devices and applications. Detection of threats and attacks is implemented by validating network nodes and analyzing header fields of IP packets and TCP segments. The intrusion detection system includes a parser and analyzer of data packets, a module for filtering traffic by type, port numbers and other characteristics of packets, a module for synthesizing digital signatures of trusted nodes and their validation, a module for analyzing and clustering packets based on fuzzy logic and a neural network, modules for logging procedures. The probability function of packets belonging to clusters is tuned through deep learning of a five-layer neural network. The conclusion about belonging and degree of similarity with malicious packages is formed using the fuzzy logic apparatus. To train the neural network, the previously synthesized rules of the flow tables and the identified signs of atypical data packets are used. The functionality and effectiveness of the SDN architecture with an intrusion detection system is validated by simulating procedures in the NS3 Simulator system, evaluating authenticity, latency, throughput, response time, and accuracy in detecting atypical data packets.},
  archive      = {J_AAI},
  author       = {Alexey Finogeev and Michael Deev and Danila Parygin and Аnton Finogeev},
  doi          = {10.1080/08839514.2022.2145634},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145634},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intelligent SDN architecture with fuzzy neural network and blockchain for monitoring critical events},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Comparative study of AutoML approach, conventional ensemble
learning method, and KNearest oracle-AutoML model for predicting student
dropouts in sub-saharan african countries. <em>AAI</em>, <em>36</em>(1),
Article: 2145632. (<a
href="https://doi.org/10.1080/08839514.2022.2145632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Student dropout in secondary schools is a major issue in developing countries, particularly in Sub-Saharan Africa. Sub-Saharan African countries had the highest dropout rate (37.5%), followed by South Asia (15.5%), the Middle East (11%), East Asia (9.5%), Latin America (7%), and Central Asia (3.5%). Various initiatives such as the big results now initiatives, no child left behind, and secondary education development programme as well as machine learning prediction models have been used to reduce the severity of the problem in Sub-Saharan countries. The ongoing dropout problem, particularly in secondary schools is ascribed to improper root cause identification and the absence of formal procedures that can be used to estimate the severity of the issue. This study has compared the AutoML model, ensemble learning approach, and KNORA-AutoML to predict student dropout problems. The KNORA-AutoML model scored 97% of accuracy, precision = 71%, and AUC = 87% when compared to the conventional ensemble of optimized ML models with accuracy = 96%, precision = 70%, and AUC = 78%. KNORA-AutoML model performance increased by 0.6% accuracy, 0.8% precision, and 8.7% AUC. An optimized model draws a lot of attention to the findings related to student dropout rates in developing countries.},
  archive      = {J_AAI},
  author       = {Yuda N Mnyawami and Hellen H Maziku and Joseph C Mushi},
  doi          = {10.1080/08839514.2022.2145632},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145632},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Comparative study of AutoML approach, conventional ensemble learning method, and KNearest oracle-AutoML model for predicting student dropouts in sub-saharan african countries},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence and human resources management: A
bibliometric analysis. <em>AAI</em>, <em>36</em>(1), Article: 2145631.
(<a href="https://doi.org/10.1080/08839514.2022.2145631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is increasingly present in organizations. In the specific case of Human Resource Management (HRM), AI has become increasingly relevant in recent years. This article aims to perform a bibliometric analysis of the scientific literature that addresses in a connected way the application and impact of AI in the field of HRM. The scientific databases consulted were Web of Science and Scopus, yielding an initial number of 156 articles, of which 73 were selected for subsequent analysis. The information was processed using the Bibliometrix tool, which provided information on annual production, analysis of journals, authors, documents, keywords, etc. The results obtained show that AI applied to HRM is a developing field of study with constant growth and a positive future vision, although it should also be noted that it has a very specific character as a result of the fact that most of the research is focused on the application of AI in recruitment and selection actions, leaving aside other sub-areas with a great potential for application.},
  archive      = {J_AAI},
  author       = {P.R. Palos-Sánchez and P. Baena-Luna and A. Badicu and J.C. Infante-Moro},
  doi          = {10.1080/08839514.2022.2145631},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2145631},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence and human resources management: A bibliometric analysis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning based groundwater prediction in a
data-scarce basin of ghana. <em>AAI</em>, <em>36</em>(1), Article:
2138130. (<a
href="https://doi.org/10.1080/08839514.2022.2138130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Groundwater (GW) is a key source of drinking water and irrigation to combat growing food insecurity and for improved water access in rural sub-Saharan Africa. However, there are limited studies due to data scarcity in the region. New modeling techniques such as Machine learning (ML) are found robust and promising tools to assess GW recharge with less expensive data. The study utilized ML technique in GW recharge prediction for selected locations to assess sustainability of GW resources in Ghana. Two artificial neural networks (ANN) models namely Feedforward Neural Network with Multilayer Perceptron (FNN-MLP) and Extreme Learning Machine (FNN-ELM) were used for the prediction of GW using 58 years (1960–2018) of GW data. Model evaluation between FNN-MLP and FNN-ELM showed that the former approach was better in predicting GW with R 2 ranging from 0.97 to 0.99 while the latter has an R 2 between 0.42 to 0.68. The overall performance of both models was acceptable and suggests that ANN is a useful forecasting tool for GW assessment. The outcomes from this study will add value to the current methods of GW assessment and development, which is one of the pillars of the sustainable development goals (SDG 6).},
  archive      = {J_AAI},
  author       = {Ebenezer K. Siabi and Yihun Taddele Dile and Amos T. Kabo-Bah and Mark Amo-Boateng and Geophery K. Anornu and Komlavi Akpoti and Christopher Vuu and Peter Donkor and Samuel K. Mensah and Awo B. M. Incoom and Emmanuel K. Opoku and Thomas Atta-Darkwa},
  doi          = {10.1080/08839514.2022.2138130},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2138130},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Machine learning based groundwater prediction in a data-scarce basin of ghana},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the performance analysis of solving the rubik’s cube
using swarm intelligence algorithms. <em>AAI</em>, <em>36</em>(1),
Article: 2138129. (<a
href="https://doi.org/10.1080/08839514.2022.2138129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence algorithms are nature-inspired algorithms that mimic natural phenomena to solve optimization problems. These natural phenomena are intelligent animal behavior used by animals for survival from hunting prey, migration, escaping predators, and reproduction. Some examples are ant colonies, flocking of birds, tracking patterns of hawks, herding behaviour of animals, bacterial growth, fish schooling, and intelligent microbial organisms. The Rubik’s cube is a 3D combinatorial puzzle with six faces covered by nine stickers of colors: white, red, blue, orange, green, and yellow. The objective is to turn the scrambled cube, where each side will have more than one colour, into a solved cube having only one colour on each side. This study uses the following algorithms – particle swarm optimization, ant colony optimization, discrete krill herd optimization, and a greedy tree search algorithm – to investigate which of the four can solve the Rubik’s cube in the shortest time using the shortest possible move sequence and show that swarm intelligence algorithms are capable of solving the Rubik’s cube.},
  archive      = {J_AAI},
  author       = {Jishnu Jeevan and Madhu S. Nair},
  doi          = {10.1080/08839514.2022.2138129},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2138129},
  shortjournal = {Appl. Artif. Intell.},
  title        = {On the performance analysis of solving the rubik’s cube using swarm intelligence algorithms},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intracerebral hemorrhage detection in computed tomography
scans through cost-sensitive machine learning. <em>AAI</em>,
<em>36</em>(1), Article: 2138126. (<a
href="https://doi.org/10.1080/08839514.2022.2138126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intracerebral hemorrhage is the most severe form of stroke, with a greater than 75% likelihood of death or severe disability, and half of its mortality occurs in the first 24 hours. The grave nature of intracerebral hemorrhage and the high cost of false negatives in its diagnosis are representative of many medical tasks. Cost-sensitive machine learning has shown promise in various studies as a method of minimizing unwanted results. In this study, 6 machine learning models were trained on 160 computed tomography brain scans both with and without utility matrices based on penalization, an implementation of cost-sensitive learning. The highest-performing model was the support vector machine, which obtained an accuracy of 97.5%, sensitivity of 95% and specificity of 100% without penalization, and an accuracy of 92.5%, sensitivity of 100% and specificity of 85% with penalization, on a test dataset of 40 scans. In both cases, the model outperforms a range of previous work using other techniques despite the small size of and high heterogeneity in the dataset. Utility matrices demonstrate strong potential for sensitive yet accurate artificial intelligence techniques in medical contexts and workflows where a reduction of false negatives is crucial.},
  archive      = {J_AAI},
  author       = {Rushank Goyal},
  doi          = {10.1080/08839514.2022.2138126},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2138126},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intracerebral hemorrhage detection in computed tomography scans through cost-sensitive machine learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Systematic review of financial distress identification using
artificial intelligence methods. <em>AAI</em>, <em>36</em>(1), Article:
2138124. (<a
href="https://doi.org/10.1080/08839514.2022.2138124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study presents a systematic review of 232 studies on various aspects of the use of artificial intelligence methods for identification of financial distress (such as bankruptcy or insolvency). We follow the guidelines of the PRISMA methodology for performing the systematic reviews. The study discusses bankruptcy-related financial datasets, data imbalance, feature dimensionality reduction in financial datasets, financial distress prediction, data pre-processing issues, non-financial indicators, frequently used machine-learning methods, performance evolution metrics, and other related issues of machine-learning-based workflows. The study findings revealed the necessity of data balancing, dimensionality reduction techniques in data preprocessing, and allow researchers to identify new research directions that have not been analyzed yet.},
  archive      = {J_AAI},
  author       = {Dovilė Kuizinienė and Tomas Krilavičius and Robertas Damaševičius and Rytis Maskeliūnas},
  doi          = {10.1080/08839514.2022.2138124},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2138124},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Systematic review of financial distress identification using artificial intelligence methods},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emulating heterogeneity of individuals and visualizing its
influence on ant swarm migration. <em>AAI</em>, <em>36</em>(1), Article:
2138120. (<a
href="https://doi.org/10.1080/08839514.2022.2138120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot swarm can be given with different functions such as ground cruising, wall climbing, and each robot is implemented with a choice from such functions. Regarding ground mobility, findings on ant swarm in biology indicate that Temnothorax albipennis ant swarm including many immobile individuals accomplishes efficient migration. Our previous work revealed that 60% of active population is enough to achieve such goal and the conclusion is consistent with field studies of biologists. However, the impacts of active population ratio (active ratio) rather than species-specific elements have not been clear enough yet. Here, hypothesizing that efficient swarm migration could be generated by lowering active ratio, we removed species-specific elements from simulation and challenged particle swarm optimization (PSO) to emulate the migration and visualize global status of the swarm with simple parameter configurations. Our statistical analysis shows that the performance simulation outcomes of the algorithm are equivalent between each active-ratios of 60% and 100%. Heterogeneity of ground mobility of individuals has not put any negative impacts on efficient swarm migration. Statistical visualization of the outcomes provides the basis for evaluation of global status of swarm migration and it can lead to exploration of robot swarm migration involving functional heterogeneity of ground mobility.},
  archive      = {J_AAI},
  author       = {Hideyasu Sasaki},
  doi          = {10.1080/08839514.2022.2138120},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2138120},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Emulating heterogeneity of individuals and visualizing its influence on ant swarm migration},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vehicle interior sound classification based on local quintet
magnitude pattern and iterative neighborhood component analysis.
<em>AAI</em>, <em>36</em>(1), Article: 2137653. (<a
href="https://doi.org/10.1080/08839514.2022.2137653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, environmental sound classification (ESC) has become one of the most studied research areas. Sound signals that are indistinguishable from the human auditory systems have been classified by computer-aided systems and machine learning methods. Therefore, ESC has been used in signal processing and sound forensics applications. A novel ESC type is presented in this paper, and it is named as vehicle interior sound classification (VISC). VISC is defined as one of the sub-branches of the ESC, and it is utilized as sound-based biometrics for vehicles. A hand-crafted feature-based VISC method is presented. The proposed method has multileveled feature generation by using maximum pooling and the proposed local quintet magnitude pattern (LQMP), feature selection with iterative neighborhood component analysis (INCA), and classification phases. A novel VISC dataset was collected from YouTube and the proposed LQMP and INCA based method applied to the collected sounds. The results denoted that following: the accuracy, F1-score, and geometric mean of the proposed LQMP and INCA based VISC method were calculated as 98.38%,98.23%, and 98.21% by using support vector machine classifier respectively. The contribution of the proposed VISC method is to denote that the vehicles can be classified by using sound.},
  archive      = {J_AAI},
  author       = {Erhan Akbal and Turker Tuncer and Sengul Dogan},
  doi          = {10.1080/08839514.2022.2137653},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2137653},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Vehicle interior sound classification based on local quintet magnitude pattern and iterative neighborhood component analysis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). End-to-end convolutional neural network feature extraction
for remote sensed images classification. <em>AAI</em>, <em>36</em>(1),
Article: 2137650. (<a
href="https://doi.org/10.1080/08839514.2022.2137650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, land cover and land use (LCLU) classification in remote sensing imagery has attracted research interest. The LCLU contains dynamic remote sensed images due to sensor technology ability, seasonal changes, and distance for resolution. Therefore, the deep learning-based LCLU classification system needs more investigation using deep learning techniques. Deep learning approaches have gotten more attention for their powerful performance improvements. Most recent studies have been performed on deep convolutional neural networks (CNNs) that have been trained on pre-trained networks in remote sensing classification. However, designing CNNs from scratch has not yet been widely investigated in remote sensed images as they need ample training time and a powerful processor. Therefore, we used hyperparameters and early stopping techniques to apply an end-to-end CNN feature extractor (CNN-FE) model for LCLU classification in the UC-Merced dataset. We approved the model&#39;s applicability in the domain area by retraining it on another dataset called SIRI-WHU and building the VGG19 pre-trained feature extractor model built on the same hyperparameters. The CNN-FE has outperformed the state-of-the-art baseline studies&#39; accuracy and the VGG19 pre-trained model. Moreover, a better CNN-FE performance was achieved when trained in the UC-Merced dataset than the model performance when trained in the SIRI-WHU dataset.},
  archive      = {J_AAI},
  author       = {Abebaw Alem and Shailender Kumar},
  doi          = {10.1080/08839514.2022.2137650},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2137650},
  shortjournal = {Appl. Artif. Intell.},
  title        = {End-to-end convolutional neural network feature extraction for remote sensed images classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Yield-SpikeSegNet: An extension of SpikeSegNet deep-learning
approach for the yield estimation in the wheat using visual images.
<em>AAI</em>, <em>36</em>(1), Article: 2137642. (<a
href="https://doi.org/10.1080/08839514.2022.2137642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-throughput plant phenotyping integrated with computer vision is an emerging topic in the domain of nondestructive and noninvasive plant breeding. Analysis of the emerging grain spikes and the grain weight or yield estimation in the wheat plant for a huge number of genotypes in a nondestructive way has achieved significant research attention. In this study, we developed a deep learning approach, “Yield-SpikeSegNet,” for the yield estimation in the wheat plant using visual images. Our approach consists of two consecutive modules: “Spike detection module” and “Yield estimation module.” The spike detection module is implemented using a deep encoder-decoder network for spike segmentation and output of this module is spike area and spike count. In yield estimation module, we develop machine learning models using artificial neural network and support vector regression for the yield estimation in the wheat plant. The model’s precision, accuracy, and robustness are found satisfactory in spike segmentation as 0.9982, 0.9987, and 0.9992, respectively. The spike segmentation and yield estimation performance reflect that the Yield-SpikeSegNet approach is a significant step forward in the domain of high-throughput and nondestructive wheat phenotyping.},
  archive      = {J_AAI},
  author       = {Tanuj Misra and Alka Arora and Sudeep Marwaha and Ranjeet Ranjan Jha and Mrinmoy Ray and Shailendra Kumar and Sudhir Kumar and Viswanathan Chinnusamy},
  doi          = {10.1080/08839514.2022.2137642},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2137642},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Yield-SpikeSegNet: An extension of SpikeSegNet deep-learning approach for the yield estimation in the wheat using visual images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection for cyber internet of things attacks: A
systematic review. <em>AAI</em>, <em>36</em>(1), Article: 2137639. (<a
href="https://doi.org/10.1080/08839514.2022.2137639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From past few years, the Internet of things (IoT) is an emerging and encouraging technology that has gained prominence in the industries. Due to its increasing usages, a huge amount of data are exchanged within IoT architecture using the internet, which is why privacy and cyber-security are major issues. The heterogeneous nature of various technologies that are combined using IoT makes it problematic to provide security using prescriptive networking. The future of secure IoT depends on privacy issues. The research intends to improve security mechanisms based on intrusion and anomaly detection for IoT using deep learning. In this context, a systematic literature review (SLR) is conducted to identify ‘How to perform data transformation analysis of IoT dataset to detect anomaly detection for cyber IoT attacks? The SLR result found 24 datasets used for IoT analysis, 35 performance metrics to evaluate IoT problems, 6–42 features identified for detection, 42 preprocessing techniques have been used for transforming data, and 26 different methods and models were used to process the given problem. The SLR highlights further enhancement for the issue and identification of cyber-security in IoT. Anomaly detection can be done based on reinforcement deep learning after a thorough analysis of SLR.},
  archive      = {J_AAI},
  author       = {Laraib Sana and Muhammad Mohsin Nazir and Muddesar Iqbal and Lal Hussain and Amjad Ali},
  doi          = {10.1080/08839514.2022.2137639},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2137639},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Anomaly detection for cyber internet of things attacks: A systematic review},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). LifeGuard: An improvement of actor-critic model with
collision predictor in autonomous UAV navigation. <em>AAI</em>,
<em>36</em>(1), Article: 2137632. (<a
href="https://doi.org/10.1080/08839514.2022.2137632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The needs for autonomous unmanned aerial vehicle navigation (AUN) have been emerging for recent years due to the growth of the logistic industry and the need for social distancing during the pandemic. There have been different methods trying to overcome the AUN task, and most of them have focused on deep reinforcement learning (DRL). But the results were still far from satisfactory, and even if the result was good, the environment was usually too trivial and simple. We report in this paper one of the causes of low success rate for AUN in our previous work, which is the apprehensive behavior of agents. After numerous episodes of training, when the agent faces risky scenes, it often moves back and forth repeatedly until running out of the limited steps. Hence, in this paper, we propose a new role, LifeGuard, into the popular DRL model, Actor-Critic, to tackle the apprehensive behavior and expect a better success rate. In addition, we developed a pilot method of unsupervised classification for sequential data to further enhance our reward function from previous work, augmentative backward reward function. The experimental results demonstrated that the proposed method can eliminate the apprehensive behavior and gain higher success rates than the state-of-the-art method, FORK, with lesser effort.},
  archive      = {J_AAI},
  author       = {Manit Chansuparp and Kulsawasd Jitkajornwanich},
  doi          = {10.1080/08839514.2022.2137632},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2137632},
  shortjournal = {Appl. Artif. Intell.},
  title        = {LifeGuard: An improvement of actor-critic model with collision predictor in autonomous UAV navigation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Internet and telecommunication fraud prevention analysis
based on deep learning. <em>AAI</em>, <em>36</em>(1), Article: 2137630.
(<a href="https://doi.org/10.1080/08839514.2022.2137630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, contactless fraud crimes via telecommunication and Internet have grown rapidly. Meanwhile, the rate of solved criminal cases is much lower, which is mainly due to two reasons. Firstly, the definition of risk factors in the field of new Internet and telecommunication fraud crime is not comprehensive, resulting in the problem not being well defined. Secondly, Internet fraud crime information is mostly recorded using natural language with huge volume, and there is a lack of automated and intelligent way to deeply analyze and extract the risk factor. To better analyze the Internet and telecommunication fraud crime to help solve more cases, in this paper, we propose a new Internet and telecommunication fraud crime risk factor extraction system. After studying the existing related research, we propose a novel risk factor extraction technology based on BERT. This novel technology can gracefully deal with multi-sources and heterogeneous data problems during the extraction of risk factors in multiple dimensions; meanwhile, it can significantly reduce the need for computation resources and improve the online serving performance. After experimentation, this technique can significantly reduce training time by 60%-70%, and meanwhile, it can reduce the computation resources by 80% and improve serving performance by 5 times during serving. In our approach, we propose a novel approach to set sample weight and loss weight based on data characteristics and data distribution during model training, which can significantly improve extraction precision. With adjusting the sample weight during model training, we can get 1.56% precision improved. Moreover, setting the loss weight during model training, the precision can be improved by 1.63% compared to baseline mode.},
  archive      = {J_AAI},
  author       = {Peifeng Ni and Quanxiu Wang},
  doi          = {10.1080/08839514.2022.2137630},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2137630},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Internet and telecommunication fraud prevention analysis based on deep learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational autoencoder for classification and regression
for out-of-distribution detection in learning-enabled cyber-physical
systems. <em>AAI</em>, <em>36</em>(1), Article: 2131056. (<a
href="https://doi.org/10.1080/08839514.2022.2131056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-Enabled Components (LECs), such as neural networks, are broadly employed in Cyber-Physical Systems (CPSs) to tackle a wide variety of complex tasks in high-uncertainty environments. However, the training dataset is inevitably incomplete, and Out-Of-Distribution (OOD) data not encountered during the LEC training may lead to erroneous predictions, jeopardizing the safety of the system. In this paper, we first analyze the causes of OOD data and define various types of OOD data in learning-enabled CPSs. We propose an approach to effectively detect OOD data for both classification and regression problems. The proposed approach incorporates the variational autoencoder for classification and regression model to the Inductive Conformal Anomaly Detection (ICAD) framework, enabling the detection algorithm to take into consideration not only the LEC inputs but also the LEC outputs. We evaluate the approach using extensive experiments for both classification and regression tasks, and the experimental results validate the effectiveness of the proposed method for detecting different types of OOD data. Furthermore, the execution time of detection is relatively short; therefore, the proposed approach can be used for real-time detection.},
  archive      = {J_AAI},
  author       = {Feiyang Cai and Ali I. Ozdagli and Xenofon Koutsoukos},
  doi          = {10.1080/08839514.2022.2131056},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2131056},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Variational autoencoder for classification and regression for out-of-distribution detection in learning-enabled cyber-physical systems},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Text classification of conversational implicatures based on
lexical features. <em>AAI</em>, <em>36</em>(1), Article: 2127598. (<a
href="https://doi.org/10.1080/08839514.2022.2127598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the guiding hypothesis in NLP, similar word frequency vectors may have similar implicatures, but some scholars are more inclined conversational implicatures cannot be obtained only through lexical features. To judge which view is more reasonable and explore the reasons for the divergence between them, whether conversational implicatures can be obtained only through lexical features is verified empirically. Main work of this paper includes: First, based on 600 corpora in the annotated dataset, the values of 20 lexical features of each corpus are obtained by automatic calculation. Second, meta-transformer of logistic regression for selecting features is adopted for feature selection and ranking. Third, after determining the features, the text is classified by the binomial logistic regression with the type of implicatures as labels. Fourth, results are tested for significance to identify relationships between variables. Experiments show that there is a statistical dependence between lexical features and conversational implicatures, and the text classification of implicatures can be performed only based on lexical features. In addition, the results of text classification will not be different due to the difference in context utterance or the type of implicature, and the text classification of implicatures only based on “response utterance” is more efficient.},
  archive      = {J_AAI},
  author       = {Xianbo Li},
  doi          = {10.1080/08839514.2022.2127598},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2127598},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Text classification of conversational implicatures based on lexical features},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep sentiments analysis for roman urdu dataset using faster
recurrent convolutional neural network model. <em>AAI</em>,
<em>36</em>(1), Article: 2123094. (<a
href="https://doi.org/10.1080/08839514.2022.2123094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urdu language is being spoken by over 64 million people and its Roman script is very popular, especially on social networking sites. Most users prefer Roman Urdu over English grammar for communication on social networking platforms such as Facebook, Twitter, Instagram and WhatsApp. For research, Urdu is a poor resource language as there are a few research papers and projects that have been carried out for the language and vocabulary enhancement in comparison to other languages especially English. A lot of research has been made in the domain of sentiment analysis in English but only a limited work has been performed on the Roman Urdu language. Sentiment analysis is the method of understanding human emotions or points of view, expressed in a textual form about a particular thing. This article proposes a deep learning model to perform data mining on emotions and attitudes of people using Roman Urdu. The main objective of the research is to evaluate sentiment analysis on Roman Urdu corpus containing RUSA-19 using faster recurrent convolutional neural network (FRCNN), RCNN, rule-based and N -gram model. For assessment, two series of experiments were performed on each model, binary classification (positive and negative) and tertiary classification (positive, negative, and neutral). Finally, the evaluation of the faster RCNN model is analyzed and a comparative analysis is performed for the outcomes of four models. The faster RCNN model outperformed others as the model achieves an accuracy of 91.73% for binary classification and 89.94% for tertiary classification.},
  archive      = {J_AAI},
  author       = {Arfan Ali Nagra and Khalid Alissa and Taher M. Ghazal and Saigeeta Kukunuru and Muhammad Mugees Asif and Muhammad Fawad},
  doi          = {10.1080/08839514.2022.2123094},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2123094},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep sentiments analysis for roman urdu dataset using faster recurrent convolutional neural network model},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual inspection of surface defects of extreme size based
on an advanced FCOS. <em>AAI</em>, <em>36</em>(1), Article: 2122222. (<a
href="https://doi.org/10.1080/08839514.2022.2122222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defects of industrial products are generally detected through anchor-based object detection methods during manufacturing. However, these methods are prone to missed and false detection for ultra-elongated and ultra-fine defects. An advanced fully convolutional one-stage object detector (FCOS) is proposed. This method is based on an anchor-free FCOS network model. First, a novel type of center-ness is proposed to reduce the suppression of off-centered positions of defects of extreme size. In addition, to eliminate background interference, a self-adaptive center sampling method is proposed as a replacement for the conventional center sampling method. The regularization method and the loss function are also improved according to the defect characteristics. Experimental results show that this advanced-FCOS-based method outperforms anchor-based methodson the surface defect dataset. The proposed method effectively detects defects of extreme size without affecting the detection of normal defects. The performance of the proposed method meets the requirements of real industrial applications.},
  archive      = {J_AAI},
  author       = {Hui Shi and Rui Lai and Gangyan Li and Wenyong Yu},
  doi          = {10.1080/08839514.2022.2122222},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2122222},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Visual inspection of surface defects of extreme size based on an advanced FCOS},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CFD validation for assessing the repercussions of filter
cake breakers; EDTA and SiO2 on filter cake return permeability.
<em>AAI</em>, <em>36</em>(1), Article: 2112551. (<a
href="https://doi.org/10.1080/08839514.2022.2112551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drill-in-fluids create what are known as filter cakes. Filter cakes, in some cases, lead to well abandonment because they prevent hydrocarbons from flowing freely from the formation into the wellbore. Cake removal is essential to avoid formation damage. A previous study on filter cake breakers was considered for computational fluid dynamic (CFD) validation. Matlab-CFD and Navier-Stokes equations aimed at predicting and validating visual, multiphase flow under finite element analysis (FEA). The interactions of separate chemical breakers and drill-in-fluid such as ethylenediaminetetraacetic acid (EDTA), silica-nanoparticle (SiO 2 ), and biodegradable synthetic-based mud drill-in-fluid (BSBMDIF) were monitored under a particle size distribution, viscosity, density, and pressure. Predicting return permeability of filter cake was considered under a simple filtration process. The particles’ deposition created pore spaces between them; barite 74 μm, nano-silica 150 nm, and EDTA 10 μm generally closed up the pores of the filtration medium. Under extreme drilling conditions, barite formed thicker regions, and EDTA chemical properties easily disjointed these particles, while SiO 2 entirely did not. The experimented results of (EDTA) and SiO 2 for return permeability were in full force agreeable with the 2D simulation. A hybrid computational analysis considering CFD under discrete element analysis and neural network can be employed for further research validations.},
  archive      = {J_AAI},
  author       = {Dennis Delali Kwesi Wayo and Sonny Irawan and Javed Akbar Khan and Fitrianti},
  doi          = {10.1080/08839514.2022.2112551},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2112551},
  shortjournal = {Appl. Artif. Intell.},
  title        = {CFD validation for assessing the repercussions of filter cake breakers; EDTA and SiO2 on filter cake return permeability},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Future challenges of particulate matters (PMs) monitoring by
computing associations among extracted multimodal features applying
bayesian network approach. <em>AAI</em>, <em>36</em>(1), Article:
2112545. (<a
href="https://doi.org/10.1080/08839514.2022.2112545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particulate matter (PM) is emitted from diverse sources and affects the human health very badly. In the past, researchers applied different automated computational tools in the predication of PM. Accurate prediction of PM requires more relevant features and feature importance. In this research, we first extracted the multimodal features from time domain standard deviation average (SDAPM), standard deviation of standard deviation (SDSD), standard deviation of particulate matter (SDPM), root-mean square of standard deviation (RMSSD), and nonlinear dynamical measure wavelet entropy (WE) – Shannon, norm, threshold, multiscale entropy based on KD tree (MSEKD), and multiscale approximate entropy (MAEnt). We then applied the intelligent-based Bayesian inference approach to compute the strength of relationship among multimodal features. We also computed total incoming and outgoing forces between the features (nodes). The results reveal that there was a very highly significant correlation ( p -value &lt;0.05) between the selected nodes. The highest total force was yielded by WE-norm followed by SDAPM and SDPM. The association will further help to investigate that which extracted features are more positively or negatively correlated and associated with each other. The results revealed that the proposed methodology can further provide deeper insights into computing the association among the features.},
  archive      = {J_AAI},
  author       = {Amani Abdulrahman Albraikan and Jaber S. Alzahrani and Noha Negm and Lal Hussain and Mesfer Al Duhayyim and Manar Ahmed Hamza and Abdelwahed Motwakel and Ishfaq Yaseen},
  doi          = {10.1080/08839514.2022.2112545},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2112545},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Future challenges of particulate matters (PMs) monitoring by computing associations among extracted multimodal features applying bayesian network approach},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stock market prediction of NIFTY 50 index applying machine
learning techniques. <em>AAI</em>, <em>36</em>(1), Article: 2111134. (<a
href="https://doi.org/10.1080/08839514.2022.2111134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock market is viewed as an unpredictable, volatile, and competitive market. The prediction of stock prices has been a challenging task for many years. In fact, many analysts are highly interested in the research area of stock price prediction. Various forecasting methods can be categorized into linear and non-linear algorithms. In this paper, we offer an overview of the use of deep learning networks for the Indian National Stock Exchange time series analysis and prediction. The networks used are Recurrent Neural Network, Long Short-Term Memory Network, and Convolutional Neural Network to predict future trends of NIFTY 50 stock prices. Comparative analysis is done using different evaluation metrics. These analysis led us to identify the impact of feature selection process and hyper-parameter optimization on prediction quality and metrics used in the prediction of stock market performance and prices. The performance of the models was quantified using MSE metric. These errors in the LSTM model are found to be lower compared to RNN and CNN models.},
  archive      = {J_AAI},
  author       = {Zahra Fathali and Zahra Kodia and Lamjed Ben Said},
  doi          = {10.1080/08839514.2022.2111134},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2111134},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Stock market prediction of NIFTY 50 index applying machine learning techniques},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development and evaluation of an intelligent system for
calibrating karaoke lyrics based on fuzzy petri nets. <em>AAI</em>,
<em>36</em>(1), Article: 2110699. (<a
href="https://doi.org/10.1080/08839514.2022.2110699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the home entertainment system, karaoke is a popular leisure facility in our daily life. Via the karaoke system, users can sing along with the lyrics based on the recordings of pop songs. However, a lot of karaoke systems can display lyrics semi-automatically. Traditionally, some lyrics are input manually and need to be synchronized with the tonal music stepwise, which is time-consuming. One of the famous musical phrase segmentation theories is a generative theory of tonal music, through which we have implemented a karaoke system in C# programming language. This intelligent system can automatically segment music phrases and use a high-level fuzzy Petri net model to calibrate the lyrics in pop songs. Fifty Chinese pop songs are selected to evaluate its performance. The experimental results have shown that the average calibration precision value (92.78%) and recall value (90.46%) are highly acceptable.},
  archive      = {J_AAI},
  author       = {Yi-Nan Lin and Cheng-Ying Yang and Sheng-Kuan Wang and Gwo-Jen Chiou and Victor R.L. Shen and Yi-Chih Tung and Frank H.C. Shen and Hung-Chi Cheng},
  doi          = {10.1080/08839514.2022.2110699},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2110699},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Development and evaluation of an intelligent system for calibrating karaoke lyrics based on fuzzy petri nets},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessment of occupational exposure to noise among sawmill
workers in the timber processing factories. <em>AAI</em>,
<em>36</em>(1), Article: 2110696. (<a
href="https://doi.org/10.1080/08839514.2022.2110696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the workplace, exposure to noise levels at or above 85 dB(A) can increase the risk for the development of noise-induced hearing loss (NIHL). Sawmill workers are continuously exposed to noise levels above 85 dB(A) and they had to raise their voices when they communicate if they are 1 m away from each other. The study was conducted to measure and determine the time-weighted average (TWA) occupational exposure levels to noise in the timber processing factories and compare the results with the noise rating limits. Personal and area noise survey was undertaken using a calibrated SV104IS noise dosimeters (Svantek, Poland) and integrating type 1 sound level meter (Soundpro SE/DL, U.S.A.). Data was analyzed using Microsoft Office Excel 2019 Analysis Tool Pak for descriptive statistics. Both the geometric means and standard deviation as well the minimum and maximum values were determined. The geometric mean (GSD) for area noise exposure levels at sawmill A was 90.05(8.02) dB(A) while at sawmill B was 90.14(7.94) dB(A). Furthermore, the geometric mean (GSD) for personal noise exposure level at sawmill A was 92.26(4.35) dB(A) while at sawmill B was 92.24(2.65) dB(A). The results revealed that sawmill workers were exposed to high noise level above the 85 dB(A) noise rating limit and were at moderate-to-high risk of suffering from NIHL.},
  archive      = {J_AAI},
  author       = {M. Rathipe and F. S. Raphela},
  doi          = {10.1080/08839514.2022.2110696},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2110696},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Assessment of occupational exposure to noise among sawmill workers in the timber processing factories},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal failure matching point based motion object
saliency detection for unconstrained videos. <em>AAI</em>,
<em>36</em>(1), Article: 2110695. (<a
href="https://doi.org/10.1080/08839514.2022.2110695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by classical feature descriptors in motion matching, this paper proposes a multimodal failure matching point collection method, which is defined as FMP. FMP is, in fact, a collection of unstable features with a low matching degree in the conventional matching task. Based on FMP, a novel model for the saliency detection of motion object is developed. Models are evaluated on the DAVIS and SegTrackv2 datasets and compared with recently advanced object detection algorithms. The comparison results demonstrate the availability and effectiveness of FMP in the detection of motion object saliency.},
  archive      = {J_AAI},
  author       = {Jiang Qian and Jingkang Wei and Hui Chen and Gongping Chen},
  doi          = {10.1080/08839514.2022.2110695},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2110695},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multimodal failure matching point based motion object saliency detection for unconstrained videos},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient method for generating synthetic data for
low-resource machine translation. <em>AAI</em>, <em>36</em>(1), Article:
2101755. (<a
href="https://doi.org/10.1080/08839514.2022.2101755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data sparsity is one of the challenges for low-resource language pairs in Neural Machine Translation (NMT). Previous works have presented different approaches for data augmentation, but they mostly require additional resources and obtain low-quality dummy data in the low-resource issue. This paper proposes a simple and effective novel for generating synthetic bilingual data without using external resources as in previous approaches. Moreover, some works recently have shown that multilingual translation or transfer learning can boost the translation quality in low-resource situations. However, for logographic languages such as Chinese or Japanese, this approach is still limited due to the differences in translation units in the vocabularies. Although Japanese texts contain Kanji characters that are derived from Chinese characters, and they are quite homologous in sharp and meaning, the word orders in the sentences of these languages have a big divergence. Our study will investigate these impacts in machine translation. In addition, a combined pre-trained model is also leveraged to demonstrate the efficacy of translation tasks in the more high-resource scenario. Our experiments present performance improvements up to +6.2 and +7.8 BLEU scores over bilingual baseline systems on two low-resource translation tasks from Chinese to Vietnamese and Japanese to Vietnamese.},
  archive      = {J_AAI},
  author       = {Thi-Vinh Ngo and Phuong-Thai Nguyen and Van Vinh Nguyen and Thanh-Le Ha and Le-Minh Nguyen},
  doi          = {10.1080/08839514.2022.2101755},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2101755},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An efficient method for generating synthetic data for low-resource machine translation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic speech recognition using limited vocabulary: A
survey. <em>AAI</em>, <em>36</em>(1), Article: 2095039. (<a
href="https://doi.org/10.1080/08839514.2022.2095039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic Speech Recognition (ASR) is an active field of research due to its large number of applications and the proliferation of interfaces or computing devices that can support speech processing. However, the bulk of applications are based on well-resourced languages that overshadow under-resourced ones. Yet, ASR represents an undeniable means to promote such languages, especially when designing human-to-human or human-to-machine systems involving illiterate people. An approach to design an ASR system targeting under-resourced languages is to start with a limited vocabulary. ASR using a limited vocabulary is a subset of the speech recognition problem that focuses on the recognition of a small number of words or sentences. This paper aims to provide a comprehensive view of mechanisms behind ASR systems as well as techniques, tools, projects, recent contributions, and possible future directions in ASR using a limited vocabulary. This work consequently provides a way forward when designing an ASR system using limited vocabulary. Although an emphasis is put on limited vocabulary, most of the tools and techniques reported in this survey can be applied to ASR systems in general. Abbreviations ACC: Accuracy; AM: Acoustic Model; ASR: Automatic Speech Recognition; BD-4SK-ASR: Basic Dataset for Sorani Kurdish Automatic Speech Recognition; CER: Character Error Rate; CMU: Carnegie Mellon University; CNN: Convolutional Neural Network; CNTK: CogNitive ToolKit; CUED: Cambridge University Engineering Department; DCT:Discrete Cosine Transformation; DL: Deep Learning; DNN: Deep Neural Network; DRL: Deep Reinforcement Learning; DWT: Discrete Wavelet Transform; FFT: Fast Fourier Transformation; GMM: Gaussian Mixture Model; HMM: Hidden Markov Model; HTK: Hidden Markov Model ToolKit; JASPER: Just Another Speech Recognizer; LDA: Linear Discriminant Analysis; LER: Letter Error Rate; LGB: Light Gradient Boosting Machine; LM:Language Model; LPC: Linear Predictive Coding; LVCSR: Large Vocabulary Continuous Speech Recognition; LVQ: Learning Vector Quantization Algorithm; MFCC: Mel-Frequency Cepstrum Coefficient; ML: Machine Learning; PCM:Pulse-Code Modulation; PPVT: Peabody Picture Vocabulary Test; RASTA: RelAtive SpecTral; RLAT: Rapid Language Adaptation Toolkit; S2ST: Speech-to-Speech Translation; SAPI: Speech Application Programming Interface; SDK: Software Development Kit; SVASR:Small Vocabulary Automatic Speech Recognition; WER: Word Error Rate},
  archive      = {J_AAI},
  author       = {Jean Louis K. E Fendji and Diane C. M. Tala and Blaise O. Yenke and Marcellin Atemkeng},
  doi          = {10.1080/08839514.2022.2095039},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2095039},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automatic speech recognition using limited vocabulary: A survey},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection using siamese network with attention
mechanism for few-shot learning. <em>AAI</em>, <em>36</em>(1), Article:
2094885. (<a
href="https://doi.org/10.1080/08839514.2022.2094885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated inspection using deep-learning has been attracting attention for visual inspection at the manufacturing site. However, the inability to obtain sufficient abnormal product data for training deep- learning models is a problem in practical application. This study proposes an anomaly detection method based on the Siamese network with an attention mechanism for a small dataset. Moreover, attention branch loss (ABL) is proposed for Siamese network to render more task-specific attention maps from attention mechanism. Experimental results confirm that the proposed method with the attention mechanism and ABL is effective even with limited abnormal data.},
  archive      = {J_AAI},
  author       = {Hironori Takimoto and Junya Seki and Sulfayanti F. Situju and Akihiro Kanagawa},
  doi          = {10.1080/08839514.2022.2094885},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2094885},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Anomaly detection using siamese network with attention mechanism for few-shot learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep learning approach for classification of dentinal
tubule occlusions. <em>AAI</em>, <em>36</em>(1), Article: 2094446. (<a
href="https://doi.org/10.1080/08839514.2022.2094446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aimed to develop a novel deep learning model for reliable quantification of dentinal tubule occlusions instead of manual assessment techniques, and the performance of the model was compared to other methods in the literature. Ninety-six dentin samples were cut and prepared with desensitizing agents to occlude dentinal tubules on different levels. After obtaining images via scanning electron microscope (SEM), 2793 single dentinal tubule images with 48 × 48 resolution were segmented and labeled. Data augmentation techniques were applied for improvement in the learning rate. The augmented data having a total of 10700 images belonging to five classes were used as the network training dataset. The proposed convolutional neural network (CNN) is a class of deep learning model and was able to classify the degree of dentinal tubule occlusions into five classes with an overall accuracy rate of 90.24%. This paper primarily focuses on developing a CNN architecture for detecting the level of dentin tubule occlusions imaged by SEM. The results showed that the proposed CNN architecture is an immensely successful alternative and allowed for objective and automatic classification of segmented dentinal tubule images.},
  archive      = {J_AAI},
  author       = {Anday Duru and İsmail Rakıp Karaş and Fatih Karayürek and Aydın Gülses},
  doi          = {10.1080/08839514.2022.2094446},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2094446},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A deep learning approach for classification of dentinal tubule occlusions},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Saliency detection using a bio-inspired spiking neural
network driven by local and global saliency. <em>AAI</em>,
<em>36</em>(1), Article: 2094408. (<a
href="https://doi.org/10.1080/08839514.2022.2094408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of the most salient parts of images as objects in salient object detection tasks mimics human behavior, which is useful for a variety of computer vision applications. In this paper, the Local and Global Saliency Driven Dual-Channel Pulse Coupled Neural Network (LGSD-DCPCNN) model is used to provide a novel strategy for saliency detection. To achieve visually homogeneous sections and save computation costs, the input image is first subjected to superpixel segmentation. The global and local saliency maps are then created using the segmented image’s position, color, and textural properties. The LGSD-DCPCNN network is activated using these saliency maps to extract visually consistent features from the input maps to provide the final saliency map. An extensive qualitative and quantitative performance study is undertaken to assess the efficacy of the proposed method. When compared to state-of-the-art approaches, the experimental results show a considerable improvement in the detection of salient regions. Quantitative analysis of the proposed method reveals a significant improvement in the area under the ROC curve (AUC) score, F-measure score, and mean absolute error (MAE) score. The qualitative analysis describes the proposed algorithm’s ability to detect multiple salient objects accurately while maintaining significant border preservation.},
  archive      = {J_AAI},
  author       = {Bhagyashree V. Lad and Manisha Das and Mohammad Farukh Hashmi and Avinash G. Keskar and Deep Gupta},
  doi          = {10.1080/08839514.2022.2094408},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2094408},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Saliency detection using a bio-inspired spiking neural network driven by local and global saliency},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of deep learning-based human activity recognition
on benchmark video datasets. <em>AAI</em>, <em>36</em>(1), Article:
2093705. (<a
href="https://doi.org/10.1080/08839514.2022.2093705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different types of research have been done on video data using Artificial Intelligence (AI) deep learning techniques. Most of them are behavior analysis, scene understanding, scene labeling, human activity recognition (HAR), object localization, and event recognition. Among all these, HAR is one of the challenging tasks and thrust areas of video data processing research. HAR is applicable in different areas, such as video surveillance systems, human-computer interaction, human behavior characterization, and robotics. This paper aims to present a comparative review of vision-based human activity recognition with the main focus on deep learning techniques on various benchmark video datasets comprehensively. We propose a new taxonomy for categorizing the literature as CNN and RNN-based approaches. We further divide these approaches into four sub-categories and present various methodologies with their experimental datasets and efficiency. A short comparison is also made with the handcrafted feature-based approach and its fusion with deep learning to show the evolution of HAR methods. Finally, we discuss future research directions and some open challenges on human activity recognition. The objective of this survey is to give the current progress of vision-based deep learning HAR methods with the up-to-date study of literature.},
  archive      = {J_AAI},
  author       = {Vijeta Sharma and Manjari Gupta and Anil Kumar Pandey and Deepti Mishra and Ajai Kumar},
  doi          = {10.1080/08839514.2022.2093705},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2093705},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A review of deep learning-based human activity recognition on benchmark video datasets},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligence based accurate medium and long term load
forecasting system. <em>AAI</em>, <em>36</em>(1), Article: 2088452. (<a
href="https://doi.org/10.1080/08839514.2022.2088452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we aim to provide an efficient load prediction system projected for different local feeders to predict the Medium- and Long-term Load Forecasting. This model improves future requirements for expansions, equipment retailing or staff recruiting to the electric utility company. We aimed to improve ahead forecasting by using hybrid approach and optimizing the parameters of our models. We used Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN), Multilayer perceptron (MLP) and hybrid methods. We used Root Mean Square Error (RMSE), Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE) and squared error for comparison. To predict the 3 months ahead load forecasting, the lowermost prediction error was acquired using LSTM MAPE (2.70). For 6 months ahead forecasting prediction, MLP gives highest predictions with MAPE (2.36). Moreover, to predict the 9 months ahead load forecasting, the highest prediction has been attained using LSTM in terms of MAPE (2.37). Likewise, ahead 1 years MAPE (2.25) was yielded using LSTM and ahead six years MAPE (2.49) was provided using MLP. The proposed methods attain stable and better performance for prediction of load forecasting. The finding indicates that this model can be better instigated for future expansion requirements.},
  archive      = {J_AAI},
  author       = {Faisal Mehmood Butt and Lal Hussain and Syed Hassan Mujtaba Jafri and Haya Mesfer Alshahrani and Fahd N Al-Wesabi and Kashif Javed Lone and Elsayed M. Tag El Din and Mesfer Al Duhayyim},
  doi          = {10.1080/08839514.2022.2088452},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2088452},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intelligence based accurate medium and long term load forecasting system},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Credit card fraud detection with automated machine learning
systems. <em>AAI</em>, <em>36</em>(1), Article: 2086354. (<a
href="https://doi.org/10.1080/08839514.2022.2086354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The steady increase at the turnover of online trading during the last decade and the increasing use of credit cards has subsequently made credit card frauds more prevalent. Machine Learning (ML) models are among the most prominent techniques in detecting illicit transactions. In this paper, we apply the Just-Add-Data (JAD), a system that automates the selection of Machine Learning algorithms, the tuning of their hyper-parameter values, and the estimation of performance in detecting fraudulent transactions using a highly unbalanced dataset, swiftly providing prediction model for credit card fraud detection. The training of the model does not require the user setting up any of the methods’ (hyper)parameters. In addition, it is trivial to retrain the model with the arrival of new data, to visualize, interpret, and share the results at all management levels within a credit card organization, as well as to apply the model. The model selected by JAD identifies 32 out of a total of 39 fraudulent transactions of the test sample, with all missed fraudulent transactions being small transactions below 50€. The comparison with other methods on the same dataset reveals that all the above come with a high forecasting performance that matches the existing literature.},
  archive      = {J_AAI},
  author       = {Vasilios Plakandaras and Periklis Gogas and Theophilos Papadimitriou and Ioannis Tsamardinos},
  doi          = {10.1080/08839514.2022.2086354},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2086354},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Credit card fraud detection with automated machine learning systems},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lane detection based on instance segmentation of BiSeNet v2
backbone network. <em>AAI</em>, <em>36</em>(1), Article: 2085321. (<a
href="https://doi.org/10.1080/08839514.2022.2085321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most lane line detection algorithms still have room for improvement in detection accuracy, speed, and robustness. Meanwhile, these algorithms only test the performance indicators through the test set of the open-source dataset rather than deploying them on actual vehicles and evaluating the performance indicators through road scenarios. Therefore, this paper proposes a lane detection algorithm based on instance segmentation. Firstly, a dual-branch neural network model for lane line image segmentation was designed based on BiSeNet V2. Then the discrete lane line feature points are operated through the clustering model. The corresponding feature points are selected for fitting by combining straight lines and curves to obtain the appropriate fitting parameter equation for the specific visual field area. Finally, the model is trained and verified based on the TuSimple dataset. The algorithm has a noticeable performance improvement under the two evaluation indicators of mIoU and FPS. Meanwhile, the model is integrated into the ROS task platform for intelligent vehicles. The results show that the algorithm’s accuracy and detection speed are increased to about 3.9 and 2.9 times, respectively, that of the improved probabilistic Hough transform algorithm under the two evaluation indicators of lateral distance and the detection time of each image frame.},
  archive      = {J_AAI},
  author       = {Sun Yang and Li Yunpeng and Liu Yu},
  doi          = {10.1080/08839514.2022.2085321},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2085321},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Lane detection based on instance segmentation of BiSeNet v2 backbone network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy closed filters in bounded BE-algebras. <em>AAI</em>,
<em>36</em>(1), Article: 2084477. (<a
href="https://doi.org/10.1080/08839514.2022.2084477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we use the method of fuzzification of crisp set to fuzzy set as extension of crisp set to fuzzy set. In particular the concepts of fuzzy closed filters of a bounded BE-algebra are introduced; and also some related properties are investigated. As a result a new concept of fuzzy closed filters of a bounded BE-algebras are discussed. Using the idea of fuzzy closed filters of a bounded BE-algebras, some related properties are investigated. In general characterization theorems that related fuzzy closed filters and fuzzy filter are proved. Furthermore, characterization theorem that relate closed filter and fuzzy closed filter in abounded BE-algebra is investigated.},
  archive      = {J_AAI},
  author       = {Gerima Tefera and Mohammed Adem},
  doi          = {10.1080/08839514.2022.2084477},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2084477},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Fuzzy closed filters in bounded BE-algebras},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A novel augmentative backward reward function with deep
reinforcement learning for autonomous UAV navigation. <em>AAI</em>,
<em>36</em>(1), Article: 2084473. (<a
href="https://doi.org/10.1080/08839514.2022.2084473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The autonomous UAV (unmanned aerial vehicle) navigation has recently gained an increasing interest from both academic and industrial sectors due to its potential uses in various fields and especially, the need for social distancing during the pandemic. Many works have adopted a deep reinforcement learning (RL) method with experience replay called deep deterministic policy gradient (DDPG) to control the motion of UAV, and gain high accuracy results in static and simplified environments. However, they are still far from being ready for real world adoption in that the UAVs have to operate under complex and dynamic conditions. We also found that using only DDPG makes the learning process prone to oscillation and is inefficient for tasks having high dimensional action-state spaces. Furthermore, the goal reward mechanism in traditional reward functions brings a bias to the state, which resembles the one at the goal area and leads to erroneous action selection. To get closer to being ready for real world adoption, we proposed a novel method that enables UAVs to be capable of handling motion control in realistic environments. The first component of our proposed method is point cloud data (PCD) simplification with truncated icosahedron structure which converts enormous PCD into a few essential data points. In the second component of our method, we replace the traditional goal reward mechanism with a new mechanism called Augmentative Backward Reward (ABR) function to dispense the goal reward to transitions proportionately to its participation. By integrating simplified PCD and ABR, we achieved significantly better results when compared with using only the-state-of-the-art, TD3. In addition, we tested the proposed method with another navigation task, BipedalWalkerHardcore, a testbed for RL, and the result is still better and steadier than of TD3. These results indicate that the proposed method is robust.},
  archive      = {J_AAI},
  author       = {Manit Chansuparp and Kulsawasd Jitkajornwanich},
  doi          = {10.1080/08839514.2022.2084473},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2084473},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel augmentative backward reward function with deep reinforcement learning for autonomous UAV navigation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI predicted product portfolio for profit maximization.
<em>AAI</em>, <em>36</em>(1), Article: 2083799. (<a
href="https://doi.org/10.1080/08839514.2022.2083799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprises analyze opportunities and threats in the external environment, measure internal strengths and weaknesses, and formulate strategic objectives to stay ahead of their opponents. Product portfolio management (PPM) is a dynamic process by which an enterprise chooses which products to develop, sell, maintain, and remove to achieve strategic objectives, maximize profit, and balance markets for different capabilities. Most product portfolios involve new products only and exclude existing products. This study proposes a product/market portfolio model that considers both old/new products and old/new markets to maximize overall PPM profit, determine which old products should stay in existing markets, which new markets should be considered, or which markets should be abandoned, and develop new products for old markets or to introduce new products to some new markets. This study uses machine learning and deep learning algorithms to establish prediction models to screen the planned products and markets with a high success rate. Mathematical programming is then used to determine which old products should be sold in which old and new markets and which new products should be launched in which new and old markets to maximize profit. A sensitivity analysis is used to determine the effect of changes in the resource and the risk threshold on profit and product/market selection.},
  archive      = {J_AAI},
  author       = {Chan-Chih Cheng and Chiu-Chi Wei and Ta-Jen Chu and Hsien-Hong Lin},
  doi          = {10.1080/08839514.2022.2083799},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2083799},
  shortjournal = {Appl. Artif. Intell.},
  title        = {AI predicted product portfolio for profit maximization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development and evaluation of an attendance tracking system
using smartphones with GPS and NFC. <em>AAI</em>, <em>36</em>(1),
Article: 2083796. (<a
href="https://doi.org/10.1080/08839514.2022.2083796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As usual, if many students are attending the lectures, their attendance tracking may become time consuming. Furthermore, there are some possibilities that students could cheat the lecturers of their attendance in the classroom. Therefore, a reliable method to manage the attendance tracking has become a critical issue. This paper aims to propose an attendance tracking system using an Android smartphone equipped with Global Positioning System (GPS) and Near Field Communication (NFC) technologies. Lecturers and students can constantly connect with one another by using smartphones to check and show their attendance automatically if they download and install the software Application (App). Finally, the experimental results have shown that our proposed system can successfully reduce some time for tracking students’ attendance. It also allows users to use their own Android smartphones without purchasing other electronic devices.},
  archive      = {J_AAI},
  author       = {Te-Wei Chiang and Cheng-Ying Yang and Gwo-Jen Chiou and Frank Yeong-Sung Lin and Yi-Nan Lin and Victor R. L. Shen and Tony Tong-Ying Juang and Chia-Yang Lin},
  doi          = {10.1080/08839514.2022.2083796},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2083796},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Development and evaluation of an attendance tracking system using smartphones with GPS and NFC},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GAN-BElectra: Enhanced multi-class sentiment analysis with
limited labeled data. <em>AAI</em>, <em>36</em>(1), Article: 2083794.
(<a href="https://doi.org/10.1080/08839514.2022.2083794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing sentiment analysis with high accuracy using machine-learning techniques requires a large quantity of training data. However, getting access to such a large quantity of labeled data for specific domains can be expensive and time-consuming. These warrant developing more efficient techniques that can perform sentiment analysis with high accuracy with a few labeled training data. In this paper, we aim to address this problem with our proposed novel sentiment analysis technique, named GAN-BElectra. With rigorous experiments, we demonstrate that GAN-BElectra outperforms its baseline technique in terms of multiclass sentiment analysis accuracy with a few labeled data while maintaining an architecture with reduced complexity compared to its predecessor.},
  archive      = {J_AAI},
  author       = {Md. Riyadh and M. Omair Shafiq},
  doi          = {10.1080/08839514.2022.2083794},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2083794},
  shortjournal = {Appl. Artif. Intell.},
  title        = {GAN-BElectra: Enhanced multi-class sentiment analysis with limited labeled data},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GACSNet: A lightweight network for the noninvasive blood
glucose detection. <em>AAI</em>, <em>36</em>(1), Article: 2081898. (<a
href="https://doi.org/10.1080/08839514.2022.2081898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is a disease that requires long-term monitoring, and noninvasive glucose detection effectively reduces patient self-monitor resistance. Traditional noninvasive blood glucose methods are limited by many aspects, such as equipment, environment, and safety, which are not suitable for practical use. Aiming at this problem, propose a lightweight network called Group Asymmetric Convolution Shuffle Network (GACSNet) for noninvasive blood glucose detection: use infrared imaging to acquire human metabolic heat and construct a dataset, combine asymmetric convolution with channel shuffle unit, the novel convolution neural network is designed, and extract metabolic heat and cool-heat deviation features in thermal imaging. The test set was analyzed and compared using Clarke’s error grid. The current neural network showed an mean absolute percentage error of 9.17%, with a training time of 2 min 54 s and a inference time of 1.35 ms, which was superior to several traditional convolution neural networks’ accuracy, training cost, and real-time performance in the blood glucose region 3.9–9 mmol/L, and provided new insights into noninvasive blood glucose detection.},
  archive      = {J_AAI},
  author       = {Rui Yang and Yingnian Wu and Xiaolong Liu and Wenbai Chen},
  doi          = {10.1080/08839514.2022.2081898},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2081898},
  shortjournal = {Appl. Artif. Intell.},
  title        = {GACSNet: A lightweight network for the noninvasive blood glucose detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Can artificial intelligence boost employment in service
industries? Empirical analysis based on china. <em>AAI</em>,
<em>36</em>(1), Article: 2080336. (<a
href="https://doi.org/10.1080/08839514.2022.2080336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the provincial panel data of China during 2007–2020, this study examines the temporal and spatial dynamic characteristics of artificial intelligence (AI) development and service industry employment, using the fixed-effect model to analyze the influence mechanism of AI development on service industry employment. We analyzed the regional heterogeneity. The results revealed the following: (i) AI experts a direct and indirect impact on the service industry employment. The direct impact is manifested in the creation effect and substitution effect, while the indirect impact is manifested in the competition effect. These effects exert a positive and significant indigenous impact on the service industry employment: increasing the number of jobs, optimizing the employment structure, and increasing employment income; (ii) Subregional studies demonstrated that the impact of AI development on employment in services has regional heterogeneity, which is conducive to narrowing regional differences in services; (iii) Cross-industry studies reported that AI development has augmented cross-industry inflows of labor and increased job competition for medium-skilled labor. This study is utmost significance to improve the employment policy of China’s service industry, optimize the training system of service talents, promote the upgrading of the service industry, and promote the synchronized development of the regional service industry.},
  archive      = {J_AAI},
  author       = {Ting-Ting Gu and San-Feng Zhang and Rongrong Cai},
  doi          = {10.1080/08839514.2022.2080336},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2080336},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Can artificial intelligence boost employment in service industries? empirical analysis based on china},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study of non-deep learning, deep learning, and
ensemble learning methods for sunspot number prediction. <em>AAI</em>,
<em>36</em>(1), Article: 2074129. (<a
href="https://doi.org/10.1080/08839514.2022.2074129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar activity has significant impacts on human activities and health. One most commonly used measure of solar activity is the sunspot number. This paper compares three important non-deep learning models, four popular deep learning models, and their five ensemble models in forecasting sunspot numbers. In particular, we propose an ensemble model called XGBoost-DL, which uses XGBoost as a two-level nonlinear ensemble method to combine the deep learning models. Our XGBoost-DL achieves the best forecasting performance (RMSE = 25.70 and MAE = 19.82 ) in the comparison, outperforming the best non-deep learning model SARIMA (RMSE = 54.11 and MAE = 45.51 ), the best deep learning model Informer (RMSE = 29.90 and MAE = 22.35 ) and the NASA’s forecast (RMSE = 48.38 and MAE = 38.45 ). Our XGBoost-DL forecasts a peak sunspot number of 133.47 in May 2025 for Solar Cycle 25 and 164.62 in November 2035 for Solar Cycle 26, similar to but later than the NASA’s at 137.7 in October 2024 and 161.2 in December 2034. An open-source Python package of our XGBoost-DL for the sunspot number prediction is available at https://github.com/yd1008/ts_ensemble_sunspot .},
  archive      = {J_AAI},
  author       = {Yuchen Dang and Ziqi Chen and Heng Li and Hai Shu},
  doi          = {10.1080/08839514.2022.2074129},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2074129},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A comparative study of non-deep learning, deep learning, and ensemble learning methods for sunspot number prediction},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent human age and gender forecasting framework
using deep learning algorithms. <em>AAI</em>, <em>36</em>(1), Article:
2073724. (<a
href="https://doi.org/10.1080/08839514.2022.2073724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental images are utilized to gather significant signs that are useful in disease diagnosis, treatment, and forensic examination. Many dental age and gender detection procedures have limitations, such as minimal accuracy and dependability. Gender identification techniques aren’t well studied, despite the fact that classification effectiveness and accuracy are low. The suggested approach takes into account the shortcomings of the current system. Deep learning techniques can successfully resolve issues that occurred in other classifiers. Human gender and age identification is a crucial process in the fields of forensics, anthropology, and bio archeology. The image preparation and feature extraction process are accomplished by deep learning algorithms. The performance of classification is improved by minimizing the occurrence of loss with the assistance of a spike neuron-based convolutional neural network (SN-CNN). The performance of SN-CNN is examined by comparing the performance metrics with the existing state-of-art techniques. SN-CNN-based classifier achieved 99.6% accuracy over existing techniques.},
  archive      = {J_AAI},
  author       = {Hemalatha Balan and Adel Fahad Alrasheedi and S. S. Askar and Mohamed Abouhawwash},
  doi          = {10.1080/08839514.2022.2073724},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2073724},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An intelligent human age and gender forecasting framework using deep learning algorithms},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). An unsupervised detection method for multiple abnormal
wi-fi access points in large-scale wireless network. <em>AAI</em>,
<em>36</em>(1), Article: 2073722. (<a
href="https://doi.org/10.1080/08839514.2022.2073722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The probability of a single access point (AP) failure is very small. In addition, APs communicate with each other; therefore, it is considered that these failures have little impact on the wireless network. Only when a large number of APs are abnormal offline, do we consider that the wireless network is faulty and needs to be recovered immediately. Network breakdown, network congestion, and AP management software shutdown may cause numerous APs in aborted status. In this article, we utilize DBSCAN algorithm to detect abnormal Wi-Fi APs. Compared with other research works, our proposed unsupervised method can distinguish between normal and abnormal offline APs. This study proposes a new date dimension to calculate the number of online APs together with the time dimension, and it provides new insights to set up thresholds of online APs automatically. Experimental results show that this 3-D model based on date and time is more accurate than the traditional 2-D model only based on time. With regard to the sampling method of random forest, this paper carries out repetitive random sampling to form small sample sets and finally to obtain the mean feature plane, which can reduce the interference of abnormal points to our algorithm.},
  archive      = {J_AAI},
  author       = {Song Chen and Hai Liao},
  doi          = {10.1080/08839514.2022.2073722},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2073722},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An unsupervised detection method for multiple abnormal wi-fi access points in large-scale wireless network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing berth-quay crane allocation considering economic
factors using chaotic quantum SSA. <em>AAI</em>, <em>36</em>(1),
Article: 2073719. (<a
href="https://doi.org/10.1080/08839514.2022.2073719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the regular development of the global epidemic, the global port shipping supply is tight. The problem of port congestion, soaring freight rates, and hard-to-find container space has emerged. This paper proposes a new joint berth-quay crane allocation model, namely E-B&amp;QC, by taking the minimum of the time in the port of the ship, the cost of extra transportation distance for collector trucks in the land area of the port, and the cost of extra waiting time for ships. Then, the deficiencies of the sparrow search algorithm (SSA) are considered in solving the E-B&amp;QC model, and the SSA is improved based on the three-dimensional Cat chaos mapping and quantum computing theory. Chaotic Quantum Sparrow Search Algorithm (CQSSA) is proposed, population individual coding rules are formulated, also E-B&amp;QC model solving algorithm is established. Finally, a new berth-crane allocation optimization method, namely, E-B&amp;QC-CQSSA, is proposed. Subsequently, the feasibility and superiority of the proposed allocation model and solution algorithm are tested according to the actual data of a small river port in the south and a medium-sized river port in the north. Simulation examples show that the E-B&amp;QC model can develop different high-quality solutions for container ports under different working conditions, and the more complex the actual situation of the port, the more significant the optimization effect. The proposed CQSSA for E-B&amp;QC model can obtain a better solution.},
  archive      = {J_AAI},
  author       = {Xia Cao and Zhong-Yi Yang and Wei-Chiang Hong and Rui-Zhe Xu and Yu-Tian Wang},
  doi          = {10.1080/08839514.2022.2073719},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2073719},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimizing berth-quay crane allocation considering economic factors using chaotic quantum SSA},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic type detection of 311 service requests based on
customer provided descriptions. <em>AAI</em>, <em>36</em>(1), Article:
2073717. (<a
href="https://doi.org/10.1080/08839514.2022.2073717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 311 phone number is for reporting non-emergency service requests (SRs) to authorities. This service is available through web, e-mail, and text message as well. Through this service, citizens would describe the issue and its location and the authorities would determine its category and the responsible unit and track the problem until it is resolved. The number of 311 SRs would amount to hundreds of thousands every year in some cities and determining the category of SRs manually is time-consuming, burdensome, and prone to human error. Additionally, these categories are not standardized across the states. In this paper, we standardize these categories across two cities and study the recurrent neural network’s ability in automatically determining the category of SRs based on the transcript of customer-provided descriptions. According to our results, the automatic categorization of these descriptions is not only faster and less cumbersome, but also more accurate than manual categorization. A close look at the mistakes made by the machine in labeling SRs revealed that in many cases either the SR’s description was insufficient to infer its category or the category identified by the machine was correct but the ground truth label assigned to that SR was incorrect.},
  archive      = {J_AAI},
  author       = {Mahdi Hashemi},
  doi          = {10.1080/08839514.2022.2073717},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2073717},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automatic type detection of 311 service requests based on customer provided descriptions},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Enhanced model for predicting student dropouts in
developing countries using automated machine learning approach: A case
of tanzanian’s secondary schools. <em>AAI</em>, <em>36</em>(1), Article:
2071406. (<a
href="https://doi.org/10.1080/08839514.2022.2071406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Sub-Saharan countries are leading in dropout rates in secondary schools by 37.5% followed by South Asia 15.5% and Middle East 11% in 2018. In Tanzania, student dropouts in secondary schools increased from 3.8% in 2018 to 4.2% in 2019. Different initiatives such as parent-workshops, parent-teacher meetings, community empowerment programs, school feed programs, and secondary education development program (SEDP) have been used to address student dropout but unfortunately, the dropout problem still persists. The persisting dropout problem especially in secondary schools is attributed to a lack of proper identification of root causes and unavailability of formal methods that can be used to project the severity of the problem. In addressing this problem, machine learning (ML) techniques have done a great job in predicting secondary school dropouts. However, most of the ML models suffer from processing features, and hyper-parameters tuning leads to poor prediction accuracy in identifying the root causes of the student dropout. In this study, the AutoML model has been used to improve prediction accuracy by selecting the corresponding hyper-parameters, features, and ML algorithm for the acquired dataset. The proposed model achieved a better prediction accuracy of DT = 99.8%, KNN = 99.6%, MLP = 99% and NB = 97%. The improved prediction score indicates an accurate selection of features that cause student dropout that can be looked in a close eye in the learning process for early intervention.},
  archive      = {J_AAI},
  author       = {Yuda N. Mnyawami and Hellen H. Maziku and Joseph C. Mushi},
  doi          = {10.1080/08839514.2022.2071406},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2071406},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhanced model for predicting student dropouts in developing countries using automated machine learning approach: A case of tanzanian’s secondary schools},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smart cities-based improving atmospheric particulate matters
prediction using chi-square feature selection methods by employing
machine learning techniques. <em>AAI</em>, <em>36</em>(1), Article:
2067647. (<a
href="https://doi.org/10.1080/08839514.2022.2067647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particulate matter is emitted from diverse sources and affect the human health very badly. Dust particles exposure from the stated environment can affect our heart and lungs very badly. The particle pollution exposure creates a variety of problems including nonfatal heart attacks, premature deaths in people with lung or heart disease, asthma, difficulty in breathing, etc. In this article, we developed an automated tool by computing multimodal features to capture the diverse dynamics of ambient particulate matter and then applied the Chi-square feature selection method to acquire the most relevant features. We also optimized parameters of robust machine learning algorithms to further improve the prediction performance such as Decision Tree, SVM with Linear and Regression, Naïve Bayes (NB), Random Forest (RF), Ensemble Classifier, K-Nearest Neighbor, and XGBoost for classification. The classification results with and without feature selection methods yielded the highest detection performance with random forest, and GBM yielded 100% of accuracy and AUC. The results revealed that the proposed methodology is more robust to provide an efficient system that will detect the particulate matters automatically and will help the individuals to improve their lifestyle and comfort. The concerned department can monitor the individual’s healthcare services and reduce the mortality risk},
  archive      = {J_AAI},
  author       = {Hanan Abdullah Mengash and Lal Hussain and Hany Mahgoub and A. Al-Qarafi and Mohamed K Nour and Radwa Marzouk and Shahzad Ahmad Qureshi and Anwer Mustafa Hilal},
  doi          = {10.1080/08839514.2022.2067647},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2067647},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Smart cities-based improving atmospheric particulate matters prediction using chi-square feature selection methods by employing machine learning techniques},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BreastCNN: A novel layer-based convolutional neural network
for breast cancer diagnosis in DMR-thermogram images. <em>AAI</em>,
<em>36</em>(1), Article: 2067631. (<a
href="https://doi.org/10.1080/08839514.2022.2067631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most prominent sources of death in females. Every year many women suffer breast cancer, and, in the end, death occurs. The early detection of breast cancer may cause to reduce the death rate and save women’s lives. The medical care and cost of prevention of women’s breast cancer are costly and become a priority to diagnose breast cancer at its early stages. Initially, the mammography technique was the leading technique to detect the early stage of breast cancer. However, it cannot deal with a tumor size of less than 2 mm. To overcome this challenge, by considering the DMR-thermogram images, a novel layer-based Convolutional Neural Network (BreastCNN) for breast cancer detection and classification was proposed. BreastCNN method works in five different layers and uses different types of filters. The learning rate and structures of layers change after every convolution layer. The proposed technique is tested on the Database for Mastology Research (DMR) having 745 healthy and 261 sick images. The performance is calculated as the statistical values known as sensitivity, specificity, precision, accuracy, and F1-score. The proposed technique shows better accuracy of 99.7% as related to the already presented methods.},
  archive      = {J_AAI},
  author       = {Samar M. Alqhtani},
  doi          = {10.1080/08839514.2022.2067631},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2067631},
  shortjournal = {Appl. Artif. Intell.},
  title        = {BreastCNN: A novel layer-based convolutional neural network for breast cancer diagnosis in DMR-thermogram images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying labor market competitors with machine learning
based on maimai platform. <em>AAI</em>, <em>36</em>(1), Article:
2064047. (<a
href="https://doi.org/10.1080/08839514.2022.2064047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for skilled labor has increased dramatically in the current knowledge-based economy, which is characterized by the growing intensity in labor market competition between firms. Therefore, it would be of special interest to identify future labor market competitors. At present, with the vast amount of textual data, the existing study focuses on constructing the human capital overlap and product overlap metrics with the text data as predictors to predict the labor market competition in the United States. Based on these metrics, this paper experiments with machine learning methods to predict Chinese labor market competition with Chinese text data. Furthermore, sentiment analysis is becoming popular and it has been used in a wide variety of fields. However, due to lack of data, there are few existing studies using sentiment analysis approach of firms’ online reviews. In response to this research gap, this paper constructs the sentiment analysis metric by mining the emotional content expressed in the firms’ online reviews on Maimai’s platform. The results show that our proposed metrics have superior predictive power over conventional measures and highlight the predictive utility of proposed sentiment analysis metric. Moreover, the nuanced two-dimensional competition analysis gives some interesting results.},
  archive      = {J_AAI},
  author       = {Yu Zheng and Yonghong Long and Honggang Fan},
  doi          = {10.1080/08839514.2022.2064047},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2064047},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Identifying labor market competitors with machine learning based on maimai platform},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A context-aware artificial intelligence-based system to
support street crossings for pedestrians with visual impairments.
<em>AAI</em>, <em>36</em>(1), Article: 2062818. (<a
href="https://doi.org/10.1080/08839514.2022.2062818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence has the potential to support and improve the quality of life of people with disabilities. Mobility is a potentially dangerous activity for people with impaired ability. This article presents an assistive technology solution to assist visually impaired pedestrians in safely crossing the street. We use a signal trilateration technique and deep learning (DL) for image processing to segment visually impaired pedestrians from the rest of pedestrians. The system receives information about the presence of a potential user through WiFi signals from a mobile application installed on the user’s phone. The software runs on an intelligent semaphore originally designed and installed to improve urban mobility in a smart city context. This solution can communicate with users, interpret the traffic situation, and make the necessary adjustments (with the semaphore’s capabilities) to ensure a safe street crossing. The proposed system has been implemented in Maringá, Brazil, for a one-year period. Trial tests carried out with visually impaired pedestrians confirm its feasibility and practicality in a real-life environment.},
  archive      = {J_AAI},
  author       = {Aleksandro Montanha and Andreea M. Oprescu and MCarmen Romero-Ternero},
  doi          = {10.1080/08839514.2022.2062818},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2062818},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A context-aware artificial intelligence-based system to support street crossings for pedestrians with visual impairments},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of stochastic frontier to agriculture in
ethiopia. <em>AAI</em>, <em>36</em>(1), Article: 2062817. (<a
href="https://doi.org/10.1080/08839514.2022.2062817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Farming is more than just a job of Ethiopia’s smallholder farmers, who live in a low productivity environment. This study employed stochastic frontier approach agricultural efficiency in Ethiopia. Furthermore, Tobit model results show that loss due to wild animals had a negative impact on technical efficiency, while slope of the land and off-farm income had a positive impact. Regarding to the determinants of allocative efficiency, uses of mobile have positive impacts and the off-/non-farm income have negative impacts. In terms of economic efficiency determinants, land slope has a positive influence, while loss due to wild animals and off-farm income have a negative influence. According to the study findings, farmers in the study area kill wild animals, such as monkeys, pigs, and apes, because the loss of wild animals has a high impact on agricultural production during the pre-harvest season. Thus to increase efficiency of farmers and boosting agricultural output, Ethiopian governments policies and strategies should be directed toward providing tourism, construction of soil bunds, tree planting, planting grass, fencing and use of natural fertilizer to maintain the fertility of steep slopes, and supporting farmers by providing network facilities for mobile users that boost farmers’ maize productive efficiency.},
  archive      = {J_AAI},
  author       = {Tolesa Tesema},
  doi          = {10.1080/08839514.2022.2062817},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2062817},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Application of stochastic frontier to agriculture in ethiopia},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Convolutional neural networks hyperparameter tunning for
classifying firearms on images. <em>AAI</em>, <em>36</em>(1), Article:
2058165. (<a
href="https://doi.org/10.1080/08839514.2022.2058165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rates of firearm-related violent acts worldwide have risen significantly. It is a severe social problem that compromises the safety of every individual to some extent. This situation has motivated researchers to find new ways to improve the current state-of-the-art solutions, such as automatic surveillance systems, to detect and classify the presence of firearms within a specific scene. These systems reduce the drawbacks of using direct human supervision. Among the available solutions for the classification task, the performance of Deep Learning models stands out, especially those based on Convolutional Neural Networks. Since they start learning directly from raw data ( e.g ., images), their learning process can be improved even further by using Transfer Learning techniques. However, the classification accuracy depends significantly on choosing the optimum set of values for the different hyperparameters composing them. Thus, this paper analyses the improvement in the performance of an image-based handgun classification algorithm when tuning its hypermeters values instead of using its default values. In this work, we evaluated the performance variation using two benchmarks Convolutional Neural Networks architectures: AlexNet and Inception V3. We obtained a maximum accuracy of 94.11% when using the Inception V3 network and transfer learning. We employed Nadam as the optimizer and a learning rate equal to 0.0001, a batch size equal 256, and a total of 13 epochs. Experimental results suggest an essential relationship between the performance of the classification model and the data set, the specific combinations of values for the selected optimizer, the batch size, and the learning rate. The obtained improvement in the accuracy was up to 10.33% after the tuning process.},
  archive      = {J_AAI},
  author       = {Isaac Cardoza and Juan P. García-Vázquez and Arnoldo Díaz-Ramírez and Verónica Quintero-Rosas},
  doi          = {10.1080/08839514.2022.2058165},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2058165},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Convolutional neural networks hyperparameter tunning for classifying firearms on images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pattern-of-life activity recognition in seismic data.
<em>AAI</em>, <em>36</em>(1), Article: 2057400. (<a
href="https://doi.org/10.1080/08839514.2022.2057400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern-of-life analysis models the observable activities associated with a particular entity or location over time. Automatically finding and separating these activities from noise and other background activity presents a technical challenge for a variety of data types and sources. This paper investigates a framework for finding and separating a variety of vehicle activities recorded using seismic sensors situated around a construction site. Our approach breaks the seismic waveform into segments, preprocesses them, and extracts features from each. We then apply feature scaling and dimensionality reduction algorithms before clustering and visualizing the data. Results suggest that the approach effectively separates the use of certain vehicle types and reveals interesting distributions in the data. Our reliance on unsupervised machine learning algorithms suggests that the approach can generalize to other data sources and monitoring contexts. We conclude by discussing limitations and future work.},
  archive      = {J_AAI},
  author       = {Erick Draayer and David Stracuzzi and Craig Ulmer and Nicole McMahon},
  doi          = {10.1080/08839514.2022.2057400},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2057400},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Pattern-of-life activity recognition in seismic data},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using a layered ensemble of physics-guided graph attention
networks to predict COVID-19 trends. <em>AAI</em>, <em>36</em>(1),
Article: 2055989. (<a
href="https://doi.org/10.1080/08839514.2022.2055989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has spread rapidly and significantly impacted most countries in the world. Providing an accurate forecast of COVID-19 at multiple scales would help inform public health decisions, but recent forecasting models are typically used at the state or country level. Furthermore, traditional mathematical models are limited by simplifying assumptions, while machine learning algorithms struggle to generalize to unseen trends. This motivates the need for hybrid machine learning models that integrate domain knowledge for accurate long-term prediction. We propose a three-layer, geographically informed ensemble, an extensive peer-learning framework, for predicting COVID-19 trends at the country, continent, and global levels. As the base layer, we develop a country-level predictor using a hybrid Graph Attention Network that incorporates a modified SIR model, adaptive loss function, and edge weights informed by mobility data. We aggregated 163 country GATs to train the continent and world MLP layers of the ensemble. Our results indicate that incorporating quantitatively accurate equations and real-world data to model inter-community interactions improves the performance of spatio-temporal machine learning algorithms. Additionally, we demonstrate that integrating geographic information (continent composition) improves the performance of the world predictor in our layered architecture.},
  archive      = {J_AAI},
  author       = {Connie Sun and Vijayalakshmi K. Kumarasamy and Yu Liang and Dalei Wu and Yingfeng Wang},
  doi          = {10.1080/08839514.2022.2055989},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055989},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Using a layered ensemble of physics-guided graph attention networks to predict COVID-19 trends},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cybersecurity deep: Approaches, attacks dataset, and
comparative study. <em>AAI</em>, <em>36</em>(1), Article: 2055399. (<a
href="https://doi.org/10.1080/08839514.2022.2055399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber attacks are increasing rapidly due to advanced digital technologies used by hackers. In addition, cybercriminals are conducting cyber attacks, making cyber security a rapidly growing field. Although machine learning techniques worked well in solving large-scale cybersecurity problems, an emerging concept of deep learning (DL) that caught on during this period caused information security specialists to improvise the result. The deep learning techniques analyzed in this study are convolution neural networks, recurrent neural networks, and deep neural networks in the context of cybersecurity.A framework is proposed, and a real-time laboratory setup is performed to capture network packets and examine this captured data using various DL techniques. A comparable interpretation is presented under the DL techniques with essential parameters, particularly accuracy, false alarm rate, precision, and detection rate. The DL techniques experimental output projects improvise the performance of various real-time cybersecurity applications on a real-time dataset. CNN model provides the highest accuracy of 98.64% with a precision of 98% with binary class. The RNN model offers the second-highest accuracy of 97.75%. CNN model provides the highest accuracy of 98.42 with multiclass class. The study shows that DL techniques can be effectively used in cybersecurity applications. Future research areas are being elaborated, including the potential research topics to improve several DL methodologies for cybersecurity applications.},
  archive      = {J_AAI},
  author       = {Kousik Barik and Sanjay Misra and Karabi Konar and Luis Fernandez-Sanz and Murat Koyuncu},
  doi          = {10.1080/08839514.2022.2055399},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055399},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Cybersecurity deep: Approaches, attacks dataset, and comparative study},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Initial stage COVID-19 detection system based on patients’
symptoms and chest x-ray images. <em>AAI</em>, <em>36</em>(1), Article:
2055398. (<a
href="https://doi.org/10.1080/08839514.2022.2055398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate diagnosis of the initial stage COVID-19 is necessary for minimizing its spreading rate. The physicians most often recommend RT-PCR tests; this is invasive, time-consuming, and ineffective in reducing the spread rate of COVID-19. However, this can be minimized by using noninvasive and fast machine learning methods trained either on labeled patients’ symptoms or medical images. The machine learning methods trained on labeled patients’ symptoms cannot differentiate between different types of pneumonias like COVID-19, viral pneumonia, and bacterial pneumonia because of similar symptoms, i.e., cough, fever, headache, sore throat, and shortness of breath. The machine learning methods trained on labeled patients’ medical images have the potential to overcome the limitation of the symptom-based method; however, these methods are incapable of detecting COVID-19 in the initial stage because the infection of COVID-19 takes 3 to 12 days to appear. This research proposes a COVID-19 detection system with the potential to detect COVID-19 in the initial stage by employing deep learning models over patients’ symptoms and chest X-Ray images. The proposed system obtained average accuracy 78.88%, specificity 94%, and sensitivity 77% on a testing dataset containing 800 patients’ X-Ray images and 800 patients’ symptoms, better than existing COVID-19 detection methods.},
  archive      = {J_AAI},
  author       = {Muhammad Attaullah and Mushtaq Ali and Maram Fahhad Almufareh and Muneer Ahmad and Lal Hussain and Nz Jhanjhi and Mamoona Humayun},
  doi          = {10.1080/08839514.2022.2055398},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055398},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Initial stage COVID-19 detection system based on patients’ symptoms and chest X-ray images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research on multi-side joint industrial parts inspection
based on model fusion. <em>AAI</em>, <em>36</em>(1), Article: 2055396.
(<a href="https://doi.org/10.1080/08839514.2022.2055396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid identification of many industrial material parts is the key to effectively improving the efficiency of the industrial production process and intelligent warehousing. Accurate identification of both similar and special parts is an important problem. In this paper, a multi-side joint industrial part recognition method based on model fusion learning is proposed. A multi-channel visual acquisition system is designed to construct a fast industrial part data set with time and space consistency. Two joint identification methods for multi-side acquisition are proposed, and the classification results are fused to improve the model’s accuracy and solve the classification problem for similar parts. The experimental results show that compared with the traditional model, the prediction accuracy of the multi-channel multi-input model proposed in this paper is improved by approximately 6%, and the accuracy of the single-channel multi-input model is improved by approximately 10%. The accuracy of part recognition is far better than that of the traditional model, and it therefore provides a new strategy for the rapid training and recognition of industri-al parts in intelligent storage.},
  archive      = {J_AAI},
  author       = {Lei Jiao and Xuesong Lin and Kang An and Yaqing Song and Yingyuan Liu and Hui Liu and Hai Nan},
  doi          = {10.1080/08839514.2022.2055396},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055396},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Research on multi-side joint industrial parts inspection based on model fusion},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer vision approach for liver tumor classification
using CT dataset. <em>AAI</em>, <em>36</em>(1), Article: 2055395. (<a
href="https://doi.org/10.1080/08839514.2022.2055395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The liver tumor is one of the most foremost critical causes of death in the world. Nowadays, Medical Imaging (MI) is one of the prominent Computer Vision fields (CV), which helps physicians and radiologists to detect and diagnose liver tumors at an early stage. Radiologists and physicians use manual or semi-automated systems to read hundreds of images, such as Computed Tomography (CT) for the diagnosis. Therefore, there is a need for a fully-automated method to diagnose and detect the tumor early using the most popular and widely used imaging modality, CT images. The proposed work focuses on the Machine Learning (ML) methods: Random Forest (RF), J48, Logistic Model Tree (LMT), and Random Tree (RT) with multiple automated Region of Interest (ROI) for multiclass liver tumor classification. The dataset comprises four tumor classes: hemangioma, cyst, hepatocellular carcinoma, and metastasis. Converted the images into gray-scale, and the contrast of images was improved by applying histogram equalization. The noise was reduced using the Gabor filter, and image quality was improved by applying an image sharpening algorithm. Furthermore, 55 features were acquired for each ROI of different pixel dimensions using texture, binary, histogram and rotational, scalability, and translational (RST) techniques. The correlation-based feature selection (CFS) technique was deployed to obtain 20 optimized features from these 55 features for classification. The results showed that RF and RT performed better than J48 and LMT, with an accuracy of 97.48% and 97.08%, respectively. The proposed novel framework will help radiologists and physicians better diagnose liver tumors.},
  archive      = {J_AAI},
  author       = {Mubasher Hussain and Najia Saher and Salman Qadri},
  doi          = {10.1080/08839514.2022.2055395},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055395},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Computer vision approach for liver tumor classification using CT dataset},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic resource allocation using improved firefly
optimization algorithm in cloud environment. <em>AAI</em>,
<em>36</em>(1), Article: 2055394. (<a
href="https://doi.org/10.1080/08839514.2022.2055394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, cloud computing has provided a suitable platform to meet the computing needs of users. One of the most important challenges facing cloud computing is Dynamic Resource Allocation (DSA), which is in the NP-Hard class. One of the goals of the DSA is to utilization resources efficiently and maximize productivity. In this paper, an improved Firefly algorithm based on load balancing optimization is introduced to solve the DSA problem called IFA-DSA. In addition to balancing workloads between existing virtual machines, IFA-DSA also reduces completion time by selecting appropriate objectives in the fitness function. The best sequence of tasks for resource allocation is formulated as a multi-objective problem. The intended objectives are load balancing, completion time, average runtime, and migration rate. In order to improve the initial population creation in the firefly algorithm, a heuristic method is used instead of a random approach. In the heuristic method, the initial population is created based on the priority of tasks, where the priority of each task is determined based on the pay as you use model and a fuzzy approach. The results of the experiments show the superiority of the proposed method in the makespan criterion over the ICFA method by an average of 3%.},
  archive      = {J_AAI},
  author       = {Simin Abedi and Mostafa Ghobaei-Arani and Ehsan Khorami and Musa Mojarad},
  doi          = {10.1080/08839514.2022.2055394},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055394},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Dynamic resource allocation using improved firefly optimization algorithm in cloud environment},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable analytics to predict the quality of life in
patients with prostate cancer from longitudinal data. <em>AAI</em>,
<em>36</em>(1), Article: 2055393. (<a
href="https://doi.org/10.1080/08839514.2022.2055393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate cancer (PCa) is a complicated cancer with high level of unexplained variability that might affect the patient’s health-related quality of life (HRQoL). Using 2670 patients’ information with 433 measures per patient, our objective is to identify the minimal set of important variables which can predict 1-year follow-up HRQoL for PCa patients while adding interpretability to the proposed model. We address three problems of dimension reduction, prediction, and interpretability by first developing deep neural networks on top of a clustering algorithm to extract minimal set of important variables of baseline visit. Second, we build a model to predict a 1-year follow-up of HRQoL for PCa patients using the extracted important baseline variables. Third, we utilize Bayesian networks method to provide insights into the proposed model results to discover the relationship between patients’ baseline variables and their 1-year follow-up satisfaction. The results support the use of the proposed machine-learning technique as an essential tool in identifying potential baseline variables for predicting 1-year HRQoL. Furthermore, our approach to interpret the findings will help to establish guidelines for a better shared decision-making platform for PCa patients.},
  archive      = {J_AAI},
  author       = {Fatemeh Sharifi and Emad Mohammed and Trafford Crump and Behrouz H. Far},
  doi          = {10.1080/08839514.2022.2055393},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055393},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Explainable analytics to predict the quality of life in patients with prostate cancer from longitudinal data},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Above-ground biomass wheat estimation: Deep learning with
UAV-based RGB images. <em>AAI</em>, <em>36</em>(1), Article: 2055392.
(<a href="https://doi.org/10.1080/08839514.2022.2055392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of biomass is essential in agriculture to delineate crop management practices, and this is usually done manually, which is time-consuming and destructive. This work proposes an artificial neural network and convolutional neural network to estimate the above-ground biomass (AGB) of wheat using visible spectrum images captured by an unmanned aerial vehicle. The utilized dataset has two Brazilian wheat types, called Parrudo and Toruk. Furthermore, the experimental area has variability in crop growth by varying the amount of nitrogen. To determine AGB, samples of plants were collected at three different crop growth stages, approximately a month apart, making our database spatial and temporal variability. We have shown the feasibility of developing a regression model using RGB images for biomass estimation for two wheat types. The best results for ANN were 489.5, 826.4, and 0.9056 for MAE, RMSE, and R 2 , respectively. In CNN, MAE = 699.2, RMSE = 940.5, and R 2 = 0.9065. These results show high accuracy in estimation of biomass, and the R 2 shows good estimation and generalization capacity. The results demonstrate that our methodology can be used in precision agriculture to predict the spatial and temporal variability of AGB.},
  archive      = {J_AAI},
  author       = {Lincoln Vinicius Schreiber and João Gustavo Atkinson Amorim and Leticia Guimarães and Debora Motta Matos and Celso Maciel da Costa and Adriane Parraga},
  doi          = {10.1080/08839514.2022.2055392},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2055392},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Above-ground biomass wheat estimation: Deep learning with UAV-based RGB images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fully bayesian inference with gibbs sampling for finite
and infinite discrete exponential mixture models. <em>AAI</em>,
<em>36</em>(1), Article: 2043526. (<a
href="https://doi.org/10.1080/08839514.2022.2043526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose clustering algorithms based on finite mixture and infinite mixture models of exponential approximation to the Multinomial Generalized Dirichlet (EMGD), Multinomial Beta-Liouville (EMBL) and Multinomial Shifted-Scaled Dirichlet (EMSSD) with Bayesian inference. The finite mixtures have already shown superior performance in real data sets clustering using the Expectation–Maximization approach. The proposed approaches in this paper are based on a Monte Carlo simulation technique namely Gibbs sampling algorithm including an additional Metropolis–Hastings step, and we utilize exponential family conjugate prior information to construct their posterior relying on Bayesian theory. Furthermore, we also present the infinite models based on Dirichlet processes, which results in clustering algorithms that do not require the specification of the number of mixture components to be given in advance and selects it in a principled manner. The performance of our Bayesian approaches was evaluated in some challenging real-world applications concerning text sentiment analysis, fake news detection, and human face gender recognition.},
  archive      = {J_AAI},
  author       = {Xuanbo Su and Nuha Zamzami and Nizar Bouguila},
  doi          = {10.1080/08839514.2022.2043526},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2043526},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A fully bayesian inference with gibbs sampling for finite and infinite discrete exponential mixture models},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using skeleton correction to improve flash lidar-based gait
recognition. <em>AAI</em>, <em>36</em>(1), Article: 2043525. (<a
href="https://doi.org/10.1080/08839514.2022.2043525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents GlidarPoly, an efficacious pipeline of 3D gait recognition for flash lidar data based on pose estimation and robust correction of erroneous and missing joint measurements. A flash lidar can provide new opportunities for gait recognition through a fast acquisition of depth and intensity data over an extended range of distance. However, the flash lidar data are plagued by artifacts, outliers, noise, and sometimes missing measurements, which negatively affects the performance of existing analytics solutions. We present a filtering mechanism that corrects noisy and missing skeleton joint measurements to improve gait recognition. Furthermore, robust statistics are integrated with conventional feature moments to encode the dynamics of the motion. As a comparison, length-based and vector-based features extracted from the noisy skeletons are investigated for outlier removal. Experimental results illustrate the superiority of the proposed methodology in improving gait recognition given noisy, low-resolution flash lidar data.},
  archive      = {J_AAI},
  author       = {Nasrin Sadeghzadehyazdi and Tamal Batabyal and Alexander Glandon and Nibir Dhar and Babajide Familoni and Khan Iftekharuddin and Scott T. Acton},
  doi          = {10.1080/08839514.2022.2043525},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2043525},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Using skeleton correction to improve flash lidar-based gait recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting plasma vitamin c using machine learning.
<em>AAI</em>, <em>36</em>(1), Article: 2042924. (<a
href="https://doi.org/10.1080/08839514.2022.2042924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision Nutrition makes use of personal information about individuals to produce nutritional recommendations that have more utility than general population level recommendations. In many cases, being able to predict current status is a necessary first step in offering tailored nutritional advice. The objective of this study is to predict plasma vitamin C using machine learning. The NHANES dataset was used to predict plasma vitamin C in a cohort of 2952 American adults using regression algorithms and clustering in a way that a hypothetical health application might. Variables were selected based on a known or hypothesized relationship with plasma vitamin C, and variables that are expensive or difficult to obtain were excluded in order to more closely replicate the situation of a real health application. The best performance was seen with the XGBoost regressor, with random forest performing almost identically. Clustering was also investigated as a means of improving regression accuracy by splitting the data up into smaller yet more homogeneous groups, however, this was not successful. The low R-squared scores obtained by the models are likely to be due to the low resolution of the NHANES data, particularly the dietary data. This emphasizes the need for high-quality data sets in Precision Nutrition research.},
  archive      = {J_AAI},
  author       = {Daniel Kirk and Cagatay Catal and Bedir Tekinerdogan},
  doi          = {10.1080/08839514.2022.2042924},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2042924},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Predicting plasma vitamin c using machine learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effect of label noise on multi-class semantic segmentation:
A case study on bangladesh marine region. <em>AAI</em>, <em>36</em>(1),
Article: 2039348. (<a
href="https://doi.org/10.1080/08839514.2022.2039348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The volume and availability of satellite image data has greatly increased over the past few years. But, during the transmission and acquisition of these digital images, noise becomes a prevailing term. When preprocessing the data for computer vision tasks, human experts often produce noise in the labels which can downturn the performance of learning algorithms drastically. This study is directed toward finding the effect of label noise in the performance of a semantic segmentation model, namely U-net. We collected satellite images of the Bangladesh marine region for four different time frames, created patches and segmented the sediment load into five different classes. The U-Net model trained with Dec-2019 dataset yielded the best performance and we tested this model under three types of label noise (NCAR – noise completely at random, NAR – noise at random and NNAR – noise not at random) while varying their intensity gradually from low to high. The performance of the model decreased slightly as the percentage of NCAR noise is increased. NAR is found to be defiant until 20 ◦ of rotation, and for NNAR, the model fails to classify pixels to its correct label for maximum cases.},
  archive      = {J_AAI},
  author       = {Tahmid Hasan Pranto and Abdulla All Noman and Asaduzzaman Noor and Ummey Habiba Deepty and Rashedur M. Rahman},
  doi          = {10.1080/08839514.2022.2039348},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2039348},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Effect of label noise on multi-class semantic segmentation: A case study on bangladesh marine region},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Energy optimization for smart cities using IoT.
<em>AAI</em>, <em>36</em>(1), Article: 2037255. (<a
href="https://doi.org/10.1080/08839514.2022.2037255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When it comes to smart cities, one of the biggest issues is energy optimization. This is because these cities employ a large number of interconnected devices to autonomously manage city operations, which consumes a lot of energy. This difficulty has been addressed in this paper by using the advantages of contemporary cutting-edge technologies such as the Internet of Things (IoT), 5 G, and cloud computing for energy efficiency in smart cities. With the use of these cutting-edge technologies, we have proposed a model that can be used to optimize energy consumption in smart homes and smart cities alike. Street lighting, building and street billboards, smart homes, and smart parking are among the four essential features of smart cities that would benefit from the proposed model’s energy savings. All smart city electric appliances will be equipped with IoT sensors that will detect movements and react to commands. In order to transport data swiftly between communication channels and the cloud, 5 G technology will be deployed, and the cloud technology will be used to store and retrieve data effectively. The suggested model was evaluated using mathematical modeling, and the findings indicate that the proposed model may assist in improving energy usage in smart cities.},
  archive      = {J_AAI},
  author       = {Mamoona Humayun and Mohammed Saleh Alsaqer and Nz Jhanjhi},
  doi          = {10.1080/08839514.2022.2037255},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2037255},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Energy optimization for smart cities using IoT},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The emerging threat of ai-driven cyber attacks: A review.
<em>AAI</em>, <em>36</em>(1), Article: 2037254. (<a
href="https://doi.org/10.1080/08839514.2022.2037254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberattacks are becoming more sophisticated and ubiquitous. Cybercriminals are inevitably adopting Artificial Intelligence (AI) techniques to evade the cyberspace and cause greater damages without being noticed. Researchers in cybersecurity domain have not researched the concept behind AI-powered cyberattacks enough to understand the level of sophistication this type of attack possesses. This paper aims to investigate the emerging threat of AI-powered cyberattacks and provide insights into malicious used of AI in cyberattacks. The study was performed through a three-step process by selecting only articles based on quality, exclusion, and inclusion criteria that focus on AI-driven cyberattacks. Searches in ACM, arXiv Blackhat, Scopus, Springer, MDPI, IEEE Xplore and other sources were executed to retrieve relevant articles. Out of the 936 papers that met our search criteria, a total of 46 articles were finally selected for this study. The result shows that 56% of the AI-Driven cyberattack technique identified was demonstrated in the access and penetration phase, 12% was demonstrated in exploitation, and command and control phase, respectively; 11% was demonstrated in the reconnaissance phase; 9% was demonstrated in the delivery phase of the cybersecurity kill chain. The findings in this study shows that existing cyber defence infrastructures will become inadequate to address the increasing speed, and complex decision logic of AI-driven attacks. Hence, organizations need to invest in AI cybersecurity infrastructures to combat these emerging threats.},
  archive      = {J_AAI},
  author       = {Blessing Guembe and Ambrose Azeta and Sanjay Misra and Victor Chukwudi Osamor and Luis Fernandez-Sanz and Vera Pospelova},
  doi          = {10.1080/08839514.2022.2037254},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2037254},
  shortjournal = {Appl. Artif. Intell.},
  title        = {The emerging threat of ai-driven cyber attacks: A review},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An artificial intelligence neural network predictive model
for anomaly detection and monitoring of wind turbines using SCADA data.
<em>AAI</em>, <em>36</em>(1), Article: 2034718. (<a
href="https://doi.org/10.1080/08839514.2022.2034718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The industry 4.0 has created a paradigm shift in how industrial equipment could be monitored and diagnosed with the help of emerging technologies such as artificial intelligence (AI). AI-driven troubleshooting tools play an important role in high-efficacy diagnosis and monitoring processes, especially for systems consisting of several components including wind turbines (WTs). The utilization of such approaches not only reduces the troubleshooting and diagnosis time but also enables fault prevention by predicting the behavior of different components and calculating the probability of near future failure. This not only decreases the costs of repair by providing constant component’s monitoring and identifying faults’ causes but also increases the efficacy of the apparatus by lowering the downtimes due to the AI-driven early warning system. This article evaluated, compared, and contrasted eight different artificial neural network (ANN) models for diagnosis and monitoring of WTs that predict the machinery’s system failure based on internal components’ sensor signals and generation temperature. This article employed a machine learning model approach with two hidden layers using multilayer linear regression to achieve its objective. The developed system predicted the output of the WT’s generator temperature with an accuracy of 99.8% with 2 months in advance measurement prediction.},
  archive      = {J_AAI},
  author       = {Amin Amini and Jamil Kanfoud and Tat-Hean Gan},
  doi          = {10.1080/08839514.2022.2034718},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2034718},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An artificial intelligence neural network predictive model for anomaly detection and monitoring of wind turbines using SCADA data},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature selection for supervised learning and compression.
<em>AAI</em>, <em>36</em>(1), Article: 2034293. (<a
href="https://doi.org/10.1080/08839514.2022.2034293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised feature selection aims to find the signals that best predict a target variable. Typical approaches use measures of correlation or similarity, as seen in filter methods, or predictive power in learned models, as seen in wrapper methods. In both approaches, the selected features often have high entropies and are not suitable for compression. This is a particular drawback in the automotive domain where fast communication and archival of vehicle telemetry data is increasingly important, especially with technologies such as V2V and V2X (vehicle-to-vehicle and vehicle-to-everything communication). This paper aims to select features with good predictive performances and good compression by introducing a compressibility factor into several existing feature selection approaches. Where appropriate, performance guarantees are provided for greedy searches based on monotonicity and submodularity. Using the language of entropy, the relationship between relevance, redundancy, and compressibility is discussed from the perspective of signal selection. The approaches are then demonstrated in selecting features from a vehicle Controller Area Network for use in SVMs in a regression task, namely predicting fuel consumption, and a classification task, namely identifying Points of Interest. We show that while predictive performance is slightly lower when compression is considered, the compressibility of the selected features is significantly improved.},
  archive      = {J_AAI},
  author       = {Phillip Taylor and Nathan Griffiths and Vince Hall and Zhou Xu and Alex Mouzakitis},
  doi          = {10.1080/08839514.2022.2034293},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2034293},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Feature selection for supervised learning and compression},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Associative word relations in natural language processing.
<em>AAI</em>, <em>36</em>(1), Article: 2034262. (<a
href="https://doi.org/10.1080/08839514.2022.2034262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivation for this work comes from the longest-running Serbian television quiz show called TV Slagalica and more specifically from one of its games named associations. In the associations game, two players attempt to guess a solution given several clue words. There is a large number of publicly available game scenarios that were used to evaluate applicability of trained artificial neural networks to predict possible solutions. Material used for the network training was obtained through unconventional sources as no professional text corpus exists for Serbian language. Under outlined schemes, it is observed that solution words come up within 2% or less of the training vocabulary, depending on the method of data preparation. Data preparation and neural network training specifics are further outlined to demonstrate effects of each technique used. Even though the results obtained are below human-level performance, they can nevertheless be useful for puzzle creation.},
  archive      = {J_AAI},
  author       = {Nebojša D. Grujić and Vladimir M. Milovanović},
  doi          = {10.1080/08839514.2022.2034262},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2034262},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Associative word relations in natural language processing},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting the electricity capacity and electricity
generation values of wind &amp;solar energy with artificial neural
networks approach: The case of germany. <em>AAI</em>, <em>36</em>(1),
Article: 2033911. (<a
href="https://doi.org/10.1080/08839514.2022.2033911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, studies on energy estimation have been developing rapidly to increase the efficiency of Wind &amp; Solar energy production-consumption. Artificial Neural Networks, an algorithm based on the human brain and its nervous system inspired by the data transfer and storage mechanism, can work very well as a prediction model. In this study, total Wind &amp; Solar Electricity Capacity (WSEC) and total Wind &amp; Solar Electricity Generation (WSEG) values of Germany, a G8 member and a European country, have been estimated by using Artificial Neural Networks (ANN) method. Population, unemployment, GDP growth and total renewable energy capacity (excluding wind and solar energy total) parameters have been used as input variables in ANN calculations. The use of geographic, socio-economic and technological parameters has strengthened the estimation model. WSEC training and test regressions calculated by ANN have been 1 and 0.99988, respectively. WSEC Mean Absolute Deviation (MAD), Mean Squared Error (MSE), Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) parameters have been calculated as 94.783, 62496.807, 249.994 and 0.364, respectively. WSEG training and test regressions values have been 1 and 0.99983, respectively. The WSEG MAD, MSE, RMSE and MAPE parameters have been calculated as 114.406, 59252.128, 243.418 and 0.526, respectively.},
  archive      = {J_AAI},
  author       = {Faruk Kılıç},
  doi          = {10.1080/08839514.2022.2033911},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2033911},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Forecasting the electricity capacity and electricity generation values of wind &amp;Solar energy with artificial neural networks approach: The case of germany},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel data augmentation convolutional neural network for
detecting malaria parasite in blood smear images. <em>AAI</em>,
<em>36</em>(1), Article: 2033473. (<a
href="https://doi.org/10.1080/08839514.2022.2033473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malaria fever is a potentially fatal disease caused by the Plasmodium parasite. Identifying Plasmodium parasites in blood smear images can help diagnose malaria fever rapidly and precisely. According to the World Health Organization (WHO), there were 241 million malaria cases and 627 000 deaths worldwide in 2020, while 95% of malaria cases and 96% of malaria deaths occurred in Africa. Also in Africa, children that are less than five years old accounted for an estimated 80% of all malaria deaths. To address the menace of malaria, this paper proposes a novel deep learning model, called a data augmentation convolutional neural network (DACNN), trained by reinforcement learning to tackle this problem. The performance of the proposed DACNN model is compared with CNN and directed acyclic graph convolutional neural network (DAGCNN) models. Results show that DACNN outperforms previous studies in processing and classification images. It achieved 94.79% classification accuracy in malaria blood sample images of balanced class dataset obtained from the Kaggle dataset. The proposed model can serve as an effective tool for the detection of malaria parasites in blood smear images.},
  archive      = {J_AAI},
  author       = {David Opeoluwa Oyewola and Emmanuel Gbenga Dada and Sanjay Misra and Robertas Damaševičius},
  doi          = {10.1080/08839514.2022.2033473},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2033473},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel data augmentation convolutional neural network for detecting malaria parasite in blood smear images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of the torques produced by human upper limb
during eating activities using NARX-NN. <em>AAI</em>, <em>36</em>(1),
Article: 2033472. (<a
href="https://doi.org/10.1080/08839514.2022.2033472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upper limb movement disorders significantly hamper the ability of impaired to perform basic activities of daily living (ADL). Eating, without doubt, is one of the essential ADLs necessary for human survival. To develop a rehabilitation system meant specifically to assist the hand during eating, an in-depth knowledge of hand motion and the forces/torques produced, during eating is vital. Since, Human Upper Limb (HUL) motion is highly dexterous, its dynamic model can be beneficial for predicting the torques during different eating activities. Four degrees of freedom (DOF), dynamic model of HUL including wrist and elbow joints, focusing on elbow and wrist flexion/extension, forearm pronation/supination, wrist flexion/extension and wrist adduction/abduction is formulated, using Nonlinear AutoRegressive network with eXogenous input Neural Network (NARX-NN), during different eating activities. We conducted an experimental validation involving five different food types and using two types of cutleries. Torque prediction accuracy of the model is determined by comparing predicted values to that of measured load cell torques, for all eating activities and using Root mean square error (RMSE) as a statistical measure, to test the model performance. Torques predicted by the model track the measured torque efficiently.},
  archive      = {J_AAI},
  author       = {Zakia Hussain and Norsinnira Zainul Azlan},
  doi          = {10.1080/08839514.2022.2033472},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2033472},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Estimation of the torques produced by human upper limb during eating activities using NARX-NN},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Complex interval-valued q-rung orthopair 2-tuple linguistic
aggregation operators and their application in multi-attribute
decision-making. <em>AAI</em>, <em>36</em>(1), Article: 2033471. (<a
href="https://doi.org/10.1080/08839514.2022.2033471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to study the conception of the complex interval-valued q-rung orthopair 2-tuple linguistic set (CIVQRO2-TLS), which is a new powerful mixture to handle unreliable and vague data in realistic decision concerns. We also explore its fundamental properties as well as important laws. In the occurrence of the above theory, we discover some useful aggregation methods for the CIVQRO2-TLS, including the CIVQRO2-TLWA, CIVQRO2-TLOWA, CIVQRO2-TLHA, CIVQRO2-TLWG, CIVQRO2-TLOWG, and CIVQRO2-TLHG operators. To demonstrate the beneficial features of the invented works, a multi-attribute decision-making (MADM) system is presented and exposed to the supremacy of the presented operators with the help of several examples. In last, we elaborate on the advantages, comparative analysis, and graphical interpretation of the invented approaches.},
  archive      = {J_AAI},
  author       = {Shouzhen Zeng and Zeeshan Ali and Tahir Mahmood and Huanhuan Jin},
  doi          = {10.1080/08839514.2022.2033471},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2033471},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Complex interval-valued q-rung orthopair 2-tuple linguistic aggregation operators and their application in multi-attribute decision-making},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-script video caption localization based on visual
rhythms. <em>AAI</em>, <em>36</em>(1), Article: 2032926. (<a
href="https://doi.org/10.1080/08839514.2022.2032926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization of video caption plays an important role in information retrieval in multimedia applications. In this work, we present and evaluate a novel method for localizing video captions using visual rhythms, which enable the representation and analysis of a specific feature throughout the time. We build visual rhythms from the text location maps produced by general text localization methods that are far more common in the literature than caption-oriented ones. Then, we process the maps properly to keep only the captions, generating caption localization masks. To meet the need for a standardized and large dataset, we constructed a new one, where captions with thirteen different scripts are added to the video frames, generating a total of 221 videos with ground truth. Experiments demonstrate that our method achieves competitive results when compared to other literature approaches.},
  archive      = {J_AAI},
  author       = {Marcos Roberto e Souza and Helena de Almeida Maia and Anderson Carlos Souza e Santos and Marcelo Bernardes Vieira and Helio Pedrini},
  doi          = {10.1080/08839514.2022.2032926},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2032926},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-script video caption localization based on visual rhythms},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Missing data analysis in regression. <em>AAI</em>,
<em>36</em>(1), Article: 2032925. (<a
href="https://doi.org/10.1080/08839514.2022.2032925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many of the datasets in real-world applications contain incompleteness. In this paper, we approach the effects and possible solutions to incomplete databases in regression, aiming to bridge a gap between theoretically effective algorithms. We investigated the actual effects of missing data for regression by analyzing its impact in several publicly available databases implementing popular algorithms like Decision Tree, Random Forests, Adaboost, K-Nearest Neighbors, Support Vector Machines, and Neural Networks. Our goal is to offer a systematic view of how missing data may affect regression results. After exhaustive simulation analyzing eight public datasets from UCI and KEEL (Abalone, Arfoil, Bike, California, Compactiv, Mortage, Wankara and Wine), we concluded that the effect of missing data may be significant. The results obtained showed that K-Nearest Neighbors works better than others in the regression of data that has missing data.},
  archive      = {J_AAI},
  author       = {C. G. Marcelino and G. M. C. Leite and P. Celes and C. E. Pedreira},
  doi          = {10.1080/08839514.2022.2032925},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2032925},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Missing data analysis in regression},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on deep learning-based architectures for semantic
segmentation on 2D images. <em>AAI</em>, <em>36</em>(1), Article:
2032924. (<a
href="https://doi.org/10.1080/08839514.2022.2032924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is the pixel-wise labeling of an image. Boosted by the extraordinary ability of convolutional neural networks (CNN) in creating semantic, high-level and hierarchical image features; several deep learning-based 2D semantic segmentation approaches have been proposed within the last decade. In this survey, we mainly focus on the recent scientific developments in semantic segmentation, specifically on deep learning-based methods using 2D images. We started with an analysis of the public image sets and leaderboards for 2D semantic segmentation, with an overview of the techniques employed in performance evaluation. In examining the evolution of the field, we chronologically categorized the approaches into three main periods, namely pre-and early deep learning era, the fully convolutional era, and the post-FCN era. We technically analyzed the solutions put forward in terms of solving the fundamental problems of the field, such as fine-grained localization and scale invariance. Before drawing our conclusions, we present a table of methods from all mentioned eras, with a summary of each approach that explains their contribution to the field. We conclude the survey by discussing the current challenges of the field and to what extent they have been solved.},
  archive      = {J_AAI},
  author       = {Irem Ulku and Erdem Akagündüz},
  doi          = {10.1080/08839514.2022.2032924},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2032924},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A survey on deep learning-based architectures for semantic segmentation on 2D images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bayesian allocation model based approach to mixed
membership stochastic blockmodels. <em>AAI</em>, <em>36</em>(1),
Article: 2032923. (<a
href="https://doi.org/10.1080/08839514.2022.2032923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although detecting communities in networks has attracted considerable recent attention, estimating the number of communities is still an open problem. In this paper, we propose a model, which replicates the generative process of the mixed-membership stochastic block model (MMSB) within the generic allocation framework of Bayesian allocation model (BAM) and BAM-MMSB. In contrast to traditional blockmodels, BAM-MMSB considers the observations as Poisson counts generated by a base Poisson process and marks according to the generative process of MMSB. Moreover, the optimal number of communities for BAM-MMSB is estimated by computing the variational approximations of the marginal likelihood for each model order. Experiments on synthetic and real data sets show that the proposed approach promises a generalized model selection solution that can choose not only the model size but also the most appropriate decomposition.},
  archive      = {J_AAI},
  author       = {Çağlar Hızlı and Serap Kırbız},
  doi          = {10.1080/08839514.2022.2032923},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2032923},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A bayesian allocation model based approach to mixed membership stochastic blockmodels},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining clinical symptoms and patient features for malaria
diagnosis: Machine learning approach. <em>AAI</em>, <em>36</em>(1),
Article: 2031826. (<a
href="https://doi.org/10.1080/08839514.2022.2031826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presumptive treatment and self-medication for malaria have been used in limited-resource countries. However, these approaches have been considered unreliable due to the unnecessary use of malaria medication. This study aims to demonstrate supervised machine learning models in diagnosing malaria using patient symptoms and demographic features. Malaria diagnosis dataset extracted in two regions of Tanzania: Morogoro and Kilimanjaro. Important features were selected to improve model performance and reduce processing time. Machine learning classifiers with the k-fold cross-validation method were used to train and validate the model. The dataset developed a machine learning model for malaria diagnosis using patient symptoms and demographic features. A malaria diagnosis dataset of 2556 patients’ records with 36 features was used. It was observed that the ranking of features differs among regions and when combined dataset. Significant features were selected, residence area, fever, age, general body malaise, visit date, and headache. Random Forest was the best classifier with an accuracy of 95% in Kilimanjaro, 87% in Morogoro and 82% in the combined dataset. Based on clinical symptoms and demographic features, a regional-specific malaria predictive model was developed to demonstrate relevant machine learning classifiers. Important features are useful in making the disease prediction.},
  archive      = {J_AAI},
  author       = {Martina Mariki and Elizabeth Mkoba and Neema Mduma},
  doi          = {10.1080/08839514.2022.2031826},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031826},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Combining clinical symptoms and patient features for malaria diagnosis: Machine learning approach},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligent system utilizing HOG and CNN for thermal
image-based detection of wild animals in nocturnal periods for vehicle
safety. <em>AAI</em>, <em>36</em>(1), Article: 2031825. (<a
href="https://doi.org/10.1080/08839514.2022.2031825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animal Vehicle Collision, commonly called roadkill , is an emerging threat to drivers and wild animals, increasing fatalities every year. Currently, prevalent methods using visible light cameras are efficient for animal detection in daylight time. This paper focuses on locating wildlife close to roads during nocturnal hours by utilizing thermographic obtained images, thus enhancing vehicle safety. In particular, it proposes an intelligent system for animal detection during nighttime that combines the technique of Histogram of Oriented Gradients (HOG) with a Convolutional Neural Network (CNN). The proposed intelligent system is benchmarked against a variety of CNN’s like basic CNN and VGG16-based CNN and also with the machine learning algorithms such as Support Vector Machine (SVM), Random Forest (RF), Decision Tree Algorithm (DT), Linear Regression (LR), and Gaussian Naïve Bayes (GNB). The proposed detection system was tested on a set of real-world data acquired with a thermal camera on the move in the city of San Antonio, TX, USA that includes images of wild deer. Obtained results exhibit that the HOG-CNN combination achieved approximately 91% correct detection accuracy of wild deer on roadsides, while it outperformed the rest of the tested machine learning algorithms.},
  archive      = {J_AAI},
  author       = {Yuvaraj Munian and Antonio Martinez-Molina and Dimitrios Miserlis and Hermilo Hernandez and Miltiadis Alamaniotis},
  doi          = {10.1080/08839514.2022.2031825},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031825},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intelligent system utilizing HOG and CNN for thermal image-based detection of wild animals in nocturnal periods for vehicle safety},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Brain tumor classification based on hybrid optimized
multi-features analysis using magnetic resonance imaging dataset.
<em>AAI</em>, <em>36</em>(1), Article: 2031824. (<a
href="https://doi.org/10.1080/08839514.2022.2031824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors are deadly but become deadliest because of delayed and inefficient diagnosis process. Large variations in tumor types also instigate additional complexity. Machine vision brain tumor diagnosis addresses the problem. This research’s objective was to develop a brain tumor classification model based on machine vision techniques using brain Magnetic Resonance Imaging (MRI). For this purpose, a novel hybrid-brain-tumor-classification (HBTC) framework was designed and evaluated for the classification of cystic (cyst), glioma, meningioma (menin), and metastatic (meta) brain tumors. The proposed framework lessens the inherent complexities and boosts performance of the brain tumor diagnosis process. The brain MRI dataset was input to the HBTC framework, pre-processed, segmented to localize the tumor region. From the segmented dataset Co-occurrence matrix (COM), run-length matrix (RLM), and gradient features were extracted. After the application of hybrid multi-features, the nine most optimized features were selected and input to the framework’s classifiers, namely multilayer perception (MLP), J48, meta bagging (MB), and random tree (RT) to classify cyst, glioma, menin, and meta tumors. Maximum brain tumor classification performance achieved by the HBTC framework was 98.8%. The components and performance of the proposed framework show that it is a novel and robust classification framework.},
  archive      = {J_AAI},
  author       = {Syed Ali Nawaz and Dost Muhammad Khan and Salman Qadri},
  doi          = {10.1080/08839514.2022.2031824},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031824},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Brain tumor classification based on hybrid optimized multi-features analysis using magnetic resonance imaging dataset},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An intelligent system for operators performance
multicriteria evaluation of distribution networks. <em>AAI</em>,
<em>36</em>(1), Article: 2031822. (<a
href="https://doi.org/10.1080/08839514.2022.2031822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {– The operators play a important role in the distribution system control centers, especially during network contingencies. In these situations, the operators have to quickly restore the service and mitigate the impact of a failure on the electrical networks. The utilities need to know how efficiently the operators have executed their maneuvers and whether they are following the company proceedings. Thus, it is paramount to the utilities to have computational tools to evaluate operator performance. The development of this evaluation system is not usually discussed in the literature, whose focus is on developing computational tools for operator training and system operation simulators. Hence, we developed a computational system to evaluate the operator performance of distribution networks, taking the operator’s past actions and their impact on the company’s economic and technical indexes into account. This paper’s main contribution lies in proposing a multicriteria methodology and the computational model, based on an expert system, to assess the distribution network operator performance, considering 13 technical and economic criteria. The obtained results, by using real data from a Brazilian utility, present not only the operator’s global performance but also which criteria the operator has to improve, when past contingencies are analyzed.},
  archive      = {J_AAI},
  author       = {Raimundo Celeste Ghizoni Teive and Alex Luciano Roesler Rese and João Paulo Parreira},
  doi          = {10.1080/08839514.2022.2031822},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031822},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An intelligent system for operators performance multicriteria evaluation of distribution networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid deep learning-based models for crop yield prediction.
<em>AAI</em>, <em>36</em>(1), Article: 2031822. (<a
href="https://doi.org/10.1080/08839514.2022.2031823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting crop yield is a complex task since it depends on multiple factors. Although many models have been developed so far in the literature, the performance of current models is not satisfactory, and hence, they must be improved. In this study, we developed deep learning-based models to evaluate how the underlying algorithms perform with respect to different performance criteria. The algorithms evaluated in our study are the XGBoost machine learning (ML) algorithm, Convolutional Neural Networks (CNN)-Deep Neural Networks (DNN), CNN-XGBoost, CNN-Recurrent Neural Networks (RNN), and CNN-Long Short Term Memory (LSTM). For the case study, we performed experiments on a public soybean dataset that consists of 395 features including weather and soil parameters and 25,345 samples. The results showed that the hybrid CNN-DNN model outperforms other models, having an RMSE equal to 0.266, an MSE of 0.071, and an MAE of 0.199. The predictions of the model fit with an R 2 of 0.87. The second-best result was achieved by the XGBoost model, which required less time to execute compared to the other DL-based models.},
  archive      = {J_AAI},
  author       = {Alexandros Oikonomidis and Cagatay Catal and Ayalew Kassahun},
  doi          = {10.1080/08839514.2022.2031823},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031822},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Hybrid deep learning-based models for crop yield prediction},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reinforcement learning based decision support tool for
epidemic control: Validation study for COVID-19. <em>AAI</em>,
<em>36</em>(1), Article: 2031821. (<a
href="https://doi.org/10.1080/08839514.2022.2031821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epidemics such as COVID-19 present a substantial menace to public health and global economies. While the problem of epidemic forecasting has been thoroughly investigated in the literature, there is limited work studying the problem of optimal epidemic control. In the present paper, we introduce a novel epidemiological model (EM) that is inherently suitable for analyzing different control policies. We validated the potential of the developed EM in modeling the evolution of COVID-19 infections with a mean Pearson correlation of 0.609 CI 0.525–0.690 and P-value &lt; 0.001. To automate the process of analyzing control policies and finding the optimal one, we adapted the developed EM to the reinforcement learning (RL) setting and ran several experiments. The results of this work show that the problem of optimal epidemic control can be significantly difficult for governments and policymakers, especially if faced with several constraints at once, hence, the need for such machine learning-based decision support tools. Moreover, it demonstrated the potential of deep RL in addressing such real-world problems.},
  archive      = {J_AAI},
  author       = {Mohamed-Amine Chadi and Hajar Mousannif},
  doi          = {10.1080/08839514.2022.2031821},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031821},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A reinforcement learning based decision support tool for epidemic control: Validation study for COVID-19},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A homogeneous ensemble classifier for breast cancer
detection using parameters tuning of MLP neural network. <em>AAI</em>,
<em>36</em>(1), Article: 2031820. (<a
href="https://doi.org/10.1080/08839514.2022.2031820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most common cancers among worldwide, and its detection is recognized as a significant public health problem in today’s society. Extensive studies have been conducted to classify patients into malignant or benign groups, but given the importance of the problems, efforts are still ongoing. This paper aims are to parameters tuning of Multi-Layer Perceptron (MLP) neural network for the breast cancer detection. This work presents an MLP-based homogeneous ensemble approach for classifying breast cancer samples. Basically, ensemble learning is used to improve the classification process. This technique is a method of combining different basic classifiers from which a new classifier is derived. In this regard, several optimization algorithms including GA, PSO, and ODMA have been used to determine which algorithm provides the most suitable parameters for MLP. These parameters include effective features, number of hidden layers, number of nodes in layers, and weight values. The proposed algorithm is applied to three datasets of the Wisconsin Breast Cancer Database (i.e., WBCD, WDBC, and WPBC) and then comparison is made between different algorithms to achieve the highest accuracy. Experiments show that the proposed classifier has promising results in breast cancer detection than other state-of-the-art classifiers with 98.79% in the WBCD. Data analysis and its results can confirm the superiority of ensemble classifiers over state-of-the-art methods for breast cancer detection.},
  archive      = {J_AAI},
  author       = {Zhiqiang Guo and Lina Xu and Nona Ali Asgharzadeholiaee},
  doi          = {10.1080/08839514.2022.2031820},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031820},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A homogeneous ensemble classifier for breast cancer detection using parameters tuning of MLP neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How to apply artificial intelligence for social innovations.
<em>AAI</em>, <em>36</em>(1), Article: 2031819. (<a
href="https://doi.org/10.1080/08839514.2022.2031819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates how to apply artificial intelligence for social innovations using two socio-political factors critical for a Behavioral Theory of the Firm (BTF) – uncertainty and conflict. The analysis leads to four approaches for applying artificial intelligence for social innovations such as the agent-based modeling, social entrepreneurship, stakeholder capital, and social contract approaches. The valuation of artificial intelligence in the projects is endogenously created while the social innovators evaluate their environments, goals, and technologies. The study offers step-by-step guidance to assess the performance of and to create implementation strategies for social innovation projects combined with artificial intelligence.},
  archive      = {J_AAI},
  author       = {Eunji Kim and Ga-Young Jang and Soo-Hyun Kim},
  doi          = {10.1080/08839514.2022.2031819},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031819},
  shortjournal = {Appl. Artif. Intell.},
  title        = {How to apply artificial intelligence for social innovations},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Focusing on shared areas for partial person
re-identification. <em>AAI</em>, <em>36</em>(1), Article: 2031818. (<a
href="https://doi.org/10.1080/08839514.2022.2031818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) can achieve ideal performance based on the prerequisite that the sampling image is complete. However, the whole body cannot be detected because pedestrians may be occluded or are at the edge of the surveillance range in real-world scenarios. Consequently, the image only contains part of the visible information of the pedestrian. When using the standard person re-identification to match the partial image with the complete one, we witness the problem of spatial misalignment and interference caused by missing areas. Hence, we propose a focused shared area model (FSA) for partial re-identification to solve such descriptive problems. We use self-supervised learning to locate the shared area and learn region-level features. In addition, we adopt self-attention mechanism to help the network visualize the important features of the image, thus reducing the influence of the background information. Finally, we verify the effectiveness of our method through experiments on two mainstream datasets: Market-1501, DukeMTMC-reID and two important partial datasets: Partial-REID and Partial-iLIDS.},
  archive      = {J_AAI},
  author       = {Shuren Zhou and Fan Zhang and Wenmin Zou},
  doi          = {10.1080/08839514.2022.2031818},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031818},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Focusing on shared areas for partial person re-identification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully unsupervised machine translation using context-aware
word translation and denoising autoencoder. <em>AAI</em>,
<em>36</em>(1), Article: 2031817. (<a
href="https://doi.org/10.1080/08839514.2022.2031817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning machine translation by using only monolingual data sets is a complex task as there are many possible ways to connect or associate target sentences with source sentences. The monolingual word embeddings are linearly mapped on a common shared space through robust learning or adversarial training in an unsupervised way, but these learning techniques have fundamental limitations in translating sentences. In this paper, a simple yet effective method has been proposed for fully unsupervised machine translation that is based on cross-lingual sense to word embedding instead of cross-lingual word embedding and language model. We have utilized word sense disambiguation to incorporate the source language context in order to select the sense of a word more appropriately. A language model for considering target language context in lexical choices and denoising autoencoder for language insertion, deletion, and reordering are integrated. The proposed approach eliminates the problem of noisy target language context due to erroneous word translations. This work takes into account the challenge of homonyms and polysemous words in the case of morphologically rich languages. The experiments performed on English-Hindi and Hindi-English using different evaluation metrics show an improvement of +3 points in BLEU and METEOR-Hindi over the baseline system.},
  archive      = {J_AAI},
  author       = {Shweta Chauhan and Philemon Daniel and Shefali Saxena and Ayush Sharma},
  doi          = {10.1080/08839514.2022.2031817},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031817},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Fully unsupervised machine translation using context-aware word translation and denoising autoencoder},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cardiac diagnosis with machine learning: A paradigm shift in
cardiac care. <em>AAI</em>, <em>36</em>(1), Article: 2031816. (<a
href="https://doi.org/10.1080/08839514.2022.2031816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For successful prognosis of cardiovascular diseases (CVDs), an early and quick diagnosis is essential. Heart disease and strokes are the predominant causes and account for more than 80% of CVD deaths, whilst one-third of these deaths occurs prematurely in people under 70 years of age. For CVD diagnosis, patients need to show an elevated level of biomarkers in the blood sample associated with severe pain in the chest, and diagnostic electrocardiogram (ECG). The majority of CVD patients making CVD diagnosis difficult for physicians show a surprisingly normal ECG pattern. Artificial intelligence techniques can radically improve and optimize CVD outcomes. AI has the potential to provide novel tools and techniques to collect and interpret data and make faster and more accurate decisions reducing hospitalization cost, thereby increasing the quality of life. AI has also improved medical knowledge by unlocking clinically relevant information from the voluminous and complex data received from various resources. This paper reviews the present biosensors and describes various AI techniques, which can effectively be used for early and accurate detection of CVD, thereby improving cardiac care.},
  archive      = {J_AAI},
  author       = {Meena Laad and Ketan Kotecha and Kailas Patil and Reshma Pise},
  doi          = {10.1080/08839514.2022.2031816},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031816},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Cardiac diagnosis with machine learning: A paradigm shift in cardiac care},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning: Parameter optimization using proposed novel
hybrid bees bayesian convolutional neural network. <em>AAI</em>,
<em>36</em>(1), Article: 2031815. (<a
href="https://doi.org/10.1080/08839514.2022.2031815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) is a type of machine learning used to model big data to extract complex relationship as it has the advantage of automatic feature extraction. This paper presents a review on DL showing all its network topologies along with their advantages, limitations, and applications. The most popular Deep Neural Network (DNN) is called a Convolutional Neural Network (CNN), the review found that the most important issue is designing better CNN topology, which needs to be addressed to improve CNN performance further. This paper addresses this problem by proposing a novel nature inspired hybrid algorithm that combines the Bees Algorithm (BA), which is known to mimic the behavior of honey bees, with Bayesian Optimization (BO) in order to increase the overall performance of CNN, which is referred to as BA-BO-CNN. Applying the hybrid algorithm on Cifar10DataDir benchmark image data yielded an increase in the validation accuracy from 80.72% to 82.22%, while applying it on digits datasets showed the same accuracy as the existing original CNN and BO-CNN, but with an improvement in the computational time by 3 min and 12 s reduction, and finally applying it on concrete cracks images produced almost similar results to existing algorithms.},
  archive      = {J_AAI},
  author       = {Nawaf Mohammad H Alamri and Michael Packianather and Samuel Bigot},
  doi          = {10.1080/08839514.2022.2031815},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031815},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep learning: Parameter optimization using proposed novel hybrid bees bayesian convolutional neural network},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence aided agricultural sensors for plant
frostbite protection. <em>AAI</em>, <em>36</em>(1), Article: 2031814.
(<a href="https://doi.org/10.1080/08839514.2022.2031814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frostbite and frost is one of the problems that endanger the health of crops and can ruin plants and fruits. Soil temperature is the most significant factor that influences the freezing depth. Therefore, monitoring and predicting this characteristic is crucial for frostbite protection. This study aims to predict soil temperature on cold days to prevent frostbite injury in crops. For this matter, we used the registered and logged hourly data by the HOBO U30 data logging device and predicted the soil temperature from air temperature, soil water content, and relative humidity. We used 80% of the data set for the training data and assigned the other 20% to the test data. RMSE and MSE were two of the evaluation criteria of the neural network in this study. Also, we calculated P-value and T-value for statistical hypothesis testing. In another approach for weighting the neural network, we used evolutionary algorithms such as Genetic Algorithm and Particle Swarm Optimization instead of the gradient-based methods. According to the results, Multi-layer perceptron neural network with the respective values 0.082 and 0.0068 for RMSE and MSE in training data and 0.085 and 0.0073 for RMSE and MSE in testing data proved to have a better performance in the soil temperature prediction compared to the ANN-GA and ANN-PSO models. Farmers, botanical researchers, and policymakers in food security can use these results.},
  archive      = {J_AAI},
  author       = {Shiva Hassanjani Roshan and Javad Kazemitabar and Ghorban Kheradmandian},
  doi          = {10.1080/08839514.2022.2031814},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2031814},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence aided agricultural sensors for plant frostbite protection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causal structure learning algorithm based on partial rank
correlation under additive noise model. <em>AAI</em>, <em>36</em>(1),
Article: 2023390. (<a
href="https://doi.org/10.1080/08839514.2021.2023390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the structural learning problem of the additive noise model in causal discovery and the challenge of massive data processing in the era of artificial intelligence, this paper combines partial rank correlation coefficients and proposes two new Bayesian network causal structure learning algorithms: PRCB algorithm based on threshold selection and PRCS algorithm based on hypothesis testing. We mainly made three contributions. First, we proved that the partial rank correlation coefficient can be used as the standard of independence test, and explored the distribution of corresponding statistics. Second, the partial rank correlation coefficient is associated with the correlation, and a causal discovery algorithm PRCB based on partial rank correlation and an improved PRCS algorithm based on hypothesis testing are proposed. Finally, comparing with the existing technology on seven classic Bayesian networks, it proves the superiority of the algorithm in low-dimensional networks; the processing of millions of data on three high-dimensional Bayesian networks verifies the high-efficiency performance of the algorithm in high-dimensional large sample data; the application performance of the algorithm is tested by performing fault prediction on the real power plant equipment measurement point data set. Theoretical analysis and experimental results have proved the superiority of the algorithm.},
  archive      = {J_AAI},
  author       = {Jing Yang and Liufeng Jiang and Kai Xie and Qiqi Chen and Aiguo Wang},
  doi          = {10.1080/08839514.2021.2023390},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2023390},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Causal structure learning algorithm based on partial rank correlation under additive noise model},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting physiological needs using deep inverse
reinforcement learning. <em>AAI</em>, <em>36</em>(1), Article: 2022340.
(<a href="https://doi.org/10.1080/08839514.2021.2022340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart health-care assistants are designed to improve the comfort of the patient where smart refers to the ability to imitate the human intelligence to facilitate his life without, or with limited, human intervention. As a part of this, we are proposing a new Intelligent Communication Assistant capable of detecting physiological needs by following a new efficient Inverse Reinforcement learning algorithm designed to be able to deal with new time-recorded states. The latter processes the patient’s environment data, learns from the patient previous choices and becomes capable of suggesting the right action at the right time. In this paper, we took the case study of Locked-in Syndrome patients, studied their actual communication methods and tried to enhance the existing solutions by adding an intelligent layer. We showed that by using Deep Inverse Reinforcement Learning using Maximum Entropy, we can learn how to regress the reward amount of new states from the ambient environment recorded states. After that, we can suggest the highly rewarded need to the target patient. Also, we proposed a full architecture of the system by describing the pipeline of the information from the ambient environment to the different actors.},
  archive      = {J_AAI},
  author       = {Khaoula Hantous and Lilia Rejeb and Rahma Hellali},
  doi          = {10.1080/08839514.2021.2022340},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2022340},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting physiological needs using deep inverse reinforcement learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of the insureds using integrated machine
learning algorithms: A comparative study. <em>AAI</em>, <em>36</em>(1),
Article: 2020489. (<a
href="https://doi.org/10.1080/08839514.2021.2020489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing number of insurance purchasers, the sophisticated claim analysis system has become an imperative must for any insurance firm. Claims Analysis can be utilized to better understand the customer strata and incorporate the findings throughout the insurance policy enrollment, including the underwriting and approval or rejection stages. In recent years machine learning (ML) technologies are increasingly being used to claims Analysis. However, choosing the optimal techniques, whether the features selection techniques, feature discretization techniques, resampling mechanisms, and ML classifiers for insurance decision assistance, is difficult and can harm the quality of claim suggestions. This study aims to develop appropriate decision models by combining binary classification, feature selection, feature discretization, and data resampling techniques. We did Extensive tests on three different datasets to evaluate the viability of the selected models. We used multiple assessment metrics besides the statistical significance test from The ANOVA test and the Friedman test to evaluate the ML models. The findings show that the models perform highly better after applying the feature discretization technique, reducing dimensionality using feature selection methods and solving the unbalanced data problem with resampling methods.},
  archive      = {J_AAI},
  author       = {Mohamed Hanafy and Ruixing Ming},
  doi          = {10.1080/08839514.2021.2020489},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2020489},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Classification of the insureds using integrated machine learning algorithms: A comparative study},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SVM-based analysis for predicting success rate of interest
packets in information centric networks. <em>AAI</em>, <em>36</em>(1),
Article: 2020488. (<a
href="https://doi.org/10.1080/08839514.2021.2020488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A consumer in Information Centric Network (ICN) generates an Interest packet by specifying the name of the required content. As the network emphasizes on content retrieval without much bothering about who serves it (a cache location or actual producer), every Content Router (CR) either provides the requested content back to the requester (if exists in its cache) or forwards the Interest packet to the nearest CR. While forwarding an Interest packet, the ICN routing by default does not provide any mechanism to predict the probable location of the content searched. However, having a predictive model before forwarding may significantly improve content retrieval performance. In this paper, a machine learning (ML) algorithm, particularly a Support Vector Machine (SVM) is used to forecast the success of the Interest packet. A CR can then send an Interest packet in the outgoing interface which is forecasted successful. The objective is to maximize the success rate which in turn minimizes content search time and maximizes throughput. The dataset used in is generated from a simulation topology designed in ndnSim comprising 10 K data points having 10 features. The linear, RBF and the polynomial kernel (with degree 3) are used to analyze the dataset. The polynomial kernel shows the best behavior with 98% accuracy. A comparative retrieval time with and without ML demonstrates around 10% improvement with SVM enable forwarding compared to normal ICN forwarding.},
  archive      = {J_AAI},
  author       = {Nitul Dutta and Sudeep Tanwar and Shobhit K. Patel and Gheorghita Ghinea},
  doi          = {10.1080/08839514.2021.2020488},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2020488},
  shortjournal = {Appl. Artif. Intell.},
  title        = {SVM-based analysis for predicting success rate of interest packets in information centric networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning bilingual word embedding mappings with similar
words in related languages using GAN. <em>AAI</em>, <em>36</em>(1),
Article: 2019885. (<a
href="https://doi.org/10.1080/08839514.2021.2019885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual word embeddings display words from different languages in the same vector space. They provide reasoning about semantics, compare the meaning of words across languages and word meaning in multilingual contexts, necessary to bilingual lexicon induction, machine translation, and cross-lingual information retrieval. This paper proposes an efficient approach to learn bilingual transform mapping between monolingual word embeddings in language pairs. We choose ten different languages from three different language families and downloaded their last update Wikipedia dumps 1 1. https://dumps.wikimedia.org .},
  archive      = {J_AAI},
  author       = {Ghafour Alipour and Jamshid Bagherzadeh Mohasefi and Mohammad-Reza Feizi-Derakhshi},
  doi          = {10.1080/08839514.2021.2019885},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2019885},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Learning bilingual word embedding mappings with similar words in related languages using GAN},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction in traffic accident duration based on
heterogeneous ensemble learning. <em>AAI</em>, <em>36</em>(1), Article:
2018643. (<a
href="https://doi.org/10.1080/08839514.2021.2018643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on millions of traffic accident data in the United States, we build an accident duration prediction model based on heterogeneous ensemble learning to study the problem of accident duration prediction in the initial stage of the accident. First, we focus on the earlier stage of the accident development, and select some effective information from five aspects of traffic, location, weather, points of interest and time attribute. Then, we improve data quality by means of data cleaning, outlier processing and missing value processing. In addition, we encode category features for high-frequency category variables and extract deeper information from the limited initial information through feature extraction. A pre-processing scheme of accident duration data is established. Finally, from the perspective of model, sample and parameter diversity, we use XGBoost, LightGBM, CatBoost, stacking and elastic network to build a heterogeneous ensemble learning model to predict the accident duration. The results show that the model not only has good prediction accuracy but can synthesize multiple models to give a comprehensive degree of importance of influencing factors, and the feature importance of the model shows that the time, location, weather and relevant historical statistics of the accident are important to the accident duration.},
  archive      = {J_AAI},
  author       = {Yuexu Zhao and Wei Deng},
  doi          = {10.1080/08839514.2021.2018643},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2018643},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prediction in traffic accident duration based on heterogeneous ensemble learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative assessment of deep neural network models for
detecting obstacles in the real time aerial railway track images.
<em>AAI</em>, <em>36</em>(1), Article: 2018184. (<a
href="https://doi.org/10.1080/08839514.2021.2018184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstacles on the railway track leading to derailment accidents that cause significant damages to the railway in terms of killed and injuries over the years. Count of accident is increasing day by day due to its causes such as boulders on track, trees falling on the gauge, etc. Monitoring these events has been possible with humans working in railways. But when it comes to the real-time scenario, it turns to fatal work and requires more workers, particularly in a dangerous area. Also, this manual monitoring is not adequate to halt derailment accidents. In this perspective, railroad obstacle detection from aerial images has been growing as a trending research topic under artificial intelligence. Also, this mandates the assessment of familiar and latest deep neural network models such as CenterNet Hourglass, EfficientDet, Faster RCNN, SSD Mobile Net, SSD ResNet, and YOLO that detects the violator of accidents with the aid of our own developed Rail Obstacle Detection Dataset (RODD). These detectors were implemented on real-time aerial railway track images captured by Unmanned Aerial Vehicle (UAV) in India. Initially, the input images in the collected datasets were undergone to data preprocessing after that; the above mentioned deep neural models were trained individually. After that, the experiment is analyzed based on training, time, and performance metrics. At last, the results are visualized, evaluated, and compared; hence based on the performance, some effective deep neural network models have identified for detecting obstacles. The result shows that SSD Mobile Net and Faster RCNN can be used for railroad obstacle detection even in the different lighting conditions in railway with the accuracy of 96.75% and 84.75%, respectively.},
  archive      = {J_AAI},
  author       = {R. S. Rampriya and R. Suganya and Sabari Nathan and P. Shunmuga Perumal},
  doi          = {10.1080/08839514.2021.2018184},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2018184},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A comparative assessment of deep neural network models for detecting obstacles in the real time aerial railway track images},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse based recurrent neural network long short term memory
(rnn-lstm) model for the classification of ecg signals. <em>AAI</em>,
<em>36</em>(1), Article: 2018183. (<a
href="https://doi.org/10.1080/08839514.2021.2018183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the advancement of classical signal processing approaches, numerous works have been performed on the automatic ECG detection schemes for the enhancement of the effectiveness of the identification of the type of ECG heartbeats. One common issue faced by the previous works is the complexity of signal processing. In order to resolve the computational and complexity issues of existing techniques of signal processing, this research work introduces Sparse representation technique for extracting feature. In this study, adaptive thresholding technique combined with Sparse-based Recurrent Neural Network – Long Short Term Memory (RNN-LSTM) model is employed for the classification of ECG signals. P -QRS-T peaks are identified by employing Adaptive thresholding technique. Statistical features are obtained for each signal and are employed in the process of dictionary learning of sparse decomposition. Sparse representations of the incoming ECG signals are used in training the RNN-LSTM network. The trained classifier will give a classified result on giving a test ECG input signal. The performance indices for the process of classification such as accuracy, precision, error rate, sensitivity, and F-score are calculated. The performance of the proposed Sparse based RNN-LSTM classifier is found to be better in comparison with the existing RNN classifier, K-Nearest Neighbor (K-NN) classifier, and Decision Tree (DT) classifier. Furthermore, for validating the performance of the proposed framework, this approach is tested experimentally with real-world raw ECG data acquired using the AD8232 single-lead ECG sensor. The performance of the proposed experimental setup is compared with the existing state-of-the-art approaches.},
  archive      = {J_AAI},
  author       = {Sampath A and Sumithira T. R},
  doi          = {10.1080/08839514.2021.2018183},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2018183},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Sparse based recurrent neural network long short term memory (rnn-lstm) model for the classification of ecg signals},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel multi-neural ensemble approach for cancer diagnosis.
<em>AAI</em>, <em>36</em>(1), Article: 2018182. (<a
href="https://doi.org/10.1080/08839514.2021.2018182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is a complex worldwide health concern that resulted in 10 million cancer deaths in 2018; hence, early cancer detection is crucial. Early detection involves developing more precise technology that offers information about the patient’s cancer, allowing clinicians to make better-informed treatment options. This study provides an in-depth analysis of multiple cancers. This study also exhibits a good survey of the machine or deep learning techniques used in cancer research. Also, the study proposed a stacking-based multi-neural ensemble learning method’s prediction performance on eight datasets, including the benchmark datasets like Wisconsin Breast cancer dataset, mesothelioma, cervical cancer, non-small cell lung cancer survival dataset, and prostate cancer dataset. This study also analyzes the three real-time cancer datasets (Lung, Ovarian &amp; Leukemia) of the Jammu and Kashmir region. The simulation findings indicate that the methodology described in our study attained the highest level of prediction accuracy across all types of cancer data sets. Additionally, the proposed approach has been statistically validated. The purpose of this investigation was to develop and evaluate a prediction model that might be used as a biomarker for malignancy based on anthropometric, clinical, imaging, and gene data.},
  archive      = {J_AAI},
  author       = {Surbhi Gupta and Manoj Kumar Gupta and Rakesh Kumar},
  doi          = {10.1080/08839514.2021.2018182},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2018182},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel multi-neural ensemble approach for cancer diagnosis},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Force control of a shape memory alloy spring actuator based
on internal electric resistance feedback and artificial neural networks.
<em>AAI</em>, <em>36</em>(1), Article: 2015106. (<a
href="https://doi.org/10.1080/08839514.2021.2015106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a study of the resistive behavior of a Shape Memory Alloy spring, with a focus on the application of electrical resistance feedback in control systems. Artificial Neural Networks of different topologies were designed to learn the relation between spring electrical resistance and the force exerted. The feedback between layers in Neural Networks is demonstrated to be a key parameter in learning the non-linear and hysteretic behavior of Shape Memory Alloys. Experiments with closed-loop systems showed that shape memory alloy springs generated forces that converged satisfactorily to the desired reference values. The scientific contribution of this work is the use of electrical resistance variation as feedback for controlling the spring force, eliminating the use of an external force sensor. Neural networks were used for both, the sensing process and the system control; in that way the nonlinear and hysterical behavior of the shape memory alloy actuator was well considered.},
  archive      = {J_AAI},
  author       = {Nathan L.D. Sarmento and José Marques Basílio and Maxsuel F. Cunha and Cícero R. Souto and Andreas Ries},
  doi          = {10.1080/08839514.2021.2015106},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2015106},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Force control of a shape memory alloy spring actuator based on internal electric resistance feedback and artificial neural networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring internet meme activity during COVID-19 lockdown
using artificial intelligence techniques. <em>AAI</em>, <em>36</em>(1),
Article: 2014218. (<a
href="https://doi.org/10.1080/08839514.2021.2014218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sudden outbreak of the novel coronavirus (nCoV-19, COVID-19) and its rampant spread led to a significant number of people being infected worldwide and disrupted several businesses. With most of the countries imposing serious lockdowns due to the increasing number of fatalities, the social lives of millions of people were affected. Although the lockdown led to an increase in network activities, online shopping, and social network usage, it also raised questions On the mental wellness of society. Interestingly, excessive usage of social networks also witnessed humor traveling across the Internet in the form of Internet Memes during the lockdown period. Humor is known to affect our well-being, decision-making, and psychological systems. In this paper, we have analyzed the Internet Meme activity in Social Networks during the COVID-19 Lockdown period. As humor is known to relieve individuals from psychological stress, it is necessary to understand how human beings adopted Internet Memes for coping up with the lockdown stress and stress-relieving mechanism during the lockdown period. In this paper, we have considered thirty popular memes and the increase in the number of their captions within the period (September 2017 to August 2020). An increase in Internet Meme activity since the lockdown period (March 2020) depicts an increase in online social behavior. We analyze the internet meme activity in social networks during the COVID-19 lockdown period using random forest, multi-layer perceptron, and instance-based learning algorithms followed by data visualization using line graph and Heat Map (8 &amp; 15 clustered). We also compared the performance of the models using evaluation parameters like mean absolute error, root-mean-squared error &amp; Kappa statistics and observed that random forest and instance-based learning algorithms perform better than multi-layer perceptrons. The result indicates that random forest and instance-based learning classifiers are having near perfect classification tendencies whereas multi-layer perceptrons showed around 97% classification accuracy.},
  archive      = {J_AAI},
  author       = {Ishaani Priyadarshini and Jyotir Moy Chatterjee and R. Sujatha and Nz Jhanjhi and Ali Karime and Mehedi Masud},
  doi          = {10.1080/08839514.2021.2014218},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014218},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Exploring internet meme activity during COVID-19 lockdown using artificial intelligence techniques},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive artificial intelligence based user intention
assessment model from online reviews and social media. <em>AAI</em>,
<em>36</em>(1), Article: 2014193. (<a
href="https://doi.org/10.1080/08839514.2021.2014193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive analytics is being increasingly used to predict various aspects of applications and users. It offers vast opportunities in the growth of the modern era’s business transformation by enabling automated decision-making processes. Being able to determine the intention of users in an automated way is one of the important factors in enabling automated decision-making for applications and businesses using such applications. In this paper, we utilize and build upon the existing works, and propose a comprehensive intention assessment model that detects different possible intents of users by analyzing their text-based reviews on online forums, retail market websites, or on social media. If the information about a product or service experience is present somewhere in a review or post, our technique can accurately segregate different possible purchase intention labels (i.e., positive, negative, and unknown). Our proposed comprehensive model for intention assessment includes extensive data pre-processing, extended feature selection model, utilization of artificial intelligence (machine learning and deep learning) techniques, and customized cost and loss functions. We built a comprehensive testbed and carried out evaluations and comparisons. Our solution demonstrates high accuracy, precision, and F1 score. The proposed solution helps in mining and gaining deeper insights into behavior of consumers and market tendencies and can help in making informed decisions.},
  archive      = {J_AAI},
  author       = {Archika Sharma and M. Omair Shafiq},
  doi          = {10.1080/08839514.2021.2014193},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014193},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A comprehensive artificial intelligence based user intention assessment model from online reviews and social media},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Transfer learning models for land cover and land use
classification in remote sensing image. <em>AAI</em>, <em>36</em>(1),
Article: 2014192. (<a
href="https://doi.org/10.1080/08839514.2021.2014192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land Cover or Land Use (LCLU) classification is an important, challenging problem in remote sensing (RS) images. RS image classification is a recent technology used to extract hidden information from remotely sensed images in the observed earth environment. This classification is essential for sustainable development in agricultural decisions and urban planning using deep learning (DL) methods. DL gets more attention for accuracy and performance improvements in large datasets. This paper is aimed to apply one of the DL methods called transfer learning (TL). TL is the recent research problem in machine learning and DL approaches for image classification. DL consumes much time for training when starting from scratch. This problem could be overcome in the TL modeling technique, which uses pre-trained models to build deep TL models efficiently. We applied the TL model using bottleneck feature extraction from the pre-trained models: InceptionV3, Resnet50V2, and VGG19 to LCLU classification in the UC Merced dataset. With these experiments, the TL model has been built the outdate performance of 92.46, 94.38, and 99.64 in Resnet50V2, InceptionV3, and VGG19, respectively.},
  archive      = {J_AAI},
  author       = {Abebaw Alem and Shailender Kumar},
  doi          = {10.1080/08839514.2021.2014192},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014192},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Transfer learning models for land cover and land use classification in remote sensing image},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hand gesture recognition of methods-time measurement-1
motions in manual assembly tasks using graph convolutional networks.
<em>AAI</em>, <em>36</em>(1), Article: 2014191. (<a
href="https://doi.org/10.1080/08839514.2021.2014191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition is gaining popularity in many fields, including gesture control, robotics, or medical applications. However, the technology is barely used in industrial manufacturing processes due to high costs, a time-consuming configuration, and changes in the workflow. This paper proposes a minimally invasive approach to recognize workers&#39; hand motions in manual assembly tasks. The novelty of this approach is the use of only one camera instead of any other sensors and the application of state-of-the-art graph neural networks. The method relies on monocular RGB video data to predict the basic motions of the industry standard motion-time system Methods-Time Measurement-1. Our two-stage neural network composed of hand key point extraction and adaptive graph convolution delivers accurate classification results in real-time. To train and validate the model, we created a dataset containing 22,000 frames of real-world assembly tasks. The data produced by this method in a production line can be used for motion time verification, assembly-line design, or assembly cost estimation. In a use-case study, we show that the proposed approach can generate Methods-Time Measurement analysis tables. These have so far only been accurately created by human experts. Source code: https://github.com/alexriedel1/Hand-Gesture-Recognition-in-manual-assembly-tasks-using-GCN},
  archive      = {J_AAI},
  author       = {Alexander Riedel and Nico Brehm and Tobias Pfeifroth},
  doi          = {10.1080/08839514.2021.2014191},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014191},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Hand gesture recognition of methods-time measurement-1 motions in manual assembly tasks using graph convolutional networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Prediction of the probability and risk factors of early
abdominal aortic aneurysm using the gradient boosted decision trees
model. <em>AAI</em>, <em>36</em>(1), Article: 2014190. (<a
href="https://doi.org/10.1080/08839514.2021.2014190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, abdominal aortic aneurysm (AAA) diagnosis mainly relies on the analysis of the image data, such as Doppler ultrasonic and computed tomography (CT). Once AAA has formed, it may rupture and lead to death at any time. Surgical or endovascular treatment was the only method, but it has a high complication rate and poses a huge economic burden to patients. The gradient boosted decision trees (GBDT) model proposed in this paper is used to predict the probability and risk factors that lead to AAA, and the prediction accuracy of the algorithm is able to reach as high as 96%. This study selected 15 related AAA features as training samples. After the training, age, triglycerides (TG), blood pressure (BP), low-density lipoprotein cholesterol (LDL-C), blood glucose (Glu), and body mass index (BMI) are found to have a direct impact on AAA. For individuals with a high AAA probability, the risk factors that contribute the most to the AAA probability can be determined with the GBDT model. This study presents the GBDT model that effectively predicts the probability and risk factors of early AAA, which enables an early intervention and control of these risk factors against incidence of AAA.},
  archive      = {J_AAI},
  author       = {Song Chen and Chuan-Jun Liao},
  doi          = {10.1080/08839514.2021.2014190},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014190},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prediction of the probability and risk factors of early abdominal aortic aneurysm using the gradient boosted decision trees model},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deciding heavy metal levels in soil based on various
ecological information through artificial intelligence modeling.
<em>AAI</em>, <em>36</em>(1), Article: 2014189. (<a
href="https://doi.org/10.1080/08839514.2021.2014189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to decide on heavy metal levels based on ecological parameters by effectively eliminating common disadvantages such as high cost and serious time-consuming laboratory procedures via an effective artificial intelligence approach. Therefore, this study is hinged on an artificial intelligence technique, ANN, because of its low cost and high accuracy in overcoming the mentioned limitations and obstacles in the determination process of the amounts of elements. The ANNs have thus been employed to determine essential heavy metals, such as Fe, Mn, and Zn depending on Ca, K, and Mg concentrations of soil samples obtained from different altitudes in Mount Ida. To the best knowledge of the authors, this is the first study in the literature in which altitude was considered as a parameter in the prediction of nutrient heavy metals. The computed relative errors are significantly low for each of the considered elements (Fe, Mn, and Zn); and are found to be between 1.0–4.1%, 1.0–4.2%, 1.5–7.1%, respectively, for the training, testing, and holdout data. The findings indicate that the relative errors could still be decreased further by assuming the altitude as a factor variable.},
  archive      = {J_AAI},
  author       = {Murat Sari and Tahir Cosgun and Ibrahim Ertugrul Yalcin and Mahmut Taner and Ibrahim Ilker Ozyigit},
  doi          = {10.1080/08839514.2021.2014189},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014189},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deciding heavy metal levels in soil based on various ecological information through artificial intelligence modeling},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of deep convolution neural network in crack
identification. <em>AAI</em>, <em>36</em>(1), Article: 2014188. (<a
href="https://doi.org/10.1080/08839514.2021.2014188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surface crack of structure is an important sign to evaluate the safety of structure. In order to ensure the safety and reliability of the building structure, it is necessary to detect and monitor the surface cracks of the structure. Traditional artificial surface inspections are time-consuming because inspectors have different experience and knowledge, which can lead to misjudgments. Based on the basic framework of four deep convolution neural networks, their classifiers are reconstructed. To fully train these networks and simulate crack images taken in various situations in life, image enhancement techniques are used to extend the dataset. After training, compared with the established shallow network structure, they can learn the feature information in the image more fully, and finally improve the accuracy. After further verification, it is found that one of the models can achieve an accuracy of 96.5%. To verify the universality and validity of the model, two cross-datasets experiments were performed. The experimental results show the validity of the model, and the diagnostic precision is 98.23% and 99.04%, respectively.},
  archive      = {J_AAI},
  author       = {Zhengyun Xu and Songrong Qian and Xiu Ran and Ji Zhou},
  doi          = {10.1080/08839514.2021.2014188},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014188},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Application of deep convolution neural network in crack identification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid improved whale optimization algorithm with support
vector machine for short-term photovoltaic power prediction.
<em>AAI</em>, <em>36</em>(1), Article: 2014187. (<a
href="https://doi.org/10.1080/08839514.2021.2014187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, the grid-connected scale from photovoltaic (PV) system is getting higher among renewable power generations. However, the PV output power can be affected by different meteorological conditions due to PV randomness and volatility. Accordingly, reasonable generation plans can be well arranged using accurate PV power prediction among various types of energy sources, thus reducing the effect of PV system on the grid. To resolve this problem, a PV output power prediction model, namely IMWOASVM, is proposed based on the combination of improved whale optimization algorithm (IMWOA) and support vector machine (SVM). The IMWOA is used to optimize the kernel function parameter and penalty coefficient in SVM. The optimal parameter and coefficient values can then be input to SVM for enhancing the PV prediction. The performance results verify that the coefficient of determination using the IMWOA model can reach beyond 99% in both sunny and cloudy days. Simultaneously, the mean absolute errors on sunny and cloudy days are 0.0251 and 0.0705, respectively. The root mean square errors in sunny and cloudy days are 2.17% and 1.03%, respectively. The results confirm that the proposed model effectively increases the accuracy of the PV output power prediction and is superior to existing methods.},
  archive      = {J_AAI},
  author       = {Bing Gao and Haiyue Yang and Hsiung-Cheng Lin and Zhengping Wang and Weipeng Zhang and Hua Li},
  doi          = {10.1080/08839514.2021.2014187},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014187},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A hybrid improved whale optimization algorithm with support vector machine for short-term photovoltaic power prediction},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning approach for aspect-based sentiment
classification: A comparative review. <em>AAI</em>, <em>36</em>(1),
Article: 2014186. (<a
href="https://doi.org/10.1080/08839514.2021.2014186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of various e-commerce sites has led to an increase in review sites for various services and products. People nowadays easily get information about products and services that will be used through reviews. Here sentiment analysis plays an important role in classifying the polarity of product reviews. However, with a large number of reviews, a sentiment analysis that only gives overall polarity is not sufficient. This will make it difficult to find the reviews of certain aspects (features) of the product. Aspect-based sentiment analysis as fine-grained sentiment analysis is able to provide specific polarity for each aspect contained in a sentence. Various kinds of development methods have been carried out to provide accurate results in aspect-based sentiment analysis. This paper will discuss the various deep learning methods that have been carried out and provide the possibility of research that can be carried out from Aspect-Based Sentiment Analysis.},
  archive      = {J_AAI},
  author       = {Komang Wahyu Trisna and Huang Jin Jie},
  doi          = {10.1080/08839514.2021.2014186},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014186},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep learning approach for aspect-based sentiment classification: A comparative review},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence-based image classification
techniques for hydrologic applications. <em>AAI</em>, <em>36</em>(1),
Article: 2014185. (<a
href="https://doi.org/10.1080/08839514.2021.2014185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrologic modeling is a complex phenomenon dependent on numerous parameters. Since the estimation of parameters is subjected to high uncertainty due to high spatial variation. Therefore, the accuracy of each parameter becomes prime necessary for hydrologic modeling. Gene Expression Programming (GEP) is employed for the first time for Land Use Land Cover (LULC) classification. In the present study, five AI techniques, namely Support Vector Machine (SVM), Adaptive Neuro-Fuzzy Inference System (ANFIS), the M5 Model tree, the multivariate adaptive regression splines (MARS), and Gene Expression Programming (GEP), were studied comparatively for their image classification capability. Comparison criteria adopted for considered AI techniques were errors estimators’ (omission and commission errors) and accuracy estimators’ (overall accuracy and Kappa coefficient). Based on the obtained results, the performance of the GEP technique is found very much comparable with SVM and ANFIS based on overall &amp; Kappa coefficient (&gt;0.85). GEP has a significant advantage over other techniques in producing mathematical functions for the given set of input and output parameters. The present study recommends the use of the GEP technique for LULC image classification.},
  archive      = {J_AAI},
  author       = {Ritica Thakur and V. L. Manekar},
  doi          = {10.1080/08839514.2021.2014185},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2014185},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence-based image classification techniques for hydrologic applications},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human judges in the era of artificial intelligence:
Challenges and opportunities. <em>AAI</em>, <em>36</em>(1), Article:
2013652. (<a
href="https://doi.org/10.1080/08839514.2021.2013652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence technology has been widely used in the field of justice. Compared with human judges, judicial artificial intelligence is more efficient, experience and objective. But artificial intelligence has its limits. Artificial intelligence is still essentially machine intelligence based on big data, algorithms and computing power, not organic intelligence. Subject to the difference between judicial artificial intelligence and human judges in knowledge structure, application scenario and potential ability, judicial artificial intelligence can not completely replace human judges. Therefore, it is important to make it clear that judicial artificial intelligence is only a helper of human judges, not a stand-in. Firstly, it should give full play to the role of judicial artificial intelligence in dealing with simple cases and transactional work. Secondly, the roles and functions of judges should be actively transformed to make them more professional, rational and warm.},
  archive      = {J_AAI},
  author       = {Zichun Xu},
  doi          = {10.1080/08839514.2021.2013652},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2013652},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Human judges in the era of artificial intelligence: Challenges and opportunities},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating the efficacy of small face recognition by
convolutional neural networks with interpolation based on auto-adjusted
parameters and transfer learning. <em>AAI</em>, <em>36</em>(1), Article:
2012982. (<a
href="https://doi.org/10.1080/08839514.2021.2012982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a new approach for face recognition using low-resolution images. By cleverly combining conventional interpolation methods with the state-of-the-art classification approach, i.e. convolutional neural network, we introduce a new approach to efficiently leverage low-resolution images in classification task, especially in face recognition. Besides, we also do experiments on some recent popular methods, our approach outperforms some of them. Additionally, we propose a specific transfer learning strategy based on the preexisting well-known concept dedicated to low-resolution transfer learning. It boosts performance and reduces training time significantly. We also investigate on scalability by applying Bayesian optimization for hyper-parameter search. Therefore, our approach is able to be widely applied in many kinds of datasets and low-resolution classification tasks due to automatically seeking optimal hyper-parameters, which makes our method competitive to others.},
  archive      = {J_AAI},
  author       = {Quan M. Tran and Vuong T. Pham and Duong Thi Thuy Nga and Pham The Bao},
  doi          = {10.1080/08839514.2021.2012982},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2012982},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Evaluating the efficacy of small face recognition by convolutional neural networks with interpolation based on auto-adjusted parameters and transfer learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantics analysis of agricultural experts’ opinions for
crop productivity through machine learning. <em>AAI</em>,
<em>36</em>(1), Article: 2012055. (<a
href="https://doi.org/10.1080/08839514.2021.2012055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic analysis is a particular technique, which is an interesting area of research that associates with Natural Language Processing (NLP), artificial intelligence, opinion mining, text clustering, and classification. Numerous text processing techniques are being used to find out sentiments from the comments, such as social media tweets, hoax, fiction, nonfiction, novels, books, movies, health care, and stock exchange. Agrarian experts’ opinions play a vital role in the agriculture sector that yields good crop productivity. This paper presents a descriptive analysis of agriculture experts’ opinions through machine learning methods based on textual data collection. The data has been collected by surveying various academia, research institute, and industry of Punjab, Pakistan. The impact of various agricultural inputs such as seed quality, soil quality, soil-intensive tillage, climate changes, water shortage, synthetic fertilizer, and precision technologies on crop productivity have been collected through questionnaires. This research provides a descriptive analysis of collected agrarians experts opinions to increase the crop yield by providing awareness regarding current agriculture inputs to farmers by using machine learning. The current research provides a cohesive expert guideline for improving crop productivity, useful for agricultural policymaking, and conveys adequate farmers’ knowledge. Consequently, the proposed method is an innovative way of discovering recommendations of agrarians through sentiment analysis in survey data using machine learning methods. Furthermore, to the best of our knowledge, agrarians experts opinions on enhancing crop productivity have been considered for the first time in Pakistan.},
  archive      = {J_AAI},
  author       = {Mehak Rehman and Abdul Razzaq and Irfan Ahmad Baig and Javeria Jabeen and Muhammad Hammad Nadeem Tahir and Umar Ijaz Ahmed and Adnan Altaf and Touqeer Abbas},
  doi          = {10.1080/08839514.2021.2012055},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2012055},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Semantics analysis of agricultural experts’ opinions for crop productivity through machine learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving tax audit efficiency using machine learning: The
role of taxpayer’s network data in fraud detection. <em>AAI</em>,
<em>36</em>(1), Article: 2012002. (<a
href="https://doi.org/10.1080/08839514.2021.2012002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the universe of Armenian business tax payers operating under a standard tax regime, we develop a fraud prediction model based on machine learning tools, with gradient boosting as the primary choice. Having to deal with broadly defined fraud and heterogeneous taxpayers, as well as a relatively small sample, we successfully derive important features from tax returns with a minimum of additional information. Among the important fraud predictors, we obtain historical fraud and audit, share of administrative costs, and external economic activity. We see two main contributions with generalizable practical implications for auditing authorities. First, by focusing on the lift score of the top decile, we demonstrate that even moderately accurate models can improve upon existing accuracy of rule-based approaches. Second, and more importantly, we demonstrate that the information contained in the supplier and buyer network of the taxpayer can be used whenever important predictors of fraud such as historical audits and fraud are not available. This is particularly important for situations with newly established companies, who would otherwise be under-rated in terms of fraud probability.},
  archive      = {J_AAI},
  author       = {Vardan Baghdasaryan and Hrant Davtyan and Arsine Sarikyan and Zaruhi Navasardyan},
  doi          = {10.1080/08839514.2021.2012002},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2012002},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Improving tax audit efficiency using machine learning: The role of taxpayer’s network data in fraud detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Indoor and outdoor classification using light measurements
and machine learning. <em>AAI</em>, <em>36</em>(1), Article: 2012001.
(<a href="https://doi.org/10.1080/08839514.2021.2012001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents an indoor/outdoor classification system which uses light measurements coupled with machine learning algorithms to predict whether the sensing system is indoors or outdoors. The system measures ultraviolet light, color temperature, luminosity, and red, green, blue, and clear components of light at one-minute intervals using an Arduino-based measurement system. Three machine learning algorithms – support vector machine, artificial neural network, and bagged tree – were trained and tested using experimentally collected sensor data from multiple locations, dates, and times. A comparison of these classifiers revealed superior classification performance of the bagged tree classifier (&gt;99%) compared to the other two algorithms. Each of the presented classifiers offered high estimation performance (&gt;96.9%) in all the considered cases with cross-validation. These results demonstrate the feasibility of using light measurements alone to predict indoor or outdoor condition, which has practical applications in psychology research.},
  archive      = {J_AAI},
  author       = {Matthew B. Rhudy and Scott K. Dolan and Catherine Mello and Nathan Greenauer},
  doi          = {10.1080/08839514.2021.2012001},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2012001},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Indoor and outdoor classification using light measurements and machine learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An improved grey wolves optimization algorithm for dynamic
community detection and data clustering. <em>AAI</em>, <em>36</em>(1),
Article: 2012000. (<a
href="https://doi.org/10.1080/08839514.2021.2012000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the salient features of real-world networks such as social networks is the existence of community structures. Because of the importance of groups and communities in social networks, various algorithms have been proposed to identify communities in this type of dynamic networks. In this paper, we present a new approach to community recognition in dynamic social networks, which is multi-objective and metaheuristic. Our approach is to improve the Grey Wolf Optimizer algorithm and the Label Propagation algorithm and to combine the two algorithms for better performance. We performed our experiments on two artificial and real datasets, and the results show that our proposed method performs better compared to present algorithms in terms of both quality and detection speed. We also applied our proposed algorithm to 23 base functions, which performed better than the other metaheuristic algorithms. At the end, the performance of our proposed algorithm is compared to six other clustering methods on nine datasets from the UCI machine learning laboratory. The simulation results show the effectiveness of the proposed algorithm for solving data clustering problems.},
  archive      = {J_AAI},
  author       = {Fatemeh Besharatnia and Alireza Talebpour and Sadegh Aliakbary},
  doi          = {10.1080/08839514.2021.2012000},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2012000},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An improved grey wolves optimization algorithm for dynamic community detection and data clustering},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian convolutional neural network-based models for
diagnosis of blood cancer. <em>AAI</em>, <em>36</em>(1), Article:
2011688. (<a
href="https://doi.org/10.1080/08839514.2021.2011688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods allow computational models involving multiple processing layers to discover intricate structures in data sets. Classifying an image is one such problem where these methods are found to be very useful. Although different approaches have been proposed in the literature, this paper illustrates a successful implementation of the Bayesian Convolution Neural Networks (BCNN)-based classification procedure to classify microscopic images of blood samples (lymphocyte cells) without involving manual feature extractions. The data set contains 260 microscopic images of cancerous and noncancerous lymphocyte cells. We experiment with different network structures and obtain the model that returns the lowest error rate in classifying the images. Our developed models not only produce high accuracy in classifying cancerous and noncancerous lymphocyte cells but also provide useful information regarding uncertainty in predictions.},
  archive      = {J_AAI},
  author       = {Mohammad Ehtasham Billah and Farrukh Javed},
  doi          = {10.1080/08839514.2021.2011688},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2011688},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bayesian convolutional neural network-based models for diagnosis of blood cancer},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A cluster analysis methodology for the categorization of
soil samples for forensic sciences based on elemental fingerprint.
<em>AAI</em>, <em>36</em>(1), Article: 2010941. (<a
href="https://doi.org/10.1080/08839514.2021.2010941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soil and dirt fragments are easily transferred from the ground to objects such as clothing, shoes, skin, nails, and tires. The elemental analysis of these samples involved in crimes can be an important source of information for forensic scientists because they can present substantial evidence by creating links between victims, suspects, crime scenes and other relevant actors or places. In this work we present a promising new approach for the study of soil samples, using data mining techniques applied to the elemental fingerprints of soil. We experimented on soil samples obtained from southeast Oregon and northern Nevada, two neighboring states in the United States that have similar geological characteristics while also displaying some specific differences. The chemical composition of soil and sediments samples were determined by the use of inductively coupled plasma-mass spectrometry (ICP-MS). Thirty-three elements were analyzed, and we used their concentrations to conduct the analysis. Cluster analysis was performed employing the K-means clustering algorithm. We found three clusters that showed interesting chemical patterns. In order to investigate the most significant chemical elements that distinguish the clusters, we employed the Correlation-Based Feature Selection (CFS) algorithm. Lastly, we developed a classification model based on support vector machine (SVM), which can predict in which of the found clusters an arbitrary soil sample would fall with a 99% prediction accuracy when all 32 variables were used for training the model, and a 95% prediction accuracy when only the 10 most relevant elements were used for training the model. Following this methodology, forensic scientists and experts would be able to establish profiles of soil samples extracted from the crime scene and nearby regions, and use classification models to predict which of these profiles an arbitrary soil sample found on the subjects involved in the crime would be associated with.},
  archive      = {J_AAI},
  author       = {Camila Maione and Nattane Luíza da Costa and Fernando Barbosa Jr. and Rommel Melgaço Barbosa},
  doi          = {10.1080/08839514.2021.2010941},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2010941},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A cluster analysis methodology for the categorization of soil samples for forensic sciences based on elemental fingerprint},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying influentials in social networks. <em>AAI</em>,
<em>36</em>(1), Article: 2010886. (<a
href="https://doi.org/10.1080/08839514.2021.2010886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, social networks have become very popular and an integral part of everyday life. People express their feelings and experiences in this virtual environment and become aware of others’ opinions and interests. Among them, influential users play an important role in disseminating information on social networks. Identifying such influencers is important in designing techniques to increase the speed of information dissemination. Such techniques are applicable in various fields including viral marketing, preventing the dissemination of harmful information, providing specialized recommendations, etc. Various approaches have been used to detect influencers on social networks, mostly based on the individual’s position in the network structure and their interactions. Considering the strengths and weaknesses of the previous methods, this study presents a novel method based on the content of the users’ posts without considering the network structure. This is done using a combination of high-level features extracted from images to measure the individual’s influence. Users’ images are investigated from three aspects: (1) color scheme, (2) advertising nature, (3) images’ semantics. To describe each of these aspects, feature extraction methods were used with acceptable accuracy in recognizing influential users. Finally, to achieve greater efficiency and precision, feature-combination methods have been investigated to provide an integrated classifier.},
  archive      = {J_AAI},
  author       = {Fatemeh Abbasi and Ehsan Fazl-Ersi},
  doi          = {10.1080/08839514.2021.2010886},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2010886},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Identifying influentials in social networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Customer mobile behavioral segmentation and analysis in
telecom using machine learning. <em>AAI</em>, <em>36</em>(1), Article:
2009223. (<a
href="https://doi.org/10.1080/08839514.2021.2009223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to identify telecom customer segments by utilizing machine learning and subsequently develop a web-based dashboard. The dashboard visualizes the cluster analysis based on demographics, behavior, and region features. The study applied analytic pipeline that involved five stages i.e. data generation, data pre-processing, data clustering, clusters analysis, and data visualization. Firstly, the customer’s dataset was generated using Faker Python package. Secondly was the pre-processing which includes the dimensionality reduction of the dataset using the PCA technique and finding the optimal number of clusters using the Elbow method. Unsupervised machine learning algorithm K-means was used to cluster the data, and these results were analyzed and labeled with labels and descriptions. Lastly, a dashboard was developed using Microsoft Power BI to visualize the clustering results in meaningful analysis. According to the results, four customer clusters were obtained. An interactive web-based dashboard called INSIGHT was developed to provide analysis of customer segments based on demographic, behavioral, and regional traits; and to devise customized query for deeper analysis. The correctness of the clustering results was evaluated and achieved a satisfactory Silhouette Score of 0.3853. Hence, the telecom could target their customers accurately based on their needs and preferences to increase service satisfaction.},
  archive      = {J_AAI},
  author       = {Eman Hussein Sharaf Addin and Novia Admodisastro and Siti Nur Syahirah Mohd Ashri and Azrina Kamaruddin and Yew Chew Chong},
  doi          = {10.1080/08839514.2021.2009223},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2009223},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Customer mobile behavioral segmentation and analysis in telecom using machine learning},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A participatory data-centric approach to AI ethics by
design. <em>AAI</em>, <em>36</em>(1), Article: 2009222. (<a
href="https://doi.org/10.1080/08839514.2021.2009222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven artificial intelligence (AI) based on machine learning techniques (ML) has increasingly become an enabler in critical societal domains. However, the introduction of ML systems is often accompanied by unjustified, biased, and discriminated outcomes with severe consequences for the individuals affected. Consequently, in recent years value-based design methods have sought to anticipate and mitigate moral wrongdoing by drawing attention to ethical and epistemic challenges related to the design of AI systems. This article presents a participatory data-centric approach to AI Ethics by Design by promoting and refining insights from contributions within the family of value-sensitive design methods. The approach provides a practicable outlook on addressing epistemic and ethical issues related to data activities in early ML development project stages. Hence, the article seeks to enhance opportunities for ethically informed AI design by stressing the need for bridge building to cultivate a shared understanding among system developers and domain experts about a given data domain and its relatedness to a specific practice.},
  archive      = {J_AAI},
  author       = {Anne Gerdes},
  doi          = {10.1080/08839514.2021.2009222},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2009222},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A participatory data-centric approach to AI ethics by design},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding bias and variance of learning-to-rank
algorithms: An empirical framework. <em>AAI</em>, <em>36</em>(1),
Article: 2009164. (<a
href="https://doi.org/10.1080/08839514.2021.2009164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-to-rank (LtR) algorithms are at the heart of modern day information retrieval systems. While a good number of LtR algorithms have been developed and scrutinized over the past decade, theoretical underpinnings of these algorithms are not thoroughly investigated so far. Amongst the theoretical aspects of a supervised learning algorithm, the bias-variance profiles are of utmost importance. In this article we aim to better understand the bias-variance profiles of rank-learning algorithms. Firstly, we formalize the bias and variance from a pointwise perspective where each query-document pair is treated as an individual training example. Secondly, we develop a framework to analyze the variability and systematic error of a rank-learner in terms of its ranking error, i.e., we analyze the bias-variance from a listwise perspective where a query and all of its associated documents are treated as a single training example. After developing the theoretical framework, we move on to test its applicability in practice. In particular, we choose a promising algorithm, namely random forest-based rank-learning algorithms for our investigation. We study the effect of varying an important parameter of the algorithm, namely the sub-sample size used to learn each tree, on bias and variance. Our hypothesis is that as the sub-sample size (per tree) increases, classical bias-variance tradeoff should be observed. On two large LtR benchmark datasets, experimental results show that our hypothesis holds true. We also explain the relative performance of two of the top performing LtR algorithms using their bias and variance profiles. To the best of our knowledge, this article presents the first thorough investigation into bias and variance analysis of rank-learning algorithms.},
  archive      = {J_AAI},
  author       = {Muhammad Ibrahim},
  doi          = {10.1080/08839514.2021.2009164},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2009164},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Understanding bias and variance of learning-to-rank algorithms: An empirical framework},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contexts and context-awareness revisited from an intelligent
environments perspective. <em>AAI</em>, <em>36</em>(1), Article:
2008644. (<a
href="https://doi.org/10.1080/08839514.2021.2008644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context is a useful concept somehow unconsciously used by humans in daily life problem-solving. Recently, several subareas of computer science have been increasingly trying to rely on this concept to design systems with practical use in certain predefined circumstances. The perception is that imbuing in the system certain context-awareness qualities can support intelligent decision-making in specific practical situations. Despite a significant number of implemented systems that aim at providing context-awareness, there is a lack of commonly accepted and used methodologies and tools. At the root of this, is the lack of agreement on a set of good principles or standards, which can act as a guide to the scientific community and the developers interested in this class of systems. There have been some extensive surveys on the use of context, still there is no theoretical corpus emerging that we can use to discuss the essential concepts making up the fabric of contexts and its use by system developers. Here we attempted such enterprise at a level, which is more formal than popular surveys, in a way that is not implementation dependent and in a way that highlights key concepts of relevance to developers. We reassessed first the basic concepts identifying the need to more prominently consider system beneficiaries’ satisfaction. We then transfer explicitly these values to a more formal outline of the basic componentgs and the operations which emerge as relevant. We identify and highlight the tasks of context activation, comparison, influence, construction, and interaction. We hint at how these may work in practice and explained these through examples. We show how the theory is flexible enough by generalizing it to multiusers so that optimization of global preferences and expectations is used to drive system development and system behavior.},
  archive      = {J_AAI},
  author       = {Juan Carlos Augusto},
  doi          = {10.1080/08839514.2021.2008644},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2008644},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Contexts and context-awareness revisited from an intelligent environments perspective},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Watermarking of deep recurrent neural network using
adversarial examples to protect intellectual property. <em>AAI</em>,
<em>36</em>(1), Article: 2008613. (<a
href="https://doi.org/10.1080/08839514.2021.2008613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present era, deep learning algorithms are the key elements of several state-of-the-art solutions. But developing these algorithms for production requires a huge volume of data, computational resources, and human expertise. Thus, illegal reproduction, distribution, and modification of these models can cause economic damage to developers and can lead to copyright infringement. We propose a novel watermarking algorithm for deep recurrent neural networks based on adversarial examples that can verify the ownership of the model in a black-box way. In this paper, a novel algorithm to watermark a popular pre-trained speech-to-text deep recurrent neural network model Deep Speech without affecting the accuracy of the model is demonstrated. Watermarking is done by generating a set of adversarial examples by adding noise to the input such that the DeepSpeech model predicts the given input as the target string. In the case of copyright infringement, these adversarial examples can be used to verify ownership of the model. If the alleged stolen model predicts the same target string for the adversarial examples, the ownership of the model is verified. This novel watermarking algorithm can minimize the economic damage to the owners of the deep learning models due to stealing and plagiarizing.},
  archive      = {J_AAI},
  author       = {Pulkit Rathi and Saumya Bhadauria and Sugandha Rathi},
  doi          = {10.1080/08839514.2021.2008613},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2008613},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Watermarking of deep recurrent neural network using adversarial examples to protect intellectual property},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differentiation between epileptic and psychogenic
nonepileptic seizures in electroencephalogram using wavelets and
support-vector machines. <em>AAI</em>, <em>36</em>(1), Article: 2008612.
(<a href="https://doi.org/10.1080/08839514.2021.2008612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of people suffering from epilepsy in the world exceeds 50 million and around 20% of this group refers to patients who have psychogenic nonepileptic seizures (PNES). Unlike epilepsy, PNES requires psychological treatment. When not correctly diagnosed, these patients can be submitted to a treatment based on antiepileptic drugs besides specific procedures for epilepsy. In this work, we propose the identification of patients with PNES from those with epilepsy using electroencephalogram (EEG) signals. Discrete Wavelet Transform (DWT) decomposition and a Support-Vector Machine (SVM) classifier were employed. Common types of wavelet families and SVM kernels were combined and compared. The results obtained for accuracy, sensitivity, and specificity are equal to 100% for the set of configuration parameters composed of windows encompassing whole seizures, wavelet Coiflet 1, and SVM kernel sigmoid or RBF. The proposed method is efficient and feasible to be applied to new patients admitted in a hospital center, even without having their previous EEG signals already collected. The main advantages of the proposed work are not requiring the use of accelerometer nor electromyographic signals, not being patient specific and outperforming other works results.},
  archive      = {J_AAI},
  author       = {Kauê Reis dos Santos and Miguel Angelo de Abreu de Sousa and Sara Dereste dos Santos and Ricardo Pires and Sigride Thome-Souza},
  doi          = {10.1080/08839514.2021.2008612},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2008612},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Differentiation between epileptic and psychogenic nonepileptic seizures in electroencephalogram using wavelets and support-vector machines},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An evolutionary multi-objective optimization technique to
deploy the IoT services in fog-enabled networks: An autonomous approach.
<em>AAI</em>, <em>36</em>(1), Article: 2008149. (<a
href="https://doi.org/10.1080/08839514.2021.2008149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) generates countless amounts of data, much of which is processed in cloud data centers. When data is transferred to the cloud over longer distances, there is a long latency in IoT services. Therefore, in order to increase the speed of service provision, resources should be placed close to the user (i.e., at the edge of the network). To address this challenge, a new paradigm called Fog Computing was introduced and added as a layer in the IoT architecture. Fog computing is a decentralized computing infrastructure in which provides storage and computing in the vicinity of IoT devices instead of sending to the cloud. Hence, fog computing can provide less latency and better Quality of Service (QoS) for real-time applications than cloud computing. In general, the theoretical foundations of fog computing have already been presented, but the problem of IoT services placement to fog nodes is still challenging and has attracted much attention from researchers. In this paper, a conceptual computing framework based on fog-cloud control middleware is proposed to optimally IoT services placement. Here, this problem is formulated as an automated planning model for managing service requests due to some limitations that take into account the heterogeneity of applications and resources. To solve the problem of IoT services placement, an automated evolutionary approach based on Particle Swarm Optimization (PSO) has been proposed with the aim of making maximize the utilization of fog resources and improving QoS. Experimental studies on a synthetic environment have been evaluated based on various metrics including services performed, waiting time, failed services, services cost, services remaining, and runtime. The results of the comparisons showed that the proposed framework based on PSO performs better than the state-of-the-art methods.},
  archive      = {J_AAI},
  author       = {Mahboubeh Salimian and Mostafa Ghobaei-Arani and Ali Shahidinejad},
  doi          = {10.1080/08839514.2021.2008149},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2008149},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An evolutionary multi-objective optimization technique to deploy the IoT services in fog-enabled networks: An autonomous approach},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable models for the potentially harmful content in
video games based on game rating predictions. <em>AAI</em>,
<em>36</em>(1), Article: 2008148. (<a
href="https://doi.org/10.1080/08839514.2021.2008148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies reported that playing video games with harmful content can lead to adverse effects on players. Therefore, understanding the harmful content can help reduce these adverse effects. This study is the first to examine the potential of interpretable machine learning (ML) models for explaining the harmful content in video games that may potentially cause adverse effects on players based on game rating predictions. First, the study presents a performance analysis of the supervised ML models for game rating predictions. Secondly, using an interpretability analysis, this study explains the potentially harmful content. The results show that the ensemble Random Forest model robustly predicted game ratings. Then, the interpretable ML model successfully exposed and explained several harmful contents, including Blood, Fantasy Violence, Strong Language , and Blood and Gore . This revealed that the depiction of blood, the depiction of the mutilation of body parts, violent actions of human or non-human characters , and the frequent use of profanity might potentially be associated with adverse effects on players. The findings suggest the strength of interpretable ML models in explaining harmful content. The knowledge gained can be used to develop effective regulations for controlling identified video game content and potential adverse effects.},
  archive      = {J_AAI},
  author       = {Feng Zhipeng and Hamdan Gani},
  doi          = {10.1080/08839514.2021.2008148},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2008148},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Interpretable models for the potentially harmful content in video games based on game rating predictions},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved artificial bee colony algorithm with adaptive
parameter for numerical optimization. <em>AAI</em>, <em>36</em>(1),
Article: 2008147. (<a
href="https://doi.org/10.1080/08839514.2021.2008147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem that ABC (Artificial Bee Colony) algorithm is good at exploration but poor at exploitation for the numerical optimization is investigated in this paper. PA-ABC (Parameter Adaptive ABC) algorithm is proposed, which adopts different search equations with different search abilities for the employed bee and the onlooker bee. Firstly, the best-so-far solution is introduced into each search equation to enhance exploitation; secondly, the employed bee uses two random solutions to search, so as to keep high ability of exploration; thirdly, the onlooker bee searches around a random solution to keep population diversity; most importantly, adaptive parameter computed by fitness function is introduced in the search equation of the onlooker bee, which makes the search step adjust according to the search process. So the search equation of the employed bee has balanced abilities of exploration and exploitation, while the search equation of the onlooker bee can make the search focus transfer from exploration to exploitation adaptively. The experiment results on benchmark functions show that the search performance of PA-ABC is higher than or at least comparable to basic ABC and typical improved ABCs. In addition, compared to the performance of the state-of-the-art ABC variants under their original parameter configuration, PA-ABC is verified to have similar performance to them.},
  archive      = {J_AAI},
  author       = {Ming Zhao and Xiaoyu Song and Shuangyun Xing},
  doi          = {10.1080/08839514.2021.2008147},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2008147},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Improved artificial bee colony algorithm with adaptive parameter for numerical optimization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic overview of android malware detection.
<em>AAI</em>, <em>36</em>(1), Article: 2007327. (<a
href="https://doi.org/10.1080/08839514.2021.2007327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the completely open-source nature of Android, the exploitable vulnerability of malware attacks is increasing. To stay ahead of other similar review work attempting to deal with the serious security problem of the Android environment, this work not only summarizes the approaches in the malware classification phase but also lays emphasis on the Android feature selection algorithm and presents some areas neglected in previous works in the field of Android malware detection, like limitations and commonly applied datasets in machine learning-based models. In this paper, the Android OS environment, feature selection, classification models, and confronted challenges of machine learning detection are described in detail. Based on the brief introduction to Android background knowledge, feature selection methods are elaborated from key perspectives as feature extraction, raw data preprocessing, valid feature subsets selection, and machine learning-based selection models. For the algorithms of the malware classification, machine learning methods are categorized according to different standards to present an all-around view. Furthermore, this paper focuses on the study of deterioration problems and evasion attacks in machine learning detectors.},
  archive      = {J_AAI},
  author       = {Li Meijin and Fang Zhiyang and Wang Junfeng and Cheng Luyu and Zeng Qi and Yang Tao and Wu Yinwei and Geng Jiaxuan},
  doi          = {10.1080/08839514.2021.2007327},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2007327},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A systematic overview of android malware detection},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic educational recommender system based on improved
recurrent neural networks using attention technique. <em>AAI</em>,
<em>36</em>(1), Article: 2005298. (<a
href="https://doi.org/10.1080/08839514.2021.2005298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most web-based educational systems contain some drawbacks, as compared to traditional classrooms. Particularly, it becomes difficult for teachers to guide students to choose an appropriate learning resource due to the large number of online learning resources. Meanwhile, student decisions make it more difficult to choose educational resources according to their circumstances. In this matter, the resource recommender system can be employed as an educational environment to recommend the educational resource advice for students, so that these recommendations can be coordinated to each student’s preferences and needs. This paper presents the resource recommender system as a combination of MLP, BiLSTM, and LSTM improved deep learning networks using the attention method. Compared to similar studies conducted using DBN networks and focus only on the near past interests and preferences of users, the proposed system provides higher accuracy and more appropriate recommendations considering current interests, in addition to the user’s long-term past interests. The proposed recommender system with accuracy of 0.96 and a loss of 0.0822 contains a better performance to recommend resources to students compared to other methods.},
  archive      = {J_AAI},
  author       = {Hadis Ahmadian Yazdi and Seyyed Javad Seyyed Mahdavi Chabok and Maryam Kheirabadi},
  doi          = {10.1080/08839514.2021.2005298},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2005298},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Dynamic educational recommender system based on improved recurrent neural networks using attention technique},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comparative study on performance of SVM and CNN in
tanzania sign language translation using image recognition.
<em>AAI</em>, <em>36</em>(1), Article: 2005297. (<a
href="https://doi.org/10.1080/08839514.2021.2005297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language is an effective form of communication for speech impaired people. However, there is a challenge for people without impairment to communicate with speech impaired people because most are unaware of the language. There are several Machine Learning techniques that have been used in sign language translation. However, no study has been found in Tanzania Sign Language which is the sign language used by speech impaired people in Tanzania. This study seeks to compare the performance of SVM and CNN on translating sign language through the image recognition. The study employs Tanzanian Sign Language images as datasets. Principal Component Analysis was employed for feature extraction. Furthermore, the study used Combined 5x2cv F test to compare the two techniques. The findings indicate that CNN scored 96% in all of the parameters which are accuracy, recall, and precision while SVM scored similar rate in precision but lag behind on recall and accuracy. Additionally, the results show that there is significant difference in performance between the techniques. Therefore, the study recommends the use of CNN since it has high accuracy.},
  archive      = {J_AAI},
  author       = {Kasian Myagila and Hassan Kilavo},
  doi          = {10.1080/08839514.2021.2005297},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2005297},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A comparative study on performance of SVM and CNN in tanzania sign language translation using image recognition},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel machine learning based framework for detection of
autism spectrum disorder (ASD). <em>AAI</em>, <em>36</em>(1), Article:
2004655. (<a
href="https://doi.org/10.1080/08839514.2021.2004655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is linked with abridged ability in social behavior. Scientists working in the broader domain of cognitive sciences have done a lot of research to discover the root cause of ASD, but its biomarkers are still unknown. Some studies from the domain of neuroscience have highlighted the fact that corpus callosum and intracranial brain volume hold significant information for the detection of ASD. Taking inspiration from such findings, in this article, we have proposed a machine learning based framework for automatic detection of ASD using features extracted from corpus callosum and intracranial brain volume. Our proposed framework has not only achieved good recognition accuracy but has also reduced the complexity of training machine learning model by selecting features that are most significant in terms of discriminative capabilities for classification of ASD. Second, for benchmarking and to verify potential of deep learning on analyzing neuroimaging data, in this article, we have presented results achieved by using the transfer learning approach. For this purpose, we have used the pre-trained VGG16 model for the classification of ASD.},
  archive      = {J_AAI},
  author       = {Hamza Sharif and Rizwan Ahmed Khan},
  doi          = {10.1080/08839514.2021.2004655},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2004655},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel machine learning based framework for detection of autism spectrum disorder (ASD)},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistical analysis of infrared thermogram for CNN-based
electrical equipment identification methods. <em>AAI</em>,
<em>36</em>(1), Article: 2004348. (<a
href="https://doi.org/10.1080/08839514.2021.2004348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is essential to develop infrared (IR) thermogram identification technologies to establish automatic diagnosis systems in power substations. The convolutional neural network (CNN) based methods show the highest accuracy in this field. The IR thermograms of electrical equipment are very different from general digital images, which means the present methods need further improvements. For data-driven CNN methods, it is necessary to study the characteristics of the IR data. This paper collected 11817 thermograms from substations and structured the dataset according to equipment types. The statistical features of mean, variance, skewness, kurtosis and contrast are analyzed and compared with other five image datasets. Several tricks are revealed from the analysis and tested on CNN models. Firstly, greycaling the Iron pseudo-color images extracts the temperature information and makes it possible to design models with fewer channels. The test shows it could reduce over 35% computational costs. Secondly, the sparse information of color and edges of thermograms makes it necessary to keep the original aspect ratio. The image preprocessing method of cropping shows better performance than padding and rescaling. Thirdly, the 0–1 normalization can boost the training process for about 100 epochs, which is related to the particular background of thermograms.},
  archive      = {J_AAI},
  author       = {Sheng Han and Fan Yang and Hui Jiang and Gang Yang and Dawei Wang and Na Zhang},
  doi          = {10.1080/08839514.2021.2004348},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2004348},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Statistical analysis of infrared thermogram for CNN-based electrical equipment identification methods},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parsing AUC result-figures in machine learning specific
scholarly documents for semantically-enriched summarization.
<em>AAI</em>, <em>36</em>(1), Article: 2004347. (<a
href="https://doi.org/10.1080/08839514.2021.2004347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning specific scholarly full-text documents contain a number of result-figures expressing valuable data, including experimental results, evaluations, and cross-model comparisons. The scholarly search system often overlooks this vital information while indexing important terms using conventional text-based content extraction approaches. In this paper, we propose creating semantically enriched document summaries by extracting meaningful data from the results-figures specific to the evaluation metric of the area under the curve (AUC) and their associated captions from full-text documents. At first, classify the extracted figures and analyze them by parsing the figure text, legends, and data plots – using a convolutional neural network classification model with a pre-trained ResNet-50 on 1.2 million Images from ImageNet. Next, we extract information from the result figures specific to AUC by approximating the region under the function’s graph as a trapezoid and calculating its area, i.e., the trapezoidal rule. Using over 12,000 figures extracted from 1000 scholarly documents, we show that figure specialized summaries contain more enriched terms about figure semantics. Furthermore, we empirically show that the trapezoidal rule can calculate the area under the curve by dividing the curve into multiple intervals. Finally, we measure the quality of specialized summaries using ROUGE, Edit distance, and Jaccard Similarity metrics. Overall, we observed that figure specialized summaries are more comprehensive and semantically enriched. The applications of our research are enormous, including improved document searching, figure searching, and figure focused plagiarism. The data and code used in this paper can be accessed at the following URL: https://github.com/slab-itu/fig-ir/ .},
  archive      = {J_AAI},
  author       = {Iqra Safder and Hafsa Batool and Raheem Sarwar and Farooq Zaman and Naif Radi Aljohani and Raheel Nawaz and Mohamed Gaber and Saeed-Ul Hassan},
  doi          = {10.1080/08839514.2021.2004347},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2004347},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Parsing AUC result-figures in machine learning specific scholarly documents for semantically-enriched summarization},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rail steel health analysis based on a novel genetic
density-based clustering technique and manifold representation of
acoustic emission signals. <em>AAI</em>, <em>36</em>(1), Article:
2004346. (<a
href="https://doi.org/10.1080/08839514.2021.2004346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effectiveness of the acoustic emission (AE) technique in rail health monitoring, a novel genetic clustering technique is proposed to categorize data automatically, integrating density-based clustering and t-distributed stochastic neighbor embedding. A primary problem in optimizing density-based clustering is to accommodate noise, for it explicitly computes the noise subset. Thus, the generalized silhouette index is proposed as a profitable objective to properly tackle noise and arbitrary shapes. The proposed method is initially testified in ten benchmark datasets, which manifests a superiority in handling irregular shape datasets and noise interference. Furthermore, the proposed method is applied in real-world AE signals acquired from tensile tests. The clustering results elucidated that it outperforms the comparative methods in categorizing the fused AE features and remains robust with increasing railway noise interference. In conclusion, the proposed method is validated to discover intrinsic groups of AE data and analyze potential rail health stages.},
  archive      = {J_AAI},
  author       = {Kangwei Wang and Xin Zhang and Shuzhi Song and Yan Wang and Yi Shen and Paul D. Wilcox},
  doi          = {10.1080/08839514.2021.2004346},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2004346},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Rail steel health analysis based on a novel genetic density-based clustering technique and manifold representation of acoustic emission signals},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature selection empowered by self-inertia weight adaptive
particle swarm optimization for text classification. <em>AAI</em>,
<em>36</em>(1), Article: 2004345. (<a
href="https://doi.org/10.1080/08839514.2021.2004345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification (TC) is a crucial practice in case of organizing a vast number of documents. The computational complexity of the TC process is usually high because of the large dimensionality of the feature space. Feature Selection (FS) procedures are used to extract the helpful information from the feature space and results in dimensionality reduction. The development of the FS method that reduces the dimensionality of feature space without compromising the categorization accuracy is desirable. This paper proposes a Self-Inertia Weight Adaptive Particle Swarm Optimization (SIW-APSO) based FS methodology to enhance the performance of text classification systems. SIW-APSO has fast convergence phenomena due to its high search competency and ability to find feature sub-set efficiently. For text classification, the K-nearest neighbors algorithm is used. The experimental analysis shows that the proposed method outperformed the existing state-of-the-art algorithms on the Reuters-21578 data set by achieving 98.60% precision, 96.56% recall, and 97.57% F1 score.},
  archive      = {J_AAI},
  author       = {Muhammad Asif and Arfan Ali Nagra and Maaz Bin Ahmad and Khalid Masood},
  doi          = {10.1080/08839514.2021.2004345},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2004345},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Feature selection empowered by self-inertia weight adaptive particle swarm optimization for text classification},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of local scour around bridge piers using
hierarchical clustering and adaptive genetic programming. <em>AAI</em>,
<em>36</em>(1), Article: 2001734. (<a
href="https://doi.org/10.1080/08839514.2021.2001734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The physics of local scour around bridge piers is fairly complex because of multiple forces acting on it. Existing empirical formulas cannot cover all scenarios and soft computing methods require ever greater amounts of data to cover all cases with a single formula or a neural network. The approach proposed in this study brings together observations from over 40 studies, grouping similar observations with hierarchical clustering, and using genetic programming with adaptive operators to evolve formulas specific to each cluster to predict the scour depth. The resulting formulas are made available along with a basic web-based user interface that finds the closest cluster for newly presented data and finds the scour depth using the formula for that cluster. All formulas have R 2 scores over 0.8 and have been validated with validation and testing sets to reduce overfitting. When compared to existing empirical formulas, the generated formulas consistently record higher R 2 scores.},
  archive      = {J_AAI},
  author       = {Kaya Oğuz and Aslı Bor},
  doi          = {10.1080/08839514.2021.2001734},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2001734},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prediction of local scour around bridge piers using hierarchical clustering and adaptive genetic programming},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crystal cube: Forecasting disruptive events. <em>AAI</em>,
<em>36</em>(1), Article: 2001179. (<a
href="https://doi.org/10.1080/08839514.2021.2001179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disruptive events within a country can have global repercussions, creating a need for the anticipation and planning of these events. Crystal Cube (CC) is a novel approach to forecasting disruptive political events at least one month into the future. The system uses a recurrent neural network and a novel measure of event similarity between past and current events. We also introduce the innovative Thermometer of Irregular Leadership Change (ILC). We present an evaluation of CC in predicting ILC for 167 countries and show promising results in forecasting events one to twelve months in advance. We compare CC results with results using a random forest as well as previous work.},
  archive      = {J_AAI},
  author       = {Anna L. Buczak and Benjamin D. Baugher and Christine S. Martin and Meg W. Keiley-Listermann and James Howard II and Nathan H. Parrish and Anton Q. Stalick and Daniel S. Berman and Mark H. Dredze},
  doi          = {10.1080/08839514.2021.2001179},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2001179},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Crystal cube: Forecasting disruptive events},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble classifier for stock trading recommendation.
<em>AAI</em>, <em>36</em>(1), Article: 2001178. (<a
href="https://doi.org/10.1080/08839514.2021.2001178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a heterogeneous ensemble classifier for price trend prediction of a stock, in which the prediction results are subsequently used in trading recommendation. The proposed ensemble model is based on Support vector machine, Artificial neural networks, Random forest, Extreme gradient boosting, and Light gradient boosting machine. A feature selection is performed to choose an optimal set of 45 technical indicators as input attributes of the model. Each base classifier is executed with an extensive hyperparameter tuning to improve performance. The prediction results from five base classifiers are aggregated through a modified majority voting among three classifiers with the highest accuracies, to obtain final prediction result. The performance of proposed ensemble classifier is evaluated using daily historical prices of 20 stocks from Stock Exchange of Thailand, with 3 overlapping datasets of 5-year intervals during 2014–2020 for different market conditions. The experimental results show that the proposed ensemble classifier clearly outperforms buy-and-hold strategy, individual base classifiers, and the ensemble with straightforward majority voting in terms of both trading return and Sharpe ratio.},
  archive      = {J_AAI},
  author       = {Chukiat Worasucheep},
  doi          = {10.1080/08839514.2021.2001178},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2001178},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Ensemble classifier for stock trading recommendation},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multimodal sentiment analysis using multi-tensor fusion
network with cross-modal modeling. <em>AAI</em>, <em>36</em>(1),
Article: 2000688. (<a
href="https://doi.org/10.1080/08839514.2021.2000688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of social networks, more and more people express their emotions and opinions via online videos. However, most of the current research on multimodal sentiment analysis cannot do well with effective emotional fusion in multimodal data. To deal with the problem, we propose a multi-tensor fusion network with cross-modal modeling for multimodal sentiment analysis. In this study, the multimodal feature extraction with cross-modal modeling is utilized to obtain the relationship of emotional information between multiple modalities. Moreover, the multi-tensor fusion network is used to model the interaction of multiple pairs of bimodal and realize the emotional prediction of multimodal features. The proposed approach performs well in regression and different dimensions of classification experiments on the two public datasets CMU-MOSI and CMU-MOSEI.},
  archive      = {J_AAI},
  author       = {Xueming Yan and Haiwei Xue and Shengyi Jiang and Ziang Liu},
  doi          = {10.1080/08839514.2021.2000688},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2000688},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multimodal sentiment analysis using multi-tensor fusion network with cross-modal modeling},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constrained clustering for the capacitated vehicle routing
problem (CC-CVRP). <em>AAI</em>, <em>36</em>(1), Article: 1995658. (<a
href="https://doi.org/10.1080/08839514.2021.1995658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {eCommerce, postal and logistics’ planners require to solve large-scale capacitated vehicle routing problems (CVRPs) on a daily basis. CVRP problems are NP-Hard and cannot be easily solved for large problem instances. Given their complexity, we propose a methodology to reduce the size of CVRP problems that can be later solved with state-of-the-art optimization solvers. Our method is an efficient version of clustering that considers the constraints of the original problem to transform it into a more tractable version. We call this approach Constrained Clustering Capacitated Vehicle Routing Solver (CC-CVRS) because it produces a soft-clustered vehicle routing problem with reduced decision variables. We demonstrate how this method reduces the computational complexity associated with the solution of the original CVRP and how the computed solution can be transformed back into the original space. Extensive numerical experiments show that our method allows to solve very large CVRP instances within seconds with optimality gaps of less than 16%. Therefore, our method has the following benefits: it can compute improved solutions with small optimality gaps in near real-time, and it can be used as a warm-up solver to compute an improved solution that can be used as an initial solution guess by an exact solver.},
  archive      = {J_AAI},
  author       = {Francesco Alesiani and Gulcin Ermis and Konstantinos Gkiotsalitis},
  doi          = {10.1080/08839514.2021.1995658},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1995658},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Constrained clustering for the capacitated vehicle routing problem (CC-CVRP)},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic classification of blue and white porcelain sherds
based on data augmentation and feature fusion. <em>AAI</em>,
<em>36</em>(1), Article: 1994232. (<a
href="https://doi.org/10.1080/08839514.2021.1994232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many blue and white porcelain are unearthed in Jingdezhen every year. The patterns on the sherds have important research significance. At present, the classification of porcelain shards is mainly based on manual work, which has the disadvantages of large workload. The use of automatic classification methods also faces complex patterns and sample sizes. In order to solve these problems, this paper proposes a new automatic recognition method based on deep learning, including data preprocessing method combined with color segmentation algorithm, a new data augmentation method FCutMix for regions of interest, a new integration strategy and the redesigned deep network model FFCNet that integrates multiple features. After experiments, the data preprocessing method, feature fusion method and integration strategy proposed in the paper can effectively improve the performance of the model by removing redundant information and adding effective features. The FCutMix method can also obtain more accurate mixed samples than the traditional CutMix. The method proposed in this paper improves the accuracy of tasks in 14 categories from 71.7% to 83.2% in a dataset containing only 373 images of porcelain sherds. In the future, this research will further design the network structure and multi-level feature fusion.},
  archive      = {J_AAI},
  author       = {Yanzhe Liu and Bingxiang Liu and Jiajia Yu and Jingwen Xia and Canfei Luo},
  doi          = {10.1080/08839514.2021.1994232},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1994232},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automatic classification of blue and white porcelain sherds based on data augmentation and feature fusion},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integration learning of neural network training with swarm
intelligence and meta-heuristic algorithms for spot gold price forecast.
<em>AAI</em>, <em>36</em>(1), Article: 1994217. (<a
href="https://doi.org/10.1080/08839514.2021.1994217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research attempts to enhance the learning performance of radial basis function neural network (RBFNuNet) via swarm intelligence (SI) and meta-heuristic algorithms (MHAs). Further, the genetic algorithm (GA) and ant colony optimization (ACO) algorithms are applied for RBFNuNet to learn. The proposed integration of GA and ACO approaches-based (IGACO) algorithm combines the complementarity of exploitation and exploration capabilities to achieve optimization resolve. The feature of population diversification has higher opportunity to pursue the global optimal substitute being constrained to local optimal exceeding in five continuous test functions. The experimental results have illustrated that GA and ACO approaches can be incorporated intelligently and propose an integrated algorithm, which intents for obtaining the optimal accuracy training performance among relevant algorithms in this study. Additionally, method assessment results for five benchmark problems and a practical spot gold price forecast exercise show that the proposed IGACO algorithm outperforms other algorithms and the Box-Jenkins models in terms of forecasting preciseness and execution time.},
  archive      = {J_AAI},
  author       = {Zhen-Yao Chen},
  doi          = {10.1080/08839514.2021.1994217},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1994217},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Integration learning of neural network training with swarm intelligence and meta-heuristic algorithms for spot gold price forecast},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A lexicon-based method for detecting eye diseases on
microblogs. <em>AAI</em>, <em>36</em>(1), Article: 1993003. (<a
href="https://doi.org/10.1080/08839514.2021.1993003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explored the feasibility of detecting eye diseases on microblogs. A lexicon-based approach was developed to provide an early recognition of common eye disease from social media platforms. The data were obtained using Twitter free streaming Application Programming Interface (API). A cluster analysis was applied to extract instances that share similar characteristics. We extracted three types of emotions (positive, negative, and neutral) from users’ messages (tweets) using SentiStrength. A time-series method was used to determine the applicability of predicting emotional changes over a period of seven months. The relevant disease symptoms were extracted using Apriori algorithm with prediction accuracy of 98.89%. This study offers a timely and effective method that can be implemented to help healthcare decision makers and researchers reduce the spread of eye diseases in a population specific manner.},
  archive      = {J_AAI},
  author       = {Samer Muthana Sarsam and Hosam Al-Samarraie},
  doi          = {10.1080/08839514.2021.1993003},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1993003},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A lexicon-based method for detecting eye diseases on microblogs},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence methods: Toward a new decision
making tool. <em>AAI</em>, <em>36</em>(1), Article: 1992141. (<a
href="https://doi.org/10.1080/08839514.2021.1992141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is based on a mixe between the dynamics of investor decision making and the effectiveness of the forecasting models used to model market movements. Thus, it appears that the determination of adequate models can help to explain the behavior of agents and result to easier decision making through the anticipation of future prices. For this reason, we will use artificial intelligence models, in particular Machine Learning and Deep Learning algorithms, in order to better understand the variation of asset prices and their future evolution. In order to do so, we will use Recurrent Neural Networks (RNN), which has proven to be very suitable in the case of the Moroccan banking sector. The comparison between classical models and advanced artificial intelligence (AI) algorithms has demonstrated the inadequacy of classical statistical models. The latter are based on certain assumptions not verified in the framework of financial series, which reduces the capacity of classical models to correctly predict new data. The integration of AI has also made it possible to overcome the assumption of market efficiency by modeling the behavior of irrational agents, who trade on rumors and false news.},
  archive      = {J_AAI},
  author       = {Ismail Lotfi and Abdelhamid El Bouhadi},
  doi          = {10.1080/08839514.2021.1992141},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1992141},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence methods: Toward a new decision making tool},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Highlight removal from a single grayscale image using
attentive GAN. <em>AAI</em>, <em>36</em>(1), Article: 1988441. (<a
href="https://doi.org/10.1080/08839514.2021.1988441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existence of specular highlights hinders high-level computer algorithms. In this paper, we propose a novel approach to remove specular highlights from a single grayscale image by regarding the problem as an image-to-image translation task between the highlight domain and the diffuse domain. We solve this problem by using the generative adversarial network framework, where a generator removes highlights and discriminator judges whether outputs of the generator are clear and highlight-free. Specular highlight removal is intractable as we should remove specular highlights while keeping as many details as possible. Considering the similarity between the highlight image and diffuse image, we adopt an attention-based submodule that generates a mask image, which we call the highlight intensity mask, to locate pixels that contain specular highlights and help the skip-connected autoencoder to remove highlights. A pixel discriminator and Structural Similarity loss are utilized to ensure that more details can be retained in the output images. For training and testing models, we build a grayscale highlight images dataset. It consists of more than a thousand sets of grayscale highlight images with ground truth. Finally, quantitative and qualitative evaluations demonstrate the effectiveness of our method than other contrast generative adversarial network methods.},
  archive      = {J_AAI},
  author       = {Haitao Xu and Qiang Li and Jing Chen},
  doi          = {10.1080/08839514.2021.1988441},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1988441},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Highlight removal from a single grayscale image using attentive GAN},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finger contact area analysis with convolutional neural
networks. <em>AAI</em>, <em>36</em>(1), Article: 1987035. (<a
href="https://doi.org/10.1080/08839514.2021.1987035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of the contact area formed between a human finger and a counter surface is of great interest because it is the key parameter for various interaction parameters. Adhesional friction forces and the thermal contact conductance critically depend on the contact area, further influencing the tactile sensation of stickiness and warmth. The contact area is also of concern regarding safety issues. Injuries caused by objects slipping out of our hands might be prevented by optimizing the contact area and the concomitant grip through appropriate surface structures and material choice. Until now the contact area is mainly studied on smooth and transparent materials. The contact area is recorded optically and rule-based image processing methods can be used for detection. These methods might be insufficient for rough surfaces where the contact area is optically unclear due to light scattering. In this paper we demonstrate the successful analysis of such optically unclear contact area images via convolutional neural networks to identify the fingerprint ridges in contact with structured surfaces. The proposed method relies on the generation of synthetic contact images that provide the pixelwise ground truth for the efficient training of a segmentation pipeline based on convolutional neural networks.},
  archive      = {J_AAI},
  author       = {Thomas Ules and Matthias Haselmann and Michael Grieβer and Dieter P. Gruber},
  doi          = {10.1080/08839514.2021.1987035},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1987035},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Finger contact area analysis with convolutional neural networks},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Solution of combined economic and emission dispatch problems
of power systems without penalty. <em>AAI</em>, <em>36</em>(1), Article:
1976092. (<a
href="https://doi.org/10.1080/08839514.2021.1976092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present paper, the Optimization Without Penalty-based Optimization by Morphological Filter algorithm (OWP-based OMF) has been proposed to find the optimal solution for the Combined Economic and Emission Dispatch (CEED) problem. The objective function of the CEED problem is to minimize fuel cost and emission simultaneously while satisfying the load demand, equality and inequality constraints. The evaluation of OWP-based OMF performances is carried out on three test systems with 6, 10 and 40 generating units, with different constraints and various costs. The present paper shows that OWP-based OMF gives an accurate and effective solution of the CEED problem and outperforms the other tested algorithms.},
  archive      = {J_AAI},
  author       = {Sihem Zaoui and Abderrahim Belmadani},
  doi          = {10.1080/08839514.2021.1976092},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1976092},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Solution of combined economic and emission dispatch problems of power systems without penalty},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new hybrid under-sampling approach to imbalanced
classification problems. <em>AAI</em>, <em>36</em>(1), Article: 1975393.
(<a href="https://doi.org/10.1080/08839514.2021.1975393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among many machine learning applications, classification is one of the important tasks. Most classification algorithms have been designed under the assumption that the number of samples for each class is approximately balanced. However, if the conventional classification approaches are applied to a class imbalanced dataset, it is likely to cause misclassification and, as a result, may distort classification performance results. Thus, in this study, we consider imbalanced classification problems and adopt an efficient preprocessing technique to improve the classification performances. In particular, we focus on borderline noise and outlier samples that belong to the majority class since they may influence classification performance. For this, we propose a hybrid resampling method, called BOD-based under-sampling, which is based on density-based spatial clustering of applications with noise (DBSCAN) approach as well as noise and outlier detection methods, that is, borderline noise factor (BNF) and outlierness based on neighborhood (OBN) to divide majority class samples into four distinctive categories, i.e., safe, borderline noise, rare, and outlier. Specifically, we first determine the borderline noise samples in the overlapped region using the BNF method. Secondly, we use the OBN method to detect outlier samples and apply the DBSCAN approach to cluster the samples. Based on the results obtained from the sample identification analysis, we then segregate the safe category samples which are not abnormal samples while keeping the rest of the samples as rare samples. Finally, we remove some of safe samples by using the random under-sampling (RUS) method and verify the effectiveness of the proposed algorithm through the comprehensive experimental analysis with considering several class imbalance datasets.},
  archive      = {J_AAI},
  author       = {Chun-Yang Peng and You-Jin Park},
  doi          = {10.1080/08839514.2021.1975393},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 1975393},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A new hybrid under-sampling approach to imbalanced classification problems},
  volume       = {36},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
