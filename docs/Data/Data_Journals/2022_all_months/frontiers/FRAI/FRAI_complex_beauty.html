<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FRAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frai---299">FRAI - 299</h2>
<ul>
<li><details>
<summary>
(2022). Editorial: AI and healthcare financial management (HFM)
towards sustainable development. <em>FRAI</em>, <em>5</em>, 1096496. (<a
href="https://doi.org/10.3389/frai.2022.1096496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Rao, Ananth and Manoj Kumar, M. V. and Sashtry, Nanda Kumar B. V. S. and Moonesar, Immanuel Azaad and Ramaprasad, Arkalgud and Núñez, Alicia and Annappa, B. and Bhanot, Karan and Mansoor, Wathiq},
  doi          = {10.3389/frai.2022.1096496},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1096496},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: AI and healthcare financial management (HFM) towards sustainable development},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable machine learning for predicting pathologic
complete response in patients treated with chemoradiation therapy for
rectal adenocarcinoma. <em>FRAI</em>, <em>5</em>, 1059033. (<a
href="https://doi.org/10.3389/frai.2022.1059033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposePathologic complete response (pCR) is a critical factor in determining whether patients with rectal cancer (RC) should have surgery after neoadjuvant chemoradiotherapy (nCRT). Currently, a pathologist&#39;s histological analysis of surgical specimens is necessary for a reliable assessment of pCR. Machine learning (ML) algorithms have the potential to be a non-invasive way for identifying appropriate candidates for non-operative therapy. However, these ML models&#39; interpretability remains challenging. We propose using explainable boosting machine (EBM) to predict the pCR of RC patients following nCRT.MethodsA total of 296 features were extracted, including clinical parameters (CPs), dose-volume histogram (DVH) parameters from gross tumor volume (GTV) and organs-at-risk, and radiomics (R) and dosiomics (D) features from GTV. R and D features were subcategorized into shape (S), first-order (L1), second-order (L2), and higher-order (L3) local texture features. Multi-view analysis was employed to determine the best set of input feature categories. Boruta was used to select all-relevant features for each input dataset. ML models were trained on 180 cases from our institution, with 37 cases from RTOG 0822 clinical trial serving as the independent dataset for model validation. The performance of EBM in predicting pCR on the test dataset was evaluated using ROC AUC and compared with that of three state-of-the-art black-box models: extreme gradient boosting (XGB), random forest (RF) and support vector machine (SVM). The predictions of all black-box models were interpreted using Shapley additive explanations.ResultsThe best input feature categories were CP+DVH+S+R_L1+R_L2 for all models, from which Boruta-selected features enabled the EBM, XGB, RF, and SVM models to attain the AUCs of 0.820, 0.828, 0.828, and 0.774, respectively. Although EBM did not achieve the best performance, it provided the best capability for identifying critical turning points in response scores at distinct feature values, revealing that the bladder with maximum dose &amp;gt;50 Gy, and the tumor with maximum2DDiameterColumn &amp;gt;80 mm, elongation &amp;lt;0.55, leastAxisLength &amp;gt;50 mm and lower variance of CT intensities were associated with unfavorable outcomes.ConclusionsEBM has the potential to enhance the physician&#39;s ability to evaluate an ML-based prediction of pCR and has implications for selecting patients for a “watchful waiting” strategy to RC therapy.},
  archive      = {J_FRAI},
  author       = {Wang, Du and Lee, Sang Ho and Geng, Huaizhi and Zhong, Haoyu and Plastaras, John and Wojcieszynski, Andrzej and Caruana, Richard and Xiao, Ying},
  doi          = {10.3389/frai.2022.1059033},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1059033},
  shortjournal = {Front. Artif. Intell.},
  title        = {Interpretable machine learning for predicting pathologic complete response in patients treated with chemoradiation therapy for rectal adenocarcinoma},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structuring ontologies from natural language for
collaborative scenario modeling in agri-food systems. <em>FRAI</em>,
<em>5</em>, 1056989. (<a
href="https://doi.org/10.3389/frai.2022.1056989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prospective studies require discussing and collaborating with the stakeholders to create scenarios of the possible evolution of the studied value-chain. However, stakeholders do not always use the same words when referring to one idea. Constructing an ontology and homogenizing vocabularies is thus crucial to identify key variables, which serve in the construction of the needed scenarios. Nevertheless, it is a very complex and time-consuming task. In this paper we present the method we used to manually build ontologies adapted to the needs of two complementary system-analysis models (namely the “Godet” and the “MyChoice” models), starting from interviews of the agri-food system&#39;s stakeholders. The objective of the paper is to explore whether and how prospective studies may have to gain from complementing the methodologies used (here Godet) with formal approaches from other disciplines, such as knowledge engineering (here MyChoice), which is usually not the case currently.},
  archive      = {J_FRAI},
  author       = {Chaib, Romy Lynn and Macombe, Catherine and Thomopoulos, Rallou},
  doi          = {10.3389/frai.2022.1056989},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1056989},
  shortjournal = {Front. Artif. Intell.},
  title        = {Structuring ontologies from natural language for collaborative scenario modeling in agri-food systems},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applications of contemporary artificial intelligence
technology in forensic odontology as primary forensic identifier: A
scoping review. <em>FRAI</em>, <em>5</em>, 1049584. (<a
href="https://doi.org/10.3389/frai.2022.1049584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundForensic odontology may require a visual or clinical method during identification. Sometimes it may require forensic experts to refer to the existing technique to identify individuals, for example, by using the atlas to estimate the dental age. However, the existing technology can be a complicated procedure for a large-scale incident requiring a more significant number of forensic identifications, particularly during mass disasters. This has driven many experts to perform automation in their current practice to improve efficiency.ObjectiveThis article aims to evaluate current artificial intelligence applications and discuss their performance concerning the algorithm architecture used in forensic odontology.MethodsThis study summarizes the findings of 28 research papers published between 2010 and June 2022 using the Arksey and O&#39;Malley framework, updated by the Joanna Briggs Institute Framework for Scoping Reviews methodology, highlighting the research trend of artificial intelligence technology in forensic odontology. In addition, a literature search was conducted on Web of Science (WoS), Scopus, Google Scholar, and PubMed, and the results were evaluated based on their content and significance.ResultsThe potential application of artificial intelligence technology in forensic odontology can be categorized into four: (1) human bite marks, (2) sex determination, (3) age estimation, and (4) dental comparison. This powerful tool can solve humanity&#39;s problems by giving an adequate number of datasets, the appropriate implementation of algorithm architecture, and the proper assignment of hyperparameters that enable the model to perform the prediction at a very high level of performance.ConclusionThe reviewed articles demonstrate that machine learning techniques are reliable for studies involving continuous features such as morphometric parameters. However, machine learning models do not strictly require large training datasets to produce promising results. In contrast, deep learning enables the processing of unstructured data, such as medical images, which require large volumes of data. Occasionally, transfer learning was used to overcome the limitation of data. In the meantime, this method&#39;s capacity to automatically learn task-specific feature representations has made it a significant success in forensic odontology.},
  archive      = {J_FRAI},
  author       = {Mohammad, Norhasmira and Ahmad, Rohana and Kurniawan, Arofi and Mohd Yusof, Mohd Yusmiaidil Putera},
  doi          = {10.3389/frai.2022.1049584},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1049584},
  shortjournal = {Front. Artif. Intell.},
  title        = {Applications of contemporary artificial intelligence technology in forensic odontology as primary forensic identifier: A scoping review},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of COVID-19 detection and prediction approaches
using mobile devices, AI, and telemedicine. <em>FRAI</em>, <em>5</em>,
1034732. (<a href="https://doi.org/10.3389/frai.2022.1034732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 2019, the COVID-19 pandemic has had an extremely high impact on all facets of the society and will potentially have an everlasting impact for years to come. In response to this, over the past years, there have been a significant number of research efforts on exploring approaches to combat COVID-19. In this paper, we present a survey of the current research efforts on using mobile Internet of Thing (IoT) devices, Artificial Intelligence (AI), and telemedicine for COVID-19 detection and prediction. We first present the background and then present current research in this field. Specifically, we present the research on COVID-19 monitoring and detection, contact tracing, machine learning based approaches, telemedicine, and security. We finally discuss the challenges and the future work that lay ahead in this field before concluding this paper.},
  archive      = {J_FRAI},
  author       = {Shen, John and Ghatti, Siddharth and Levkov, Nate Ryan and Shen, Haiying and Sen, Tanmoy and Rheuban, Karen and Enfield, Kyle and Facteau, Nikki Reyer and Engel, Gina and Dowdell, Kim},
  doi          = {10.3389/frai.2022.1034732},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1034732},
  shortjournal = {Front. Artif. Intell.},
  title        = {A survey of COVID-19 detection and prediction approaches using mobile devices, AI, and telemedicine},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The turing teacher: Identifying core attributes for AI
learning in k-12. <em>FRAI</em>, <em>5</em>, 1031450. (<a
href="https://doi.org/10.3389/frai.2022.1031450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionArtificial intelligence in the educational domain has many uses; however, using AI specifically to enhance education and teaching in a K-12 environment poses the most significant challenges to its use. Beyond usage and application, the quality of the education is made even more arduous due to the dynamics of teaching primary and secondary school children, whose needs far exceed mere fact recollection. Utilizing prior research using AI in education and online education in the K-12 space, we explore some of the hurdles that AI applications face in K-12 teaching and provide core attributes for a “Turing Teacher,” i.e., an AI powered technology for learning, specifically targeting the K-12 space.MethodsUsing a survey, which included qualitative responses during the implementation of online learning during the Covid Pandemic, we analyze the results using univariate and multivariate tests and analyzed the qualitative responses to create core attributes needed for AI powered teaching technology.ResultsThe results present the challenges faced by any technology in an education setting and show that AI technology must help overcome negative feelings about technology in education. Further, the core attributes identified in the research must be addressed from the three stakeholder perspectives of teachers, parents and students.DiscussionWe present our findings and lay the groundwork for future research in the area of AI powered education. The Turing Teacher must be able to adapt and collaborate with real teachers and address the varying needs of students. In addition, we explore the use of AI technology as a means to close the digital divide in traditionally disadvantaged communities.},
  archive      = {J_FRAI},
  author       = {Pelaez, Alexander and Jacobson, Amal and Trias, Kara and Winston, Elaine},
  doi          = {10.3389/frai.2022.1031450},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1031450},
  shortjournal = {Front. Artif. Intell.},
  title        = {The turing teacher: Identifying core attributes for AI learning in K-12},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large-scale vietnamese point-of-interest classification
using weak labeling. <em>FRAI</em>, <em>5</em>, 1020532. (<a
href="https://doi.org/10.3389/frai.2022.1020532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-of-Interests (POIs) represent geographic location by different categories (e.g., touristic places, amenities, or shops) and play a prominent role in several location-based applications. However, the majority of POIs category labels are crowd-sourced by the community, thus often of low quality. In this paper, we introduce the first annotated dataset for the POIs categorical classification task in Vietnamese. A total of 750,000 POIs are collected from WeMap, a Vietnamese digital map. Large-scale hand-labeling is inherently time-consuming and labor-intensive, thus we have proposed a new approach using weak labeling. As a result, our dataset covers 15 categories with 275,000 weak-labeled POIs for training, and 30,000 gold-standard POIs for testing, making it the largest compared to the existing Vietnamese POIs dataset. We empirically conduct POI categorical classification experiments using a strong baseline (BERT-based fine-tuning) on our dataset and find that our approach shows high efficiency and is applicable on a large scale. The proposed baseline gives an F1 score of 90% on the test dataset, and significantly improves the accuracy of WeMap POI data by a margin of 37% (from 56 to 93%).},
  archive      = {J_FRAI},
  author       = {Tran, Van Trung and Le, Quang Dao and Pham, Bao Son and Luu, Viet Hung and Bui, Quang Hung},
  doi          = {10.3389/frai.2022.1020532},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1020532},
  shortjournal = {Front. Artif. Intell.},
  title        = {Large-scale vietnamese point-of-interest classification using weak labeling},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Targeting resources efficiently and justifiably by combining
causal machine learning and theory. <em>FRAI</em>, <em>5</em>, 1015604.
(<a href="https://doi.org/10.3389/frai.2022.1015604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionEfficient allocation of limited resources relies on accurate estimates of potential incremental benefits for each candidate. These heterogeneous treatment effects (HTE) can be estimated with properly specified theory-driven models and observational data that contain all confounders. Using causal machine learning to estimate HTE from big data offers higher benefits with limited resources by identifying additional heterogeneity dimensions and fitting arbitrary functional forms and interactions, but decisions based on black-box models are not justifiable.MethodsOur solution is designed to increase resource allocation efficiency, enhance the understanding of the treatment effects, and increase the acceptance of the resulting decisions with a rationale that is in line with existing theory. The case study identifies the right individuals to incentivize for increasing their physical activity to maximize the population&#39;s health benefits due to reduced diabetes and heart disease prevalence. We leverage large-scale data from multi-wave nationally representative health surveys and theory from the published global meta-analysis results. We train causal machine learning ensembles, extract the heterogeneity dimensions of the treatment effect, sign, and monotonicity of its moderators with explainable AI, and incorporate them into the theory-driven model with our generalized linear model with the qualitative constraint (GLM_QC) method.ResultsThe results show that the proposed methodology improves the expected health benefits for diabetes by 11% and for heart disease by 9% compared to the traditional approach of using the model specification from the literature and estimating the model with large-scale data. Qualitative constraints not only prevent counter-intuitive effects but also improve achieved benefits by regularizing the model.},
  archive      = {J_FRAI},
  author       = {Gur Ali, Ozden},
  doi          = {10.3389/frai.2022.1015604},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1015604},
  shortjournal = {Front. Artif. Intell.},
  title        = {Targeting resources efficiently and justifiably by combining causal machine learning and theory},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sentence-level complexity in russian: An evaluation of BERT
and graph neural networks. <em>FRAI</em>, <em>5</em>, 1008411. (<a
href="https://doi.org/10.3389/frai.2022.1008411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionSentence-level complexity evaluation (SCE) can be formulated as assigning a given sentence a complexity score: either as a category, or a single value. SCE task can be treated as an intermediate step for text complexity prediction, text simplification, lexical complexity prediction, etc. What is more, robust prediction of a single sentence complexity needs much shorter text fragments than the ones typically required to robustly evaluate text complexity. Morphosyntactic and lexical features have proved their vital role as predictors in the state-of-the-art deep neural models for sentence categorization. However, a common issue is the interpretability of deep neural network results.MethodsThis paper presents testing and comparing several approaches to predict both absolute and relative sentence complexity in Russian. The evaluation involves Russian BERT, Transformer, SVM with features from sentence embeddings, and a graph neural network. Such a comparison is done for the first time for the Russian language.Results and discussionPre-trained language models outperform graph neural networks, that incorporate the syntactical dependency tree of a sentence. The graph neural networks perform better than Transformer and SVM classifiers that employ sentence embeddings. Predictions of the proposed graph neural network architecture can be easily explained.},
  archive      = {J_FRAI},
  author       = {Ivanov, Vladimir Vladimirovich},
  doi          = {10.3389/frai.2022.1008411},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {1008411},
  shortjournal = {Front. Artif. Intell.},
  title        = {Sentence-level complexity in russian: An evaluation of BERT and graph neural networks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepCausality: A general AI-powered causal inference
framework for free text: A case study of LiverTox. <em>FRAI</em>,
<em>5</em>, 999289. (<a
href="https://doi.org/10.3389/frai.2022.999289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality plays an essential role in multiple scientific disciplines, including the social, behavioral, and biological sciences and portions of statistics and artificial intelligence. Manual-based causality assessment from a large number of free text-based documents is very time-consuming, labor-intensive, and sometimes even impractical. Herein, we proposed a general causal inference framework named DeepCausality to empirically estimate the causal factors for suspected endpoints embedded in the free text. The proposed DeepCausality seamlessly incorporates AI-powered language models, named entity recognition and Judea Pearl&#39;s Do-calculus, into a general framework for causal inference to fulfill different domain-specific applications. We exemplified the utility of the proposed DeepCausality framework by employing the LiverTox database to estimate idiosyncratic drug-induced liver injury (DILI)-related causal terms and generate a knowledge-based causal tree for idiosyncratic DILI patient stratification. Consequently, the DeepCausality yielded a prediction performance with an accuracy of 0.92 and an F-score of 0.84 for the DILI prediction. Notably, 90% of causal terms enriched by the DeepCausality were consistent with the clinical causal terms defined by the American College of Gastroenterology (ACG) clinical guideline for evaluating suspected idiosyncratic DILI (iDILI). Furthermore, we observed a high concordance of 0.91 between the iDILI severity scores generated by DeepCausality and domain experts. Altogether, the proposed DeepCausality framework could be a promising solution for causality assessment from free text and is publicly available through https://github.com/XingqiaoWang/https-github.com-XingqiaoWang-DeepCausality-LiverTox.},
  archive      = {J_FRAI},
  author       = {Wang, Xingqiao and Xu, Xiaowei and Tong, Weida and Liu, Qi and Liu, Zhichao},
  doi          = {10.3389/frai.2022.999289},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {999289},
  shortjournal = {Front. Artif. Intell.},
  title        = {DeepCausality: a general AI-powered causal inference framework for free text: a case study of LiverTox},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AmericasNLI: Machine translation and natural language
inference systems for indigenous languages of the americas.
<em>FRAI</em>, <em>5</em>, 995667. (<a
href="https://doi.org/10.3389/frai.2022.995667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Little attention has been paid to the development of human language technology for truly low-resource languages—i.e., languages with limited amounts of digitally available text data, such as Indigenous languages. However, it has been shown that pretrained multilingual models are able to perform crosslingual transfer in a zero-shot setting even for low-resource languages which are unseen during pretraining. Yet, prior work evaluating performance on unseen languages has largely been limited to shallow token-level tasks. It remains unclear if zero-shot learning of deeper semantic tasks is possible for unseen languages. To explore this question, we present AmericasNLI, a natural language inference dataset covering 10 Indigenous languages of the Americas. We conduct experiments with pretrained models, exploring zero-shot learning in combination with model adaptation. Furthermore, as AmericasNLI is a multiway parallel dataset, we use it to benchmark the performance of different machine translation models for those languages. Finally, using a standard transformer model, we explore translation-based approaches for natural language inference. We find that the zero-shot performance of pretrained models without adaptation is poor for all languages in AmericasNLI, but model adaptation via continued pretraining results in improvements. All machine translation models are rather weak, but, surprisingly, translation-based approaches to natural language inference outperform all other models on that task.},
  archive      = {J_FRAI},
  author       = {Kann, Katharina and Ebrahimi, Abteen and Mager, Manuel and Oncevay, Arturo and Ortega, John E. and Rios, Annette and Fan, Angela and Gutierrez-Vasques, Ximena and Chiruzzo, Luis and Giménez-Lugo, Gustavo A. and Ramos, Ricardo and Meza Ruiz, Ivan Vladimir and Mager, Elisabeth and Chaudhary, Vishrav and Neubig, Graham and Palmer, Alexis and Coto-Solano, Rolando and Vu, Ngoc Thang},
  doi          = {10.3389/frai.2022.995667},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {995667},
  shortjournal = {Front. Artif. Intell.},
  title        = {AmericasNLI: Machine translation and natural language inference systems for indigenous languages of the americas},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imagining the city in lockdown: Place in the COVID-19
self-recordings of the lothian diary project. <em>FRAI</em>, <em>5</em>,
945643. (<a href="https://doi.org/10.3389/frai.2022.945643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic brought about a profound change to the organization of space and time in our daily lives. In this paper we analyze the self-recorded audio/video diaries made by residents of Edinburgh and the Lothian counties during the first national lockdown. We identify three ways in which diarists describe a shift in place-time, or “chronotope”, in lockdown. We argue that the act of making a diary for an audience of the future prompts diarists to contrast different chronotopes, and each of these orientations illuminates the differential impact of the COVID-19 lockdowns across the community.},
  archive      = {J_FRAI},
  author       = {Cowie, Claire and Hall-Lew, Lauren and Elliott, Zuzana and Klingler, Anita and Markl, Nina and McNulty, Stephen Joseph},
  doi          = {10.3389/frai.2022.945643},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {945643},
  shortjournal = {Front. Artif. Intell.},
  title        = {Imagining the city in lockdown: Place in the COVID-19 self-recordings of the lothian diary project},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Research agenda for algorithmic fairness studies: Access to
justice lessons for interdisciplinary research. <em>FRAI</em>,
<em>5</em>, 882134. (<a
href="https://doi.org/10.3389/frai.2022.882134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access to justice is one of the fundamental legitimating principles underlying all modern Western legal systems, yet its role in critical algorithm studies remains underdeveloped. In historical and methodological terms, the access to justice movement showcased multi- and interdisciplinary research on legal phenomena. We argue that interdisciplinary research on AI ethics and regulation, datafication of society, and algorithmic governance could benefit from adopting access to justice as a vantage point for bridging the different approaches in the context of administering justice. To this end, we explore technological, legal, and societal intersections to demonstrate how law, social sciences, and algorithm studies could benefit from a historically more informed and holistic approach facilitating more “cost-effective” interdisciplinary research collaboration. Such approach could assist the substantive study of algorithmic fairness to contribute actionable systemic solutions on what we perceive as systemic challenges. We propose utilizing access to justice as a boundary object for interdisciplinary dialogue over algorithmic fairness while respecting the epistemic diversity of disciplines.},
  archive      = {J_FRAI},
  author       = {Kontiainen, Laura and Koulu, Riikka and Sankari, Suvi},
  doi          = {10.3389/frai.2022.882134},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {882134},
  shortjournal = {Front. Artif. Intell.},
  title        = {Research agenda for algorithmic fairness studies: Access to justice lessons for interdisciplinary research},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sentiment analysis approach to the prediction of market
volatility. <em>FRAI</em>, <em>5</em>, 836809. (<a
href="https://doi.org/10.3389/frai.2022.836809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction and quantification of future volatility and returns play an important role in financial modeling, both in portfolio optimisation and risk management. Natural language processing today allows one to process news and social media comments to detect signals of investors&#39; confidence. We have explored the relationship between sentiment extracted from financial news and tweets and FTSE100 movements. We investigated the strength of the correlation between sentiment measures on a given day and market volatility and returns observed the next day. We found that there is evidence of correlation between sentiment and stock market movements. Moreover, the sentiment captured from news headlines could be used as a signal to predict market returns; we also found that the same does not apply for volatility. However, for the sentiment found in Twitter comments we obtained, in a surprising finding, a correlation coefficient of –0.7 (p &amp;lt; 0.05), which indicates a strong negative correlation between negative sentiment captured from the tweets on a given day and the volatility observed the next day. It is important to keep in mind that stock volatility rises greatly when the market collapses but not symmetrically so when it goes up (the so-called leverage effect). We developed an accurate classifier for the prediction of market volatility in response to the arrival of new information by deploying topic modeling, based on Latent Dirichlet Allocation, in order to extract feature vectors from a collection of tweets and financial news. The obtained features were used as additional input to the classifier. Thanks to the combination of sentiment and topic modeling even on modest (essentially personal) architecture our classifier achieved a directional prediction accuracy for volatility of 63%.},
  archive      = {J_FRAI},
  author       = {Deveikyte, Justina and Geman, Helyette and Piccari, Carlo and Provetti, Alessandro},
  doi          = {10.3389/frai.2022.836809},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {12},
  pages        = {836809},
  shortjournal = {Front. Artif. Intell.},
  title        = {A sentiment analysis approach to the prediction of market volatility},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Perspectives for natural language processing
between AI, linguistics and cognitive science. <em>FRAI</em>,
<em>5</em>, 1059998. (<a
href="https://doi.org/10.3389/frai.2022.1059998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Lenci, Alessandro and Padó, Sebastian},
  doi          = {10.3389/frai.2022.1059998},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1059998},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Perspectives for natural language processing between AI, linguistics and cognitive science},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepHeartCT: A fully automatic artificial intelligence
hybrid framework based on convolutional neural network and multi-atlas
segmentation for multi-structure cardiac computed tomography angiography
image segmentation. <em>FRAI</em>, <em>5</em>, 1059007. (<a
href="https://doi.org/10.3389/frai.2022.1059007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac computed tomography angiography (CTA) is an emerging imaging modality for assessing coronary artery as well as various cardiovascular structures. Recently, deep learning (DL) methods have been successfully applied to many applications of medical image analysis including cardiac CTA structure segmentation. However, DL requires a large amounts of data and high-quality labels for training which can be burdensome to obtain due to its labor-intensive nature. In this study, we aim to develop a fully automatic artificial intelligence (AI) system, named DeepHeartCT, for accurate and rapid cardiac CTA segmentation based on DL. The proposed system was trained using a large clinical dataset with computer-generated labels to segment various cardiovascular structures including left and right ventricles (LV, RV), left and right atria (LA, RA), and LV myocardium (LVM). This new system was trained directly using high-quality computer labels generated from our previously developed multi-atlas based AI system. In addition, a reverse ranking strategy was proposed to assess the segmentation quality in the absence of manual reference labels. This strategy allowed the new framework to assemble optimal computer-generated labels from a large dataset for effective training of a deep convolutional neural network (CNN). A large clinical cardiac CTA studies (n = 1,064) were used to train and validate our framework. The trained model was then tested on another independent dataset with manual labels (n = 60). The Dice score, Hausdorff distance and mean surface distance were used to quantify the segmentation accuracy. The proposed DeepHeartCT framework yields a high median Dice score of 0.90 [interquartile range (IQR), 0.90–0.91], a low median Hausdorff distance of 7 mm (IQR, 4–15 mm) and a low mean surface distance of 0.80 mm (IQR, 0.57–1.29 mm) across all segmented structures. An additional experiment was conducted to evaluate the proposed DL-based AI framework trained with a small vs. large dataset. The results show our framework also performed well when trained on a small optimal training dataset (n = 110) with a significantly reduced training time. These results demonstrated that the proposed DeepHeartCT framework provides accurate and rapid cardiac CTA segmentation that can be readily generalized for handling large-scale medical imaging applications.},
  archive      = {J_FRAI},
  author       = {Bui, Vy and Hsu, Li-Yueh and Chang, Lin-Ching and Sun, An-Yu and Tran, Loc and Shanbhag, Sujata M. and Zhou, Wunan and Mehta, Nehal N. and Chen, Marcus Y.},
  doi          = {10.3389/frai.2022.1059007},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1059007},
  shortjournal = {Front. Artif. Intell.},
  title        = {DeepHeartCT: A fully automatic artificial intelligence hybrid framework based on convolutional neural network and multi-atlas segmentation for multi-structure cardiac computed tomography angiography image segmentation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence applied to omics data in liver
diseases: Enhancing clinical predictions. <em>FRAI</em>, <em>5</em>,
1050439. (<a href="https://doi.org/10.3389/frai.2022.1050439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid development of biotechnology has led to the generation of vast amounts of multi-omics data, necessitating the advancement of bioinformatics and artificial intelligence to enable computational modeling to diagnose and predict clinical outcome. Both conventional machine learning and new deep learning algorithms screen existing data unbiasedly to uncover patterns and create models that can be valuable in informing clinical decisions. We summarized published literature on the use of AI models trained on omics datasets, with and without clinical data, to diagnose, risk-stratify, and predict survivability of patients with non-malignant liver diseases. A total of 20 different models were tested in selected studies. Generally, the addition of omics data to regular clinical parameters or individual biomarkers improved the AI model performance. For instance, using NAFLD fibrosis score to distinguish F0-F2 from F3-F4 fibrotic stages, the area under the curve (AUC) was 0.87. When integrating metabolomic data by a GMLVQ model, the AUC drastically improved to 0.99. The use of RF on multi-omics and clinical data in another study to predict progression of NAFLD to NASH resulted in an AUC of 0.84, compared to 0.82 when using clinical data only. A comparison of RF, SVM and kNN models on genomics data to classify immune tolerant phase in chronic hepatitis B resulted in AUC of 0.8793–0.8838 compared to 0.6759–0.7276 when using various serum biomarkers. Overall, the integration of omics was shown to improve prediction performance compared to models built only on clinical parameters, indicating a potential use for personalized medicine in clinical setting.},
  archive      = {J_FRAI},
  author       = {Baciu, Cristina and Xu, Cherry and Alim, Mouaid and Prayitno, Khairunnadiya and Bhat, Mamatha},
  doi          = {10.3389/frai.2022.1050439},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1050439},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence applied to omics data in liver diseases: Enhancing clinical predictions},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum: DeepCarc: Deep learning-powered carcinogenicity
prediction using model-level representation. <em>FRAI</em>, <em>5</em>,
1046668. (<a href="https://doi.org/10.3389/frai.2022.1046668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Li, Ting and Tong, Weida and Roberts, Ruth and Liu, Zhichao and Thakkar, Shraddha},
  doi          = {10.3389/frai.2022.1046668},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1046668},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: DeepCarc: deep learning-powered carcinogenicity prediction using model-level representation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clear, easy, plain, and simple as keywords for text
simplification. <em>FRAI</em>, <em>5</em>, 1042258. (<a
href="https://doi.org/10.3389/frai.2022.1042258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we distinguish between four interconnected notions that recur in the literature on text simplification: clarity, easiness, plainness, and simplicity. While plain language and easy language have both been the subject of standardization efforts, there are few attempts to define text clarity and text simplicity. Indeed, in the definition of plain language, clarity has been favored at the expense of simplicity but is employed as a self-evident notion. Meanwhile, text simplicity suffers from a negative connotation and is more likely to be defined by its antonym, text complexity. In our analysis, we examine the current definitions of plain language and easy language and discuss common definitions of text clarity and text complexity. We propose a model of text simplification that can clarify the transition from specialized texts to plain language texts, and easy language texts. It is our contention that text simplification should be placed in a more general framework of discursive ergonomics.},
  archive      = {J_FRAI},
  author       = {Vecchiato, Sara},
  doi          = {10.3389/frai.2022.1042258},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1042258},
  shortjournal = {Front. Artif. Intell.},
  title        = {Clear, easy, plain, and simple as keywords for text simplification},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptability of AI for safety evaluation in regulatory
science: A case study of drug-induced liver injury. <em>FRAI</em>,
<em>5</em>, 1034631. (<a
href="https://doi.org/10.3389/frai.2022.1034631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has played a crucial role in advancing biomedical sciences but has yet to have the impact it merits in regulatory science. As the field advances, in silico and in vitro approaches have been evaluated as alternatives to animal studies, in a drive to identify and mitigate safety concerns earlier in the drug development process. Although many AI tools are available, their acceptance in regulatory decision-making for drug efficacy and safety evaluation is still a challenge. It is a common perception that an AI model improves with more data, but does reality reflect this perception in drug safety assessments? Importantly, a model aiming at regulatory application needs to take a broad range of model characteristics into consideration. Among them is adaptability, defined as the adaptive behavior of a model as it is retrained on unseen data. This is an important model characteristic which should be considered in regulatory applications. In this study, we set up a comprehensive study to assess adaptability in AI by mimicking the real-world scenario of the annual addition of new drugs to the market, using a model we previously developed known as DeepDILI for predicting drug-induced liver injury (DILI) with a novel Deep Learning method. We found that the target test set plays a major role in assessing the adaptive behavior of our model. Our findings also indicated that adding more drugs to the training set does not significantly affect the predictive performance of our adaptive model. We concluded that the proposed adaptability assessment framework has utility in the evaluation of the performance of a model over time.},
  archive      = {J_FRAI},
  author       = {Connor, Skylar and Li, Ting and Roberts, Ruth and Thakkar, Shraddha and Liu, Zhichao and Tong, Weida},
  doi          = {10.3389/frai.2022.1034631},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1034631},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adaptability of AI for safety evaluation in regulatory science: A case study of drug-induced liver injury},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An autoencoder-based deep learning method for genotype
imputation. <em>FRAI</em>, <em>5</em>, 1028978. (<a
href="https://doi.org/10.3389/frai.2022.1028978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genotype imputation has a wide range of applications in genome-wide association study (GWAS), including increasing the statistical power of association tests, discovering trait-associated loci in meta-analyses, and prioritizing causal variants with fine-mapping. In recent years, deep learning (DL) based methods, such as sparse convolutional denoising autoencoder (SCDA), have been developed for genotype imputation. However, it remains a challenging task to optimize the learning process in DL-based methods to achieve high imputation accuracy. To address this challenge, we have developed a convolutional autoencoder (AE) model for genotype imputation and implemented a customized training loop by modifying the training process with a single batch loss rather than the average loss over batches. This modified AE imputation model was evaluated using a yeast dataset, the human leukocyte antigen (HLA) data from the 1,000 Genomes Project (1KGP), and our in-house genotype data from the Louisiana Osteoporosis Study (LOS). Our modified AE imputation model has achieved comparable or better performance than the existing SCDA model in terms of evaluation metrics such as the concordance rate (CR), the Hellinger score, the scaled Euclidean norm (SEN) score, and the imputation quality score (IQS) in all three datasets. Taking the imputation results from the HLA data as an example, the AE model achieved an average CR of 0.9468 and 0.9459, Hellinger score of 0.9765 and 0.9518, SEN score of 0.9977 and 0.9953, and IQS of 0.9515 and 0.9044 at missing ratios of 10% and 20%, respectively. As for the results of LOS data, it achieved an average CR of 0.9005, Hellinger score of 0.9384, SEN score of 0.9940, and IQS of 0.8681 at the missing ratio of 20%. In summary, our proposed method for genotype imputation has a great potential to increase the statistical power of GWAS and improve downstream post-GWAS analyses.},
  archive      = {J_FRAI},
  author       = {Song, Meng and Greenbaum, Jonathan and Luttrell, Joseph and Zhou, Weihua and Wu, Chong and Luo, Zhe and Qiu, Chuan and Zhao, Lan Juan and Su, Kuan-Jui and Tian, Qing and Shen, Hui and Hong, Huixiao and Gong, Ping and Shi, Xinghua and Deng, Hong-Wen and Zhang, Chaoyang},
  doi          = {10.3389/frai.2022.1028978},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1028978},
  shortjournal = {Front. Artif. Intell.},
  title        = {An autoencoder-based deep learning method for genotype imputation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic modeling of student characteristics with
interaction and physiological data using machine learning: A review.
<em>FRAI</em>, <em>5</em>, 1015660. (<a
href="https://doi.org/10.3389/frai.2022.1015660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Student characteristics affect their willingness and ability to acquire new knowledge. Assessing and identifying the effects of student characteristics is important for online educational systems. Machine learning (ML) is becoming significant in utilizing learning data for student modeling, decision support systems, adaptive systems, and evaluation systems. The growing need for dynamic assessment of student characteristics in online educational systems has led to application of machine learning methods in modeling the characteristics. Being able to automatically model student characteristics during learning processes is essential for dynamic and continuous adaptation of teaching and learning to each student&#39;s needs. This paper provides a review of 8 years (from 2015 to 2022) of literature on the application of machine learning methods for automatic modeling of various student characteristics. The review found six student characteristics that can be modeled automatically and highlighted the data types, collection methods, and machine learning techniques used to model them. Researchers, educators, and online educational systems designers will benefit from this study as it could be used as a guide for decision-making when creating student models for adaptive educational systems. Such systems can detect students&#39; needs during the learning process and adapt the learning interventions based on the detected needs. Moreover, the study revealed the progress made in the application of machine learning for automatic modeling of student characteristics and suggested new future research directions for the field. Therefore, machine learning researchers could benefit from this study as they can further advance this area by investigating new, unexplored techniques and find new ways to improve the accuracy of the created student models.},
  archive      = {J_FRAI},
  author       = {Orji, Fidelia A. and Vassileva, Julita},
  doi          = {10.3389/frai.2022.1015660},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1015660},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automatic modeling of student characteristics with interaction and physiological data using machine learning: A review},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge and attitudes of medical students in lebanon
toward artificial intelligence: A national survey study. <em>FRAI</em>,
<em>5</em>, 1015418. (<a
href="https://doi.org/10.3389/frai.2022.1015418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeThis study assesses the knowledge and attitudes of medical students in Lebanon toward Artificial Intelligence (AI) in medical education. It also explores the students&#39; perspectives regarding the role of AI in medical education as a subject in the curriculum and a teaching tool.MethodsThis is a cross-sectional study using an online survey consisting of close-ended questions. The survey targets medical students at all medical levels across the 7 medical schools in Lebanon.ResultsA total of 206 medical students responded. When assessing AI knowledge sources (81.1%) got their information from the media as compared to (9.7%) from medical school curriculum. However, Students who learned the basics of AI as part of the medical school curriculum were more knowledge about AI than their peers who did not. Students in their clinical years appear to be more knowledgeable about AI in medicine. The advancements in AI affected the choice of specialty of around a quarter of the students (26.8%). Finally, only a quarter of students (26.5%) want to be assessed by AI, even though the majority (57.7%) reported that assessment by AI is more objective.ConclusionsEducation about AI should be incorporated in the medical school curriculum to improve the knowledge and attitudes of medical students. Improving AI knowledge in medical students will in turn increase acceptance of AI as a tool in medical education, thus unlocking its potential in revolutionizing medical education.},
  archive      = {J_FRAI},
  author       = {Doumat, George and Daher, Darine and Ghanem, Nadim-Nicolas and Khater, Beatrice},
  doi          = {10.3389/frai.2022.1015418},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1015418},
  shortjournal = {Front. Artif. Intell.},
  title        = {Knowledge and attitudes of medical students in lebanon toward artificial intelligence: A national survey study},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hammering with the telescope. <em>FRAI</em>, <em>5</em>,
1010219. (<a href="https://doi.org/10.3389/frai.2022.1010219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid pace in which various Artificial Intelligence and Machine Learning tools are developed, both within the research community and outside of it, often discourages the involved researchers from taking time to consider potential consequences and applications of the technical advances, especially the unintended ones. While there are notable exceptions to this “gold rush” tendency, individuals and groups providing careful analyses and recommendations for future actions, their adoption remains, at best, limited. This essay presents an analysis of the ethical (and not only) challenges connected with the applications of AI/ML methods in the socio-legal domain.},
  archive      = {J_FRAI},
  author       = {Sobkowicz, Pawel},
  doi          = {10.3389/frai.2022.1010219},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1010219},
  shortjournal = {Front. Artif. Intell.},
  title        = {Hammering with the telescope},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of user queries according to a hierarchical
medical procedure encoding system using an ensemble classifier.
<em>FRAI</em>, <em>5</em>, 1000283. (<a
href="https://doi.org/10.3389/frai.2022.1000283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Swiss classification of surgical interventions (CHOP) has to be used in daily practice by physicians to classify clinical procedures. Its purpose is to encode the delivered healthcare services for the sake of quality assurance and billing. For encoding a procedure, a code of a maximal of 6-digits has to be selected from the classification system, which is currently realized by a rule-based system composed of encoding experts and a manual search in the CHOP catalog. In this paper, we will investigate the possibility of automatic CHOP code generation based on a short query to enable automatic support of manual classification. The wide and deep hierarchy of CHOP and the differences between text used in queries and catalog descriptions are two apparent obstacles for training and deploying a learning-based algorithm. Because of these challenges, there is a need for an appropriate classification approach. We evaluate different strategies (multi-class non-terminal and per-node classifications) with different configurations so that a flexible modular solution with high accuracy and efficiency can be provided. The results clearly show that the per-node binary classification outperforms the non-terminal multi-class classification with an F1-micro measure between 92.6 and 94%. The hierarchical prediction based on per-node binary classifiers achieved a high exact match by the single code assignment on the 5-fold cross-validation. In conclusion, the hierarchical context from the CHOP encoding can be employed by both classifier training and representation learning. The hierarchical features have all shown improvement in the classification performances under different configurations, respectively: the stacked autoencoder and training examples aggregation using true path rules as well as the unified vocabulary space have largely increased the utility of hierarchical features. Additionally, the threshold adaption through Bayesian aggregation has largely increased the vertical reachability of the per node classification. All the trainable nodes can be triggered after the threshold adaption, while the F1 measures at code levels 3–6 have been increased from 6 to 89% after the threshold adaption.},
  archive      = {J_FRAI},
  author       = {Deng, Yihan and Denecke, Kerstin},
  doi          = {10.3389/frai.2022.1000283},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {1000283},
  shortjournal = {Front. Artif. Intell.},
  title        = {Classification of user queries according to a hierarchical medical procedure encoding system using an ensemble classifier},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CLIP knows image aesthetics. <em>FRAI</em>, <em>5</em>,
976235. (<a href="https://doi.org/10.3389/frai.2022.976235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most Image Aesthetic Assessment (IAA) methods use a pretrained ImageNet classification model as a base to fine-tune. We hypothesize that content classification is not an optimal pretraining task for IAA, since the task discourages the extraction of features that are useful for IAA, e.g., composition, lighting, or style. On the other hand, we argue that the Contrastive Language-Image Pretraining (CLIP) model is a better base for IAA models, since it has been trained using natural language supervision. Due to the rich nature of language, CLIP needs to learn a broad range of image features that correlate with sentences describing the image content, composition, environments, and even subjective feelings about the image. While it has been shown that CLIP extracts features useful for content classification tasks, its suitability for tasks that require the extraction of style-based features like IAA has not yet been shown. We test our hypothesis by conducting a three-step study, investigating the usefulness of features extracted by CLIP compared to features obtained from the last layer of a comparable ImageNet classification model. In each step, we get more computationally expensive. First, we engineer natural language prompts that let CLIP assess an image&#39;s aesthetic without adjusting any weights in the model. To overcome the challenge that CLIP&#39;s prompting only is applicable to classification tasks, we propose a simple but effective strategy to convert multiple prompts to a continuous scalar as required when predicting an image&#39;s mean aesthetic score. Second, we train a linear regression on the AVA dataset using image features obtained by CLIP&#39;s image encoder. The resulting model outperforms a linear regression trained on features from an ImageNet classification model. It also shows competitive performance with fully fine-tuned networks based on ImageNet, while only training a single layer. Finally, by fine-tuning CLIP&#39;s image encoder on the AVA dataset, we show that CLIP only needs a fraction of training epochs to converge, while also performing better than a fine-tuned ImageNet model. Overall, our experiments suggest that CLIP is better suited as a base model for IAA methods than ImageNet pretrained networks.},
  archive      = {J_FRAI},
  author       = {Hentschel, Simon and Kobs, Konstantin and Hotho, Andreas},
  doi          = {10.3389/frai.2022.976235},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {976235},
  shortjournal = {Front. Artif. Intell.},
  title        = {CLIP knows image aesthetics},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “Snake flu,” “killer bug,” and “chinese virus”: A
corpus-assisted critical discourse analysis of lexical choices in early
UK press coverage of the COVID-19 pandemic. <em>FRAI</em>, <em>5</em>,
970972. (<a href="https://doi.org/10.3389/frai.2022.970972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Now mostly known as “COVID-19” (or simply “Covid”), early discourse around the pandemic was characterized by a particularly large variation in naming choices (ranging from “new coronavirus” and “new respiratory disease” to “killer bug” and the racist term “Chinese virus”). The current study is situated within corpus-assisted discourse studies and analyses these naming choices in UK newspaper coverage (January–March 2020), focusing on terminology deemed “inappropriate” as per WHO guidelines on naming infectious diseases. The results show that 9% of all terms referring to COVID-19 or the virus causing it are “inappropriate” overall, with “inappropriate” naming being more prevalent (1) in tabloids than broadsheets and (2) in the period before compared to the period after the virus was officially named on 11th February, 2020. Selected examples within each of the categories of “inappropriate” names are explored in more detail [terms (1) inciting undue fear, (2) containing geographic locations, and (3) containing species of animals], and the findings are discussed with regard to the contribution of lexical choices to the reproduction of (racist and otherwise problematic) ideologies in mainstream media.},
  archive      = {J_FRAI},
  author       = {Kania, Ursula},
  doi          = {10.3389/frai.2022.970972},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {970972},
  shortjournal = {Front. Artif. Intell.},
  title        = {“Snake flu,” “killer bug,” and “Chinese virus”: A corpus-assisted critical discourse analysis of lexical choices in early UK press coverage of the COVID-19 pandemic},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A cognitive modeling approach to learning and using
reference biases in language. <em>FRAI</em>, <em>5</em>, 933504. (<a
href="https://doi.org/10.3389/frai.2022.933504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During real-time language processing, people rely on linguistic and non-linguistic biases to anticipate upcoming linguistic input. One of these linguistic biases is known as the implicit causality bias, wherein language users anticipate that certain entities will be rementioned in the discourse based on the entity&#39;s particular role in an expressed causal event. For example, when language users encounter a sentence like “Elizabeth congratulated Tina…” during real-time language processing, they seemingly anticipate that the discourse will continue about Tina, the object referent, rather than Elizabeth, the subject referent. However, it is often unclear how these reference biases are acquired and how exactly they get used during real-time language processing. In order to investigate these questions, we developed a reference learning model within the PRIMs cognitive architecture that simulated the process of predicting upcoming discourse referents and their linguistic forms. Crucially, across the linguistic input the model was presented with, there were asymmetries with respect to how the discourse continued. By utilizing the learning mechanisms of the PRIMs architecture, the model was able to optimize its predictions, ultimately leading to biased model behavior. More specifically, following subject-biased implicit causality verbs the model was more likely to predict that the discourse would continue about the subject referent, whereas following object-biased implicit causality verbs the model was more likely to predict that the discourse would continue about the object referent. In a similar fashion, the model was more likely to predict that subject referent continuations would be in the form of a pronoun, whereas object referent continuations would be in the form of a proper name. These learned biases were also shown to generalize to novel contexts in which either the verb or the subject and object referents were new. The results of the present study demonstrate that seemingly complex linguistic behavior can be explained by cognitively plausible domain-general learning mechanisms. This study has implications for psycholinguistic accounts of predictive language processing and language learning, as well as for theories of implicit causality and reference processing.},
  archive      = {J_FRAI},
  author       = {Toth, Abigail G. and Hendriks, Petra and Taatgen, Niels A. and van Rij, Jacolien},
  doi          = {10.3389/frai.2022.933504},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {933504},
  shortjournal = {Front. Artif. Intell.},
  title        = {A cognitive modeling approach to learning and using reference biases in language},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Use of AI to assess COVID-19 variant impacts on
hospitalization, ICU, and death. <em>FRAI</em>, <em>5</em>, 927203. (<a
href="https://doi.org/10.3389/frai.2022.927203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid spread of COVID-19 and its variants have devastated communities worldwide, and as the highly transmissible Omicron variant becomes the dominant strain of the virus in late 2021, the need to characterize and understand the difference between the new variant and its predecessors has been an increasing priority for public health authorities. Artificial Intelligence has played a significant role in the analysis of various facets of COVID-19 since the early stages of the pandemic. This study proposes the use of AI, specifically an XGBoost model, to quantify the impact of various medical risk factors (or “population features”) on the possibility of a patient outcome resulting in hospitalization, ICU admission, or death. The results are compared between the Delta and Omicron COVID-19 variants. Results indicated that older age and an unvaccinated patient status most consistently correspond as the most significant population features contributing to all three scenarios (hospitalization, ICU, death). The top 15 features for each variant-outcome scenario were determined, which most frequently included diabetes, cardiovascular disease, chronic kidney disease, and complications of pneumonia as highly significant population features contributing to serious illness outcomes. The Delta/Hospitalization model returned the highest performance metric scores for the area under the receiver operating characteristic (AUROC), F1, and Recall, while Omicron/ICU and Omicron/Hospitalization had the highest accuracy and precision values, respectively. The recall was found to be above 0.60 in most cases (with only two exceptions), indicating that the total number of false positives was generally minimized (accounting for more of the people who would theoretically require medical care).},
  archive      = {J_FRAI},
  author       = {Hilal, Waleed and Chislett, Michael G. and Snider, Brett and McBean, Edward A. and Yawney, John and Gadsden, S. Andrew},
  doi          = {10.3389/frai.2022.927203},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {927203},
  shortjournal = {Front. Artif. Intell.},
  title        = {Use of AI to assess COVID-19 variant impacts on hospitalization, ICU, and death},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explanatory machine learning for justified trust in human-AI
collaboration: Experiments on file deletion recommendations.
<em>FRAI</em>, <em>5</em>, 919534. (<a
href="https://doi.org/10.3389/frai.2022.919534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital age, saving and accumulating large amounts of digital data is a common phenomenon. However, saving does not only consume energy, but may also cause information overload and prevent people from staying focused and working effectively. We present and systematically examine an explanatory AI system (Dare2Del), which supports individuals to delete irrelevant digital objects. To give recommendations for the optimization of related human-computer interactions, we vary different design features (explanations, familiarity, verifiability) within and across three experiments (N1 = 61, N2 = 33, N3= 73). Moreover, building on the concept of distributed cognition, we check possible cross-connections between external (digital) and internal (human) memory. Specifically, we examine whether deleting external files also contributes to human forgetting of the related mental representations. Multilevel modeling results show the importance of presenting explanations for the acceptance of deleting suggestions in all three experiments, but also point to the need of their verifiability to generate trust in the system. However, we did not find clear evidence that deleting computer files contributes to human forgetting of the related memories. Based on our findings, we provide basic recommendations for the design of AI systems that can help to reduce the burden on people and the digital environment, and suggest directions for future research.},
  archive      = {J_FRAI},
  author       = {Göbel, Kyra and Niessen, Cornelia and Seufert, Sebastian and Schmid, Ute},
  doi          = {10.3389/frai.2022.919534},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {919534},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explanatory machine learning for justified trust in human-AI collaboration: Experiments on file deletion recommendations},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differences between remote and analog design thinking
through the lens of distributed cognition. <em>FRAI</em>, <em>5</em>,
915922. (<a href="https://doi.org/10.3389/frai.2022.915922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the huge surge in remote work all over the world caused by the COVID-19 pandemic, today&#39;s work is largely defined by tools for information exchange as well as new complex problems that must be solved. Design Thinking offers a well-known and established methodological approach for iterative, collaborative and interdisciplinary problem solving. Still, recent circumstances shed a new light on how to facilitate Design Thinking activities in a remote rather than an analog way. Due to Design Thinking&#39;s high production of artifacts and its focus on communication and interaction between team members, the theory of Distributed Cognition, specifically the Distributed Cognition for Teamwork (DiCoT) framework, provides an interesting perspective on the recent going-remote of Design Thinking activities. For this, we first highlight differences of analog vs. remote Design Thinking by analyzing corresponding literature from the recent years. Next, we apply the DiCoT framework to those findings, pointing out implications for practical facilitation of Design Thinking activities in an analog and remote setting. Finally, we discuss opportunities through artificial intelligence-based technologies and methods.},
  archive      = {J_FRAI},
  author       = {Wolferts, Daniel and Stein, Elisabeth and Bernards, Ann-Kathrin and Reiners, René},
  doi          = {10.3389/frai.2022.915922},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {915922},
  shortjournal = {Front. Artif. Intell.},
  title        = {Differences between remote and analog design thinking through the lens of distributed cognition},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Digital microscopy and artificial intelligence could
profoundly contribute to malaria diagnosis in elimination settings.
<em>FRAI</em>, <em>5</em>, 510483. (<a
href="https://doi.org/10.3389/frai.2022.510483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Beck, Hans-Peter},
  doi          = {10.3389/frai.2022.510483},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {11},
  pages        = {510483},
  shortjournal = {Front. Artif. Intell.},
  title        = {Digital microscopy and artificial intelligence could profoundly contribute to malaria diagnosis in elimination settings},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Biomedical informatics applications in rare
diseases. <em>FRAI</em>, <em>5</em>, 1051182. (<a
href="https://doi.org/10.3389/frai.2022.1051182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Zhu, Qian and Chen, Yong-Zi and Xu, Yanji},
  doi          = {10.3389/frai.2022.1051182},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1051182},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Biomedical informatics applications in rare diseases},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Explanation in human-AI systems. <em>FRAI</em>,
<em>5</em>, 1048568. (<a
href="https://doi.org/10.3389/frai.2022.1048568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Angelopoulou, Anastasia and Kapetanios, Epaminondas and Smith, David Harris and Steuber, Volker and Woll, Bencie and Zeller, Frauke},
  doi          = {10.3389/frai.2022.1048568},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1048568},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Explanation in human-AI systems},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adapting conversational strategies in information-giving
human-agent interaction. <em>FRAI</em>, <em>5</em>, 1029340. (<a
href="https://doi.org/10.3389/frai.2022.1029340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we focus on human-agent interaction where the role of the socially interactive agent is to optimize the amount of information to give to a user. In particular, we developed a dialog manager able to adapt the agent&#39;s conversational strategies to the preferences of the user it is interacting with to maximize the user&#39;s engagement during the interaction. For this purpose, we train an agent in interaction with a user using the reinforcement learning approach. The engagement of the user is measured using their non-verbal behaviors and turn-taking status. This measured engagement is used in the reward function, which balances the task of the agent (giving information) and its social goal (maintaining the user highly engaged). Agent&#39;s dialog acts may have different impact on the user&#39;s engagement depending on several factors, such as their personality, interest in the discussion topic, and attitude toward the agent. A subjective study was conducted with 120 participants to measure how third-party observers can perceive the adaptation of our dialog model. The results show that adapting the agent&#39;s conversational strategies has an influence on the participants&#39; perception.},
  archive      = {J_FRAI},
  author       = {Galland, Lucie and Pelachaud, Catherine and Pecune, Florian},
  doi          = {10.3389/frai.2022.1029340},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1029340},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adapting conversational strategies in information-giving human-agent interaction},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging artificial intelligence to optimize COVID-19
robust spread and vaccination roll-out strategies in southern africa.
<em>FRAI</em>, <em>5</em>, 1013010. (<a
href="https://doi.org/10.3389/frai.2022.1013010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of coronavirus in the year 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) prompted widespread illness, death, and extended economic devastation worldwide. In response, numerous countries, including Botswana and South Africa, instituted various clinical public health (CPH) strategies to mitigate and control the disease. However, the emergence of variants of concern (VOC), vaccine hesitancy, morbidity, inadequate and inequitable vaccine supply, and ineffective vaccine roll-out strategies caused continuous disruption of essential services. Based on Botswana and South Africa hospitalization and mortality data, we studied the impact of age and gender on disease severity. Comparative analysis was performed between the two countries to establish a vaccination strategy that could complement the existing CPH strategies. To optimize the vaccination roll-out strategy, artificial intelligence was used to identify the population groups in need of insufficient vaccines. We found that COVID-19 was associated with several comorbidities. However, hypertension and diabetes were more severe and common in both countries. The elderly population aged ≥60 years had 70% of major COVID-19 comorbidities; thus, they should be prioritized for vaccination. Moreover, we found that the Botswana and South Africa populations had similar COVID-19 mortality rates. Hence, our findings should be extended to the rest of Southern African countries since the population in this region have similar demographic and disease characteristics.},
  archive      = {J_FRAI},
  author       = {Mathaha, Thuso and Mafu, Mhlambululi and Mabikwa, Onkabetse V. and Ndenda, Joseph and Hillhouse, Gregory and Mellado, Bruce},
  doi          = {10.3389/frai.2022.1013010},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1013010},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging artificial intelligence to optimize COVID-19 robust spread and vaccination roll-out strategies in southern africa},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid model of complexity estimation: Evidence from
russian legal texts. <em>FRAI</em>, <em>5</em>, 1008530. (<a
href="https://doi.org/10.3389/frai.2022.1008530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a hybrid model for the estimation of the complexity of legal documents in Russian. The model consists of two main modules: linguistic feature extractor and a transformer-based neural encoder. The set of linguistic metrics includes both non-specific metrics traditionally used to predict complexity, as well as style-specific metrics developed in order to deal with the peculiarities of official texts. The model was trained on a dataset constructed from text sequences from Russian textbooks. Training data were collected on either subjects related to the topic of legal documents such as Jurisprudence, Economics, Social Sciences, or subjects characterized by the use of general languages such as Literature, History, and Culturology. The final set of materials used contain 48 thousand selected text blocks having various subjects and level-of-complexity identifiers. We have tested the baseline fine-tuned BERT model, models trained on linguistic features, and models trained on features in combination with BERT predictions. The scores show that a hybrid approach to complexity estimation can provide high-quality results in terms of different metrics. The model has been tested on three sets of legal documents.},
  archive      = {J_FRAI},
  author       = {Blinova, Olga and Tarasov, Nikita},
  doi          = {10.3389/frai.2022.1008530},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1008530},
  shortjournal = {Front. Artif. Intell.},
  title        = {A hybrid model of complexity estimation: Evidence from russian legal texts},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diversity in people’s reluctance to use medical artificial
intelligence: Identifying subgroups through latent profile analysis.
<em>FRAI</em>, <em>5</em>, 1006173. (<a
href="https://doi.org/10.3389/frai.2022.1006173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical artificial intelligence (AI) is important for future health care systems. Research on medical AI has examined people&#39;s reluctance to use medical AI from the knowledge, attitude, and behavioral levels in isolation using a variable-centered approach while overlooking the possibility that there are subpopulations of people who may differ in their combined level of knowledge, attitude and behavior. To address this gap in the literature, we adopt a person-centered approach employing latent profile analysis to consider people&#39;s medical AI objective knowledge, subjective knowledge, negative attitudes and behavioral intentions. Across two studies, we identified three distinct medical AI profiles that systemically varied according to people&#39;s trust in and perceived risk imposed by medical AI. Our results revealed new insights into the nature of people&#39;s reluctance to use medical AI and how individuals with different profiles may characteristically have distinct knowledge, attitudes and behaviors regarding medical AI.},
  archive      = {J_FRAI},
  author       = {Wang, Haixia and Sun, Qiaoqiao and Gu, Li and Lai, Kaisheng and He, Lingnan},
  doi          = {10.3389/frai.2022.1006173},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {1006173},
  shortjournal = {Front. Artif. Intell.},
  title        = {Diversity in people&#39;s reluctance to use medical artificial intelligence: Identifying subgroups through latent profile analysis},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Is it time we get real? A systematic review of the potential
of data-driven technologies to address teachers’ implicit biases.
<em>FRAI</em>, <em>5</em>, 994967. (<a
href="https://doi.org/10.3389/frai.2022.994967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven technologies for education, such as artificial intelligence in education (AIEd) systems, learning analytics dashboards, open learner models, and other applications, are often created with an aspiration to help teachers make better, evidence-informed decisions in the classroom. Addressing gender, racial, and other biases inherent to data and algorithms in such applications is seen as a way to increase the responsibility of these systems and has been the focus of much of the research in the field, including systematic reviews. However, implicit biases can also be held by teachers. To the best of our knowledge, this systematic literature review is the first of its kind to investigate what kinds of teacher biases have been impacted by data-driven technologies, how or if these technologies were designed to challenge these biases, and which strategies were most effective at promoting equitable teaching behaviors and decision making. Following PRISMA guidelines, a search of five databases returned n = 359 records of which only n = 2 studies by a single research team were identified as relevant. The findings show that there is minimal evidence that data-driven technologies have been evaluated in their capacity for supporting teachers to make less biased decisions or promote equitable teaching behaviors, even though this capacity is often used as one of the core arguments for the use of data-driven technologies in education. By examining these two studies in conjunction with related studies that did not meet the eligibility criteria during the full-text review, we reveal the approaches that could play an effective role in mitigating teachers&#39; biases, as well as ones that may perpetuate biases. We conclude by summarizing directions for future research that should seek to directly confront teachers&#39; biases through explicit design strategies within teacher tools, to ensure that the impact of biases of both technology (including data, algorithms, models etc.) and teachers are minimized. We propose an extended framework to support future research and design in this area, through motivational, cognitive, and technological debiasing strategies.},
  archive      = {J_FRAI},
  author       = {Gauthier, Andrea and Rizvi, Saman and Cukurova, Mutlu and Mavrikis, Manolis},
  doi          = {10.3389/frai.2022.994967},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {994967},
  shortjournal = {Front. Artif. Intell.},
  title        = {Is it time we get real? a systematic review of the potential of data-driven technologies to address teachers&#39; implicit biases},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating distribution shifts for predicting cross-subject
generalization in electroencephalography-based mental workload
assessment. <em>FRAI</em>, <em>5</em>, 992732. (<a
href="https://doi.org/10.3389/frai.2022.992732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessment of mental workload in real-world conditions is key to ensuring the performance of workers executing tasks that demand sustained attention. Previous literature has employed electroencephalography (EEG) to this end despite having observed that EEG correlates of mental workload vary across subjects and physical strain, thus making it difficult to devise models capable of simultaneously presenting reliable performance across users. Domain adaptation consists of a set of strategies that aim at allowing for improving machine learning systems performance on unseen data at training time. Such methods, however, might rely on assumptions over the considered data distributions, which typically do not hold for applications of EEG data. Motivated by this observation, in this work we propose a strategy to estimate two types of discrepancies between multiple data distributions, namely marginal and conditional shifts, observed on data collected from different subjects. Besides shedding light on the assumptions that hold for a particular dataset, the estimates of statistical shifts obtained with the proposed approach can be used for investigating other aspects of a machine learning pipeline, such as quantitatively assessing the effectiveness of domain adaptation strategies. In particular, we consider EEG data collected from individuals performing mental tasks while running on a treadmill and pedaling on a stationary bike and explore the effects of different normalization strategies commonly used to mitigate cross-subject variability. We show the effects that different normalization schemes have on statistical shifts and their relationship with the accuracy of mental workload prediction as assessed on unseen participants at training time.},
  archive      = {J_FRAI},
  author       = {Albuquerque, Isabela and Monteiro, João and Rosanne, Olivier and Falk, Tiago H.},
  doi          = {10.3389/frai.2022.992732},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {992732},
  shortjournal = {Front. Artif. Intell.},
  title        = {Estimating distribution shifts for predicting cross-subject generalization in electroencephalography-based mental workload assessment},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotional characteristic analysis of human gait while
real-time movie viewing. <em>FRAI</em>, <em>5</em>, 989860. (<a
href="https://doi.org/10.3389/frai.2022.989860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition is useful in many applications such as preventing crime or improving customer satisfaction. Most of current methods are performed using facial features, which require close-up face information. Such information is difficult to capture with normal security cameras. The advantage of using gait and posture over conventional biometrics such as facial features is that gaits and postures can be obtained unobtrusively from faraway, even in a noisy environment. This study aims to investigate and analyze the relationship between human emotions and their gaits or postures. We collected a dataset made from the input of 49 participants for our experiments. Subjects were instructed to walk naturally in a circular walking path, while watching emotion-inducing videos on Microsoft HoloLens 2 smart glasses. An OptiTrack motion-capturing system was used for recording the gaits and postures of participants. The angles between body parts and walking straightness were calculated as features for comparison of body-part movements while walking under different emotions. Results of statistical analyses show that the subjects&#39; arm swings are significantly different among emotions. And the arm swings on one side of the body could reveal subjects&#39; emotions more obviously than those on the other side. Our results suggest that the arm movements together with information of arm side and walking straightness can reveal the subjects&#39; current emotions while walking. That is, emotions of humans are unconsciously expressed by their arm swings, especially by the left arm, when they are walking in a non-straight walking path. We found that arm swings in happy emotion are larger than arm swings in sad emotion. To the best of our knowledge, this study is the first to perform emotion induction by showing emotion-inducing videos to the participants using smart glasses during walking instead of showing videos before walking. This induction method is expected to be more consistent and more realistic than conventional methods. Our study will be useful for implementation of emotion recognition applications in real-world scenarios, since our emotion induction method and the walking direction we used are designed to mimic the real-time emotions of humans as they walk in a non-straight walking direction.},
  archive      = {J_FRAI},
  author       = {Jianwattanapaisarn, Nitchan and Sumi, Kaoru and Utsumi, Akira and Khamsemanan, Nirattaya and Nattee, Cholwich},
  doi          = {10.3389/frai.2022.989860},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {989860},
  shortjournal = {Front. Artif. Intell.},
  title        = {Emotional characteristic analysis of human gait while real-time movie viewing},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Jersey number detection using synthetic data in a low-data
regime. <em>FRAI</em>, <em>5</em>, 988113. (<a
href="https://doi.org/10.3389/frai.2022.988113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Player identification is an essential and complex task in sports video analysis. Different strategies have been devised over the years and identification based on jersey numbers is one of the most common approaches given its versatility and relative simplicity. However, automatic detection of jersey numbers is challenging due to changing camera angles, low video resolution, small object size in wide-range shots, and transient changes in the player&#39;s posture and movement. In this paper, we present a novel approach for jersey number identification in a small, highly imbalanced dataset from the Seattle Seahawks practice videos. We generate novel synthetic datasets of different complexities to mitigate the data imbalance and scarcity in the samples. To show the effectiveness of our synthetic data generation, we use a multi-step strategy that enforces attention to a particular region of interest (player&#39;s torso), to identify jersey numbers. The solution first identifies and crops players in a frame using a person detection model, then utilizes a human pose estimation model to localize jersey numbers in the detected players, obviating the need for annotating bounding boxes for number detection. We experimented with two sets of Convolutional Neural Networks (CNNs) with different learning objectives: multi-class for two-digit number identification and multi-label for digit-wise detection to compare performance. Our experiments indicate that our novel synthetic data generation method improves the accuracy of various CNN models by 9% overall, and 18% on low frequency numbers.},
  archive      = {J_FRAI},
  author       = {Bhargavi, Divya and Gholami, Sia and Pelaez Coyotl, Erika},
  doi          = {10.3389/frai.2022.988113},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {988113},
  shortjournal = {Front. Artif. Intell.},
  title        = {Jersey number detection using synthetic data in a low-data regime},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Developing and testing a prediction model for periodontal
disease using machine learning and big electronic dental record data.
<em>FRAI</em>, <em>5</em>, 979525. (<a
href="https://doi.org/10.3389/frai.2022.979525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite advances in periodontal disease (PD) research and periodontal treatments, 42% of the US population suffer from periodontitis. PD can be prevented if high-risk patients are identified early to provide preventive care. Prediction models can help assess risk for PD before initiation and progression; nevertheless, utilization of existing PD prediction models is seldom because of their suboptimal performance. This study aims to develop and test the PD prediction model using machine learning (ML) and electronic dental record (EDR) data that could provide large sample sizes and up-to-date information. A cohort of 27,138 dental patients and grouped PD diagnoses into: healthy control, mild PD, and severe PD was generated. The ML model (XGBoost) was trained (80% training data) and tested (20% testing data) with a total of 74 features extracted from the EDR. We used a five-fold cross-validation strategy to identify the optimal hyperparameters of the model for this one-vs.-all multi-class classification task. Our prediction model differentiated healthy patients vs. mild PD cases and mild PD vs. severe PD cases with an average area under the curve of 0.72. New associations and features compared to existing models were identified that include patient-level factors such as patient anxiety, chewing problems, speaking trouble, teeth grinding, alcohol consumption, injury to teeth, presence of removable partial dentures, self-image, recreational drugs (Heroin and Marijuana), medications affecting periodontium, and medical conditions such as osteoporosis, cancer, neurological conditions, infectious diseases, endocrine conditions, cardiovascular diseases, and gastroenterology conditions. This pilot study demonstrated promising results in predicting the risk of PD using ML and EDR data. The model may provide new information to the clinicians about the PD risks and the factors responsible for the disease progression to take preventive approaches. Further studies are warned to evaluate the prediction model&#39;s performance on the external dataset and determine its usability in clinical settings.},
  archive      = {J_FRAI},
  author       = {Patel, Jay S. and Su, Chang and Tellez, Marisol and Albandar, Jasim M. and Rao, Rishi and Iyer, Vishnu and Shi, Evan and Wu, Huanmei},
  doi          = {10.3389/frai.2022.979525},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {979525},
  shortjournal = {Front. Artif. Intell.},
  title        = {Developing and testing a prediction model for periodontal disease using machine learning and big electronic dental record data},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring gender biases in ML and AI academic research
through systematic literature review. <em>FRAI</em>, <em>5</em>, 976838.
(<a href="https://doi.org/10.3389/frai.2022.976838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated systems that implement Machine learning (ML) and Artificial Intelligence (AI) algorithms present promising solutions to a variety of technological and non-technological issues. Although, industry leaders are rapidly adopting these systems for anything from marketing to national defense operations, these systems are not without flaws. Recently, many of these systems are found to inherit and propagate gender and racial biases that disadvantages the minority population. In this paper, we analyze academic publications in the area of gender biases in ML and AI algorithms thus outlining different themes, mitigation and detection methods explored through research in this topic. Through a detailed analysis of N = 120 papers, we map the current research landscape on gender specific biases present in ML and AI assisted automated systems. We further point out the aspects of ML/AI gender biases research that are less explored and require more attention. Mainly we focus on the lack of user studies and inclusivity in this field of study. We also shed some light into the gender bias issue as experienced by the algorithm designers. In conclusion, in this paper we provide a holistic view of the breadth of studies conducted in the field of exploring, detecting and mitigating gender biases in ML and AI systems and, a future direction for the studies to take in order to provide a fair and accessible ML and AI systems to all users.},
  archive      = {J_FRAI},
  author       = {Shrestha, Sunny and Das, Sanchari},
  doi          = {10.3389/frai.2022.976838},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {976838},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring gender biases in ML and AI academic research through systematic literature review},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cutting-edge communication and learning assistive
technologies for disabled children: An artificial intelligence
perspective. <em>FRAI</em>, <em>5</em>, 970430. (<a
href="https://doi.org/10.3389/frai.2022.970430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study we provide an in-depth review and analysis of the impact of artificial intelligence (AI) components and solutions that support the development of cutting-edge assistive technologies for children with special needs. Various disabilities are addressed and the most recent assistive technologies that enhance communication and education of disabled children, as well as the AI technologies that have enabled their development, are presented. The paper summarizes with an AI perspective on future assistive technologies and ethical concerns arising from the use of such cutting-edge communication and learning technologies for children with disabilities.},
  archive      = {J_FRAI},
  author       = {Zdravkova, Katerina and Krasniqi, Venera and Dalipi, Fisnik and Ferati, Mexhid},
  doi          = {10.3389/frai.2022.970430},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {970430},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cutting-edge communication and learning assistive technologies for disabled children: An artificial intelligence perspective},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring neural question generation for formal pragmatics:
Data set and model evaluation. <em>FRAI</em>, <em>5</em>, 966013. (<a
href="https://doi.org/10.3389/frai.2022.966013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide the first openly-available German QUestion-Answer Congruence Corpus (QUACC), designed for the task of sentence-based question generation with question-answer congruence. Based on this corpus, we establish suitable baselines for question generation, comparing systems of very different nature. Question generation is an interesting challenge in particular for current neural network architectures given that it combines aspects of language meaning and forms in complex ways. The systems have to generate question phrases appropriately linking to the meaning of the envisaged answer phrases, and they have to learn to generate well-formed questions using the source. We show that our QUACC corpus is well-suited to investigate the performance of various neural models and gain insights about the specific error sources.},
  archive      = {J_FRAI},
  author       = {De Kuthy, Kordula and Kannan, Madeeswaran and Santhi Ponnusamy, Haemanth and Meurers, Detmar},
  doi          = {10.3389/frai.2022.966013},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {966013},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring neural question generation for formal pragmatics: Data set and model evaluation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intersemiotic translation of contracts into digital
environments. <em>FRAI</em>, <em>5</em>, 963692. (<a
href="https://doi.org/10.3389/frai.2022.963692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intersemiotic translation is any form of translation that involves at least two different semiotic codes; for example, the translation from words to images, to numerical code, or to non-verbal sounds. One of the most widespread examples of intersemiotic translation in the contemporary world is transposing natural language into machine language in digital environments. In this case, if the source text is a legal text, we encounter a particular type of intersemiotic translation, namely an intersemiotic legal translation in a digital environment. This paper will focus on the intersemiotic legal translation of contracts in digital environments, and is divided into two parts. In the first part (Section Ways of intersemiotically translating a contract using digital tools), we will analyze four possible uses of the intersemiotic translation of contracts in a digital context. In particular, we will highlight the technical characteristics of intersemiotic translation, its limitations, and its potential in different phases of contract management, namely the drafting of the document, the agreement, the archiving of the document, and the execution of contractual clauses. We will examine different digital tools that exploit intersemiotic translation, such as contract drafting tools and online platforms that allow for the conclusion of electronic contracts, document archiving in blockchains, and building smart contracts. When analyzing these uses of intersemiotic translation in the digital environment, we will highlight four types of output that can represent the product of intersemiotic translation in the digital environment: epistemic effects, legal effects, digital effects, and economic effects. In the second part (Section A tool for translating the contract intersemiotically), we will describe a hypothetical prototype that, in light of the four potential uses of intersemiotic translation, could represent a support tool to simplify the communication between professionals and clients through the drafting of legal documents with the aid of dynamic forms and, eventually, with the help of artificial intelligence (AI). Beyond facilitating the dialogue between legal professionals and their clients, we use interfaces to allow clients to create their own drafts of their documents and the lawyer to work on the drafts drawn up by the customer, correct them, and structure them in order to guarantee the validity of the document. The system can also be designed to archive legal documents and private deeds securely and entrust them to a professional by using blockchain technology and automating the execution of some contractual clauses via smart contract protocols.},
  archive      = {J_FRAI},
  author       = {Loddo, Olimpia Giuliana and Addis, Andrea and Lorini, Giuseppe},
  doi          = {10.3389/frai.2022.963692},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {963692},
  shortjournal = {Front. Artif. Intell.},
  title        = {Intersemiotic translation of contracts into digital environments},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence assisted acute patient journey.
<em>FRAI</em>, <em>5</em>, 962165. (<a
href="https://doi.org/10.3389/frai.2022.962165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is taking the world by storm and soon will be aiding patients in their journey at the hospital. The trials and tribulations of the healthcare system during the COVID-19 pandemic have set the stage for shifting healthcare from a physical to a cyber-physical space. A physician can now remotely monitor a patient, admitting them only if they meet certain thresholds, thereby reducing the total number of admissions at the hospital. Coordination, communication, and resource management have been core issues for any industry. However, it is most accurate in healthcare. Both systems and providers are exhausted under the burden of increasing data and complexity of care delivery, increasing costs, and financial burden. Simultaneously, there is a digital transformation of healthcare in the making. This transformation provides an opportunity to create systems of care that are artificial intelligence-enabled. Healthcare resources can be utilized more justly. The wastage of financial and intellectual resources in an overcrowded healthcare system can be avoided by implementing IoT, telehealth, and AI/ML-based algorithms. It is imperative to consider the design principles of the patient&#39;s journey while simultaneously prioritizing a better user experience to alleviate physician concerns. This paper discusses the entire blueprint of the AI/ML-assisted patient journey and its impact on healthcare provision.},
  archive      = {J_FRAI},
  author       = {Nazir, Talha and Mushhood Ur Rehman, Muhammad and Asghar, Muhammad Roshan and Kalia, Junaid S.},
  doi          = {10.3389/frai.2022.962165},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {962165},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence assisted acute patient journey},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Argumentation: A calculus for human-centric AI.
<em>FRAI</em>, <em>5</em>, 955579. (<a
href="https://doi.org/10.3389/frai.2022.955579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to expose and analyze the potential foundational role of Argumentation for Human-Centric AI, and to present the main challenges for this foundational role to be realized in a way that will fit well with the wider requirements and challenges of Human-Centric AI. The central idea set forward is that by endowing machines with the ability to argue with forms of machine argumentation that are cognitively compatible with those of human argumentation, we will be able to support a naturally effective, enhancing and ethical human-machine cooperation and “social” integration.},
  archive      = {J_FRAI},
  author       = {Dietz, Emmanuelle and Kakas, Antonis and Michael, Loizos},
  doi          = {10.3389/frai.2022.955579},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {955579},
  shortjournal = {Front. Artif. Intell.},
  title        = {Argumentation: A calculus for human-centric AI},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review on AI safety in highly automated driving.
<em>FRAI</em>, <em>5</em>, 952773. (<a
href="https://doi.org/10.3389/frai.2022.952773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remarkable progress in the fields of machine learning (ML) and artificial intelligence (AI) has led to an increased number of applications of (data-driven) AI systems for the partial or complete control of safety-critical systems. Recently, ML solutions have been particularly popular. Such approaches are often met with concerns regarding their correct and safe execution, which is often caused by missing knowledge or intransparency of their exact functionality. The investigation and derivation of methods for the safety assessment of AI systems are thus of great importance. Among others, these issues are addressed in the field of AI Safety. The aim of this work is to provide an overview of this field by means of a systematic literature review with special focus on the area of highly automated driving, as well as to present a selection of approaches and methods for the safety assessment of AI systems. Particularly, validation, verification, and testing are considered in light of this context. In the review process, two distinguished classes of approaches have been identified: On the one hand established methods, either referring to already published standards or well-established concepts from multiple research areas outside ML and AI. On the other hand newly developed approaches, including methods tailored to the scope of ML and AI which gained importance only in recent years.},
  archive      = {J_FRAI},
  author       = {Wäschle, Moritz and Thaler, Florian and Berres, Axel and Pölzlbauer, Florian and Albers, Albert},
  doi          = {10.3389/frai.2022.952773},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {952773},
  shortjournal = {Front. Artif. Intell.},
  title        = {A review on AI safety in highly automated driving},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Error driven synapse augmented neurogenesis. <em>FRAI</em>,
<em>5</em>, 949707. (<a
href="https://doi.org/10.3389/frai.2022.949707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing the learning capabilities of the brain has the potential to revolutionize artificial intelligence. Humans display an impressive ability to acquire knowledge on the fly and immediately store it in a usable format. Parametric models of learning, such as gradient descent, focus on capturing the statistical properties of a data set. Information is precipitated into a network through repeated updates of connection weights in the direction gradients dictate will lead to less error. This work presents the EDN (Error Driven Neurogenesis) algorithm which explores how neurogenesis coupled with non-linear synaptic activations enables a biologically plausible mechanism to immediately store data in a one-shot, online fashion and readily apply it to a task without the need for parameter updates. Regression (auto-mpg) test error was reduced more than 135 times faster and converged to an error around three times smaller compared to gradient descent using ADAM optimization. EDN also reached the same level of performance in wine cultivar classification 25 times faster than gradient descent and twice as fast when applied to MNIST and the inverted pendulum (reinforcement learning).},
  archive      = {J_FRAI},
  author       = {Perrett, Adam and Furber, Steve B. and Rhodes, Oliver},
  doi          = {10.3389/frai.2022.949707},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {949707},
  shortjournal = {Front. Artif. Intell.},
  title        = {Error driven synapse augmented neurogenesis},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of elderly pain severity from automated video
clip facial action unit analysis: A study from a thai data repository.
<em>FRAI</em>, <em>5</em>, 942248. (<a
href="https://doi.org/10.3389/frai.2022.942248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data from 255 Thais with chronic pain were collected at Chiang Mai Medical School Hospital. After the patients self-rated their level of pain, a smartphone camera was used to capture faces for 10 s at a one-meter distance. For those unable to self-rate, a video recording was taken immediately after the move that causes the pain. The trained assistant rated each video clip for the pain assessment in advanced dementia (PAINAD). The pain was classified into three levels: mild, moderate, and severe. OpenFace© was used to convert the video clips into 18 facial action units (FAUs). Five classification models were used, including logistic regression, multilayer perception, naïve Bayes, decision tree, k-nearest neighbors (KNN), and support vector machine (SVM). Out of the models that only used FAU described in the literature (FAU 4, 6, 7, 9, 10, 25, 26, 27, and 45), multilayer perception is the most accurate, at 50%. The SVM model using FAU 1, 2, 4, 7, 9, 10, 12, 20, 25, and 45, and gender had the best accuracy of 58% among the machine learning selection features. Our open-source experiment for automatically analyzing video clips for FAUs is not robust for classifying pain in the elderly. The consensus method to transform facial recognition algorithm values comparable to the human ratings, and international good practice for reciprocal sharing of data may improve the accuracy and feasibility of the machine learning&#39;s facial pain rater.},
  archive      = {J_FRAI},
  author       = {Gomutbutra, Patama and Kittisares, Adisak and Sanguansri, Atigorn and Choosri, Noppon and Sawaddiruk, Passakorn and Fakfum, Puriwat and Lerttrakarnnon, Peerasak and Saralamba, Sompob},
  doi          = {10.3389/frai.2022.942248},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {942248},
  shortjournal = {Front. Artif. Intell.},
  title        = {Classification of elderly pain severity from automated video clip facial action unit analysis: A study from a thai data repository},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active learning for data efficient semantic segmentation of
canine bones in radiographs. <em>FRAI</em>, <em>5</em>, 939967. (<a
href="https://doi.org/10.3389/frai.2022.939967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray bone semantic segmentation is one crucial task in medical imaging. Due to deep learning&#39;s emergence, it was possible to build high-precision models. However, these models require a large quantity of annotated data. Furthermore, semantic segmentation requires pixel-wise labeling, thus being a highly time-consuming task. In the case of hip joints, there is still a need for increased anatomic knowledge due to the intrinsic nature of the femur and acetabulum. Active learning aims to maximize the model&#39;s performance with the least possible amount of data. In this work, we propose and compare the use of different queries, including uncertainty and diversity-based queries. Our results show that the proposed methods permit state-of-the-art performance using only 81.02% of the data, with &lt;mml:math id=&quot;M1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;-tex-caligraphic&quot;&gt;O&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt; time complexity.},
  archive      = {J_FRAI},
  author       = {Moreira da Silva, D. E. and Gonçalves, Lio and Franco-Gonçalo, Pedro and Colaço, Bruno and Alves-Pimenta, Sofia and Ginja, Mário and Ferreira, Manuel and Filipe, Vitor},
  doi          = {10.3389/frai.2022.939967},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {939967},
  shortjournal = {Front. Artif. Intell.},
  title        = {Active learning for data efficient semantic segmentation of canine bones in radiographs},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relation is an option for processing context information.
<em>FRAI</em>, <em>5</em>, 924688. (<a
href="https://doi.org/10.3389/frai.2022.924688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention mechanisms are one of the most frequently used architectures in the development of artificial intelligence because they can process contextual information efficiently. Various artificial intelligence architectures, such as Transformer for processing natural language, image data, etc., include the Attention. Various improvements have been made to enhance its performance since Attention is a powerful component to realize artificial intelligence. The time complexity of Attention depends on the square of the input sequence length. Developing methods to improve the time complexity of Attention is one of the most popular research topics. Attention is a mechanism that conveys contextual information of input sequences to downstream networks. Thus, if one wants to improve the performance of processing contextual information, the focus should not be confined only on improving Attention but also on devising other similar mechanisms as possible alternatives. In this study, we devised an alternative mechanism called “Relation” that can understand the context information of sequential data. Relation is easy to implement, and its time complexity depends only on the length of the sequences; a comparison of the performance of Relation and Attention on several benchmark datasets showed that the context processing capability of Relation is comparable to that of Attention but with less computation time. Processing contextual information at high speeds would be useful because natural language processing and biological sequence processing sometimes deal with very long sequences. Hence, Relation is an ideal option for processing context information.},
  archive      = {J_FRAI},
  author       = {Yamada, Kazunori D and Baladram, M. Samy and Lin, Fangzhou},
  doi          = {10.3389/frai.2022.924688},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {924688},
  shortjournal = {Front. Artif. Intell.},
  title        = {Relation is an option for processing context information},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning prediction of two-dimensional ocean dynamics
with wavelet-compressed data. <em>FRAI</em>, <em>5</em>, 923932. (<a
href="https://doi.org/10.3389/frai.2022.923932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge represented by the application of deep learning models to the prediction of ocean dynamics using datasets over a large region or with high spatial or temporal resolution In a previous study by the authors of this article, they showed that such a challenge could be met by using a divide and conquer approach. The domain was in fact split into multiple sub-regions, which were small enough to be predicted individually and in parallel with each other by a deep learning model. At each time step of the prediction process, the sub-model solutions would be merged at the boundary of each sub-region to remove discontinuities between consecutive domains in order to predict the evolution of the full domain. This approach led to the growth of non-dynamical errors that decreased the prediction skill of our model. In the study herein, we show that wavelets can be used to compress the data and reduce its dimension. Each compression level reduces by a factor of two the horizontal resolution of the dataset. We show that despite the loss of information, a level 3 compression produces an improved prediction of the ocean two-dimensional data in comparison to the divide and conquer approach. Our method is evaluated on the prediction of the sea surface height of the most energetic feature of the Gulf of Mexico, namely the Loop Current.},
  archive      = {J_FRAI},
  author       = {Muhamed Ali, Ali and Zhuang, Hanqi and Ibrahim, Ali K. and Wang, Justin L. and Chérubin, Laurent M.},
  doi          = {10.3389/frai.2022.923932},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {923932},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning prediction of two-dimensional ocean dynamics with wavelet-compressed data},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Judgment aggregation, discursive dilemma and reflective
equilibrium: Neural language models as self-improving doxastic agents.
<em>FRAI</em>, <em>5</em>, 900943. (<a
href="https://doi.org/10.3389/frai.2022.900943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural language models (NLMs) are susceptible to producing inconsistent output. This paper proposes a new diagnosis as well as a novel remedy for NLMs&#39; incoherence. We train NLMs on synthetic text corpora that are created by simulating text production in a society. For diagnostic purposes, we explicitly model the individual belief systems of artificial agents (authors) who produce corpus texts. NLMs, trained on those texts, can be shown to aggregate the judgments of individual authors during pre-training according to sentence-wise vote ratios (roughly, reporting frequencies), which inevitably leads to so-called discursive dilemmas: aggregate judgments are inconsistent even though all individual belief states are consistent. As a remedy for such inconsistencies, we develop a self-training procedure—inspired by the concept of reflective equilibrium—that effectively reduces the extent of logical incoherence in a model&#39;s belief system, corrects global mis-confidence, and eventually allows the model to settle on a new, epistemically superior belief state. Thus, social choice theory helps to understand why NLMs are prone to produce inconsistencies; epistemology suggests how to get rid of them.},
  archive      = {J_FRAI},
  author       = {Betz, Gregor and Richardson, Kyle},
  doi          = {10.3389/frai.2022.900943},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {900943},
  shortjournal = {Front. Artif. Intell.},
  title        = {Judgment aggregation, discursive dilemma and reflective equilibrium: Neural language models as self-improving doxastic agents},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying geopolitical event precursors using
attention-based LSTMs. <em>FRAI</em>, <em>5</em>, 893875. (<a
href="https://doi.org/10.3389/frai.2022.893875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting societal events such as civil unrest, mass protests, and violent conflicts is a challenging problem with several important real-world applications in planning and policy making. While traditional forecasting approaches have typically relied on historical time series for generating such forecasts, recent research has focused on using open source surrogate data for more accurate and timely forecasts. Furthermore, leveraging such data can also help to identify precursors of those events that can be used to gain insights into the generated forecasts. The key challenge is to develop a unified framework for forecasting and precursor identification that can deal with missing historical data. Other challenges include sufficient flexibility in handling different types of events and providing interpretable representations of identified precursors. Although existing methods exhibit promising performance for predictive modeling in event detection, these models do not adequately address the above challenges. Here, we propose a unified framework based on an attention-based long short-term memory (LSTM) model to simultaneously forecast events with sequential text datasets as well as identify precursors at different granularity such as documents and document excerpts. The key idea is to leverage word context in sequential and time-stamped documents such as news articles and blogs for learning a rich set of precursors. We validate the proposed framework by conducting extensive experiments with two real-world datasets—military action and violent conflicts in the Middle East and mass protests in Latin America. Our results show that overall, the proposed approach generates more accurate forecasts compared to the existing state-of-the-art methods, while at the same time producing a rich set of precursors for the forecasted events.},
  archive      = {J_FRAI},
  author       = {Hossain, K. S. M. Tozammel and Harutyunyan, Hrayr and Ning, Yue and Kennedy, Brendan and Ramakrishnan, Naren and Galstyan, Aram},
  doi          = {10.3389/frai.2022.893875},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {893875},
  shortjournal = {Front. Artif. Intell.},
  title        = {Identifying geopolitical event precursors using attention-based LSTMs},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The AI trilemma: Saving the planet without ruining our jobs.
<em>FRAI</em>, <em>5</em>, 886561. (<a
href="https://doi.org/10.3389/frai.2022.886561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digitalization and artificial intelligence increasingly affect the world of work. Rising risk of massive job losses have sparked technological fears. Limited income and productivity gains concentrated among a few tech companies are fueling inequalities. In addition, the increasing ecological footprint of digital technologies has become the focus of much discussion. This creates a trilemma of rising inequality, low productivity growth and high ecological costs brought by technological progress. How can this trilemma be resolved? Which digital applications should be promoted specifically? And what should policymakers do to address this trilemma? This contribution shows that policymakers should create suitable conditions to fully exploit the potential in the area of network applications (transport, information exchange, supply, provisioning) in order to reap maximum societal benefits that can be widely shared. This requires shifting incentives away from current uses toward those that can, at least partially, address the trilemma. The contribution analyses the scope and limits of current policy instruments in this regard and discusses alternative approaches that are more aligned with the properties of the emerging technological paradigm underlying the digital economy. In particular, it discusses the possibility of institutional innovations required to address the socio-economic challenges resulting from the technological innovations brought about by artificial intelligence.},
  archive      = {J_FRAI},
  author       = {Ernst, Ekkehard},
  doi          = {10.3389/frai.2022.886561},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {886561},
  shortjournal = {Front. Artif. Intell.},
  title        = {The AI trilemma: Saving the planet without ruining our jobs},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding heterogeneity of investor sentiment on social
media: A structural topic modeling approach. <em>FRAI</em>, <em>5</em>,
884699. (<a href="https://doi.org/10.3389/frai.2022.884699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investors nowadays post heterogeneous sentiments on social media about financial assets based on their trading preferences. However, existing works typically analyze the sentiment by its content only and do not account for investor profiles and trading preferences in different types of assets. This paper explicitly considers how investor sentiment about financial market events is shaped by the relative discussions of different types of investors. We leverage a large-scale financial social media dataset and employ a structural topic modeling approach to extract topical contents of investor sentiment across multiple finance-specific factors. The identified topics reveal important events related to the financial market and show strong heterogeneity in the social media content in terms of compositions of investor profiles, asset categories, and bullish/bearish sentiment. Results show that investors with different profiles and trading preferences tend to discuss financial markets with heterogeneous beliefs, leading to divergent opinions about those events regarding the topic prevalence and proportion. Moreover, our findings may shed light on the mechanism that underlies the efficient investor sentiment extraction and aggregation while considering the heterogeneity of investor sentiment across different dimensions.},
  archive      = {J_FRAI},
  author       = {Ji, Rongjiao and Han, Qiwei},
  doi          = {10.3389/frai.2022.884699},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {884699},
  shortjournal = {Front. Artif. Intell.},
  title        = {Understanding heterogeneity of investor sentiment on social media: A structural topic modeling approach},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The three-step persuasion model on YouTube: A grounded
theory study on persuasion in the protein supplements industry.
<em>FRAI</em>, <em>5</em>, 838377. (<a
href="https://doi.org/10.3389/frai.2022.838377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persuasion can be defined as an active attempt by a person to change the behavior and attitudes of others. The purposive attempt to influence one&#39;s behavior can originate from different areas, and people who are able to do so are often referred to as influencers. Social media platforms such as Instagram or YouTube have become crucial platforms for influencers who generate their income by recommending products and services to their followers, including cosmetics, multimedia articles or clothing. Studies indicate that influencers actively try to persuade the viewer to adopt specific desirable behavior by strategically altering their displayed behavior on social media. Such strategies have mainly been explored in the context of beauty products, where lack of expertise and misinformation might have few negative consequences. Less is known about strategies used in a health-sensitive context, such as nutritional supplements. This research addresses this gap and aims to understand persuasive techniques used by health professionals on YouTube to promote the use of protein supplements. This study is based on an interpretive paradigm using interpretive grounded theory to analyze 60 YouTube videos. We developed a three-step model of persuasion for YouTube videos consisting of the steps: reaching the message, staying on the message, and performing the action that the persuader desires. Our analysis resulted in five core themes that contributed to the persuasiveness of the analyzed YouTube videos. These themes included: Quality, curiosity, engagement, concretization, and genuineness. We conclude the paper with reflections on our model&#39;s theoretical and practical implications.},
  archive      = {J_FRAI},
  author       = {Tripathi, Jayanshi and de Vries, Roelof A. J. and Lemke, Mailin},
  doi          = {10.3389/frai.2022.838377},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {838377},
  shortjournal = {Front. Artif. Intell.},
  title        = {The three-step persuasion model on YouTube: A grounded theory study on persuasion in the protein supplements industry},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Schrödinger’s tree—on syntax and neural language models.
<em>FRAI</em>, <em>5</em>, 796788. (<a
href="https://doi.org/10.3389/frai.2022.796788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last half-decade, the field of natural language processing (NLP) has undergone two major transitions: the switch to neural networks as the primary modeling paradigm and the homogenization of the training regime (pre-train, then fine-tune). Amidst this process, language models have emerged as NLP&#39;s workhorse, displaying increasingly fluent generation capabilities and proving to be an indispensable means of knowledge transfer downstream. Due to the otherwise opaque, black-box nature of such models, researchers have employed aspects of linguistic theory in order to characterize their behavior. Questions central to syntax—the study of the hierarchical structure of language—have factored heavily into such work, shedding invaluable insights about models&#39; inherent biases and their ability to make human-like generalizations. In this paper, we attempt to take stock of this growing body of literature. In doing so, we observe a lack of clarity across numerous dimensions, which influences the hypotheses that researchers form, as well as the conclusions they draw from their findings. To remedy this, we urge researchers to make careful considerations when investigating coding properties, selecting representations, and evaluating via downstream tasks. Furthermore, we outline the implications of the different types of research questions exhibited in studies on syntax, as well as the inherent pitfalls of aggregate metrics. Ultimately, we hope that our discussion adds nuance to the prospect of studying language models and paves the way for a less monolithic perspective on syntax in this context.},
  archive      = {J_FRAI},
  author       = {Kulmizev, Artur and Nivre, Joakim},
  doi          = {10.3389/frai.2022.796788},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {10},
  pages        = {796788},
  shortjournal = {Front. Artif. Intell.},
  title        = {Schrödinger&#39;s tree—On syntax and neural language models},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Corrigendum: Poultry diseases diagnostics models using deep
learning. <em>FRAI</em>, <em>5</em>, 1016695. (<a
href="https://doi.org/10.3389/frai.2022.1016695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Machuve, Dina and Nwankwo, Ezinne and Mduma, Neema and Mbelwa, Jimmy},
  doi          = {10.3389/frai.2022.1016695},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1016695},
  shortjournal = {Front. Artif. Intell.},
  title        = {Corrigendum: Poultry diseases diagnostics models using deep learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge, attitude, and practice of artificial intelligence
among doctors and medical students in syria: A cross-sectional online
survey. <em>FRAI</em>, <em>5</em>, 1011524. (<a
href="https://doi.org/10.3389/frai.2022.1011524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence has been prevalent recently as its use in the medical field is noticed to be increased. However, middle east countries like Syria are deficient in multiple AI implementation methods in the field of medicine. So, holding these AI implementation methods in the medical field is necessary, which may be incredibly beneficial for making diagnosis more accessible and help in the treatment. This paper intends to determine AI&#39;s knowledge, attitude, and practice among doctors and medical students in Syria. A questionnaire conducted an online cross-sectional study on the google form website consisting of demographic data, knowledge, and perception of AI. There were 1,494 responses from both doctors and medical students. We included Syrian medical students and doctors who are currently residing in Syria. Of the 1,494 participants, 255 (16.9%) are doctors, while the other 1,252 (83.1%) are undergraduate medical students. About 1,055 (70%) participants have previous knowledge about AI. However, only 357 (23.7%) participants know about its application in the medical field. Most have shown positive attitudes toward its necessity in the medical field; 689 (45.7%) individuals strongly agree, and 628 (41.7%) agree. The undergraduate students had 3.327 times more adequate knowledge of AI than students in the first year. In contrast, the undergraduate 6th-year students had 2.868 times the attitude toward AI higher than students in the first year. The residents and assistant professors had 2.371 and 4.422 times the practice of AI higher than students, respectively. Although most physicians and medical students do not sufficiently understand AI and its significance in the medical field, they have favorable views regarding using AI in the medical field. Syrian medical authorities and international organizations should suggest including artificial intelligence in the medical field, particularly when training residents and fellowship physicians.},
  archive      = {J_FRAI},
  author       = {Swed, Sarya and Alibrahim, Hidar and Elkalagi, Nashaat Kamal Hamdy and Nasif, Mohamad Nour and Rais, Mohammed Amir and Nashwan, Abdulqadir J. and Aljabali, Ahmed and Elsayed, Mohamed and Sawaf, Bisher and Albuni, Mhd Kutaiba and Battikh, Elias and Elsharif, Leena Abdelwahab Mohamed and Ahmed, Safaa Mohamed Alsharief and Ahmed, Eman Mohammed Sharif and Othman, Zain Alabdeen and Alsaleh, Ahmad and Shoib, Sheikh},
  doi          = {10.3389/frai.2022.1011524},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1011524},
  shortjournal = {Front. Artif. Intell.},
  title        = {Knowledge, attitude, and practice of artificial intelligence among doctors and medical students in syria: A cross-sectional online survey},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Artificial intelligence in finance and industry:
Highlights from 6 european COST conferences. <em>FRAI</em>, <em>5</em>,
1007074. (<a href="https://doi.org/10.3389/frai.2022.1007074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Henrici, Andreas and Osterrieder, Jörg},
  doi          = {10.3389/frai.2022.1007074},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1007074},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: artificial intelligence in finance and industry: highlights from 6 european COST conferences},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated analysis of whole slide digital skin biopsy
images. <em>FRAI</em>, <em>5</em>, 1005086. (<a
href="https://doi.org/10.3389/frai.2022.1005086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rapidly increasing rate of melanoma diagnosis has been noted over the past three decades, and nearly 1 in 4 skin biopsies are diagnosed as melanocytic lesions. The gold standard for diagnosis of melanoma is the histopathological examination by a pathologist to analyze biopsy material at both the cellular and structural levels. A pathologist&#39;s diagnosis is often subjective and prone to variability, while deep learning image analysis methods may improve and complement current diagnostic and prognostic capabilities. Mitoses are important entities when reviewing skin biopsy cases as their presence carries prognostic information; thus, their precise detection is an important factor for clinical care. In addition, semantic segmentation of clinically important structures in skin biopsies might help the diagnosis pipeline with an accurate classification. We aim to provide prognostic and diagnostic information on skin biopsy images, including the detection of cellular level entities, segmentation of clinically important tissue structures, and other important factors toward the accurate diagnosis of skin biopsy images. This paper is an overview of our work on analysis of digital whole slide skin biopsy images, including mitotic figure (mitosis) detection, semantic segmentation, diagnosis, and analysis of pathologists&#39; viewing patterns, and with new work on melanocyte detection. Deep learning has been applied to our methods for all the detection, segmentation, and diagnosis work. In our studies, deep learning is proven superior to prior approaches to skin biopsy analysis. Our work on analysis of pathologists&#39; viewing patterns is the only such work in the skin biopsy literature. Our work covers the whole spectrum from low-level entities through diagnosis and understanding what pathologists do in performing their diagnoses.},
  archive      = {J_FRAI},
  author       = {Nofallah, Shima and Wu, Wenjun and Liu, Kechun and Ghezloo, Fatemeh and Elmore, Joann G. and Shapiro, Linda G.},
  doi          = {10.3389/frai.2022.1005086},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {1005086},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automated analysis of whole slide digital skin biopsy images},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Efficient AI in particle physics and
astrophysics. <em>FRAI</em>, <em>5</em>, 999173. (<a
href="https://doi.org/10.3389/frai.2022.999173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Duarte, Javier and Liu, Mia and Ngadiuba, Jennifer and Cuoco, Elena and Thaler, Jesse},
  doi          = {10.3389/frai.2022.999173},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {999173},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Efficient AI in particle physics and astrophysics},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SNPAAMapper-python: A highly efficient genome-wide SNP
variant analysis pipeline for next-generation sequencing data.
<em>FRAI</em>, <em>5</em>, 991733. (<a
href="https://doi.org/10.3389/frai.2022.991733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, there are many publicly available Next Generation Sequencing tools developed for variant annotation and classification. However, as modern sequencing technology produces more and more sequencing data, a more efficient analysis program is desired, especially for variant analysis. In this study, we updated SNPAAMapper, a variant annotation pipeline by converting perl codes to python for generating annotation output with an improved computational efficiency and updated information for broader applicability. The new pipeline written in Python can classify variants by region (Coding Sequence, Untranslated Regions, upstream, downstream, intron), predict amino acid change type (missense, nonsense, etc.), and prioritize mutation effects (e.g., synonymous &amp;gt; non-synonymous) while being faster and more efficient. Our new pipeline works in five steps. First, exon annotation files are generated. Next, the exon annotation files are processed, and gene mapping and feature information files are produced. Afterward, the python scrips classify the variants based on genomic regions and predict the amino acid change category. Lastly, another python script prioritizes and ranks the mutation effects of variants to output the result file. The Python version of SNPAAMapper accomplished the overall speed by running most annotation steps in a substantially shorter time. The Python script can classify variants by region in 53 s compared to 166 s for the Perl script in a test sample run on a Latitude 7480 Desktop computer with 8GB RAM and an Intel Core i5-6300 CPU @ 2.4Ghz. Steps of predicting amino acid change type and prioritizing mutation effects of variants were executed within 1 s for both pipelines. SNPAAMapper-Python was developed and tested on the ClinVar database, a NCBI database of information on genomic variation and its relationship to human health. We believe our developed Python version of SNPAAMapper variant annotation pipeline will benefit the community by elucidating the variant consequence and speed up the discovery of causative genetic variants through whole genome/exome sequencing. Source codes, test data files, instructions, and further explanations are available on the web at https://github.com/BaiLab/SNPAAMapper-Python.},
  archive      = {J_FRAI},
  author       = {Li, Chang and Ma, Kevin and Xu, Nicole and Fu, Chenjian and He, Andrew and Liu, Xiaoming and Bai, Yongsheng},
  doi          = {10.3389/frai.2022.991733},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {991733},
  shortjournal = {Front. Artif. Intell.},
  title        = {SNPAAMapper-python: A highly efficient genome-wide SNP variant analysis pipeline for next-generation sequencing data},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lexical simplification benchmarks for english, portuguese,
and spanish. <em>FRAI</em>, <em>5</em>, 991242. (<a
href="https://doi.org/10.3389/frai.2022.991242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even in highly-developed countries, as many as 15–30% of the population can only understand texts written using a basic vocabulary. Their understanding of everyday texts is limited, which prevents them from taking an active role in society and making informed decisions regarding healthcare, legal representation, or democratic choice. Lexical simplification is a natural language processing task that aims to make text understandable to everyone by replacing complex vocabulary and expressions with simpler ones, while preserving the original meaning. It has attracted considerable attention in the last 20 years, and fully automatic lexical simplification systems have been proposed for various languages. The main obstacle for the progress of the field is the absence of high-quality datasets for building and evaluating lexical simplification systems. In this study, we present a new benchmark dataset for lexical simplification in English, Spanish, and (Brazilian) Portuguese, and provide details about data selection and annotation procedures, to enable compilation of comparable datasets in other languages and domains. As the first multilingual lexical simplification dataset, where instances in all three languages were selected and annotated using comparable procedures, this is the first dataset that offers a direct comparison of lexical simplification systems for three languages. To showcase the usability of the dataset, we adapt two state-of-the-art lexical simplification systems with differing architectures (neural vs. non-neural) to all three languages (English, Spanish, and Brazilian Portuguese) and evaluate their performances on our new dataset. For a fairer comparison, we use several evaluation measures which capture varied aspects of the systems&#39; efficacy, and discuss their strengths and weaknesses. We find that a state-of-the-art neural lexical simplification system outperforms a state-of-the-art non-neural lexical simplification system in all three languages, according to all evaluation measures. More importantly, we find that the state-of-the-art neural lexical simplification systems perform significantly better for English than for Spanish and Portuguese, thus posing a question if such an architecture can be used for successful lexical simplification in other languages, especially the low-resourced ones.},
  archive      = {J_FRAI},
  author       = {Štajner, Sanja and Ferrés, Daniel and Shardlow, Matthew and North, Kai and Zampieri, Marcos and Saggion, Horacio},
  doi          = {10.3389/frai.2022.991242},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {991242},
  shortjournal = {Front. Artif. Intell.},
  title        = {Lexical simplification benchmarks for english, portuguese, and spanish},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Applications for open access normalized synthesis in
metastatic prostate cancer trials. <em>FRAI</em>, <em>5</em>, 984836.
(<a href="https://doi.org/10.3389/frai.2022.984836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent metastatic castration-resistant prostate cancer (mCRPC) clinical trials have integrated homologous recombination and DNA repair deficiency (HRD/DRD) biomarkers into eligibility criteria and secondary objectives. These trials led to the approval of some PARP inhibitors for mCRPC with HRD/DRD indications. Unfortunately, biomarker-trial outcome data is only discovered by reviewing publications, a process that is error-prone, time-consuming, and laborious. While prostate cancer researchers have written systematic evidence reviews (SERs) on this topic, given the time involved from the last search to publication, an SER is often outdated even before publication. The difficulty in reusing previous review data has resulted in multiple reviews of the same trials. Thus, it will be useful to create a normalized evidence base from recently published/presented biomarker-trial outcome data that one can quickly update. We present a new approach to semi-automating normalized, open-access data tables from published clinical trials of metastatic prostate cancer using a data curation and SER platform. Clinicaltrials.gov and Pubmed.gov were used to collect mCRPC clinical trial publications with HRD/DRD biomarkers. We extracted data from 13 publications covering ten trials that started before 22nd Apr 2021. We extracted 585 hazard ratios, response rates, duration metrics, and 543 adverse events. Across 334 patients, we also extracted 8,180 patient-level survival and biomarker values. Data tables were populated with survival metrics, raw patient data, eligibility criteria, adverse events, and timelines. A repeated strong association between HRD and improved PARP inhibitor response was observed. Several use cases for the extracted data are demonstrated via analyses of trial methods, comparison of treatment hazard ratios, and association of treatments with adverse events. Machine learning models are also built on combined and normalized patient data to demonstrate automated discovery of therapy/biomarker relationships. Overall, we demonstrate the value of systematically extracted and normalized data. We have also made our code open-source with simple instructions on updating the analyses as new data becomes available, which anyone can use even with limited programming knowledge. Finally, while we present a novel method of SER for mCRPC trials, one can also implement such semi-automated methods in other clinical trial domains to advance precision medicine.},
  archive      = {J_FRAI},
  author       = {Luechtefeld, Thomas and Bozada, Thomas and Goel, Rahul and Wang, Lin and Paller, Channing J.},
  doi          = {10.3389/frai.2022.984836},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {984836},
  shortjournal = {Front. Artif. Intell.},
  title        = {Applications for open access normalized synthesis in metastatic prostate cancer trials},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Creating a list of word alignments from parallel russian
simplification data. <em>FRAI</em>, <em>5</em>, 984759. (<a
href="https://doi.org/10.3389/frai.2022.984759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work describes the development of a list of monolingual word alignments taken from parallel Russian simplification data. This word lists can be used in such lexical simplification tasks as rule-based simplification applications and lexically constrained decoding for neural machine translation models. Moreover, they constitute a valuable source of information for developing educational materials for teaching Russian as a second/foreign language. In this work, a word list was compiled automatically and post-edited by human experts. The resulting list contains 1409 word pairs in which each “complex” word has an equivalent “simpler” (shorter, more frequent, modern, international) synonym. We studied the contents of the word list by comparing the frequencies of the words in the pairs and their levels in the special CEFR-graded vocabulary lists for learners of Russian as a foreign language. The evaluation demonstrated that lexical simplification by means of single-word synonym replacement does not occur often in the adapted texts. The resulting list also illustrates the peculiarities of the lexical simplification task for L2 learners, such as the choice of a less frequent but international word.},
  archive      = {J_FRAI},
  author       = {Dmitrieva, Anna and Laposhina, Antonina and Lebedeva, Maria Yuryevna},
  doi          = {10.3389/frai.2022.984759},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {984759},
  shortjournal = {Front. Artif. Intell.},
  title        = {Creating a list of word alignments from parallel russian simplification data},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). It’s not just a phase: Investigating text simplification in
a second language from a process and product perspective. <em>FRAI</em>,
<em>5</em>, 983008. (<a
href="https://doi.org/10.3389/frai.2022.983008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text simplification involves making texts easier to understand, usually for lay readers. Simplifying texts is a complex task, especially when conducted in a second language. The readability of the produced texts and the way in which authors manage the different phases of the text simplification process are influenced by their writing expertise and by their language proficiency. Training on audience awareness can be beneficial for writers, but most research so far has devoted attention to first-language writers who simplify their own texts. Therefore, this study investigated the impact of text simplification training on second-language writers (university students) who simplify already existing texts. Specifically, after identifying a first and a second phase in the text simplification process (namely, two distinct series of writing dynamics), we analyzed the impact of our training on pausing and revision behavior across phases, as well as levels of readability achieved by the students. Additionally, we examined correlations between pausing behavior and readability by using keystroke logging data and automated text analysis. We found that phases of text simplification differ along multiple dimensions, even though our training did not seem to influence pausing and revision dynamics. Our training led to texts with fewer and shorter words, and with syntactically simpler sentences. The correlation analysis showed that longer and more frequent pauses at specific text locations were linked with increased readability in the same or adjacent text locations. We conclude the paper by discussing theoretical, methodological, and pedagogical implications, alongside limitations and areas for future research.},
  archive      = {J_FRAI},
  author       = {Rossetti, Alessandra and Van Waes, Luuk},
  doi          = {10.3389/frai.2022.983008},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {983008},
  shortjournal = {Front. Artif. Intell.},
  title        = {It&#39;s not just a phase: Investigating text simplification in a second language from a process and product perspective},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Yes we care!-certification for machine learning methods
through the care label framework. <em>FRAI</em>, <em>5</em>, 975029. (<a
href="https://doi.org/10.3389/frai.2022.975029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning applications have become ubiquitous. Their applications range from embedded control in production machines over process optimization in diverse areas (e.g., traffic, finance, sciences) to direct user interactions like advertising and recommendations. This has led to an increased effort of making machine learning trustworthy. Explainable and fair AI have already matured. They address the knowledgeable user and the application engineer. However, there are users that want to deploy a learned model in a similar way as their washing machine. These stakeholders do not want to spend time in understanding the model, but want to rely on guaranteed properties. What are the relevant properties? How can they be expressed to the stake- holder without presupposing machine learning knowledge? How can they be guaranteed for a certain implementation of a machine learning model? These questions move far beyond the current state of the art and we want to address them here. We propose a unified framework that certifies learning methods via care labels. They are easy to understand and draw inspiration from well-known certificates like textile labels or property cards of electronic devices. Our framework considers both, the machine learning theory and a given implementation. We test the implementation&#39;s compliance with theoretical properties and bounds.},
  archive      = {J_FRAI},
  author       = {Morik, Katharina J. and Kotthaus, Helena and Fischer, Raphael and Mücke, Sascha and Jakobs, Matthias and Piatkowski, Nico and Pauly, Andreas and Heppe, Lukas and Heinrich, Danny},
  doi          = {10.3389/frai.2022.975029},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {975029},
  shortjournal = {Front. Artif. Intell.},
  title        = {Yes we care!-certification for machine learning methods through the care label framework},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Business analytics approach to artificial intelligence.
<em>FRAI</em>, <em>5</em>, 974180. (<a
href="https://doi.org/10.3389/frai.2022.974180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence has become an essential element for strengthening the business fabric. The advances obtained in recent years as a result of the incorporation of technology for the improvement of productive activities and the positioning of companies in the markets are remarkable. Hence, the purpose of this paper is to analyze the origin, evolution and development of business analytics (BA) and its relationship with Artificial Intelligence (AI); from the conceptualization, evolution and identification of the main characteristics and research areas of AI and BA, as well as research conducted and published in journals indexed in Scopus between 2002 and 2022. The aim is to define the incidence of BA in business activities and analyze scientific activity and advances of BA to define new research horizons in this field. For this purpose, a bibliometric and documentary analysis is applied, allowing to highlight the findings that provide recognition and comparison of the results. This will facilitate the understanding of the current dynamics, its importance for organizations, and its impact in the face of the new challenges generated by the requirements of world trade.},
  archive      = {J_FRAI},
  author       = {Gómez-Caicedo, Melva Inés and Gaitán-Angulo, Mercedes and Bacca-Acosta, Jorge and Briñez Torres, Carlos Yesid and Cubillos Díaz, Jenny},
  doi          = {10.3389/frai.2022.974180},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {974180},
  shortjournal = {Front. Artif. Intell.},
  title        = {Business analytics approach to artificial intelligence},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training and intrinsic evaluation of lightweight word
embeddings for the clinical domain in spanish. <em>FRAI</em>,
<em>5</em>, 970517. (<a
href="https://doi.org/10.3389/frai.2022.970517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resources for Natural Language Processing (NLP) are less numerous for languages different from English. In the clinical domain, where these resources are vital for obtaining new knowledge about human health and diseases, creating new resources for the Spanish language is imperative. One of the most common approaches in NLP is word embeddings, which are dense vector representations of a word, considering the word&#39;s context. This vector representation is usually the first step in various NLP tasks, such as text classification or information extraction. Therefore, in order to enrich Spanish language NLP tools, we built a Spanish clinical corpus from waiting list diagnostic suspicions, a biomedical corpus from medical journals, and term sequences sampled from the Unified Medical Language System (UMLS). These three corpora can be used to compute word embeddings models from scratch using Word2vec and fastText algorithms. Furthermore, to validate the quality of the calculated embeddings, we adapted several evaluation datasets in English, including some tests that have not been used in Spanish to the best of our knowledge. These translations were validated by two bilingual clinicians following an ad hoc validation standard for the translation. Even though contextualized word embeddings nowadays receive enormous attention, their calculation and deployment require specialized hardware and giant training corpora. Our static embeddings can be used in clinical applications with limited computational resources. The validation of the intrinsic test we present here can help groups working on static and contextualized word embeddings. We are releasing the training corpus and the embeddings within this publication1.},
  archive      = {J_FRAI},
  author       = {Chiu, Carolina and Villena, Fabián and Martin, Kinan and Núñez, Fredy and Besa, Cecilia and Dunstan, Jocelyn},
  doi          = {10.3389/frai.2022.970517},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {970517},
  shortjournal = {Front. Artif. Intell.},
  title        = {Training and intrinsic evaluation of lightweight word embeddings for the clinical domain in spanish},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of artificial intelligence based systems for cost
optimization in colorectal cancer prevention programs. <em>FRAI</em>,
<em>5</em>, 955399. (<a
href="https://doi.org/10.3389/frai.2022.955399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal Cancer (CRC) has seen a dramatic increase in incidence globally. In 2019, colorectal cancer accounted for 1.15 million deaths and 24.28 million disability-adjusted life-years (DALYs) worldwide. In India, the annual incidence rates (AARs) for colon cancer was 4.4 per 100,000. There has been a steady rise in the prevalence of CRC in India which may be attributed to urbanization, mass migration of population, westernization of diet and lifestyle practices and a rise of obesity and metabolic risk factors that place the population at a higher risk of CRC. Moreoever, CRC in India differs from that described in the Western countries, with a higher proportion of young patients and more patients presenting with an advanced stage. This may be due to poor access to specialized healthcare and socio-economic factors. Early identification of adenomatous colonic polyps, which are well-recognized pre-cancerous lesions, at the time of screening colonoscopy has been shown to be the most effective measure used for CRC prevention. However, colonic polyps are frequently missed during colonoscopy and moreover, these screening programs necessitate man-power, time and resources for processing resected polyps, that may hamper penetration and efficacy in mid- to low-income countries. In the last decade, there has been significant progress made in the automatic detection of colonic polyps by multiple AI-based systems. With the advent of better AI methodology, the focus has shifted from mere detection to accurate discrimination and diagnosis of colonic polyps. These systems, once validated, could usher in a new era in Colorectal Cancer (CRC) prevention programs which would center around “Leave in-situ” and “Resect and discard” strategies. These new strategies hinge around the specificity and accuracy of AI based systems in correctly identifying the pathological diagnosis of the polyps, thereby providing the endoscopist with real-time information in order to make a clinical decision of either leaving the lesion in-situ (mucosal polyps) or resecting and discarding the polyp (hyperplastic polyps). The major advantage of employing these strategies would be in cost optimization of CRC prevention programs while ensuring good clinical outcomes. The adoption of these AI-based systems in the national cancer prevention program of India in accordance with the mandate to increase technology integration could prove to be cost-effective and enable implementation of CRC prevention programs at the population level. This level of penetration could potentially reduce the incidence of CRC and improve patient survival by enabling early diagnosis and treatment. In this review, we will highlight key advancements made in the field of AI in the identification of polyps during colonoscopy and explore the role of AI based systems in cost optimization during the universal implementation of CRC prevention programs in the context of mid-income countries like India.},
  archive      = {J_FRAI},
  author       = {Rao, Harshavardhan B. and Sastry, Nandakumar Bidare and Venu, Rama P. and Pattanayak, Preetiparna},
  doi          = {10.3389/frai.2022.955399},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {955399},
  shortjournal = {Front. Artif. Intell.},
  title        = {The role of artificial intelligence based systems for cost optimization in colorectal cancer prevention programs},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural analysis of VirD4 a type IV ATPase encoded by
transmissible plasmids of salmonella enterica isolated from poultry
products. <em>FRAI</em>, <em>5</em>, 952997. (<a
href="https://doi.org/10.3389/frai.2022.952997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bacterial species have evolved with a wide variety of cellular devices, and they employ these devices for communication and transfer of genetic materials and toxins. They are classified into secretory system types I to VI based on their structure, composition, and functional activity. Specifically, the bacterial type IV secretory system (T4SS) is a more versatile system than the other secretory systems because it is involved in the transfer of genetic materials, proteins, and toxins to the host cells or other bacterial species. The T4SS machinery is made up of several proteins with distinct functions and forms a complex which spans the inner and outer membranes. This secretory machinery contains three ATPases that are the driving force for the functionality of this apparatus. At the initial stage of the secretion process, the selection of substrate molecules and processing occurs at the cytoplasmic region (also known as relaxosome), and then transfer mechanisms occur through the secretion complex. In this process, the VirD4 ATPase is the first molecule that initiates substrate selection, which is subsequently delivered to the secretory machinery. In the protein data bank (PDB), no structural information is available for the VirD4 ATPase to understand the functional property. In this manuscript, we have modeled VirD4 structure in the Gram-negative bacterium Salmonella enterica and described the predicted functional importance. The sequence alignment shows that VirD4 of S. enterica contains several insertion regions as compared with the template structure (pdb:1E9R) used for homology modeling. In this study, we hypothesized that the insertion regions could play a role in the flexible movement of the hexameric unit during the relaxosome processing or transfer of the substrate.},
  archive      = {J_FRAI},
  author       = {Gokulan, Kuppan and Khare, Sangeeta and Foley, Steven L.},
  doi          = {10.3389/frai.2022.952997},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {952997},
  shortjournal = {Front. Artif. Intell.},
  title        = {Structural analysis of VirD4 a type IV ATPase encoded by transmissible plasmids of salmonella enterica isolated from poultry products},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning corroborates subjective ratings of walking
and balance difficulty in multiple sclerosis. <em>FRAI</em>, <em>5</em>,
952312. (<a href="https://doi.org/10.3389/frai.2022.952312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning can discern meaningful information from large datasets. Applying machine learning techniques to raw sensor data from instrumented walkways could automatically detect subtle changes in walking and balance. Multiple sclerosis (MS) is a neurological disorder in which patients report varying degrees of walking and balance disruption. This study aimed to determine whether machine learning applied to walkway sensor data could classify severity of self-reported symptoms in MS patients. Ambulatory people with MS (n = 107) were asked to rate the severity of their walking and balance difficulties, from 1-No problems to 5-Extreme problems, using the MS-Impact Scale-29. Those who scored less than 3 (moderately) were assigned to the “mild” group (n = 35), and those scoring higher were in the “moderate” group (n = 72). Three machine learning algorithms were applied to classify the “mild” group from the “moderate” group. The classification achieved 78% accuracy, a precision of 85%, a recall of 90%, and an F1 score of 87% for distinguishing those people reporting mild from moderate walking and balance difficulty. This study demonstrates that machine learning models can reliably be applied to instrumented walkway data and distinguish severity of self-reported impairment in people with MS.},
  archive      = {J_FRAI},
  author       = {Hu, Wenting and Combden, Owen and Jiang, Xianta and Buragadda, Syamala and Newell, Caitlin J. and Williams, Maria C. and Critch, Amber L. and Ploughman, Michelle},
  doi          = {10.3389/frai.2022.952312},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {952312},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning corroborates subjective ratings of walking and balance difficulty in multiple sclerosis},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating high-fidelity privacy-conscious synthetic patient
data for causal effect estimation with multiple treatments.
<em>FRAI</em>, <em>5</em>, 918813. (<a
href="https://doi.org/10.3389/frai.2022.918813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, there has been exponentially growing interest in the use of observational data collected as a part of routine healthcare practice to determine the effect of a treatment with causal inference models. Validation of these models, however, has been a challenge because the ground truth is unknown: only one treatment-outcome pair for each person can be observed. There have been multiple efforts to fill this void using synthetic data where the ground truth can be generated. However, to date, these datasets have been severely limited in their utility either by being modeled after small non-representative patient populations, being dissimilar to real target populations, or only providing known effects for two cohorts (treated vs. control). In this work, we produced a large-scale and realistic synthetic dataset that provides ground truth effects for over 10 hypertension treatments on blood pressure outcomes. The synthetic dataset was created by modeling a nationwide cohort of more than 580, 000 hypertension patient data including each person&#39;s multi-year history of diagnoses, medications, and laboratory values. We designed a data generation process by combining an adapted ADS-GAN model for fictitious patient information generation and a neural network for treatment outcome generation. Wasserstein distance of 0.35 demonstrates that our synthetic data follows a nearly identical joint distribution to the patient cohort used to generate the data. Patient privacy was a primary concern for this study; the ϵ-identifiability metric, which estimates the probability of actual patients being identified, is 0.008%, ensuring that our synthetic data cannot be used to identify any actual patients. To demonstrate its usage, we tested the bias in causal effect estimation of four well-established models using this dataset. The approach we used can be readily extended to other types of diseases in the clinical domain, and to datasets in other domains as well.},
  archive      = {J_FRAI},
  author       = {Shi, Jingpu and Wang, Dong and Tesei, Gino and Norgeot, Beau},
  doi          = {10.3389/frai.2022.918813},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {918813},
  shortjournal = {Front. Artif. Intell.},
  title        = {Generating high-fidelity privacy-conscious synthetic patient data for causal effect estimation with multiple treatments},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The precision medicine process for treating rare disease
using the artificial intelligence tool mediKanren. <em>FRAI</em>,
<em>5</em>, 910216. (<a
href="https://doi.org/10.3389/frai.2022.910216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are over 6,000 different rare diseases estimated to impact 300 million people worldwide. As genetic testing becomes more common practice in the clinical setting, the number of rare disease diagnoses will continue to increase, resulting in the need for novel treatment options. Identifying treatments for these disorders is challenging due to a limited understanding of disease mechanisms, small cohort sizes, interindividual symptom variability, and little commercial incentive to develop new treatments. A promising avenue for treatment is drug repurposing, where FDA-approved drugs are repositioned as novel treatments. However, linking disease mechanisms to drug action can be extraordinarily difficult and requires a depth of knowledge across multiple fields, which is complicated by the rapid pace of biomedical knowledge discovery. To address these challenges, The Hugh Kaul Precision Medicine Institute developed an artificial intelligence tool, mediKanren, that leverages the mechanistic insight of genetic disorders to identify therapeutic options. Using knowledge graphs, mediKanren enables an efficient way to link all relevant literature and databases. This tool has allowed for a scalable process that has been used to help over 500 rare disease families. Here, we provide a description of our process, the advantages of mediKanren, and its impact on rare disease patients.},
  archive      = {J_FRAI},
  author       = {Foksinska, Aleksandra and Crowder, Camerron M. and Crouse, Andrew B. and Henrikson, Jeff and Byrd, William E. and Rosenblatt, Gregory and Patton, Michael J. and He, Kaiwen and Tran-Nguyen, Thi K. and Zheng, Marissa and Ramsey, Stephen A. and Amin, Nada and Osborne, John and , UAB Precision Medicine Institute and Might, Matthew and Barnes, Stephen and Chen, Mei-Jan and Crumbley, Mary E. and Eckenrode, Madeline and Fargason, Crayton A. and Fehrmann, Nathaniel and Huls, Forest and Jarrell, Matthew and Jenkins, Lindsay and McCalley, Meg and Osborn, Tamsyn and Pollard, Elizabeth and Rucka, Sienna and Southern, Nicholas T. and Tinglin, Jillian and Whitlock, Jordan H.},
  doi          = {10.3389/frai.2022.910216},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {910216},
  shortjournal = {Front. Artif. Intell.},
  title        = {The precision medicine process for treating rare disease using the artificial intelligence tool mediKanren},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The potential of learning with (and not from) artificial
intelligence in education. <em>FRAI</em>, <em>5</em>, 903051. (<a
href="https://doi.org/10.3389/frai.2022.903051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI-powered technologies are increasingly being developed for educational purposes to contribute to students&#39; academic performance and overall better learning outcomes. This exploratory review uses the PRISMA approach to describe how the effectiveness of AI-driven technologies is being measured, as well as the roles attributed to teachers, and the theoretical and practical contributions derived from the interventions. Findings from 48 articles highlighted that learning outcomes were more aligned with the optimization of AI systems, mostly nested in a computer science perspective, and did not consider teachers in an active role in the research. Most studies proved to be atheoretical and practical contributions were limited to enhancing the design of the AI system. We discuss the importance of developing complementary research designs for AI-powered tools to be integrated optimally into education.},
  archive      = {J_FRAI},
  author       = {Chichekian, Tanya and Benteux, Bérenger},
  doi          = {10.3389/frai.2022.903051},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {903051},
  shortjournal = {Front. Artif. Intell.},
  title        = {The potential of learning with (and not from) artificial intelligence in education},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electronic brainstorming with a chatbot partner: A good idea
due to increased productivity and idea diversity. <em>FRAI</em>,
<em>5</em>, 880673. (<a
href="https://doi.org/10.3389/frai.2022.880673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brainstorming is a creative technique that fosters collaboration to enhance idea generation. The occurrence of evaluation apprehension, a fear of being evaluated negatively by others, however, can stymy brainstorming. How the advantages of collaboration can be leveraged while evaluation apprehension is prevented is an open scientific and practical problem. In this brief research report, it is proposed that chatbots could provide a solution. Chatbots can be designed to share ideas with their users, facilitating inspiration. Compared to human beings, chatbots are also perceived as possessing limited agency and evaluative capacity. This could reduce evaluation apprehension. Given that chatbots are often embedded in a textual chat interface, social cues (picture, name, and description) can reinforce the perceived chatbot identity, enhancing its alleged effects on evaluation apprehension and subsequently on brainstorming performance. These conjectures were tested in an online 2 × 2 between-subjects experiment (n = 120) where people were instructed to brainstorm with a partner that was framed as either a chatbot or human being (but followed the same automated script), with or without the presence of social cues. The results showed that brainstorming with a chatbot led participants to produce more ideas, with more diversity than brainstorming with an alleged human being. Social cues enhanced the effect on idea diversity, but only with the chatbot. No significant effects on evaluation apprehension were found. The contribution of this study is therefore that chatbots can be used for effective human–machine teaming during brainstorming, but this enhancement is not explained by its effects on evaluation apprehension.},
  archive      = {J_FRAI},
  author       = {Wieland, Britt and de Wit, Jan and de Rooij, Alwin},
  doi          = {10.3389/frai.2022.880673},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {880673},
  shortjournal = {Front. Artif. Intell.},
  title        = {Electronic brainstorming with a chatbot partner: A good idea due to increased productivity and idea diversity},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving plant disease classification by adaptive minimal
ensembling. <em>FRAI</em>, <em>5</em>, 868926. (<a
href="https://doi.org/10.3389/frai.2022.868926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel method for improving plant disease classification, a challenging and time-consuming process, is proposed. First, using as baseline EfficientNet, a recent and advanced family of architectures having an excellent accuracy/complexity trade-off, we have introduced, devised, and applied refined techniques based on transfer learning, regularization, stratification, weighted metrics, and advanced optimizers in order to achieve improved performance. Then, we go further by introducing adaptive minimal ensembling, which is a unique input to the knowledge base of the proposed solution. This represents a leap forward since it allows improving the accuracy with limited complexity using only two EfficientNet-b0 weak models, performing ensembling on feature vectors by a trainable layer instead of classic aggregation on outputs. To the best of our knowledge, such an approach to ensembling has never been used before in literature. Our method was tested on PlantVillage, a public reference dataset used for benchmarking models&#39; performances for crop disease diagnostic, considering both its original and augmented versions. We noticeably improved the state of the art by achieving 100% accuracy in both the original and augmented datasets. Results were obtained using PyTorch to train, test, and validate the models; reproducibility is granted by providing exhaustive details, including hyperparameters used in the experimentation. A Web interface is also made publicly available to test the proposed methods.},
  archive      = {J_FRAI},
  author       = {Bruno, Antonio and Moroni, Davide and Dainelli, Riccardo and Rocchi, Leandro and Morelli, Silvia and Ferrari, Emilio and Toscano, Piero and Martinelli, Massimo},
  doi          = {10.3389/frai.2022.868926},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {868926},
  shortjournal = {Front. Artif. Intell.},
  title        = {Improving plant disease classification by adaptive minimal ensembling},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigation of independent reinforcement learning
algorithms in multi-agent environments. <em>FRAI</em>, <em>5</em>,
805823. (<a href="https://doi.org/10.3389/frai.2022.805823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. However, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. Moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. In this paper, we carry out an empirical comparison of the performance of independent algorithms on seven PettingZoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. For the cooperative setting, we show that independent algorithms can perform on par with multi-agent algorithms in fully-observable environments, while adding recurrence improves the learning of independent algorithms in partially-observable environments. In the competitive setting, independent algorithms can perform on par or better than multi-agent algorithms, even in more challenging environments. We also show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies in mixed environments.},
  archive      = {J_FRAI},
  author       = {Lee, Ken Ming and Ganapathi Subramanian, Sriram and Crowley, Mark},
  doi          = {10.3389/frai.2022.805823},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {805823},
  shortjournal = {Front. Artif. Intell.},
  title        = {Investigation of independent reinforcement learning algorithms in multi-agent environments},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Affordance embeddings for situated language understanding.
<em>FRAI</em>, <em>5</em>, 774752. (<a
href="https://doi.org/10.3389/frai.2022.774752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much progress in AI over the last decade has been driven by advances in natural language processing technology, in turn facilitated by large datasets and increased computation power used to train large neural language models. These systems demonstrate apparently sophisticated linguistic understanding or generation capabilities, but often fail to transfer their skills to situations they have not encountered before. We argue that computational situated grounding of linguistic information to real or simulated scenarios provide a solution to some of these learning challenges by creating situational representations that both serve as a formal model of the salient phenomena, and contain rich amounts of exploitable, task-appropriate data for training new, flexible computational models. We approach this problem from a neurosymbolic perspective, using multimodal contextual modeling of interactive situations, events, and object properties, particularly afforded behaviors, and habitats, the situations that condition them. These properties are tightly coupled to processes of situated grounding, and herein we discuss we combine neural and symbolic methods with multimodal simulations to create a platform, VoxWorld, for modeling communication in context, and we demonstrate how neural embedding vectors of symbolically-encoded object affordances facilitate transferring knowledge of objects and situations to novel entities, and learning how to recognize and generate linguistic and gestural denotations.},
  archive      = {J_FRAI},
  author       = {Krishnaswamy, Nikhil and Pustejovsky, James},
  doi          = {10.3389/frai.2022.774752},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {9},
  pages        = {774752},
  shortjournal = {Front. Artif. Intell.},
  title        = {Affordance embeddings for situated language understanding},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Artificial intelligence techniques for
personalized educational software. <em>FRAI</em>, <em>5</em>, 988289.
(<a href="https://doi.org/10.3389/frai.2022.988289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Troussas, Christos and Krouska, Akrivi and Kabassi, Katerina and Sgouropoulou, Cleo and Cristea, Alexandra I.},
  doi          = {10.3389/frai.2022.988289},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {988289},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Artificial intelligence techniques for personalized educational software},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Explainable artificial intelligence models and
methods in finance and healthcare. <em>FRAI</em>, <em>5</em>, 970246.
(<a href="https://doi.org/10.3389/frai.2022.970246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Caffo, Brian S. and D&#39;Asaro, Fabio A. and Garcez, Artur and Raffinetti, Emanuela},
  doi          = {10.3389/frai.2022.970246},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {970246},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Explainable artificial intelligence models and methods in finance and healthcare},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning: A non-invasive prediction method for
gastric cancer based on a survey of lifestyle behaviors. <em>FRAI</em>,
<em>5</em>, 956385. (<a
href="https://doi.org/10.3389/frai.2022.956385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gastric cancer remains an enormous threat to human health. It is extremely significant to make a clear diagnosis and timely treatment of gastrointestinal tumors. The traditional diagnosis method (endoscope, surgery, and pathological tissue extraction) of gastric cancer is usually invasive, expensive, and time-consuming. The machine learning method is fast and low-cost, which breaks through the limitations of the traditional methods as we can apply the machine learning method to diagnose gastric cancer. This work aims to construct a cheap, non-invasive, rapid, and high-precision gastric cancer diagnostic model using personal behavioral lifestyles and non-invasive characteristics. A retrospective study was implemented on 3,630 participants. The developed models (extreme gradient boosting, decision tree, random forest, and logistic regression) were evaluated by cross-validation and the generalization ability in our test set. We found that the model developed using fingerprints based on the extreme gradient boosting (XGBoost) algorithm produced better results compared with the other models. The overall accuracy of which test set was 85.7%, AUC was 89.6%, sensitivity 78.7%, specificity 76.9%, and positive predictive values 73.8%, verifying that the proposed model has significant medical value and good application prospects.},
  archive      = {J_FRAI},
  author       = {Jiang, Siqing and Gao, Haojun and He, Jiajin and Shi, Jiaqi and Tong, Yuling and Wu, Jian},
  doi          = {10.3389/frai.2022.956385},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {956385},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning: A non-invasive prediction method for gastric cancer based on a survey of lifestyle behaviors},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated quantification of penile curvature using
artificial intelligence. <em>FRAI</em>, <em>5</em>, 954497. (<a
href="https://doi.org/10.3389/frai.2022.954497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveTo develop and validate an artificial intelligence (AI)-based algorithm for capturing automated measurements of Penile curvature (PC) based on 2-dimensional images.Materials and methodsNine 3D-printed penile models with differing curvature angles (ranging from 18 to 88°) were used to compile a 900-image dataset featuring multiple camera positions, inclination angles, and background/lighting conditions. The proposed framework of PC angle estimation consisted of three stages: automatic penile area localization, shaft segmentation, and curvature angle estimation. The penile model images were captured using a smartphone camera and used to train and test a Yolov5 model that automatically cropped the penile area from each image. Next, an Unet-based segmentation model was trained, validated, and tested to segment the penile shaft, before a custom Hough-Transform-based angle estimation technique was used to evaluate degree of PC.ResultsThe proposed framework displayed robust performance in cropping the penile area [mean average precision (mAP) 99.4%] and segmenting the shaft [Dice Similarity Coefficient (DSC) 98.4%]. Curvature angle estimation technique generally demonstrated excellent performance, with a mean absolute error (MAE) of just 8.5 when compared with ground truth curvature angles.ConclusionsConsidering current intra- and inter-surgeon variability of PC assessments, the framework reported here could significantly improve precision of PC measurements by surgeons and hypospadiology researchers.},
  archive      = {J_FRAI},
  author       = {Abbas, Tariq O. and AbdelMoniem, Mohamed and Chowdhury, Muhammad E. H.},
  doi          = {10.3389/frai.2022.954497},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {954497},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automated quantification of penile curvature using artificial intelligence},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accurate species identification of food-contaminating
beetles with quality-improved elytral images and deep learning.
<em>FRAI</em>, <em>5</em>, 952424. (<a
href="https://doi.org/10.3389/frai.2022.952424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food samples are routinely screened for food-contaminating beetles (i.e., pantry beetles) due to their adverse impact on the economy, environment, public health and safety. If found, their remains are subsequently analyzed to identify the species responsible for the contamination; each species poses different levels of risk, requiring different regulatory and management steps. At present, this identification is done through manual microscopic examination since each species of beetle has a unique pattern on its elytra (hardened forewing). Our study sought to automate the pattern recognition process through machine learning. Such automation will enable more efficient identification of pantry beetle species and could potentially be scaled up and implemented across various analysis centers in a consistent manner. In our earlier studies, we demonstrated that automated species identification of pantry beetles is feasible through elytral pattern recognition. Due to poor image quality, however, we failed to achieve prediction accuracies of more than 80%. Subsequently, we modified the traditional imaging technique, allowing us to acquire high-quality elytral images. In this study, we explored whether high-quality elytral images can truly achieve near-perfect prediction accuracies for 27 different species of pantry beetles. To test this hypothesis, we developed a convolutional neural network (CNN) model and compared performance between two different image sets for various pantry beetles. Our study indicates improved image quality indeed leads to better prediction accuracy; however, it was not the only requirement for achieving good accuracy. Also required are many high-quality images, especially for species with a high number of variations in their elytral patterns. The current study provided a direction toward achieving our ultimate goal of automated species identification through elytral pattern recognition.},
  archive      = {J_FRAI},
  author       = {Bisgin, Halil and Bera, Tanmay and Wu, Leihong and Ding, Hongjian and Bisgin, Neslihan and Liu, Zhichao and Pava-Ripoll, Monica and Barnes, Amy and Campbell, James F. and Vyas, Himansi and Furlanello, Cesare and Tong, Weida and Xu, Joshua},
  doi          = {10.3389/frai.2022.952424},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {952424},
  shortjournal = {Front. Artif. Intell.},
  title        = {Accurate species identification of food-contaminating beetles with quality-improved elytral images and deep learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel technique for detecting sudden concept drift in
healthcare data using multi-linear artificial intelligence techniques.
<em>FRAI</em>, <em>5</em>, 950659. (<a
href="https://doi.org/10.3389/frai.2022.950659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A financial market is a platform to produce data streams continuously and around 1. 145 Trillion MB of data per day. Estimation and the analysis of unknown or dynamic behaviors of these systems is one the challenging tasks. Analysis of these systems is very much essential to strengthen the environmental parameters to stabilize society activities. This can elevate the living style of society to the next level. In this connection, the proposed paper is trying to accommodate the financial data stream using the sliding window approach and random forest algorithm to provide a solution to handle concept drift in the financial market to stabilize the behavior of the system through drift estimation. The proposed approach provides promising results in terms of accuracy in detecting concept drift over the state of existing drift detection methods like one class drifts detection (OCDD), Adaptive Windowing ADWIN), and the Page-Hinckley test.},
  archive      = {J_FRAI},
  author       = {M. S., Abdul Razak and Nirmala, C. R. and Aljohani, Maha and Sreenivasa, B. R.},
  doi          = {10.3389/frai.2022.950659},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {950659},
  shortjournal = {Front. Artif. Intell.},
  title        = {A novel technique for detecting sudden concept drift in healthcare data using multi-linear artificial intelligence techniques},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Experiments with LDA and Top2Vec for embedded topic
discovery on social media data—a case study of cystic fibrosis.
<em>FRAI</em>, <em>5</em>, 948313. (<a
href="https://doi.org/10.3389/frai.2022.948313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has become an important resource for discussing, sharing, and seeking information pertinent to rare diseases by patients and their families, given the low prevalence in the extraordinarily sparse populations. In our previous study, we identified prevalent topics from Reddit via topic modeling for cystic fibrosis (CF). While we were able to derive/access concerns/needs/questions of patients with CF, we observed challenges and issues with the traditional techniques of topic modeling, e.g., Latent Dirichlet Allocation (LDA), for fulfilling the task of topic extraction. Thus, here we present our experiments to extend the previous study with an aim of improving the performance of topic modeling, by experimenting with LDA model optimization and examination of the Top2Vec model with different embedding models. With the demonstrated results with higher coherence and qualitatively higher human readability of derived topics, we implemented the Top2Vec model with doc2vec as the embedding model as our final model to extract topics from a subreddit of CF (“r/CysticFibrosis”) and proposed to expand its use with other types of social media data for other rare diseases for better assessing patients&#39; needs with social media data.},
  archive      = {J_FRAI},
  author       = {Karas, Bradley and Qu, Sue and Xu, Yanji and Zhu, Qian},
  doi          = {10.3389/frai.2022.948313},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {948313},
  shortjournal = {Front. Artif. Intell.},
  title        = {Experiments with LDA and Top2Vec for embedded topic discovery on social media data—A case study of cystic fibrosis},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rare disease-based scientific annotation knowledge graph.
<em>FRAI</em>, <em>5</em>, 932665. (<a
href="https://doi.org/10.3389/frai.2022.932665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rare diseases (RDs) are naturally associated with a low prevalence rate, which raises a big challenge due to there being less data available for supporting preclinical and clinical studies. There has been a vast improvement in our understanding of RD, largely owing to advanced big data analytic approaches in genetics/genomics. Consequently, a large volume of RD-related publications has been accumulated in recent years, which offers opportunities to utilize these publications for accessing the full spectrum of the scientific research and supporting further investigation in RD. In this study, we systematically analyzed, semantically annotated, and scientifically categorized RD-related PubMed articles, and integrated those semantic annotations in a knowledge graph (KG), which is hosted in Neo4j based on a predefined data model. With the successful demonstration of scientific contribution in RD via the case studies performed by exploring this KG, we propose to extend the current effort by expanding more RD-related publications and more other types of resources as a next step.},
  archive      = {J_FRAI},
  author       = {Zhu, Qian and Qu, Chunxu and Liu, Ruizheng and Vatas, Gunjan and Clough, Andrew and Nguyễn, Ðắc-Trung and Sid, Eric and Mathé, Ewy and Xu, Yanji},
  doi          = {10.3389/frai.2022.932665},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {932665},
  shortjournal = {Front. Artif. Intell.},
  title        = {Rare disease-based scientific annotation knowledge graph},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asian hate speech detection on twitter during COVID-19.
<em>FRAI</em>, <em>5</em>, 932381. (<a
href="https://doi.org/10.3389/frai.2022.932381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease 2019 (COVID-19) started in Wuhan, China, in late 2019, and after being utterly contagious in Asian countries, it rapidly spread to other countries. This disease caused governments worldwide to declare a public health crisis with severe measures taken to reduce the speed of the spread of the disease. This pandemic affected the lives of millions of people. Many citizens that lost their loved ones and jobs experienced a wide range of emotions, such as disbelief, shock, concerns about health, fear about food supplies, anxiety, and panic. All of the aforementioned phenomena led to the spread of racism and hate against Asians in western countries, especially in the United States. An analysis of official preliminary police data by the Center for the Study of Hate &amp;amp; Extremism at California State University shows that Anti-Asian hate crime in 16 of America&#39;s largest cities increased by 149% in 2020. In this study, we first chose a baseline of Americans&#39; hate crimes against Asians on Twitter. Then we present an approach to balance the biased dataset and consequently improve the performance of tweet classification. We also have downloaded 10 million tweets through the Twitter API V-2. In this study, we have used a small portion of that, and we will use the entire dataset in the future study. In this article, three thousand tweets from our collected corpus are annotated by four annotators, including three Asian and one Asian-American. Using this data, we built predictive models of hate speech using various machine learning and deep learning methods. Our machine learning methods include Random Forest, K-nearest neighbors (KNN), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), Logistic Regression, Decision Tree, and Naive Bayes. Our Deep Learning models include Basic Long-Term Short-Term Memory (LSTM), Bidirectional LSTM, Bidirectional LSTM with Drop out, Convolution, and Bidirectional Encoder Representations from Transformers (BERT). We also adjusted our dataset by filtering tweets that were ambiguous to the annotators based on low Fleiss Kappa agreement between annotators. Our final result showed that Logistic Regression achieved the best statistical machine learning performance with an F1 score of 0.72, while BERT achieved the best performance of the deep learning models, with an F1-Score of 0.85.},
  archive      = {J_FRAI},
  author       = {Toliyat, Amir and Levitan, Sarah Ita and Peng, Zheng and Etemadpour, Ronak},
  doi          = {10.3389/frai.2022.932381},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {932381},
  shortjournal = {Front. Artif. Intell.},
  title        = {Asian hate speech detection on twitter during COVID-19},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overview and commentary of the CDEI’s extended roadmap to an
effective AI assurance ecosystem. <em>FRAI</em>, <em>5</em>, 932358. (<a
href="https://doi.org/10.3389/frai.2022.932358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the field of ethical artificial intelligence (AI), or AI ethics, has gained traction and aims to develop guidelines and best practices for the responsible and ethical use of AI across sectors. As part of this, nations have proposed AI strategies, with the UK releasing both national AI and data strategies, as well as a transparency standard. Extending these efforts, the Centre for Data Ethics and Innovation (CDEI) has published an AI Assurance Roadmap, which is the first of its kind and provides guidance on how to manage the risks that come from the use of AI. In this article, we provide an overview of the document&#39;s vision for a “mature AI assurance ecosystem” and how the CDEI will work with other organizations for the development of regulation, industry standards, and the creation of AI assurance practitioners. We also provide a commentary of some key themes identified in the CDEI&#39;s roadmap in relation to (i) the complexities of building “justified trust”, (ii) the role of research in AI assurance, (iii) the current developments in the AI assurance industry, and (iv) convergence with international regulation.},
  archive      = {J_FRAI},
  author       = {Barrance, Ethan and Kazim, Emre and Hilliard, Airlie and Trengove, Markus and Zannone, Sara and Koshiyama, Adriano},
  doi          = {10.3389/frai.2022.932358},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {932358},
  shortjournal = {Front. Artif. Intell.},
  title        = {Overview and commentary of the CDEI&#39;s extended roadmap to an effective AI assurance ecosystem},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SRflow: Deep learning based super-resolution of 4D-flow MRI
data. <em>FRAI</em>, <em>5</em>, 928181. (<a
href="https://doi.org/10.3389/frai.2022.928181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting 4D-flow magnetic resonance imaging (MRI) data to quantify hemodynamics requires an adequate spatio-temporal vector field resolution at a low noise level. To address this challenge, we provide a learned solution to super-resolve in vivo 4D-flow MRI data at a post-processing level. We propose a deep convolutional neural network (CNN) that learns the inter-scale relationship of the velocity vector map and leverages an efficient residual learning scheme to make it computationally feasible. A novel, direction-sensitive, and robust loss function is crucial to learning vector-field data. We present a detailed comparative study between the proposed super-resolution and the conventional cubic B-spline based vector-field super-resolution. Our method improves the peak-velocity to noise ratio of the flow field by 10 and 30% for in vivo cardiovascular and cerebrovascular data, respectively, for 4 × super-resolution over the state-of-the-art cubic B-spline. Significantly, our method offers 10x faster inference over the cubic B-spline. The proposed approach for super-resolution of 4D-flow data would potentially improve the subsequent calculation of hemodynamic quantities.},
  archive      = {J_FRAI},
  author       = {Shit, Suprosanna and Zimmermann, Judith and Ezhov, Ivan and Paetzold, Johannes C. and Sanches, Augusto F. and Pirkl, Carolin and Menze, Bjoern H.},
  doi          = {10.3389/frai.2022.928181},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {928181},
  shortjournal = {Front. Artif. Intell.},
  title        = {SRflow: Deep learning based super-resolution of 4D-flow MRI data},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Direct domain adaptation through reciprocal linear
transformations. <em>FRAI</em>, <em>5</em>, 927676. (<a
href="https://doi.org/10.3389/frai.2022.927676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a direct domain adaptation (DDA) approach to enrich the training of supervised neural networks on synthetic data by features from real-world data. The process involves a series of linear operations on the input features to the NN model, whether they are from the source or target distributions, as follows: (1) A cross-correlation of the input data (i.e., images) with a randomly picked sample pixel (or pixels) of all images from the input or the mean of all randomly picked sample pixel (or pixels) of all input images. (2) The convolution of the resulting data with the mean of the autocorrelated input images from the other domain. In the training stage, as expected, the input images are from the source distribution, and the mean of auto-correlated images are evaluated from the target distribution. In the inference/application stage, the input images are from the target distribution, and the mean of auto-correlated images are evaluated from the source distribution. The proposed method only manipulates the data from the source and target domains and does not explicitly interfere with the training workflow and network architecture. An application that includes training a convolutional neural network on the MNIST dataset and testing the network on the MNIST-M dataset achieves a 70% accuracy on the test data. A principal component analysis (PCA), as well as t-SNE, shows that the input features from the source and target domains, after the proposed direct transformations, share similar properties along the principal components as compared to the original MNIST and MNIST-M input features.},
  archive      = {J_FRAI},
  author       = {Alkhalifah, Tariq and Ovcharenko, Oleg},
  doi          = {10.3389/frai.2022.927676},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {927676},
  shortjournal = {Front. Artif. Intell.},
  title        = {Direct domain adaptation through reciprocal linear transformations},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). COVID-19 diagnosis using deep learning neural networks
applied to CT images. <em>FRAI</em>, <em>5</em>, 919672. (<a
href="https://doi.org/10.3389/frai.2022.919672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19, a deadly and highly contagious virus, caused the deaths of millions of individuals around the world. Early detection of the virus can reduce the virus transmission and fatality rate. Many deep learning (DL) based COVID-19 detection methods have been proposed, but most are trained on either small, incomplete, noisy, or imbalanced datasets. Many are also trained on a small number of COVID-19 samples. This study tackles these concerns by introducing DL-based solutions for COVID-19 diagnosis using computerized tomography (CT) images and 12 cutting-edge DL pre-trained models with acceptable Top-1 accuracy. All the models are trained on 9,000 COVID-19 samples and 5,000 normal images, which is higher than the COVID-19 images used in most studies. In addition, while most of the research used X-ray images for training, this study used CT images. CT scans capture blood arteries, bones, and soft tissues more effectively than X-Ray. The proposed techniques were evaluated, and the results show that NASNetLarge produced the best classification accuracy, followed by InceptionResNetV2 and DenseNet169. The three models achieved an accuracy of 99.86, 99.79, and 99.71%, respectively. Moreover, DenseNet121 and VGG16 achieved the best sensitivity, while InceptionV3 and InceptionResNetV2 achieved the best specificity. DenseNet121 and VGG16 attained a sensitivity of 99.94%, while InceptionV3 and InceptionResNetV2 achieved a specificity of 100%. The models are compared to those designed in three existing studies, and they produce better results. The results show that deep neural networks have the potential for computer-assisted COVID-19 diagnosis. We hope this study will be valuable in improving the decisions and accuracy of medical practitioners when diagnosing COVID-19. This study will assist future researchers in minimizing the repetition of analysis and identifying the ideal network for their tasks.},
  archive      = {J_FRAI},
  author       = {Akinyelu, Andronicus A. and Blignaut, Pieter},
  doi          = {10.3389/frai.2022.919672},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {919672},
  shortjournal = {Front. Artif. Intell.},
  title        = {COVID-19 diagnosis using deep learning neural networks applied to CT images},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Limiting medical certainties? Funding challenges for german
and comparable public healthcare systems due to AI prediction and how to
address them. <em>FRAI</em>, <em>5</em>, 913093. (<a
href="https://doi.org/10.3389/frai.2022.913093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current technological and medical advances lend substantial momentum to efforts to attain new medical certainties. Artificial Intelligence can enable unprecedented precision and capabilities in forecasting the health conditions of individuals. But, as we lay out, this novel access to medical information threatens to exacerbate adverse selection in the health insurance market. We conduct an interdisciplinary conceptual analysis to study how this risk might be averted, considering legal, ethical, and economic angles. We ask whether it is viable and effective to ban or limit AI and its medical use as well as to limit medical certainties and find that neither of these limitation-based approaches provides an entirely sufficient resolution. Hence, we argue that this challenge must not be neglected in future discussions regarding medical applications of AI forecasting, that it should be addressed on a structural level and we encourage further research on the topic.},
  archive      = {J_FRAI},
  author       = {von Ulmenstein, Ulrich and Tretter, Max and Ehrlich, David B. and Lauppert von Peharnik, Christina},
  doi          = {10.3389/frai.2022.913093},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {913093},
  shortjournal = {Front. Artif. Intell.},
  title        = {Limiting medical certainties? funding challenges for german and comparable public healthcare systems due to AI prediction and how to address them},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed cognition for collaboration between human
drivers and self-driving cars. <em>FRAI</em>, <em>5</em>, 910801. (<a
href="https://doi.org/10.3389/frai.2022.910801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the collaboration between human drivers and intelligent vehicles. We propose a collaboration mechanism grounded on the concept of distributed cognition. With distributed cognition, intelligence does not lie just in the single entity but also in the interaction with the other cognitive components in a system. We apply this idea to vehicle intelligence, proposing a system distributed into two cognitive entities—the human and the autonomous agent—that together contribute to drive the vehicle. This account of vehicle intelligence differs from the mainstream research effort on highly autonomous cars. The proposed mechanism follows one of the paradigm derived from distributed cognition, the rider-horse metaphor: just like the rider communicates their intention to the horse through the reins, the human influences the agent using the pedals and the steering wheel. We use a driving simulator to demonstrate the collaboration in action, showing how the human can communicate and interact with the agent in various ways with safe outcomes.},
  archive      = {J_FRAI},
  author       = {Plebe, Alice and Rosati Papini, Gastone Pietro and Cherubini, Antonello and Da Lio, Mauro},
  doi          = {10.3389/frai.2022.910801},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {910801},
  shortjournal = {Front. Artif. Intell.},
  title        = {Distributed cognition for collaboration between human drivers and self-driving cars},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring the associative learning capabilities of the
segmented attractor network for lifelong learning. <em>FRAI</em>,
<em>5</em>, 910407. (<a
href="https://doi.org/10.3389/frai.2022.910407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the process of adapting the segmented attractor network to a lifelong learning setting. Taking inspirations from Hopfield networks and content-addressable memory, the segmented attractor network is a powerful tool for associative memory applications. The network&#39;s performance as an associative memory is analyzed using multiple metrics. In addition to the network&#39;s general hit rate, its capability to recall unique memories and their frequency is also evaluated with respect to time. Finally, additional learning techniques are implemented to enhance the network&#39;s recall capacity in the application of lifelong learning. These learning techniques are based on human cognitive functions such as memory consolidation, prediction, and forgetting.},
  archive      = {J_FRAI},
  author       = {Jones, Alexander and Jha, Rashmi},
  doi          = {10.3389/frai.2022.910407},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {910407},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring the associative learning capabilities of the segmented attractor network for lifelong learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Requirements and challenges for hybrid intelligence: A
case-study in education. <em>FRAI</em>, <em>5</em>, 891630. (<a
href="https://doi.org/10.3389/frai.2022.891630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential for Artificial Intelligence is widely proclaimed. Yet, in everyday educational settings the use of this technology is limited. Particularly, if we consider smart systems that actually interact with learners in a knowledgeable way and as such support the learning process. It illustrates the fact that teaching professionally is a complex challenge that is beyond the capabilities of current autonomous robots. On the other hand, dedicated forms of Artificial Intelligence can be very good at certain things. For example, computers are excellent chess players and automated route planners easily outperform humans. To deploy this potential, experts argue for a hybrid approach in which humans and smart systems collaboratively accomplish goals. How to realize this for education? What does it entail in practice? In this contribution, we investigate the idea of a hybrid approach in secondary education. As a case-study, we focus on learners acquiring systems thinking skills and our recently for this purpose developed pedagogical approach. Particularly, we discuss the kind of Artificial Intelligence that is needed in this situation, as well as which tasks the software can perform well and which tasks are better, or necessarily, left with the teacher.},
  archive      = {J_FRAI},
  author       = {Bredeweg, Bert and Kragten, Marco},
  doi          = {10.3389/frai.2022.891630},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {891630},
  shortjournal = {Front. Artif. Intell.},
  title        = {Requirements and challenges for hybrid intelligence: A case-study in education},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence at work: The problem of managerial
control from call centers to transport platforms. <em>FRAI</em>,
<em>5</em>, 888817. (<a
href="https://doi.org/10.3389/frai.2022.888817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been much recent research on the topic of artificial intelligence at work, which is increasingly featuring in more types of work and across the labor process. Much research takes the application of artificial intelligence, in its various forms, as a break from the previous methods of organizing work. Less is known about how these applications of artificial intelligence build upon previous forms of managerial control or are adapted in practice. This paper aims to situate the use of artificial intelligence by management within a longer history of control at work. In doing so, it seeks to draw out the novelty of the technology, while also critically appraising the impact of artificial intelligence as a managerial tool. The aim is to understand the contest at work over the introduction of these tools, taking call centers and transport platforms as case studies. Call centers are important because they have been a site of struggle over previous forms of electronic surveillance and computation control, providing important lessons for how artificial intelligence is, or may, be used in practice. In particular, this paper will draw out moments and tactics in algorithmic management has been challenged at work, using this as a discussion point for considering the possible future of artificial intelligence at work.},
  archive      = {J_FRAI},
  author       = {Woodcock, Jamie},
  doi          = {10.3389/frai.2022.888817},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {888817},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence at work: The problem of managerial control from call centers to transport platforms},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A recommender for research collaborators using graph neural
networks. <em>FRAI</em>, <em>5</em>, 881704. (<a
href="https://doi.org/10.3389/frai.2022.881704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As most great discoveries and advancements in science and technology invariably involve the cooperation of a group of researchers, effective collaboration is the key factor. Nevertheless, finding suitable scholars and researchers to work with is challenging and, mostly, time-consuming for many. A recommender who is capable of finding and recommending collaborators would prove helpful. In this work, we utilized a life science and biomedical research database, i.e., MEDLINE, to develop a collaboration recommendation system based on novel graph neural networks, i.e., GraphSAGE and Temporal Graph Network, which can capture intrinsic, complex, and changing dependencies among researchers, including temporal user–user interactions. The baseline methods based on LightGCN and gradient boosting trees were also developed in this work for comparison. Internal automatic evaluations and external evaluations through end-users&#39; ratings were conducted, and the results revealed that our graph neural networks recommender exhibits consistently encouraging results.},
  archive      = {J_FRAI},
  author       = {Zhu, Jie and Yaseen, Ashraf},
  doi          = {10.3389/frai.2022.881704},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {881704},
  shortjournal = {Front. Artif. Intell.},
  title        = {A recommender for research collaborators using graph neural networks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of artificial intelligence to plasma
metabolomics profiles to predict response to neoadjuvant chemotherapy in
triple-negative breast cancer. <em>FRAI</em>, <em>5</em>, 876100. (<a
href="https://doi.org/10.3389/frai.2022.876100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a need to identify biomarkers predictive of response to neoadjuvant chemotherapy (NACT) in triple-negative breast cancer (TNBC). We previously obtained evidence that a polyamine signature in the blood is associated with TNBC development and progression. In this study, we evaluated whether plasma polyamines and other metabolites may identify TNBC patients who are less likely to respond to NACT. Pre-treatment plasma levels of acetylated polyamines were elevated in TNBC patients that had moderate to extensive tumor burden (RCB-II/III) following NACT compared to those that achieved a complete pathological response (pCR/RCB-0) or had minimal residual disease (RCB-I). We further applied artificial intelligence to comprehensive metabolic profiles to identify additional metabolites associated with treatment response. Using a deep learning model (DLM), a metabolite panel consisting of two polyamines as well as nine additional metabolites was developed for improved prediction of RCB-II/III. The DLM has potential clinical value for identifying TNBC patients who are unlikely to respond to NACT and who may benefit from other treatment modalities.},
  archive      = {J_FRAI},
  author       = {Irajizad, Ehsan and Wu, Ranran and Vykoukal, Jody and Murage, Eunice and Spencer, Rachelle and Dennison, Jennifer B. and Moulder, Stacy and Ravenberg, Elizabeth and Lim, Bora and Litton, Jennifer and Tripathym, Debu and Valero, Vicente and Damodaran, Senthil and Rauch, Gaiane M. and Adrada, Beatriz and Candelaria, Rosalind and White, Jason B. and Brewster, Abenaa and Arun, Banu and Long, James P. and Do, Kim Anh and Hanash, Sam and Fahrmann, Johannes F.},
  doi          = {10.3389/frai.2022.876100},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {876100},
  shortjournal = {Front. Artif. Intell.},
  title        = {Application of artificial intelligence to plasma metabolomics profiles to predict response to neoadjuvant chemotherapy in triple-negative breast cancer},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Phenotype clustering in health care: A narrative review for
clinicians. <em>FRAI</em>, <em>5</em>, 842306. (<a
href="https://doi.org/10.3389/frai.2022.842306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pathophysiology is occasionally too complex for unaided hypothetical-deductive reasoning and the isolated application of additive or linear statistical methods. Clustering algorithms use input data patterns and distributions to form groups of similar patients or diseases that share distinct properties. Although clinicians frequently perform tasks that may be enhanced by clustering, few receive formal training and clinician-centered literature in clustering is sparse. To add value to clinical care and research, optimal clustering practices require a thorough understanding of how to process and optimize data, select features, weigh strengths and weaknesses of different clustering methods, select the optimal clustering method, and apply clustering methods to solve problems. These concepts and our suggestions for implementing them are described in this narrative review of published literature. All clustering methods share the weakness of finding potential clusters even when natural clusters do not exist, underscoring the importance of applying data-driven techniques as well as clinical and statistical expertise to clustering analyses. When applied properly, patient and disease phenotype clustering can reveal obscured associations that can help clinicians understand disease pathophysiology, predict treatment response, and identify patients for clinical trial enrollment.},
  archive      = {J_FRAI},
  author       = {Loftus, Tyler J. and Shickel, Benjamin and Balch, Jeremy A. and Tighe, Patrick J. and Abbott, Kenneth L. and Fazzone, Brian and Anderson, Erik M. and Rozowsky, Jared and Ozrazgat-Baslanti, Tezcan and Ren, Yuanfang and Berceli, Scott A. and Hogan, William R. and Efron, Philip A. and Moorman, J. Randall and Rashidi, Parisa and Upchurch, Gilbert R. and Bihorac, Azra},
  doi          = {10.3389/frai.2022.842306},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {842306},
  shortjournal = {Front. Artif. Intell.},
  title        = {Phenotype clustering in health care: A narrative review for clinicians},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The effects of anthropomorphism and multimodal biometric
authentication on the user experience of voice intelligence.
<em>FRAI</em>, <em>5</em>, 831046. (<a
href="https://doi.org/10.3389/frai.2022.831046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice intelligence is a revolutionary “zero-touch” type of human-machine interaction based on spoken language. There has been a recent increase in the number and variations of voice assistants and applications that help users to acquire information. The increased popularity of voice intelligence, however, has not been reflected in the customer value chain. Current research on the socio-technological aspects of human-technology interaction has emphasized the importance of anthropomorphism and user identification in the adoption of the technology. Prior research has also pointed out that user perception toward the technology is key to its adoption. Therefore, this research examines how anthropomorphism and multimodal biometric authentication influence the adoption of voice intelligence through user perception in the customer value chain. In this study we conducted a between-subjects online experiment. We designed a 2 × 2 factorial experiment by manipulating anthropomorphism and multimodal biometric authentication into four conditions, namely with and without a combination of these two factors. Subjects were recruited from Amazon MTurk platform and randomly assigned to one of the four conditions. The results drawn from the empirical study showed a significant direct positive effect of anthropomorphism and multimodal biometric authentication on user adoption of voice intelligence in the customer value chain. Moreover, the effect of anthropomorphism is partially mediated by users&#39; perceived ease of use, perceived usefulness, and perceived security risk. This research contributes to the existing literature on human-computer interaction and voice intelligence by empirically testing the simultaneous impact of anthropomorphism and biometric authentication on users&#39; experience of the technology. The study also provides practitioners who wish to adopt voice intelligence in the commercial environment with insights into the user interface design.},
  archive      = {J_FRAI},
  author       = {de Kloet, Mels and Yang, Shengyun},
  doi          = {10.3389/frai.2022.831046},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {831046},
  shortjournal = {Front. Artif. Intell.},
  title        = {The effects of anthropomorphism and multimodal biometric authentication on the user experience of voice intelligence},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Poultry diseases diagnostics models using deep learning.
<em>FRAI</em>, <em>5</em>, 733345. (<a
href="https://doi.org/10.3389/frai.2022.733345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coccidiosis, Salmonella, and Newcastle are the common poultry diseases that curtail poultry production if they are not detected early. In Tanzania, these diseases are not detected early due to limited access to agricultural support services by poultry farmers. Deep learning techniques have the potential for early diagnosis of these poultry diseases. In this study, a deep Convolutional Neural Network (CNN) model was developed to diagnose poultry diseases by classifying healthy and unhealthy fecal images. Unhealthy fecal images may be symptomatic of Coccidiosis, Salmonella, and Newcastle diseases. We collected 1,255 laboratory-labeled fecal images and fecal samples used in Polymerase Chain Reaction diagnostics to annotate the laboratory-labeled fecal images. We took 6,812 poultry fecal photos using an Open Data Kit. Agricultural support experts annotated the farm-labeled fecal images. Then we used a baseline CNN model, VGG16, InceptionV3, MobileNetV2, and Xception models. We trained models using farm and laboratory-labeled fecal images and then fine-tuned them. The test set used farm-labeled images. The test accuracies results without fine-tuning were 83.06% for the baseline CNN, 85.85% for VGG16, 94.79% for InceptionV3, 87.46% for MobileNetV2, and 88.27% for Xception. Finetuning while freezing the batch normalization layer improved model accuracies, resulting in 95.01% for VGG16, 95.45% for InceptionV3, 98.02% for MobileNetV2, and 98.24% for Xception, with F1 scores for all classifiers above 75% in all four classes. Given the lighter weight of the trained MobileNetV2 and its better ability to generalize, we recommend deploying this model for the early detection of poultry diseases at the farm level.},
  archive      = {J_FRAI},
  author       = {Machuve, Dina and Nwankwo, Ezinne and Mduma, Neema and Mbelwa, Jimmy},
  doi          = {10.3389/frai.2022.733345},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {8},
  pages        = {733345},
  shortjournal = {Front. Artif. Intell.},
  title        = {Poultry diseases diagnostics models using deep learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: The mental lexicon, blueprint of the dictionaries
of tomorrow: Cognitive aspects of the lexicon. <em>FRAI</em>,
<em>5</em>, 945705. (<a
href="https://doi.org/10.3389/frai.2022.945705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Zock, Michael and De Deyne, Simon and Stella, Massimo and Pirrelli, Vito},
  doi          = {10.3389/frai.2022.945705},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {945705},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: the mental lexicon, blueprint of the dictionaries of tomorrow: cognitive aspects of the lexicon},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IRC-safe graph autoencoder for unsupervised anomaly
detection. <em>FRAI</em>, <em>5</em>, 943135. (<a
href="https://doi.org/10.3389/frai.2022.943135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection through employing machine learning techniques has emerged as a novel powerful tool in the search for new physics beyond the Standard Model. Historically similar to the development of jet observables, theoretical consistency has not always assumed a central role in the fast development of algorithms and neural network architectures. In this work, we construct an infrared and collinear safe autoencoder based on graph neural networks by employing energy-weighted message passing. We demonstrate that whilst this approach has theoretically favorable properties, it also exhibits formidable sensitivity to non-QCD structures.},
  archive      = {J_FRAI},
  author       = {Atkinson, Oliver and Bhardwaj, Akanksha and Englert, Christoph and Konar, Partha and Ngairangbam, Vishal S. and Spannowsky, Michael},
  doi          = {10.3389/frai.2022.943135},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {943135},
  shortjournal = {Front. Artif. Intell.},
  title        = {IRC-safe graph autoencoder for unsupervised anomaly detection},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using the DiCoT framework for integrated multimodal analysis
in mixed-reality training environments. <em>FRAI</em>, <em>5</em>,
941825. (<a href="https://doi.org/10.3389/frai.2022.941825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation-based training (SBT) programs are commonly employed by organizations to train individuals and teams for effective workplace cognitive and psychomotor skills in a broad range of applications. Distributed cognition has become a popular cognitive framework for the design and evaluation of these SBT environments, with structured methodologies such as Distributed Cognition for Teamwork (DiCoT) used for analysis. However, the analysis and evaluations generated by such distributed cognition frameworks require extensive domain-knowledge and manual coding and interpretation, and the analysis is primarily qualitative. In this work, we propose and develop the application of multimodal learning analysis techniques to SBT scenarios. Using these analysis methods, we can use the rich multimodal data collected in SBT environments to generate more automated interpretations of trainee performance that supplement and extend traditional DiCoT analysis. To demonstrate the use of these methods, we present a case study of nurses training in a mixed-reality manikin-based (MRMB) training environment. We show how the combined analysis of the video, speech, and eye-tracking data collected as the nurses train in the MRMB environment supports and enhances traditional qualitative DiCoT analysis. By applying such quantitative data-driven analysis methods, we can better analyze trainee activities online in SBT and MRMB environments. With continued development, these analysis methods could be used to provide targeted feedback to learners, a detailed review of training performance to the instructors, and data-driven evidence for improving the environment to simulation designers.},
  archive      = {J_FRAI},
  author       = {Vatral, Caleb and Biswas, Gautam and Cohn, Clayton and Davalos, Eduardo and Mohammed, Naveeduddin},
  doi          = {10.3389/frai.2022.941825},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {941825},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using the DiCoT framework for integrated multimodal analysis in mixed-reality training environments},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integration of machine learning with complex industrial
mining systems for reduced energy consumption. <em>FRAI</em>,
<em>5</em>, 938641. (<a
href="https://doi.org/10.3389/frai.2022.938641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep-level mining industry is experiencing narrowing profit margins due to increasing operating costs and decreasing production. The industry is known for its lack of dynamic control across complex integrated systems running deep underground, making IoT technologies difficult to implement. An important integrated system in a typical underground mine is the refrigeration-ventilation system. In practice, the two systems are still controlled independently, often due to a lack of continuous measurements. However, their integrated effects ultimately affect energy usage and production. This study develops and compares various machine learning prediction techniques to predict the integrated behavior of a key component operating on the boundary of the refrigeration-ventilation system, while also addressing the lack of continuous measurements. The component lacks sensors and the developed industrial machine learning models negate the effect thereof using integrated control. The predictive models are compared based on accuracy, prediction time, as well as the amount of data required to obtain the required level of accuracy. The “Support Vector Machines” method achieved the lowest average error (1.97%), but the “Artificial Neural Network” method is more robust (with a maximum percentage error of 12.90%). A potential energy saving of 215 kW or 2.9% of the ventilation and refrigeration system, equivalent to R1.33-million per annum ($82 9001) is achievable using the “Support Vector Machines” method.},
  archive      = {J_FRAI},
  author       = {Harmse, Michael David and van Laar, Jean Herman and Pelser, Wiehan Adriaan and Schutte, Cornelius Stephanus Lodewyk},
  doi          = {10.3389/frai.2022.938641},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {938641},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integration of machine learning with complex industrial mining systems for reduced energy consumption},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine translation and foreign language education.
<em>FRAI</em>, <em>5</em>, 936111. (<a
href="https://doi.org/10.3389/frai.2022.936111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online machine translation tools have great potential to transform foreign language education. This essay will synthesize systematic research on the role of machine translation conducted in the field of educational linguistics. After describing approaches developed that promote the integration of machine translation into language learning environments, the essay will briefly outline lingering concerns associated with the integration of MT tools into educational settings. We will propose future R&amp;amp;D priorities that can generate products based on existing technologies that have the potential to support language learners more optimally compared to existing machine translation tools. We conclude that an acknowledgment of the difficulties of MT tools to handle socio-culturally complex source text would pave the way for the development of MT-based pedagogical tools.},
  archive      = {J_FRAI},
  author       = {Urlaub, Per and Dessein, Eva},
  doi          = {10.3389/frai.2022.936111},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {936111},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine translation and foreign language education},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inferior: The challenges of gender parity in the artificial
intelligence ecosystem-a case for canada. <em>FRAI</em>, <em>5</em>,
931182. (<a href="https://doi.org/10.3389/frai.2022.931182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) systems are gaining momentum in complementing and/or replacing performing tasks typically done with the aid of human ability. AI systems, inherently human creations, are, however, beset by, wittingly or unwittingly, so-called male chauvinism, despite all the advancements made in the progress of civilization to make inroads for women&#39;s equitable participation in the labor force, particularly in relation to the digital economy, and more importantly, AI. In regards to the Canadian context, this perspective has examined the evidence to find research highlighting gender representation in the Canadian AI ecosystem. We found a lack of studies on women and their contribution to AI-related activities. Canadian women&#39;s participation in their country&#39;s AI sector therefore should go beyond mere instruments such as the Montreal Declaration for a Responsible Development of AI, and disjointed interests. On a more general level, the paucity in a paradigm shift toward AI-female friendly policies from design phase to implementation omits the female voice for adequate representation for action. Advocating for Canadian women in the AI sector requires a voice of unison best achieved through parliamentary action. This perspective is thus issuing a clarion call to attaining gender fairness and equity, global principles under the United Nations (UN) Sustainable Development Goals, to which the Government of Canada is committed.},
  archive      = {J_FRAI},
  author       = {Daraz, Lubna and Chang, Bebe S. and Bouseh, Sheila},
  doi          = {10.3389/frai.2022.931182},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {931182},
  shortjournal = {Front. Artif. Intell.},
  title        = {Inferior: The challenges of gender parity in the artificial intelligence ecosystem-A case for canada},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The fourth industrial revolution – smart technology,
artificial intelligence, robotics and algorithms: Industrial
psychologists in future workplaces. <em>FRAI</em>, <em>5</em>, 913168.
(<a href="https://doi.org/10.3389/frai.2022.913168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Fourth Industrial Revolution (4IR), STARA (smart technology, artificial intelligence, robotics, and algorithms) is predicted to replace a third of the jobs that exist today. Almost twice as many current work tasks will be handled by robots. It is forecast that by 2025, 85 million jobs may be displaced by a shift in the division of labor between humans and machines, while 97 million new roles may emerge that are more adapted to the new division of labor between humans, machines and algorithms. Industrial psychologists are playing an increasingly important role in the workplace due to these trends from a strategic intelligence perspective. The objective of this article is to present a critical review of industrial psychologists in future workplaces in the context of the 4IR - STARA. A competence model is posed for industrial psychologists to perform a strategic intelligence role in organizations in the 4IR.},
  archive      = {J_FRAI},
  author       = {Oosthuizen, Rudolf M.},
  doi          = {10.3389/frai.2022.913168},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {913168},
  shortjournal = {Front. Artif. Intell.},
  title        = {The fourth industrial revolution – smart technology, artificial intelligence, robotics and algorithms: Industrial psychologists in future workplaces},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On distributed cognition while designing an AI system for
adapted learning. <em>FRAI</em>, <em>5</em>, 910630. (<a
href="https://doi.org/10.3389/frai.2022.910630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When analyzing learning, focus has traditionally been on the teacher, but has in the recent decades slightly moved toward the learner. This is also reflected when supporting systems, both computer-based and more practical equipment, has been introduced. Seeing learning as an integration of both an internal psychological process of acquisition and elaboration, and an external interaction process between the learner and the rest of the learning environment though, we see the necessity of expanding the vision and taking on a more holistic view to include the whole learning environment. Specially, when introducing an AI (artificial intelligence) system for adapting the learning process to an individual learner through machine learning, this AI system should take into account both the learner and the other agents and artifacts being part of this extended learning system. This paper outlines some lessons learned in a process of developing an electronic textbook adapting to a single learner through machine learning, to the process of extracting input from and providing feedback both to the learner, the teacher, the learning institution, and the learning resources provider based on a XAI (explainable artificial intelligence) system while also taking into account characteristics with respect to the learner&#39;s peers.},
  archive      = {J_FRAI},
  author       = {Aarset, Magne V. and Johannessen, Leiv Kåre},
  doi          = {10.3389/frai.2022.910630},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {910630},
  shortjournal = {Front. Artif. Intell.},
  title        = {On distributed cognition while designing an AI system for adapted learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pilot study of real-world monitoring of the heart rate
variability in amyotrophic lateral sclerosis. <em>FRAI</em>, <em>5</em>,
910049. (<a href="https://doi.org/10.3389/frai.2022.910049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AimsCardiovascular dysautonomia may impact the quality of life and survival in amyotrophic lateral sclerosis (ALS). Such dysfunction is not systematically assessed in these patients. Wearable devices could help. The feasibility of a wearable biosensor to detect heart rate variability (HRV), a physiological marker of sympathovagal balance, was studied for the first time in real-world settings in ALS.MethodsFive ALS patients (two early/three late; one bulbar-onset; mildly-to-moderately disabled) and five age/sex/BMI/comorbidities-matched controls underwent assessment of 3-day HRV via VitalConnect biosensor (worn on the left thorax). De-identified data captured by the biosensor were transferred to a secure cloud server via a relay Bluetooth device. Baseline ALS severity/anxiety and physical activity during testing were documented/quantified. Time-domain HRV measures (i.e., pNN50) were analyzed.ResultsAn overall 3-day abnormal HRV (pNN50 &amp;lt; 3%), was found in three out of five patients (mean ± SD for the group, 2.49 ± 1.51). Similar changes were reported in controls (12.32 ± 21.14%). There were no statistically significant relationships between pNN50 values and baseline anxiety or physical activity during the tested days (p &amp;gt; 0.05 for both groups). A negative correlation was found between pNN50 values and age in patients (p = 0.01) and controls (p = 0.09), which is similar with what is found in the general population. In line with prior studies, pNN50 values were independent of disease stage (p = 0.6) and disability (p = 0.4).ConclusionsThese preliminary results suggest that remote HRV measures using the VitalConnect is feasible and may constitute an improved strategy to provide insights into sympathovagal balance in ALS. Further work with larger sample sizes is warranted.},
  archive      = {J_FRAI},
  author       = {Brown, Alexander A. and Ferguson, Bradley J. and Jones, Vovanti and Green, Bruce E. and Pearre, Justin D. and Anunoby, Ifeoma A. and Beversdorf, David Q. and Barohn, Richard J. and Cirstea, Carmen M.},
  doi          = {10.3389/frai.2022.910049},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {910049},
  shortjournal = {Front. Artif. Intell.},
  title        = {Pilot study of real-world monitoring of the heart rate variability in amyotrophic lateral sclerosis},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unifying framework for reinforcement learning and
planning. <em>FRAI</em>, <em>5</em>, 908353. (<a
href="https://doi.org/10.3389/frai.2022.908353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential decision making, commonly formalized as optimization of a Markov Decision Process, is a key challenge in artificial intelligence. Two successful approaches to MDP optimization are reinforcement learning and planning, which both largely have their own research communities. However, if both research fields solve the same problem, then we might be able to disentangle the common factors in their solution approaches. Therefore, this paper presents a unifying algorithmic framework for reinforcement learning and planning (FRAP), which identifies underlying dimensions on which MDP planning and learning algorithms have to decide. At the end of the paper, we compare a variety of well-known planning, model-free and model-based RL algorithms along these dimensions. Altogether, the framework may help provide deeper insight in the algorithmic design space of planning and reinforcement learning.},
  archive      = {J_FRAI},
  author       = {Moerland, Thomas M. and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M.},
  doi          = {10.3389/frai.2022.908353},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {908353},
  shortjournal = {Front. Artif. Intell.},
  title        = {A unifying framework for reinforcement learning and planning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supporting cognition with modern technology: Distributed
cognition today and in an AI-enhanced future. <em>FRAI</em>, <em>5</em>,
908261. (<a href="https://doi.org/10.3389/frai.2022.908261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present article, we explore prospects for using artificial intelligence (AI) to distribute cognition via cognitive offloading (i.e., to delegate thinking tasks to AI-technologies). Modern technologies for cognitive support are rapidly developing and increasingly popular. Today, many individuals heavily rely on their smartphones or other technical gadgets to support their daily life but also their learning and work. For instance, smartphones are used to track and analyze changes in the environment, and to store and continually update relevant information. Thus, individuals can offload (i.e., externalize) information to their smartphones and refresh their knowledge by accessing it. This implies that using modern technologies such as AI empowers users via offloading and enables them to function as always-updated knowledge professionals, so that they can deploy their insights strategically instead of relying on outdated and memorized facts. This AI-supported offloading of cognitive processes also saves individuals&#39; internal cognitive resources by distributing the task demands into their environment. In this article, we provide (1) an overview of empirical findings on cognitive offloading and (2) an outlook on how individuals&#39; offloading behavior might change in an AI-enhanced future. More specifically, we first discuss determinants of offloading such as the design of technical tools and links to metacognition. Furthermore, we discuss benefits and risks of cognitive offloading. While offloading improves immediate task performance, it might also be a threat for users&#39; cognitive abilities. Following this, we provide a perspective on whether individuals will make heavier use of AI-technologies for offloading in the future and how this might affect their cognition. On one hand, individuals might heavily rely on easily accessible AI-technologies which in return might diminish their internal cognition/learning. On the other hand, individuals might aim at enhancing their cognition so that they can keep up with AI-technologies and will not be replaced by them. Finally, we present own data and findings from the literature on the assumption that individuals&#39; personality is a predictor of trust in AI. Trust in modern AI-technologies might be a strong determinant for wider appropriation and dependence on these technologies to distribute cognition and should thus be considered in an AI-enhanced future.},
  archive      = {J_FRAI},
  author       = {Grinschgl, Sandra and Neubauer, Aljoscha C.},
  doi          = {10.3389/frai.2022.908261},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {908261},
  shortjournal = {Front. Artif. Intell.},
  title        = {Supporting cognition with modern technology: Distributed cognition today and in an AI-enhanced future},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Benchmarking perturbation-based saliency maps for explaining
atari agents. <em>FRAI</em>, <em>5</em>, 903875. (<a
href="https://doi.org/10.3389/frai.2022.903875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most prominent methods for explaining the behavior of Deep Reinforcement Learning (DRL) agents is the generation of saliency maps that show how much each pixel attributed to the agents&#39; decision. However, there is no work that computationally evaluates and compares the fidelity of different perturbation-based saliency map approaches specifically for DRL agents. It is particularly challenging to computationally evaluate saliency maps for DRL agents since their decisions are part of an overarching policy, which includes long-term decision making. For instance, the output neurons of value-based DRL algorithms encode both the value of the current state as well as the expected future reward after doing each action in this state. This ambiguity should be considered when evaluating saliency maps for such agents. In this paper, we compare five popular perturbation-based approaches to create saliency maps for DRL agents trained on four different Atari 2,600 games. The approaches are compared using two computational metrics: dependence on the learned parameters of the underlying deep Q-network of the agents (sanity checks) and fidelity to the agents&#39; reasoning (input degradation). During the sanity checks, we found that a popular noise-based saliency map approach for DRL agents shows little dependence on the parameters of the output layer. We demonstrate that this can be fixed by tweaking the algorithm such that it focuses on specific actions instead of the general entropy within the output values. For fidelity, we identify two main factors that influence which saliency map approach should be chosen in which situation. Particular to value-based DRL agents, we show that analyzing the agents&#39; choice of action requires different saliency map approaches than analyzing the agents&#39; state value estimation.},
  archive      = {J_FRAI},
  author       = {Huber, Tobias and Limmer, Benedikt and André, Elisabeth},
  doi          = {10.3389/frai.2022.903875},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {903875},
  shortjournal = {Front. Artif. Intell.},
  title        = {Benchmarking perturbation-based saliency maps for explaining atari agents},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The interactive reading task: Transformer-based automatic
item generation. <em>FRAI</em>, <em>5</em>, 903077. (<a
href="https://doi.org/10.3389/frai.2022.903077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic item generation (AIG) has the potential to greatly expand the number of items for educational assessments, while simultaneously allowing for a more construct-driven approach to item development. However, the traditional item modeling approach in AIG is limited in scope to content areas that are relatively easy to model (such as math problems), and depends on highly skilled content experts to create each model. In this paper we describe the interactive reading task, a transformer-based deep language modeling approach for creating reading comprehension assessments. This approach allows a fully automated process for the creation of source passages together with a wide range of comprehension questions about the passages. The format of the questions allows automatic scoring of responses with high fidelity (e.g., selected response questions). We present the results of a large-scale pilot of the interactive reading task, with hundreds of passages and thousands of questions. These passages were administered as part of the practice test of the Duolingo English Test. Human review of the materials and psychometric analyses of test taker results demonstrate the feasibility of this approach for automatic creation of complex educational assessments.},
  archive      = {J_FRAI},
  author       = {Attali, Yigal and Runge, Andrew and LaFlair, Geoffrey T. and Yancey, Kevin and Goodwin, Sarah and Park, Yena and von Davier, Alina A.},
  doi          = {10.3389/frai.2022.903077},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {903077},
  shortjournal = {Front. Artif. Intell.},
  title        = {The interactive reading task: Transformer-based automatic item generation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online brand community user segments: A text mining
approach. <em>FRAI</em>, <em>5</em>, 900775. (<a
href="https://doi.org/10.3389/frai.2022.900775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a trend that customers increasingly join the online brand community. However, evidence shows that there are nuances between different user segments, and only a small group of users are active. Thus, one key concern marketers face is identifying and targeting specific segments and decreasing user churn rates in an online environment. To this end, this study aims to propose a UGC-based segmentation of online brand community users, identify the characteristics of each segment, and consequently reduce online brand community users&#39; churn rate. We used python to obtain users&#39; post data from a well-known online brand community in China between July 2012 and December 2019, resulting in 912,452 posts and 20,493 users. We then use text mining and clustering methods to segment the users and compare the differences between the segments. Three groups—information-oriented users, entertainment-oriented users, and multi-motivation users—were emerged. Our results imply that entertainment-oriented users were the most active, yet, multi-directional users have the lowest probability of churn, with a churn rate of only 0.607 times than that of users who focus either on information or entertainment. Implications for marketing and future research opportunities are discussed.},
  archive      = {J_FRAI},
  author       = {Ge, Ruichen and Zhao, Hong and Zhang, Sha},
  doi          = {10.3389/frai.2022.900775},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {900775},
  shortjournal = {Front. Artif. Intell.},
  title        = {Online brand community user segments: A text mining approach},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding robustness and generalization of artificial
neural networks through fourier masks. <em>FRAI</em>, <em>5</em>,
890016. (<a href="https://doi.org/10.3389/frai.2022.890016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the enormous success of artificial neural networks (ANNs) in many disciplines, the characterization of their computations and the origin of key properties such as generalization and robustness remain open questions. Recent literature suggests that robust networks with good generalization properties tend to be biased toward processing low frequencies in images. To explore the frequency bias hypothesis further, we develop an algorithm that allows us to learn modulatory masks highlighting the essential input frequencies needed for preserving a trained network&#39;s performance. We achieve this by imposing invariance in the loss with respect to such modulations in the input frequencies. We first use our method to test the low-frequency preference hypothesis of adversarially trained or data-augmented networks. Our results suggest that adversarially robust networks indeed exhibit a low-frequency bias but we find this bias is also dependent on directions in frequency space. However, this is not necessarily true for other types of data augmentation. Our results also indicate that the essential frequencies in question are effectively the ones used to achieve generalization in the first place. Surprisingly, images seen through these modulatory masks are not recognizable and resemble texture-like patterns.},
  archive      = {J_FRAI},
  author       = {Karantzas, Nikos and Besier, Emma and Ortega Caro, Josue and Pitkow, Xaq and Tolias, Andreas S. and Patel, Ankit B. and Anselmi, Fabio},
  doi          = {10.3389/frai.2022.890016},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {890016},
  shortjournal = {Front. Artif. Intell.},
  title        = {Understanding robustness and generalization of artificial neural networks through fourier masks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recommendations for ethical and responsible use of
artificial intelligence in digital agriculture. <em>FRAI</em>,
<em>5</em>, 884192. (<a
href="https://doi.org/10.3389/frai.2022.884192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) applications are an integral and emerging component of digital agriculture. AI can help ensure sustainable production in agriculture by enhancing agricultural operations and decision-making. Recommendations about soil condition and pesticides or automatic devices for milking and apple picking are examples of AI applications in digital agriculture. Although AI offers many benefits in farming, AI systems may raise ethical issues and risks that should be assessed and proactively managed. Poor design and configuration of intelligent systems may impose harm and unintended consequences on digital agriculture. Invasion of farmers&#39; privacy, damaging animal welfare due to robotic technologies, and lack of accountability for issues resulting from the use of AI tools are only some examples of ethical challenges in digital agriculture. This paper examines the ethical challenges of the use of AI in agriculture in six categories including fairness, transparency, accountability, sustainability, privacy, and robustness. This study further provides recommendations for agriculture technology providers (ATPs) and policymakers on how to proactively mitigate ethical issues that may arise from the use of AI in farming. These recommendations cover a wide range of ethical considerations, such as addressing farmers&#39; privacy concerns, ensuring reliable AI performance, enhancing sustainability in AI systems, and reducing AI bias.},
  archive      = {J_FRAI},
  author       = {Dara, Rozita and Hazrati Fard, Seyed Mehdi and Kaur, Jasmin},
  doi          = {10.3389/frai.2022.884192},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {884192},
  shortjournal = {Front. Artif. Intell.},
  title        = {Recommendations for ethical and responsible use of artificial intelligence in digital agriculture},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Experiences of game-based learning and reviewing history of
the experience using player’s emotions. <em>FRAI</em>, <em>5</em>,
874106. (<a href="https://doi.org/10.3389/frai.2022.874106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss whether the history of a learning experience, containing action and emotion information, is useful for review of the experience in game-based learning using virtual space. We developed a game-based story generation system that automatically generates scripts in real time by using a player&#39;s emotions and actions. The system has two functions: a game-based experiential learning environment and automatic story generation. The system provides the player with a virtual world and a virtual tool operated by using a hand controller and a display. The system recognizes the player&#39;s real-time emotions through facial expressions, and it outputs reactions based on these emotions and actions via a knowledge-based system when the player operates the tool. Then, it outputs scripts based on the emotions and the history of actions. We evaluated the system by conducting experiments with university students as subjects. As a result, subjects found the stories generated by this system interesting because they were based on the player&#39;s experience in the game and used the player&#39;s behavioral history and emotions. If we consider this as a record of the learning experience, the learning history is an impressive record accompanied by emotions. Thus, historical information that records the actions and emotions of the learner in real time is considered effective because it allows the learner to recall his or her own experiences after the game experience. The results suggest that the historical information, including the learner&#39;s real-time actions and emotions, is helpful for review in learning. There is a possibility that experiential learning through games using virtual spaces, such as the one used in this study, will become widespread in the future. In such cases, it will be necessary to examine the learning effects of using historical information with emotions. Therefore, we believe that the results and discussions in this study will be useful for experiential learning using virtual spaces.},
  archive      = {J_FRAI},
  author       = {Sumi, Kaoru and Sato, Shusuke},
  doi          = {10.3389/frai.2022.874106},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {874106},
  shortjournal = {Front. Artif. Intell.},
  title        = {Experiences of game-based learning and reviewing history of the experience using player&#39;s emotions},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparing deep learning approaches for understanding
genotype × phenotype interactions in biomass sorghum. <em>FRAI</em>,
<em>5</em>, 872858. (<a
href="https://doi.org/10.3389/frai.2022.872858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the use of deep convolutional neural networks (CNNs) trained on overhead imagery of biomass sorghum to ascertain the relationship between single nucleotide polymorphisms (SNPs), or groups of related SNPs, and the phenotypes they control. We consider both CNNs trained explicitly on the classification task of predicting whether an image shows a plant with a reference or alternate version of various SNPs as well as CNNs trained to create data-driven features based on learning features so that images from the same plot are more similar than images from different plots, and then using the features this network learns for genetic marker classification. We characterize how efficient both approaches are at predicting the presence or absence of a genetic markers, and visualize what parts of the images are most important for those predictions. We find that the data-driven approaches give somewhat higher prediction performance, but have visualizations that are harder to interpret; and we give suggestions of potential future machine learning research and discuss the possibilities of using this approach to uncover unknown genotype × phenotype relationships.},
  archive      = {J_FRAI},
  author       = {Zhang, Zeyu and Pope, Madison and Shakoor, Nadia and Pless, Robert and Mockler, Todd C. and Stylianou, Abby},
  doi          = {10.3389/frai.2022.872858},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {872858},
  shortjournal = {Front. Artif. Intell.},
  title        = {Comparing deep learning approaches for understanding genotype × phenotype interactions in biomass sorghum},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Politics by automatic means? A critique of artificial
intelligence ethics at work. <em>FRAI</em>, <em>5</em>, 869114. (<a
href="https://doi.org/10.3389/frai.2022.869114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calls for “ethical Artificial Intelligence” are legion, with a recent proliferation of government and industry guidelines attempting to establish ethical rules and boundaries for this new technology. With few exceptions, they interpret Artificial Intelligence (AI) ethics narrowly in a liberal political framework of privacy concerns, transparency, governance and non-discrimination. One of the main hurdles to establishing “ethical AI” remains how to operationalize high-level principles such that they translate to technology design, development and use in the labor process. This is because organizations can end up interpreting ethics in an ad-hoc way with no oversight, treating ethics as simply another technological problem with technological solutions, and regulations have been largely detached from the issues AI presents for workers. There is a distinct lack of supra-national standards for fair, decent, or just AI in contexts where people depend on and work in tandem with it. Topics such as discrimination and bias in job allocation, surveillance and control in the labor process, and quantification of work have received significant attention, yet questions around AI and job quality and working conditions have not. This has left workers exposed to potential risks and harms of AI. In this paper, we provide a critique of relevant academic literature and policies related to AI ethics. We then identify a set of principles that could facilitate fairer working conditions with AI. As part of a broader research initiative with the Global Partnership on Artificial Intelligence, we propose a set of accountability mechanisms to ensure AI systems foster fairer working conditions. Such processes are aimed at reshaping the social impact of technology from the point of inception to set a research agenda for the future. As such, the key contribution of the paper is how to bridge from abstract ethical principles to operationalizable processes in the vast field of AI and new technology at work.},
  archive      = {J_FRAI},
  author       = {Cole, Matthew and Cant, Callum and Ustek Spilda, Funda and Graham, Mark},
  doi          = {10.3389/frai.2022.869114},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {869114},
  shortjournal = {Front. Artif. Intell.},
  title        = {Politics by automatic means? a critique of artificial intelligence ethics at work},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An occupational safety and health perspective on human in
control and AI. <em>FRAI</em>, <em>5</em>, 868382. (<a
href="https://doi.org/10.3389/frai.2022.868382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous and rapid development of AI-based systems comes along with an increase in automation of tasks and, therewith, a qualitative shift in opportunities and challenges for occupational safety and health. A fundamental aspect of humane working conditions is the ability to exert influence over different aspects of one&#39;s own work. Consequently, stakeholders contribute to the prospect of maintaining the workers&#39; autonomy albeit increasing automation and summarize this aspiration with the human in control principle. Job control has been part of multiple theories and models within the field of occupational psychology. However, most of the models do not include specific technical considerations nor focus on task but rather on job level. That is, they are possibly not able to fully explain specific changes regarding the digitalization of tasks. According to the results of a large-scale study on German workers (DiWaBe), this seems to be the case to some extend: the influence of varying degrees of automation, moderated by perceived autonomy, on workers&#39; wellbeing was not consistent. However, automation is a double-edged sword: on a high level, it can be reversely related to the workers&#39; job control while highly autonomous and reliable systems can also create opportunities for more flexible, impactful and diverse working tasks. Consequently, automation can foster and decrease the factor of job control. Models about the optimal level of automation aim to give guidelines on how the former can be achieved. The results of the DiWaBe study indicate that automation in occupational practice does not always happen in line with these models. Instead, a substantial part of automation happens at the decision-making level, while executive actions remain with the human. From an occupational safety and health perspective, it is therefore crucial to closely monitor and anticipate the implementation of AI in working systems. Constellations where employees are too controlled by technology and are left with a high degree of demands and very limited resources should be avoided. Instead, it would be favorable to use AI as an assistance tool for the employees, helping them to gather and process information and assisting them in decision-making.},
  archive      = {J_FRAI},
  author       = {Niehaus, Susanne and Hartwig, Matthias and Rosen, Patricia H. and Wischniewski, Sascha},
  doi          = {10.3389/frai.2022.868382},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {868382},
  shortjournal = {Front. Artif. Intell.},
  title        = {An occupational safety and health perspective on human in control and AI},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dichotomic pattern mining integrated with constraint
reasoning for digital behavior analysis. <em>FRAI</em>, <em>5</em>,
868085. (<a href="https://doi.org/10.3389/frai.2022.868085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential pattern mining remains a challenging task due to the large number of redundant candidate patterns and the exponential search space. In addition, further analysis is still required to map extracted patterns to different outcomes. In this paper, we introduce a pattern mining framework that operates on semi-structured datasets and exploits the dichotomy between outcomes. Our approach takes advantage of constraint reasoning to find sequential patterns that occur frequently and exhibit desired properties. This allows the creation of novel pattern embeddings that are useful for knowledge extraction and predictive modeling. Based on dichotomic pattern mining, we present two real-world applications for customer intent prediction and intrusion detection. Overall, our approach plays an integrator role between semi-structured sequential data and machine learning models, improves the performance of the downstream task, and retains interpretability.},
  archive      = {J_FRAI},
  author       = {Ghosh, Sohom and Yadav, Shefali and Wang, Xin and Chakrabarty, Bibhash and Kadıoğlu, Serdar},
  doi          = {10.3389/frai.2022.868085},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {868085},
  shortjournal = {Front. Artif. Intell.},
  title        = {Dichotomic pattern mining integrated with constraint reasoning for digital behavior analysis},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generative models of brain dynamics. <em>FRAI</em>,
<em>5</em>, 807406. (<a
href="https://doi.org/10.3389/frai.2022.807406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review article gives a high-level overview of the approaches across different scales of organization and levels of abstraction. The studies covered in this paper include fundamental models in computational neuroscience, nonlinear dynamics, data-driven methods, as well as emergent practices. While not all of these models span the intersection of neuroscience, AI, and system dynamics, all of them do or can work in tandem as generative models, which, as we argue, provide superior properties for the analysis of neuroscientific data. We discuss the limitations and unique dynamical traits of brain data and the complementary need for hypothesis- and data-driven modeling. By way of conclusion, we present several hybrid generative models from recent literature in scientific machine learning, which can be efficiently deployed to yield interpretable models of neural dynamics.},
  archive      = {J_FRAI},
  author       = {Ramezanian-Panahi, Mahta and Abrevaya, Germán and Gagnon-Audet, Jean-Christophe and Voleti, Vikram and Rish, Irina and Dumas, Guillaume},
  doi          = {10.3389/frai.2022.807406},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {807406},
  shortjournal = {Front. Artif. Intell.},
  title        = {Generative models of brain dynamics},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel bayesian general medical diagnostic assistant
achieves superior accuracy with sparse history. <em>FRAI</em>,
<em>5</em>, 727486. (<a
href="https://doi.org/10.3389/frai.2022.727486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online AI symptom checkers and diagnostic assistants (DAs) have tremendous potential to reduce misdiagnosis and cost, while increasing the quality, convenience, and availability of healthcare, but only if they can perform with high accuracy. We introduce a novel Bayesian DA designed to improve diagnostic accuracy by addressing key weaknesses of Bayesian Network implementations for clinical diagnosis. We compare the performance of our prototype DA (MidasMed) to that of physicians and six other publicly accessible DAs (Ada, Babylon, Buoy, Isabel, Symptomate, and WebMD) using a set of 30 publicly available case vignettes, and using only sparse history (no exam findings or tests). Our results demonstrate superior performance of the MidasMed DA, with the correct diagnosis being the top ranked disorder in 93% of cases, and in the top 3 in 96% of cases.},
  archive      = {J_FRAI},
  author       = {Jones, Alicia M. and Jones, Daniel R.},
  doi          = {10.3389/frai.2022.727486},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {7},
  pages        = {727486},
  shortjournal = {Front. Artif. Intell.},
  title        = {A novel bayesian general medical diagnostic assistant achieves superior accuracy with sparse history},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Artificial intelligence and machine learning
applications in plant genomics and genetics. <em>FRAI</em>, <em>5</em>,
959470. (<a href="https://doi.org/10.3389/frai.2022.959470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {van Dijk, Aalt D. J. and Shiu, Shin-Han and de Ridder, Dick},
  doi          = {10.3389/frai.2022.959470},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {959470},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Artificial intelligence and machine learning applications in plant genomics and genetics},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Intelligence support for mentoring processes in
higher education (and beyond). <em>FRAI</em>, <em>5</em>, 935020. (<a
href="https://doi.org/10.3389/frai.2022.935020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Klamma, Ralf and Kravčík, Miloš and Pammer-Schindler, Viktoria and Popescu, Elvira},
  doi          = {10.3389/frai.2022.935020},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {935020},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Intelligence support for mentoring processes in higher education (and beyond)},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph learning for fake review detection. <em>FRAI</em>,
<em>5</em>, 922589. (<a
href="https://doi.org/10.3389/frai.2022.922589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake reviews have become prevalent on various social networks such as e-commerce and social media platforms. As fake reviews cause a heavily negative influence on the public, timely detection and response are of great significance. To this end, effective fake review detection has become an emerging research area that attracts increasing attention from various disciplines like network science, computational social science, and data science. An important line of research in fake review detection is to utilize graph learning methods, which incorporate both the attribute features of reviews and their relationships into the detection process. To further compare these graph learning methods in this paper, we conduct a detailed survey on fake review detection. The survey presents a comprehensive taxonomy and covers advancements in three high-level categories, including fake review detection, fake reviewer detection, and fake review analysis. Different kinds of fake reviews and their corresponding examples are also summarized. Furthermore, we discuss the graph learning methods, including supervised and unsupervised learning approaches for fake review detection. Specifically, we outline the unsupervised learning approach that includes generation-based and contrast-based methods, respectively. In view of the existing problems in the current methods and data, we further discuss some challenges and open issues in this field, including the imperfect data, explainability, model efficiency, and lightweight models.},
  archive      = {J_FRAI},
  author       = {Yu, Shuo and Ren, Jing and Li, Shihao and Naseriparsa, Mehdi and Xia, Feng},
  doi          = {10.3389/frai.2022.922589},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {922589},
  shortjournal = {Front. Artif. Intell.},
  title        = {Graph learning for fake review detection},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Infusing expert knowledge into a deep neural network using
attention mechanism for personalized learning environments.
<em>FRAI</em>, <em>5</em>, 921476. (<a
href="https://doi.org/10.3389/frai.2022.921476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are biased toward data seen during the training steps. The models will tend to give good results in classes where there are many examples and poor results in those with few examples. This problem generally occurs when the classes to predict are imbalanced and this is frequent in educational data where for example, there are skills that are very difficult or very easy to master. There will be less data on students that correctly answered questions related to difficult skills and who incorrectly answered those related to skills easy to master. In this paper, we tackled this problem by proposing a hybrid architecture combining Deep Neural Network architectures— especially Long Short-Term Memory (LSTM) and Convolutional Neural Networks (CNN)—with expert knowledge for user modeling. The proposed solution uses attention mechanism to infuse expert knowledge into the Deep Neural Network. It has been tested in two contexts: knowledge tracing in an intelligent tutoring system (ITS) called Logic-Muse and prediction of socio-moral reasoning in a serious game called MorALERT. The proposed solution is compared to state-of-the-art machine learning solutions and experiments show that the resulting model can accurately predict the current student&#39;s knowledge state (in Logic-Muse) and thus enable an accurate personalization of the learning process. Other experiments show that the model can also be used to predict the level of socio-moral reasoning skills (in MorALERT). Our findings suggest the need for hybrid neural networks that integrate prior expert knowledge (especially when it is necessary to compensate for the strong dependency—of deep learning methods—on data size or the possible unbalanced datasets). Many domains can benefit from such an approach to building models that allow generalization even when there are small training data.},
  archive      = {J_FRAI},
  author       = {Tato, Ange and Nkambou, Roger},
  doi          = {10.3389/frai.2022.921476},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {921476},
  shortjournal = {Front. Artif. Intell.},
  title        = {Infusing expert knowledge into a deep neural network using attention mechanism for personalized learning environments},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging open electronic health record data and
environmental exposures data to derive insights into rare pulmonary
disease. <em>FRAI</em>, <em>5</em>, 918888. (<a
href="https://doi.org/10.3389/frai.2022.918888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on rare diseases has received increasing attention, in part due to the realized profitability of orphan drugs. Biomedical informatics holds promise in accelerating translational research on rare disease, yet challenges remain, including the lack of diagnostic codes for rare diseases and privacy concerns that prevent research access to electronic health records when few patients exist. The Integrated Clinical and Environmental Exposures Service (ICEES) provides regulatory-compliant open access to electronic health record data that have been integrated with environmental exposures data, as well as analytic tools to explore the integrated data. We describe a proof-of-concept application of ICEES to examine demographics, clinical characteristics, environmental exposures, and health outcomes among a cohort of patients enriched for phenotypes associated with cystic fibrosis (CF), idiopathic bronchiectasis (IB), and primary ciliary dyskinesia (PCD). We then focus on a subset of patients with CF, leveraging the availability of a diagnostic code for CF and serving as a benchmark for our development work. We use ICEES to examine select demographics, co-diagnoses, and environmental exposures that may contribute to poor health outcomes among patients with CF, defined as emergency department or inpatient visits for respiratory issues. We replicate current understanding of the pathogenesis and clinical manifestations of CF by identifying co-diagnoses of asthma, chronic nasal congestion, cough, middle ear disease, and pneumonia as factors that differentiate patients with poor health outcomes from those with better health outcomes. We conclude by discussing our preliminary findings in relation to other published work, the strengths and limitations of our approach, and our future directions.},
  archive      = {J_FRAI},
  author       = {Fecho, Karamarie and Ahalt, Stanley C. and Knowles, Michael and Krishnamurthy, Ashok and Leigh, Margaret and Morton, Kenneth and Pfaff, Emily and Wang, Max and Yi, Hong},
  doi          = {10.3389/frai.2022.918888},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {918888},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging open electronic health record data and environmental exposures data to derive insights into rare pulmonary disease},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross country determinants of investors’ sentiments
prediction in emerging markets using ANN. <em>FRAI</em>, <em>5</em>,
912403. (<a href="https://doi.org/10.3389/frai.2022.912403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper models investor sentiments (IS) to attract investments for Health Sector and Growth in emerging markets, viz., India, Mainland China, and the UAE, by asking questions such as: What specific healthcare sector opportunities are available in the three markets? Are the USA-IS key IS predictors in the three economies? How important are macroeconomic and sociocultural factors in predicting IS in these markets? How important are economic crises and pandemic events in predicting IS in these markets? Is there contemporaneous relation in predicting IS across the three countries in terms of USA-IS, and, if yes, is the magnitude of the impact of USA-IS uniform across the three countries&#39; IS? The artificial neural network (ANN) model is applied to weekly time-series data from January 2003 to December 2020 to capture behavioral elements in the investors&#39; decision-making in these emerging economies. The empirical findings confirmed the superiority of the ANN framework over the traditional logistic model in capturing the cognitive behavior of investors. Health predictor—current health expenditure as a percentage of GDP, USA IS predictor—spread, and Macro-factor GDP—annual growth % are the common predictors across the 3 economies that positively impacted the emerging markets&#39; IS behavior. USA (S&amp;amp;P 500) return is the only common predictor across the three economies that negatively impacted the emerging markets&#39; IS behavior. However, the magnitude of both positive and negative impacts varies across the countries, signifying unique, diverse socioeconomic, cultural, and market features in each of the 3 economies. The results have four key implications: Firstly, US market sentiments are an essential factor influencing stock markets in these countries. Secondly, there is a need for developing a robust sentiment proxy on similar lines to the USA in the three countries. Thirdly, investment opportunities in the healthcare sector in these economies have been identified for potential investments by the investors. Fourthly, this study is the first study to investigate investors&#39; sentiments in these three fast-emerging economies to attract investments in the Health Sector and Growth in the backdrop of UN&#39;s 2030 SDG 3 and SDG 8 targets to be achieved by these economies.},
  archive      = {J_FRAI},
  author       = {Rao, Ananth and M. V., Manoj Kumar and Moonesar, Immanuel Azaad and Atalla, Shadi and Prashanth, B. S. and Joshi, Gaurav and Soni, Tarun K. and Le, Thi and Verma, Anuj and Marashdeh, Hazem},
  doi          = {10.3389/frai.2022.912403},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {912403},
  shortjournal = {Front. Artif. Intell.},
  title        = {Cross country determinants of investors&#39; sentiments prediction in emerging markets using ANN},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ICT enabled disease diagnosis, treatment and management—a
holistic cost-effective approach through data management and analysis in
UAE and india. <em>FRAI</em>, <em>5</em>, 909101. (<a
href="https://doi.org/10.3389/frai.2022.909101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This concept paper addresses specific challenges identified in the UN 2030 Agenda Sustainable Development Goals (SDG) as well as the National Health Policy of India (NHP-India) and the Ministry of Health Policy of UAE (MHP-UAE). This policy calls for a digital health technology ecosystem. SDG Goal 1 and its related objectives are conceptualized which serves as the foundation for Virtual Consultations, Tele-pharmacy, Virtual Storage, and Virtual Community (VCom). SDG Goals 2 and 3 are conceptualized as Data Management &amp;amp; Analytical (DMA) Architecture. Individual researchers and health care professionals in India and the UAE can use DMA to uncover and harness PHC and POC data into practical insights. In addition, the DMA would provide a set of core tools for cross-network initiatives, allowing researchers and other users to compare their data with DMA data. In rural, urban, and remote populations of the UAE and India, the concept augments the PHC system with ICT-based interventions. The ICT-based interventions may improve patient health outcomes. The open and flexible design allows users to access various digital materials. Extendable data/metadata format, scalable architecture for petabyte-scale federated discovery. The modular DMA is designed using existing technology and resources. Public health functions include population health assessment, policy development, and monitoring policy implementation. PHC and POC periodically conduct syndromic surveillance to identify population risk patterns. In addition, the PHC and POC deploy medical and non-medical preventive measures to prevent disease outbreaks. To assess the impact of social and economic factors on health, epidemiologists must first understand diseases. Improved health due to compliance with holistic disease treatment plans and access to scientific health information.},
  archive      = {J_FRAI},
  author       = {Kumar M V, Manoj and Patil, Jagadish and Shastry, K. Aditya and Darshan, Shiva and Sastry, Nanda Kumar Bidare and Moonesar, Immanuel Azaad and Atalla, Shadi and Almuraqab, Nasser and Rao, Ananth},
  doi          = {10.3389/frai.2022.909101},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {909101},
  shortjournal = {Front. Artif. Intell.},
  title        = {ICT enabled disease diagnosis, treatment and Management—A holistic cost-effective approach through data management and analysis in UAE and india},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bridging the gap of AutoGraph between academia and industry:
Analyzing AutoGraph challenge at KDD cup 2020. <em>FRAI</em>,
<em>5</em>, 905104. (<a
href="https://doi.org/10.3389/frai.2022.905104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph structured data is ubiquitous in daily life and scientific areas and has attracted increasing attention. Graph Neural Networks (GNNs) have been proved to be effective in modeling graph structured data and many variants of GNN architectures have been proposed. However, much human effort is often needed to tune the architecture depending on different datasets. Researchers naturally adopt Automated Machine Learning on Graph Learning, aiming to reduce human effort and achieve generally top-performing GNNs, but their methods focus more on the architecture search. To understand GNN practitioners&#39; automated solutions, we organized AutoGraph Challenge at KDD Cup 2020, emphasizing automated graph neural networks for node classification. We received top solutions, especially from industrial technology companies like Meituan, Alibaba, and Twitter, which are already open sourced on GitHub. After detailed comparisons with solutions from academia, we quantify the gaps between academia and industry on modeling scope, effectiveness, and efficiency, and show that (1) academic AutoML for Graph solutions focus on GNN architecture search while industrial solutions, especially the winning ones in the KDD Cup, tend to obtain an overall solution (2) with only neural architecture search, academic solutions achieve on average 97.3% accuracy of industrial solutions (3) academic solutions are cheap to obtain with several GPU hours while industrial solutions take a few months&#39; labors. Academic solutions also contain much fewer parameters.},
  archive      = {J_FRAI},
  author       = {Xu, Zhen and Wei, Lanning and Zhao, Huan and Ying, Rex and Yao, Quanming and Tu, Wei-Wei and Guyon, Isabelle},
  doi          = {10.3389/frai.2022.905104},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {905104},
  shortjournal = {Front. Artif. Intell.},
  title        = {Bridging the gap of AutoGraph between academia and industry: Analyzing AutoGraph challenge at KDD cup 2020},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Educational automatic question generation improves reading
comprehension in non-native speakers: A learner-centric case study.
<em>FRAI</em>, <em>5</em>, 900304. (<a
href="https://doi.org/10.3389/frai.2022.900304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundAsking learners manually authored questions about their readings improves their text comprehension. Yet, not all reading materials comprise sufficiently many questions and many informal reading materials do not contain any. Therefore, automatic question generation has great potential in education as it may alleviate the lack of questions. However, currently, there is insufficient evidence on whether or not those automatically generated questions are beneficial for learners&#39; understanding in reading comprehension scenarios.ObjectivesWe investigate the positive and negative effects of automatically generated short-answer questions on learning outcomes in a reading comprehension scenario.MethodsA learner-centric, in between-groups, quasi-experimental reading comprehension case study with 48 college students is conducted. We test two hypotheses concerning positive and negative effects on learning outcomes during the text comprehension of science texts and descriptively explore how the generated questions influenced learners.ResultsThe results show a positive effect of the generated questions on the participants learning outcomes. However, we cannot entirely exclude question-induced adverse side effects on learning of non-questioned information. Interestingly, questions identified as computer-generated by learners nevertheless seemed to benefit their understanding.Take AwayAutomatic question generation positively impacts reading comprehension in the given scenario. In the reported case study, even questions recognized as computer-generated supported reading comprehension.},
  archive      = {J_FRAI},
  author       = {Steuer, Tim and Filighera, Anna and Tregel, Thomas and Miede, André},
  doi          = {10.3389/frai.2022.900304},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {900304},
  shortjournal = {Front. Artif. Intell.},
  title        = {Educational automatic question generation improves reading comprehension in non-native speakers: A learner-centric case study},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The relationship between performance and trust in AI in
e-finance. <em>FRAI</em>, <em>5</em>, 891529. (<a
href="https://doi.org/10.3389/frai.2022.891529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is fundamentally changing how people work in nearly every field, including online finance. However, our ability to interact with AI is moderated by factors such as performance, complexity, and trust. The work presented in this study analyzes the effect of performance on trust in a robo-advisor (AI which assists in managing investments) through an empirical investment simulation. Results show that for applications where humans and AI have comparable capabilities, the difference in performance (between the human and AI) is a moderate indicator of change in trust; however, human or AI performance individually were weak indicators. Additionally, results indicate that biases typically seen in human-human interactions may also occur in human-AI interactions when AI transparency is low.},
  archive      = {J_FRAI},
  author       = {Maier, Torsten and Menold, Jessica and McComb, Christopher},
  doi          = {10.3389/frai.2022.891529},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {891529},
  shortjournal = {Front. Artif. Intell.},
  title        = {The relationship between performance and trust in AI in E-finance},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on human cancer categorization based on deep
learning. <em>FRAI</em>, <em>5</em>, 884749. (<a
href="https://doi.org/10.3389/frai.2022.884749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, we have witnessed the fast growth of deep learning, which involves deep neural networks, and the development of the computing capability of computer devices following the advance of graphics processing units (GPUs). Deep learning can prototypically and successfully categorize histopathological images, which involves imaging classification. Various research teams apply deep learning to medical diagnoses, especially cancer diseases. Convolutional neural networks (CNNs) detect the conventional visual features of disease diagnoses, e.g., lung, skin, brain, prostate, and breast cancer. A CNN has a procedure for perfectly investigating medicinal science images. This study assesses the main deep learning concepts relevant to medicinal image investigation and surveys several charities in the field. In addition, it covers the main categories of imaging procedures in medication. The survey comprises the usage of deep learning for object detection, classification, and human cancer categorization. In addition, the most popular cancer types have also been introduced. This article discusses the Vision-Based Deep Learning System among the dissimilar sorts of data mining techniques and networks. It then introduces the most extensively used DL network category, which is convolutional neural networks (CNNs) and investigates how CNN architectures have evolved. Starting with Alex Net and progressing with the Google and VGG networks, finally, a discussion of the revealed challenges and trends for upcoming research is held.},
  archive      = {J_FRAI},
  author       = {Ibrahim, Ahmad and Mohamed, Hoda K. and Maher, Ali and Zhang, Baochang},
  doi          = {10.3389/frai.2022.884749},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {884749},
  shortjournal = {Front. Artif. Intell.},
  title        = {A survey on human cancer categorization based on deep learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short-term nationwide airport throughput prediction with
graph attention recurrent neural network. <em>FRAI</em>, <em>5</em>,
884485. (<a href="https://doi.org/10.3389/frai.2022.884485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the dynamic air traffic demand and the constrained capacity resources, accurately predicting airport throughput is essential to ensure the efficiency and resilience of air traffic operations. Many research efforts have been made to predict traffic throughputs or flight delays at an airport or over a network. However, it is still a challenging problem due to the complex spatiotemporal dynamics of the highly interacted air transportation systems. To address this challenge, we propose a novel deep learning model, graph attention neural network stacking with a Long short-term memory unit (GAT-LSTM), to predict the short-term airport throughput over a national air traffic network. LSTM layers are included to extract the temporal correlations in the data, while the graph attention mechanism is used to capture the spatial dependencies. For the graph attention mechanism, two graph modeling methods, airport-based graph and OD-pair graph are explored in this study. We tested the proposed model using real-world air traffic data involving 65 major airports in China over 3 months in 2017 and compared its performance with other state-of-the-art models. Results showed that the temporal pattern was the dominate factor, compared to the spatial pattern, in predicting airport throughputs over an air traffic network. Among the prediction models that we compared, both the proposed model and LSTM performed well on prediction accuracy over the entire network. Better performance of the proposed model was observed when focusing on airports with larger throughputs. We also conducted an analysis on model interpretability. We found that spatiotemporal correlations in the data were learned and shown via the model parameters, which helped us to gain insights into the topology and the dynamics of the air traffic network.},
  archive      = {J_FRAI},
  author       = {Zhu, Xinting and Lin, Yu and He, Yuxin and Tsui, Kwok-Leung and Chan, Pak Wai and Li, Lishuai},
  doi          = {10.3389/frai.2022.884485},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {884485},
  shortjournal = {Front. Artif. Intell.},
  title        = {Short-term nationwide airport throughput prediction with graph attention recurrent neural network},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building one-shot semi-supervised (BOSS) learning up to
fully supervised performance. <em>FRAI</em>, <em>5</em>, 880729. (<a
href="https://doi.org/10.3389/frai.2022.880729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reaching the performance of fully supervised learning with unlabeled data and only labeling one sample per class might be ideal for deep learning applications. We demonstrate for the first time the potential for building one-shot semi-supervised (BOSS) learning on CIFAR-10 and SVHN up to attain test accuracies that are comparable to fully supervised learning. Our method combines class prototype refining, class balancing, and self-training. A good prototype choice is essential and we propose a technique for obtaining iconic examples. In addition, we demonstrate that class balancing methods substantially improve accuracy results in semi-supervised learning to levels that allow self-training to reach the level of fully supervised learning performance. Our experiments demonstrate the value with computing and analyzing test accuracies for every class, rather than only a total test accuracy. We show that our BOSS methodology can obtain total test accuracies with CIFAR-10 images and only one labeled sample per class up to 95% (compared to 94.5% for fully supervised). Similarly, the SVHN images obtains test accuracies of 97.8%, compared to 98.27% for fully supervised. Rigorous empirical evaluations provide evidence that labeling large datasets is not necessary for training deep neural networks. Our code is available at https://github.com/lnsmith54/BOSS to facilitate replication.},
  archive      = {J_FRAI},
  author       = {Smith, Leslie N. and Conovaloff, Adam},
  doi          = {10.3389/frai.2022.880729},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {880729},
  shortjournal = {Front. Artif. Intell.},
  title        = {Building one-shot semi-supervised (BOSS) learning up to fully supervised performance},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An overview of alphafold’s breakthrough. <em>FRAI</em>,
<em>5</em>, 875587. (<a
href="https://doi.org/10.3389/frai.2022.875587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a short summary of the protein folding problem, what it is and why it is significant. Introduces the CASP competition and how accuracy is measured. Looks at different approaches for solving the problem followed by a review of the current breakthroughs in the field introduced by AlphaFold 1 and AlphaFold 2.},
  archive      = {J_FRAI},
  author       = {Marcu, Ştefan-Bogdan and Tăbîrcă, Sabin and Tangney, Mark},
  doi          = {10.3389/frai.2022.875587},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {875587},
  shortjournal = {Front. Artif. Intell.},
  title        = {An overview of alphafold&#39;s breakthrough},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing banks’ distress using news and regular financial
data. <em>FRAI</em>, <em>5</em>, 871863. (<a
href="https://doi.org/10.3389/frai.2022.871863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus our attention on leveraging the information contained in financial news to enhance the performance of a bank distress classifier. The news information should be analyzed and inserted into the predictive model in the most efficient way and this task deals with the issues related to Natural Language interpretation and to the analysis of news media. Among the different models proposed for such purpose, we investigate a deep learning approach. The methodology is based on a distributed representation of textual data obtained from a model (Doc2Vec) that maps the documents and the words contained within a text onto a reduced latent semantic space. Afterwards, a second supervised feed forward fully connected neural network is trained combining news data distributed representations with standard financial figures in input. The goal of the model is to classify the corresponding banks in distressed or tranquil state. The final aim is to comprehend both the improvement of the predictive performance of the classifier and to assess the importance of news data in the classification process. This to understand if news data really bring useful information not contained in standard financial variables.},
  archive      = {J_FRAI},
  author       = {Cerchiello, Paola and Nicola, Giancarlo and Rönnqvist, Samuel and Sarlin, Peter},
  doi          = {10.3389/frai.2022.871863},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {871863},
  shortjournal = {Front. Artif. Intell.},
  title        = {Assessing banks&#39; distress using news and regular financial data},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How are patented AI, software and robot technologies related
to wage changes in the united states? <em>FRAI</em>, <em>5</em>, 869282.
(<a href="https://doi.org/10.3389/frai.2022.869282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the relationships of three different types of patented technologies, namely artificial intelligence, software and industrial robots, with individual-level wage changes in the United States from 2011 to 2021. The aim of the study is to investigate if the availability of AI technologies is associated with increases or decreases in individual workers&#39; wages and how this association compares to previous innovations related to software and industrial robots. Our analysis is based on available indicators extracted from the text of patents to measure the exposure of occupations to these three types of technologies. We combine data on individual wages for the United States with the new technology measures and regress individual annual wage changes on these measures controlling for a variety of other factors. Our results indicate that innovations in software and industrial robots are associated with wage decreases, possibly indicating a large displacement effect of these technologies on human labor. On the contrary, for innovations in AI, we find wage increases, which may indicate that productivity effects and effects coming from the creation of new human tasks are larger than displacement effects of AI. AI exposure is associated with positive wage changes in services, whereas exposure to robots is associated with negative wage changes in manufacturing. The relationship of the AI exposure measure with wage increases has become stronger in 2016–2021 in comparison to the 5 years before.JEL Classification: J24, J31, O33.},
  archive      = {J_FRAI},
  author       = {Fossen, Frank M. and Samaan, Daniel and Sorgner, Alina},
  doi          = {10.3389/frai.2022.869282},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {869282},
  shortjournal = {Front. Artif. Intell.},
  title        = {How are patented AI, software and robot technologies related to wage changes in the united states?},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “The rodney dangerfield of stylistic devices”: End-to-end
detection and extraction of vossian antonomasia using neural networks.
<em>FRAI</em>, <em>5</em>, 868249. (<a
href="https://doi.org/10.3389/frai.2022.868249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vossian Antonomasia (VA) is a well-known stylistic device based on attributing a certain property to a person by relating them to another person who is famous for this property. Although the morphological and semantic characteristics of this phenomenon have long been the subject of linguistic research, little is known about its distribution. In this paper, we describe end-to-end approaches for detecting and extracting VA expressions from large news corpora in order to study VA more broadly. We present two types of approaches: binary sentence classifiers that detect whether or not a sentence contains a VA expression, and sequence tagging of all parts of a VA on the word level, enabling their extraction. All models are based on neural networks and outperform previous approaches, best results are obtained with a fine-tuned BERT model. Furthermore, we study the impact of training data size and class imbalance by adding negative (and possibly noisy) instances to the training data. We also evaluate the models&#39; performance on out-of-corpus and real-world data and analyze the ability of the sequence tagging model to generalize in terms of new entity types and syntactic patterns.},
  archive      = {J_FRAI},
  author       = {Schwab, Michel and Jäschke, Robert and Fischer, Frank},
  doi          = {10.3389/frai.2022.868249},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {868249},
  shortjournal = {Front. Artif. Intell.},
  title        = {“The rodney dangerfield of stylistic devices”: End-to-end detection and extraction of vossian antonomasia using neural networks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated learning for privacy-aware human mobility
modeling. <em>FRAI</em>, <em>5</em>, 867046. (<a
href="https://doi.org/10.3389/frai.2022.867046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human mobility modeling is a complex yet essential subject of study related to modeling important spatiotemporal events, including traffic, disease spreading, and customized directions and recommendations. While spatiotemporal data can be collected easily via smartphones, current state-of-the-art deep learning methods require vast amounts of such privacy-sensitive data to generate useful models. This work investigates the creation of spatiotemporal models using a Federated Learning (FL) approach—a machine learning technique that avoids sharing personal data with centralized servers. More specifically, we examine three centralized models for next-place prediction: a simple Gated Recurrent Unit (GRU) model, as well as two state-of-the-art centralized approaches, Flashback and DeepMove. Flashback is a Recurrent Neural Network (RNN) that utilizes historical hidden states with similar context as the current spatiotemporal context to improve performance. DeepMove is an attentional RNN that aims to capture human mobility&#39;s regularity while coping with data sparsity. We then implemented models based on FL for the two best-performing centralized models. We compared the performance of all models using two large public datasets: Foursquare (9,450 million check-ins, February 2009 to October 2010) and Gowalla (3,300 million check-ins, April 2012 to January 2014). We first replicated the performance of both Flashback and DeepMove, as reported in the original studies, and compared them to the simple GRU model. Flashback and GRU proved to be the best performing centralized models, so we further explored both in FL scenarios, including several parameters such as the number of clients, rounds, and epochs. Our results indicated that the training process of the federated models was less stable, i.e., the FL versions of both Flashback and GRU tended to have higher variability in the loss curves. The higher variability led to a slower convergence and thus a poorer performance when compared to the corresponding centralized models. Model performance was also highly influenced by the number of federated clients and the sparsity of the evaluation dataset. We additionally provide insights into the technical challenges of applying FL to state-of-the-art deep learning methods for human mobility.},
  archive      = {J_FRAI},
  author       = {Ezequiel, Castro Elizondo Jose and Gjoreski, Martin and Langheinrich, Marc},
  doi          = {10.3389/frai.2022.867046},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {867046},
  shortjournal = {Front. Artif. Intell.},
  title        = {Federated learning for privacy-aware human mobility modeling},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting stock price trends by analyzing economic reports
with analyst profiles. <em>FRAI</em>, <em>5</em>, 866723. (<a
href="https://doi.org/10.3389/frai.2022.866723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a methodology to forecast the movements of analysts&#39; estimated net income and stock prices using analyst profiles. Our methodology is based on applying natural language processing and neural networks in the context of analyst reports. First, we apply the proposed method to extract opinion sentences from the analyst report while classifying the remaining parts as non-opinion sentences. Then, we employ the proposed method to forecast the movements of analysts&#39; estimated net income and stock price by inputting the opinion and non-opinion sentences into separate neural networks. In addition to analyst reports, we input analyst profiles to the networks. As analyst profiles, we used the name of an analyst, the securities company to which the analyst belongs, the sector which the analyst covers, and the analyst ranking. Consequently, we obtain an indication that the analyst profile effectively improves the model forecasts. However, classifying analyst reports into opinion and non-opinion sentences is insignificant for the forecasts.},
  archive      = {J_FRAI},
  author       = {Suzuki, Masahiro and Sakaji, Hiroki and Izumi, Kiyoshi and Ishikawa, Yasushi},
  doi          = {10.3389/frai.2022.866723},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {866723},
  shortjournal = {Front. Artif. Intell.},
  title        = {Forecasting stock price trends by analyzing economic reports with analyst profiles},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spectroscopy approaches for food safety applications:
Improving data efficiency using active learning and semi-supervised
learning. <em>FRAI</em>, <em>5</em>, 863261. (<a
href="https://doi.org/10.3389/frai.2022.863261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decade witnessed rapid development in the measurement and monitoring technologies for food science. Among these technologies, spectroscopy has been widely used for the analysis of food quality, safety, and nutritional properties. Due to the complexity of food systems and the lack of comprehensive predictive models, rapid and simple measurements to predict complex properties in food systems are largely missing. Machine Learning (ML) has shown great potential to improve the classification and prediction of these properties. However, the barriers to collecting large datasets for ML applications still persists. In this paper, we explore different approaches of data annotation and model training to improve data efficiency for ML applications. Specifically, we leverage Active Learning (AL) and Semi-Supervised Learning (SSL) and investigate four approaches: baseline passive learning, AL, SSL, and a hybrid of AL and SSL. To evaluate these approaches, we collect two spectroscopy datasets: predicting plasma dosage and detecting foodborne pathogen. Our experimental results show that, compared to the de facto passive learning approach, advanced approaches (AL, SSL, and the hybrid) can greatly reduce the number of labeled samples, with some cases decreasing the number of labeled samples by more than half.},
  archive      = {J_FRAI},
  author       = {Zhang, Huanle and Wisuthiphaet, Nicharee and Cui, Hemiao and Nitin, Nitin and Liu, Xin and Zhao, Qing},
  doi          = {10.3389/frai.2022.863261},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {863261},
  shortjournal = {Front. Artif. Intell.},
  title        = {Spectroscopy approaches for food safety applications: Improving data efficiency using active learning and semi-supervised learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact of pedagogical agents’ gender on academic
learning: A systematic review. <em>FRAI</em>, <em>5</em>, 862997. (<a
href="https://doi.org/10.3389/frai.2022.862997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual learning environments often use virtual characters to facilitate and improve the learning process. These characters, known as pedagogical agents, can take on different roles, such as tutors or companions. Research has highlighted the importance of various characteristics of virtual agents, including their voice or non-verbal behaviors. Little attention has been paid to the gender-specific design of pedagogical agents, although gender has an important influence on the educational process. In this article, we perform an extensive review of the literature regarding the impact of the gender of pedagogical agents on academic outcomes. Based on a detailed review of 59 articles, we analyze the influence of pedagogical agents&#39; gender on students&#39; academic self-evaluations and achievements to answer the following questions: (1) Do students perceive virtual agents differently depending on their own gender and the gender of the agent? (2) Does the gender of pedagogical agents influence students&#39; academic performance and self-evaluations? (3) Are there tasks or academic situations to which a male virtual agent is better suited than a female virtual agent, and vice versa, according to empirical evidence? (4) How do a virtual agent&#39;s pedagogical roles impact these results? (5) How do a virtual agent&#39;s appearance and interactive capacities impact these results? (6) Are androgynous virtual agents a potential solution to combatting gender stereotypes? This review provides important insight to researchers on how to approach gender when designing pedagogical agents in virtual learning environments.},
  archive      = {J_FRAI},
  author       = {Armando, Marjorie and Ochs, Magalie and Régner, Isabelle},
  doi          = {10.3389/frai.2022.862997},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {862997},
  shortjournal = {Front. Artif. Intell.},
  title        = {The impact of pedagogical agents&#39; gender on academic learning: A systematic review},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic artifact detection algorithm in fetal MRI.
<em>FRAI</em>, <em>5</em>, 861791. (<a
href="https://doi.org/10.3389/frai.2022.861791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fetal MR imaging is subject to artifacts including motion, chemical shift, and radiofrequency artifacts. Currently, such artifacts are detected by the MRI operator, a process which is subjective, time consuming, and prone to errors. We propose a novel algorithm, RISE-Net, that can consistently, automatically, and objectively detect artifacts in 3D fetal MRI. It makes use of a CNN ensemble approach where the first CNN aims to identify and classify any artifacts in the image, and the second CNN uses regression to determine the severity of the detected artifacts. The main mechanism in RISE-Net is the stacked Residual, Inception, Squeeze and Excitation (RISE) blocks. This classification network achieved an accuracy of 90.34% and a F1 score of 90.39% and outperformed other state-of-the-art architectures, such as VGG-16, Inception, ResNet-50, ReNet-Inception, SE-ResNet, and SE-Inception. The severity regression network had an MSE of 0.083 across all classes. The presented algorithm facilitates rapid and accurate fetal MRI quality assurance that can be implemented into clinical use.},
  archive      = {J_FRAI},
  author       = {Lim, Adam and Lo, Justin and Wagner, Matthias W. and Ertl-Wagner, Birgit and Sussman, Dafna},
  doi          = {10.3389/frai.2022.861791},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {861791},
  shortjournal = {Front. Artif. Intell.},
  title        = {Automatic artifact detection algorithm in fetal MRI},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A straightforward HPV16 lineage classification based on
machine learning. <em>FRAI</em>, <em>5</em>, 851841. (<a
href="https://doi.org/10.3389/frai.2022.851841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Papillomavirus (HPV) is the causal agent of 5% of cancers worldwide and the main cause of cervical cancer and it is also associated with a significant percentage of oropharyngeal and anogenital cancers. More than 60% of cervical cancers are caused by HPV16 genotype, which has been classified into lineages (A, B, C, and D). Lineages are related to the progression of cervical cancer and the current method to assess lineages is by building a Maximum Likelihood Tree (MLT); which is slow, it cannot assess poor sequenced samples, and annotation is done manually. In this study, we have developed a new model to assess HPV16 lineage using machine learning tools. A total of 645 HPV16 genomes were analyzed using Genome-Wide Association Study (GWAS), which identified 56 lineage-specific Single Nucleotide Polymorphisms (SNPs). From the SNPs found, training-test models were constructed using different algorithms such as Random Forest (RF), Support Vector Machine (SVM), and K-nearest neighbor (KNN). A distinct set of HPV16 sequences (n = 1,028), whose lineage was previously determined by MLT, was used for validation. The RF-based model allowed a precise assignment of HPV16 lineage, showing an accuracy of 99.5% in the known lineage samples. Moreover, the RF model could assess lineage to 273 samples that MLT could not determine. In terms of computer consuming time, the RF-based model was almost 40 times faster than MLT. Having a fast and efficient method for assigning HPV16 lineages, could facilitate the implementation of lineage classification as a triage or prognostic marker in the clinical setting.},
  archive      = {J_FRAI},
  author       = {Asensio-Puig, Laura and Alemany, Laia and Pavón, Miquel Angel},
  doi          = {10.3389/frai.2022.851841},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {851841},
  shortjournal = {Front. Artif. Intell.},
  title        = {A straightforward HPV16 lineage classification based on machine learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving crowdsourcing-based image classification through
expanded input elicitation and machine learning. <em>FRAI</em>,
<em>5</em>, 848056. (<a
href="https://doi.org/10.3389/frai.2022.848056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates how different forms of input elicitation obtained from crowdsourcing can be utilized to improve the quality of inferred labels for image classification tasks, where an image must be labeled as either positive or negative depending on the presence/absence of a specified object. Five types of input elicitation methods are tested: binary classification (positive or negative); the (x, y)-coordinate of the position participants believe a target object is located; level of confidence in binary response (on a scale from 0 to 100%); what participants believe the majority of the other participants&#39; binary classification is; and participant&#39;s perceived difficulty level of the task (on a discrete scale). We design two crowdsourcing studies to test the performance of a variety of input elicitation methods and utilize data from over 300 participants. Various existing voting and machine learning (ML) methods are applied to make the best use of these inputs. In an effort to assess their performance on classification tasks of varying difficulty, a systematic synthetic image generation process is developed. Each generated image combines items from the MPEG-7 Core Experiment CE-Shape-1 Test Set into a single image using multiple parameters (e.g., density, transparency, etc.) and may or may not contain a target object. The difficulty of these images is validated by the performance of an automated image classification method. Experiment results suggest that more accurate results can be achieved with smaller training datasets when both the crowdsourced binary classification labels and the average of the self-reported confidence values in these labels are used as features for the ML classifiers. Moreover, when a relatively larger properly annotated dataset is available, in some cases augmenting these ML algorithms with the results (i.e., probability of outcome) from an automated classifier can achieve even higher performance than what can be obtained by using any one of the individual classifiers. Lastly, supplementary analysis of the collected data demonstrates that other performance metrics of interest, namely reduced false-negative rates, can be prioritized through special modifications of the proposed aggregation methods.},
  archive      = {J_FRAI},
  author       = {Yasmin, Romena and Hassan, Md Mahmudulla and Grassel, Joshua T. and Bhogaraju, Harika and Escobedo, Adolfo R. and Fuentes, Olac},
  doi          = {10.3389/frai.2022.848056},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {848056},
  shortjournal = {Front. Artif. Intell.},
  title        = {Improving crowdsourcing-based image classification through expanded input elicitation and machine learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain-informed neural networks for interaction localization
within astroparticle experiments. <em>FRAI</em>, <em>5</em>, 832909. (<a
href="https://doi.org/10.3389/frai.2022.832909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a domain-informed neural network architecture for experimental particle physics, using particle interaction localization with the time-projection chamber (TPC) technology for dark matter research as an example application. A key feature of the signals generated within the TPC is that they allow localization of particle interactions through a process called reconstruction (i.e., inverse-problem regression). While multilayer perceptrons (MLPs) have emerged as a leading contender for reconstruction in TPCs, such a black-box approach does not reflect prior knowledge of the underlying scientific processes. This paper looks anew at neural network-based interaction localization and encodes prior detector knowledge, in terms of both signal characteristics and detector geometry, into the feature encoding and the output layers of a multilayer (deep) neural network. The resulting neural network, termed Domain-informed Neural Network (DiNN), limits the receptive fields of the neurons in the initial feature encoding layers in order to account for the spatially localized nature of the signals produced within the TPC. This aspect of the DiNN, which has similarities with the emerging area of graph neural networks in that the neurons in the initial layers only connect to a handful of neurons in their succeeding layer, significantly reduces the number of parameters in the network in comparison to an MLP. In addition, in order to account for the detector geometry, the output layers of the network are modified using two geometric transformations to ensure the DiNN produces localizations within the interior of the detector. The end result is a neural network architecture that has 60% fewer parameters than an MLP, but that still achieves similar localization performance and provides a path to future architectural developments with improved performance because of their ability to encode additional domain knowledge into the architecture.},
  archive      = {J_FRAI},
  author       = {Liang, Shixiao and Higuera, Aaron and Peters, Christina and Roy, Venkat and Bajwa, Waheed U. and Shatkay, Hagit and Tunnell, Christopher D.},
  doi          = {10.3389/frai.2022.832909},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {832909},
  shortjournal = {Front. Artif. Intell.},
  title        = {Domain-informed neural networks for interaction localization within astroparticle experiments},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An analysis of music perception skills on crowdsourcing
platforms. <em>FRAI</em>, <em>5</em>, 828733. (<a
href="https://doi.org/10.3389/frai.2022.828733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music content annotation campaigns are common on paid crowdsourcing platforms. Crowd workers are expected to annotate complex music artifacts, a task often demanding specialized skills and expertise, thus selecting the right participants is crucial for campaign success. However, there is a general lack of deeper understanding of the distribution of musical skills, and especially auditory perception skills, in the worker population. To address this knowledge gap, we conducted a user study (N = 200) on Prolific and Amazon Mechanical Turk. We asked crowd workers to indicate their musical sophistication through a questionnaire and assessed their music perception skills through an audio-based skill test. The goal of this work is to better understand the extent to which crowd workers possess higher perceptions skills, beyond their own musical education level and self reported abilities. Our study shows that untrained crowd workers can possess high perception skills on the music elements of melody, tuning, accent, and tempo; skills that can be useful in a plethora of annotation tasks in the music domain.},
  archive      = {J_FRAI},
  author       = {Samiotis, Ioannis Petros and Qiu, Sihang and Lofi, Christoph and Yang, Jie and Gadiraju, Ujwal and Bozzon, Alessandro},
  doi          = {10.3389/frai.2022.828733},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {828733},
  shortjournal = {Front. Artif. Intell.},
  title        = {An analysis of music perception skills on crowdsourcing platforms},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A genetic folding strategy based support vector machine to
optimize lung cancer classification. <em>FRAI</em>, <em>5</em>, 826374.
(<a href="https://doi.org/10.3389/frai.2022.826374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is defined as an abnormal growth of human cells classified into benign and malignant. The site makes further classification of cancers of initiation and genomic underpinnings. Lung cancer displays extreme heterogeneity, making genomic classification vital for future targeted therapies. Especially considering lung cancers account for 1.76 million deaths worldwide annually. However, tumors do not always correlate to cancer as they can be benign, severely dysplastic (pre-cancerous), or malignant (cancerous). Lung cancer presents with ambiguous symptoms, thus is difficult to diagnose and is detected later compared to other cancers. Diagnosis relies heavily on radiology and invasive procedures. Different models developed employing Artificial Intelligence (AI), and Machine Learning (ML) have been used to classify various cancers. In this study, the authors propose a Genetic Folding Strategy (GFS) based model to predict lung cancer from a lung cancer dataset. We developed and implemented GF to improve Support Vector Machines (SVM) classification kernel functions and used it to classify lung cancer. We developed and implemented GF to improve SVM classification kernel functions and used it to classify lung cancer. Classification performance evaluations and comparisons between the authors&#39; GFS model and three SVM kernels, linear, polynomial and radial basis function, were conducted thoroughly on real lung cancer datasets. While using GFS in classifying lung cancer, the authors obtained an accuracy of 96.2%. This is the highest current accuracy compared to other kernels.},
  archive      = {J_FRAI},
  author       = {Mezher, Mohammad A. and Altamimi, Almothana and Altamimi, Ruhaifa},
  doi          = {10.3389/frai.2022.826374},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {826374},
  shortjournal = {Front. Artif. Intell.},
  title        = {A genetic folding strategy based support vector machine to optimize lung cancer classification},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Signal perceptron: On the identifiability of boolean
function spaces and beyond. <em>FRAI</em>, <em>5</em>, 770254. (<a
href="https://doi.org/10.3389/frai.2022.770254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a seminal book, Minsky and Papert define the perceptron as a limited implementation of what they called “parallel machines.” They showed that some binary Boolean functions including XOR are not definable in a single layer perceptron due to its limited capacity to learn only linearly separable functions. In this work, we propose a new more powerful implementation of such parallel machines. This new mathematical tool is defined using analytic sinusoids—instead of linear combinations—to form an analytic signal representation of the function that we want to learn. We show that this re-formulated parallel mechanism can learn, with a single layer, any non-linear k-ary Boolean function. Finally, to provide an example of its practical applications, we show that it outperforms the single hidden layer multilayer perceptron in both Boolean function learning and image classification tasks, while also being faster and requiring fewer parameters.},
  archive      = {J_FRAI},
  author       = {Mendez Lucero, Miguel-Angel and Karampatsis, Rafael-Michael and Bojorquez Gallardo, Enrique and Belle, Vaishak},
  doi          = {10.3389/frai.2022.770254},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {770254},
  shortjournal = {Front. Artif. Intell.},
  title        = {Signal perceptron: On the identifiability of boolean function spaces and beyond},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-linearity of metabolic pathways critically influences
the choice of machine learning model. <em>FRAI</em>, <em>5</em>, 744755.
(<a href="https://doi.org/10.3389/frai.2022.744755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of machine learning (ML) in life sciences has gained wide interest over the past years, as it speeds up the development of high performing models. Important modeling tools in biology have proven their worth for pathway design, such as mechanistic models and metabolic networks, as they allow better understanding of mechanisms involved in the functioning of organisms. However, little has been done on the use of ML to model metabolic pathways, and the degree of non-linearity associated with them is not clear. Here, we report the construction of different metabolic pathways with several linear and non-linear ML models. Different types of data are used; they lead to the prediction of important biological data, such as pathway flux and final product concentration. A comparison reveals that the data features impact model performance and highlight the effectiveness of non-linear models (e.g., QRF: RMSE = 0.021 nmol·min−1 and R2 = 1 vs. Bayesian GLM: RMSE = 1.379 nmol·min−1 R2 = 0.823). It turns out that the greater the degree of non-linearity of the pathway, the better suited a non-linear model will be. Therefore, a decision-making support for pathway modeling is established. These findings generally support the hypothesis that non-linear aspects predominate within the metabolic pathways. This must be taken into account when devising possible applications of these pathways for the identification of biomarkers of diseases (e.g., infections, cancer, neurodegenerative diseases) or the optimization of industrial production processes.},
  archive      = {J_FRAI},
  author       = {Lo-Thong-Viramoutou, Ophélie and Charton, Philippe and Cadet, Xavier F. and Grondin-Perez, Brigitte and Saavedra, Emma and Damour, Cédric and Cadet, Frédéric},
  doi          = {10.3389/frai.2022.744755},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {6},
  pages        = {744755},
  shortjournal = {Front. Artif. Intell.},
  title        = {Non-linearity of metabolic pathways critically influences the choice of machine learning model},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Bias, subjectivity and perspectives in natural
language processing. <em>FRAI</em>, <em>5</em>, 926435. (<a
href="https://doi.org/10.3389/frai.2022.926435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Basile, Valerio and Caselli, Tommaso and Balahur, Alexandra and Ku, Lun-Wei},
  doi          = {10.3389/frai.2022.926435},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {926435},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Bias, subjectivity and perspectives in natural language processing},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Theory of mind in humans and in machines.
<em>FRAI</em>, <em>5</em>, 917565. (<a
href="https://doi.org/10.3389/frai.2022.917565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Langley, Christelle and Cîrstea, Bogdan-Ionuţ and Cuzzolin, Fabio and Sahakian, Barbara Jacquelyn},
  doi          = {10.3389/frai.2022.917565},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {917565},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Theory of mind in humans and in machines},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detection of COVID-19 using deep learning techniques and
cost effectiveness evaluation: A survey. <em>FRAI</em>, <em>5</em>,
912022. (<a href="https://doi.org/10.3389/frai.2022.912022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphical-design-based symptomatic techniques in pandemics perform a quintessential purpose in screening hit causes that comparatively render better outcomes amongst the principal radioscopy mechanisms in recognizing and diagnosing COVID-19 cases. The deep learning paradigm has been applied vastly to investigate radiographic images such as Chest X-Rays (CXR) and CT scan images. These radiographic images are rich in information such as patterns and clusters like structures, which are evident in conformance and detection of COVID-19 like pandemics. This paper aims to comprehensively study and analyze detection methodology based on Deep learning techniques for COVID-19 diagnosis. Deep learning technology is a good, practical, and affordable modality that can be deemed a reliable technique for adequately diagnosing the COVID-19 virus. Furthermore, the research determines the potential to enhance image character through artificial intelligence and distinguishes the most inexpensive and most trustworthy imaging method to anticipate dreadful viruses. This paper further discusses the cost-effectiveness of the surveyed methods for detecting COVID-19, in contrast with the other methods. Several finance-related aspects of COVID-19 detection effectiveness of different methods used for COVID-19 detection have been discussed. Overall, this study presents an overview of COVID-19 detection using deep learning methods and their cost-effectiveness and financial implications from the perspective of insurance claim settlement.},
  archive      = {J_FRAI},
  author       = {M. V., Manoj Kumar and Atalla, Shadi and Almuraqab, Nasser and Moonesar, Immanuel Azaad},
  doi          = {10.3389/frai.2022.912022},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {912022},
  shortjournal = {Front. Artif. Intell.},
  title        = {Detection of COVID-19 using deep learning techniques and cost effectiveness evaluation: A survey},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: AI in healthcare: From data to intelligence.
<em>FRAI</em>, <em>5</em>, 909391. (<a
href="https://doi.org/10.3389/frai.2022.909391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hulsen, Tim and Petkovic, Milan and Varga, Orsolya Edit and Jamuar, Saumya Shekhar},
  doi          = {10.3389/frai.2022.909391},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {909391},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: AI in healthcare: from data to intelligence},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Explainable, trustworthy, and responsible AI for
the financial service industry. <em>FRAI</em>, <em>5</em>, 902519. (<a
href="https://doi.org/10.3389/frai.2022.902519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Hadji Misheva, Branka and Papenbrock, Jochen},
  doi          = {10.3389/frai.2022.902519},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {902519},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Explainable, trustworthy, and responsible AI for the financial service industry},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network training with asymmetric crosspoint elements.
<em>FRAI</em>, <em>5</em>, 891624. (<a
href="https://doi.org/10.3389/frai.2022.891624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analog crossbar arrays comprising programmable non-volatile resistors are under intense investigation for acceleration of deep neural network training. However, the ubiquitous asymmetric conductance modulation of practical resistive devices critically degrades the classification performance of networks trained with conventional algorithms. Here we first describe the fundamental reasons behind this incompatibility. Then, we explain the theoretical underpinnings of a novel fully-parallel training algorithm that is compatible with asymmetric crosspoint elements. By establishing a powerful analogy with classical mechanics, we explain how device asymmetry can be exploited as a useful feature for analog deep learning processors. Instead of conventionally tuning weights in the direction of the error function gradient, network parameters can be programmed to successfully minimize the total energy (Hamiltonian) of the system that incorporates the effects of device asymmetry. Our technique enables immediate realization of analog deep learning accelerators based on readily available device technologies.},
  archive      = {J_FRAI},
  author       = {Onen, Murat and Gokmen, Tayfun and Todorov, Teodor K. and Nowicki, Tomasz and del Alamo, Jesús A. and Rozen, John and Haensch, Wilfried and Kim, Seyoung},
  doi          = {10.3389/frai.2022.891624},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {891624},
  shortjournal = {Front. Artif. Intell.},
  title        = {Neural network training with asymmetric crosspoint elements},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shallow univariate ReLU networks as splines: Initialization,
loss surface, hessian, and gradient flow dynamics. <em>FRAI</em>,
<em>5</em>, 889981. (<a
href="https://doi.org/10.3389/frai.2022.889981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the learning dynamics and inductive bias of neural networks (NNs) is hindered by the opacity of the relationship between NN parameters and the function represented. Partially, this is due to symmetries inherent within the NN parameterization, allowing multiple different parameter settings to result in an identical output function, resulting in both an unclear relationship and redundant degrees of freedom. The NN parameterization is invariant under two symmetries: permutation of the neurons and a continuous family of transformations of the scale of weight and bias parameters. We propose taking a quotient with respect to the second symmetry group and reparametrizing ReLU NNs as continuous piecewise linear splines. Using this spline lens, we study learning dynamics in shallow univariate ReLU NNs, finding unexpected insights and explanations for several perplexing phenomena. We develop a surprisingly simple and transparent view of the structure of the loss surface, including its critical and fixed points, Hessian, and Hessian spectrum. We also show that standard weight initializations yield very flat initial functions, and that this flatness, together with overparametrization and the initial weight scale, is responsible for the strength and type of implicit regularization, consistent with previous work. Our implicit regularization results are complementary to recent work, showing that initialization scale critically controls implicit regularization via a kernel-based argument. Overall, removing the weight scale symmetry enables us to prove these results more simply and enables us to prove new results and gain new insights while offering a far more transparent and intuitive picture. Looking forward, our quotiented spline-based approach will extend naturally to the multivariate and deep settings, and alongside the kernel-based view, we believe it will play a foundational role in efforts to understand neural networks. Videos of learning dynamics using a spline-based visualization are available at http://shorturl.at/tFWZ2.},
  archive      = {J_FRAI},
  author       = {Sahs, Justin and Pyle, Ryan and Damaraju, Aneel and Caro, Josue Ortega and Tavaslioglu, Onur and Lu, Andy and Anselmi, Fabio and Patel, Ankit B.},
  doi          = {10.3389/frai.2022.889981},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {889981},
  shortjournal = {Front. Artif. Intell.},
  title        = {Shallow univariate ReLU networks as splines: Initialization, loss surface, hessian, and gradient flow dynamics},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transparency of AI in healthcare as a multilayered system of
accountabilities: Between legal requirements and technical limitations.
<em>FRAI</em>, <em>5</em>, 879603. (<a
href="https://doi.org/10.3389/frai.2022.879603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of transparency is one of the artificial intelligence (AI)&#39;s fundamental challenges, but the concept of transparency might be even more opaque than AI itself. Researchers in different fields who attempt to provide the solutions to improve AI&#39;s transparency articulate different but neighboring concepts that include, besides transparency, explainability and interpretability. Yet, there is no common taxonomy neither within one field (such as data science) nor between different fields (law and data science). In certain areas like healthcare, the requirements of transparency are crucial since the decisions directly affect people&#39;s lives. In this paper, we suggest an interdisciplinary vision on how to tackle the issue of AI&#39;s transparency in healthcare, and we propose a single point of reference for both legal scholars and data scientists on transparency and related concepts. Based on the analysis of the European Union (EU) legislation and literature in computer science, we submit that transparency shall be considered the “way of thinking” and umbrella concept characterizing the process of AI&#39;s development and use. Transparency shall be achieved through a set of measures such as interpretability and explainability, communication, auditability, traceability, information provision, record-keeping, data governance and management, and documentation. This approach to deal with transparency is of general nature, but transparency measures shall be always contextualized. By analyzing transparency in the healthcare context, we submit that it shall be viewed as a system of accountabilities of involved subjects (AI developers, healthcare professionals, and patients) distributed at different layers (insider, internal, and external layers, respectively). The transparency-related accountabilities shall be built-in into the existing accountability picture which justifies the need to investigate the relevant legal frameworks. These frameworks correspond to different layers of the transparency system. The requirement of informed medical consent correlates to the external layer of transparency and the Medical Devices Framework is relevant to the insider and internal layers. We investigate the said frameworks to inform AI developers on what is already expected from them with regards to transparency. We also discover the gaps in the existing legislative frameworks concerning AI&#39;s transparency in healthcare and suggest the solutions to fill them in.},
  archive      = {J_FRAI},
  author       = {Kiseleva, Anastasiya and Kotzinos, Dimitris and De Hert, Paul},
  doi          = {10.3389/frai.2022.879603},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {879603},
  shortjournal = {Front. Artif. Intell.},
  title        = {Transparency of AI in healthcare as a multilayered system of accountabilities: Between legal requirements and technical limitations},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Machine learning applied to the search for nonlinear
features in breeding populations. <em>FRAI</em>, <em>5</em>, 876578. (<a
href="https://doi.org/10.3389/frai.2022.876578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large plant breeding populations are traditionally a source of novel allelic diversity and are at the core of selection efforts for elite material. Finding rare diversity requires a deep understanding of biological interactions between the genetic makeup of one genotype and its environmental conditions. Most modern breeding programs still rely on linear regression models to solve this problem, generalizing the complex genotype by phenotype interactions through manually constructed linear features. However, the identification of positive alleles vs. background can be addressed using deep learning approaches that have the capacity to learn complex nonlinear functions for the inputs. Machine learning (ML) is an artificial intelligence (AI) approach involving a range of algorithms to learn from input data sets and predict outcomes in other related samples. This paper describes a variety of techniques that include supervised and unsupervised ML algorithms to improve our understanding of nonlinear interactions from plant breeding data sets. Feature selection (FS) methods are combined with linear and nonlinear predictors and compared to traditional prediction methods used in plant breeding. Recent advances in ML allowed the construction of complex models that have the capacity to better differentiate between positive alleles and the genetic background. Using real plant breeding program data, we show that ML methods have the ability to outperform current approaches, increase prediction accuracies, decrease the computing time drastically, and improve the detection of important alleles involved in qualitative or quantitative traits.},
  archive      = {J_FRAI},
  author       = {Gabur, Iulian and Simioniuc, Danut Petru and Snowdon, Rod J. and Cristea, Dan},
  doi          = {10.3389/frai.2022.876578},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {876578},
  shortjournal = {Front. Artif. Intell.},
  title        = {Machine learning applied to the search for nonlinear features in breeding populations},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mortality prediction in cardiac intensive care unit
patients: A systematic review of existing and artificial intelligence
augmented approaches. <em>FRAI</em>, <em>5</em>, 876007. (<a
href="https://doi.org/10.3389/frai.2022.876007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medical complexity and high acuity of patients in the cardiac intensive care unit make for a unique patient population with high morbidity and mortality. While there are many tools for predictions of mortality in other settings, there is a lack of robust mortality prediction tools for cardiac intensive care unit patients. The ongoing advances in artificial intelligence and machine learning also pose a potential asset to the advancement of mortality prediction. Artificial intelligence algorithms have been developed for application of electrocardiogram interpretation with promising accuracy and clinical application. Additionally, artificial intelligence algorithms applied to electrocardiogram interpretation have been developed to predict various variables such as structural heart disease, left ventricular systolic dysfunction, and atrial fibrillation. These variables can be used and applied to new mortality prediction models that are dynamic with the changes in the patient&#39;s clinical course and may lead to more accurate and reliable mortality prediction. The application of artificial intelligence to mortality prediction will fill the gaps left by current mortality prediction tools.},
  archive      = {J_FRAI},
  author       = {Rafie, Nikita and Jentzer, Jacob C. and Noseworthy, Peter A. and Kashou, Anthony H.},
  doi          = {10.3389/frai.2022.876007},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {876007},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mortality prediction in cardiac intensive care unit patients: A systematic review of existing and artificial intelligence augmented approaches},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic learning in kolkata paise restaurant problem:
Classical and quantum strategies. <em>FRAI</em>, <em>5</em>, 874061. (<a
href="https://doi.org/10.3389/frai.2022.874061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We review the results for stochastic learning strategies, both classical (one-shot and iterative) and quantum (one-shot only), for optimizing the available many-choice resources among a large number of competing agents, developed over the last decade in the context of the Kolkata Paise Restaurant (KPR) Problem. Apart from few rigorous and approximate analytical results, both for classical and quantum strategies, most of the interesting results on the phase transition behavior (obtained so far for the classical model) uses classical Monte Carlo simulations. All these including the applications to computer science [job or resource allotments in Internet-of-Things (IoT)], transport engineering (online vehicle hire problems), operation research (optimizing efforts for delegated search problem, efficient solution of Traveling Salesman problem) will be discussed.},
  archive      = {J_FRAI},
  author       = {Chakrabarti, Bikas K. and Rajak, Atanu and Sinha, Antika},
  doi          = {10.3389/frai.2022.874061},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {874061},
  shortjournal = {Front. Artif. Intell.},
  title        = {Stochastic learning in kolkata paise restaurant problem: Classical and quantum strategies},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Affective response categories—toward personalized reactions
in affect-adaptive tutoring systems. <em>FRAI</em>, <em>5</em>, 873056.
(<a href="https://doi.org/10.3389/frai.2022.873056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affect-adaptive tutoring systems detect the current emotional state of the learner and are capable of adequately responding by adapting the learning experience. Adaptations could be employed to manipulate the emotional state in a direction favorable to the learning process; for example, contextual help can be offered to mitigate frustration, or lesson plans can be accelerated to avoid boredom. Safety-critical situations, in which wrong decisions and behaviors can have fatal consequences, may particularly benefit from affect-adaptive tutoring systems, because accounting for affecting responses during training may help develop coping strategies and improve resilience. Effective adaptation, however, can only be accomplished when knowing which emotions benefit high learning performance in such systems. The results of preliminary studies indicate interindividual differences in the relationship between emotion and performance that require consideration by an affect-adaptive system. To that end, this article introduces the concept of Affective Response Categories (ARCs) that can be used to categorize learners based on their emotion-performance relationship. In an experimental study, N = 50 subjects (33% female, 19–57 years, M = 32.75, SD = 9.8) performed a simulated airspace surveillance task. Emotional valence was detected using facial expression analysis, and pupil diameters were used to indicate emotional arousal. A cluster analysis was performed to group subjects into ARCs based on their individual correlations of valence and performance as well as arousal and performance. Three different clusters were identified, one of which showed no correlations between emotion and performance. The performance of subjects in the other two clusters benefitted from negative arousal and differed only in the valence-performance correlation, which was positive or negative. Based on the identified clusters, the initial ARC model was revised. We then discuss the resulting model, outline future research, and derive implications for the larger context of the field of adaptive tutoring systems. Furthermore, potential benefits of the proposed concept are discussed and ethical issues are identified and addressed.},
  archive      = {J_FRAI},
  author       = {Schmitz-Hübsch, Alina and Stasch, Sophie-Marie and Becker, Ron and Fuchs, Sven and Wirzberger, Maria},
  doi          = {10.3389/frai.2022.873056},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {873056},
  shortjournal = {Front. Artif. Intell.},
  title        = {Affective response Categories—Toward personalized reactions in affect-adaptive tutoring systems},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging guided backpropagation to select convolutional
neural networks for plant classification. <em>FRAI</em>, <em>5</em>,
871162. (<a href="https://doi.org/10.3389/frai.2022.871162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of state-of-the-art convolutional neural networks (CNN) has allowed researchers to perform plant classification tasks previously thought impossible and rely on human judgment. Researchers often develop complex CNN models to achieve better performances, introducing over-parameterization and forcing the model to overfit on a training dataset. The most popular process for evaluating overfitting in a deep learning model is using accuracy and loss curves. Train and loss curves may help understand the performance of a model but do not provide guidance on how the model could be modified to attain better performance. In this article, we analyzed the relation between the features learned by a model and its capacity and showed that a model with higher representational capacity might learn many subtle features that may negatively affect its performance. Next, we showed that the shallow layers of a deep learning model learn more diverse features than the ones learned by the deeper layers. Finally, we propose SSIM cut curve, a new way to select the depth of a CNN model by using the pairwise similarity matrix between the visualization of the features learned at different depths by using Guided Backpropagation. We showed that our proposed method could potentially pave a new way to select a better CNN model.},
  archive      = {J_FRAI},
  author       = {Mostafa, Sakib and Mondal, Debajyoti and Beck, Michael A. and Bidinosti, Christopher P. and Henry, Christopher J. and Stavness, Ian},
  doi          = {10.3389/frai.2022.871162},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {871162},
  shortjournal = {Front. Artif. Intell.},
  title        = {Leveraging guided backpropagation to select convolutional neural networks for plant classification},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the impact of digitalization and artificial intelligence
on employers’ flexibility requirements in occupations—empirical evidence
for germany. <em>FRAI</em>, <em>5</em>, 868789. (<a
href="https://doi.org/10.3389/frai.2022.868789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has a high application potential in many areas of the economy, and its use is expected to accelerate strongly in the coming years. This is linked with changes in working conditions that may be substantial and entail serious health risks for employees. With our paper we are the first to conduct an empirical analysis of employers&#39; increasing flexibility requirements in the course of advancing digitalization, based on a representative business survey, the IAB Job Vacancy Survey. We combine establishment-level data from the survey and occupation-specific characteristics from other sources and apply non-linear random effects estimations. According to employers&#39; assessments, office and secretarial occupations are undergoing the largest changes in terms of flexibility requirements, followed by other occupations that are highly relevant in the context of AI: occupations in company organization and strategy, vehicle/aerospace/shipbuilding technicians and occupations in insurance and financial services. The increasing requirements we observe most frequently are those concerning demands on employees&#39; self-organization, although short-term working-time flexibility and workplace flexibility also play an important role. The estimation results show that the occupational characteristics, independently of the individual employer, play a major role for increasing flexibility requirements. For example, occupations with a larger share of routine cognitive activities (which in the literature are usually more closely associated with artificial intelligence than others) reveal a significantly higher probability of increasing flexibility demands, specifically with regard to the employees&#39; self-organization. This supports the argument that AI changes above all work content and work processes. For the average age of the workforce and the unemployment rate in an occupation we find significantly negative effects. At the establishment level the share of female employees plays a significant negative role. Our findings provide clear indications for targeted action in labor market and education policy in order to minimize the risks and to strengthen the chances of an increasing application of AI technologies.},
  archive      = {J_FRAI},
  author       = {Warning, Anja and Weber, Enzo and Püffel, Anouk},
  doi          = {10.3389/frai.2022.868789},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {868789},
  shortjournal = {Front. Artif. Intell.},
  title        = {On the impact of digitalization and artificial intelligence on employers&#39; flexibility requirements in Occupations—Empirical evidence for germany},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Credit risk modeling using transfer learning and domain
adaptation. <em>FRAI</em>, <em>5</em>, 868232. (<a
href="https://doi.org/10.3389/frai.2022.868232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of credit risk assessment lenders may have limited or no data on the historical lending outcomes of credit applicants. Typically this disproportionately affects Micro, Small, and Medium Enterprises (MSMEs), for which credit may be restricted or too costly, due to the difficulty of predicting the Probability of Default (PD). However, if data from other related credit risk domains is available Transfer Learning may be applied to successfully train models, e.g., from the credit card lending and debt consolidation (CD) domains to predict in the small business lending domain. In this article, we report successful results from an approach using transfer learning to predict the probability of default based on the novel concept of Progressive Shift Contribution (PSC) from source to target domain. Toward real-world application by lenders of this approach, we further address two key questions. The first is to explain transfer learning models, and the second is to adjust features when the source and target domains differ. To address the first question, we apply Shapley values to investigate how and why transfer learning improves model accuracy, and also propose and test a domain adaptation approach to address the second. These results show that adaptation improves model accuracy in addition to the improvement from transfer learning. We extend this by proposing and testing a combined strategy of feature selection and adaptation to convert values of source domain features to better approximate values of target domain features. Our approach includes a strategy to choose features for adaptation and an algorithm to adapt the values of these features. In this setting, transfer learning appears to improve model accuracy by increasing the contribution of less predictive features. Although the percentage improvements are small, such improvements in real world lending could be of significant economic importance.},
  archive      = {J_FRAI},
  author       = {Suryanto, Hendra and Mahidadia, Ashesh and Bain, Michael and Guan, Charles and Guan, Ada},
  doi          = {10.3389/frai.2022.868232},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {868232},
  shortjournal = {Front. Artif. Intell.},
  title        = {Credit risk modeling using transfer learning and domain adaptation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inclusive growth in the era of automation and AI: How can
taxation help? <em>FRAI</em>, <em>5</em>, 867832. (<a
href="https://doi.org/10.3389/frai.2022.867832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, the world economy is facing a massive rise in automation, robotics and Artificial Intelligence (AI) which, according to some analysts, could lead to significant job losses or job polarization and hence widen income and wealth disparities. This scenario may impede the achievement of the Sustainable Development Goal 8 (SDG 8). In this context, the role of government and regulation becomes crucial in order to prevent an undesirable scenario, where technological change, namely automation and AI, comes at the cost of mass unemployment and growing inequality. This paper focuses on the role of taxation as a possible tool for sharing the gains from automation and AI. Nowadays, advances in technology may have a direct impact on tax systems, which should be re-adapted to take into account new forms of jobs and new business models. The paper discusses pros and cons of several possible solutions and then compares progresses achieved in different countries. Concerning robot tax and digital taxes there are already some concrete steps undertaken both at national and international level, while other proposals remain still nebulous. Of course, taxation per se, and any single policy in general, is not sufficient to achieve a more inclusive and equal growth. It is instead crucial to create synergies across policies and a strong link between employment creation strategies, redistributive policies, skill development and social protection systems.},
  archive      = {J_FRAI},
  author       = {Merola, Rossana},
  doi          = {10.3389/frai.2022.867832},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {867832},
  shortjournal = {Front. Artif. Intell.},
  title        = {Inclusive growth in the era of automation and AI: How can taxation help?},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing equity investment strategies using analyst
reports and regime switching models. <em>FRAI</em>, <em>5</em>, 865950.
(<a href="https://doi.org/10.3389/frai.2022.865950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study demonstrates whether analysts&#39; sentiments toward individual stocks are useful for stock investment strategies. This is achieved by using natural language processing to create a polarity index from textual information in analyst reports. In this study, we performed time series forecasting for the created polarity index using deep learning, and clustered the forecasted values by volatility using a regime switching model. In addition, we constructed a portfolio from stock data and rebalanced it at each change point of the regime. Consequently, the investment strategy proposed in this study outperforms the benchmark portfolio in terms of returns. This suggests that the polarity index is useful for constructing stock investment strategies.},
  archive      = {J_FRAI},
  author       = {Taguchi, Rei and Watanabe, Hikaru and Sakaji, Hiroki and Izumi, Kiyoshi and Hiramatsu, Kenji},
  doi          = {10.3389/frai.2022.865950},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {865950},
  shortjournal = {Front. Artif. Intell.},
  title        = {Constructing equity investment strategies using analyst reports and regime switching models},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time inference with 2D convolutional neural networks on
field programmable gate arrays for high-rate particle imaging detectors.
<em>FRAI</em>, <em>5</em>, 855184. (<a
href="https://doi.org/10.3389/frai.2022.855184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a custom implementation of a 2D Convolutional Neural Network (CNN) as a viable application for real-time data selection in high-resolution and high-rate particle imaging detectors, making use of hardware acceleration in high-end Field Programmable Gate Arrays (FPGAs). To meet FPGA resource constraints, a two-layer CNN is optimized for accuracy and latency with KerasTuner, and network quantization is further used to minimize the computing resource utilization of the network. We use “High Level Synthesis for Machine Learning” (hls4ml) tools to test CNN deployment on a Xilinx UltraScale+ FPGA, which is an FPGA technology proposed for use in the front-end readout system of the future Deep Underground Neutrino Experiment (DUNE) particle detector. We evaluate network accuracy and estimate latency and hardware resource usage, and comment on the feasibility of applying CNNs for real-time data selection within the currently planned DUNE data acquisition system. This represents the first-ever exploration of employing 2D CNNs on FPGAs for DUNE.},
  archive      = {J_FRAI},
  author       = {Jwa, Yeon-jae and Di Guglielmo, Giuseppe and Arnold, Lukas and Carloni, Luca and Karagiorgi, Georgia},
  doi          = {10.3389/frai.2022.855184},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {855184},
  shortjournal = {Front. Artif. Intell.},
  title        = {Real-time inference with 2D convolutional neural networks on field programmable gate arrays for high-rate particle imaging detectors},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tracing the phonetic space of prosodic focus marking.
<em>FRAI</em>, <em>5</em>, 842546. (<a
href="https://doi.org/10.3389/frai.2022.842546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Focus is known to be expressed by a wide range of phonetic cues but only a few studies have explicitly compared different phonetic variables within the same experiment. Therefore, we presented results from an analysis of 19 phonetic variables conducted on a data set of the German language that comprises the opposition of unaccented (background) vs. accented (in focus), as well as different focus types with the nuclear accent on the same syllable (broad, narrow, and contrastive focus). The phonetic variables are measures of the acoustic and articulographic signals of a target syllable. Overall, our results provide the highest number of reliable effects and largest effect sizes for accentuation (unaccented vs. accented), while the differentiation of focus types with accented target syllables (broad, narrow, and contrastive focus) are more subtle. The most important phonetic variables across all conditions are measures of the fundamental frequency. The articulatory variables and their corresponding acoustic formants reveal lower tongue positions for both vowels /o, a/, and larger lip openings for the vowel /a/ under increased prosodic prominence with the strongest effects for accentuation. While duration exhibits consistent mid-ranked results for both accentuation and the differentiation of focus types, measures related to intensity are particularly important for accentuation. Furthermore, voice quality and spectral tilt are affected by accentuation but also in the differentiation of focus types. Our results confirm that focus is realized via multiple phonetic cues. Additionally, the present analysis allows a comparison of the relative importance of different measures to better understand the phonetic space of focus marking.},
  archive      = {J_FRAI},
  author       = {Roessig, Simon and Winter, Bodo and Mücke, Doris},
  doi          = {10.3389/frai.2022.842546},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {842546},
  shortjournal = {Front. Artif. Intell.},
  title        = {Tracing the phonetic space of prosodic focus marking},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). I need a CAVAA: How conversational agent voting advice
applications (CAVAAs) affect users’ political knowledge and tool
experience. <em>FRAI</em>, <em>5</em>, 835505. (<a
href="https://doi.org/10.3389/frai.2022.835505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In election times, millions of voters consult Voting Advice Applications (VAAs) to learn more about political parties and their standpoints. While VAAs have been shown to enhance political knowledge and increase electoral turnout, research also demonstrates that voters frequently experience comprehension problems when responding to the political attitude statements in a VAA. We describe two studies in which we test a new type of VAA, called Conversational Agent VAA (CAVAA), in which users can easily access relevant information about the political issues in the VAA statements by asking questions to a chatbot. Study 1 reports about an online experiment (N = 229) with a 2 (Type: traditional VAA/CAVAA) x 2 (Political sophistication: low/high) design. Results show that CAVAA users report higher perceived political knowledge scores and also answer more factual knowledge questions correctly than users of a regular VAA. Also, participants&#39; CAVAA experience was evaluated better. In Study 2 (N = 180), we compared three CAVAA designs (a structured design with buttons, a non-structured design with an open text field, and a semi-structured design with both buttons and an open text field), again for higher and lower politically sophisticated users. While the three designs score equally high on factual and perceived knowledge indicators, the experience of the structured CAVAA was evaluated more positively than the non-structured version. To explore the possible cause for these results, we conducted an additional qualitative content analysis on 90 chatbot-conversations (30 per chatbot version). This analysis shows that users more frequently access additional information in a structured design than in a non-structured design, whereas the number of break-offs is the same. This suggests that the structured design delivers the best experience, because it provides the best trigger to ask questions to the chatbot.},
  archive      = {J_FRAI},
  author       = {Kamoen, Naomi and Liebrecht, Christine},
  doi          = {10.3389/frai.2022.835505},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {835505},
  shortjournal = {Front. Artif. Intell.},
  title        = {I need a CAVAA: How conversational agent voting advice applications (CAVAAs) affect users&#39; political knowledge and tool experience},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial intelligence and employment: New cross-country
evidence. <em>FRAI</em>, <em>5</em>, 832736. (<a
href="https://doi.org/10.3389/frai.2022.832736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen impressive advances in artificial intelligence (AI) and this has stoked renewed concern about the impact of technological progress on the labor market, including on worker displacement. This paper looks at the possible links between AI and employment in a cross-country context. It adapts the AI occupational impact measure developed by Felten, Raj and Seamans—an indicator measuring the degree to which occupations rely on abilities in which AI has made the most progress—and extends it to 23 OECD countries. Overall, there appears to be no clear relationship between AI exposure and employment growth. However, in occupations where computer use is high, greater exposure to AI is linked to higher employment growth. The paper also finds suggestive evidence of a negative relationship between AI exposure and growth in average hours worked among occupations where computer use is low. One possible explanation is that partial automation by AI increases productivity directly as well as by shifting the task composition of occupations toward higher value-added tasks. This increase in labor productivity and output counteracts the direct displacement effect of automation through AI for workers with good digital skills, who may find it easier to use AI effectively and shift to non-automatable, higher-value added tasks within their occupations. The opposite could be true for workers with poor digital skills, who may not be able to interact efficiently with AI and thus reap all potential benefits of the technology1.},
  archive      = {J_FRAI},
  author       = {Georgieff, Alexandre and Hyee, Raphaela},
  doi          = {10.3389/frai.2022.832736},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {832736},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial intelligence and employment: New cross-country evidence},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting tissue-specific mRNA and protein abundance in
maize: A machine learning approach. <em>FRAI</em>, <em>5</em>, 830170.
(<a href="https://doi.org/10.3389/frai.2022.830170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and modeling approaches have been used to classify protein sequences for a broad set of tasks including predicting protein function, structure, expression, and localization. Some recent studies have successfully predicted whether a given gene is expressed as mRNA or even translated to proteins potentially, but given that not all genes are expressed in every condition and tissue, the challenge remains to predict condition-specific expression. To address this gap, we developed a machine learning approach to predict tissue-specific gene expression across 23 different tissues in maize, solely based on DNA promoter and protein sequences. For class labels, we defined high and low expression levels for mRNA and protein abundance and optimized classifiers by systematically exploring various methods and combinations of k-mer sequences in a two-phase approach. In the first phase, we developed Markov model classifiers for each tissue and built a feature vector based on the predictions. In the second phase, the feature vector was used as an input to a Bayesian network for final classification. Our results show that these methods can achieve high classification accuracy of up to 95% for predicting gene expression for individual tissues. By relying on sequence alone, our method works in settings where costly experimental data are unavailable and reveals useful insights into the functional, evolutionary, and regulatory characteristics of genes.},
  archive      = {J_FRAI},
  author       = {Cho, Kyoung Tak and Sen, Taner Z. and Andorf, Carson M.},
  doi          = {10.3389/frai.2022.830170},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {830170},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting tissue-specific mRNA and protein abundance in maize: A machine learning approach},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). In search of ambiguity: A three-stage workflow design to
clarify annotation guidelines for crowd workers. <em>FRAI</em>,
<em>5</em>, 828187. (<a
href="https://doi.org/10.3389/frai.2022.828187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel three-stage FIND-RESOLVE-LABEL workflow for crowdsourced annotation to reduce ambiguity in task instructions and, thus, improve annotation quality. Stage 1 (FIND) asks the crowd to find examples whose correct label seems ambiguous given task instructions. Workers are also asked to provide a short tag that describes the ambiguous concept embodied by the specific instance found. We compare collaborative vs. non-collaborative designs for this stage. In Stage 2 (RESOLVE), the requester selects one or more of these ambiguous examples to label (resolving ambiguity). The new label(s) are automatically injected back into task instructions in order to improve clarity. Finally, in Stage 3 (LABEL), workers perform the actual annotation using the revised guidelines with clarifying examples. We compare three designs using these examples: examples only, tags only, or both. We report image labeling experiments over six task designs using Amazon&#39;s Mechanical Turk. Results show improved annotation accuracy and further insights regarding effective design for crowdsourced annotation tasks.},
  archive      = {J_FRAI},
  author       = {Pradhan, Vivek Krishna and Schaekermann, Mike and Lease, Matthew},
  doi          = {10.3389/frai.2022.828187},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {828187},
  shortjournal = {Front. Artif. Intell.},
  title        = {In search of ambiguity: A three-stage workflow design to clarify annotation guidelines for crowd workers},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explainable model fusion for customer journey mapping.
<em>FRAI</em>, <em>5</em>, 824197. (<a
href="https://doi.org/10.3389/frai.2022.824197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advances in computing power and internet technology, various industrial sectors are adopting IT infrastructure and artificial intelligence (AI) technologies. Recently, data-driven predictions have attracted interest in high-stakes decision-making. Despite this, advanced AI methods are less often used for such tasks. This is because AI technology is a black box for the social systems it is meant to support; trustworthiness and fairness have not yet been established. Meanwhile in the field of marketing, strategic decision-making is a high-stakes problem that has a significant impact on business trends. For global marketing, with its diverse cultures and market environments, future decision-making is likely to focus on building consensus on the formulation of the problem itself rather than on solutions for achieving the goal. There are two important and conflicting facts: the fact that the core of domestic strategic decision-making comes down to the formulation of the problem itself, and the fact that it is difficult to realize AI technology that can achieve problem formulation. How can we resolve this difficulty with current technology? This is the main challenge for the realization of high-level human-AI systems in the marketing field. Thus, we propose customer journey mapping (CJM) automation through model-level data fusion, a process for the practical problem formulation known as explainable alignment. Using domain-specific requirements and observations as inputs, the system automatically outputs a CJM. Explainable alignment corresponds with both human and AI perspectives and in formulating the problem, thereby improving strategic decision-making in marketing. Following preprocessing to make latent variables and their dynamics transparent with latent Dirichlet allocation and a variational autoencoder, a post-hoc explanation is implemented in which a hidden Markov model and learning from an interpretation transition are combined with a long short-term memory architecture that learns sequential data between touchpoints for extracting attitude rules for CJM. Finally, we realize the application of human-AI systems to strategic decision-making in marketing with actual logs in over-the-top media services, in which the dynamic behavior of customers for CJM can be automatically extracted.},
  archive      = {J_FRAI},
  author       = {Okazaki, Kotaro and Inoue, Katsumi},
  doi          = {10.3389/frai.2022.824197},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {824197},
  shortjournal = {Front. Artif. Intell.},
  title        = {Explainable model fusion for customer journey mapping},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crowdsourcing team formation with worker-centered modeling.
<em>FRAI</em>, <em>5</em>, 818562. (<a
href="https://doi.org/10.3389/frai.2022.818562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern crowdsourcing offers the potential to produce solutions for increasingly complex tasks requiring teamwork and collective labor. However, the vast scale of the crowd makes forming project teams an intractable problem to coordinate manually. To date, most crowdsourcing collaborative platforms rely on algorithms to automate team formation based on worker profiling data and task objectives. As a top-down strategy, algorithmic crowd team formation tends to alienate workers causing poor collaboration, interpersonal clashes, and dissatisfaction. In this paper, we investigate different ways that crowd teams can be formed through three team formation models namely bottom-up, top-down, and hybrid. By simulating an open collaboration scenario such as a hackathon, we observe that the bottom-up model forms the most competitive teams with the highest teamwork quality. Furthermore, we note that bottom-up approaches are particularly suitable for populations with high-risk appetites (most workers being lenient toward exploring new team configurations) and high degrees of homophily (most workers preferring to work with similar teammates). Our study highlights the importance of integrating worker agency in algorithm-mediated team formation systems, especially in collaborative/competitive settings, and bears practical implications for large-scale crowdsourcing platforms.},
  archive      = {J_FRAI},
  author       = {Vinella, Federica Lucia and Hu, Jiayuan and Lykourentzou, Ioanna and Masthoff, Judith},
  doi          = {10.3389/frai.2022.818562},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {818562},
  shortjournal = {Front. Artif. Intell.},
  title        = {Crowdsourcing team formation with worker-centered modeling},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How personality and communication patterns affect online
ad-hoc teams under pressure. <em>FRAI</em>, <em>5</em>, 818491. (<a
href="https://doi.org/10.3389/frai.2022.818491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical, time-bounded, and high-stress tasks, like incident response, have often been solved by teams that are cohesive, adaptable, and prepared. Although a fair share of the literature has explored the effect of personality on various other types of teams and tasks, little is known about how it contributes to teamwork when teams of strangers have to cooperate ad-hoc, fast, and efficiently. This study explores the dynamics between 120 crowd participants paired into 60 virtual dyads and their collaboration outcome during the execution of a high-pressure, time-bound task. Results show that the personality trait of Openness to experience may impact team performance with teams with higher minimum levels of Openness more likely to defuse the bomb on time. An analysis of communication patterns suggests that winners made more use of action and response statements. The team role was linked to the individual&#39;s preference of certain communication patterns and related to their perception of the collaboration quality. Highly agreeable individuals seemed to cope better with losing, and individuals in teams heterogeneous in Conscientiousness seemed to feel better about collaboration quality. Our results also suggest there may be some impact of gender on performance. As this study was exploratory in nature, follow-on studies are needed to confirm these results. We discuss how these findings can help the development of AI systems to aid the formation and support of crowdsourced remote emergency teams.},
  archive      = {J_FRAI},
  author       = {Vinella, Federica Lucia and Odo, Chinasa and Lykourentzou, Ioanna and Masthoff, Judith},
  doi          = {10.3389/frai.2022.818491},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {818491},
  shortjournal = {Front. Artif. Intell.},
  title        = {How personality and communication patterns affect online ad-hoc teams under pressure},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward sharing brain images: Differentially private TOF-MRA
images with segmentation labels using generative adversarial networks.
<em>FRAI</em>, <em>5</em>, 813842. (<a
href="https://doi.org/10.3389/frai.2022.813842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharing labeled data is crucial to acquire large datasets for various Deep Learning applications. In medical imaging, this is often not feasible due to privacy regulations. Whereas anonymization would be a solution, standard techniques have been shown to be partially reversible. Here, synthetic data using a Generative Adversarial Network (GAN) with differential privacy guarantees could be a solution to ensure the patient&#39;s privacy while maintaining the predictive properties of the data. In this study, we implemented a Wasserstein GAN (WGAN) with and without differential privacy guarantees to generate privacy-preserving labeled Time-of-Flight Magnetic Resonance Angiography (TOF-MRA) image patches for brain vessel segmentation. The synthesized image-label pairs were used to train a U-net which was evaluated in terms of the segmentation performance on real patient images from two different datasets. Additionally, the Fréchet Inception Distance (FID) was calculated between the generated images and the real images to assess their similarity. During the evaluation using the U-Net and the FID, we explored the effect of different levels of privacy which was represented by the parameter ϵ. With stricter privacy guarantees, the segmentation performance and the similarity to the real patient images in terms of FID decreased. Our best segmentation model, trained on synthetic and private data, achieved a Dice Similarity Coefficient (DSC) of 0.75 for ϵ = 7.4 compared to 0.84 for ϵ = ∞ in a brain vessel segmentation paradigm (DSC of 0.69 and 0.88 on the second test set, respectively). We identified a threshold of ϵ &amp;lt;5 for which the performance (DSC &amp;lt;0.61) became unstable and not usable. Our synthesized labeled TOF-MRA images with strict privacy guarantees retained predictive properties necessary for segmenting the brain vessels. Although further research is warranted regarding generalizability to other imaging modalities and performance improvement, our results mark an encouraging first step for privacy-preserving data sharing in medical imaging.},
  archive      = {J_FRAI},
  author       = {Kossen, Tabea and Hirzel, Manuel A. and Madai, Vince I. and Boenisch, Franziska and Hennemuth, Anja and Hildebrand, Kristian and Pokutta, Sebastian and Sharma, Kartikey and Hilbert, Adam and Sobesky, Jan and Galinovic, Ivana and Khalil, Ahmed A. and Fiebach, Jochen B. and Frey, Dietmar},
  doi          = {10.3389/frai.2022.813842},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {813842},
  shortjournal = {Front. Artif. Intell.},
  title        = {Toward sharing brain images: Differentially private TOF-MRA images with segmentation labels using generative adversarial networks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain generalization for language-independent automatic
speech recognition. <em>FRAI</em>, <em>5</em>, 806274. (<a
href="https://doi.org/10.3389/frai.2022.806274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A language-independent automatic speech recognizer (ASR) is one that can be used for phonetic transcription in languages other than the languages in which it was trained. Language-independent ASR is difficult to train, because different languages implement phones differently: even when phonemes in two different languages are written using the same symbols in the international phonetic alphabet, they are differentiated by different distributions of language-dependent redundant articulatory features. This article demonstrates that the goal of language-independence may be approximated in different ways, depending on the size of the training set, the presence vs. absence of familial relationships between the training and test languages, and the method used to implement phone recognition or classification. When the training set contains many languages, and when every language in the test set is related (shares the same language family with) a language in the training set, then language-independent ASR may be trained using an empirical risk minimization strategy (e.g., using connectionist temporal classification without extra regularizers). When the training set is limited to a small number of languages from one language family, however, and the test languages are not from the same language family, then the best performance is achieved by using domain-invariant representation learning strategies. Two different representation learning strategies are tested in this article: invariant risk minimization, and regret minimization. We find that invariant risk minimization is better at the task of phone token classification (given known segment boundary times), while regret minimization is better at the task of phone token recognition.},
  archive      = {J_FRAI},
  author       = {Gao, Heting and Ni, Junrui and Zhang, Yang and Qian, Kaizhi and Chang, Shiyu and Hasegawa-Johnson, Mark},
  doi          = {10.3389/frai.2022.806274},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {806274},
  shortjournal = {Front. Artif. Intell.},
  title        = {Domain generalization for language-independent automatic speech recognition},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond the benchmarks: Toward human-like lexical
representations. <em>FRAI</em>, <em>5</em>, 796741. (<a
href="https://doi.org/10.3389/frai.2022.796741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To process language in a way that is compatible with human expectations in a communicative interaction, we need computational representations of lexical properties that form the basis of human knowledge of words. In this article, we concentrate on word-level semantics. We discuss key concepts and issues that underlie the scientific understanding of the human lexicon: its richly structured semantic representations, their ready and continual adaptability, and their grounding in crosslinguistically valid conceptualization. We assess the state of the art in natural language processing (NLP) in achieving these identified properties, and suggest ways in which the language sciences can inspire new approaches to their computational instantiation.},
  archive      = {J_FRAI},
  author       = {Stevenson, Suzanne and Merlo, Paola},
  doi          = {10.3389/frai.2022.796741},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {796741},
  shortjournal = {Front. Artif. Intell.},
  title        = {Beyond the benchmarks: Toward human-like lexical representations},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling users’ cognitive performance using digital pen
features. <em>FRAI</em>, <em>5</em>, 787179. (<a
href="https://doi.org/10.3389/frai.2022.787179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital pen features model characteristics of sketches and user behavior, and can be used for various supervised machine learning (ML) applications, such as multi-stroke sketch recognition and user modeling. In this work, we use a state-of-the-art set of more than 170 digital pen features, which we implement and make publicly available. The feature set is evaluated in the use case of analyzing paper-pencil-based neurocognitive assessments in the medical domain. Most cognitive assessments, for dementia screening for example, are conducted with a pen on normal paper. We record these tests with a digital pen as part of a new interactive cognitive assessment tool with automatic analysis of pen input. The physician can, first, observe the sketching process in real-time on a mobile tablet, e.g., in telemedicine settings or to follow Covid-19 distancing regulations. Second, the results of an automatic test analysis are presented to the physician in real-time, thereby reducing manual scoring effort and producing objective reports. As part of our evaluation we examine how accurately different feature-based, supervised ML models can automatically score cognitive tests, with and without semantic content analysis. A series of ML-based sketch recognition experiments is conducted, evaluating 10 modern off-the-shelf ML classifiers (i.e., SVMs, Deep Learning, etc.) on a sketch data set which we recorded with 40 subjects from a geriatrics daycare clinic. In addition, an automated ML approach (AutoML) is explored for fine-tuning and optimizing classification performance on the data set, achieving superior recognition accuracies. Using standard ML techniques our feature set outperforms all previous approaches on the cognitive tests considered, i.e., the Clock Drawing Test, the Rey-Osterrieth Complex Figure Test, and the Trail Making Test, by automatically scoring cognitive tests with up to 87.5% accuracy in a binary classification task.},
  archive      = {J_FRAI},
  author       = {Prange, Alexander and Sonntag, Daniel},
  doi          = {10.3389/frai.2022.787179},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {787179},
  shortjournal = {Front. Artif. Intell.},
  title        = {Modeling users&#39; cognitive performance using digital pen features},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Componential analysis of english verbs. <em>FRAI</em>,
<em>5</em>, 780385. (<a
href="https://doi.org/10.3389/frai.2022.780385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational lexical resources such as WordNet, PropBank, VerbNet, and FrameNet are in regular use in various NLP applications, assisting in the never-ending quest for richer, more precise semantic representations. Coherent class-based organization of lexical units in VerbNet and FrameNet can improve the efficiency of processing by clustering similar items together and sharing descriptions. However, class members are sometimes quite different, and the clustering in both can gloss over useful fine-grained semantic distinctions. FrameNet officially eschews syntactic considerations and focuses primarily on semantic coherence, associating nouns, verbs and adjectives with the same semantic frame, while VerbNet considers both syntactic and semantic factors in defining a class of verbs, relying heavily on meaning-preserving diathesis alternations. Many VerbNet classes significantly overlap in membership with similar FrameNet Frames, e.g., VerbNet Cooking-45.3 and FrameNet Apply_heat, but some VerbNet classes are so heterogeneous as to be difficult to characterize semantically, e.g., Other_cos-45.4. We discuss a recent addition to the VerbNet class semantics, verb-specific semantic features, that provides significant enrichment to the information associated with verbs in each VerbNet class. They also implicitly group together verbs sharing semantic features within a class, forming more semantically coherent subclasses. These efforts began with introspection and dictionary lookup, and progressed to automatic techniques, such as using NLTK sentiment analysis on verb members of VerbNet classes with an Experiencer argument role, to assign positive, negative or neutral labels to them. More recently we found the Brandeis Semantic Ontology (BSO) to be an invaluable source of rich semantic information and were able to use a VerbNet-BSO mapping to find fine-grained distinctions in the semantic features of verb members of 25 VerbNet classes. This not only confirmed the assignments previously made to classes such as Admire-31.2, but also gave a more fine-grained semantic decomposition for the members. Also, for the Judgment-31.1 class, the new method revealed new, more fine-grained existing semantic features for the verbs. Overall, the BSO mapping produced promising results, and as a manually curated resource, we have confidence the results are reliable and need little (if any) further hand-correction. We discuss our various techniques, illustrating the results with specific classes.},
  archive      = {J_FRAI},
  author       = {Kazeminejad, Ghazaleh and Palmer, Martha and Brown, Susan Windisch and Pustejovsky, James},
  doi          = {10.3389/frai.2022.780385},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {780385},
  shortjournal = {Front. Artif. Intell.},
  title        = {Componential analysis of english verbs},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Targeted screening for alzheimer’s disease clinical trials
using data-driven disease progression models. <em>FRAI</em>, <em>5</em>,
660581. (<a href="https://doi.org/10.3389/frai.2022.660581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneity in Alzheimer&#39;s disease progression contributes to the ongoing failure to demonstrate efficacy of putative disease-modifying therapeutics that have been trialed over the past two decades. Any treatment effect present in a subgroup of trial participants (responders) can be diluted by non-responders who ideally should have been screened out of the trial. How to identify (screen-in) the most likely potential responders is an important question that is still without an answer. Here, we pilot a computational screening tool that leverages recent advances in data-driven disease progression modeling to improve stratification. This aims to increase the sensitivity to treatment effect by screening out non-responders, which will ultimately reduce the size, duration, and cost of a clinical trial. We demonstrate the concept of such a computational screening tool by retrospectively analyzing a completed double-blind clinical trial of donepezil in people with amnestic mild cognitive impairment (clinicaltrials.gov: NCT00000173), identifying a data-driven subgroup having more severe cognitive impairment who showed clearer treatment response than observed for the full cohort.},
  archive      = {J_FRAI},
  author       = {Oxtoby, Neil P. and Shand, Cameron and Cash, David M. and Alexander, Daniel C. and Barkhof, Frederik},
  doi          = {10.3389/frai.2022.660581},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {5},
  pages        = {660581},
  shortjournal = {Front. Artif. Intell.},
  title        = {Targeted screening for alzheimer&#39;s disease clinical trials using data-driven disease progression models},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting universal healthcare through health financial
management for sustainable development in BRICS, GCC, and AUKUS economic
blocks. <em>FRAI</em>, <em>5</em>, 887225. (<a
href="https://doi.org/10.3389/frai.2022.887225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of the world&#39;s population is still facing difficulties in getting access to primary healthcare facilities. Universal health coverage (UHC) proposes access to high-quality, affordable primary healthcare for all. The 17 UN sustainable development goals (SDGs) are expected to be executed and achieved by all the 193 countries through national sustainable development strategies and multi-stakeholder partnerships. This article addresses SDG 3.8—access to good quality and affordable healthcare and two subindicators related to societal impact (SDG 3.8.1 and 3.8.2) through two objectives. The first objective is to determine whether health expenditure indicators (HEIs) drive UHC, and the second objective is to analyze the importance of key determinants and their interactions with UHC in three economic blocks: emerging Gulf Cooperation Council (GCC); developing Brazil, Russia, India, China, and South Africa (BRICS) vis-à-vis the developed Australia, UK, and USA (AUKUS). We use the WHO Global Health Indicator database and UHC periodical surveys to evaluate the hypotheses. We apply state-of-the-art machine learning (ML) models and ordinary least square (traditional—OLS regression) methods to see the superiority of artificial intelligence (AI) over traditional ones. The ML Random Forest Tree method is found to be superior to the OLS model in terms of lower root mean square error (RMSE). The ML results indicate that domestic private health expenditure (PVT-D), out-of-pocket expenditure (OOPS) per Capita in US dollars, and voluntary health insurance (VHI) as a percentage of current health expenditure (CHE) are the key factors influencing UHC across the three economic blocks. Our findings have implications for drafting health and finance sector public policies, such as providing affordable social health insurance to the weaker sections of the population, making insurance premiums less expensive and affordable for the masses, and designing healthcare financing policies that are beneficial to the masses. UHC is an important determinant of health for all and requires an in-depth analysis of related factors. Policymakers are often faced with the challenge of prioritizing the economic needs of sectors such as education and food safety, making it difficult for healthcare to receive its due share. In this context, this article attempts to identify the key components that may influence the attainment of UHC and enable policy changes to address them more effectively and efficiently.},
  archive      = {J_FRAI},
  author       = {M. V., Manoj Kumar and Sastry, Nanda Kumar Bidare and Moonesar, Immanuel Azaad and Rao, Ananth},
  doi          = {10.3389/frai.2022.887225},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {887225},
  shortjournal = {Front. Artif. Intell.},
  title        = {Predicting universal healthcare through health financial management for sustainable development in BRICS, GCC, and AUKUS economic blocks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emerging grounded shared vocabularies between human and
machine, inspired by human language evolution. <em>FRAI</em>,
<em>5</em>, 886349. (<a
href="https://doi.org/10.3389/frai.2022.886349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Kouwenhoven, Tom and Verhoef, Tessa and de Kleijn, Roy and Raaijmakers, Stephan},
  doi          = {10.3389/frai.2022.886349},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {886349},
  shortjournal = {Front. Artif. Intell.},
  title        = {Emerging grounded shared vocabularies between human and machine, inspired by human language evolution},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impact of box-cox transformation on machine-learning
algorithms. <em>FRAI</em>, <em>5</em>, 877569. (<a
href="https://doi.org/10.3389/frai.2022.877569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studied the effects of applying the Box-Cox transformation for classification tasks. Different optimization strategies were evaluated, and the results were promising on four synthetic datasets and two real-world datasets. A consistent improvement in accuracy was demonstrated using a grid exploration with cross-validation. In conclusion, applying the Box-Cox transformation could drastically improve the performance by up to a 12% accuracy increase. Moreover, the Box-Cox parameter choice was dependent on the data and the used classifier.},
  archive      = {J_FRAI},
  author       = {Blum, Luca and Elgendi, Mohamed and Menon, Carlo},
  doi          = {10.3389/frai.2022.877569},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {877569},
  shortjournal = {Front. Artif. Intell.},
  title        = {Impact of box-cox transformation on machine-learning algorithms},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework on generalizability of clinical
prediction models. <em>FRAI</em>, <em>5</em>, 872720. (<a
href="https://doi.org/10.3389/frai.2022.872720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To be useful, clinical prediction models (CPMs) must be generalizable to patients in new settings. Evaluating generalizability of CPMs helps identify spurious relationships in data, provides insights on when they fail, and thus, improves the explainability of the CPMs. There are discontinuities in concepts related to generalizability of CPMs in the clinical research and machine learning domains. Specifically, conventional statistical reasons to explain poor generalizability such as inadequate model development for the purposes of generalizability, differences in coding of predictors and outcome between development and external datasets, measurement error, inability to measure some predictors, and missing data, all have differing and often complementary treatments, in the two domains. Much of the current machine learning literature on generalizability of CPMs is in terms of dataset shift of which several types have been described. However, little research exists to synthesize concepts in the two domains. Bridging this conceptual discontinuity in the context of CPMs can facilitate systematic development of CPMs and evaluation of their sensitivity to factors that affect generalizability. We survey generalizability and dataset shift in CPMs from both the clinical research and machine learning perspectives, and describe a unifying framework to analyze generalizability of CPMs and to explain their sensitivity to factors affecting it. Our framework leads to a set of signaling statements that can be used to characterize differences between datasets in terms of factors that affect generalizability of the CPMs.},
  archive      = {J_FRAI},
  author       = {Wan, Bohua and Caffo, Brian and Vedula, S. Swaroop},
  doi          = {10.3389/frai.2022.872720},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {872720},
  shortjournal = {Front. Artif. Intell.},
  title        = {A unified framework on generalizability of clinical prediction models},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Intelligent conversational agents. <em>FRAI</em>,
<em>5</em>, 867834. (<a
href="https://doi.org/10.3389/frai.2022.867834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Specht, Marcus and Oertel, Catharine},
  doi          = {10.3389/frai.2022.867834},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {867834},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Intelligent conversational agents},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-explaining social robots: An explainable behavior
generation architecture for human-robot interaction. <em>FRAI</em>,
<em>5</em>, 866920. (<a
href="https://doi.org/10.3389/frai.2022.866920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the ability of intelligent systems to be understood by developers and users has received growing attention. This holds in particular for social robots, which are supposed to act autonomously in the vicinity of human users and are known to raise peculiar, often unrealistic attributions and expectations. However, explainable models that, on the one hand, allow a robot to generate lively and autonomous behavior and, on the other, enable it to provide human-compatible explanations for this behavior are missing. In order to develop such a self-explaining autonomous social robot, we have equipped a robot with own needs that autonomously trigger intentions and proactive behavior, and form the basis for understandable self-explanations. Previous research has shown that undesirable robot behavior is rated more positively after receiving an explanation. We thus aim to equip a social robot with the capability to automatically generate verbal explanations of its own behavior, by tracing its internal decision-making routes. The goal is to generate social robot behavior in a way that is generally interpretable, and therefore explainable on a socio-behavioral level increasing users&#39; understanding of the robot&#39;s behavior. In this article, we present a social robot interaction architecture, designed to autonomously generate social behavior and self-explanations. We set out requirements for explainable behavior generation architectures and propose a socio-interactive framework for behavior explanations in social human-robot interactions that enables explaining and elaborating according to users&#39; needs for explanation that emerge within an interaction. Consequently, we introduce an interactive explanation dialog flow concept that incorporates empirically validated explanation types. These concepts are realized within the interaction architecture of a social robot, and integrated with its dialog processing modules. We present the components of this interaction architecture and explain their integration to autonomously generate social behaviors as well as verbal self-explanations. Lastly, we report results from a qualitative evaluation of a working prototype in a laboratory setting, showing that (1) the robot is able to autonomously generate naturalistic social behavior, and (2) the robot is able to verbally self-explain its behavior to the user in line with users&#39; requests.},
  archive      = {J_FRAI},
  author       = {Stange, Sonja and Hassan, Teena and Schröder, Florian and Konkol, Jacqueline and Kopp, Stefan},
  doi          = {10.3389/frai.2022.866920},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {866920},
  shortjournal = {Front. Artif. Intell.},
  title        = {Self-explaining social robots: An explainable behavior generation architecture for human-robot interaction},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous tool for monitoring multi-morbidity health
conditions in UAE and india. <em>FRAI</em>, <em>5</em>, 865792. (<a
href="https://doi.org/10.3389/frai.2022.865792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-morbidity is the presence of two or more long-term health conditions, including defined physical or mental health conditions, such as diabetes or schizophrenia. One of the regular and critical health cases is an elderly person with a multi-morbid health condition and special complications who lives alone. These patients are typically not familiar with advanced Information and Communications Technology (ICT), but they are comfortable using smart devices such as wearable watches and mobile phones. The use of ICT improves medical quality, promotes patient security and data security, lowers operational and administrative costs, and gives the people in charge to make informed decisions. Additionally, the use of ICT in healthcare practices greatly reduces human errors, enhances clinical outcomes, ramps up care coordination, boosts practice efficiencies, and helps in collecting data over time. The proposed research concept provides a natural technique to implement preventive health care innovative solutions since several health sensors are embedded in devices that autonomously monitor the patients&#39; health conditions in real-time. This enhances the elder&#39;s limited ability to predict and respond to critical health situations. Autonomous monitoring can alert doctors and patients themselves of unexpected health conditions. Real-time monitoring, modeling, and predicting health conditions can trigger swift responses by doctors and health officials in case of emergencies. This study will use data science to stimulate discoveries and breakthroughs in the United Arab Emirates (UAE) and India, which will then be reproduced in other world areas to create major gains in health for people, communities, and populations.},
  archive      = {J_FRAI},
  author       = {Atalla, Shadi and Amin, Saad Ali and Manoj Kumar, M. V. and Sastry, Nanda Kumar Bidare and Mansoor, Wathiq and Rao, Ananth},
  doi          = {10.3389/frai.2022.865792},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {865792},
  shortjournal = {Front. Artif. Intell.},
  title        = {Autonomous tool for monitoring multi-morbidity health conditions in UAE and india},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mitigating issues with/of/for true personalization.
<em>FRAI</em>, <em>5</em>, 844817. (<a
href="https://doi.org/10.3389/frai.2022.844817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common but false perception persists about the level and type of personalization in the offerings of contemporary software, information systems, and services, known as Personalization Myopia: this involves a tendency for researchers to think that there are many more personalized services than there genuinely are, for the general audience to think that they are offered personalized services when they really are not, and for practitioners to have a mistaken idea of what makes a service personalized. And yet in an era, which mashes up large amounts of data, business analytics, deep learning, and persuasive systems, true personalization is a most promising approach for innovating and developing new types of systems and services—including support for behavior change. The potential of true personalization is elaborated in this article, especially with regards to persuasive software features and the oft-neglected fact that users change over time.},
  archive      = {J_FRAI},
  author       = {Oinas-Kukkonen, Harri and Pohjolainen, Sami and Agyei, Eunice},
  doi          = {10.3389/frai.2022.844817},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {844817},
  shortjournal = {Front. Artif. Intell.},
  title        = {Mitigating issues with/of/for true personalization},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated evolutionary learning: An artificial intelligence
approach to joint learning of features and hyperparameters for
optimized, explainable machine learning. <em>FRAI</em>, <em>5</em>,
832530. (<a href="https://doi.org/10.3389/frai.2022.832530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence and machine learning techniques have proved fertile methods for attacking difficult problems in medicine and public health. These techniques have garnered strong interest for the analysis of the large, multi-domain open science datasets that are increasingly available in health research. Discovery science in large datasets is challenging given the unconstrained nature of the learning environment where there may be a large number of potential predictors and appropriate ranges for model hyperparameters are unknown. As well, it is likely that explainability is at a premium in order to engage in future hypothesis generation or analysis. Here, we present a novel method that addresses these challenges by exploiting evolutionary algorithms to optimize machine learning discovery science while exploring a large solution space and minimizing bias. We demonstrate that our approach, called integrated evolutionary learning (IEL), provides an automated, adaptive method for jointly learning features and hyperparameters while furnishing explainable models where the original features used to make predictions may be obtained even with artificial neural networks. In IEL the machine learning algorithm of choice is nested inside an evolutionary algorithm which selects features and hyperparameters over generations on the basis of an information function to converge on an optimal solution. We apply IEL to three gold standard machine learning algorithms in challenging, heterogenous biobehavioral data: deep learning with artificial neural networks, decision tree-based techniques and baseline linear models. Using our novel IEL approach, artificial neural networks achieved ≥ 95% accuracy, sensitivity and specificity and 45–73% R2 in classification and substantial gains over default settings. IEL may be applied to a wide range of less- or unconstrained discovery science problems where the practitioner wishes to jointly learn features and hyperparameters in an adaptive, principled manner within the same algorithmic process. This approach offers significant flexibility, enlarges the solution space and mitigates bias that may arise from manual or semi-manual hyperparameter tuning and feature selection and presents the opportunity to select the inner machine learning algorithm based on the results of optimized learning for the problem at hand.},
  archive      = {J_FRAI},
  author       = {de Lacy, Nina and Ramshaw, Michael J. and Kutz, J. Nathan},
  doi          = {10.3389/frai.2022.832530},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {832530},
  shortjournal = {Front. Artif. Intell.},
  title        = {Integrated evolutionary learning: An artificial intelligence approach to joint learning of features and hyperparameters for optimized, explainable machine learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A community-based model of care during the fourth wave of
the COVID-19 outbreak in ho chi minh city, vietnam. <em>FRAI</em>,
<em>5</em>, 831841. (<a
href="https://doi.org/10.3389/frai.2022.831841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to a call for help during a surge in coronavirus disease-19 (COVID-19) cases in Ho Chi Minh City in July 2021, the University of Medicine and Pharmacy at Ho Chi Minh City developed and implemented a community care model for the management of patients with COVID-19. This was based on three main principles: home care; providing monitoring and care at a distance; and providing timely emergency care if needed. One team supported patients at home with frequent contacts and remote monitoring, while a second team transferred and cared for patients requiring treatment at field emergency care facilities. COVID-19-related mortality rates at the two districts where this approach was implemented (0.43% and 0.57%) were substantially lower than the overall rate in Ho Chi Minh City over the same period (4.95%). Thus, utilization of a community care model can increase the number of patients with COVID-19 who can be effectively managed from home, and use of field emergency care facilities limited the number of patients that had to be referred for tertiary care. Importantly, the community care model also markedly reduced the mortality rate compared with traditional methods of COVID-19 patient management.},
  archive      = {J_FRAI},
  author       = {Vuong, Lan N. and Huynh, Nghia and Ngo, Dat Q. and Nguyen, Vinh N. and Duong, Khoa D. and Tran, Nguyen N. and Le, Truyen P. and Nguyen, Nghia A. and Doan, Thao T. P. and Pham, Duy L. and Trinh, Tu H. K. and Vu, Quan T. T. and Nguyen, Phong H. and Tran, Tuan D.},
  doi          = {10.3389/frai.2022.831841},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {831841},
  shortjournal = {Front. Artif. Intell.},
  title        = {A community-based model of care during the fourth wave of the COVID-19 outbreak in ho chi minh city, vietnam},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TB-net: A tailored, self-attention deep convolutional neural
network design for detection of tuberculosis cases from chest x-ray
images. <em>FRAI</em>, <em>5</em>, 827299. (<a
href="https://doi.org/10.3389/frai.2022.827299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tuberculosis (TB) remains a global health problem, and is the leading cause of death from an infectious disease. A crucial step in the treatment of tuberculosis is screening high risk populations and the early detection of the disease, with chest x-ray (CXR) imaging being the most widely-used imaging modality. As such, there has been significant recent interest in artificial intelligence-based TB screening solutions for use in resource-limited scenarios where there is a lack of trained healthcare workers with expertise in CXR interpretation. Motivated by this pressing need and the recent recommendation by the World Health Organization (WHO) for the use of computer-aided diagnosis of TB in place of a human reader, we introduce TB-Net, a self-attention deep convolutional neural network tailored for TB case screening. We used CXR data from a multi-national patient cohort to train and test our models. A machine-driven design exploration approach leveraging generative synthesis was used to build a highly customized deep neural network architecture with attention condensers. We conducted an explainability-driven performance validation process to validate TB-Net&#39;s decision-making behavior. Experiments on CXR data from a multi-national patient cohort showed that the proposed TB-Net is able to achieve accuracy/sensitivity/specificity of 99.86/100.0/99.71%. Radiologist validation was conducted on select cases by two board-certified radiologists with over 10 and 19 years of experience, respectively, and showed consistency between radiologist interpretation and critical factors leveraged by TB-Net for TB case detection for the case where radiologists identified anomalies. The proposed TB-Net not only achieves high tuberculosis case detection performance in terms of sensitivity and specificity, but also leverages clinically relevant critical factors in its decision making process. While not a production-ready solution, we hope that the open-source release of TB-Net as part of the COVID-Net initiative will support researchers, clinicians, and citizen data scientists in advancing this field in the fight against this global public health crisis.},
  archive      = {J_FRAI},
  author       = {Wong, Alexander and Lee, James Ren Hou and Rahmat-Khah, Hadi and Sabri, Ali and Alaref, Amer and Liu, Haiyue},
  doi          = {10.3389/frai.2022.827299},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {827299},
  shortjournal = {Front. Artif. Intell.},
  title        = {TB-net: A tailored, self-attention deep convolutional neural network design for detection of tuberculosis cases from chest X-ray images},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI technologies, privacy, and security. <em>FRAI</em>,
<em>5</em>, 826737. (<a
href="https://doi.org/10.3389/frai.2022.826737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy remains one of the most recurrent concerns that people have about AI technologies. The meaning of the concept of “privacy” has proven to be fairly elusive. Accordingly, the concerns people have about privacy are often vague and ill-formed, which makes it correspondingly difficult to address these concerns, and to explain the ways in which AI technologies do or do not pose threats to people&#39;s interests. In this article, we draw attention to some important distinctions that are frequently overlooked, and spell out their implications for concerns about the threats that AI-related technology poses for privacy. We argue that, when people express concerns about privacy in relation to AI technologies, they are usually referring to security interests rather than interests in privacy per se. Nevertheless, we argue that focusing primarily on security interests misses the importance that interests in privacy per se have through their contribution to autonomy and the development of our identities. Improving insight about these issues can make it easier for the developers of AI technologies to provide explanations for users about what interests are and are not at stake through the use of AI systems.},
  archive      = {J_FRAI},
  author       = {Elliott, David and Soifer, Eldon},
  doi          = {10.3389/frai.2022.826737},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {826737},
  shortjournal = {Front. Artif. Intell.},
  title        = {AI technologies, privacy, and security},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EXP-crowd: A gamified crowdsourcing framework for
explainability. <em>FRAI</em>, <em>5</em>, 826499. (<a
href="https://doi.org/10.3389/frai.2022.826499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of AI and black-box machine learning models made it necessary to explain their behavior. Consequently, the research field of Explainable AI was born. The main objective of an Explainable AI system is to be understood by a human as the final beneficiary of the model. In our research, we frame the explainability problem from the crowds point of view and engage both users and AI researchers through a gamified crowdsourcing framework. We research whether it&#39;s possible to improve the crowds understanding of black-box models and the quality of the crowdsourced content by engaging users in a set of gamified activities through a gamified crowdsourcing framework named EXP-Crowd. While users engage in such activities, AI researchers organize and share AI- and explainability-related knowledge to educate users. We present the preliminary design of a game with a purpose (G.W.A.P.) to collect features describing real-world entities which can be used for explainability purposes. Future works will concretise and improve the current design of the framework to cover specific explainability-related needs.},
  archive      = {J_FRAI},
  author       = {Tocchetti, Andrea and Corti, Lorenzo and Brambilla, Marco and Celino, Irene},
  doi          = {10.3389/frai.2022.826499},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {826499},
  shortjournal = {Front. Artif. Intell.},
  title        = {EXP-crowd: A gamified crowdsourcing framework for explainability},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational modeling of stereotype content in text.
<em>FRAI</em>, <em>5</em>, 826207. (<a
href="https://doi.org/10.3389/frai.2022.826207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereotypes are encountered every day, in interpersonal communication as well as in entertainment, news stories, and on social media. In this study, we present a computational method to mine large, naturally occurring datasets of text for sentences that express perceptions of a social group of interest, and then map these sentences to the two-dimensional plane of perceived warmth and competence for comparison and interpretation. This framework is grounded in established social psychological theory, and validated against both expert annotation and crowd-sourced stereotype data. Additionally, we present two case studies of how the model might be used to answer questions using data “in-the-wild,” by collecting Twitter data about women and older adults. Using the data about women, we are able to observe how sub-categories of women (e.g., Black women and white women) are described similarly and differently from each other, and from the superordinate group of women in general. Using the data about older adults, we show evidence that the terms people use to label a group (e.g., old people vs. senior citizens) are associated with different stereotype content. We propose that this model can be used by other researchers to explore questions of how stereotypes are expressed in various large text corpora.},
  archive      = {J_FRAI},
  author       = {Fraser, Kathleen C. and Kiritchenko, Svetlana and Nejadgholi, Isar},
  doi          = {10.3389/frai.2022.826207},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {826207},
  shortjournal = {Front. Artif. Intell.},
  title        = {Computational modeling of stereotype content in text},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GANterfactual—counterfactual explanations for medical
non-experts using generative adversarial learning. <em>FRAI</em>,
<em>5</em>, 825565. (<a
href="https://doi.org/10.3389/frai.2022.825565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ongoing rise of machine learning, the need for methods for explaining decisions made by artificial intelligence systems is becoming a more and more important topic. Especially for image classification tasks, many state-of-the-art tools to explain such classifiers rely on visual highlighting of important areas of the input data. Contrary, counterfactual explanation systems try to enable a counterfactual reasoning by modifying the input image in a way such that the classifier would have made a different prediction. By doing so, the users of counterfactual explanation systems are equipped with a completely different kind of explanatory information. However, methods for generating realistic counterfactual explanations for image classifiers are still rare. Especially in medical contexts, where relevant information often consists of textural and structural information, high-quality counterfactual images have the potential to give meaningful insights into decision processes. In this work, we present GANterfactual, an approach to generate such counterfactual image explanations based on adversarial image-to-image translation techniques. Additionally, we conduct a user study to evaluate our approach in an exemplary medical use case. Our results show that, in the chosen medical use-case, counterfactual explanations lead to significantly better results regarding mental models, explanation satisfaction, trust, emotions, and self-efficacy than two state-of-the art systems that work with saliency maps, namely LIME and LRP.},
  archive      = {J_FRAI},
  author       = {Mertes, Silvan and Huber, Tobias and Weitz, Katharina and Heimerl, Alexander and André, Elisabeth},
  doi          = {10.3389/frai.2022.825565},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {825565},
  shortjournal = {Front. Artif. Intell.},
  title        = {GANterfactual—Counterfactual explanations for medical non-experts using generative adversarial learning},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic representations for NLP using VerbNet and the
generative lexicon. <em>FRAI</em>, <em>5</em>, 821697. (<a
href="https://doi.org/10.3389/frai.2022.821697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for deeper semantic processing of human language by our natural language processing systems is evidenced by their still-unreliable performance on inferencing tasks, even using deep learning techniques. These tasks require the detection of subtle interactions between participants in events, of sequencing of subevents that are often not explicitly mentioned, and of changes to various participants across an event. Human beings can perform this detection even when sparse lexical items are involved, suggesting that linguistic insights into these abilities could improve NLP performance. In this article, we describe new, hand-crafted semantic representations for the lexical resource VerbNet that draw heavily on the linguistic theories about subevent semantics in the Generative Lexicon (GL). VerbNet defines classes of verbs based on both their semantic and syntactic similarities, paying particular attention to shared diathesis alternations. For each class of verbs, VerbNet provides common semantic roles and typical syntactic patterns. For each syntactic pattern in a class, VerbNet defines a detailed semantic representation that traces the event participants from their initial states, through any changes and into their resulting states. The Generative Lexicon guided the structure of these representations. In GL, event structure has been integrated with dynamic semantic models in order to represent the attribute modified in the course of the event (the location of the moving entity, the extent of a created or destroyed entity, etc.) as a sequence of states related to time points or intervals. We applied that model to VerbNet semantic representations, using a class&#39;s semantic roles and a set of predicates defined across classes as components in each subevent. We will describe in detail the structure of these representations, the underlying theory that guides them, and the definition and use of the predicates. We will also evaluate the effectiveness of this resource for NLP by reviewing efforts to use the semantic representations in NLP tasks.},
  archive      = {J_FRAI},
  author       = {Brown, Susan Windisch and Bonn, Julia and Kazeminejad, Ghazaleh and Zaenen, Annie and Pustejovsky, James and Palmer, Martha},
  doi          = {10.3389/frai.2022.821697},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {821697},
  shortjournal = {Front. Artif. Intell.},
  title        = {Semantic representations for NLP using VerbNet and the generative lexicon},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scaling and disagreements: Bias, noise, and ambiguity.
<em>FRAI</em>, <em>5</em>, 818451. (<a
href="https://doi.org/10.3389/frai.2022.818451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourced data are often rife with disagreement, either because of genuine item ambiguity, overlapping labels, subjectivity, or annotator error. Hence, a variety of methods have been developed for learning from data containing disagreement. One of the observations emerging from this work is that different methods appear to work best depending on characteristics of the dataset such as the level of noise. In this paper, we investigate the use of an approach developed to estimate noise, temperature scaling, in learning from data containing disagreements. We find that temperature scaling works with data in which the disagreements are the result of label overlap, but not with data in which the disagreements are due to annotator bias, as in, e.g., subjective tasks such as labeling an item as offensive or not. We also find that disagreements due to ambiguity do not fit perfectly either category.},
  archive      = {J_FRAI},
  author       = {Uma, Alexandra and Almanea, Dina and Poesio, Massimo},
  doi          = {10.3389/frai.2022.818451},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {818451},
  shortjournal = {Front. Artif. Intell.},
  title        = {Scaling and disagreements: Bias, noise, and ambiguity},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using facial landmark detection on thermal images as a novel
prognostic tool for emergency departments. <em>FRAI</em>, <em>5</em>,
815333. (<a href="https://doi.org/10.3389/frai.2022.815333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionEmergency departments (ED) at hospitals sometimes experience unexpected deterioration in patients that were assessed to be in a stable condition upon arrival. Odense University Hospital (OUH) has conducted a retrospective study to investigate the possibilities of prognostic tools that can detect these unexpected deterioration cases at an earlier stage. The study suggests that the temperature difference (gradient) between the core and the peripheral body parts can be used to detect these cases. The temperature between the patient&#39;s inner canthus (core temperature) and the tip of the nose (peripheral temperature) can be measured with a thermal camera. Based on the temperature measurement from a thermal image, a gradient value can be calculated, which can be used as an early indicator of potential deterioration.ProblemThe lack of a tool to automatically calculate the gradient has prevented the ED at OUH in conducting a comprehensive prospective study on early indicators of patients at risk of deterioration. The current manual way of doing facial landmark detection on thermal images is too time consuming and not feasible as part of the daily workflow at the ED, where nurses have to triage patients within a few minutes.ObjectiveThe objective of this study was to automate the process of calculating the gradient by developing a handheld prognostic tool that can be used by nurses for automatically performing facial landmark detection on thermal images of patients as they arrive at the ED.MethodsA systematic literature review has been conducted to investigate previous studies that have been done for applying computer vision methods on thermal images. Several meetings, interviews and field studies have been conducted with the ED at OUH in order to understand their workflow, formulate and prioritize requirements and co-design the prognostic tool.ResultsThe study resulted in a novel Android app that can capture a thermal image of a patient&#39;s face with a thermal camera attached to a smartphone. Within a few seconds, the app then automatically calculates the gradient to be used in the triage process. The developed tool is the first of its kind using facial landmark detection on thermal images for calculating a gradient that can serve as a novel prognostic indicator for ED patients.},
  archive      = {J_FRAI},
  author       = {Baskaran, Ruben and Møller, Karim and Wiil, Uffe Kock and Brabrand, Mikkel},
  doi          = {10.3389/frai.2022.815333},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {815333},
  shortjournal = {Front. Artif. Intell.},
  title        = {Using facial landmark detection on thermal images as a novel prognostic tool for emergency departments},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ontology-based chatbot to enhance experiential learning
in a cultural heritage scenario. <em>FRAI</em>, <em>5</em>, 808281. (<a
href="https://doi.org/10.3389/frai.2022.808281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Italy is rich in cultural attractions, many known worldwide, others more hidden and unrecognized. Cultural attractions include tangible cultural assets (works of art, archaeological excavations, and churches) and intangible ones (music, poetry, and art). Today, given the pervasive diffusion of “smart” devices, the intelligent use of modern technologies could play a crucial role in changing the habit of consulting and visiting cultural heritage mainly with traditional methodologies, making little or no use of the advantages coming from the more and more availability of digitalized resources. A realm of particular interest is “experiential learning” when applied to cultural heritage, where tourists more and more ask to be helped in discovering the richness of sites they explore. In this article, we will present an innovative chatbot-based system, called HeriBot, that supports experiential tourism. Our system has been developed and experimented with a research effort for applying ICT technologies to enhance the knowledge, valorization, and sustainable fruition of the Cultural Heritage related to the Archaeological Urban Park of Naples (PAUN—Parco Archeologico Urbano di Napoli). Our article starts exploiting the ontological approach based on a purpose ontology describing the Park Heritage. Using such an ontology, we designed a chatbot that can identify the specific characteristics and motivations of the tourist, defining language, tone, and visitable scenarios and, through the ontology, allows the visit to be transformed into a personalized educational opportunity. The system has been validated in terms of dialogue effectiveness and training efficiency by a panel of experts, and we present and discuss obtained results.},
  archive      = {J_FRAI},
  author       = {Casillo, Mario and De Santo, Massimo and Mosca, Rosalba and Santaniello, Domenico},
  doi          = {10.3389/frai.2022.808281},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {808281},
  shortjournal = {Front. Artif. Intell.},
  title        = {An ontology-based chatbot to enhance experiential learning in a cultural heritage scenario},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A model of unified perception and cognition. <em>FRAI</em>,
<em>5</em>, 806403. (<a
href="https://doi.org/10.3389/frai.2022.806403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses an approach to add perception functionality to a general-purpose intelligent system, NARS. Differently from other AI approaches toward perception, our design is based on the following major opinions: (1) Perception primarily depends on the perceiver, and subjective experience is only partially and gradually transformed into objective (intersubjective) descriptions of the environment; (2) Perception is basically a process initiated by the perceiver itself to achieve its goals, and passive receiving of signals only plays a supplementary role; (3) Perception is fundamentally unified with cognition, and the difference between them is mostly quantitative, not qualitative. The directly relevant aspects of NARS are described to show the implications of these opinions in system design, and they are compared with the other approaches. Based on the research results of cognitive science, it is argued that the Narsian approach better fits the need of perception in Artificial General Intelligence (AGI).},
  archive      = {J_FRAI},
  author       = {Wang, Pei and Hahm, Christian and Hammer, Patrick},
  doi          = {10.3389/frai.2022.806403},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {806403},
  shortjournal = {Front. Artif. Intell.},
  title        = {A model of unified perception and cognition},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intention recognition with ProbLog. <em>FRAI</em>,
<em>5</em>, 806262. (<a
href="https://doi.org/10.3389/frai.2022.806262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many scenarios where robots or autonomous systems may be deployed, the capacity to infer and reason about the intentions of other agents can improve the performance or utility of the system. For example, a smart home or assisted living facility is better able to select assistive services to deploy if it understands the goals of the occupants in advance. In this article, we present a framework for reasoning about intentions using probabilistic logic programming. We employ ProbLog, a probabilistic extension to Prolog, to infer the most probable intention given observations of the actions of the agent and sensor readings of important aspects of the environment. We evaluated our model on a domain modeling a smart home. The model achieved 0.75 accuracy at full observability. The model was robust to reduced observability.},
  archive      = {J_FRAI},
  author       = {Smith, Gary B. and Belle, Vaishak and Petrick, Ronald P. A.},
  doi          = {10.3389/frai.2022.806262},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {806262},
  shortjournal = {Front. Artif. Intell.},
  title        = {Intention recognition with ProbLog},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The issue of proxies and choice architectures. Why EU law
matters for recommender systems. <em>FRAI</em>, <em>5</em>, 789076. (<a
href="https://doi.org/10.3389/frai.2022.789076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendations are meant to increase sales or ad revenue, as these are the first priority of those who pay for them. As recommender systems match their recommendations with inferred preferences, we should not be surprised if the algorithm optimizes for lucrative preferences and thus co-produces the preferences they mine. This relates to the well-known problems of feedback loops, filter bubbles, and echo chambers. In this article, I discuss the implications of the fact that computing systems necessarily work with proxies when inferring recommendations and raise a number of questions about whether recommender systems actually do what they are claimed to do, while also analysing the often-perverse economic incentive structures that have a major impact on relevant design decisions. Finally, I will explain how the choice architectures for data controllers and providers of AI systems as foreseen in the EU&#39;s General Data Protection Regulation (GDPR), the proposed EU Digital Services Act (DSA) and the proposed EU AI Act will help to break through various vicious circles, by constraining how people may be targeted (GDPR, DSA) and by requiring documented evidence of the robustness, resilience, reliability, and the responsible design and deployment of high-risk recommender systems (AI Act).},
  archive      = {J_FRAI},
  author       = {Hildebrandt, Mireille},
  doi          = {10.3389/frai.2022.789076},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {789076},
  shortjournal = {Front. Artif. Intell.},
  title        = {The issue of proxies and choice architectures. why EU law matters for recommender systems},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Theory of mind and preference learning at the interface of
cognitive science, neuroscience, and AI: A review. <em>FRAI</em>,
<em>5</em>, 778852. (<a
href="https://doi.org/10.3389/frai.2022.778852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theory of Mind (ToM)—the ability of the human mind to attribute mental states to others—is a key component of human cognition. In order to understand other people&#39;s mental states or viewpoint and to have successful interactions with others within social and occupational environments, this form of social cognition is essential. The same capability of inferring human mental states is a prerequisite for artificial intelligence (AI) to be integrated into society, for example in healthcare and the motoring industry. Autonomous cars will need to be able to infer the mental states of human drivers and pedestrians to predict their behavior. In the literature, there has been an increasing understanding of ToM, specifically with increasing cognitive science studies in children and in individuals with Autism Spectrum Disorder. Similarly, with neuroimaging studies there is now a better understanding of the neural mechanisms that underlie ToM. In addition, new AI algorithms for inferring human mental states have been proposed with more complex applications and better generalisability. In this review, we synthesize the existing understanding of ToM in cognitive and neurosciences and the AI computational models that have been proposed. We focus on preference learning as an area of particular interest and the most recent neurocognitive and computational ToM models. We also discuss the limitations of existing models and hint at potential approaches to allow ToM models to fully express the complexity of the human mind in all its aspects, including values and preferences.},
  archive      = {J_FRAI},
  author       = {Langley, Christelle and Cirstea, Bogdan Ionut and Cuzzolin, Fabio and Sahakian, Barbara J.},
  doi          = {10.3389/frai.2022.778852},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {778852},
  shortjournal = {Front. Artif. Intell.},
  title        = {Theory of mind and preference learning at the interface of cognitive science, neuroscience, and AI: A review},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An extended UTAUT model to explain factors affecting online
learning system amidst COVID-19 pandemic: The case of a developing
economy. <em>FRAI</em>, <em>5</em>, 768831. (<a
href="https://doi.org/10.3389/frai.2022.768831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From a developing country perspective, this study explains the factors affecting online learning amidst the COVID-19 pandemic. The paper empirically tests the proposed extended unified theory of acceptance and use of technology (e-UTAUT) model in the students&#39; intention and use behavior toward the online learning system. Understanding the acceptance of online learning technology is crucial, especially among developing countries caught off-guard by the abrupt transition of face-to-face classes to pure online learning. The enjoyment, interactivity, flexibility, and quality of online learning systems were added as antecedent variables to the UTAUT model. Eight hundred eighty valid responses from selected college students in the Visayas regions, Philippines, were collected. Structural equation modeling (SEM) was employed to verify the research hypotheses. The results supported the proposed model with acceptable fit measures and substantial explanatory power. The extended constructs provide different views on online learning based on the significant cluster of antecedents to explain technology acceptance through behavioral intentions and actual system usage. The paper implies that despite the challenges of connectivity in developing countries, the variations still conform with emerging literature about the topic. Insights for higher education institutions and policy directions are recommended.},
  archive      = {J_FRAI},
  author       = {Batucan, Gesselle B. and Gonzales, Gamaliel G. and Balbuena, Merly G. and Pasaol, Kyla Rose B. and Seno, Darlyn N. and Gonzales, Roselyn R.},
  doi          = {10.3389/frai.2022.768831},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {768831},
  shortjournal = {Front. Artif. Intell.},
  title        = {An extended UTAUT model to explain factors affecting online learning system amidst COVID-19 pandemic: The case of a developing economy},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Location and language independent fake rumor detection
through epidemiological and structural graph analysis of social
connections. <em>FRAI</em>, <em>5</em>, 734347. (<a
href="https://doi.org/10.3389/frai.2022.734347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection and identification of misinformation and fake news is a complex problem that intersects several disciplines, ranging from sociology to computer science and mathematics. In this work, we focus on social media analyzing characteristics that are independent of the text language (language-independent) and social context (location-independent) and common to most social media, not only Twitter as mostly analyzed in the literature. Specifically, we analyze temporal and structural characteristics of information flow in the social networks and we evaluate the importance and effect of two different types of features in the detection process of fake rumors. Specifically, we extract epidemiological features exploiting epidemiological models for spreading false rumors; furthermore, we extract graph-based features from the graph structure of the information cascade of the social graph. Using these features, we evaluate them for fake rumor detection with 3 configurations: (i) using only epidemiological features, (ii) using only graph-based features, and (iii) using the combination of epidemiological and graph-based features. Evaluation is performed with a Gradient Boosting classifier on two benchmark fake rumor detection datasets. Our results demonstrate that epidemiological models fit rumor propagation well, while graph-based features lead to more effective classification of rumors; the combination of epidemiological and graph-based features leads to improved performance.},
  archive      = {J_FRAI},
  author       = {Serpanos, Dimitrios and Xenos, Georgios and Tsouvalas, Billy},
  doi          = {10.3389/frai.2022.734347},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {734347},
  shortjournal = {Front. Artif. Intell.},
  title        = {Location and language independent fake rumor detection through epidemiological and structural graph analysis of social connections},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How the brain dynamically constructs sentence-level meanings
from word-level features. <em>FRAI</em>, <em>5</em>, 733163. (<a
href="https://doi.org/10.3389/frai.2022.733163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How are words connected to the thoughts they help to express? Recent brain imaging studies suggest that word representations are embodied in different neural systems through which the words are experienced. Building on this idea, embodied approaches such as the Concept Attribute Representations (CAR) theory represents concepts as a set of semantic features (attributes) mapped to different brain systems. An intriguing challenge to this theory is that people weigh concept attributes differently based on context, i.e., they construct meaning dynamically according to the combination of concepts that occur in the sentence. This research addresses this challenge through the Context-dEpendent meaning REpresentations in the BRAin (CEREBRA) neural network model. Based on changes in the brain images, CEREBRA quantifies the effect of sentence context on word meanings. Computational experiments demonstrated that words in different contexts have different representations, the changes observed in the concept attributes reveal unique conceptual combinations, and that the new representations are more similar to the other words in the sentence than to the original representations. Behavioral analysis further confirmed that the changes produced by CEREBRA are actionable knowledge that can be used to predict human responses. These experiments constitute a comprehensive evaluation of CEREBRA&#39;s context-based representations, showing that CARs can be dynamic and change based on context. Thus, CEREBRA is a useful tool for understanding how word meanings are represented in the brain, providing a framework for future interdisciplinary research on the mental lexicon.},
  archive      = {J_FRAI},
  author       = {Aguirre-Celis, Nora and Miikkulainen, Risto},
  doi          = {10.3389/frai.2022.733163},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {733163},
  shortjournal = {Front. Artif. Intell.},
  title        = {How the brain dynamically constructs sentence-level meanings from word-level features},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adaptation using convolutional autoencoder and
gradient boosting for adverse events prediction in the intensive care
unit. <em>FRAI</em>, <em>5</em>, 640926. (<a
href="https://doi.org/10.3389/frai.2022.640926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than 5 million patients have admitted annually to intensive care units (ICUs) in the United States. The leading causes of mortality are cardiovascular failures, multi-organ failures, and sepsis. Data-driven techniques have been used in the analysis of patient data to predict adverse events, such as ICU mortality and ICU readmission. These models often make use of temporal or static features from a single ICU database to make predictions on subsequent adverse events. To explore the potential of domain adaptation, we propose a method of data analysis using gradient boosting and convolutional autoencoder (CAE) to predict significant adverse events in the ICU, such as ICU mortality and ICU readmission. We demonstrate our results from a retrospective data analysis using patient records from a publicly available database called Multi-parameter Intelligent Monitoring in Intensive Care-II (MIMIC-II) and a local database from Children&#39;s Healthcare of Atlanta (CHOA). We demonstrate that after adopting novel data imputation on patient ICU data, gradient boosting is effective in both the mortality prediction task and the ICU readmission prediction task. In addition, we use gradient boosting to identify top-ranking temporal and non-temporal features in both prediction tasks. We discuss the relationship between these features and the specific prediction task. Lastly, we indicate that CAE might not be effective in feature extraction on one dataset, but domain adaptation with CAE feature extraction across two datasets shows promising results.},
  archive      = {J_FRAI},
  author       = {Zhu, Yuanda and Venugopalan, Janani and Zhang, Zhenyu and Chanani, Nikhil K. and Maher, Kevin O. and Wang, May D.},
  doi          = {10.3389/frai.2022.640926},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {4},
  pages        = {640926},
  shortjournal = {Front. Artif. Intell.},
  title        = {Domain adaptation using convolutional autoencoder and gradient boosting for adverse events prediction in the intensive care unit},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Advances in goal, plan and activity recognition.
<em>FRAI</em>, <em>5</em>, 861669. (<a
href="https://doi.org/10.3389/frai.2022.861669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Vered, Mor and Mirsky, Reuth and Fraga Pereira, Ramon and Meneguzzi, Felipe},
  doi          = {10.3389/frai.2022.861669},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {861669},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Advances in goal, plan and activity recognition},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward a knowledge-based system for african traditional
herbal medicine: A design science research approach. <em>FRAI</em>,
<em>5</em>, 856705. (<a
href="https://doi.org/10.3389/frai.2022.856705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article illustrates a design approach for capturing, storing, indexing, and search of African traditional herbal medicine (ATHMed) framed on a hybrid-based knowledge model for efficient preservation and retrieval. By the hybrid approach, the framework was developed to include both the use of machine learning and ontology-based techniques. The search pattern considers ontology design and machine learning techniques for extracting ATHMed data. The framework operates on a semantically annotated corpus and delivers a contextual and multi-word search pattern against its knowledge base. In line with design science research, preliminary data were collected in this study, and a proposed strategy was developed toward processing, storing and retrieving data. While reviewing literature and interview data to reflect on the existing challenges, these findings suggest the need for a system with the capability of retrieving and archiving ATHMed in Ghana. This study contributes to SDG 3 by providing a model and conceptualizing the implementation of ATHMed. We, therefore, envision that the framework will be adopted by relevant stakeholders for the implementation of efficient systems for archival and retrieval of ATHMed.},
  archive      = {J_FRAI},
  author       = {Devine, Samuel Nii Odoi and Kolog, Emmanuel Awuni and Atinga, Roger},
  doi          = {10.3389/frai.2022.856705},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {856705},
  shortjournal = {Front. Artif. Intell.},
  title        = {Toward a knowledge-based system for african traditional herbal medicine: A design science research approach},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepSpectrumLite: A power-efficient transfer learning
framework for embedded speech and audio processing from decentralized
data. <em>FRAI</em>, <em>5</em>, 856232. (<a
href="https://doi.org/10.3389/frai.2022.856232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural speech and audio processing systems have a large number of trainable parameters, a relatively complex architecture, and require a vast amount of training data and computational power. These constraints make it more challenging to integrate such systems into embedded devices and utilize them for real-time, real-world applications. We tackle these limitations by introducing DeepSpectrumLite, an open-source, lightweight transfer learning framework for on-device speech and audio recognition using pre-trained image Convolutional Neural Networks (CNNs). The framework creates and augments Mel spectrogram plots on the fly from raw audio signals which are then used to finetune specific pre-trained CNNs for the target classification task. Subsequently, the whole pipeline can be run in real-time with a mean inference lag of 242.0 ms when a DenseNet121 model is used on a consumer-grade Motorola moto e7 plus smartphone. DeepSpectrumLite operates decentralized, eliminating the need for data upload for further processing. We demonstrate the suitability of the proposed transfer learning approach for embedded audio signal processing by obtaining state-of-the-art results on a set of paralinguistic and general audio tasks, including speech and music emotion recognition, social signal processing, COVID-19 cough and COVID-19 speech analysis, and snore sound classification. We provide an extensive command-line interface for users and developers which is comprehensively documented and publicly available at https://github.com/DeepSpectrum/DeepSpectrumLite.},
  archive      = {J_FRAI},
  author       = {Amiriparian, Shahin and Hübner, Tobias and Karas, Vincent and Gerczuk, Maurice and Ottl, Sandra and Schuller, Björn W.},
  doi          = {10.3389/frai.2022.856232},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {856232},
  shortjournal = {Front. Artif. Intell.},
  title        = {DeepSpectrumLite: A power-efficient transfer learning framework for embedded speech and audio processing from decentralized data},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised quark/gluon jet tagging with poissonian mixture
models. <em>FRAI</em>, <em>5</em>, 852970. (<a
href="https://doi.org/10.3389/frai.2022.852970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of jets induced by quarks or gluons is important for New Physics searches at high-energy colliders. However, available taggers usually rely on modeling the data through Monte Carlo simulations, which could veil intractable theoretical and systematical uncertainties. To significantly reduce biases, we propose an unsupervised learning algorithm that, given a sample of jets, can learn the SoftDrop Poissonian rates for quark- and gluon-initiated jets and their fractions. We extract the Maximum Likelihood Estimates for the mixture parameters and the posterior probability over them. We then construct a quark-gluon tagger and estimate its accuracy in actual data to be in the 0.65–0.7 range, below supervised algorithms but nevertheless competitive. We also show how relevant unsupervised metrics perform well, allowing for an unsupervised hyperparameter selection. Further, we find that this result is not affected by an angular smearing introduced to simulate detector effects for central jets. The presented unsupervised learning algorithm is simple; its result is interpretable and depends on very few assumptions.},
  archive      = {J_FRAI},
  author       = {Alvarez, E. and Spannowsky, M. and Szewc, M.},
  doi          = {10.3389/frai.2022.852970},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {852970},
  shortjournal = {Front. Artif. Intell.},
  title        = {Unsupervised Quark/Gluon jet tagging with poissonian mixture models},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating successful internal mobility: A comparison
between structural equation models and machine learning algorithms.
<em>FRAI</em>, <em>5</em>, 848015. (<a
href="https://doi.org/10.3389/frai.2022.848015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internal mobility often depends on predicting future job satisfaction, for such employees subject to internal mobility programs. In this study, we compared the predictive power of different classes of models, i.e., (i) traditional Structural Equation Modeling (SEM), with two families of Machine Learning algorithms: (ii) regressors, specifically least absolute shrinkage and selection operator (Lasso) for feature selection and (iii) classifiers, specifically Bagging meta-model with the k-nearest neighbors algorithm (k-NN) as a base estimator. Our aim is to investigate which method better predicts job satisfaction for 348 employees (with operational duties) and 35 supervisors in the training set, and 79 employees in the test set, all subject to internal mobility programs in a large Italian banking group. Results showed average predictive power for SEM and Bagging k-NN (accuracy between 61 and 66%; F1 scores between 0.51 and 0.73). Both SEM and Lasso algorithms highlighted the predictive power of resistance to change and orientation to relation in all models, together with other personality and motivation variables in different models. Theoretical implications are discussed for using these variables in predicting successful job relocation in internal mobility programs. Moreover, these results showed how crucial it is to compare methods coming from different research traditions in predictive Human Resources analytics.},
  archive      = {J_FRAI},
  author       = {Bossi, Francesco and Di Gruttola, Francesco and Mastrogiorgio, Antonio and D&#39;Arcangelo, Sonia and Lattanzi, Nicola and Malizia, Andrea P. and Ricciardi, Emiliano},
  doi          = {10.3389/frai.2022.848015},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {848015},
  shortjournal = {Front. Artif. Intell.},
  title        = {Estimating successful internal mobility: A comparison between structural equation models and machine learning algorithms},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotion analysis of arabic tweets: Language models and
available resources. <em>FRAI</em>, <em>5</em>, 843038. (<a
href="https://doi.org/10.3389/frai.2022.843038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most popular social media platforms is Twitter. Emotion analysis and classification of tweets have become a significant research topic recently. The Arabic language faces challenges for emotion classification on Twitter, requiring more preprocessing than other languages. This article provides a practical overview and detailed description of a material that can help in developing an Arabic language model for emotion classification of Arabic tweets. An emotion classification of Arabic tweets using NLP, overall current practical practices, and available resources are highlighted to provide a guideline and overview sight to facilitate future studies. Finally, the article presents some challenges and issues that can be future research directions.},
  archive      = {J_FRAI},
  author       = {Alqahtani, Ghadah and Alothaim, Abdulrahman},
  doi          = {10.3389/frai.2022.843038},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {843038},
  shortjournal = {Front. Artif. Intell.},
  title        = {Emotion analysis of arabic tweets: Language models and available resources},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Backchannel behavior influences the perceived personality of
human and artificial communication partners. <em>FRAI</em>, <em>5</em>,
835298. (<a href="https://doi.org/10.3389/frai.2022.835298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different applications or contexts may require different settings for a conversational AI system, as it is clear that e.g., a child-oriented system would need a different interaction style than a warning system used in emergency situations. The current article focuses on the extent to which a system&#39;s usability may benefit from variation in the personality it displays. To this end, we investigate whether variation in personality is signaled by differences in specific audiovisual feedback behavior, with a specific focus on embodied conversational agents. This article reports about two rating experiments in which participants judged the personalities (i) of human beings and (ii) of embodied conversational agents, where we were specifically interested in the role of variability in audiovisual cues. Our results show that personality perceptions of both humans and artificial communication partners are indeed influenced by the type of feedback behavior used. This knowledge could inform developers of conversational AI on how to also include personality in their feedback behavior generation algorithms, which could enhance the perceived personality and in turn generate a stronger sense of presence for the human interlocutor.},
  archive      = {J_FRAI},
  author       = {Blomsma, Peter and Skantze, Gabriel and Swerts, Marc},
  doi          = {10.3389/frai.2022.835298},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {835298},
  shortjournal = {Front. Artif. Intell.},
  title        = {Backchannel behavior influences the perceived personality of human and artificial communication partners},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3Es for AI: Economics, explanation, epistemology.
<em>FRAI</em>, <em>5</em>, 833238. (<a
href="https://doi.org/10.3389/frai.2022.833238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article locates its roots/routes in multiple disciplinary formations and it seeks to advance critical thinking about an aspect of our contemporary socio-technical challenges by bracketing three knowledge formations—artificial intelligence (AI), economics, and epistemology—that have not often been considered together. In doing so, it responds to the growing calls for the necessity of further transdisciplinary engagements that have emanated from work in AI and also from other disciplines. The structure of the argument here is as follows. First, I begin by demonstrating how and why explanation is a problem in AI (“XAI problem”) and what directions are being taken by recent research that draws upon social sciences to address this, noting how there is a conspicuous lack of reference in this literature to economics. Second, I identify and analyze a problem of explanation that has long plagued economics too as a discipline. I show how only a few economists have ever attempted to grapple with this problem and provide their perspectives. Third, I provide an original genealogy of explanation in economics, demonstrating the changing nature of what was meant by an explanation. These systematic changes in consensual understanding of what occurs when something is said to have been “explained”, have reflected the methodological compromises that were rendered necessary to serve different epistemological tensions over time. Lastly, I identify the various relevant historical and conceptual overlaps between economics and AI. I conclude by suggesting that we must pay greater attention to the epistemologies underpinning socio-technical knowledges about the human. The problem of explanation in AI, like the problem of explanation in economics, is perhaps not only, or really, a problem of satisfactory explanation provision alone, but interwoven with questions of competing epistemological and ethical choices and related to the ways in which we choose sociotechnical arrangements and offer consent to be governed by them.},
  archive      = {J_FRAI},
  author       = {Kaul, Nitasha},
  doi          = {10.3389/frai.2022.833238},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {833238},
  shortjournal = {Front. Artif. Intell.},
  title        = {3Es for AI: Economics, explanation, epistemology},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fetal organ anomaly classification network for identifying
organ anomalies in fetal MRI. <em>FRAI</em>, <em>5</em>, 832485. (<a
href="https://doi.org/10.3389/frai.2022.832485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid development in Magnetic Resonance Imaging (MRI) has played a key role in prenatal diagnosis over the last few years. Deep learning (DL) architectures can facilitate the process of anomaly detection and affected-organ classification, making diagnosis more accurate and observer-independent. We propose a novel DL image classification architecture, Fetal Organ Anomaly Classification Network (FOAC-Net), which uses squeeze-and-excitation (SE) and naïve inception (NI) modules to automatically identify anomalies in fetal organs. This architecture can identify normal fetal anatomy, as well as detect anomalies present in the (1) brain, (2) spinal cord, and (3) heart. In this retrospective study, we included fetal 3-dimensional (3D) SSFP sequences of 36 participants. We classified the images on a slice-by-slice basis. FOAC-Net achieved a classification accuracy of 85.06, 85.27, 89.29, and 82.20% when predicting brain anomalies, no anomalies (normal), spinal cord anomalies, and heart anomalies, respectively. In a comparison study, FOAC-Net outperformed other state-of-the-art classification architectures in terms of class-average F1 and accuracy. This work aims to develop a novel classification architecture identifying the affected organs in fetal MRI.},
  archive      = {J_FRAI},
  author       = {Lo, Justin and Lim, Adam and Wagner, Matthias W. and Ertl-Wagner, Birgit and Sussman, Dafna},
  doi          = {10.3389/frai.2022.832485},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {832485},
  shortjournal = {Front. Artif. Intell.},
  title        = {Fetal organ anomaly classification network for identifying organ anomalies in fetal MRI},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Addressing label sparsity with class-level common sense for
google maps. <em>FRAI</em>, <em>5</em>, 830299. (<a
href="https://doi.org/10.3389/frai.2022.830299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful knowledge graphs (KGs) solved the historical knowledge acquisition bottleneck by supplanting the previous expert focus with a simple, crowd-friendly one: KG nodes represent popular people, places, organizations, etc., and the graph arcs represent common sense relations like affiliations, locations, etc. Techniques for more general, categorical, KG curation do not seem to have made the same transition: the KG research community is still largely focused on logic-based methods that belie the common-sense characteristics of successful KGs. In this paper, we propose a simple yet novel three-tier crowd approach to acquiring class-level attributes that represent broad common sense associations between categories, and can be used with the classic knowledge-base default &amp;amp; override technique, to address the early label sparsity problem faced by machine learning systems for problems that lack data for training. We demonstrate the effectiveness of our acquisition and reasoning approach on a pair of very real industrial-scale problems: how to augment an existing KG of places and offerings (e.g. stores and products, restaurants and dishes) with associations between them indicating the availability of the offerings at those places. Label sparsity is a general problem, and not specific to these use cases, that prevents modern AI and machine learning techniques from applying to many applications for which labeled data is not readily available. As a result, the study of how to acquire the knowledge and data needed for AI to work is as much a problem today as it was in the 1970s and 80s during the advent of expert systems. Our approach was a critical part of enabling a worldwide local search capability on Google Maps, with which users can find products and dishes that are available in most places on earth.},
  archive      = {J_FRAI},
  author       = {Welty, Chris and Aroyo, Lora and Korn, Flip and McCarthy, Sara M. and Zhao, Shubin},
  doi          = {10.3389/frai.2022.830299},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {830299},
  shortjournal = {Front. Artif. Intell.},
  title        = {Addressing label sparsity with class-level common sense for google maps},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Behind the leaves: Estimation of occluded grapevine berries
with conditional generative adversarial networks. <em>FRAI</em>,
<em>5</em>, 830026. (<a
href="https://doi.org/10.3389/frai.2022.830026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for accurate yield estimates for viticulture is becoming more important due to increasing competition in the wine market worldwide. One of the most promising methods to estimate the harvest is berry counting, as it can be approached non-destructively, and its process can be automated. In this article, we present a method that addresses the challenge of occluded berries with leaves to obtain a more accurate estimate of the number of berries that will enable a better estimate of the harvest. We use generative adversarial networks, a deep learning-based approach that generates a highly probable scenario behind the leaves exploiting learned patterns from images with non-occluded berries. Our experiments show that the estimate of the number of berries after applying our method is closer to the manually counted reference. In contrast to applying a factor to the berry count, our approach better adapts to local conditions by directly involving the appearance of the visible berries. Furthermore, we show that our approach can identify which areas in the image should be changed by adding new berries without explicitly requiring information about hidden areas.},
  archive      = {J_FRAI},
  author       = {Kierdorf, Jana and Weber, Immanuel and Kicherer, Anna and Zabawa, Laura and Drees, Lukas and Roscher, Ribana},
  doi          = {10.3389/frai.2022.830026},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {830026},
  shortjournal = {Front. Artif. Intell.},
  title        = {Behind the leaves: Estimation of occluded grapevine berries with conditional generative adversarial networks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Is class-incremental enough for continual learning?
<em>FRAI</em>, <em>5</em>, 829842. (<a
href="https://doi.org/10.3389/frai.2022.829842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of a model to learn continually can be empirically assessed in different continual learning scenarios. Each scenario defines the constraints and the opportunities of the learning environment. Here, we challenge the current trend in the continual learning literature to experiment mainly on class-incremental scenarios, where classes present in one experience are never revisited. We posit that an excessive focus on this setting may be limiting for future research on continual learning, since class-incremental scenarios artificially exacerbate catastrophic forgetting, at the expense of other important objectives like forward transfer and computational efficiency. In many real-world environments, in fact, repetition of previously encountered concepts occurs naturally and contributes to softening the disruption of previous knowledge. We advocate for a more in-depth study of alternative continual learning scenarios, in which repetition is integrated by design in the stream of incoming information. Starting from already existing proposals, we describe the advantages such class-incremental with repetition scenarios could offer for a more comprehensive assessment of continual learning models.},
  archive      = {J_FRAI},
  author       = {Cossu, Andrea and Graffieti, Gabriele and Pellegrini, Lorenzo and Maltoni, Davide and Bacciu, Davide and Carta, Antonio and Lomonaco, Vincenzo},
  doi          = {10.3389/frai.2022.829842},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {829842},
  shortjournal = {Front. Artif. Intell.},
  title        = {Is class-incremental enough for continual learning?},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Review of multi-criteria decision-making methods in finance
using explainable artificial intelligence. <em>FRAI</em>, <em>5</em>,
827584. (<a href="https://doi.org/10.3389/frai.2022.827584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence of Artificial Intelligence is growing, as is the need to make it as explainable as possible. Explainability is one of the main obstacles that AI faces today on the way to more practical implementation. In practise, companies need to use models that balance interpretability and accuracy to make more effective decisions, especially in the field of finance. The main advantages of the multi-criteria decision-making principle (MCDM) in financial decision-making are the ability to structure complex evaluation tasks that allow for well-founded financial decisions, the application of quantitative and qualitative criteria in the analysis process, the possibility of transparency of evaluation and the introduction of improved, universal and practical academic methods to the financial decision-making process. This article presents a review and classification of multi-criteria decision-making methods that help to achieve the goal of forthcoming research: to create artificial intelligence-based methods that are explainable, transparent, and interpretable for most investment decision-makers.},
  archive      = {J_FRAI},
  author       = {Černevičienė, Jurgita and Kabašinskas, Audrius},
  doi          = {10.3389/frai.2022.827584},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {827584},
  shortjournal = {Front. Artif. Intell.},
  title        = {Review of multi-criteria decision-making methods in finance using explainable artificial intelligence},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction, knowledge, and explainability: Examining the use
of general value functions in machine knowledge. <em>FRAI</em>,
<em>5</em>, 826724. (<a
href="https://doi.org/10.3389/frai.2022.826724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within computational reinforcement learning, a growing body of work seeks to express an agent&#39;s knowledge of its world through large collections of predictions. While systems that encode predictions as General Value Functions (GVFs) have seen numerous developments in both theory and application, whether such approaches are explainable is unexplored. In this perspective piece, we explore GVFs as a form of explainable AI. To do so, we articulate a subjective agent-centric approach to explainability in sequential decision-making tasks. We propose that prior to explaining its decisions to others, an self-supervised agent must be able to introspectively explain decisions to itself. To clarify this point, we review prior applications of GVFs that involve human-agent collaboration. In doing so, we demonstrate that by making their subjective explanations public, predictive knowledge agents can improve the clarity of their operation in collaborative tasks.},
  archive      = {J_FRAI},
  author       = {Kearney, Alex and Günther, Johannes and Pilarski, Patrick M.},
  doi          = {10.3389/frai.2022.826724},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {826724},
  shortjournal = {Front. Artif. Intell.},
  title        = {Prediction, knowledge, and explainability: Examining the use of general value functions in machine knowledge},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Developing a cancer digital twin: Supervised metastases
detection from consecutive structured radiology reports. <em>FRAI</em>,
<em>5</em>, 826402. (<a
href="https://doi.org/10.3389/frai.2022.826402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of digital cancer twins relies on the capture of high-resolution representations of individual cancer patients throughout the course of their treatment. Our research aims to improve the detection of metastatic disease over time from structured radiology reports by exposing prediction models to historical information. We demonstrate that Natural language processing (NLP) can generate better weak labels for semi-supervised classification of computed tomography (CT) reports when it is exposed to consecutive reports through a patient&#39;s treatment history. Around 714,454 structured radiology reports from Memorial Sloan Kettering Cancer Center adhering to a standardized departmental structured template were used for model development with a subset of the reports included for validation. To develop the models, a subset of the reports was curated for ground-truth: 7,732 total reports in the lung metastases dataset from 867 individual patients; 2,777 reports in the liver metastases dataset from 315 patients; and 4,107 reports in the adrenal metastases dataset from 404 patients. We use NLP to extract and encode important features from the structured text reports, which are then used to develop, train, and validate models. Three models—a simple convolutional neural network (CNN), a CNN augmented with an attention layer, and a recurrent neural network (RNN)—were developed to classify the type of metastatic disease and validated against the ground truth labels. The models use features from consecutive structured text radiology reports of a patient to predict the presence of metastatic disease in the reports. A single-report model, previously developed to analyze one report instead of multiple past reports, is included and the results from all four models are compared based on accuracy, precision, recall, and F1-score. The best model is used to label all 714,454 reports to generate metastases maps. Our results suggest that NLP models can extract cancer progression patterns from multiple consecutive reports and predict the presence of metastatic disease in multiple organs with higher performance when compared with a single-report-based prediction. It demonstrates a promising automated approach to label large numbers of radiology reports without involving human experts in a time- and cost-effective manner and enables tracking of cancer progression over time.},
  archive      = {J_FRAI},
  author       = {Batch, Karen E. and Yue, Jianwei and Darcovich, Alex and Lupton, Kaelan and Liu, Corinne C. and Woodlock, David P. and El Amine, Mohammad Ali K. and Causa-Andrieu, Pamela I. and Gazit, Lior and Nguyen, Gary H. and Zulkernine, Farhana and Do, Richard K. G. and Simpson, Amber L.},
  doi          = {10.3389/frai.2022.826402},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {826402},
  shortjournal = {Front. Artif. Intell.},
  title        = {Developing a cancer digital twin: Supervised metastases detection from consecutive structured radiology reports},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shapley idioms: Analysing BERT sentence embeddings for
general idiom token identification. <em>FRAI</em>, <em>5</em>, 813967.
(<a href="https://doi.org/10.3389/frai.2022.813967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines the basis of Natural Language Understanding of transformer based language models, such as BERT. It does this through a case study on idiom token classification. We use idiom token identification as a basis for our analysis because of the variety of information types that have previously been explored in the literature for this task, including: topic, lexical, and syntactic features. This variety of relevant information types means that the task of idiom token identification enables us to explore the forms of linguistic information that a BERT language model captures and encodes in its representations. The core of this article presents three experiments. The first experiment analyzes the effectiveness of BERT sentence embeddings for creating a general idiom token identification model and the results indicate that the BERT sentence embeddings outperform Skip-Thought. In the second and third experiment we use the game theory concept of Shapley Values to rank the usefulness of individual idiomatic expressions for model training and use this ranking to analyse the type of information that the model finds useful. We find that a combination of idiom-intrinsic and topic-based properties contribute to an expression&#39;s usefulness in idiom token identification. Overall our results indicate that BERT efficiently encodes a variety of information from topic, through lexical and syntactic information. Based on these results we argue that notwithstanding recent criticisms of language model based semantics, the ability of BERT to efficiently encode a variety of linguistic information types does represent a significant step forward in natural language understanding.},
  archive      = {J_FRAI},
  author       = {Nedumpozhimana, Vasudevan and Klubička, Filip and Kelleher, John D.},
  doi          = {10.3389/frai.2022.813967},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {813967},
  shortjournal = {Front. Artif. Intell.},
  title        = {Shapley idioms: Analysing BERT sentence embeddings for general idiom token identification},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An overview of current solutions for privacy in the internet
of things. <em>FRAI</em>, <em>5</em>, 812732. (<a
href="https://doi.org/10.3389/frai.2022.812732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the Internet of Things (IoT) applications have been introduced into daily life, privacy issues have become significant concerns to users, network service providers, device producers, and related roles. This study provides a high-level introduction of current privacy-preserving solutions in IoT systems within the three phases of data collection, transmission, and storage. In these three phases, the following aspects were examined: (1). security protocols at the physical and data link layers; (2). network solutions; and (3). data storage and sharing approaches. Real-world implementations often involve more than one phase, and numerous technologies are combined to ensure privacy. Thus, an understanding of all phases and their technologies can be helpful for IoT research, design, development, and operation.},
  archive      = {J_FRAI},
  author       = {Yang, Guang},
  doi          = {10.3389/frai.2022.812732},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {812732},
  shortjournal = {Front. Artif. Intell.},
  title        = {An overview of current solutions for privacy in the internet of things},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Nonlinear noise cleaning in gravitational-wave detectors
with convolutional neural networks. <em>FRAI</em>, <em>5</em>, 811563.
(<a href="https://doi.org/10.3389/frai.2022.811563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the sub-60 Hz sensitivity of gravitational-wave (GW) detectors like Advanced LIGO (aLIGO) is limited by the control noises from auxiliary degrees of freedom which nonlinearly couple to the main GW readout. One promising way to tackle this challenge is to perform nonlinear noise mitigation using convolutional neural networks (CNNs), which we examine in detail in this study. In many cases, the noise coupling is bilinear and can be viewed as a few fast channels&#39; outputs modulated by some slow channels. We show that we can utilize this knowledge of the physical system and adopt an explicit “slow×fast” structure in the design of the CNN to enhance its performance of noise subtraction. We then examine the requirements in the signal-to-noise ratio (SNR) in both the target channel (i.e., the main GW readout) and in the auxiliary sensors in order to reduce the noise by at least a factor of a few. In the case of limited SNR in the target channel, we further demonstrate that the CNN can still reach a good performance if we use curriculum learning techniques, which in reality can be achieved by combining data from quiet times and those from periods with active noise injections.},
  archive      = {J_FRAI},
  author       = {Yu, Hang and Adhikari, Rana X.},
  doi          = {10.3389/frai.2022.811563},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {811563},
  shortjournal = {Front. Artif. Intell.},
  title        = {Nonlinear noise cleaning in gravitational-wave detectors with convolutional neural networks},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer across different machines by transfer function
estimation. <em>FRAI</em>, <em>5</em>, 811073. (<a
href="https://doi.org/10.3389/frai.2022.811073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A digital twin is a promising evolving tool for prognostic health monitoring. However, in rotating machinery, the transfer function between the rotating components and the sensor distorts the vibration signal, hence, complicating the ability to apply a digital twin to new systems. This paper demonstrates the importance of estimating the transfer function for a successful transfer across different machines (TDM). Furthermore, there are few algorithms in the literature for transfer function estimation. The current algorithms can estimate the magnitude of the transfer function without its original phase. In this study, a new approach is presented that enables the estimation of the transfer function with its phase for a gear signal. The performance of the new algorithm is demonstrated by measured signals and by a simulated transfer function.},
  archive      = {J_FRAI},
  author       = {Matania, Omri and Klein, Renata and Bortman, Jacob},
  doi          = {10.3389/frai.2022.811073},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {811073},
  shortjournal = {Front. Artif. Intell.},
  title        = {Transfer across different machines by transfer function estimation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Morphology in a parallel, distributed, interactive
architecture of language production. <em>FRAI</em>, <em>5</em>, 803259.
(<a href="https://doi.org/10.3389/frai.2022.803259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How do speakers produce novel words? This programmatic paper synthesizes research in linguistics and neuroscience to argue for a parallel distributed architecture of the language system, in which distributed semantic representations activate competing form chunks in parallel. This process accounts for both the synchronic phenomenon of paradigm uniformity and the diachronic process of paradigm leveling; i.e., the shaping or reshaping of relatively infrequent forms by semantically-related forms of higher frequency. However, it also raises the question of how leveling is avoided. A negative feedback cycle is argued to be responsible. The negative feedback cycle suppresses activated form chunks with unintended semantics or connotations and allows the speaker to decide when to begin speaking. The negative feedback cycle explains away much of the evidence for paradigmatic mappings, allowing more of the grammar to be described with only direct form-meaning mappings/constructions. However, there remains an important residue of cases for which paradigmatic mappings are necessary. I show that these cases can be accounted for by spreading activation down paradigmatic associations as the source of the activation is being inhibited by negative feedback. The negative feedback cycle provides a mechanistic explanation for several phenomena in language change that have so far eluded usage-based accounts. In particular, it provides a mechanism for degrammaticalization and affix liberation (e.g., the detachment of -holic from the context(s) in which it occurs), explaining how chunks can gain productivity despite occurring in a single fixed context. It also provides a novel perspective on paradigm gaps. Directions for future work are outlined.},
  archive      = {J_FRAI},
  author       = {Kapatsinski, Vsevolod},
  doi          = {10.3389/frai.2022.803259},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {803259},
  shortjournal = {Front. Artif. Intell.},
  title        = {Morphology in a parallel, distributed, interactive architecture of language production},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond the failure of direct-matching in keyword evaluation:
A sketch of a graph based solution. <em>FRAI</em>, <em>5</em>, 801564.
(<a href="https://doi.org/10.3389/frai.2022.801564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The starting point of this paper is the observation that methods based on the direct match of keywords are inadequate because they do not consider the cognitive ability of concept formation and abstraction. We argue that keyword evaluation needs to be based on a semantic model of language capturing the semantic relatedness of words to satisfy the claim of the human-like ability of concept formation and abstraction and achieve better evaluation results. Evaluation of keywords is difficult since semantic informedness is required for this purpose. This model must be capable of identifying semantic relationships such as synonymy, hypernymy, hyponymy, and location-based abstraction. For example, when gathering texts from online sources, one usually finds a few keywords with each text. Still, these keyword sets are neither complete for the text nor are they in themselves closed, i.e., in most cases, the keywords are a random subset of all possible keywords and not that informative w.r.t. the complete keyword set. Therefore all algorithms based on this cannot achieve good evaluation results and provide good/better keywords or even a complete keyword set for a text. As a solution, we propose a word graph that captures all these semantic relationships for a given language. The problem with the hyponym/hyperonym relationship is that, unlike synonyms, it is not bidirectional. Thus the space of keyword sets requires a metric that is non-symmetric, in other words, a quasi-metric. We sketch such a metric that works on our graph. Since it is nearly impossible to obtain such a complete word graph for a language, we propose for the keyword task a simpler graph based on the base text upon which the keyword sets should be evaluated. This reduction is usually sufficient for evaluating keyword sets.},
  archive      = {J_FRAI},
  author       = {Kölbl, Max and Kyogoku, Yuki and Philipp, J. Nathanael and Richter, Michael and Rietdorf, Clements and Yousef, Tariq},
  doi          = {10.3389/frai.2022.801564},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {801564},
  shortjournal = {Front. Artif. Intell.},
  title        = {Beyond the failure of direct-matching in keyword evaluation: A sketch of a graph based solution},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Utility of crowdsourced user experiments for measuring the
central tendency of user performance: A case of error-rate model
evaluation in a pointing task. <em>FRAI</em>, <em>5</em>, 798892. (<a
href="https://doi.org/10.3389/frai.2022.798892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of crowdsourcing to recruit numerous participants has been recognized as beneficial in the human-computer interaction (HCI) field, such as for designing user interfaces and validating user performance models. In this work, we investigate its effectiveness for evaluating an error-rate prediction model in target pointing tasks. In contrast to models for operational times, a clicking error (i.e., missing a target) occurs by chance at a certain probability, e.g., 5%. Therefore, in traditional laboratory-based experiments, a lot of repetitions are needed to measure the central tendency of error rates. We hypothesize that recruiting many workers would enable us to keep the number of repetitions per worker much smaller. We collected data from 384 workers and found that existing models on operational time and error rate showed good fits (both R2 &amp;gt; 0.95). A simulation where we changed the number of participants NP and the number of repetitions Nrepeat showed that the time prediction model was robust against small NP and Nrepeat, although the error-rate model fitness was considerably degraded. These findings empirically demonstrate a new utility of crowdsourced user experiments for collecting numerous participants, which should be of great use to HCI researchers for their evaluation studies.},
  archive      = {J_FRAI},
  author       = {Yamanaka, Shota},
  doi          = {10.3389/frai.2022.798892},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {798892},
  shortjournal = {Front. Artif. Intell.},
  title        = {Utility of crowdsourced user experiments for measuring the central tendency of user performance: A case of error-rate model evaluation in a pointing task},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A machine learning approach to personalize computerized
cognitive training interventions. <em>FRAI</em>, <em>5</em>, 788605. (<a
href="https://doi.org/10.3389/frai.2022.788605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Executive functions are a class of cognitive processes critical for purposeful goal-directed behavior. Cognitive training is the adequate stimulation of executive functions and has been extensively studied and applied for more than 20 years. However, there is still a lack of solid consensus in the scientific community about its potential to elicit consistent improvements in untrained domains. Individual differences are considered one of the most important factors of inconsistent reports on cognitive training benefits, as differences in cognitive functioning are both genetic and context-dependent, and might be affected by age and socioeconomic status. We here present a proof of concept based on the hypothesis that baseline individual differences among subjects would provide valuable information to predict the individual effectiveness of a cognitive training intervention. With a dataset from an investigation in which 73 6-year-olds trained their executive functions using an online software with a fixed protocol, freely available at www.matemarote.org.ar, we trained a support vector classifier that successfully predicted (average accuracy = 0.67, AUC = 0.707) whether a child would improve, or not, after the cognitive stimulation, using baseline individual differences as features. We also performed a permutation feature importance analysis that suggested that all features contribute equally to the model&#39;s performance. In the long term, this results might allow us to design better training strategies for those players who are less likely to benefit from the current training protocols in order to maximize the stimulation for each child.},
  archive      = {J_FRAI},
  author       = {Vladisauskas, Melina and Belloli, Laouen M. L. and Fernández Slezak, Diego and Goldin, Andrea P.},
  doi          = {10.3389/frai.2022.788605},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {788605},
  shortjournal = {Front. Artif. Intell.},
  title        = {A machine learning approach to personalize computerized cognitive training interventions},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparison of structural parsers and neural language models
as surprisal estimators. <em>FRAI</em>, <em>5</em>, 777963. (<a
href="https://doi.org/10.3389/frai.2022.777963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expectation-based theories of sentence processing posit that processing difficulty is determined by predictability in context. While predictability quantified via surprisal has gained empirical support, this representation-agnostic measure leaves open the question of how to best approximate the human comprehender&#39;s latent probability model. This article first describes an incremental left-corner parser that incorporates information about common linguistic abstractions such as syntactic categories, predicate-argument structure, and morphological rules as a computational-level model of sentence processing. The article then evaluates a variety of structural parsers and deep neural language models as cognitive models of sentence processing by comparing the predictive power of their surprisal estimates on self-paced reading, eye-tracking, and fMRI data collected during real-time language processing. The results show that surprisal estimates from the proposed left-corner processing model deliver comparable and often superior fits to self-paced reading and eye-tracking data when compared to those from neural language models trained on much more data. This may suggest that the strong linguistic generalizations made by the proposed processing model may help predict humanlike processing costs that manifest in latency-based measures, even when the amount of training data is limited. Additionally, experiments using Transformer-based language models sharing the same primary architecture and training data show a surprising negative correlation between parameter count and fit to self-paced reading and eye-tracking data. These findings suggest that large-scale neural language models are making weaker generalizations based on patterns of lexical items rather than stronger, more humanlike generalizations based on linguistic structure.},
  archive      = {J_FRAI},
  author       = {Oh, Byung-Doh and Clark, Christian and Schuler, William},
  doi          = {10.3389/frai.2022.777963},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {777963},
  shortjournal = {Front. Artif. Intell.},
  title        = {Comparison of structural parsers and neural language models as surprisal estimators},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collocations in parsing and translation. <em>FRAI</em>,
<em>5</em>, 765695. (<a
href="https://doi.org/10.3389/frai.2022.765695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper identification of collocations (and more generally of multiword expressions (MWEs), is an important qualitative step for several NLP applications and particularly so for translation. Since many MWEs cannot be translated literally, failure to identify them yields at best inaccurate translation. This paper is mostly be concerned with collocations. We will show how they differ from other types of MWEs and how they can be successfully parsed and translated by means of a grammar-based parser and translator.},
  archive      = {J_FRAI},
  author       = {Wehrli, Eric},
  doi          = {10.3389/frai.2022.765695},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {765695},
  shortjournal = {Front. Artif. Intell.},
  title        = {Collocations in parsing and translation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Declarative learning-based programming as an interface to AI
systems. <em>FRAI</em>, <em>5</em>, 755361. (<a
href="https://doi.org/10.3389/frai.2022.755361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven approaches are becoming increasingly common as problem-solving tools in many areas of science and technology. In most cases, machine learning models are the key component of these solutions. Often, a solution involves multiple learning models, along with significant levels of reasoning with the models&#39; output and input. However, the current tools are cumbersome not only for domain experts who are not fluent in machine learning but also for machine learning experts who evaluate new algorithms and models on real-world data and develop AI systems. We review key efforts made by various AI communities in providing languages for high-level abstractions over learning and reasoning techniques needed for designing complex AI systems. We classify the existing frameworks based on the type of techniques and their data and knowledge representations, compare the ways the current tools address the challenges of programming real-world applications and highlight some shortcomings and future directions. Our comparison is only qualitative and not experimental since the performance of the systems is not a factor in our study.},
  archive      = {J_FRAI},
  author       = {Kordjamshidi, Parisa and Roth, Dan and Kersting, Kristian},
  doi          = {10.3389/frai.2022.755361},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {755361},
  shortjournal = {Front. Artif. Intell.},
  title        = {Declarative learning-based programming as an interface to AI systems},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Critical analysis of deconfounded pretraining to improve
visio-linguistic models. <em>FRAI</em>, <em>5</em>, 736791. (<a
href="https://doi.org/10.3389/frai.2022.736791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important problem with many current visio-linguistic models is that they often depend on spurious correlations. A typical example of a spurious correlation between two variables is one that is due to a third variable causing both (a “confounder”). Recent work has addressed this by adjusting for spurious correlations using a technique of deconfounding with automatically found confounders. We will refer to this technique as AutoDeconfounding. This article dives more deeply into AutoDeconfounding, and surfaces a number of issues of the original technique. First, we evaluate whether its implementation is actually equivalent to deconfounding. We provide an explicit explanation of the relation between AutoDeconfounding and the underlying causal model on which it implicitly operates, and show that additional assumptions are needed before the implementation of AutoDeconfounding can be equated to correct deconfounding. Inspired by this result, we perform ablation studies to verify to what extent the improvement on downstream visio-linguistic tasks reported by the works that implement AutoDeconfounding is due to AutoDeconfounding, and to what extent it is specifically due to the deconfounding aspect of AutoDeconfounding. We evaluate AutoDeconfounding in a way that isolates its effect, and no longer see the same improvement. We also show that tweaking AutoDeconfounding to be less related to deconfounding does not negatively affect performance on downstream visio-linguistic tasks. Furthermore, we create a human-labeled ground truth causality dataset for objects in a scene to empirically verify whether and how well confounders are found. We show that some models do indeed find more confounders than a random baseline, but also that finding more confounders is not correlated with performing better on downstream visio-linguistic tasks. Finally, we summarize the current limitations of AutoDeconfounding to solve the issue of spurious correlations and provide directions for the design of novel AutoDeconfounding methods that are aimed at overcoming these limitations.},
  archive      = {J_FRAI},
  author       = {Cornille, Nathan and Laenen, Katrien and Moens, Marie-Francine},
  doi          = {10.3389/frai.2022.736791},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {736791},
  shortjournal = {Front. Artif. Intell.},
  title        = {Critical analysis of deconfounded pretraining to improve visio-linguistic models},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compact neural architecture designs by tensor
representations. <em>FRAI</em>, <em>5</em>, 728761. (<a
href="https://doi.org/10.3389/frai.2022.728761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework of tensorial neural networks (TNNs) extending existing linear layers on low-order tensors to multilinear operations on higher-order tensors. TNNs have three advantages over existing networks: First, TNNs naturally apply to higher-order data without flattening, which preserves their multi-dimensional structures. Second, compressing a pre-trained network into a TNN results in a model with similar expressive power but fewer parameters. Finally, TNNs interpret advanced compact designs of network architectures, such as bottleneck modules and interleaved group convolutions. To learn TNNs, we derive their backpropagation rules using a novel suite of generalized tensor algebra. With backpropagation, we can either learn TNNs from scratch or pre-trained models using knowledge distillation. Experiments on VGG, ResNet, and Wide-ResNet demonstrate that TNNs outperform the state-of-the-art low-rank methods on a wide range of backbone networks and datasets.},
  archive      = {J_FRAI},
  author       = {Su, Jiahao and Li, Jingling and Liu, Xiaoyu and Ranadive, Teresa and Coley, Christopher and Tuan, Tai-Ching and Huang, Furong},
  doi          = {10.3389/frai.2022.728761},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {728761},
  shortjournal = {Front. Artif. Intell.},
  title        = {Compact neural architecture designs by tensor representations},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Unleashing innovation on precision public
health–highlights from the MCBIOS and MAQC 2021 joint conference.
<em>FRAI</em>, <em>5</em>, 859700. (<a
href="https://doi.org/10.3389/frai.2022.859700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Homayouni, Ramin and Hong, Huixiao and Manda, Prashanti and Nanduri, Bindu and Toby, Inimary T.},
  doi          = {10.3389/frai.2022.859700},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {859700},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Unleashing innovation on precision public Health–Highlights from the MCBIOS and MAQC 2021 joint conference},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Learning analytics – trends and challenges.
<em>FRAI</em>, <em>5</em>, 856807. (<a
href="https://doi.org/10.3389/frai.2022.856807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Klašnja-Milićević, Aleksandra and Ivanović, Mirjana and Vesin, Boban and Satratzemi, Maya and Wasson, Barbara},
  doi          = {10.3389/frai.2022.856807},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {856807},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Learning analytics – trends and challenges},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stock price forecasting by a deep convolutional generative
adversarial network. <em>FRAI</em>, <em>5</em>, 837596. (<a
href="https://doi.org/10.3389/frai.2022.837596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock market prices are known to be very volatile and noisy, and their accurate forecasting is a challenging problem. Traditionally, both linear and non-linear methods (such as ARIMA and LSTM) have been proposed and successfully applied to stock market prediction, but there is room to develop models that further reduce the forecast error. In this paper, we introduce a Deep Convolutional Generative Adversarial Network (DCGAN) architecture to deal with the problem of forecasting the closing price of stocks. To test the empirical performance of our proposed model we use the FTSE MIB (Financial Times Stock Exchange Milano Indice di Borsa), the benchmark stock market index for the Italian national stock exchange. By conducting both single-step and multi-step forecasting, we observe that our proposed model performs better than standard widely used tools, suggesting that Deep Learning (and in particular GANs) is a promising field for financial time series forecasting.},
  archive      = {J_FRAI},
  author       = {Staffini, Alessio},
  doi          = {10.3389/frai.2022.837596},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {837596},
  shortjournal = {Front. Artif. Intell.},
  title        = {Stock price forecasting by a deep convolutional generative adversarial network},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Governing ethical AI transformation: A case study of
AuroraAI. <em>FRAI</em>, <em>5</em>, 836557. (<a
href="https://doi.org/10.3389/frai.2022.836557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can the public sector use AI ethically and responsibly for the benefit of people? The sustainable development and deployment of artificial intelligence (AI) in the public sector requires dialogue and deliberation between developers, decision makers, deployers, end users, and the public. This paper contributes to the debate on how to develop persuasive government approaches for steering the development and use of AI. We examine the ethical issues and the role of the public in the debate on developing public sector governance of socially and democratically sustainable and technology-intensive societies. To concretize this discussion, we study the co-development of a Finnish national AI program AuroraAI, which aims to provide citizens with tailored and timely services for different life situations, utilizing AI. With the help of this case study, we investigate the challenges posed by the development and use of AI in the service of public administration. We draw particular attention to the efforts made by the AuroraAI Ethics Board in deliberating the AuroraAI solution options and working toward a sustainable and inclusive AI society.},
  archive      = {J_FRAI},
  author       = {Leikas, Jaana and Johri, Aditya and Latvanen, Marko and Wessberg, Nina and Hahto, Antti},
  doi          = {10.3389/frai.2022.836557},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {836557},
  shortjournal = {Front. Artif. Intell.},
  title        = {Governing ethical AI transformation: A case study of AuroraAI},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inference-optimized AI and high performance computing for
gravitational wave detection at scale. <em>FRAI</em>, <em>5</em>,
828672. (<a href="https://doi.org/10.3389/frai.2022.828672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an ensemble of artificial intelligence models for gravitational wave detection that we trained in the Summit supercomputer using 32 nodes, equivalent to 192 NVIDIA V100 GPUs, within 2 h. Once fully trained, we optimized these models for accelerated inference using NVIDIA TensorRT. We deployed our inference-optimized AI ensemble in the ThetaGPU supercomputer at Argonne Leadership Computer Facility to conduct distributed inference. Using the entire ThetaGPU supercomputer, consisting of 20 nodes each of which has 8 NVIDIA A100 Tensor Core GPUs and 2 AMD Rome CPUs, our NVIDIA TensorRT-optimized AI ensemble processed an entire month of advanced LIGO data (including Hanford and Livingston data streams) within 50 s. Our inference-optimized AI ensemble retains the same sensitivity of traditional AI models, namely, it identifies all known binary black hole mergers previously identified in this advanced LIGO dataset and reports no misclassifications, while also providing a 3X inference speedup compared to traditional artificial intelligence models. We used time slides to quantify the performance of our AI ensemble to process up to 5 years worth of advanced LIGO data. In this synthetically enhanced dataset, our AI ensemble reports an average of one misclassification for every month of searched advanced LIGO data. We also present the receiver operating characteristic curve of our AI ensemble using this 5 year long advanced LIGO dataset. This approach provides the required tools to conduct accelerated, AI-driven gravitational wave detection at scale.},
  archive      = {J_FRAI},
  author       = {Chaturvedi, Pranshu and Khan, Asad and Tian, Minyang and Huerta, E. A. and Zheng, Huihuo},
  doi          = {10.3389/frai.2022.828672},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {828672},
  shortjournal = {Front. Artif. Intell.},
  title        = {Inference-optimized AI and high performance computing for gravitational wave detection at scale},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Catastrophic forgetting in deep graph networks: A graph
classification benchmark. <em>FRAI</em>, <em>5</em>, 824655. (<a
href="https://doi.org/10.3389/frai.2022.824655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the phenomenon of catastrophic forgetting in the graph representation learning scenario. The primary objective of the analysis is to understand whether classical continual learning techniques for flat and sequential data have a tangible impact on performances when applied to graph data. To do so, we experiment with a structure-agnostic model and a deep graph network in a robust and controlled environment on three different datasets. The benchmark is complemented by an investigation on the effect of structure-preserving regularization techniques on catastrophic forgetting. We find that replay is the most effective strategy in so far, which also benefits the most from the use of regularization. Our findings suggest interesting future research at the intersection of the continual and graph representation learning fields. Finally, we provide researchers with a flexible software framework to reproduce our results and carry out further experiments.},
  archive      = {J_FRAI},
  author       = {Carta, Antonio and Cossu, Andrea and Errica, Federico and Bacciu, Davide},
  doi          = {10.3389/frai.2022.824655},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {824655},
  shortjournal = {Front. Artif. Intell.},
  title        = {Catastrophic forgetting in deep graph networks: A graph classification benchmark},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring behavioral patterns for data-driven modeling of
learners’ individual differences. <em>FRAI</em>, <em>5</em>, 807320. (<a
href="https://doi.org/10.3389/frai.2022.807320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational data mining research has demonstrated that the large volume of learning data collected by modern e-learning systems could be used to recognize student behavior patterns and group students into cohorts with similar behavior. However, few attempts have been done to connect and compare behavioral patterns with known dimensions of individual differences. To what extent learner behavior is defined by known individual differences? Which of them could be a better predictor of learner engagement and performance? Could we use behavior patterns to build a data-driven model of individual differences that could be more useful for predicting critical outcomes of the learning process than traditional models? Our paper attempts to answer these questions using a large volume of learner data collected in an online practice system. We apply a sequential pattern mining approach to build individual models of learner practice behavior and reveal latent student subgroups that exhibit considerably different practice behavior. Using these models we explored the connections between learner behavior and both, the incoming and outgoing parameters of the learning process. Among incoming parameters we examined traditionally collected individual differences such as self-esteem, gender, and knowledge monitoring skills. We also attempted to bridge the gap between cluster-based behavior pattern models and traditional scale-based models of individual differences by quantifying learner behavior on a latent data-driven scale. Our research shows that this data-driven model of individual differences performs significantly better than traditional models of individual differences in predicting important parameters of the learning process, such as performance and engagement.},
  archive      = {J_FRAI},
  author       = {Akhuseyinoglu, Kamil and Brusilovsky, Peter},
  doi          = {10.3389/frai.2022.807320},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {807320},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring behavioral patterns for data-driven modeling of learners&#39; individual differences},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial interactionism: Avoiding isolating perception
from cognition in AI. <em>FRAI</em>, <em>5</em>, 806041. (<a
href="https://doi.org/10.3389/frai.2022.806041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss the influence upon the fields of robotics and AI of the manner one conceives the relationships between artificial agents&#39; perception, cognition, and action. We shed some light upon a widespread paradigm we call the isolated perception paradigm that addresses perception as isolated from cognition and action. By mobilizing the resources of philosophy (phenomenology and epistemology) and cognitive sciences, and by drawing on recent approaches in AI, we explore what it could mean for robotics and AI to take distance from the isolated perception paradigm. We argue that such a renouncement opens interesting ways to explore the possibilities for designing artificial agents with intrinsic motivations and constitutive autonomy. We then propose Artificial Interactionism, our approach that escapes the isolated perception paradigm by drawing on the inversion of the interaction cycle. When the interaction cycle is inverted, input data are not percepts directly received from the environment, but outcomes of control loops. Perception is not received from sensors in isolation from cognition but is actively constructed by the cognitive architecture through interaction. We give an example implementation of artificial interactionism that demonstrates basic intrinsically motivated learning behavior in a dynamic simulated environment.},
  archive      = {J_FRAI},
  author       = {Guillermin, Mathieu and Georgeon, Olivier},
  doi          = {10.3389/frai.2022.806041},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {806041},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial interactionism: Avoiding isolating perception from cognition in AI},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring the representations of individual entities in the
brain combining EEG and distributional semantics. <em>FRAI</em>,
<em>5</em>, 796793. (<a
href="https://doi.org/10.3389/frai.2022.796793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic knowledge about individual entities (i.e., the referents of proper names such as Jacinta Ardern) is fine-grained, episodic, and strongly social in nature, when compared with knowledge about generic entities (the referents of common nouns such as politician). We investigate the semantic representations of individual entities in the brain; and for the first time we approach this question using both neural data, in the form of newly-acquired EEG data, and distributional models of word meaning, employing them to isolate semantic information regarding individual entities in the brain. We ran two sets of analyses. The first set of analyses is only concerned with the evoked responses to individual entities and their categories. We find that it is possible to classify them according to both their coarse and their fine-grained category at appropriate timepoints, but that it is hard to map representational information learned from individuals to their categories. In the second set of analyses, we learn to decode from evoked responses to distributional word vectors. These results indicate that such a mapping can be learnt successfully: this counts not only as a demonstration that representations of individuals can be discriminated in EEG responses, but also as a first brain-based validation of distributional semantic models as representations of individual entities. Finally, in-depth analyses of the decoder performance provide additional evidence that the referents of proper names and categories have little in common when it comes to their representation in the brain.},
  archive      = {J_FRAI},
  author       = {Bruera, Andrea and Poesio, Massimo},
  doi          = {10.3389/frai.2022.796793},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {796793},
  shortjournal = {Front. Artif. Intell.},
  title        = {Exploring the representations of individual entities in the brain combining EEG and distributional semantics},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the construction of group equivariant non-expansive
operators via permutants and symmetric functions. <em>FRAI</em>,
<em>5</em>, 786091. (<a
href="https://doi.org/10.3389/frai.2022.786091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group Equivariant Operators (GEOs) are a fundamental tool in the research on neural networks, since they make available a new kind of geometric knowledge engineering for deep learning, which can exploit symmetries in artificial intelligence and reduce the number of parameters required in the learning process. In this paper we introduce a new method to build non-linear GEOs and non-linear Group Equivariant Non-Expansive Operators (GENEOs), based on the concepts of symmetric function and permutant. This method is particularly interesting because of the good theoretical properties of GENEOs and the ease of use of permutants to build equivariant operators, compared to the direct use of the equivariance groups we are interested in. In our paper, we prove that the technique we propose works for any symmetric function, and benefits from the approximability of continuous symmetric functions by symmetric polynomials. A possible use in Topological Data Analysis of the GENEOs obtained by this new method is illustrated.},
  archive      = {J_FRAI},
  author       = {Conti, Francesco and Frosini, Patrizio and Quercioli, Nicola},
  doi          = {10.3389/frai.2022.786091},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {786091},
  shortjournal = {Front. Artif. Intell.},
  title        = {On the construction of group equivariant non-expansive operators via permutants and symmetric functions},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Segmentation of lung nodules on CT images using a nested
three-dimensional fully connected convolutional network. <em>FRAI</em>,
<em>5</em>, 782225. (<a
href="https://doi.org/10.3389/frai.2022.782225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer-aided diagnosis systems for lung cancer, segmentation of lung nodules is important for analyzing image features of lung nodules on computed tomography (CT) images and distinguishing malignant nodules from benign ones. However, it is difficult to accurately and robustly segment lung nodules attached to the chest wall or with ground-glass opacities using conventional image processing methods. Therefore, this study aimed to develop a method for robust and accurate three-dimensional (3D) segmentation of lung nodule regions using deep learning. In this study, a nested 3D fully connected convolutional network with residual unit structures was proposed, and designed a new loss function. Compared with annotated images obtained under the guidance of a radiologist, the Dice similarity coefficient (DS) and intersection over union (IoU) were 0.845 ± 0.008 and 0.738 ± 0.011, respectively, for 332 lung nodules (lung adenocarcinoma) obtained from 332 patients. On the other hand, for 3D U-Net and 3D SegNet, the DS was 0.822 ± 0.009 and 0.786 ± 0.011, respectively, and the IoU was 0.711 ± 0.011 and 0.660 ± 0.012, respectively. These results indicate that the proposed method is significantly superior to well-known deep learning models. Moreover, we compared the results obtained from the proposed method with those obtained from conventional image processing methods, watersheds, and graph cuts. The DS and IoU results for the watershed method were 0.628 ± 0.027 and 0.494 ± 0.025, respectively, and those for the graph cut method were 0.566 ± 0.025 and 0.414 ± 0.021, respectively. These results indicate that the proposed method is significantly superior to conventional image processing methods. The proposed method may be useful for accurate and robust segmentation of lung nodules to assist radiologists in the diagnosis of lung nodules such as lung adenocarcinoma on CT images.},
  archive      = {J_FRAI},
  author       = {Kido, Shoji and Kidera, Shunske and Hirano, Yasushi and Mabu, Shingo and Kamiya, Tohru and Tanaka, Nobuyuki and Suzuki, Yuki and Yanagawa, Masahiro and Tomiyama, Noriyuki},
  doi          = {10.3389/frai.2022.782225},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {782225},
  shortjournal = {Front. Artif. Intell.},
  title        = {Segmentation of lung nodules on CT images using a nested three-dimensional fully connected convolutional network},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Models of language and multiword expressions. <em>FRAI</em>,
<em>5</em>, 781962. (<a
href="https://doi.org/10.3389/frai.2022.781962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional accounts of language postulate two basic components: words stored in a lexicon, and rules that govern how they can be combined into meaningful sentences, a grammar. But, although this words-and-rules framework has proven itself to be useful in natural language processing and cognitive science, it has also shown important shortcomings when faced with actual language use. In this article, we review evidence from language acquisition, sentence processing, and computational modeling that shows how multiword expressions such as idioms, collocations, and other meaningful and common units that comprise more than one word play a key role in the organization of our linguistic knowledge. Importantly, multiword expressions straddle the line between lexicon and grammar, calling into question how useful this distinction is as a foundation for our understanding of language. Nonetheless, finding a replacement for the foundational role the words-and-rules approach has played in our theories is not straightforward. Thus, the second part of our article reviews and synthesizes the diverse approaches that have attempted to account for the central role of multiword expressions in language representation, acquisition, and processing.},
  archive      = {J_FRAI},
  author       = {Contreras Kallens, Pablo and Christiansen, Morten H.},
  doi          = {10.3389/frai.2022.781962},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {781962},
  shortjournal = {Front. Artif. Intell.},
  title        = {Models of language and multiword expressions},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning approaches for neuroimaging analysis: A
scoping review. <em>FRAI</em>, <em>5</em>, 780405. (<a
href="https://doi.org/10.3389/frai.2022.780405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning algorithms have been moderately successful in diagnoses of diseases by analyzing medical images especially through neuroimaging that is rich in annotated data. Transfer learning methods have demonstrated strong performance in tackling annotated data. It utilizes and transfers knowledge learned from a source domain to target domain even when the dataset is small. There are multiple approaches to transfer learning that result in a range of performance estimates in diagnosis, detection, and classification of clinical problems. Therefore, in this paper, we reviewed transfer learning approaches, their design attributes, and their applications to neuroimaging problems. We reviewed two main literature databases and included the most relevant studies using predefined inclusion criteria. Among 50 reviewed studies, more than half of them are on transfer learning for Alzheimer&#39;s disease. Brain mapping and brain tumor detection were second and third most discussed research problems, respectively. The most common source dataset for transfer learning was ImageNet, which is not a neuroimaging dataset. This suggests that the majority of studies preferred pre-trained models instead of training their own model on a neuroimaging dataset. Although, about one third of studies designed their own architecture, most studies used existing Convolutional Neural Network architectures. Magnetic Resonance Imaging was the most common imaging modality. In almost all studies, transfer learning contributed to better performance in diagnosis, classification, segmentation of different neuroimaging diseases and problems, than methods without transfer learning. Among different transfer learning approaches, fine-tuning all convolutional and fully-connected layers approach and freezing convolutional layers and fine-tuning fully-connected layers approach demonstrated superior performance in terms of accuracy. These recent transfer learning approaches not only show great performance but also require less computational resources and time.},
  archive      = {J_FRAI},
  author       = {Ardalan, Zaniar and Subbian, Vignesh},
  doi          = {10.3389/frai.2022.780405},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {780405},
  shortjournal = {Front. Artif. Intell.},
  title        = {Transfer learning approaches for neuroimaging analysis: A scoping review},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Financial risk management and explainable, trustworthy,
responsible AI. <em>FRAI</em>, <em>5</em>, 779799. (<a
href="https://doi.org/10.3389/frai.2022.779799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This perspective paper is based on several sessions by the members of the Round Table AI at FIRM1, with input from a number of external and international speakers. Its particular focus lies on the management of the model risk of productive models in banks and other financial institutions. The models in view range from simple rules-based approaches to Artificial Intelligence (AI) or Machine learning (ML) models with a high level of sophistication. The typical applications of those models are related to predictions and decision making around the value chain of credit risk (including accounting side under IFRS9 or related national GAAP approaches), insurance risk or other financial risk types. We expect more models of higher complexity in the space of anti-money laundering, fraud detection and transaction monitoring as well as a rise of AI/ML models as alternatives to current methods in solving some of the more intricate stochastic differential equations needed for the pricing and/or valuation of derivatives. The same type of model is also successful in areas unrelated to risk management, such as sales optimization, customer lifetime value considerations, robo-advisory, and other fields of applications. The paper refers to recent related publications from central banks, financial supervisors and regulators as well as other relevant sources and working groups. It aims to give practical advice for establishing a risk-based governance and testing framework for the mentioned model types and discusses the use of recent technologies, approaches, and platforms to support the establishment of responsible, trustworthy, explainable, auditable, and manageable AI/ML in production. In view of the recent EU publication on AI, also referred to as the EU Artificial Intelligence Act (AIA), we also see a certain added value for this paper as an instigator of further thinking outside of the financial services sector, in particular where “High Risk” models according to the mentioned EU consultation are concerned.},
  archive      = {J_FRAI},
  author       = {Fritz-Morgenthal, Sebastian and Hein, Bernhard and Papenbrock, Jochen},
  doi          = {10.3389/frai.2022.779799},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {779799},
  shortjournal = {Front. Artif. Intell.},
  title        = {Financial risk management and explainable, trustworthy, responsible AI},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single shot corrective CNN for anatomically correct 3D hand
pose estimation. <em>FRAI</em>, <em>5</em>, 759255. (<a
href="https://doi.org/10.3389/frai.2022.759255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand pose estimation in 3D from depth images is a highly complex task. Current state-of-the-art 3D hand pose estimators focus only on the accuracy of the model as measured by how closely it matches the ground truth hand pose but overlook the resulting hand pose&#39;s anatomical correctness. In this paper, we present the Single Shot Corrective CNN (SSC-CNN) to tackle the problem of enforcing anatomical correctness at the architecture level. In contrast to previous works which use post-facto pose filters, SSC-CNN predicts the hand pose that conforms to the human hand&#39;s biomechanical bounds and rules in a single forward pass. The model was trained and tested on the HANDS2017 and MSRA datasets. Experiments show that our proposed model shows comparable accuracy to the state-of-the-art models as measured by the ground truth pose. However, the previous methods have high anatomical errors, whereas our model is free from such errors. Experiments show that our proposed model shows zero anatomical errors along with comparable accuracy to the state-of-the-art models as measured by the ground truth pose. The previous methods have high anatomical errors, whereas our model is free from such errors. Surprisingly even the ground truth provided in the existing datasets suffers from anatomical errors, and therefore Anatomical Error Free (AEF) versions of the datasets, namely AEF-HANDS2017 and AEF-MSRA, were created.},
  archive      = {J_FRAI},
  author       = {Isaac, Joseph H. R. and Manivannan, Muniyandi and Ravindran, Balaraman},
  doi          = {10.3389/frai.2022.759255},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {759255},
  shortjournal = {Front. Artif. Intell.},
  title        = {Single shot corrective CNN for anatomically correct 3D hand pose estimation},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supporting artificial social intelligence with theory of
mind. <em>FRAI</em>, <em>5</em>, 750763. (<a
href="https://doi.org/10.3389/frai.2022.750763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss the development of artificial theory of mind as foundational to an agent&#39;s ability to collaborate with human team members. Agents imbued with artificial social intelligence will require various capabilities to gather the social data needed to inform an artificial theory of mind of their human counterparts. We draw from social signals theorizing and discuss a framework to guide consideration of core features of artificial social intelligence. We discuss how human social intelligence, and the development of theory of mind, can contribute to the development of artificial social intelligence by forming a foundation on which to help agents model, interpret and predict the behaviors and mental states of humans to support human-agent interaction. Artificial social intelligence will need the processing capabilities to perceive, interpret, and generate combinations of social cues to operate within a human-agent team. Artificial Theory of Mind affords a structure by which a socially intelligent agent could be imbued with the ability to model their human counterparts and engage in effective human-agent interaction. Further, modeling Artificial Theory of Mind can be used by an ASI to support transparent communication with humans, improving trust in agents, so that they may better predict future system behavior based on their understanding of and support trust in artificial socially intelligent agents.},
  archive      = {J_FRAI},
  author       = {Williams, Jessica and Fiore, Stephen M. and Jentsch, Florian},
  doi          = {10.3389/frai.2022.750763},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {750763},
  shortjournal = {Front. Artif. Intell.},
  title        = {Supporting artificial social intelligence with theory of mind},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward an integrative approach for making sense
distinctions. <em>FRAI</em>, <em>5</em>, 745626. (<a
href="https://doi.org/10.3389/frai.2022.745626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word senses are the fundamental unit of description in lexicography, yet it is rarely the case that different dictionaries reach any agreement on the number and definition of senses in a language. With the recent rise in natural language processing and other computational approaches there is an increasing demand for quantitatively validated sense catalogues of words, yet no consensus methodology exists. In this paper, we look at four main approaches to making sense distinctions: formal, cognitive, distributional, and intercultural and examine the strengths and weaknesses of each approach. We then consider how these may be combined into a single sound methodology. We illustrate this by examining two English words, “wing” and “fish,” using existing resources for each of these four approaches and illustrate the weaknesses of each. We then look at the impact of such an integrated method and provide some future perspectives on the research that is necessary to reach a principled method for making sense distinctions.},
  archive      = {J_FRAI},
  author       = {McCrae, John P. and Fransen, Theodorus and Ahmadi, Sina and Buitelaar, Paul and Goswami, Koustava},
  doi          = {10.3389/frai.2022.745626},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {745626},
  shortjournal = {Front. Artif. Intell.},
  title        = {Toward an integrative approach for making sense distinctions},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regulating ruminative web browsing based on the
counterbalance modeling approach. <em>FRAI</em>, <em>5</em>, 741610. (<a
href="https://doi.org/10.3389/frai.2022.741610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though the web environment facilitates our daily life, emotional problems caused by its incompatibility with human cognition are becoming increasingly serious. To alleviate negative emotions during web use, we developed a browser extension that presents memorized product images to users in the form of web advertisements. This system utilizes the cognitive architecture Adaptive Control of Thought-Rational (ACT-R) as a model of human memory and emotion. A heart rate sensor attached to the user modulates the ACT-R model parameters, and the emotional states represented by the model are synchronized (following the chameleon effect) or counterbalanced (following the homeostasis regulation) with the physiological state of the user. An experiment demonstrates that the counterbalanced model suppresses negative ruminative web browsing. The authors claim that this approach, utilizing a cognitive model, is advantageous in terms of explainability.},
  archive      = {J_FRAI},
  author       = {Morita, Junya and Pitakchokchai, Thanakit and Raj, Giri Basanta and Yamamoto, Yusuke and Yuhashi, Hiroyasu and Koguchi, Teppei},
  doi          = {10.3389/frai.2022.741610},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {741610},
  shortjournal = {Front. Artif. Intell.},
  title        = {Regulating ruminative web browsing based on the counterbalance modeling approach},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep active learning via open-set recognition.
<em>FRAI</em>, <em>5</em>, 737363. (<a
href="https://doi.org/10.3389/frai.2022.737363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications, data is easy to acquire but expensive and time-consuming to label, prominent examples include medical imaging and NLP. This disparity has only grown in recent years as our ability to collect data improves. Under these constraints, it makes sense to select only the most informative instances from the unlabeled pool and request an oracle (e.g., a human expert) to provide labels for those samples. The goal of active learning is to infer the informativeness of unlabeled samples so as to minimize the number of requests to the oracle. Here, we formulate active learning as an open-set recognition problem. In this paradigm, only some of the inputs belong to known classes; the classifier must identify the rest as unknown. More specifically, we leverage variational neural networks (VNNs), which produce high-confidence (i.e., low-entropy) predictions only for inputs that closely resemble the training data. We use the inverse of this confidence measure to select the samples that the oracle should label. Intuitively, unlabeled samples that the VNN is uncertain about contain features that the network has not been exposed to; thus they are more informative for future training. We carried out an extensive evaluation of our novel, probabilistic formulation of active learning, achieving state-of-the-art results on MNIST, CIFAR-10, CIFAR-100, and FashionMNIST. Additionally, unlike current active learning methods, our algorithm can learn even in the presence of out-of-distribution outliers. As our experiments show, when the unlabeled pool consists of a mixture of samples from multiple datasets, our approach can automatically distinguish between samples from seen vs. unseen datasets. Overall, our results show that high-quality uncertainty measures are key for pool-based active learning.},
  archive      = {J_FRAI},
  author       = {Mandivarapu, Jaya Krishna and Camp, Blake and Estrada, Rolando},
  doi          = {10.3389/frai.2022.737363},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {737363},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep active learning via open-set recognition},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised text segmentation predicts eye fixations during
reading. <em>FRAI</em>, <em>5</em>, 731615. (<a
href="https://doi.org/10.3389/frai.2022.731615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Words typically form the basis of psycholinguistic and computational linguistic studies about sentence processing. However, recent evidence shows the basic units during reading, i.e., the items in the mental lexicon, are not always words, but could also be sub-word and supra-word units. To recognize these units, human readers require a cognitive mechanism to learn and detect them. In this paper, we assume eye fixations during reading reveal the locations of the cognitive units, and that the cognitive units are analogous with the text units discovered by unsupervised segmentation models. We predict eye fixations by model-segmented units on both English and Dutch text. The results show the model-segmented units predict eye fixations better than word units. This finding suggests that the predictive performance of model-segmented units indicates their plausibility as cognitive units. The Less-is-Better (LiB) model, which finds the units that minimize both long-term and working memory load, offers advantages both in terms of prediction score and efficiency among alternative models. Our results also suggest that modeling the least-effort principle for the management of long-term and working memory can lead to inferring cognitive units. Overall, the study supports the theory that the mental lexicon stores not only words but also smaller and larger units, suggests that fixation locations during reading depend on these units, and shows that unsupervised segmentation models can discover these units.},
  archive      = {J_FRAI},
  author       = {Yang, Jinbiao and van den Bosch, Antal and Frank, Stefan L.},
  doi          = {10.3389/frai.2022.731615},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {731615},
  shortjournal = {Front. Artif. Intell.},
  title        = {Unsupervised text segmentation predicts eye fixations during reading},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational models of readers’ apperceptive mass.
<em>FRAI</em>, <em>5</em>, 718690. (<a
href="https://doi.org/10.3389/frai.2022.718690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in machine-learning-based distributed semantic models (DSMs) offers new ways to simulate the apperceptive mass (AM; Kintsch, 1980) of reader groups or individual readers and to predict their performance in reading-related tasks. The AM integrates the mental lexicon with world knowledge, as for example, acquired via reading books. Following pioneering work by Denhière and Lemaire (2004), here, we computed DSMs based on a representative corpus of German children and youth literature (Jacobs et al., 2020) as null models of the part of the AM that represents distributional semantic input, for readers of different reading ages (grades 1–2, 3–4, and 5–6). After a series of DSM quality tests, we evaluated the performance of these models quantitatively in various tasks to simulate the different reader groups&#39; hypothetical semantic and syntactic skills. In a final study, we compared the models&#39; performance with that of human adult and children readers in two rating tasks. Overall, the results show that with increasing reading age performance in practically all tasks becomes better. The approach taken in these studies reveals the limits of DSMs for simulating human AM and their potential for applications in scientific studies of literature, research in education, or developmental science.},
  archive      = {J_FRAI},
  author       = {Jacobs, Arthur M. and Kinder, Annette},
  doi          = {10.3389/frai.2022.718690},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {718690},
  shortjournal = {Front. Artif. Intell.},
  title        = {Computational models of readers&#39; apperceptive mass},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A synaptic pruning-based spiking neural network for
hand-written digits classification. <em>FRAI</em>, <em>5</em>, 680165.
(<a href="https://doi.org/10.3389/frai.2022.680165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A spiking neural network model inspired by synaptic pruning is developed and trained to extract features of hand-written digits. The network is composed of three spiking neural layers and one output neuron whose firing rate is used for classification. The model detects and collects the geometric features of the images from the Modified National Institute of Standards and Technology database (MNIST). In this work, a novel learning rule is developed to train the network to detect features of different digit classes. For this purpose, randomly initialized synaptic weights between the first and second layers are updated using average firing rates of pre- and postsynaptic neurons. Then, using a neuroscience-inspired mechanism named, “synaptic pruning” and its predefined threshold values, some of the synapses are deleted. Hence, these sparse matrices named, “information channels” are constructed so that they show highly specific patterns for each digit class as connection matrices between the first and second layers. The “information channels” are used in the test phase to assign a digit class to each test image. In addition, the role of feed-back inhibition as well as the connectivity rates of the second and third neural layers are studied. Similar to the abilities of the humans to learn from small training trials, the developed spiking neural network needs a very small dataset for training, compared to the conventional deep learning methods that have shown a very good performance on the MNIST dataset. This work introduces a new class of brain-inspired spiking neural networks to extract the features of complex data images.},
  archive      = {J_FRAI},
  author       = {Faghihi, Faramarz and Alashwal, Hany and Moustafa, Ahmed A.},
  doi          = {10.3389/frai.2022.680165},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {680165},
  shortjournal = {Front. Artif. Intell.},
  title        = {A synaptic pruning-based spiking neural network for hand-written digits classification},
  volume       = {5},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Planning as inference in epidemiological dynamics models.
<em>FRAI</em>, <em>4</em>, 550603. (<a
href="https://doi.org/10.3389/frai.2021.550603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we demonstrate how to automate parts of the infectious disease-control policy-making process via performing inference in existing epidemiological models. The kind of inference tasks undertaken include computing the posterior distribution over controllable, via direct policy-making choices, simulation model parameters that give rise to acceptable disease progression outcomes. Among other things, we illustrate the use of a probabilistic programming language that automates inference in existing simulators. Neither the full capabilities of this tool for automating inference nor its utility for planning is widely disseminated at the current time. Timely gains in understanding about how such simulation-based models and inference automation tools applied in support of policy-making could lead to less economically damaging policy prescriptions, particularly during the current COVID-19 pandemic.},
  archive      = {J_FRAI},
  author       = {Wood, Frank and Warrington, Andrew and Naderiparizi, Saeid and Weilbach, Christian and Masrani, Vaden and Harvey, William and Ścibior, Adam and Beronov, Boyan and Grefenstette, John and Campbell, Duncan and Nasseri, S. Ali},
  doi          = {10.3389/frai.2021.550603},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {3},
  pages        = {550603},
  shortjournal = {Front. Artif. Intell.},
  title        = {Planning as inference in epidemiological dynamics models},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributional measures of semantic abstraction.
<em>FRAI</em>, <em>4</em>, 796756. (<a
href="https://doi.org/10.3389/frai.2021.796756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides an in-depth study of distributional measures for distinguishing between degrees of semantic abstraction. Abstraction is considered a “central construct in cognitive science” (Barsalou, 2003) and a “process of information reduction that allows for efficient storage and retrieval of central knowledge” (Burgoon et al., 2013). Relying on the distributional hypothesis, computational studies have successfully exploited measures of contextual co-occurrence and neighbourhood density to distinguish between conceptual semantic categorisations. So far, these studies have modeled semantic abstraction across lexical-semantic tasks such as ambiguity; diachronic meaning changes; abstractness vs. concreteness; and hypernymy. Yet, the distributional approaches target different conceptual types of semantic relatedness, and as to our knowledge not much attention has been paid to apply, compare or analyse the computational abstraction measures across conceptual tasks. The current article suggests a novel perspective that exploits variants of distributional measures to investigate semantic abstraction in English in terms of the abstract–concrete dichotomy (e.g., glory–banana) and in terms of the generality–specificity distinction (e.g., animal–fish), in order to compare the strengths and weaknesses of the measures regarding categorisations of abstraction, and to determine and investigate conceptual differences.In a series of experiments we identify reliable distributional measures for both instantiations of lexical-semantic abstraction and reach a precision higher than 0.7, but the measures clearly differ for the abstract–concrete vs. abstract–specific distinctions and for nouns vs. verbs. Overall, we identify two groups of measures, (i) frequency and word entropy when distinguishing between more and less abstract words in terms of the generality–specificity distinction, and (ii) neighbourhood density variants (especially target–context diversity) when distinguishing between more and less abstract words in terms of the abstract–concrete dichotomy. We conclude that more general words are used more often and are less surprising than more specific words, and that abstract words establish themselves empirically in semantically more diverse contexts than concrete words. Finally, our experiments once more point out that distributional models of conceptual categorisations need to take word classes and ambiguity into account: results for nouns vs. verbs differ in many respects, and ambiguity hinders fine-tuning empirical observations.},
  archive      = {J_FRAI},
  author       = {Schulte im Walde, Sabine and Frassinelli, Diego},
  doi          = {10.3389/frai.2021.796756},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {796756},
  shortjournal = {Front. Artif. Intell.},
  title        = {Distributional measures of semantic abstraction},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Developing and evaluating a university recommender system.
<em>FRAI</em>, <em>4</em>, 796268. (<a
href="https://doi.org/10.3389/frai.2021.796268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A challenge for many young adults is to find the right institution to follow higher education. Global university rankings are a commonly used, but inefficient tool, for they do not consider a person&#39;s preferences and needs. For example, some persons pursue prestige in their higher education, while others prefer proximity. This paper develops and evaluates a university recommender system, eliciting user preferences as ratings to build predictive models and to generate personalized university ranking lists. In Study 1, we performed offline evaluation on a rating dataset to determine which recommender approaches had the highest predictive value. In Study 2, we selected three algorithms to produce different university recommendation lists in our online tool, asking our users to compare and evaluate them in terms of different metrics (Accuracy, Diversity, Perceived Personalization, Satisfaction, and Novelty). We show that a SVD algorithm scores high on accuracy and perceived personalization, while a KNN algorithm scores better on novelty. We also report findings on preferred university features.},
  archive      = {J_FRAI},
  author       = {Elahi, Mehdi and Starke, Alain and El Ioini, Nabil and Lambrix, Anna Alexander and Trattner, Christoph},
  doi          = {10.3389/frai.2021.796268},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {796268},
  shortjournal = {Front. Artif. Intell.},
  title        = {Developing and evaluating a university recommender system},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From lexicon to flexicon: The principles of morphological
transcendence and lexical superstates in the characterization of words
in the mind. <em>FRAI</em>, <em>4</em>, 788430. (<a
href="https://doi.org/10.3389/frai.2021.788430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of mental lexicon research has benefitted greatly from the founding metaphor of a dictionary in the mind. That metaphor, however, had its origins in a perspective in which the lexicon was seen as a static repository of representations with fixed structural properties. This paper presents a contrasting view. It is a view that highlights that words are activities that we perform, rather than simply representations that we have. It is proposed that lexical representations are best seen as hierarchies of action within a highly interconnected and dynamic system. The paper presents two principles of lexical organization: morphological transcendence and lexical superstates. The former principle claims that through the activities of language comprehension and production, lexical forms can develop variant forms. Thus, the form key may develop into forms such as key- (e.g., keyboard) and -key, (e.g., turnkey). The paper also discusses how transcendence leads to lexical superstates, which do not have a fixed morphological structure. As part of a lexical superstate, alternative morphological structures exist as potential realizations. Which one is actually realized will depend on the specific circumstances of a lexical action. An account is presented in which the effects of semantic transparency are treated in terms of transcendence and superstate interactions. It is claimed that this approach, which highlights the dynamic and flexible nature of the mental lexicon, has implications for how we approach the modeling of language and cognition in general.},
  archive      = {J_FRAI},
  author       = {Libben, Gary},
  doi          = {10.3389/frai.2021.788430},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {788430},
  shortjournal = {Front. Artif. Intell.},
  title        = {From lexicon to flexicon: The principles of morphological transcendence and lexical superstates in the characterization of words in the mind},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Artificial neural network based non-linear transformation of
high-frequency returns for volatility forecasting. <em>FRAI</em>,
<em>4</em>, 787534. (<a
href="https://doi.org/10.3389/frai.2021.787534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper uses Long Short Term Memory Recurrent Neural Networks to extract information from the intraday high-frequency returns to forecast daily volatility. Applied to the IBM stock, we find significant improvements in the forecasting performance of models that use this extracted information compared to the forecasts of models that omit the extracted information and some of the most popular alternative models. Furthermore, we find that extracting the information through Long Short Term Memory Recurrent Neural Networks is superior to two Mixed Data Sampling alternatives.},
  archive      = {J_FRAI},
  author       = {Mücher, Christian},
  doi          = {10.3389/frai.2021.787534},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {787534},
  shortjournal = {Front. Artif. Intell.},
  title        = {Artificial neural network based non-linear transformation of high-frequency returns for volatility forecasting},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High resolution, annual maps of field boundaries for
smallholder-dominated croplands at national scales. <em>FRAI</em>,
<em>4</em>, 744863. (<a
href="https://doi.org/10.3389/frai.2021.744863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mapping the characteristics of Africa’s smallholder-dominated croplands, including the sizes and numbers of fields, can provide critical insights into food security and a range of other socioeconomic and environmental concerns. However, accurately mapping these systems is difficult because there is 1) a spatial and temporal mismatch between satellite sensors and smallholder fields, and 2) a lack of high-quality labels needed to train and assess machine learning classifiers. We developed an approach designed to address these two problems, and used it to map Ghana’s croplands. To overcome the spatio-temporal mismatch, we converted daily, high resolution imagery into two cloud-free composites (the primary growing season and subsequent dry season) covering the 2018 agricultural year, providing a seasonal contrast that helps to improve classification accuracy. To address the problem of label availability, we created a platform that rigorously assesses and minimizes label error, and used it to iteratively train a Random Forests classifier with active learning, which identifies the most informative training sample based on prediction uncertainty. Minimizing label errors improved model F1 scores by up to 25%. Active learning increased F1 scores by an average of 9.1% between first and last training iterations, and 2.3% more than models trained with randomly selected labels. We used the resulting 3.7 m map of cropland probabilities within a segmentation algorithm to delineate crop field boundaries. Using an independent map reference sample (n = 1,207), we found that the cropland probability and field boundary maps had respective overall accuracies of 88 and 86.7%, user’s accuracies for the cropland class of 61.2 and 78.9%, and producer’s accuracies of 67.3 and 58.2%. An unbiased area estimate calculated from the map reference sample indicates that cropland covers 17.1% (15.4–18.9%) of Ghana. Using the most accurate validation labels to correct for biases in the segmented field boundaries map, we estimated that the average size and total number of field in Ghana are 1.73 ha and 1,662,281, respectively. Our results demonstrate an adaptable and transferable approach for developing annual, country-scale maps of crop field boundaries, with several features that effectively mitigate the errors inherent in remote sensing of smallholder-dominated agriculture.},
  archive      = {J_FRAI},
  author       = {Estes, Lyndon D. and Ye, Su and Song, Lei and Luo, Boka and Eastman, J. Ronald and Meng, Zhenhua and Zhang, Qi and McRitchie, Dennis and Debats, Stephanie R. and Muhando, Justus and Amukoa, Angeline H. and Kaloo, Brian W. and Makuru, Jackson and Mbatia, Ben K. and Muasa, Isaac M. and Mucha, Julius and Mugami, Adelide M. and Mugami, Judith M. and Muinde, Francis W. and Mwawaza, Fredrick M. and Ochieng, Jeff and Oduol, Charles J. and Oduor, Purent and Wanjiku, Thuo and Wanyoike, Joseph G. and Avery, Ryan B. and Caylor, Kelly K.},
  doi          = {10.3389/frai.2021.744863},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {744863},
  shortjournal = {Front. Artif. Intell.},
  title        = {High resolution, annual maps of field boundaries for smallholder-dominated croplands at national scales},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of goal recognition systems on unreliable data
and uninspectable agents. <em>FRAI</em>, <em>4</em>, 734521. (<a
href="https://doi.org/10.3389/frai.2021.734521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Goal or intent recognition, where one agent recognizes the goals or intentions of another, can be a powerful tool for effective teamwork and improving interaction between agents. Such reasoning can be challenging to perform, however, because observations of an agent can be unreliable and, often, an agent does not have access to the reasoning processes and mental models of the other agent. Despite this difficulty, recent work has made great strides in addressing these challenges. In particular, two Artificial Intelligence (AI)-based approaches to goal recognition have recently been shown to perform well: goal recognition as planning, which reduces a goal recognition problem to the problem of plan generation; and Combinatory Categorical Grammars (CCGs), which treat goal recognition as a parsing problem. Additionally, new advances in cognitive science with respect to Theory of Mind reasoning have yielded an approach to goal recognition that leverages analogy in its decision making. However, there is still much unknown about the potential and limitations of these approaches, especially with respect to one another. Here, we present an extension of the analogical approach to a novel algorithm, Refinement via Analogy for Goal Reasoning (RAGeR). We compare RAGeR to two state-of-the-art approaches which use planning and CCGs for goal recognition, respectively, along two different axes: reliability of observations and inspectability of the other agent&#39;s mental model. Overall, we show that no approach dominates across all cases and discuss the relative strengths and weaknesses of these approaches. Scientists interested in goal recognition problems can use this knowledge as a guide to select the correct starting point for their specific domains and tasks.},
  archive      = {J_FRAI},
  author       = {Rabkina, Irina and Kantharaju, Pavan and Wilson, Jason R. and Roberts, Mark and Hiatt, Laura M.},
  doi          = {10.3389/frai.2021.734521},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {734521},
  shortjournal = {Front. Artif. Intell.},
  title        = {Evaluation of goal recognition systems on unreliable data and uninspectable agents},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Language models explain word reading times better than
empirical predictability. <em>FRAI</em>, <em>4</em>, 730570. (<a
href="https://doi.org/10.3389/frai.2021.730570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though there is a strong consensus that word length and frequency are the most important single-word features determining visual-orthographic access to the mental lexicon, there is less agreement as how to best capture syntactic and semantic factors. The traditional approach in cognitive reading research assumes that word predictability from sentence context is best captured by cloze completion probability (CCP) derived from human performance data. We review recent research suggesting that probabilistic language models provide deeper explanations for syntactic and semantic effects than CCP. Then we compare CCP with three probabilistic language models for predicting word viewing times in an English and a German eye tracking sample: (1) Symbolic n-gram models consolidate syntactic and semantic short-range relations by computing the probability of a word to occur, given two preceding words. (2) Topic models rely on subsymbolic representations to capture long-range semantic similarity by word co-occurrence counts in documents. (3) In recurrent neural networks (RNNs), the subsymbolic units are trained to predict the next word, given all preceding words in the sentences. To examine lexical retrieval, these models were used to predict single fixation durations and gaze durations to capture rapidly successful and standard lexical access, and total viewing time to capture late semantic integration. The linear item-level analyses showed greater correlations of all language models with all eye-movement measures than CCP. Then we examined non-linear relations between the different types of predictability and the reading times using generalized additive models. N-gram and RNN probabilities of the present word more consistently predicted reading performance compared with topic models or CCP. For the effects of last-word probability on current-word viewing times, we obtained the best results with n-gram models. Such count-based models seem to best capture short-range access that is still underway when the eyes move on to the subsequent word. The prediction-trained RNN models, in contrast, better predicted early preprocessing of the next word. In sum, our results demonstrate that the different language models account for differential cognitive processes during reading. We discuss these algorithmically concrete blueprints of lexical consolidation as theoretically deep explanations for human reading.},
  archive      = {J_FRAI},
  author       = {Hofmann, Markus J. and Remus, Steffen and Biemann, Chris and Radach, Ralph and Kuchinke, Lars},
  doi          = {10.3389/frai.2021.730570},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {730570},
  shortjournal = {Front. Artif. Intell.},
  title        = {Language models explain word reading times better than empirical predictability},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling speaker attribution in narrative texts with biased
and bias-adjustable neural networks. <em>FRAI</em>, <em>4</em>, 725321.
(<a href="https://doi.org/10.3389/frai.2021.725321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Literary narratives regularly contain passages that different readers attribute to different speakers: a character, the narrator, or the author. Since literary narratives are highly ambiguous constructs, it is often impossible to decide between diverging attributions of a specific passage by hermeneutic means. Instead, we hypothesise that attribution decisions are often influenced by annotator bias, in particular an annotator&#39;s literary preferences and beliefs. We present first results on the correlation between the literary attitudes of an annotator and their attribution choices. In a second set of experiments, we present a neural classifier that is capable of imitating individual annotators as well as a common-sense annotator, and reaches accuracies of up to 88% (which improves the majority baseline by 23%).},
  archive      = {J_FRAI},
  author       = {Dönicke, Tillmann and Varachkina, Hanna and Weimer, Anna Mareike and Gödeke, Luisa and Barth, Florian and Gittel, Benjamin and Holler, Anke and Sporleder, Caroline},
  doi          = {10.3389/frai.2021.725321},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {725321},
  shortjournal = {Front. Artif. Intell.},
  title        = {Modelling speaker attribution in narrative texts with biased and bias-adjustable neural networks},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Models of intervention: Helping agents and human users avoid
undesirable outcomes. <em>FRAI</em>, <em>4</em>, 723936. (<a
href="https://doi.org/10.3389/frai.2021.723936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When working in an unfamiliar online environment, it can be helpful to have an observer that can intervene and guide a user toward a desirable outcome while avoiding undesirable outcomes or frustration. The Intervention Problem is deciding when to intervene in order to help a user. The Intervention Problem is similar to, but distinct from, Plan Recognition because the observer must not only recognize the intended goals of a user but also when to intervene to help the user when necessary. We formalize a family of Intervention Problems and show that how these problems can be solved using a combination of Plan Recognition methods and classification algorithms to decide whether to intervene. For our benchmarks, the classification algorithms dominate three recent Plan Recognition approaches. We then generalize these results to Human-Aware Intervention, where the observer must decide in real time whether to intervene human users solving a cognitively engaging puzzle. Using a revised feature set more appropriate to human behavior, we produce a learned model to recognize when a human user is about to trigger an undesirable outcome. We perform a human-subject study to evaluate the Human-Aware Intervention. We find that the revised model also dominates existing Plan Recognition algorithms in predicting Human-Aware Intervention.},
  archive      = {J_FRAI},
  author       = {Weerawardhana, Sachini and Whitley, Darrell and Roberts, Mark},
  doi          = {10.3389/frai.2021.723936},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {723936},
  shortjournal = {Front. Artif. Intell.},
  title        = {Models of intervention: Helping agents and human users avoid undesirable outcomes},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic integration of multi-modal data and derived
neuroimaging results using the platform for imaging in precision
medicine (PRISM) in the arkansas imaging enterprise system (ARIES).
<em>FRAI</em>, <em>4</em>, 649970. (<a
href="https://doi.org/10.3389/frai.2021.649970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroimaging is among the most active research domains for the creation and management of open-access data repositories. Notably lacking from most data repositories are integrated capabilities for semantic representation. The Arkansas Imaging Enterprise System (ARIES) is a research data management system which features integrated capabilities to support semantic representations of multi-modal data from disparate sources (imaging, behavioral, or cognitive assessments), across common image-processing stages (preprocessing steps, segmentation schemes, analytic pipelines), as well as derived results (publishable findings). These unique capabilities ensure greater reproducibility of scientific findings across large-scale research projects. The current investigation was conducted with three collaborating teams who are using ARIES in a project focusing on neurodegeneration. Datasets included magnetic resonance imaging (MRI) data as well as non-imaging data obtained from a variety of assessments designed to measure neurocognitive functions (performance scores on neuropsychological tests). We integrate and manage these data with semantic representations based on axiomatically rich biomedical ontologies. These instantiate a knowledge graph that combines the data from the study cohorts into a shared semantic representation that explicitly accounts for relations among the entities that the data are about. This knowledge graph is stored in a triple-store database that supports reasoning over and querying these integrated data. Semantic integration of the non-imaging data using background information encoded in biomedical domain ontologies has served as a key feature-engineering step, allowing us to combine disparate data and apply analyses to explore associations, for instance, between hippocampal volumes and measures of cognitive functions derived from various assessment instruments.},
  archive      = {J_FRAI},
  author       = {Bona, Jonathan and Kemp, Aaron S. and Cox, Carli and Nolan, Tracy S. and Pillai, Lakshmi and Das, Aparna and Galvin, James E. and Larson-Prior, Linda and Virmani, Tuhin and Prior, Fred},
  doi          = {10.3389/frai.2021.649970},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {649970},
  shortjournal = {Front. Artif. Intell.},
  title        = {Semantic integration of multi-modal data and derived neuroimaging results using the platform for imaging in precision medicine (PRISM) in the arkansas imaging enterprise system (ARIES)},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development and validation of manually modified and
supervised machine learning clinical assessment algorithms for malaria
in nigerian children. <em>FRAI</em>, <em>4</em>, 554017. (<a
href="https://doi.org/10.3389/frai.2021.554017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is currently estimated that 67% of malaria deaths occur in children under-five years (WHO, 2020). To improve the identification of children at clinical risk for malaria, the WHO developed community (iCCM) and clinic-based (IMCI) protocols for frontline health workers using paper-based forms or digital mobile health (mHealth) platforms. To investigate improving the accuracy of these point-of-care clinical risk assessment protocols for malaria in febrile children, we embedded a malaria rapid diagnostic test (mRDT) workflow into THINKMD’s (IMCI) mHealth clinical risk assessment platform. This allowed us to perform a comparative analysis of THINKMD-generated malaria risk assessments with mRDT truth data to guide modification of THINKMD algorithms, as well as develop new supervised machine learning (ML) malaria risk algorithms. We utilized paired clinical data and malaria risk assessments acquired from over 555 children presenting to five health clinics in Kano, Nigeria to train ML algorithms to identify malaria cases using symptom and location data, as well as confirmatory mRDT results. Supervised ML random forest algorithms were generated using 80% of our field-based data as the ML training set and 20% to test our new ML logic. New ML-based malaria algorithms showed an increased sensitivity and specificity of 60 and 79%, and PPV and NPV of 76 and 65%, respectively over THINKD initial IMCI-based algorithms. These results demonstrate that combining mRDT “truth” data with digital mHealth platform clinical assessments and clinical data can improve identification of children with malaria/non-malaria attributable febrile illnesses.},
  archive      = {J_FRAI},
  author       = {McLaughlin, Megan and Pellé, Karell G. and Scarpino, Samuel V. and Giwa, Aisha and Mount-Finette, Ezra and Haidar, Nada and Adamu, Fatima and Ravi, Nirmal and Thompson, Adam and Heath, Barry and Dittrich, Sabine and Finette, Barry},
  doi          = {10.3389/frai.2021.554017},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {2},
  pages        = {554017},
  shortjournal = {Front. Artif. Intell.},
  title        = {Development and validation of manually modified and supervised machine learning clinical assessment algorithms for malaria in nigerian children},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Artificial intelligence for precision medicine.
<em>FRAI</em>, <em>4</em>, 834645. (<a
href="https://doi.org/10.3389/frai.2021.834645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FRAI},
  author       = {Deng, Jun and Hartung, Thomas and Capobianco, Enrico and Chen, Jake Y. and Emmert-Streib, Frank},
  doi          = {10.3389/frai.2021.834645},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {834645},
  shortjournal = {Front. Artif. Intell.},
  title        = {Editorial: Artificial intelligence for precision medicine},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Convolutional neural network-based technique for gaze
estimation on mobile devices. <em>FRAI</em>, <em>4</em>, 796825. (<a
href="https://doi.org/10.3389/frai.2021.796825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye tracking is becoming a very popular, useful, and important technology. Many eye tracking technologies are currently expensive and only available to large corporations. Some of them necessitate explicit personal calibration, which makes them unsuitable for use in real-world or uncontrolled environments. Explicit personal calibration can also be cumbersome and degrades the user experience. To address these issues, this study proposes a Convolutional Neural Network (CNN) based calibration-free technique for improved gaze estimation in unconstrained environments. The proposed technique consists of two components, namely a face component and a 39-point facial landmark component. The face component is used to extract the gaze estimation features from the eyes, while the 39-point facial landmark component is used to encode the shape and location of the eyes (within the face) into the network. Adding this information can make the network learn free-head and eye movements. Another CNN model was designed in this study primarily for the sake of comparison. The CNN model accepts only the face images as input. Different experiments were performed, and the experimental result reveals that the proposed technique outperforms the second model. Fine-tuning was also performed using the VGG16 pre-trained model. Experimental results show that the fine-tuned results of the proposed technique perform better than the fine-tuned results of the second model. Overall, the results show that 39-point facial landmarks can be used to improve the performance of CNN-based gaze estimation models.},
  archive      = {J_FRAI},
  author       = {Akinyelu, Andronicus A. and Blignaut, Pieter},
  doi          = {10.3389/frai.2021.796825},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {796825},
  shortjournal = {Front. Artif. Intell.},
  title        = {Convolutional neural network-based technique for gaze estimation on mobile devices},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmenting semantic lexicons using word embeddings and
transfer learning. <em>FRAI</em>, <em>4</em>, 783778. (<a
href="https://doi.org/10.3389/frai.2021.783778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment-aware intelligent systems are essential to a wide array of applications. These systems are driven by language models which broadly fall into two paradigms: Lexicon-based and contextual. Although recent contextual models are increasingly dominant, we still see demand for lexicon-based models because of their interpretability and ease of use. For example, lexicon-based models allow researchers to readily determine which words and phrases contribute most to a change in measured sentiment. A challenge for any lexicon-based approach is that the lexicon needs to be routinely expanded with new words and expressions. Here, we propose two models for automatic lexicon expansion. Our first model establishes a baseline employing a simple and shallow neural network initialized with pre-trained word embeddings using a non-contextual approach. Our second model improves upon our baseline, featuring a deep Transformer-based network that brings to bear word definitions to estimate their lexical polarity. Our evaluation shows that both models are able to score new words with a similar accuracy to reviewers from Amazon Mechanical Turk, but at a fraction of the cost.},
  archive      = {J_FRAI},
  author       = {Alshaabi, Thayer and Van Oort, Colin M. and Fudolig, Mikaela Irene and Arnold, Michael V. and Danforth, Christopher M. and Dodds, Peter Sheridan},
  doi          = {10.3389/frai.2021.783778},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {783778},
  shortjournal = {Front. Artif. Intell.},
  title        = {Augmenting semantic lexicons using word embeddings and transfer learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SpatialSim: Recognizing spatial configurations of objects
with graph neural networks. <em>FRAI</em>, <em>4</em>, 782081. (<a
href="https://doi.org/10.3389/frai.2021.782081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An embodied, autonomous agent able to set its own goals has to possess geometrical reasoning abilities for judging whether its goals have been achieved, namely it should be able to identify and discriminate classes of configurations of objects, irrespective of its point of view on the scene. However, this problem has received little attention so far in the deep learning literature. In this paper we make two key contributions. First, we propose SpatialSim (Spatial Similarity), a novel geometrical reasoning diagnostic dataset, and argue that progress on this benchmark would allow for diagnosing more principled approaches to this problem. This benchmark is composed of two tasks: “Identification” and “Discrimination,” each one instantiated in increasing levels of difficulty. Secondly, we validate that relational inductive biases—exhibited by fully-connected message-passing Graph Neural Networks (MPGNNs)—are instrumental to solve those tasks, and show their advantages over less relational baselines such as Deep Sets and unstructured models such as Multi-Layer Perceptrons. We additionally showcase the failure of high-capacity CNNs on the hard Discrimination task. Finally, we highlight the current limits of GNNs in both tasks.},
  archive      = {J_FRAI},
  author       = {Teodorescu, Laetitia and Hofmann, Katja and Oudeyer, Pierre-Yves},
  doi          = {10.3389/frai.2021.782081},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {782081},
  shortjournal = {Front. Artif. Intell.},
  title        = {SpatialSim: Recognizing spatial configurations of objects with graph neural networks},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarially robust learning via entropic regularization.
<em>FRAI</em>, <em>4</em>, 780843. (<a
href="https://doi.org/10.3389/frai.2021.780843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new family of algorithms, ATENT, for training adversarially robust deep neural networks. We formulate a new loss function that is equipped with an additional entropic regularization. Our loss function considers the contribution of adversarial samples that are drawn from a specially designed distribution in the data space that assigns high probability to points with high loss and in the immediate neighborhood of training samples. Our proposed algorithms optimize this loss to seek adversarially robust valleys of the loss landscape. Our approach achieves competitive (or better) performance in terms of robust classification accuracy as compared to several state-of-the-art robust learning approaches on benchmark datasets such as MNIST and CIFAR-10.},
  archive      = {J_FRAI},
  author       = {Jagatap, Gauri and Joshi, Ameya and Chowdhury, Animesh Basak and Garg, Siddharth and Hegde, Chinmay},
  doi          = {10.3389/frai.2021.780843},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {780843},
  shortjournal = {Front. Artif. Intell.},
  title        = {Adversarially robust learning via entropic regularization},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Remarks on multimodality: Grammatical interactions in the
parallel architecture. <em>FRAI</em>, <em>4</em>, 778060. (<a
href="https://doi.org/10.3389/frai.2021.778060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language is typically embedded in multimodal communication, yet models of linguistic competence do not often incorporate this complexity. Meanwhile, speech, gesture, and/or pictures are each considered as indivisible components of multimodal messages. Here, we argue that multimodality should not be characterized by whole interacting behaviors, but by interactions of similar substructures which permeate across expressive behaviors. These structures comprise a unified architecture and align within Jackendoff&#39;s Parallel Architecture: a modality, meaning, and grammar. Because this tripartite architecture persists across modalities, interactions can manifest within each of these substructures. Interactions between modalities alone create correspondences in time (ex. speech with gesture) or space (ex. writing with pictures) of the sensory signals, while multimodal meaning-making balances how modalities carry “semantic weight” for the gist of the whole expression. Here we focus primarily on interactions between grammars, which contrast across two variables: symmetry, related to the complexity of the grammars, and allocation, related to the relative independence of interacting grammars. While independent allocations keep grammars separate, substitutive allocation inserts expressions from one grammar into those of another. We show that substitution operates in interactions between all three natural modalities (vocal, bodily, graphic), and also in unimodal contexts within and between languages, as in codeswitching. Altogether, we argue that unimodal and multimodal expressions arise as emergent interactive states from a unified cognitive architecture, heralding a reconsideration of the “language faculty” itself.},
  archive      = {J_FRAI},
  author       = {Cohn, Neil and Schilperoord, Joost},
  doi          = {10.3389/frai.2021.778060},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {778060},
  shortjournal = {Front. Artif. Intell.},
  title        = {Remarks on multimodality: Grammatical interactions in the parallel architecture},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantum propensity in economics. <em>FRAI</em>, <em>4</em>,
772294. (<a href="https://doi.org/10.3389/frai.2021.772294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes an approach to economics that is inspired by quantum computing, and is motivated by the need to develop a consistent quantum mathematical framework for economics. The traditional neoclassical approach assumes that rational utility-optimisers drive market prices to a stable equilibrium, subject to external perturbations or market failures. While this approach has been highly influential, it has come under increasing criticism following the financial crisis of 2007/8. The quantum approach, in contrast, is inherently probabilistic and dynamic. Decision-makers are described, not by a utility function, but by a propensity function which specifies the probability of transacting. We show how a number of cognitive phenomena such as preference reversal and the disjunction effect can be modelled by using a simple quantum circuit to generate an appropriate propensity function. Conversely, a general propensity function can be quantized, via an entropic force, to incorporate effects such as interference and entanglement that characterise human decision-making. Applications to some common problems and topics in economics and finance, including the use of quantum artificial intelligence, are discussed.},
  archive      = {J_FRAI},
  author       = {Orrell, David and Houshmand, Monireh},
  doi          = {10.3389/frai.2021.772294},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {772294},
  shortjournal = {Front. Artif. Intell.},
  title        = {Quantum propensity in economics},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kernel conversion for robust quantitative measurements of
archived chest computed tomography using deep learning-based
image-to-image translation. <em>FRAI</em>, <em>4</em>, 769557. (<a
href="https://doi.org/10.3389/frai.2021.769557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest computed tomography (CT) is used to screen for lung cancer and evaluate pulmonary and extra-pulmonary abnormalities such as emphysema and coronary artery calcification, particularly in smokers. In real-world practice, lung abnormalities are visually assessed using high-contrast thin-slice images which are generated from raw scan data using sharp reconstruction kernels with the sacrifice of increased image noise. In contrast, accurate CT quantification requires low-contrast thin-slice images with low noise, which are generated using soft reconstruction kernels. However, only sharp-kernel thin-slice images are archived in many medical facilities due to limited data storage space. This study aimed to establish deep neural network (DNN) models to convert sharp-kernel images to soft-kernel-like images with a final goal to reuse historical chest CT images for robust quantitative measurements, particularly in completed previous longitudinal studies. By using pairs of sharp-kernel (input) and soft-kernel (ground-truth) images from 30 patients with chronic obstructive pulmonary disease (COPD), DNN models were trained. Then, the accuracy of kernel conversion based on the established DNN models was evaluated using CT from independent 30 smokers with and without COPD. Consequently, differences in CT values between new images converted from sharp-kernel images using the established DNN models and ground-truth soft-kernel images were comparable with the inter-scans variability derived from repeated phantom scans (6 times), showing that the conversion error was the same level as the measurement error of the CT device. Moreover, the Dice coefficients to quantify the similarity between low attenuation voxels on given images and the ground-truth soft-kernel images were significantly higher on the DNN-converted images than the Gaussian-filtered, median-filtered, and sharp-kernel images (p &amp;lt; 0.001). There were good agreements in quantitative measurements of emphysema, intramuscular adipose tissue, and coronary artery calcification between the converted and the ground-truth soft-kernel images. These findings demonstrate the validity of the new DNN model for kernel conversion and the clinical applicability of soft-kernel-like images converted from archived sharp-kernel images in previous clinical studies. The presented method to evaluate the validity of the established DNN model using repeated scans of phantom could be applied to various deep learning-based image conversions for robust quantitative evaluation.},
  archive      = {J_FRAI},
  author       = {Tanabe, Naoya and Kaji, Shizuo and Shima, Hiroshi and Shiraishi, Yusuke and Maetani, Tomoki and Oguma, Tsuyoshi and Sato, Susumu and Hirai, Toyohiro},
  doi          = {10.3389/frai.2021.769557},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {769557},
  shortjournal = {Front. Artif. Intell.},
  title        = {Kernel conversion for robust quantitative measurements of archived chest computed tomography using deep learning-based image-to-image translation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The role of self-improving tutoring systems in fostering
pre-service teacher self-regulated learning. <em>FRAI</em>, <em>4</em>,
769455. (<a href="https://doi.org/10.3389/frai.2021.769455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-based learning environments serve as a valuable asset to help strengthen teacher preparation and preservice teacher self-regulated learning. One of the most important advantages is the opportunity to collect ambient data unobtrusively as observable indicators of cognitive, affective, metacognitive, and motivational processes that mediate learning and performance. Ambient data refers to teacher interactions with the user interface that include but are not limited to timestamped clickstream data, keystroke and navigation events, as well as document views. We review the claim that computers designed as metacognitive tools can leverage the data to serve not only teachers in attaining the aims of instruction, but also researchers in gaining insights into teacher professional development. In our presentation of this claim, we review the current state of research and development of a network-based tutoring system called nBrowser, designed to support teacher instructional planning and technology integration. Network-based tutors are self-improving systems that continually adjust instructional decision-making based on the collective behaviors of communities of learners. A large part of the artificial intelligence resides in semantic web mining, natural language processing, and network algorithms. We discuss the implications of our findings to advance research into preservice teacher self-regulated learning.},
  archive      = {J_FRAI},
  author       = {Huang, Lingyun and Dias, Laurel and Nelson, Elizabeth and Liang, Lauren and Lajoie, Susanne P. and Poitras, Eric G.},
  doi          = {10.3389/frai.2021.769455},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {769455},
  shortjournal = {Front. Artif. Intell.},
  title        = {The role of self-improving tutoring systems in fostering pre-service teacher self-regulated learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of e. Coli concentrations in agricultural pond
waters: Application and comparison of machine learning algorithms.
<em>FRAI</em>, <em>4</em>, 768650. (<a
href="https://doi.org/10.3389/frai.2021.768650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The microbial quality of irrigation water is an important issue as the use of contaminated waters has been linked to several foodborne outbreaks. To expedite microbial water quality determinations, many researchers estimate concentrations of the microbial contamination indicator Escherichia coli (E. coli) from the concentrations of physiochemical water quality parameters. However, these relationships are often non-linear and exhibit changes above or below certain threshold values. Machine learning (ML) algorithms have been shown to make accurate predictions in datasets with complex relationships. The purpose of this work was to evaluate several ML models for the prediction of E. coli in agricultural pond waters. Two ponds in Maryland were monitored from 2016 to 2018 during the irrigation season. E. coli concentrations along with 12 other water quality parameters were measured in water samples. The resulting datasets were used to predict E. coli using stochastic gradient boosting (SGB) machines, random forest (RF), support vector machines (SVM), and k-nearest neighbor (kNN) algorithms. The RF model provided the lowest RMSE value for predicted E. coli concentrations in both ponds in individual years and over consecutive years in almost all cases. For individual years, the RMSE of the predicted E. coli concentrations (log10 CFU 100 ml−1) ranged from 0.244 to 0.346 and 0.304 to 0.418 for Pond 1 and 2, respectively. For the 3-year datasets, these values were 0.334 and 0.381 for Pond 1 and 2, respectively. In most cases there was no significant difference (P &amp;gt; 0.05) between the RMSE of RF and other ML models when these RMSE were treated as statistics derived from 10-fold cross-validation performed with five repeats. Important E. coli predictors were turbidity, dissolved organic matter content, specific conductance, chlorophyll concentration, and temperature. Model predictive performance did not significantly differ when 5 predictors were used vs. 8 or 12, indicating that more tedious and costly measurements provide no substantial improvement in the predictive accuracy of the evaluated algorithms.},
  archive      = {J_FRAI},
  author       = {Stocker, Matthew D. and Pachepsky, Yakov A. and Hill, Robert L.},
  doi          = {10.3389/frai.2021.768650},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {768650},
  shortjournal = {Front. Artif. Intell.},
  title        = {Prediction of e. coli concentrations in agricultural pond waters: Application and comparison of machine learning algorithms},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving adversarial robustness via attention and
adversarial logit pairing. <em>FRAI</em>, <em>4</em>, 752831. (<a
href="https://doi.org/10.3389/frai.2021.752831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though deep neural networks have achieved the state of the art performance in visual classification, recent studies have shown that they are all vulnerable to the attack of adversarial examples. In this paper, we develop improved techniques for defending against adversarial examples. First, we propose an enhanced defense technique denoted Attention and Adversarial Logit Pairing (AT + ALP), which encourages both attention map and logit for the pairs of examples to be similar. When being applied to clean examples and their adversarial counterparts, AT + ALP improves accuracy on adversarial examples over adversarial training. We show that AT + ALP can effectively increase the average activations of adversarial examples in the key area and demonstrate that it focuses on discriminate features to improve the robustness of the model. Finally, we conduct extensive experiments using a wide range of datasets and the experiment results show that our AT + ALP achieves the state of the art defense performance. For example, on 17 Flower Category Database, under strong 200-iteration Projected Gradient Descent (PGD) gray-box and black-box attacks where prior art has 34 and 39% accuracy, our method achieves 50 and 51%. Compared with previous work, our work is evaluated under highly challenging PGD attack: the maximum perturbation ϵ ∈ {0.25, 0.5} i.e. L∞ ∈ {0.25, 0.5} with 10–200 attack iterations. To the best of our knowledge, such a strong attack has not been previously explored on a wide range of datasets.},
  archive      = {J_FRAI},
  author       = {Li, Xingjian and Goodman, Dou and Liu, Ji and Wei, Tao and Dou, Dejing},
  doi          = {10.3389/frai.2021.752831},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {752831},
  shortjournal = {Front. Artif. Intell.},
  title        = {Improving adversarial robustness via attention and adversarial logit pairing},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving robotic hand prosthesis control with eye tracking
and computer vision: A multimodal approach based on the visuomotor
behavior of grasping. <em>FRAI</em>, <em>4</em>, 744476. (<a
href="https://doi.org/10.3389/frai.2021.744476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and dexterity of the human hand make the development of natural and robust control of hand prostheses challenging. Although a large number of control approaches were developed and investigated in the last decades, limited robustness in real-life conditions often prevented their application in clinical settings and in commercial products. In this paper, we investigate a multimodal approach that exploits the use of eye-hand coordination to improve the control of myoelectric hand prostheses. The analyzed data are from the publicly available MeganePro Dataset 1, that includes multimodal data from transradial amputees and able-bodied subjects while grasping numerous household objects with ten grasp types. A continuous grasp-type classification based on surface electromyography served as both intent detector and classifier. At the same time, the information provided by eye-hand coordination parameters, gaze data and object recognition in first-person videos allowed to identify the object a person aims to grasp. The results show that the inclusion of visual information significantly increases the average offline classification accuracy by up to 15.61 ± 4.22% for the transradial amputees and of up to 7.37 ± 3.52% for the able-bodied subjects, allowing trans-radial amputees to reach average classification accuracy comparable to intact subjects and suggesting that the robustness of hand prosthesis control based on grasp-type recognition can be significantly improved with the inclusion of visual information extracted by leveraging natural eye-hand coordination behavior and without placing additional cognitive burden on the user.},
  archive      = {J_FRAI},
  author       = {Cognolato, Matteo and Atzori, Manfredo and Gassert, Roger and Müller, Henning},
  doi          = {10.3389/frai.2021.744476},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {744476},
  shortjournal = {Front. Artif. Intell.},
  title        = {Improving robotic hand prosthesis control with eye tracking and computer vision: A multimodal approach based on the visuomotor behavior of grasping},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Co-inference of data mislabelings reveals improved models in
genomics and breast cancer diagnostics. <em>FRAI</em>, <em>4</em>,
739432. (<a href="https://doi.org/10.3389/frai.2021.739432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mislabeling of cases as well as controls in case–control studies is a frequent source of strong bias in prognostic and diagnostic tests and algorithms. Common data processing methods available to the researchers in the biomedical community do not allow for consistent and robust treatment of labeled data in the situations where both, the case and the control groups, contain a non-negligible proportion of mislabeled data instances. This is an especially prominent issue in studies regarding late-onset conditions, where individuals who may convert to cases may populate the control group, and for screening studies that often have high false-positive/-negative rates. To address this problem, we propose a method for a simultaneous robust inference of Lasso reduced discriminative models and of latent group-specific mislabeling risks, not requiring any exactly labeled data. We apply it to a standard breast cancer imaging dataset and infer the mislabeling probabilities (being rates of false-negative and false-positive core-needle biopsies) together with a small set of simple diagnostic rules, outperforming the state-of-the-art BI-RADS diagnostics on these data. The inferred mislabeling rates for breast cancer biopsies agree with the published purely empirical studies. Applying the method to human genomic data from a healthy-ageing cohort reveals a previously unreported compact combination of single-nucleotide polymorphisms that are strongly associated with a healthy-ageing phenotype for Caucasians. It determines that 7.5% of Caucasians in the 1000 Genomes dataset (selected as a control group) carry a pattern characteristic of healthy ageing.},
  archive      = {J_FRAI},
  author       = {Gerber, Susanne and Pospisil, Lukas and Sys, Stanislav and Hewel, Charlotte and Torkamani, Ali and Horenko, Illia},
  doi          = {10.3389/frai.2021.739432},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {739432},
  shortjournal = {Front. Artif. Intell.},
  title        = {Co-inference of data mislabelings reveals improved models in genomics and breast cancer diagnostics},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards computational modeling of human goal recognition.
<em>FRAI</em>, <em>4</em>, 737327. (<a
href="https://doi.org/10.3389/frai.2021.737327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, we are seeing the emergence of plan- and goal-recognition algorithms which are based on the principle of rationality. These avoid the use of a plan library that compactly encodes all possible observable plans, and instead generate plans dynamically to match the observations. However, recent experiments by Berkovitz (Berkovitz, The effect of spatial cognition and context on robot movement legibility in human-robot collaboration, 2018) show that in many cases, humans seem to have reached quick (correct) decisions when observing motions which were far from rational (optimal), while optimal motions were slower to be recognized. Intrigued by these findings, we experimented with a variety of rationality-based recognition algorithms on the same data. The results clearly show that none of the algorithms reported in the literature accounts for human subject decisions, even in this simple task. This is our first contribution. We hypothesize that humans utilize plan-recognition in service of goal recognition, i.e., match observations to known plans, and use the set of recognized plans to conclude as to the likely goals. To test this hypothesis, a second contribution in this paper is the introduction of a novel offline recognition algorithm. While preliminary, the algorithm accounts for the results reported by Berkovitz significantly better than the existing algorithms. Moreover, the proposed algorithm marries rationality-based and plan-library based methods seamlessly.},
  archive      = {J_FRAI},
  author       = {Treger, Shify and Kaminka, Gal A.},
  doi          = {10.3389/frai.2021.737327},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {737327},
  shortjournal = {Front. Artif. Intell.},
  title        = {Towards computational modeling of human goal recognition},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Backpropagation-based decoding for multimodal machine
translation. <em>FRAI</em>, <em>4</em>, 736722. (<a
href="https://doi.org/10.3389/frai.2021.736722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People are able to describe images using thousands of languages, but languages share only one visual world. The aim of this work is to use the learned intermediate visual representations from a deep convolutional neural network to transfer information across languages for which paired data is not available in any form. Our work proposes using backpropagation-based decoding coupled with transformer-based multilingual-multimodal language models in order to obtain translations between any languages used during training. We particularly show the capabilities of this approach in the translation of German-Japanese and Japanese-German sentence pairs, given a training data of images freely associated with text in English, German, and Japanese but for which no single image contains annotations in both Japanese and German. Moreover, we demonstrate that our approach is also generally useful in the multilingual image captioning task when sentences in a second language are available at test time. The results of our method also compare favorably in the Multi30k dataset against recently proposed methods that are also aiming to leverage images as an intermediate source of translations.},
  archive      = {J_FRAI},
  author       = {Yang, Ziyan and Pinto-Alva, Leticia and Dernoncourt, Franck and Ordonez, Vicente},
  doi          = {10.3389/frai.2021.736722},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {736722},
  shortjournal = {Front. Artif. Intell.},
  title        = {Backpropagation-based decoding for multimodal machine translation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparing plan recognition algorithms through standard plan
libraries. <em>FRAI</em>, <em>4</em>, 732177. (<a
href="https://doi.org/10.3389/frai.2021.732177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plan recognition deals with reasoning about the goals and execution process of an actor, given observations of its actions. It is one of the fundamental problems of AI, applicable to many domains, from user interfaces to cyber-security. Despite the prevalence of these approaches, they lack a standard representation, and have not been compared using a common testbed. This paper provides a first step towards bridging this gap by providing a standard plan library representation that can be used by hierarchical, discrete-space plan recognition and evaluation criteria to consider when comparing plan recognition algorithms. This representation is comprehensive enough to describe a variety of known plan recognition problems and can be easily used by existing algorithms in this class. We use this common representation to thoroughly compare two known approaches, represented by two algorithms, SBR and Probabilistic Hostile Agent Task Tracker (PHATT). We provide meaningful insights about the differences and abilities of these algorithms, and evaluate these insights both theoretically and empirically. We show a tradeoff between expressiveness and efficiency: SBR is usually superior to PHATT in terms of computation time and space, but at the expense of functionality and representational compactness. We also show how different properties of the plan library affect the complexity of the recognition process, regardless of the concrete algorithm used. Lastly, we show how these insights can be used to form a new algorithm that outperforms existing approaches both in terms of expressiveness and efficiency.},
  archive      = {J_FRAI},
  author       = {Mirsky, Reuth and Galun, Ran and Gal, Kobi and Kaminka, Gal},
  doi          = {10.3389/frai.2021.732177},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {732177},
  shortjournal = {Front. Artif. Intell.},
  title        = {Comparing plan recognition algorithms through standard plan libraries},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning based superconducting radio-frequency cavity
fault classification at jefferson laboratory. <em>FRAI</em>, <em>4</em>,
718950. (<a href="https://doi.org/10.3389/frai.2021.718950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the efficacy of deep learning (DL) for classifying C100 superconducting radio-frequency (SRF) cavity faults in the Continuous Electron Beam Accelerator Facility (CEBAF) at Jefferson Lab. CEBAF is a large, high-power continuous wave recirculating linac that utilizes 418 SRF cavities to accelerate electrons up to 12 GeV. Recent upgrades to CEBAF include installation of 11 new cryomodules (88 cavities) equipped with a low-level RF system that records RF time-series data from each cavity at the onset of an RF failure. Typically, subject matter experts (SME) analyze this data to determine the fault type and identify the cavity of origin. This information is subsequently utilized to identify failure trends and to implement corrective measures on the offending cavity. Manual inspection of large-scale, time-series data, generated by frequent system failures is tedious and time consuming, and thereby motivates the use of machine learning (ML) to automate the task. This study extends work on a previously developed system based on traditional ML methods (Tennant and Carpenter and Powers and Shabalina Solopova and Vidyaratne and Iftekharuddin, Phys. Rev. Accel. Beams, 2020, 23, 114601), and investigates the effectiveness of deep learning approaches. The transition to a DL model is driven by the goal of developing a system with sufficiently fast inference that it could be used to predict a fault event and take actionable information before the onset (on the order of a few hundred milliseconds). Because features are learned, rather than explicitly computed, DL offers a potential advantage over traditional ML. Specifically, two seminal DL architecture types are explored: deep recurrent neural networks (RNN) and deep convolutional neural networks (CNN). We provide a detailed analysis on the performance of individual models using an RF waveform dataset built from past operational runs of CEBAF. In particular, the performance of RNN models incorporating long short-term memory (LSTM) are analyzed along with the CNN performance. Furthermore, comparing these DL models with a state-of-the-art fault ML model shows that DL architectures obtain similar performance for cavity identification, do not perform quite as well for fault classification, but provide an advantage in inference speed.},
  archive      = {J_FRAI},
  author       = {Vidyaratne, Lasitha and Carpenter, Adam and Powers, Tom and Tennant, Chris and Iftekharuddin, Khan M. and Rahman, Md Monibor and Shabalina, Anna S.},
  doi          = {10.3389/frai.2021.718950},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {718950},
  shortjournal = {Front. Artif. Intell.},
  title        = {Deep learning based superconducting radio-frequency cavity fault classification at jefferson laboratory},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Keep calm and do not carry-forward: Toward sensor-data
driven AI agent to enhance human learning. <em>FRAI</em>, <em>4</em>,
713176. (<a href="https://doi.org/10.3389/frai.2021.713176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Multimodal Data (MMD) and embodied learning systems (such as Motion Based Educational Games, MBEG), can help learning researchers to better understand the synergy between students&#39; interactions and their learning experiences. Unfolding the dynamics behind this important synergy can lead to the design of intelligent agents which leverage students&#39; movements and support their learning. However, real-time use of student-generated MMD derived from their interactions with embodied learning systems (MBEG in our case) is challenging and remains under-explored due to its complexity (e.g., handle sensor-data and enable an AI agent to use them). To bridge this gap, we conducted an in-situ study where 40 children, aged 9–12, played MBEG on maths and language development. We automatically, unobtrusively, and continuously monitored students&#39; experiences using eye-tracking glasses, physiological wristbands, and Kinect, during game-play. This allowed us to understand the different cognitive and physiological dimensions of students&#39; progress (right/wrong responses) during the three different stages of the MBEG problem-solving processes, namely the “see-solve-move-respond” (S2MR) cycle. We introduce the novel Carry Forward Effect (CFE); a phenomenon occurring in such games, whereby students propagate, or “carry forward,” the cognitive and physiological effects derived from their MMD, to subsequent phases in the see-solve-move-respond cycle. By identifying moments when the Carry Forward Effect is congruent (or not) to students&#39; learning performance, we uncover opportunities for feedback delivery to encourage or subdue the impact of the CFE. Our results demonstrate the importance of wristband and eye-tracking data as key indicators for prioritizing adaptive feedback to support students in MBEG and emphasize the significance of using MMD to support students&#39; performance in real-time educational settings.},
  archive      = {J_FRAI},
  author       = {Sharma, Kshitij and Lee-Cultura, Serena and Giannakos, Michail},
  doi          = {10.3389/frai.2021.713176},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {713176},
  shortjournal = {Front. Artif. Intell.},
  title        = {Keep calm and do not carry-forward: Toward sensor-data driven AI agent to enhance human learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). General-purpose bayesian tensor learning with automatic rank
determination and uncertainty quantification. <em>FRAI</em>, <em>4</em>,
668353. (<a href="https://doi.org/10.3389/frai.2021.668353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major challenge in many machine learning tasks is that the model expressive power depends on model size. Low-rank tensor methods are an efficient tool for handling the curse of dimensionality in many large-scale machine learning models. The major challenges in training a tensor learning model include how to process the high-volume data, how to determine the tensor rank automatically, and how to estimate the uncertainty of the results. While existing tensor learning focuses on a specific task, this paper proposes a generic Bayesian framework that can be employed to solve a broad class of tensor learning problems such as tensor completion, tensor regression, and tensorized neural networks. We develop a low-rank tensor prior for automatic rank determination in nonlinear problems. Our method is implemented with both stochastic gradient Hamiltonian Monte Carlo (SGHMC) and Stein Variational Gradient Descent (SVGD). We compare the automatic rank determination and uncertainty quantification of these two solvers. We demonstrate that our proposed method can determine the tensor rank automatically and can quantify the uncertainty of the obtained results. We validate our framework on tensor completion tasks and tensorized neural network training tasks.},
  archive      = {J_FRAI},
  author       = {Zhang, Kaiqi and Hawkins, Cole and Zhang, Zheng},
  doi          = {10.3389/frai.2021.668353},
  journal      = {Frontiers in Artificial Intelligence},
  month        = {1},
  pages        = {668353},
  shortjournal = {Front. Artif. Intell.},
  title        = {General-purpose bayesian tensor learning with automatic rank determination and uncertainty quantification},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
