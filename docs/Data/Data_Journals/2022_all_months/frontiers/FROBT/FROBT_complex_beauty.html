<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FROBT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frobt---394">FROBT - 394</h2>
<ul>
<li><details>
<summary>
(2022). Editorial: 4D printing and 3D printing in robotics, sensors,
and actuators manufacturing. <em>FROBT</em>, <em>9</em>, 1110571. (<a
href="https://doi.org/10.3389/frobt.2022.1110571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zolfagharian, Ali and Bodaghi, Mahdi and Le Duigou, Antoine},
  doi          = {10.3389/frobt.2022.1110571},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1110571},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: 4D printing and 3D printing in robotics, sensors, and actuators manufacturing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end jordanian dialect speech-to-text self-supervised
learning framework. <em>FROBT</em>, <em>9</em>, 1090012. (<a
href="https://doi.org/10.3389/frobt.2022.1090012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech-to-text engines are extremely needed nowadays for different applications, representing an essential enabler in human–robot interaction. Still, some languages suffer from the lack of labeled speech data, especially in the Arabic dialects or any low-resource languages. The need for a self-supervised training process and self-training using noisy training is proven to be one of the up-and-coming feasible solutions. This article proposes an end-to-end, transformers-based model with a framework for low-resource languages. In addition, the framework incorporates customized audio-to-text processing algorithms to achieve a highly efficient Jordanian Arabic dialect speech-to-text system. The proposed framework enables ingesting data from many sources, making the ground truth from external sources possible by speeding up the manual annotation process. The framework allows the training process using noisy student training and self-supervised learning to utilize the unlabeled data in both pre- and post-training stages and incorporate multiple types of data augmentation. The proposed self-training approach outperforms the fine-tuned Wav2Vec model by 5% in terms of word error rate reduction. The outcome of this work provides the research community with a Jordanian-spoken data set along with an end-to-end approach to deal with low-resource languages. This is done by utilizing the power of the pretraining, post-training, and injecting noisy labeled and augmented data with minimal human intervention. It enables the development of new applications in the field of Arabic language speech-to-text area like the question-answering systems and intelligent control systems, and it will add human-like perception and hearing sensors to intelligent robots.},
  archive      = {J_FROBT},
  author       = {Safieh, Ali A. and Alhaol, Ibrahim Abu and Ghnemat, Rawan},
  doi          = {10.3389/frobt.2022.1090012},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1090012},
  shortjournal = {Front. Robot. AI},
  title        = {End-to-end jordanian dialect speech-to-text self-supervised learning framework},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Future bio-inspired robots require delicate structures.
<em>FROBT</em>, <em>9</em>, 1073329. (<a
href="https://doi.org/10.3389/frobt.2022.1073329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ren, Ziyu and Shao, Yuxiu},
  doi          = {10.3389/frobt.2022.1073329},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1073329},
  shortjournal = {Front. Robot. AI},
  title        = {Future bio-inspired robots require delicate structures},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous detection and sorting of litter using deep
learning and soft robotic grippers. <em>FROBT</em>, <em>9</em>, 1064853.
(<a href="https://doi.org/10.3389/frobt.2022.1064853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road infrastructure is one of the most vital assets of any country. Keeping the road infrastructure clean and unpolluted is important for ensuring road safety and reducing environmental risk. However, roadside litter picking is an extremely laborious, expensive, monotonous and hazardous task. Automating the process would save taxpayers money and reduce the risk for road users and the maintenance crew. This work presents LitterBot, an autonomous robotic system capable of detecting, localizing and classifying common roadside litter. We use a learning-based object detection and segmentation algorithm trained on the TACO dataset for identifying and classifying garbage. We develop a robust modular manipulation framework by using soft robotic grippers and a real-time visual-servoing strategy. This enables the manipulator to pick up objects of variable sizes and shapes even in dynamic environments. The robot achieves greater than 80% classified picking and binning success rates for all experiments; which was validated on a wide variety of test litter objects in static single and cluttered configurations and with dynamically moving test objects. Our results showcase how a deep model trained on an online dataset can be deployed in real-world applications with high accuracy by the appropriate design of a control framework around it.},
  archive      = {J_FROBT},
  author       = {Almanzor, Elijah and Anvo, Nzebo Richard and Thuruthel, Thomas George and Iida, Fumiya},
  doi          = {10.3389/frobt.2022.1064853},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1064853},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous detection and sorting of litter using deep learning and soft robotic grippers},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Social human-robot interaction (sHRI) of
human-care service robots. <em>FROBT</em>, <em>9</em>, 1064440. (<a
href="https://doi.org/10.3389/frobt.2022.1064440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Jang, Minsu and Choi, JongSuk and Ahn, Ho Seok and Park, Chung Hyuk},
  doi          = {10.3389/frobt.2022.1064440},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1064440},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Social human-robot interaction (sHRI) of human-care service robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Embodied airflow sensing for improved in-gust flight of
flapping wing MAVs. <em>FROBT</em>, <em>9</em>, 1060933. (<a
href="https://doi.org/10.3389/frobt.2022.1060933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flapping wing micro aerial vehicles (FWMAVs) are known for their flight agility and maneuverability. These bio-inspired and lightweight flying robots still present limitations in their ability to fly in direct wind and gusts, as their stability is severely compromised in contrast with their biological counterparts. To this end, this work aims at making in-gust flight of flapping wing drones possible using an embodied airflow sensing approach combined with an adaptive control framework at the velocity and position control loops. At first, an extensive experimental campaign is conducted on a real FWMAV to generate a reliable and accurate model of the in-gust flight dynamics, which informs the design of the adaptive position and velocity controllers. With an extended experimental validation, this embodied airflow-sensing approach integrated with the adaptive controller reduces the root-mean-square errors along the wind direction by 25.15% when the drone is subject to frontal wind gusts of alternating speeds up to 2.4 m/s, compared to the case with a standard cascaded PID controller. The proposed sensing and control framework improve flight performance reliably and serve as the basis of future progress in the field of in-gust flight of lightweight FWMAVs.},
  archive      = {J_FROBT},
  author       = {Wang, Chenyao and Wang, Sunyi and De Croon, Guido and Hamaza, Salua},
  doi          = {10.3389/frobt.2022.1060933},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1060933},
  shortjournal = {Front. Robot. AI},
  title        = {Embodied airflow sensing for improved in-gust flight of flapping wing MAVs},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Drive competition underlies effective allostatic
orchestration. <em>FROBT</em>, <em>9</em>, 1052998. (<a
href="https://doi.org/10.3389/frobt.2022.1052998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Living systems ensure their fitness by self-regulating. The optimal matching of their behavior to the opportunities and demands of the ever-changing natural environment is crucial for satisfying physiological and cognitive needs. Although homeostasis has explained how organisms maintain their internal states within a desirable range, the problem of orchestrating different homeostatic systems has not been fully explained yet. In the present paper, we argue that attractor dynamics emerge from the competitive relation of internal drives, resulting in the effective regulation of adaptive behaviors. To test this hypothesis, we develop a biologically-grounded attractor model of allostatic orchestration that is embedded into a synthetic agent. Results show that the resultant neural mass model allows the agent to reproduce the navigational patterns of a rodent in an open field. Moreover, when exploring the robustness of our model in a dynamically changing environment, the synthetic agent pursues the stability of the self, being its internal states dependent on environmental opportunities to satisfy its needs. Finally, we elaborate on the benefits of resetting the model’s dynamics after drive-completion behaviors. Altogether, our studies suggest that the neural mass allostatic model adequately reproduces self-regulatory dynamics while overcoming the limitations of previous models.},
  archive      = {J_FROBT},
  author       = {Rosado, Oscar Guerrero and Amil, Adrian F. and Freire, Ismael T. and Verschure, Paul F. M. J.},
  doi          = {10.3389/frobt.2022.1052998},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1052998},
  shortjournal = {Front. Robot. AI},
  title        = {Drive competition underlies effective allostatic orchestration},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Additively manufactured unimorph dielectric elastomer
actuators: Design, materials, and fabrication. <em>FROBT</em>,
<em>9</em>, 1034914. (<a
href="https://doi.org/10.3389/frobt.2022.1034914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dielectric elastomer actuator (DEA) is a smart material that holds promise for soft robotics due to the material’s intrinsic softness, high energy density, fast response, and reversible electromechanical characteristics. Like for most soft robotics materials, additive manufacturing (AM) can significantly benefit DEAs and is mainly applied to the unimorph DEA (UDEA) configuration. While major aspects of UDEA modeling are known, 3D printed UDEAs are subject to specific material and geometrical limitations due to the AM process and require a more thorough analysis of their design and performance. Furthermore, a figure of merit (FOM) is an analytical tool that is frequently used for planar DEA design optimization and material selection but is not yet derived for UDEA. Thus, the objective of the paper is modeling of 3D printed UDEAs, analyzing the effects of their design features on the actuation performance, and deriving FOMs for UDEAs. As a result, the derived analytical model demonstrates dependence of actuation performance on various design parameters typical for 3D printed DEAs, provides a new optimum thickness to Young’s modulus ratio of UDEA layers when designing a 3D printed DEA with fixed dielectric elastomer layer thickness, and serves as a base for UDEAs’ FOMs. The FOMs have various degrees of complexity depending on considered UDEA design features. The model was numerically verified and experimentally validated through the actuation of a 3D printed UDEA. The fabricated and tested UDEA design was optimized geometrically by controlling the thickness of each layer and from the material perspective by mixing commercially available silicones in non-standard ratios for the passive and dielectric layers. Finally, the prepared non-standard mix ratios of the silicones were characterized for their viscosity dynamics during curing at various conditions to investigate the silicones’ manufacturability through AM.},
  archive      = {J_FROBT},
  author       = {Sikulskyi, Stanislav and Ren, Zefu and Mekonnen, Danayit T. and Holyoak, Aleiya and Srinivasaraghavan Govindarajan, Rishikesh and Kim, Daewon},
  doi          = {10.3389/frobt.2022.1034914},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1034914},
  shortjournal = {Front. Robot. AI},
  title        = {Additively manufactured unimorph dielectric elastomer actuators: Design, materials, and fabrication},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fault-tolerant and robust controller using model
predictive path integral control for free-flying space robots.
<em>FROBT</em>, <em>9</em>, 1027918. (<a
href="https://doi.org/10.3389/frobt.2022.1027918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of manipulators in space missions has become popular, as their applications can be extended to various space missions such as on-orbit servicing, assembly, and debris removal. Due to space reachability limitations, such robots must accomplish their tasks in space autonomously and under severe operating conditions such as the occurrence of faults or uncertainties. For robots and manipulators used in space missions, this paper provides a unique, robust control technique based on Model Predictive Path Integral Control (MPPI). The proposed algorithm, named Planner-Estimator MPPI (PE-MPPI), comprises a planner and an estimator. The planner controls a system, while the estimator modifies the system parameters in the case of parameter uncertainties. The performance of the proposed controller is investigated under parameter uncertainties and system component failure in the pre-capture phase of the debris removal mission. Simulation results confirm the superior performance of PE-MPPI against vanilla MPPI.},
  archive      = {J_FROBT},
  author       = {Raisi, Mehran and Noohian, Amirhossein and Fallah, Saber},
  doi          = {10.3389/frobt.2022.1027918},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1027918},
  shortjournal = {Front. Robot. AI},
  title        = {A fault-tolerant and robust controller using model predictive path integral control for free-flying space robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From the lab to the field with evolutionary field robotics.
<em>FROBT</em>, <em>9</em>, 1027389. (<a
href="https://doi.org/10.3389/frobt.2022.1027389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Howard, David},
  doi          = {10.3389/frobt.2022.1027389},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1027389},
  shortjournal = {Front. Robot. AI},
  title        = {From the lab to the field with evolutionary field robotics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review of the applications of multi-agent reinforcement
learning in smart factories. <em>FROBT</em>, <em>9</em>, 1027340. (<a
href="https://doi.org/10.3389/frobt.2022.1027340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart factory is at the heart of Industry 4.0 and is the new paradigm for establishing advanced manufacturing systems and realizing modern manufacturing objectives such as mass customization, automation, efficiency, and self-organization all at once. Such manufacturing systems, however, are characterized by dynamic and complex environments where a large number of decisions should be made for smart components such as production machines and the material handling system in a real-time and optimal manner. AI offers key intelligent control approaches in order to realize efficiency, agility, and automation all at once. One of the most challenging problems faced in this regard is uncertainty, meaning that due to the dynamic nature of the smart manufacturing environments, sudden seen or unseen events occur that should be handled in real-time. Due to the complexity and high-dimensionality of smart factories, it is not possible to predict all the possible events or prepare appropriate scenarios to respond. Reinforcement learning is an AI technique that provides the intelligent control processes needed to deal with such uncertainties. Due to the distributed nature of smart factories and the presence of multiple decision-making components, multi-agent reinforcement learning (MARL) should be incorporated instead of single-agent reinforcement learning (SARL), which, due to the complexities involved in the development process, has attracted less attention. In this research, we will review the literature on the applications of MARL to tasks within a smart factory and then demonstrate a mapping connecting smart factory attributes to the equivalent MARL features, based on which we suggest MARL to be one of the most effective approaches for implementing the control mechanism for smart factories.},
  archive      = {J_FROBT},
  author       = {Bahrpeyma, Fouad and Reichelt, Dirk},
  doi          = {10.3389/frobt.2022.1027340},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1027340},
  shortjournal = {Front. Robot. AI},
  title        = {A review of the applications of multi-agent reinforcement learning in smart factories},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable production of large components by industrial robots
and machine tools through segmentation. <em>FROBT</em>, <em>9</em>,
1021755. (<a href="https://doi.org/10.3389/frobt.2022.1021755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The production of large components currently requires cost-intensive special machine tools with large workspaces. The corresponding process chains are usually sequential and hard to scale. Furthermore, large components are usually manufactured in small batches; consequently, the planning effort has a significant share in the manufacturing costs. This paper presents a novel approach for manufacturing large components by industrial robots and machine tools through segmented manufacturing. This leads to a decoupling of component size and necessary workspace and enables a new type of flexible and scalable manufacturing system. The presented solution is based on the automatic segmentation of the CAD model of the component into segments, which are provided with predefined connection elements. The proposed segmentation strategy divides the part into segments whose structural design is adapted to the capabilities (workspace, axis configuration, etc.) of the field components available on the shopfloor. The capabilities are provided by specific information models containing a self-description. The process planning step of each segment is automated by utilizing the similarity of the segments and the self-description of the corresponding field component. The result is a transformation of a batch size one production into an automated quasi-serial production of the segments. To generate the final component geometry, the individual segments are mounted and joined by robot-guided Direct Energy Deposition. The final surface finish is achieved by post-processing using a mobile machine tool coupled to the component. The entire approach is demonstrated along the process chain for manufacturing a forming tool.},
  archive      = {J_FROBT},
  author       = {Schnellhardt, Thorben and Hemschik, Rico and Weiß, Arno and Schoesau, Rene and Hellmich, Arvid and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2022.1021755},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1021755},
  shortjournal = {Front. Robot. AI},
  title        = {Scalable production of large components by industrial robots and machine tools through segmentation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards understanding and synthesis of contact-rich
anthropomorphic motions through interactive cyber-physical human.
<em>FROBT</em>, <em>9</em>, 1019523. (<a
href="https://doi.org/10.3389/frobt.2022.1019523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents perspective on the research challenge of understanding and synthesizing anthropomorphic whole-body contact motions through a platform called “interactive cyber-physical human (iCPH)” for data collection and augmentation. The iCPH platform combines humanoid robots as “physical twins” of human and “digital twins” that simulates humans and robots in cyber-space. Several critical research topics are introduced to address this challenge by leveraging the advanced model-based analysis together with data-driven learning to exploit collected data from the integrated platform of iCPH. Definition of general description is identified as the first topic as a common basis of contact motions compatible to both humans and humanoids. Then, we set continual learning of a feasible contact motion network as the second challenge by benefiting from model-based approach and machine learning bridged by the efficient analytical gradient computation developed by the author and his collaborators. The final target is to establish a high-level symbolic system allowing automatic understanding and generation of contact motions in unexperienced environments. The proposed approaches are still under investigation, and the author expects that this article triggers discussions and further collaborations from different research communities, including robotics, artificial intelligence, neuroscience, and biomechanics.},
  archive      = {J_FROBT},
  author       = {Yoshida, Eiichi},
  doi          = {10.3389/frobt.2022.1019523},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1019523},
  shortjournal = {Front. Robot. AI},
  title        = {Towards understanding and synthesis of contact-rich anthropomorphic motions through interactive cyber-physical human},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of an intelligent system based on metaverse
learning for students with disabilities. <em>FROBT</em>, <em>9</em>,
1006921. (<a href="https://doi.org/10.3389/frobt.2022.1006921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the coronavirus-2019 pandemic, people have had to work and study using the Internet such that the strengthened metaverse has become a part of the lives of people worldwide. The advent of technology linking the real and virtual worlds has facilitated the transmission of spatial audio and haptics to allow the metaverse to offer multisensory experiences in diverse fields, especially in teaching. The main idea of the proposed project is the development of a simple intelligent system for meta-learning. The suggested system should be self-configurable according to the different users of the metaverse. We aimed to design and create a virtual learning environment using Open Simulator based on a 3D virtual environment and simulation of the real-world environment. We then connected this environment to a learning management system (Moodle) through technology for 3D virtual environments (Sloodle) to allow the management of students, especially those with different abilities, and followed up on their activities, tests, and exams. This environment also has the advantage of storing educational content. We evaluated the performance of the Open Simulator in both standalone and grid modes based on the login times. The result showed times the standalone and grid modes of 12 s and 16 s, which demonstrated the robustness of the proposed platform. We also tested the system on 50 disabled learners, according to the t-test of independent samples. A test was conducted in the mathematics course, in which the students were divided into two equal groups (n = 25 each) to take the test traditionally and using the chair test tool, which is one of the most important tools of the Sloodle technology. According to the results, the null hypothesis was rejected, and we accepted the alternative hypothesis that demonstrated a difference in achievement between the two groups.},
  archive      = {J_FROBT},
  author       = {Sghaier, Souhir and Elfakki, Abir Osman and Alotaibi, Abdullah Alhumaidi},
  doi          = {10.3389/frobt.2022.1006921},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1006921},
  shortjournal = {Front. Robot. AI},
  title        = {Development of an intelligent system based on metaverse learning for students with disabilities},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive arbitration of aerial swarm interactions through a
gaussian kernel for coherent group motion. <em>FROBT</em>, <em>9</em>,
1006786. (<a href="https://doi.org/10.3389/frobt.2022.1006786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm behaviors offer scalability and robustness to failure through a decentralized and distributed design. When designing coherent group motion as in swarm flocking, virtual potential functions are a widely used mechanism to ensure the aforementioned properties. However, arbitrating through different virtual potential sources in real-time has proven to be difficult. Such arbitration is often affected by fine tuning of the control parameters used to select among the different sources and by manually set cut-offs used to achieve a balance between stability and velocity. A reliance on parameter tuning makes these methods not ideal for field operations of aerial drones which are characterized by fast non-linear dynamics hindering the stability of potential functions designed for slower dynamics. A situation that is further exacerbated by parameters that are fine-tuned in the lab is often not appropriate to achieve satisfying performances on the field. In this work, we investigate the problem of dynamic tuning of local interactions in a swarm of aerial vehicles with the objective of tackling the stability–velocity trade-off. We let the focal agent autonomously and adaptively decide which source of local information to prioritize and at which degree—for example, which neighbor interaction or goal direction. The main novelty of the proposed method lies in a Gaussian kernel used to regulate the importance of each element in the swarm scheme. Each agent in the swarm relies on such a mechanism at every algorithmic iteration and uses it to tune the final output velocities. We show that the presented approach can achieve cohesive flocking while at the same time navigating through a set of way-points at speed. In addition, the proposed method allows to achieve other desired field properties such as automatic group splitting and joining over long distances. The aforementioned properties have been empirically proven by an extensive set of simulated and field experiments, in communication-full and communication-less scenarios. Moreover, the presented approach has been proven to be robust to failures, intermittent communication, and noisy perceptions.},
  archive      = {J_FROBT},
  author       = {Manoni, Tiziano and Albani, Dario and Horyna, Jiri and Petracek, Pavel and Saska, Martin and Ferrante, Eliseo},
  doi          = {10.3389/frobt.2022.1006786},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1006786},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive arbitration of aerial swarm interactions through a gaussian kernel for coherent group motion},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Higher education personnel’s perceptions about telepresence
robots. <em>FROBT</em>, <em>9</em>, 976836. (<a
href="https://doi.org/10.3389/frobt.2022.976836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interest towards using telepresence robots in a variety of educational contexts is growing, as they have a great potential to enhance the educational experience of remote learners and provide support for teachers. This paper describes a study, examining the perception of Georgian university personnel about the use of telepresence robots in education. This exploratory research aimed to obtain evidence-based information on how the personnel (16 persons) from eight Georgian universities perceived the telepresence robots’ role in enhancing learning and teaching, and what challenges, benefits, opportunities, weaknesses and threats would characterise these robots. The results of the study revealed that the university personnel perceived telepresence robots to have a great potential to enhance educational activities. In addition, the participants indicated the major challenges, benefits, opportunities, weaknesses and threats, regarding integrating telepresence robotics into the teaching and learning in Georgia. Recommendations for future research are also presented.},
  archive      = {J_FROBT},
  author       = {Leoste, Janika and Virkus, Sirje and Talisainen, Aleksei and Tammemäe, Kalle and Kangur, Katrin and Petriashvili, Izabella},
  doi          = {10.3389/frobt.2022.976836},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {976836},
  shortjournal = {Front. Robot. AI},
  title        = {Higher education personnel’s perceptions about telepresence robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Framework for qualifying exoskeletons as adaptive support
technology. <em>FROBT</em>, <em>9</em>, 951382. (<a
href="https://doi.org/10.3389/frobt.2022.951382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fifth industrial revolution and the accompanying influences of digitalization are presenting enterprises with significant challenges. Regardless of the trend, however, humans will remain a central resource in future factories and will continue to be required to perform manual tasks. Against the backdrop of, e.g., societal and demographic changes and skills shortage, future-oriented support technologies such as exoskeletons represent a promising opportunity to support workers. Accordingly, the increasing interconnection of human operators, devices, and the environment, especially in human-centered work processes, requires improved human-machine interaction and further qualification of support systems to smart devices. In order to meet these requirements and enable exoskeletons as a future-proof technology, this article presents a framework for the future-oriented qualification of exoskeletons, which reveals potential in terms of user-individual and context-dependent adaptivity of support systems. In this context, a framework has been developed, allowing different support situations to be classified based on elementary functions. Using these support function dependencies and characteristics, it becomes possible to describe adaptive system behavior for human-centered support systems such as exoskeletons as a central aspect. For practical illustration, it is shown for an exemplary active exoskeleton using the example of user-individuality and context-specificity how the support characteristics of exoskeletons in the form of different support characteristics can bring about a purposeful and needs-based application for users and can contribute valuably to design future workplaces.},
  archive      = {J_FROBT},
  author       = {Ott, Oliver and Ralfs, Lennart and Weidner, Robert},
  doi          = {10.3389/frobt.2022.951382},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {951382},
  shortjournal = {Front. Robot. AI},
  title        = {Framework for qualifying exoskeletons as adaptive support technology},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporary improvement of cognitive and behavioral scales for
dementia elderly by shiritori word game with a dialogue robot: A pilot
study. <em>FROBT</em>, <em>9</em>, 941056. (<a
href="https://doi.org/10.3389/frobt.2022.941056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication therapies based on conversations with caregivers, such as reminiscence therapy and music therapy, have been proposed to delay the progression of dementia. Although these therapies have been reported to improve the cognitive and behavioral functions of elderly people suffering from dementia, caregivers do not have enough time to spend on administering such communication therapies, especially in Japan where the workforce of caregivers is inadequate. Consequently, the progression of dementia in the elderly and the accompanying increased burden on caregivers has become a social problem. While the automation of communication therapy using robots and virtual agents has been proposed, the accuracy of both speech recognition and dialogue control is still insufficient to improve the cognitive and behavioral functions of the dementia elderly. In this study, we examine the effect of a Japanese word-chain game (Shiritori game) with an interactive robot and that of music listening on the maintenance and improvement of cognitive and behavioral scales [Mini-Mental State Examination (MMSE) and Dementia Behavior Disturbance scale (DBD)] of the dementia elderly. These activities can provide linguistic and phonetic stimuli, and they are simpler to implement than conventional daily conversation. The results of our Wizard-of-Oz-based experiments show that the cognitive and behavioral function scores of the elderly who periodically played the Shiritori game with an interactive robot were significantly improved over the elderly in a control group. On the other hand, no such effect was observed with the music listening stimuli. Our further experiments showed that, in the Shiritori intervention group, there was a ceiling on the increase in MMSE. The lower the MMSE before participating in the experiment, the greater the increase. Furthermore, greater improvement in DBD was observed when the participants actively played the Shiritori game. Since the Shiritori game is relatively easy to automate, our findings show the potential benefits of automating dementia therapies to maintain cognitive and behavioral functions.},
  archive      = {J_FROBT},
  author       = {Sugiyama, Hiroaki and Nakamura, Kenji},
  doi          = {10.3389/frobt.2022.941056},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {941056},
  shortjournal = {Front. Robot. AI},
  title        = {Temporary improvement of cognitive and behavioral scales for dementia elderly by shiritori word game with a dialogue robot: A pilot study},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Socio-conversational systems: Three challenges at the
crossroads of fields. <em>FROBT</em>, <em>9</em>, 937825. (<a
href="https://doi.org/10.3389/frobt.2022.937825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Socio-conversational systems are dialogue systems, including what are sometimes referred to as chatbots, vocal assistants, social robots, and embodied conversational agents, that are capable of interacting with humans in a way that treats both the specifically social nature of the interaction and the content of a task. The aim of this paper is twofold: 1) to uncover some places where the compartmentalized nature of research conducted around socio-conversational systems creates problems for the field as a whole, and 2) to propose a way to overcome this compartmentalization and thus strengthen the capabilities of socio-conversational systems by defining common challenges. Specifically, we examine research carried out by the signal processing, natural language processing and dialogue, machine/deep learning, social/affective computing and social sciences communities. We focus on three major challenges for the development of effective socio-conversational systems, and describe ways to tackle them.},
  archive      = {J_FROBT},
  author       = {Clavel, Chloé and Labeau, Matthieu and Cassell, Justine},
  doi          = {10.3389/frobt.2022.937825},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {937825},
  shortjournal = {Front. Robot. AI},
  title        = {Socio-conversational systems: Three challenges at the crossroads of fields},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Task-specific robot base pose optimization for
robot-assisted surgeries. <em>FROBT</em>, <em>9</em>, 899646. (<a
href="https://doi.org/10.3389/frobt.2022.899646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preoperative planning and intra-operative system setup are crucial steps to successfully integrate robotically assisted surgical systems (RASS) into the operating room. Efficiency in terms of setup planning directly affects the overall procedural costs and increases acceptance of RASS by surgeons and clinical personnel. Due to the kinematic limitations of RASS, selecting an optimal robot base location and surgery access point for the patient is essential to avoid potentially critical complications due to reachability issues. To this end, this work proposes a novel versatile method for RASS setup and planning based on robot capability maps (CMAPs). CMAPs are a common tool to perform workspace analysis in robotics, as they are in general applicable to any robot kinematics. However, CMAPs have not been completely exploited so far for RASS setup and planning. By adapting global CMAPs to surgical procedure-specific tasks and constraints, a novel RASS capability map (RASSCMAP) is generated. Furthermore, RASSCMAPs can be derived to also comply with kinematic access constraints such as access points in laparoscopy. RASSCMAPs are versatile and applicable to any kind of surgical procedure; they can be used on the one hand for aiding in intra-operative experience-based system setup by visualizing online the robot’s capability to perform a task. On the other hand, they can be used to find the optimal setup by applying a multi-objective optimization based on a genetic algorithm preoperatively, which is then transfered to the operating room during system setup. To illustrate these applications, the method is evaluated in two different use cases, namely, pedicle screw placement in vertebral fixation procedures and general laparoscopy. The proposed RASSCMAPs help in increasing the overall clinical value of RASS by reducing system setup time and guaranteeing proper robot reachability to successfully perform the intended surgeries.},
  archive      = {J_FROBT},
  author       = {Sundaram, Ashok M. and Budjakoski, Nikola and Klodmann, Julian and Roa, Máximo A.},
  doi          = {10.3389/frobt.2022.899646},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {899646},
  shortjournal = {Front. Robot. AI},
  title        = {Task-specific robot base pose optimization for robot-assisted surgeries},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Materials, design, modeling and control of soft
robotic artificial muscles. <em>FROBT</em>, <em>9</em>, 1074549. (<a
href="https://doi.org/10.3389/frobt.2022.1074549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Huang, Xiaonan and Sabelhaus, Andrew P. and Jawed, M. Khalid and Jin, Lihua and Zou, Jun and Chen, Yuzhen},
  doi          = {10.3389/frobt.2022.1074549},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1074549},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Materials, design, modeling and control of soft robotic artificial muscles},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A rolled-up-based fabrication method of 3D helical
microrobots. <em>FROBT</em>, <em>9</em>, 1063987. (<a
href="https://doi.org/10.3389/frobt.2022.1063987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the potential of using helical microrobots for biomedical applications, such as cargo transport, drug delivery, and micromanipulation, had been demonstrated, the viability to use them for practical applications is hindered by the cost, speed, and repeatability of current fabrication techniques. Hence, this paper introduces a simple, low-cost, high-throughput manufacturing process for single nickel layer helical microrobots with consistent dimensions. Photolithography and electron-beam (e-beam) evaporation were used to fabricate 2D parallelogram patterns that were sequentially rolled up into helical microstructures through the swelling effect of a photoresist sacrificial layer. Helical parameters were controlled by adjusting the geometric parameters of parallelogram patterns. To validate the fabrication process and characterize the microrobots’ mobility, we characterized the structures and surface morphology of the microrobots using a scanning electron microscope and tested their steerability using feedback control, respectively. Finally, we conducted a benchmark comparison to demonstrate that the fabrication method can produce helical microrobots with swimming properties comparable to previously reported microrobots.},
  archive      = {J_FROBT},
  author       = {Wang, Zihan and Mu, Xueliang and Tan, Liyuan and Zhong, Yukun and Cheang, U. Kei},
  doi          = {10.3389/frobt.2022.1063987},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1063987},
  shortjournal = {Front. Robot. AI},
  title        = {A rolled-up-based fabrication method of 3D helical microrobots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: AI processing of UAV acquired images for pattern
monitoring in natural and urban environments. <em>FROBT</em>,
<em>9</em>, 1053063. (<a
href="https://doi.org/10.3389/frobt.2022.1053063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Diez Donoso, Yago and Gracias, Nuno and Cabezas , Mariano and Juergens , Carsten and Lopez Caceres , Maximo Larry},
  doi          = {10.3389/frobt.2022.1053063},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1053063},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: AI processing of UAV acquired images for pattern monitoring in natural and urban environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization and fabrication of programmable domains for
soft magnetic robots: A review. <em>FROBT</em>, <em>9</em>, 1040984. (<a
href="https://doi.org/10.3389/frobt.2022.1040984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the aim of realizing functional robotic systems at the milli- and submillimetre scale for biomedical applications, the area of magnetically driven soft devices has received significant recent attention. This has resulted in a new generation of magnetically controlled soft robots with patterns of embedded, programmable domains throughout their structures. This type of programmable magnetic profiling equips magnetic soft robots with shape programmable memory and can be achieved through the distribution of discrete domains (voxels) with variable magnetic densities and magnetization directions. This approach has produced highly compliant, and often bio-inspired structures that are well suited to biomedical applications at small scales, including microfluidic transport and shape-forming surgical catheters. However, to unlock the full potential of magnetic soft robots with improved designs and control, significant challenges remain in their compositional optimization and fabrication. This review considers recent advances and challenges in the interlinked optimization and fabrication aspects of programmable domains within magnetic soft robots. Through a combination of improvements in the computational capacity of novel optimization methods with advances in the resolution, material selection and automation of existing and novel fabrication methods, significant further developments in programmable magnetic soft robots may be realized.},
  archive      = {J_FROBT},
  author       = {Bacchetti, Alistair and Lloyd, Peter and Taccola, Silvia and Fakhoury, Evan and Cochran, Sandy and Harris, Russell A. and Valdastri, Pietro and Chandler, James H.},
  doi          = {10.3389/frobt.2022.1040984},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1040984},
  shortjournal = {Front. Robot. AI},
  title        = {Optimization and fabrication of programmable domains for soft magnetic robots: A review},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Socio-technical ecologies: Design for
human-machine systems. <em>FROBT</em>, <em>9</em>, 1037454. (<a
href="https://doi.org/10.3389/frobt.2022.1037454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Botev, Jean and Diaconescu, Ada and Hamann, Heiko and Marsh, Stephen and Rodríguez Lera, Francisco J.},
  doi          = {10.3389/frobt.2022.1037454},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1037454},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: socio-technical ecologies: design for human-machine systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surgical instrument detection and tracking technologies:
Automating dataset labeling for surgical skill assessment.
<em>FROBT</em>, <em>9</em>, 1030846. (<a
href="https://doi.org/10.3389/frobt.2022.1030846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical skills can be improved by continuous surgical training and feedback, thus reducing adverse outcomes while performing an intervention. With the advent of new technologies, researchers now have the tools to analyze surgical instrument motion to differentiate surgeons’ levels of technical skill. Surgical skills assessment is time-consuming and prone to subjective interpretation. The surgical instrument detection and tracking algorithm analyzes the image captured by the surgical robotic endoscope and extracts the movement and orientation information of a surgical instrument to provide surgical navigation. This information can be used to label raw surgical video datasets that are used to form an action space for surgical skill analysis. Instrument detection and tracking is a challenging problem in MIS, including robot-assisted surgeries, but vision-based approaches provide promising solutions with minimal hardware integration requirements. This study offers an overview of the developments of assessment systems for surgical intervention analysis. The purpose of this study is to identify the research gap and make a leap in developing technology to automate the incorporation of new surgical skills. A prime factor in automating the learning is to create datasets with minimal manual intervention from raw surgical videos. This review encapsulates the current trends in artificial intelligence (AI) based visual detection and tracking technologies for surgical instruments and their application for surgical skill assessment.},
  archive      = {J_FROBT},
  author       = {Nema, Shubhangi and Vachhani, Leena},
  doi          = {10.3389/frobt.2022.1030846},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1030846},
  shortjournal = {Front. Robot. AI},
  title        = {Surgical instrument detection and tracking technologies: Automating dataset labeling for surgical skill assessment},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the dynamics and control of a squirrel locking its
head/eyes toward a fixed spot for safe landing while its body is
tumbling in air. <em>FROBT</em>, <em>9</em>, 1030601. (<a
href="https://doi.org/10.3389/frobt.2022.1030601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An arboreal mammal such as a squirrel can amazingly lock its head (and thus eyes) toward a fixed spot for safe landing while its body is tumbling in air after unexpectedly being thrown into air. Such an impressive ability of body motion control of squirrels has been shown in a recent YouTube video, which has amazed public with over 100 million views. In the video, a squirrel attracted to food crawled onto an ejection device and was unknowingly ejected into air by the device. During the resulting projectile flight, the squirrel managed to quickly turn its head (eyes) toward and then keeps staring at the landing spot until it safely landed on feet. Understanding the underline dynamics and how the squirrel does this behavior can inspire robotics researchers to develop bio-inspired control strategies for challenging robotic operations such as hopping/jumping robots operating in an unstructured environment. To study this problem, we implemented a 2D multibody dynamics model, which simulated the dynamic motion behavior of the main body segments of a squirrel in a vertical motion plane. The inevitable physical contact between the body segments is also modeled and simulated. Then, we introduced two motion control methods aiming at locking the body representing the head of the squirrel toward a globally fixed spot while the other body segments of the squirrel were undergoing a general 2D rotation and translation. One of the control methods is a conventional proportional-derivative (PD) controller, and the other is a reinforcement learning (RL)-based controller. Our simulation-based experiment shows that both controllers can achieve the intended control goal, quickly turning and then locking the head toward a globally fixed spot under any feasible initial motion conditions. In comparison, the RL-based method is more robust against random noise in sensor data and also more robust under unexpected initial conditions.},
  archive      = {J_FROBT},
  author       = {Ma, Tianqi and Zhang, Tao and Ma, Ou},
  doi          = {10.3389/frobt.2022.1030601},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1030601},
  shortjournal = {Front. Robot. AI},
  title        = {On the dynamics and control of a squirrel locking its head/eyes toward a fixed spot for safe landing while its body is tumbling in air},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safely catching aerial micro-robots in mid-air using an
open-source aerial robot with soft gripper. <em>FROBT</em>, <em>9</em>,
1030515. (<a href="https://doi.org/10.3389/frobt.2022.1030515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on catching safely an aerial micro-robot in mid-air using another aerial robot that is equipped with a universal soft gripper. To avoid aerodynamic disturbances such as downwash, that would push the target robot away, we follow a horizontal grasping approach. To this end, the article introduces a gripper design based on soft actuators that can stay horizontally straight with a single fixture and maintain sufficiently compliance in order to bend when air pressure is applied. Further, we develop the Soft Aerial Gripper (SoAG), an open-source aerial robot equipped with the developed soft end-effector and that features an onboard pneumatic regulation system. Experimental results show that the developed low-cost soft gripper has fast opening and closing responses despite being powered by lightweight air pumps, responses that are comparable to those of a commercially available end-effector tested we test against. Static grasping tests study the soft gripper’s robustness in capturing aerial micro-robots under aerodynamic disturbances. We experimentally demonstrated the feasibility of using the SoAG robot to catch a hovering micro-robot with or without propeller guards. The feasibility of dynamic catching is also shown by capturing a moving aerial micro-robot with a velocity of 0.2 m/s. The free flight performance of the SoAG robot is studied against a conventional quadrotor and in different gripper and payload status.},
  archive      = {J_FROBT},
  author       = {Liu, Zhichao and Mucchiani, Caio and Ye, Keran and Karydis, Konstantinos},
  doi          = {10.3389/frobt.2022.1030515},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1030515},
  shortjournal = {Front. Robot. AI},
  title        = {Safely catching aerial micro-robots in mid-air using an open-source aerial robot with soft gripper},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multistimuli-responsive microrobots: A comprehensive review.
<em>FROBT</em>, <em>9</em>, 1027415. (<a
href="https://doi.org/10.3389/frobt.2022.1027415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Untethered robots of the size of a few microns have attracted increasing attention for the potential to transform many aspects of manufacturing, medicine, health care, and bioengineering. Previously impenetrable environments have become available for high-resolution in situ and in vivo manipulations as the size of the untethered robots goes down to the microscale. Nevertheless, the independent navigation of several robots at the microscale is challenging as they cannot have onboard transducers, batteries, and control like other multi-agent systems, due to the size limitations. Therefore, various unconventional propulsion mechanisms have been explored to power motion at the nanoscale. Moreover, a variety of combinations of actuation methods has also been extensively studied to tackle different issues. In this survey, we present a thorough review of the recent developments of various dedicated ways to actuate and control multistimuli-enabled microrobots. We have also discussed existing challenges and evolving concepts associated with each technique.},
  archive      = {J_FROBT},
  author       = {Shah, Zameer Hussain and Wu, Bingzhi and Das, Sambeeta},
  doi          = {10.3389/frobt.2022.1027415},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1027415},
  shortjournal = {Front. Robot. AI},
  title        = {Multistimuli-responsive microrobots: A comprehensive review},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft robotics for infrastructure protection. <em>FROBT</em>,
<em>9</em>, 1026891. (<a
href="https://doi.org/10.3389/frobt.2022.1026891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paradigm change introduced by soft robotics is going to dramatically push forward the abilities of autonomous systems in the next future, enabling their applications in extremely challenging scenarios. The ability of soft robots to safely interact and adapt to the surroundings is key to operate in unstructured environments, where the autonomous agent has little or no knowledge about the world around it. A similar context occurs when critical infrastructures face threats or disruptions, for examples due to natural disasters or external attacks (physical or cyber). In this case, autonomous systems may be employed to respond to such emergencies and have to be able to deal with unforeseen physical conditions and uncertainties, where the mechanical interaction with the environment is not only inevitable but also desirable to successfully perform their tasks. In this perspective, I discuss applications of soft robots for the protection of infrastructures, including recent advances in pipelines inspection, rubble search and rescue, and soft aerial manipulation, and promising perspectives on operations in radioactive environments, underwater monitoring and space exploration.},
  archive      = {J_FROBT},
  author       = {Milana, Edoardo},
  doi          = {10.3389/frobt.2022.1026891},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1026891},
  shortjournal = {Front. Robot. AI},
  title        = {Soft robotics for infrastructure protection},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safety considerations for autonomous, modular robotics in
aerospace manufacturing. <em>FROBT</em>, <em>9</em>, 1024594. (<a
href="https://doi.org/10.3389/frobt.2022.1024594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial robots are versatile machines that can be used to implement numerous tasks. They have been successful in applications where–after integration and commissioning–a more or less static and repetitive behaviour in conjunction with closed work cells is sufficient. In aerospace manufacturing, robots still struggle to compete against either specialized machines or manual labour. This can be attributed to complex or custom parts and/or small batch sizes. Here, applicability of robots can be improved by enabling collaborative use-cases. When fixed protective fences are not desired due to handling problems of the large parts involved, sensor-based approaches like speed and separation monitoring (SSM) are required. This contribution is about how to construct dynamic volumes of space around a robot as well as around a person in the way that their combination satisfies required separation distance between robot and person. The goal was to minimize said distance by calculating volumes both adaptively and as precisely as possible given the available information. We used a voxel-based method to compute the robot safety space that includes worst-case breaking behaviour. We focused on providing a worst-case representation considering all possible breaking variations. Our approach to generate the person safety space is based on an outlook for 2D camera, AI-based workspace surveillance.},
  archive      = {J_FROBT},
  author       = {Walter, Christoph and Bexten, Simone and Felsch, Torsten and Shysh, Myroslav and Elkmann, Norbert},
  doi          = {10.3389/frobt.2022.1024594},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1024594},
  shortjournal = {Front. Robot. AI},
  title        = {Safety considerations for autonomous, modular robotics in aerospace manufacturing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robot localization proposal for the RobotAtFactory 4.0: A
novel robotics competition within the industry 4.0 concept.
<em>FROBT</em>, <em>9</em>, 1023590. (<a
href="https://doi.org/10.3389/frobt.2022.1023590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic competitions are an excellent way to promote innovative solutions for the current industries’ challenges and entrepreneurial spirit, acquire technical and transversal skills through active teaching, and promote this area to the public. In other words, since robotics is a multidisciplinary field, its competitions address several knowledge topics, especially in the STEM (Science, Technology, Engineering, and Mathematics) category, that are shared among the students and researchers, driving further technology and science. A new competition encompassed in the Portuguese Robotics Open was created according to the Industry 4.0 concept in the production chain. In this competition, RobotAtFactory 4.0, a shop floor, is used to mimic a fully automated industrial logistics warehouse and the challenges it brings. Autonomous Mobile Robots (AMRs) must be used to operate without supervision and perform the tasks that the warehouse requests. There are different types of boxes which dictate their partial and definitive destinations. In this reasoning, AMRs should identify each and transport them to their destinations. This paper describes an approach to the indoor localization system for the competition based on the Extended Kalman Filter (EKF) and ArUco markers. Different innovation methods for the obtained observations were tested and compared in the EKF. A real robot was designed and assembled to act as a test bed for the localization system’s validation. Thus, the approach was validated in the real scenario using a factory floor with the official specifications provided by the competition organization.},
  archive      = {J_FROBT},
  author       = {Braun, João and Júnior, Alexandre O. and Berger, Guido and Pinto, Vítor H. and Soares, Inês N. and Pereira, Ana I. and Lima, José and Costa, Paulo},
  doi          = {10.3389/frobt.2022.1023590},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1023590},
  shortjournal = {Front. Robot. AI},
  title        = {A robot localization proposal for the RobotAtFactory 4.0: A novel robotics competition within the industry 4.0 concept},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven method for damage localization on soft robotic
grippers based on motion dynamics. <em>FROBT</em>, <em>9</em>, 1016883.
(<a href="https://doi.org/10.3389/frobt.2022.1016883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Damage detection is one of the critical challenges in operating soft robots in an industrial setting. In repetitive tasks, even a small cut or fatigue can propagate to large damage ceasing the complete operation process. Although research has shown that damage detection can be performed through an embedded sensor network, this approach leads to complicated sensorized systems with additional wiring and equipment, made using complex fabrication processes and often compromising the flexibility of the soft robotic body. Alternatively, in this paper, we proposed a non-invasive approach for damage detection and localization on soft grippers. The essential idea is to track changes in non-linear dynamics of a gripper due to possible damage, where minor changes in material and morphology lead to large differences in the force and torque feedback over time. To test this concept, we developed a classification model based on a bidirectional long short-time memory (biLSTM) network that discovers patterns of dynamics changes in force and torque signals measured at the mounting point. To evaluate this model, we employed a two-fingered Fin Ray gripper and collected data for 43 damage configurations. The experimental results show nearly perfect damage detection accuracy and 97% of its localization. We have also tested the effect of the gripper orientation and the length of time-series data. By shaking the gripper with an optimal roll angle, the localization accuracy can exceed 95% and increase further with additional gripper orientations. The results also show that two periods of the gripper oscillation, i.e., roughly 50 data points, are enough to achieve a reasonable level of damage localization.},
  archive      = {J_FROBT},
  author       = {Abdulali, Arsen and Terryn, Seppe and Vanderborght, Bram and Iida, Fumiya},
  doi          = {10.3389/frobt.2022.1016883},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1016883},
  shortjournal = {Front. Robot. AI},
  title        = {Data-driven method for damage localization on soft robotic grippers based on motion dynamics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A low-cost wearable device for portable sequential
compression therapy. <em>FROBT</em>, <em>9</em>, 1012862. (<a
href="https://doi.org/10.3389/frobt.2022.1012862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2020, cardiovascular diseases resulted in 25% of unnatural deaths in the United States. Treatment with long-term administration of medication can adversely affect other organs, and surgeries such as coronary artery grafts are risky. Meanwhile, sequential compression therapy (SCT) offers a low-risk alternative, but is currently expensive and unwieldy, and often requires the patient to be immobilized during administration. Here, we present a low-cost wearable device to administer SCT, constructed using a stacked lamination fabrication approach. Expanding on concepts from the field of soft robotics, textile sheets are thermally bonded to form pneumatic actuators, which are controlled by an inconspicuous and tetherless electronic onboard supply of pressurized air. Our open-source, low-profile, and lightweight (140 g) device costs $62, less than one-third the cost the least expensive alternative and one-half the weight of lightest alternative approved by the US Food and Drug Administration (FDA), presenting the opportunity to more effectively provide SCT to socioeconomically disadvantaged individuals. Furthermore, our textile-stacking method, inspired by conventional fabrication methods from the apparel industry, along with the lightweight fabrics used, allows the device to be worn more comfortably than other SCT devices. By reducing physical and financial encumbrances, the device presented in this work may better enable patients to treat cardiovascular diseases and aid in recovery from cardiac surgeries.},
  archive      = {J_FROBT},
  author       = {Schara, Mark and Zeng, Mingde and Jumet, Barclay and Preston, Daniel J.},
  doi          = {10.3389/frobt.2022.1012862},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1012862},
  shortjournal = {Front. Robot. AI},
  title        = {A low-cost wearable device for portable sequential compression therapy},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-excited valve using a flat ring tube: Application to
robotics. <em>FROBT</em>, <em>9</em>, 1008559. (<a
href="https://doi.org/10.3389/frobt.2022.1008559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex and bulky driving systems are among the main issues for soft robots driven by pneumatic actuators. Self-excited oscillation is a promising approach for dealing with this problem: oscillatory actuation is generated from non-oscillatory input. However, small varieties of self-excited pneumatic actuators currently limit their applications. We present a simple, self-excited pneumatic valve that uses a flat ring tube (FRT), a device originally developed as a self-excited pneumatic actuator. First, we explore the driving principle of the self-excited valve and investigate the effect of the flow rate and FRT length on its driving frequency. Then, a locomotive robot containing the valve is demonstrated. The prototype succeeded in walking at 5.2 mm/s when the oscillation frequency of the valve was 1.5 Hz, showing the applicability of the proposed valve to soft robotics.},
  archive      = {J_FROBT},
  author       = {Nabae, Hiroyuki and Kitamura, Eigo},
  doi          = {10.3389/frobt.2022.1008559},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1008559},
  shortjournal = {Front. Robot. AI},
  title        = {Self-excited valve using a flat ring tube: Application to robotics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aeroelastics-aware compensation system for soft aerial
vehicle stabilization. <em>FROBT</em>, <em>9</em>, 1005620. (<a
href="https://doi.org/10.3389/frobt.2022.1005620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a compensation system for soft aerial vehicle stabilization. Balancing the arms is one of the main challenges of soft UAVs since the propeller is freely tilting together with the flexible arm. In comparison with previous designs, in which the autopilot was adjusted to deal with these imbalances with no extra actuation, this work introduces a soft tendon-actuated system to achieve in-flight stabilization in an energy-efficient way. The controller is specifically designed for disturbance rejection of aeroelastic perturbations using the Ziegler-Nichols method, depending on the flight mode and material properties. This aerodynamics-aware compensation system allows to further bridge the gap between soft and aerial robotics, leading to an increase in the flexibility of the UAV, and the ability to deal with changes in material properties, increasing the useful life of the drone. In energetic terms, the novel system is 15–30% more efficient, and is the basis for future applications such as object grasping.},
  archive      = {J_FROBT},
  author       = {Ruiz, Fernando and Arrue, Begoña C. and Ollero, Aníbal},
  doi          = {10.3389/frobt.2022.1005620},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1005620},
  shortjournal = {Front. Robot. AI},
  title        = {Aeroelastics-aware compensation system for soft aerial vehicle stabilization},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Orbital hopping maneuvers with two astrobee free-flyers:
Ground and flight experiments. <em>FROBT</em>, <em>9</em>, 1004165. (<a
href="https://doi.org/10.3389/frobt.2022.1004165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic hopping maneuvers using mechanical actuation are proposed as a method of locomotion for free-flyer vehicles near or on large space structures. Such maneuvers are of interest for applications related to proximity maneuvers, observation, cargo carrying, fabrication, and sensor data collection. This study describes a set of dynamic hopping maneuver experiments performed using two Astrobees. Both vehicles were made to initially grasp onto a common free-floating handrail. From this initial condition, the active Astrobee launched itself using mechanical actuation of its robotic arm manipulator. The results are presented from the ground and flight experimental sessions completed at the Spacecraft Robotics Laboratory of the Naval Postgraduate School, the Intelligent Robotics Group facility at NASA Ames Research Center, and hopping maneuvers aboard the International Space Station. Overall, this study demonstrates that locomotion through mechanical actuation could successfully launch a free-flyer vehicle in an initial desired trajectory from another object of similar size and mass.},
  archive      = {J_FROBT},
  author       = {Kwok-Choon, Stephen and Hudson, Jennifer and Romano, Marcello},
  doi          = {10.3389/frobt.2022.1004165},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1004165},
  shortjournal = {Front. Robot. AI},
  title        = {Orbital hopping maneuvers with two astrobee free-flyers: Ground and flight experiments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance measures to benchmark the grasping,
manipulation, and assembly of deformable objects typical to
manufacturing applications. <em>FROBT</em>, <em>9</em>, 999348. (<a
href="https://doi.org/10.3389/frobt.2022.999348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The National Institute of Standards and Technology is developing performance tests and associated artifacts to benchmark research in the area of robotic assembly. Sets of components consistent with mechanical assemblies including screws, gears, electrical connectors, wires, and belts are configured for assembly or disassembly using a task board concept. Test protocols accompany the task boards and are designed to mimic low-volume, high-mixture assembly challenges typical to small and medium sized manufacturers. In addition to the typical rigid components found in assembled products, the task boards include many non-rigid component operations representative of wire harness and belt drive assemblies to support research in the area of grasping and manipulation of deformable objects, an area still considered to be an emerging research problem in robotics. A set of four primary task boards as well as competition task boards are presented as benchmarks along with scoring metrics and a method to compare robot system assembly times with human performance. Competitions are used to raise awareness to these benchmarks. Tools to progress and compare research are described along with emphasis placed on system competition-based solutions to grasp and manipulate deformable task board components.},
  archive      = {J_FROBT},
  author       = {Kimble, Kenneth and Albrecht, Justin and Zimmerman, Megan and Falco, Joe},
  doi          = {10.3389/frobt.2022.999348},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {999348},
  shortjournal = {Front. Robot. AI},
  title        = {Performance measures to benchmark the grasping, manipulation, and assembly of deformable objects typical to manufacturing applications},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous control for miniaturized mobile robots in unknown
pipe networks. <em>FROBT</em>, <em>9</em>, 997415. (<a
href="https://doi.org/10.3389/frobt.2022.997415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent advances in robotic technology, sewer pipe inspection is still limited to conventional approaches that use cable-tethered robots. Such commercially available tethered robots lack autonomy, and their operation must be manually controlled via their tethered cables. Consequently, they can only travel to a certain distance in pipe, cannot access small-diameter pipes, and their deployment incurs high costs for highly skilled operators. In this paper, we introduce a miniaturised mobile robot for pipe inspection. We present an autonomous control strategy for this robot that is effective, stable, and requires only low-computational resources. The robots used here can access pipes as small as 75 mm in diameter. Due to their small size, low carrying capacity, and limited battery supply, our robots can only carry simple sensors, a small processor, and miniature wheel-legs for locomotion. Yet, our control method is able to compensate for these limitations. We demonstrate fully autonomous robot mobility in a sewer pipe network, without any visual aid or power-hungry image processing. The control algorithm allows the robot to correctly recognise each local network configuration, and to make appropriate decisions accordingly. The control strategy was tested using the physical micro robot in a laboratory pipe network. In both simulation and experiment, the robot autonomously and exhaustively explored an unknown pipe network without missing any pipe section while avoiding obstacles. This is a significant advance towards fully autonomous inspection robot systems for sewer pipe networks.},
  archive      = {J_FROBT},
  author       = {Nguyen, T. L. and Blight, A. and Pickering, A. and Jackson-Mills, G. and Barber, A. R. and Boyle, J. H. and Richardson, R. and Dogar, M. and Cohen, N.},
  doi          = {10.3389/frobt.2022.997415},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {997415},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous control for miniaturized mobile robots in unknown pipe networks},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active-sensing-based decentralized control of autonomous
mobile agents for quick and smooth collision avoidance. <em>FROBT</em>,
<em>9</em>, 992716. (<a
href="https://doi.org/10.3389/frobt.2022.992716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an increasing demand for multi-agent systems in which each mobile agent, such as a robot in a warehouse or a flying drone, moves toward its destination while avoiding other agents. Although several control schemes for collision avoidance have been proposed, they cannot achieve quick and safe movement with minimal acceleration and deceleration. To address this, we developed a decentralized control scheme that involves modifying the social force model, a model of pedestrian dynamics, and successfully realized quick, smooth, and safe movement. However, each agent had to observe many nearby agents and predict their future motion; that is, unnecessary sensing and calculations were required for each agent. In this study, we addressed this issue by introducing active sensing. In this control scheme, an index referred to as the “collision risk level” is defined, and the observation range of each agent is actively controlled on this basis. Through simulations, we demonstrated that the proposed control scheme works reasonably while reducing unnecessary sensing and calculations.},
  archive      = {J_FROBT},
  author       = {Kano, Takeshi and Kanno, Takeru and Mikami, Taishi and Ishiguro, Akio},
  doi          = {10.3389/frobt.2022.992716},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {992716},
  shortjournal = {Front. Robot. AI},
  title        = {Active-sensing-based decentralized control of autonomous mobile agents for quick and smooth collision avoidance},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact of mixed-cultural speech on the stereotypical
perception of a virtual robot. <em>FROBT</em>, <em>9</em>, 983955. (<a
href="https://doi.org/10.3389/frobt.2022.983955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the fact that mixed-cultural backgrounds become of increasing importance in our daily life, the representation of multiple cultural backgrounds in one entity is still rare in socially interactive agents (SIAs). This paper’s contribution is twofold. First, it provides a survey of research on mixed-cultured SIAs. Second, it presents a study investigating how mixed-cultural speech (in this case, non-native accent) influences how a virtual robot is perceived in terms of personality, warmth, competence and credibility. Participants with English or German respectively as their first language watched a video of a virtual robot speaking in either standard English or German-accented English. It was expected that the German-accented speech would be rated more positively by native German participants as well as elicit the German stereotypes credibility and conscientiousness for both German and English participants. Contrary to the expectations, German participants rated the virtual robot lower in terms of competence and credibility when it spoke with a German accent, whereas English participants perceived the virtual robot with a German accent as more credible compared to the version without an accent. Both the native English and native German listeners classified the virtual robot with a German accent as significantly more neurotic than the virtual robot speaking standard English. This work shows that by solely implementing a non-native accent in a virtual robot, stereotypes are partly transferred. It also shows that the implementation of a non-native accent leads to differences in the perception of the virtual robot.},
  archive      = {J_FROBT},
  author       = {Obremski, David and Friedrich, Paula and Haak, Nora and Schaper, Philipp and Lugrin, Birgit},
  doi          = {10.3389/frobt.2022.983955},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {983955},
  shortjournal = {Front. Robot. AI},
  title        = {The impact of mixed-cultural speech on the stereotypical perception of a virtual robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). State-transfer modeling collective behavior of multi-ball
bernoulli system based on local interaction forces. <em>FROBT</em>,
<em>9</em>, 980586. (<a
href="https://doi.org/10.3389/frobt.2022.980586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collective behavior observed in nature has been actively employed in swarm robotics. In order to better respond to external cues, the agents in such systems organize themselves in an ordered structure based on simple local rules. The central assumption, in swarm robotics, is that all agents in the system collaborate to fulfill a common goal. In nature, however, many multi-agent systems exhibit a more complex collective behavior involving a certain level of competition. One representative example of complex collective behavior is a multi-ball Bernoulli-ball system. In this paper, by extracting local force among the Bernoulli balls, we approximated the state-transfer model mapping interaction forces to observed behaviors. The results show that the collective Bernoulli-ball system spent 41% of its time on competitive behaviors, in which up to 84% of the interaction state is unorganized. The rest 59% of the time is spent on collaborative behavior. We believe that the novel proposed model opens new avenues in swarm robotics research.},
  archive      = {J_FROBT},
  author       = {Ye, Fan and Abdulali, Arsen and Iida, Fumiya},
  doi          = {10.3389/frobt.2022.980586},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {980586},
  shortjournal = {Front. Robot. AI},
  title        = {State-transfer modeling collective behavior of multi-ball bernoulli system based on local interaction forces},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). NN-poly: Approximating common neural networks with taylor
polynomials to imbue dynamical system constraints. <em>FROBT</em>,
<em>9</em>, 968305. (<a
href="https://doi.org/10.3389/frobt.2022.968305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have bolstered our ability to forecast the evolution of dynamical systems, but common neural networks do not adhere to physical laws, critical information that could lead to sounder state predictions. This contribution addresses this concern by proposing a neural network to polynomial (NN-Poly) approximation, a method that furnishes algorithmic guarantees of adhering to physics while retaining state prediction accuracy. To achieve these goals, this article shows how to represent a trained fully connected perceptron, convolution, and recurrent neural networks of various activation functions as Taylor polynomials of arbitrary order. This solution is not only analytic in nature but also least squares optimal. The NN-Poly system identification or state prediction method is evaluated against a single-layer neural network and a polynomial trained on data generated by dynamic systems. Across our test cases, the proposed method maintains minimal root mean-squared state error, requires few parameters to form, and enables model structure for verification and safety. Future work will incorporate safety constraints into state predictions, with this new model structure and test high-dimensional dynamical system data.},
  archive      = {J_FROBT},
  author       = {Zhu, Frances and Jing, Dongheng and Leve, Frederick and Ferrari, Silvia},
  doi          = {10.3389/frobt.2022.968305},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {968305},
  shortjournal = {Front. Robot. AI},
  title        = {NN-poly: Approximating common neural networks with taylor polynomials to imbue dynamical system constraints},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social agents as catalysts: Social dynamics in the classroom
with book introduction robot. <em>FROBT</em>, <em>9</em>, 934325. (<a
href="https://doi.org/10.3389/frobt.2022.934325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the possible benefits of robot-mediated education is the effect of the robot becoming a catalyst between people and facilitating learning. In this study, the authors focused on an asynchronous active learning method mediated by robots. Active learning is believed to help students continue learning and develop the ability to think independently. Therefore, the authors improved the UGA (User Generated Agent) system that we have created for long-term active learning in COVID-19 to create an environment where children introduce books to each other via robots. The authors installed the robot in an elementary school and conducted an experiment lasting more than a year. As a result, it was confirmed that the robot could continue to be used without getting bored even over a long period of time. They also analyzed how the children created the contents by analyzing the contents that had a particularly high number of views. In particular, the authors observed changes in children’s behavior, such as spontaneous advertising activities, guidance from upperclassmen to lowerclassmen, collaboration with multiple people, and increased interest in technology, even under conditions where the new coronavirus was spreading and children’s social interaction was inhibited.},
  archive      = {J_FROBT},
  author       = {Osawa, Hirotaka and Horino, Kohei and Sato, Takuya},
  doi          = {10.3389/frobt.2022.934325},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {934325},
  shortjournal = {Front. Robot. AI},
  title        = {Social agents as catalysts: Social dynamics in the classroom with book introduction robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assessing tele-manipulation systems using task performance
for glovebox operations. <em>FROBT</em>, <em>9</em>, 932538. (<a
href="https://doi.org/10.3389/frobt.2022.932538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tele-manipulation is indispensable for the nuclear industry since teleoperated robots cancel the radiation hazard problem for the operator. The majority of the teleoperated solutions used in the nuclear industry rely on bilateral teleoperation, utilizing a variation of the 4-channel architecture, where the motion and force signals of the local and remote robots are exchanged in the communication channel. However, the performance limitation of teleoperated robots for nuclear decommissioning tasks is not clearly answered in the literature. In this study, we assess the task performance in bilateral tele-manipulation for radiation surveying in gloveboxes and compare it to radiation surveying of a glovebox operator. To analyze the performance, an experimental setup suitable for human operation (manual operation) and tele-manipulation is designed. Our results showed that a current commercial off-the-shelf (COTS) teleoperated robotic manipulation solution is flexible, yet insufficient, as its task performance is significantly lower when compared to manual operation and potentially hazardous for the equipment inside the glovebox. Finally, we propose a set of potential solutions, derived from both our observations and expert interviews, that could improve the performance of teleoperation systems in glovebox environments in future work.},
  archive      = {J_FROBT},
  author       = {Lopez Pulgarin, Erwin Jose and Tokatli, Ozan and Burroughes, Guy and Herrmann, Guido},
  doi          = {10.3389/frobt.2022.932538},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {932538},
  shortjournal = {Front. Robot. AI},
  title        = {Assessing tele-manipulation systems using task performance for glovebox operations},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Benchmarking the utility of maps of dynamics for human-aware
motion planning. <em>FROBT</em>, <em>9</em>, 916153. (<a
href="https://doi.org/10.3389/frobt.2022.916153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots operating with humans in highly dynamic environments need not only react to moving persons and objects but also to anticipate and adhere to patterns of motion of dynamic agents in their environment. Currently, robotic systems use information about dynamics locally, through tracking and predicting motion within their direct perceptual range. This limits robots to reactive response to observed motion and to short-term predictions in their immediate vicinity. In this paper, we explore how maps of dynamics (MoDs) that provide information about motion patterns outside of the direct perceptual range of the robot can be used in motion planning to improve the behaviour of a robot in a dynamic environment. We formulate cost functions for four MoD representations to be used in any optimizing motion planning framework. Further, to evaluate the performance gain through using MoDs in motion planning, we design objective metrics, and we introduce a simulation framework for rapid benchmarking. We find that planners that utilize MoDs waste less time waiting for pedestrians, compared to planners that use geometric information alone. In particular, planners utilizing both intensity (proportion of observations at a grid cell where a dynamic entity was detected) and direction information have better task execution efficiency.},
  archive      = {J_FROBT},
  author       = {Swaminathan, Chittaranjan Srinivas and Kucner, Tomasz Piotr and Magnusson, Martin and Palmieri, Luigi and Molina, Sergi and Mannucci, Anna and Pecora, Federico and Lilienthal, Achim J.},
  doi          = {10.3389/frobt.2022.916153},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {916153},
  shortjournal = {Front. Robot. AI},
  title        = {Benchmarking the utility of maps of dynamics for human-aware motion planning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A human-in-the-loop approach for enhancing mobile robot
navigation in presence of obstacles not detected by the sensory set.
<em>FROBT</em>, <em>9</em>, 909971. (<a
href="https://doi.org/10.3389/frobt.2022.909971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-in-the-loop approaches can greatly enhance the human–robot interaction by making the user an active part of the control loop, who can provide a feedback to the robot in order to augment its capabilities. Such feedback becomes even more important in all those situations where safety is of utmost concern, such as in assistive robotics. This study aims to realize a human-in-the-loop approach, where the human can provide a feedback to a specific robot, namely, a smart wheelchair, to augment its artificial sensory set, extending and improving its capabilities to detect and avoid obstacles. The feedback is provided by both a keyboard and a brain–computer interface: with this scope, the work has also included a protocol design phase to elicit and evoke human brain event–related potentials. The whole architecture has been validated within a simulated robotic environment, with electroencephalography signals acquired from different test subjects.},
  archive      = {J_FROBT},
  author       = {Ferracuti, Francesco and Freddi, Alessandro and Iarlori, Sabrina and Monteriù, Andrea and Omer, Karameldeen Ibrahim Mohamed and Porcaro, Camillo},
  doi          = {10.3389/frobt.2022.909971},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {909971},
  shortjournal = {Front. Robot. AI},
  title        = {A human-in-the-loop approach for enhancing mobile robot navigation in presence of obstacles not detected by the sensory set},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the application of population-based structural health
monitoring in aerospace engineering. <em>FROBT</em>, <em>9</em>, 840058.
(<a href="https://doi.org/10.3389/frobt.2022.840058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major obstacles to the widespread uptake of data-based Structural Health Monitoring so far, has been the lack of damage-state data for the (mostly high-value) structures of interest. To address this issue, a methodology for sharing data and models between structures has been developed–Population-Based Structural Health Monitoring (PBSHM). PBSHM works on the principle that, if populations of structures are sufficiently similar, or share sections which can be considered similar, then data and models can be shared between them for use in diagnostic inference. The PBSHM methodology therefore relies on two key components: firstly, identifying whether structures are sufficiently similar for successful transfer of diagnostics; this is achieved by the use of an abstract representation of structures. Secondly, machine learning techniques are exploited to effectively transfer information between the structures in a way that improves damage detection and classification across the whole population. Although PBSHM has been conceived to deal with large and general classes of structures, much of the detailed developments presented so far have concerned bridges; the aim of this paper is to provide similarly detailed discussions in the aerospace context. The overview here will examine data transfer between aircraft components, as well as illustrating how one might construct an abstract representation of a full aircraft.},
  archive      = {J_FROBT},
  author       = {Brennan, Daniel S. and Gosliga, Julian and Gardner, Paul and Mills, Robin S. and Worden, Keith},
  doi          = {10.3389/frobt.2022.840058},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {840058},
  shortjournal = {Front. Robot. AI},
  title        = {On the application of population-based structural health monitoring in aerospace engineering},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Robots for learning. <em>FROBT</em>, <em>9</em>,
1050658. (<a href="https://doi.org/10.3389/frobt.2022.1050658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Johal, Wafa and Belpaeme, Tony and Chetouani, Mohamed},
  doi          = {10.3389/frobt.2022.1050658},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1050658},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robots for learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Supervision, control and learning for intelligent
robot systems. <em>FROBT</em>, <em>9</em>, 1050237. (<a
href="https://doi.org/10.3389/frobt.2022.1050237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lima, Pedro U. and Iocchi, Luca},
  doi          = {10.3389/frobt.2022.1050237},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1050237},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Supervision, control and learning for intelligent robot systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Hot topic: Reducing operating times and
complication rates through robot-assisted surgery. <em>FROBT</em>,
<em>9</em>, 1046321. (<a
href="https://doi.org/10.3389/frobt.2022.1046321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Cafolla, Daniele and Calimeri, Francesco and Cao, Huiping and Russo, Matteo and Sappey-Marinier, Dominique and Zaffino, Paolo},
  doi          = {10.3389/frobt.2022.1046321},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1046321},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: hot topic: reducing operating times and complication rates through robot-assisted surgery},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QUaRTM: A quadcopter with unactuated rotor tilting mechanism
capable of faster, more agile, and more efficient flight.
<em>FROBT</em>, <em>9</em>, 1033715. (<a
href="https://doi.org/10.3389/frobt.2022.1033715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present QUaRTM – a novel quadcopter design capable of tilting the propellers into the forward flight direction, which reduces the drag area and therefore allows for faster, more agile, and more efficient flight. The vehicle can morph between two configurations in mid-air, including the untilted configuration and the tilted configuration. The vehicle in the untilted configuration has a higher pitch torque capacity and a smaller vertical dimension. The vehicle in the tilted configuration has a lower drag area, leading to a higher top speed, higher agility at high speed, and better flight efficiency. The morphing is accomplished without any additional actuators beyond the four motors of a quadcopter. The rigid connections between the quadcopter frame and the quadcopter arms are replaced with sprung hinges. This allows the propellers to be tilted when high thrusts are produced, and recover to the untilted configuration when the thrusts are brought low. The effectiveness of such a vehicle is demonstrated by running experiments on a prototype vehicle with a shape similar to a regular quadcopter. Through the use of tilting, the vehicle is shown to have a 12.5% higher maximum speed, better high-speed agility as the maximum crash-free cruise speed increased by 7.5%, and a better flight efficiency as the power consumption has dropped by more than 20% in the speed range of 15–20 m s−1.},
  archive      = {J_FROBT},
  author       = {Tang, Jerry and Jain, Karan P. and Mueller, Mark W.},
  doi          = {10.3389/frobt.2022.1033715},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1033715},
  shortjournal = {Front. Robot. AI},
  title        = {QUaRTM: A quadcopter with unactuated rotor tilting mechanism capable of faster, more agile, and more efficient flight},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Confidentiality in medical images through a genetic-based
steganography algorithm in artificial intelligence. <em>FROBT</em>,
<em>9</em>, 1031299. (<a
href="https://doi.org/10.3389/frobt.2022.1031299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, image steganography has an important role in hiding information in advanced applications, such as medical image communication, confidential communication and secret data storing, protection of data alteration, access control system for digital content distribution and media database systems. In these applications, one of the most important aspects is to hide information in a cover image whithout suffering any alteration. Currently, all existing approaches used to hide a secret message in a cover image produce some level of distortion in this image. Although these levels of distortion present acceptable PSNR values, this causes minimal visual degradation that can be detected by steganalysis techniques. In this work, we propose a steganographic method based on a genetic algorithm to improve the PSNR level reduction. To achieve this aim, the proposed algorithm requires a private key composed of two values. The first value serves as a seed to generate the random values required on the genetic algorithm, and the second value represents the sequence of bit locations of the secret medical image within the cover image. At least the seed must be shared by a secure communication channel. The results demonstrate that the proposed method exhibits higher capacity in terms of PNSR level compared with existing works.},
  archive      = {J_FROBT},
  author       = {Vazquez, Eduardo and Torres, Stephanie and Sanchez, Giovanny and Avalos, Juan-Gerardo and Abarca, Marco and Frias, Thania and Juarez, Emmanuel and Trejo, Carlos and Hernandez, Derlis},
  doi          = {10.3389/frobt.2022.1031299},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1031299},
  shortjournal = {Front. Robot. AI},
  title        = {Confidentiality in medical images through a genetic-based steganography algorithm in artificial intelligence},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Technological robot—machine tool collaboration for agile
production. <em>FROBT</em>, <em>9</em>, 1027173. (<a
href="https://doi.org/10.3389/frobt.2022.1027173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexibility and efficiency in parts production can be significantly increased through the technological cooperation of industrial robots and machine tools. The paper presents an approach in which a robot, in addition to the classic handling tasks, enhance machine tools by additional manufacturing technologies and thus beneficially supports workpiece machining. This can take place in various configurations, starting with pre- and final machining by the robot outside the machine, through sequential cooperative machining of the workpiece clamped in the machine, to parallel, synchronized machining of a workpiece in the machine. The approach results in a novel type of collaborative manufacturing equipment for matrix production that will improve the versatility, efficiency and profitability in production.},
  archive      = {J_FROBT},
  author       = {Wabner, Markus and Rentzsch, Hendrik and Ihlenfeldt, Steffen and Otto, Andreas},
  doi          = {10.3389/frobt.2022.1027173},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1027173},
  shortjournal = {Front. Robot. AI},
  title        = {Technological robot—Machine tool collaboration for agile production},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Progress and challenges in adaptive robotics.
<em>FROBT</em>, <em>9</em>, 1020462. (<a
href="https://doi.org/10.3389/frobt.2022.1020462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nolfi, Stefano},
  doi          = {10.3389/frobt.2022.1020462},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1020462},
  shortjournal = {Front. Robot. AI},
  title        = {Progress and challenges in adaptive robotics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Soft robotics based on liquid crystal elastomers
(LCEs). <em>FROBT</em>, <em>9</em>, 1018819. (<a
href="https://doi.org/10.3389/frobt.2022.1018819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Wang, Zhijian and Boothby, Jennifer and Roach, Devin J. and He, Qiguang},
  doi          = {10.3389/frobt.2022.1018819},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1018819},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Soft robotics based on liquid crystal elastomers (LCEs)},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transient bio-inspired gliders with embodied humidity
responsive actuators for environmental sensing. <em>FROBT</em>,
<em>9</em>, 1011793. (<a
href="https://doi.org/10.3389/frobt.2022.1011793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting temporal and spatial high-resolution environmental data can guide studies in environmental sciences to gain insights in ecological processes. The utilization of automated robotic systems to collect these types of data can maximize accuracy, resilience, and deployment rate. Furthermore, it reduces the risk to researchers deploying sensors in inaccessible environments and can significantly increase the cost-effectiveness of such studies. The introduction of transient robotic systems featuring embodied environmental sensors pushes towards building a digital ecology, while introducing only minimal disturbance to the environment. Transient robots made from fully biodegradable and non-fossil based materials, do not develop into hazardous e-waste at the end of their lifetime and can thus enable a broader adoption for environmental sensing in the real world. In this work, our approach towards the design of transient robots includes the integration of humidity-responsive materials in a glider, which is inspired by the Alsomitra macrocarpa seed. The design space of these gliders is explored and their behavior studied numerically, which allows us to make predictions on their flight characteristics. Results are validated against experiments, which show two different gliding behaviors, that can help improve the spread of the sensors. By tailoring the Cellulose-Gelatin composition of the humidity actuator, self-folding systems for selective rainwater exposure can be designed. The pH sensing layer, protected by the actuator, provides visual feedback on the pH of the rainwater. The presented methods can guide further concepts developing transient aerial robotic systems for sustainable, environmental monitoring.},
  archive      = {J_FROBT},
  author       = {Wiesemüller, Fabian and Meng, Ziwen and Hu, Yijie and Farinha, Andre and Govdeli, Yunus and Nguyen, Pham H. and Nyström, Gustav and Kovač, Mirko},
  doi          = {10.3389/frobt.2022.1011793},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1011793},
  shortjournal = {Front. Robot. AI},
  title        = {Transient bio-inspired gliders with embodied humidity responsive actuators for environmental sensing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Finding ikigai: How robots can support meaning in later
life. <em>FROBT</em>, <em>9</em>, 1011327. (<a
href="https://doi.org/10.3389/frobt.2022.1011327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous research in human-robot interaction has explored using robots to increase objective and hedonic aspects of well-being and quality of life, but there is no literature on how robots might be used to support eudaimonic aspects of well-being (such as meaning in life). A sense of meaning has been shown to positively affect health and longevity. We frame our study around the Japanese concept of ikigai, which is widely used with Japanese older adults to enhance their everyday lives, and is closely related to the concept of eudaimonic well-being (EWB) known in Western countries. Using a mixed-methods and exploratory approach, including interviews with 17 older adults and the collection of 100 survey responses, we explored how older adults in the US experience a sense of meaning, and if and how a social robot could be used to help foster this sense. We find that meaning for older adults is often obtained by helping others, through family connections, and/or through activities of daily life, and that sources of meaning often differ based on the older adults’ living situation. Assessing how meaning compares to happiness and social connection, we highlight general similarities and differences, and also find that living situation influences older adults’ sources of happiness, desire for social connection, and barriers to well-being, in addition to companionship and happiness having a weaker correlation with meaning for those who live alone than for those who live with others. Additionally, we evaluated initial perceptions of a social robot (QT) meant to enhance ikigai and overall well-being, finding mostly positive perceptions, though those who live alone also reported being less willing to adopt a social robot into their homes. Using both data collected on older adults’ meaning and the potential use of QT to support meaning, we make several design recommendations with regards to using robots to enhance ikigai, such as by prompting daily reflecting, enhancing family bonds, and suggesting new experiences and volunteer opportunities.},
  archive      = {J_FROBT},
  author       = {Randall, Natasha and Joshi, Swapna and Kamino, Waki and Hsu, Long-Jing and Agnihotri, Abhijeet and Li, Grace and Williamson, Donald and Tsui, Kate and Šabanović, Selma},
  doi          = {10.3389/frobt.2022.1011327},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1011327},
  shortjournal = {Front. Robot. AI},
  title        = {Finding ikigai: How robots can support meaning in later life},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards the neuroevolution of low-level artificial general
intelligence. <em>FROBT</em>, <em>9</em>, 1007547. (<a
href="https://doi.org/10.3389/frobt.2022.1007547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we argue that the search for Artificial General Intelligence should start from a much lower level than human-level intelligence. The circumstances of intelligent behavior in nature resulted from an organism interacting with its surrounding environment, which could change over time and exert pressure on the organism to allow for learning of new behaviors or environment models. Our hypothesis is that learning occurs through interpreting sensory feedback when an agent acts in an environment. For that to happen, a body and a reactive environment are needed. We evaluate a method to evolve a biologically-inspired artificial neural network that learns from environment reactions named Neuroevolution of Artificial General Intelligence, a framework for low-level artificial general intelligence. This method allows the evolutionary complexification of a randomly-initialized spiking neural network with adaptive synapses, which controls agents instantiated in mutable environments. Such a configuration allows us to benchmark the adaptivity and generality of the controllers. The chosen tasks in the mutable environments are food foraging, emulation of logic gates, and cart-pole balancing. The three tasks are successfully solved with rather small network topologies and therefore it opens up the possibility of experimenting with more complex tasks and scenarios where curriculum learning is beneficial.},
  archive      = {J_FROBT},
  author       = {Pontes-Filho, Sidney and Olsen, Kristoffer and Yazidi, Anis and Riegler, Michael A. and Halvorsen, Pål and Nichele, Stefano},
  doi          = {10.3389/frobt.2022.1007547},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1007547},
  shortjournal = {Front. Robot. AI},
  title        = {Towards the neuroevolution of low-level artificial general intelligence},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). No-code robotic programming for agile production: A new
markerless-approach for multimodal natural interaction in a human-robot
collaboration context. <em>FROBT</em>, <em>9</em>, 1001955. (<a
href="https://doi.org/10.3389/frobt.2022.1001955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial robots and cobots are widely deployed in most industrial sectors. However, robotic programming still needs a lot of time and effort in small batch sizes, and it demands specific expertise and special training, especially when various robotic platforms are required. Actual low-code or no-code robotic programming solutions are exorbitant and meager. This work proposes a novel approach for no-code robotic programming for end-users with adequate or no expertise in industrial robotic. The proposed method ensures intuitive and fast robotic programming by utilizing a finite state machine with three layers of natural interactions based on hand gesture, finger gesture, and voice recognition. The implemented system combines intelligent computer vision and voice control capabilities. Using a vision system, the human could transfer spatial information of a 3D point, lines, and trajectories using hand and finger gestures. The voice recognition system will assist the user in parametrizing robot parameters and interacting with the robot’s state machine. Furthermore, the proposed method will be validated and compared with state-of-the-art “Hand-Guiding” cobot devices within real-world experiments. The results obtained are auspicious, and indicate the capability of this novel approach for real-world deployment in an industrial context.},
  archive      = {J_FROBT},
  author       = {Halim, Jayanto and Eichler, Paul and Krusche, Sebastian and Bdiwi, Mohamad and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2022.1001955},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1001955},
  shortjournal = {Front. Robot. AI},
  title        = {No-code robotic programming for agile production: A new markerless-approach for multimodal natural interaction in a human-robot collaboration context},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multiarticulate pediatric prosthetic hand for clinical and
research applications. <em>FROBT</em>, <em>9</em>, 1000159. (<a
href="https://doi.org/10.3389/frobt.2022.1000159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although beginning to emerge, multiarticulate upper limb prostheses for children remain sparse despite the continued advancement of mechatronic technologies that have benefited adults with upper limb amputations. Upper limb prosthesis research is primarily focused on adults, even though rates of pediatric prosthetic abandonment far surpass those seen in adults. The implicit goal of a prosthesis is to provide effective functionality while promoting healthy social interaction. Yet most current pediatric devices offer a single degree of freedom open/close grasping function, a stark departure from the multiple grasp configurations provided in advanced adult devices. Although comparable child-sized devices are on the clinical horizon, understanding how to effectively translate these technologies to the pediatric population is vital. This includes exploring grasping movements that may provide the most functional benefits and techniques to control the newly available dexterity. Currently, no dexterous pediatric research platforms exist that offer open access to hardware and programming to facilitate the investigation and provision of multi-grasp function. Our objective was to deliver a child-sized multi-grasp prosthesis that may serve as a robust research platform. In anticipation of an open-source release, we performed a comprehensive set of benchtop and functional tests with common household objects to quantify the performance of our device. This work discusses and evaluates our pediatric-sized multiarticulate prosthetic hand that provides 6 degrees of actuation, weighs 177 g and was designed specifically for ease of implementation in a research or clinical-research setting. Through the benchtop and validated functional tests, the pediatric hand produced grasping forces ranging from 0.424–7.216 N and was found to be comparable to the functional capabilities of similar adult devices. As mechatronic technologies advance and multiarticulate prostheses continue to evolve, translating many of these emerging technologies may help provide children with more useful and functional prosthesis options. Effective translation will inevitably require a solid scientific foundation to inform how best to prescribe advanced prosthetic devices and control systems for children. This work begins addressing these current gaps by providing a much-needed research platform with supporting data to facilitate its use in laboratory and clinical research settings.},
  archive      = {J_FROBT},
  author       = {Battraw, Marcus A. and Young, Peyton R. and Joiner, Wilsaan M. and Schofield, Jonathon S.},
  doi          = {10.3389/frobt.2022.1000159},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1000159},
  shortjournal = {Front. Robot. AI},
  title        = {A multiarticulate pediatric prosthetic hand for clinical and research applications},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mole crab-inspired vertical self-burrowing. <em>FROBT</em>,
<em>9</em>, 999392. (<a
href="https://doi.org/10.3389/frobt.2022.999392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present EMBUR—EMerita BUrrowing Robot—the first legged robot inspired by the Pacific mole crab, Emerita analoga, capable of burrowing vertically downward. We choose Emerita analoga as a model organism for its rapid downward burrowing behaviors, as it is four times as fast as the most rapid bivalve mollusk. Vertical burrowing in granular media is a challenging endeavor due to the tendency for the media to create upwards resistive forces on an intruder, even during purely horizontal motions. Our robot is capable of vertically burrowing its body in granular substrate primarily through excavation using two leg pairs, which are functionally analogous to groupings of leg pairs of the mole crab. We implement a novel leg mechanism with a sweeping trajectory, using compliant fabric to enable an anisotropic force response. The maximum resistive force during the power stroke is 6.4 times that of the return stroke. We compare robot body pitch and spatial trajectories with results from biomechanical studies of the mole crabs. We characterize the sensitivity of the robot to initial depth, body pitch and leg pose, and propose bounds on initial conditions which predict various burrowing failure modes. Parametric studies utilizing Granular Resistive Force Theory inform our understanding of robot behavior in response to leg phasing and orientation. Not only does this robotic platform represent the first robophysical model of vertical mole crab-inspired burrowing, it is also one of the first legged, primarily excavative small-scale burrowing agents.},
  archive      = {J_FROBT},
  author       = {Treers, Laura K. and McInroe, Benjamin and Full, Robert J. and Stuart, Hannah S.},
  doi          = {10.3389/frobt.2022.999392},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {999392},
  shortjournal = {Front. Robot. AI},
  title        = {Mole crab-inspired vertical self-burrowing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biomechanical knee energy harvester: Design optimization and
testing. <em>FROBT</em>, <em>9</em>, 998248. (<a
href="https://doi.org/10.3389/frobt.2022.998248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomechanical energy harvesters are designed to generate electrical energy from human locomotion (e.g., walking) with minimal or no additional effort by the users. These harvesters aim to carry out the work of the muscles during phases in locomotion where the muscles are acting as brakes. Currently, many harvesters focus on the knee joint during late swing, which is only one of three phases available during the gait cycle. For the device to be successful, there is a need to consider design components such as the motor/generator and the gear ratio. These components influence the amount of electrical energy that could be harvested, metabolic power during harvesting, and more. These various components make it challenging to achieve the optimal design. This paper presents a design of a knee harvester with a direct drive that enables harvesting both in flexion and extension using optimization. Subsequently, two knee devices were built and tested using five different harvesting levels. Results show that the 30% level was the best, harvesting approximately 5 W of electricity and redacting 8 W of metabolic energy compared to walking with the device as a dead weight. Evaluation of the models used in the optimization showed a good match to the system model but less for the metabolic power model. These results could pave the way for an energy harvester that could utilize more of the negative joint power during the gait cycle while reducing metabolic effort.},
  archive      = {J_FROBT},
  author       = {Gad, Moran and Lev-Ari, Ben and Shapiro, Amir and Ben-David, Coral and Riemer, Raziel},
  doi          = {10.3389/frobt.2022.998248},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {998248},
  shortjournal = {Front. Robot. AI},
  title        = {Biomechanical knee energy harvester: Design optimization and testing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human augmentation, not replacement: A research agenda for
AI and robotics in the industry. <em>FROBT</em>, <em>9</em>, 997386. (<a
href="https://doi.org/10.3389/frobt.2022.997386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dégallier-Rochat, Sarah and Kurpicz-Briki, Mascha and Endrissat, Nada and Yatsenko, Olena},
  doi          = {10.3389/frobt.2022.997386},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {997386},
  shortjournal = {Front. Robot. AI},
  title        = {Human augmentation, not replacement: A research agenda for AI and robotics in the industry},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-based contact detection and position control of a
fabric soft robot in unknown environments. <em>FROBT</em>, <em>9</em>,
997366. (<a href="https://doi.org/10.3389/frobt.2022.997366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots have shown great potential to enable safe interactions with unknown environments due to their inherent compliance and variable stiffness. However, without knowledge of potential contacts, a soft robot could exhibit rigid behaviors in a goal-reaching task and collide into obstacles. In this paper, we introduce a Sliding Mode Augmented by Reactive Transitioning (SMART) controller to detect the contact events, adjust the robot’s desired trajectory, and reject estimated disturbances in a goal reaching task. We employ a sliding mode controller to track the desired trajectory with a nonlinear disturbance observer (NDOB) to estimate the lumped disturbance, and a switching algorithm to adjust the desired robot trajectories. The proposed controller is validated on a pneumatic-driven fabric soft robot whose dynamics is described by a new extended rigid-arm model to fit the actuator design. A stability analysis of the proposed controller is also presented. Experimental results show that, despite modeling uncertainties, the robot can detect obstacles, adjust the reference trajectories to maintain compliance, and recover to track the original desired path once the obstacle is removed. Without force sensors, the proposed model-based controller can adjust the robot’s stiffness based on the estimated disturbance to achieve goal reaching and compliant interaction with unknown obstacles.},
  archive      = {J_FROBT},
  author       = {Qiao, Zhi and Nguyen, Pham H. and Zhang, Wenlong},
  doi          = {10.3389/frobt.2022.997366},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {997366},
  shortjournal = {Front. Robot. AI},
  title        = {Model-based contact detection and position control of a fabric soft robot in unknown environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design engineering a walking robotic manipulator for
in-space assembly missions. <em>FROBT</em>, <em>9</em>, 995813. (<a
href="https://doi.org/10.3389/frobt.2022.995813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-Space Services aim to introduce sustainable futuristic technology to support the current and growing orbital ecosystem. As the scale of space missions grows, there is a need for more extensive infrastructures in orbit. In-Space Assembly missions would hold one of the key responsibilities in meeting the increasing demand. In the forthcoming decades, newer infrastructures in the Earth’s orbits, which are much more advanced than the International Space Station are needed for in-situ manufacturing, servicing, and astronomical and observational stations. The prospect of in-orbit commissioning a Large Aperture Space Telescope (LAST) has fuelled scientific and commercial interests in deep-space astronomy and Earth Observation. However, the in-situ assembly of such large-scale, high-value assets in extreme environments, like space, is highly challenging and requires advanced robotic solutions. This paper introduces an innovative dexterous walking robotic system for in-orbit assembly missions and considers the Large Aperture Space Telescope system with an aperture of 25 m as the use case. The top-level assembly requirements are identified with a deep insight into the critical functionalities and challenges to overcome while assembling the modular LAST. The design and sizing of an End-over-end Walking Robot (E-Walker) are discussed based on the design of the LAST and the specifications of the spacecraft platform. The E-Walker’s detailed design engineering includes the structural finite element analysis results for space and earth-analogue design and the corresponding actuator selection methods. Results of the modal analysis demonstrate the deflections in the E-Walker links and end-effector in the open-loop due to the extremities present in the space environment. The design and structural analysis of E-Walker’s scaled-down prototype is also presented to showcase its feasibility in supporting both in-orbit and terrestrial activities requiring robotic capabilities over an enhanced workspace. Further, the mission concept of operations is presented based on two E-Walkers that carry out the assembly of the mirror modules. The mission discussed was shortlisted after conducting an extensive trade-off study in the literature. Simulated results prove the dual E-Walker robotic system’s efficacy for accomplishing complex in-situ assembly operations through task-sharing.},
  archive      = {J_FROBT},
  author       = {Nair, Manu Harikrishnan and Rai, Mini Chakravarthini and Poozhiyil, Mithun},
  doi          = {10.3389/frobt.2022.995813},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {995813},
  shortjournal = {Front. Robot. AI},
  title        = {Design engineering a walking robotic manipulator for in-space assembly missions},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impact of resolution, colour, and motion on object
identification in digital twins from robot sensor data. <em>FROBT</em>,
<em>9</em>, 995342. (<a
href="https://doi.org/10.3389/frobt.2022.995342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper makes a contribution to research on digital twins that are generated from robot sensor data. We present the results of an online user study in which 240 participants were tasked to identify real-world objects from robot point cloud data. In the study we manipulated the render style (point clouds vs voxels), render resolution (i.e., density of point clouds and granularity of voxel grids), colour (monochrome vs coloured points/voxels), and motion (no motion vs rotational motion) of the shown objects to measure the impact of these attributes on object recognition performance. A statistical analysis of the study results suggests that there is a three-way interaction between our independent variables. Further analysis suggests: 1) objects are easier to recognise when rendered as point clouds than when rendered as voxels, particularly lower resolution voxels; 2) the effect of colour and motion is affected by how objects are rendered, e.g., utility of colour decreases with resolution for point clouds; 3) an increased resolution of point clouds only leads to an increased object recognition if points are coloured and static; 4) high resolution voxels outperform medium and low resolution voxels in all conditions, but there is little difference between medium and low resolution voxels; 5) motion is unable to improve the performance of voxels at low and medium resolutions, but is able to improve performance for medium and low resolution point clouds. Our results have implications for the design of robot sensor suites and data gathering and transmission protocols when creating digital twins from robot gathered point cloud data.},
  archive      = {J_FROBT},
  author       = {Bremner, Paul and Giuliani, Manuel},
  doi          = {10.3389/frobt.2022.995342},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {995342},
  shortjournal = {Front. Robot. AI},
  title        = {Impact of resolution, colour, and motion on object identification in digital twins from robot sensor data},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Phenotypic complexity and evolvability in evolving robots.
<em>FROBT</em>, <em>9</em>, 994485. (<a
href="https://doi.org/10.3389/frobt.2022.994485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The propensity of evolutionary algorithms to generate compact solutions have advantages and disadvantages. On one side, compact solutions can be cheaper, lighter, and faster than less compact ones. On the other hand, compact solutions might lack evolvability, i.e. might have a lower probability to improve as a result of genetic variations. In this work we study the relation between phenotypic complexity and evolvability in the case of soft-robots with varying morphology. We demonstrate a correlation between phenotypic complexity and evolvability. We demonstrate that the tendency to select compact solutions originates from the fact that the fittest robots often correspond to phenotypically simple robots which are robust to genetic variations but lack evolvability. Finally, we demonstrate that the efficacy of the evolutionary process can be improved by increasing the probability of genetic variations which produce a complexification of the agents’ phenotype or by using absolute mutation rates.},
  archive      = {J_FROBT},
  author       = {Milano, Nicola and Nolfi, Stefano},
  doi          = {10.3389/frobt.2022.994485},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {994485},
  shortjournal = {Front. Robot. AI},
  title        = {Phenotypic complexity and evolvability in evolving robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computationally efficient and sub-optimal trajectory
planning framework based on trajectory-quality growth rate analysis.
<em>FROBT</em>, <em>9</em>, 994437. (<a
href="https://doi.org/10.3389/frobt.2022.994437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A planetary exploration rover has been used for scientific missions or as a precursor for a future manned mission. The rover’s autonomous system is managed by a space-qualified, radiation-hardened onboard computer; hence, the processing performance for such a computer is strictly limited, owing to the limitation to power supply. Generally, a computationally efficient algorithm in the autonomous system is favorable. This study, therefore, presents a computationally efficient and sub-optimal trajectory planning framework for the rover. The framework exploits an incremental search algorithm, which can generate more optimal solutions as the number of iterations increases. Such an incremental search is subjected to the trade-off between trajectory optimality and computational burden. Therefore, we introduce the trajectory-quality growth rate (TQGR) to statistically analyze the relationship between trajectory optimality and computational cost. This analysis is conducted in several types of terrain, and the planning stop criterion is estimated. Furthermore, the relation between terrain features and the stop criterion is modeled offline by a machine learning technique. Then, using the criterion predicted by the model, the proposed framework appropriately interrupts the incremental search in online motion planning, resulting in a sub-optimal trajectory with less computational burden. Trajectory planning simulation in various real terrain data validates that the proposed framework can, on average, reduce the computational cost by 47.6% while maintaining 63.8% of trajectory optimality. Furthermore, the simulation result shows the proposed framework still performs well even though the planning stop criterion is not adequately predicted.},
  archive      = {J_FROBT},
  author       = {Takemura, Reiya and Ishigami, Genya},
  doi          = {10.3389/frobt.2022.994437},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {994437},
  shortjournal = {Front. Robot. AI},
  title        = {Computationally efficient and sub-optimal trajectory planning framework based on trajectory-quality growth rate analysis},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning bio-inspired head-centric representations of 3D
shapes in an active fixation setting. <em>FROBT</em>, <em>9</em>,
994284. (<a href="https://doi.org/10.3389/frobt.2022.994284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When exploring the surrounding environment with the eyes, humans and primates need to interpret three-dimensional (3D) shapes in a fast and invariant way, exploiting a highly variant and gaze-dependent visual information. Since they have front-facing eyes, binocular disparity is a prominent cue for depth perception. Specifically, it serves as computational substrate for two ground mechanisms of binocular active vision: stereopsis and binocular coordination. To this aim, disparity information, which is expressed in a retinotopic reference frame, is combined along the visual cortical pathways with gaze information and transformed in a head-centric reference frame. Despite the importance of this mechanism, the underlying neural substrates still remain widely unknown. In this work, we investigate the capabilities of the human visual system to interpret the 3D scene exploiting disparity and gaze information. In a psychophysical experiment, human subjects were asked to judge the depth orientation of a planar surface either while fixating a target point or while freely exploring the surface. Moreover, we used the same stimuli to train a recurrent neural network to exploit the responses of a modelled population of cortical (V1) cells to interpret the 3D scene layout. The results for both human performance and from the model network show that integrating disparity information across gaze directions is crucial for a reliable and invariant interpretation of the 3D geometry of the scene.},
  archive      = {J_FROBT},
  author       = {Kalou, Katerina and Sedda, Giulia and Gibaldi, Agostino and Sabatini, Silvio P.},
  doi          = {10.3389/frobt.2022.994284},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {994284},
  shortjournal = {Front. Robot. AI},
  title        = {Learning bio-inspired head-centric representations of 3D shapes in an active fixation setting},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian optimization with unknown constraints in graphical
skill models for compliant manipulation tasks using an industrial robot.
<em>FROBT</em>, <em>9</em>, 993359. (<a
href="https://doi.org/10.3389/frobt.2022.993359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on learning manipulation skills from episodic reinforcement learning (RL) in unknown environments using industrial robot platforms. These platforms usually do not provide the required compliant control modalities to cope with unknown environments, e.g., force-sensitive contact tooling. This requires designing a suitable controller, while also providing the ability of adapting the controller parameters from collected evidence online. Thus, this work extends existing work on meta-learning for graphical skill-formalisms. First, we outline how a hybrid force–velocity controller can be applied to an industrial robot in order to design a graphical skill-formalism. This skill-formalism incorporates available task knowledge and allows for online episodic RL. In contrast to the existing work, we further propose to extend this skill-formalism by estimating the success probability of the task to be learned by means of factor graphs. This method allows assigning samples to individual factors, i.e., Gaussian processes (GPs) more efficiently and thus allows improving the learning performance, especially at early stages, where successful samples are usually only drawn in a sparse manner. Finally, we propose suitable constraint GP models and acquisition functions to obtain new samples in order to optimize the information gain, while also accounting for the success probability of the task. We outline a specific application example on the task of inserting the tip of a screwdriver into a screwhead with an industrial robot and evaluate our proposed extension against the state-of-the-art methods. The collected data outline that our method allows artificial agents to obtain feasible samples faster than existing approaches, while achieving a smaller regret value. This highlights the potential of our proposed work for future robotic applications.},
  archive      = {J_FROBT},
  author       = {Gabler, Volker and Wollherr, Dirk},
  doi          = {10.3389/frobt.2022.993359},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {993359},
  shortjournal = {Front. Robot. AI},
  title        = {Bayesian optimization with unknown constraints in graphical skill models for compliant manipulation tasks using an industrial robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Architectural modelling for robotics: RoboArch and the
CorteX example. <em>FROBT</em>, <em>9</em>, 991637. (<a
href="https://doi.org/10.3389/frobt.2022.991637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for robotic systems to be verified grows as robots are increasingly used in complex applications with safety implications. Model-driven engineering and domain-specific languages (DSLs) have proven useful in the development of complex systems. RoboChart is a DSL for modelling robot software controllers using state machines and a simple component model. It is distinctive in that it has a formal semantics and support for automated verification. Our work enriches RoboChart with support for modelling architectures and architectural patterns used in the robotics domain. Support is in the shape of an additional DSL, RoboArch, whose primitive concepts encapsulate the notion of a layered architecture and architectural patterns for use in the design of the layers that are only informally described in the literature. A RoboArch model can be used to generate automatically a sketch of a RoboChart model, and the rules for automatic generation define a semantics for RoboArch. Additional patterns can be formalised by extending RoboArch. In this paper, we present RoboArch, and give a perspective of how it can be used in conjunction with CorteX, a software framework developed for the nuclear industry.},
  archive      = {J_FROBT},
  author       = {Barnett, Will and Cavalcanti, Ana and Miyazawa, Alvaro},
  doi          = {10.3389/frobt.2022.991637},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {991637},
  shortjournal = {Front. Robot. AI},
  title        = {Architectural modelling for robotics: RoboArch and the CorteX example},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Designing for culturally responsive social robots: An
application of a participatory framework. <em>FROBT</em>, <em>9</em>,
983408. (<a href="https://doi.org/10.3389/frobt.2022.983408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating cultural responsiveness into the educational setting is essential to the success of multilingual students. As social robots present the potential to support multilingual children, it is imperative that the design of social robot embodiments and interactions are culturally responsive. This paper summarizes the current literature on educational robots in culturally diverse settings. We argue the use of the Culturally Localized User Experience (CLUE) Framework is essential to ensure cultural responsiveness in HRI design. We present three case studies illustrating the CLUE framework as a social robot design approach. The results of these studies suggest co-design provides multicultural learners an accessible, nonverbal context through which to provide design requirements and preferences. Furthermore, we demonstrate the importance of key stakeholders (students, parents, and teachers) as essential to ensure a culturally responsive robot. Finally, we reflect on our own work with culturally and linguistically diverse learners and propose three guiding principles for successfully engaging diverse learners as valuable cultural informants to ensure the future success of educational robots.},
  archive      = {J_FROBT},
  author       = {Louie, Belinda and Björling, Elin A. and Kuo, Annie Camey and Alves-Oliveira, Patrícia},
  doi          = {10.3389/frobt.2022.983408},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {983408},
  shortjournal = {Front. Robot. AI},
  title        = {Designing for culturally responsive social robots: An application of a participatory framework},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Occluded object detection and exposure in cluttered
environments with automated hyperspectral anomaly detection.
<em>FROBT</em>, <em>9</em>, 982131. (<a
href="https://doi.org/10.3389/frobt.2022.982131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluttered environments with partial object occlusions pose significant challenges to robot manipulation. In settings composed of one dominant object type and various undesirable contaminants, occlusions make it difficult to both recognize and isolate undesirable objects. Spatial features alone are not always sufficiently distinct to reliably identify anomalies under multiple layers of clutter, with only a fractional part of the object exposed. We create a multi-modal data representation of cluttered object scenes pairing depth data with a registered hyperspectral data cube. Hyperspectral imaging provides pixel-wise Visible Near-Infrared (VNIR) reflectance spectral curves which are invariant in similar material types. Spectral reflectance data is grounded in the chemical-physical properties of an object, making spectral curves an excellent modality to differentiate inter-class material types. Our approach proposes a new automated method to perform hyperspectral anomaly detection in cluttered workspaces with the goal of improving robot manipulation. We first assume the dominance of a single material class, and coarsely identify the dominant, non-anomalous class. Next these labels are used to train an unsupervised autoencoder to identify anomalous pixels through reconstruction error. To tie our anomaly detection to robot actions, we then apply a set of heuristically-evaluated motion primitives to perturb and further expose local areas containing anomalies. The utility of this approach is demonstrated in numerous cluttered environments including organic and inorganic materials. In each of our four constructed scenarios, our proposed anomaly detection method is able to consistently increase the exposed surface area of anomalies. Our work advances robot perception for cluttered environments by incorporating multi-modal anomaly detection aided by hyperspectral sensing into detecting fractional object presence without need for laboriously curated labels.},
  archive      = {J_FROBT},
  author       = {Hanson, Nathaniel and Lvov, Gary and Padir, Taşkın},
  doi          = {10.3389/frobt.2022.982131},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {982131},
  shortjournal = {Front. Robot. AI},
  title        = {Occluded object detection and exposure in cluttered environments with automated hyperspectral anomaly detection},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Behavior policy learning: Learning multi-stage tasks via
solution sketches and model-based controllers. <em>FROBT</em>,
<em>9</em>, 974537. (<a
href="https://doi.org/10.3389/frobt.2022.974537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-stage tasks are a challenge for reinforcement learning methods, and require either specific task knowledge (e.g., task segmentation) or big amount of interaction times to be learned. In this paper, we propose Behavior Policy Learning (BPL) that effectively combines 1) only few solution sketches, that is demonstrations without the actions, but only the states, 2) model-based controllers, and 3) simulations to effectively solve multi-stage tasks without strong knowledge about the underlying task. Our main intuition is that solution sketches alone can provide strong data for learning a high-level trajectory by imitation, and model-based controllers can be used to follow this trajectory (we call it behavior) effectively. Finally, we utilize robotic simulations to further improve the policy and make it robust in a Sim2Real style. We evaluate our method in simulation with a robotic manipulator that has to perform two tasks with variations: 1) grasp a box and place it in a basket, and 2) re-place a book on a different level within a bookcase. We also validate the Sim2Real capabilities of our method by performing real-world experiments and realistic simulated experiments where the objects are tracked through an RGB-D camera for the first task.},
  archive      = {J_FROBT},
  author       = {Tsinganos, Konstantinos and Chatzilygeroudis, Konstantinos and Hadjivelichkov, Denis and Komninos, Theodoros and Dermatas, Evangelos and Kanoulas, Dimitrios},
  doi          = {10.3389/frobt.2022.974537},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {974537},
  shortjournal = {Front. Robot. AI},
  title        = {Behavior policy learning: Learning multi-stage tasks via solution sketches and model-based controllers},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novelty detection in rover-based planetary surface images
using autoencoders. <em>FROBT</em>, <em>9</em>, 974397. (<a
href="https://doi.org/10.3389/frobt.2022.974397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of planetary science, novelty detection is gaining attention because of the operational opportunities it offers, including annotated data products and downlink prioritization. Using a variational autoencoder (VAE), this work improves upon state-of-the-art novelty detection performance in the context of Martian exploration by &lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mo&gt;&amp;gt;&lt;/mml:mo&gt;&lt;mml:mn&gt;7&lt;/mml:mn&gt;&lt;mml:mi&gt;%&lt;/mml:mi&gt;&lt;/mml:math&gt; (measured by the area under the receiver operating characteristic curve (ROC AUC)). Autoencoders, especially VAEs, perform well across all classes of novelties defined for Martian exploration. VAEs are shown to have high recall in the Martian context, making them particularly useful for on-ground processing. Convolutional autoencoders (CAEs), on the other hand, demonstrate high precision making them good candidates for onboard downlink prioritization. In our implementation adversarial autoencoders (AAEs) are also shown to perform on par with state-of-the-art. Dimensionality reduction is a key feature of autoencoders for novelty detection. In this study the impact of dimensionality reduction on detection quality is explored, showing that both VAEs and AAEs achieve comparable ROC AUCs to CAEs despite observably poorer (blurred) image reconstructions; this is observed both in Martian data and in lunar analogue data.},
  archive      = {J_FROBT},
  author       = {Stefanuk, Braden and Skonieczny, Krzysztof},
  doi          = {10.3389/frobt.2022.974397},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {974397},
  shortjournal = {Front. Robot. AI},
  title        = {Novelty detection in rover-based planetary surface images using autoencoders},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social/dialogical roles of social robots in supporting
children’s learning of language and literacy—a review and analysis of
innovative roles. <em>FROBT</em>, <em>9</em>, 971749. (<a
href="https://doi.org/10.3389/frobt.2022.971749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the many purposes for which social robots are designed is education, and there have been many attempts to systematize their potential in this field. What these attempts have in common is the recognition that learning can be supported in a variety of ways because a learner can be engaged in different activities that foster learning. Up to now, three roles have been proposed when designing these activities for robots: as a teacher or tutor, a learning peer, or a novice. Current research proposes that deciding in favor of one role over another depends on the content or preferred pedagogical form. However, the design of activities changes not only the content of learning, but also the nature of a human–robot social relationship. This is particularly important in language acquisition, which has been recognized as a social endeavor. The following review aims to specify the differences in human–robot social relationships when children learn language through interacting with a social robot. After proposing categories for comparing these different relationships, we review established and more specific, innovative roles that a robot can play in language-learning scenarios. This follows Mead’s (1946) theoretical approach proposing that social roles are performed in interactive acts. These acts are crucial for learning, because not only can they shape the social environment of learning but also engage the learner to different degrees. We specify the degree of engagement by referring to Chi’s (2009) progression of learning activities that range from active, constructive, toward interactive with the latter fostering deeper learning. Taken together, this approach enables us to compare and evaluate different human–robot social relationships that arise when applying a robot in a particular social role.},
  archive      = {J_FROBT},
  author       = {Rohlfing, Katharina J. and Altvater-Mackensen, Nicole and Caruana, Nathan and van den Berghe, Rianne and Bruno, Barbara and Tolksdorf, Nils F. and Hanulíková, Adriana},
  doi          = {10.3389/frobt.2022.971749},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {971749},
  shortjournal = {Front. Robot. AI},
  title        = {Social/dialogical roles of social robots in supporting children’s learning of language and literacy—A review and analysis of innovative roles},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial microscopic modeling of collective movements in
multi-robot systems: Design choices and calibration. <em>FROBT</em>,
<em>9</em>, 961053. (<a
href="https://doi.org/10.3389/frobt.2022.961053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the strong increase in available computational power enabling an unprecedented level of realism in simulation, modeling robotic systems at higher abstraction level remains crucial to efficiently design robot controllers and analyze their properties. This is especially true for multi-robot systems, with their high computational complexity due to the numerous interactions among individual robots. While multiple contributions in the literature have proposed approaches leading to highly abstracted and therefore computationally efficient models, often such abstractions have been obtained with strong assumptions on the underlying spatiality of the system behavior (e.g., well-mixed system, diffusive system). In this work, we address the modeling of an arbitrary collective movement involving the displacement of a robot ensemble along a certain trajectory overlapped with continuous interactions among the robotic members. Without loss of generality, we have focused our modeling effort on a flocking case study, as a prominent and well-known example of collective movement. We investigate our case study at the microscopic level while leveraging a more faithful submicroscopic model (implemented through a high-fidelity robotic simulator) as ground-truth. More specifically, we illustrate multiple choices for designing and calibrating such microscopic models, so that their faithfulness with the underlying submicroscopic model of the same physical system is preserved. Such effort has produced concrete implementations of three different microscopic models for the same case study, all taking into account the spatiality of the collective movement. We find that all three microscopic models produce quantitatively accurate estimations for our flocking case study. As they rely on different underlying assumptions and modeling techniques, the choice between them is a trade-off between the computational cost, the modeling effort, the metrics considered to evaluate their faithfulness, and the subsequent usage (e.g., control design, system property analysis, control code prototyping).},
  archive      = {J_FROBT},
  author       = {Baumann, Cyrill and Martinoli, Alcherio},
  doi          = {10.3389/frobt.2022.961053},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {961053},
  shortjournal = {Front. Robot. AI},
  title        = {Spatial microscopic modeling of collective movements in multi-robot systems: Design choices and calibration},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One-shot learning for autonomous aerial manipulation.
<em>FROBT</em>, <em>9</em>, 960571. (<a
href="https://doi.org/10.3389/frobt.2022.960571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with learning transferable contact models for aerial manipulation tasks. We investigate a contact-based approach for enabling unmanned aerial vehicles with cable-suspended passive grippers to compute the attach points on novel payloads for aerial transportation. This is the first time that the problem of autonomously generating contact points for such tasks has been investigated. Our approach builds on the underpinning idea that we can learn a probability density of contacts over objects’ surfaces from a single demonstration. We enhance this formulation for encoding aerial transportation tasks while maintaining the one-shot learning paradigm without handcrafting task-dependent features or employing ad-hoc heuristics; the only prior is extrapolated directly from a single demonstration. Our models only rely on the geometrical properties of the payloads computed from a point cloud, and they are robust to partial views. The effectiveness of our approach is evaluated in simulation, in which one or three quadcopters are requested to transport previously unseen payloads along a desired trajectory. The contact points and the quadcopters configurations are computed on-the-fly for each test by our approach and compared with a baseline method, a modified grasp learning algorithm from the literature. Empirical experiments show that the contacts generated by our approach yield a better controllability of the payload for a transportation task. We conclude this paper with a discussion on the strengths and limitations of the presented idea, and our suggested future research directions.},
  archive      = {J_FROBT},
  author       = {Zito, Claudio and Ferrante, Eliseo},
  doi          = {10.3389/frobt.2022.960571},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {960571},
  shortjournal = {Front. Robot. AI},
  title        = {One-shot learning for autonomous aerial manipulation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social robots in a translanguaging pedagogy: A review to
identify opportunities for robot-assisted (language) learning.
<em>FROBT</em>, <em>9</em>, 958624. (<a
href="https://doi.org/10.3389/frobt.2022.958624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This mini review discusses the use of social robots in a translanguaging pedagogy: the use of robots to enable students to use their full linguistic repertoire within schools, so any language that they speak at home or in another aspect of their lives. Current research on robot-assisted second-language learning is reviewed with the aim of finding out whether students’ languages have been employed strategically to support learning of another language. A total of 83 articles has been analyzed on the use of first and second languages in student-robot interactions. Most interactions were either exclusively in the second language, or exclusively in the first language, with only target words in the second language. Few studies strategically mixed the two languages to bootstrap learning, and only one study used the first language of students with migrant backgrounds to learn the second language. The review concludes with recommendations for future use of social robots in a translanguaging pedagogy.},
  archive      = {J_FROBT},
  author       = {van den Berghe, Rianne},
  doi          = {10.3389/frobt.2022.958624},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {958624},
  shortjournal = {Front. Robot. AI},
  title        = {Social robots in a translanguaging pedagogy: A review to identify opportunities for robot-assisted (language) learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Expecting, understanding, relating, and interacting-older,
middle-aged and younger adults’ perspectives on breakdown situations in
human–robot dialogues. <em>FROBT</em>, <em>9</em>, 956709. (<a
href="https://doi.org/10.3389/frobt.2022.956709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: The purpose of this study is to explore how older, middle aged and younger adults perceive breakdown situations caused by lack of or inconsistent knowledge, sudden focus shifts, and conflicting intentions in dialogues between a human and a socially intelligent robot in a home environment, and how they perceive strategies to manage breakdown situations.Methods: Scenarios embedding dialogues on health-related topics were constructed based on activity-theoretical and argumentation frameworks. Different reasons for breakdown situations and strategies to handle these were embedded. The scenarios were recorded in a Wizard-of-Oz setup, with a human actor and a Nao robot. Twenty participants between 23 and 72 years of age viewed the recordings and participated in semi-structured interviews conducted remotely. Data were analyzed qualitatively using thematic analysis.Results: Four themes relating to breakdown situations emerged: expecting, understanding, relating, and interacting. The themes span complex human activity at different complementary levels and provide further developed understanding of breakdown situations in human–robot interaction (HRI). Older and middle-aged adults emphasized emphatic behavior and adherence to social norms, while younger adults focused on functional aspects such as gaze, response time, and length of utterances. A hierarchical taxonomy of aspects relating to breakdown situations was formed, and design implications are provided, guiding future research.Conclusion: We conclude that a socially intelligent robot agent needs strategies to 1) construct and manage its understanding related to emotions of the human, social norms, knowledge, and motive on a higher level of meaningful human activity, 2) act accordingly, for instance, adhering to transparent social roles, and 3) resolve conflicting motives, and identify reasons to prevent and manage breakdown situations at different levels of collaborative activity. Furthermore, the novel methodology to frame the dynamics of human–robot dialogues in complex activities using Activity Theory and argumentation theory was instrumental in this work and will guide the future work on tailoring the robot’s behavior.},
  archive      = {J_FROBT},
  author       = {Tewari, Maitreyee and Lindgren, Helena},
  doi          = {10.3389/frobt.2022.956709},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {956709},
  shortjournal = {Front. Robot. AI},
  title        = {Expecting, understanding, relating, and interacting-older, middle-aged and younger adults’ perspectives on breakdown situations in human–robot dialogues},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). External communication of automated shuttles: Results,
experiences, and lessons learned from three european long-term research
projects. <em>FROBT</em>, <em>9</em>, 949135. (<a
href="https://doi.org/10.3389/frobt.2022.949135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated shuttles are already seeing deployment in many places across the world and have the potential to transform public mobility to be safer and more accessible. During the current transition phase from fully manual vehicles toward higher degrees of automation and resulting mixed traffic, there is a heightened need for additional communication or external indicators to comprehend automated vehicle actions for other road users. In this work, we present and discuss the results from seven studies (three preparatory and four main studies) conducted in three European countries aimed at investigating and providing a variety of such external communication solutions to facilitate the exchange of information between automated shuttles and other motorized and non-motorized road users.},
  archive      = {J_FROBT},
  author       = {Mirnig, Alexander G. and Gärtner, Magdalena and Fröhlich, Peter and Wallner, Vivien and Dahlman, Anna Sjörs and Anund, Anna and Pokorny, Petr and Hagenzieker, Marjan and Bjørnskau, Torkel and Aasvik, Ole and Demir, Cansu and Sypniewski, Jakub},
  doi          = {10.3389/frobt.2022.949135},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {949135},
  shortjournal = {Front. Robot. AI},
  title        = {External communication of automated shuttles: Results, experiences, and lessons learned from three european long-term research projects},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards autonomous robotic minimally invasive ultrasound
scanning and vessel reconstruction on non-planar surfaces.
<em>FROBT</em>, <em>9</em>, 940062. (<a
href="https://doi.org/10.3389/frobt.2022.940062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robotic Ultrasound (US) scanning has been the subject of research for more than 2 decades. However, little work has been done to apply this concept into a minimally invasive setting, in which accurate force sensing is generally not available and robot kinematics are unreliable due to the tendon-driven, compliant robot structure. As a result, the adequate orientation of the probe towards the tissue surface remains unknown and the anatomy reconstructed from scan may become highly inaccurate. In this work we present solutions to both of these challenges: an attitude sensor fusion scheme for improved kinematic sensing and a visual, deep learning based algorithm to establish and maintain contact between the organ surface and the US probe. We further introduce a novel scheme to estimate and orient the probe perpendicular to the center line of a vascular structure. Our approach enables, for the first time, to autonomously scan across a non-planar surface and navigate along an anatomical structure with a robotically guided minimally invasive US probe. Our experiments on a vessel phantom with a convex surface confirm a significant improvement of the reconstructed curved vessel geometry, with our approach strongly reducing the mean positional error and variance. In the future, our approach could help identify vascular structures more effectively and help pave the way towards semi-autonomous assistance during partial hepatectomy and the potential to reduce procedure length and complication rates.},
  archive      = {J_FROBT},
  author       = {Marahrens, Nils and Scaglioni, Bruno and Jones, Dominic and Prasad, Raj and Biyani, Chandra Shekhar and Valdastri, Pietro},
  doi          = {10.3389/frobt.2022.940062},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {940062},
  shortjournal = {Front. Robot. AI},
  title        = {Towards autonomous robotic minimally invasive ultrasound scanning and vessel reconstruction on non-planar surfaces},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of dialogue system architecture toward
co-creating social intelligence when talking with a partner robot.
<em>FROBT</em>, <em>9</em>, 933001. (<a
href="https://doi.org/10.3389/frobt.2022.933001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots have grown increasingly integrated into our daily lives in recent years. Robots can be good social agents who engage with people, such as assistants and counselors, and good partners and companions with whom people can form good relationships. Furthermore, unlike devices such as smart speakers or virtual agents on a screen, robots have physicality, which allows them to observe the actual environment using sensors and respond behaviorally with full-body motions. In order to engage people in dialogue and create good relationships with robots as close partners, real-time interaction is important. In this article, we present a dialogue system platform developed with the aim of providing robots with social skills. We also built a system architecture for the robot to respond with speech and gestures within the dialogue system platform, which attempts to enable natural engagement with the robot and takes advantage of its physicality. In addition, we think the process called “co-creation” is important to build a good human–robot interaction system. Engineers must bridge the gap between users and robots in order for them to interact more effectively and naturally, not only by building systems unilaterally but also from a range of views based on the opinions of real users. We reported two experiments using the developed dialogue interaction system with a robot. One is an experiment with elderly people as the initial phase in this co-creation process. The second experiment was conducted with a wide range of ages, from children to adults. Through these experiments, we can obtain a lot of useful insights for improving the system. We think that repeating this co-creation process is a useful approach toward our goal that humans and robots can communicate in a natural way as good partners such as family and friends.},
  archive      = {J_FROBT},
  author       = {Fujii, Ayaka and Jokinen, Kristiina and Okada, Kei and Inaba, Masayuki},
  doi          = {10.3389/frobt.2022.933001},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {933001},
  shortjournal = {Front. Robot. AI},
  title        = {Development of dialogue system architecture toward co-creating social intelligence when talking with a partner robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Classification of multiple sclerosis clinical profiles using
machine learning and grey matter connectome. <em>FROBT</em>, <em>9</em>,
926255. (<a href="https://doi.org/10.3389/frobt.2022.926255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: The main goal of this study is to investigate the discrimination power of Grey Matter (GM) thickness connectome data between Multiple Sclerosis (MS) clinical profiles using statistical and Machine Learning (ML) methods.Materials and Methods: A dataset composed of 90 MS patients acquired at the MS clinic of Lyon Neurological Hospital was used for the analysis. Four MS profiles were considered, corresponding to Clinical Isolated Syndrome (CIS), Relapsing-Remitting MS (RRMS), Secondary Progressive MS (SPMS), and Primary Progressive MS (PPMS). Each patient was classified in one of these profiles by our neurologist and underwent longitudinal MRI examinations including T1-weighted image acquisition at each examination, from which the GM tissue was segmented and the cortical GM thickness measured. Following the GM parcellation using two different atlases (FSAverage and Glasser 2016), the morphological connectome was built and six global metrics (Betweenness Centrality (BC), Assortativity (r), Transitivity (T), Efficiency (Eg), Modularity (Q) and Density (D)) were extracted. Based on their connectivity metrics, MS profiles were first statistically compared and second, classified using four different learning machines (Logistic Regression, Random Forest, Support Vector Machine and AdaBoost), combined in a higher level ensemble model by majority voting. Finally, the impact of the GM spatial resolution on the MS clinical profiles classification was analyzed.Results: Using binary comparisons between the four MS clinical profiles, statistical differences and classification performances higher than 0.7 were observed. Good performances were obtained when comparing the two early clinical forms, RRMS and PPMS (F1 score of 0.86), and the two neurodegenerative profiles, PPMS and SPMS (F1 score of 0.72). When comparing the two atlases, slightly better performances were obtained with the Glasser 2016 atlas, especially between RRMS with PPMS (F1 score of 0.83), compared to the FSAverage atlas (F1 score of 0.69). Also, the thresholding value for graph binarization was investigated suggesting more informative graph properties in the percentile range between 0.6 and 0.8.Conclusion: An automated pipeline was proposed for the classification of MS clinical profiles using six global graph metrics extracted from the GM morphological connectome of MS patients. This work demonstrated that GM morphological connectivity data could provide good classification performances by combining four simple ML models, without the cost of long and complex MR techniques, such as MR diffusion, and/or deep learning architectures.},
  archive      = {J_FROBT},
  author       = {Barile, Berardino and Ashtari, Pooya and Stamile, Claudio and Marzullo, Aldo and Maes, Frederik and Durand-Dubief, Françoise and Van Huffel, Sabine and Sappey-Marinier, Dominique},
  doi          = {10.3389/frobt.2022.926255},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {926255},
  shortjournal = {Front. Robot. AI},
  title        = {Classification of multiple sclerosis clinical profiles using machine learning and grey matter connectome},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous robotic exploration with simultaneous environment
and traversability models learning. <em>FROBT</em>, <em>9</em>, 910113.
(<a href="https://doi.org/10.3389/frobt.2022.910113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we address generalized autonomous mobile robot exploration of unknown environments where a robotic agent learns a traversability model and builds a spatial model of the environment. The agent can benefit from the model learned online in distinguishing what terrains are easy to traverse and which should be avoided. The proposed solution enables the learning of multiple traversability models, each associated with a particular locomotion gait, a walking pattern of a multi-legged walking robot. We propose to address the simultaneous learning of the environment and traversability models by a decoupled approach. Thus, navigation waypoints are generated using the current spatial and traversability models to gain the information necessary to improve the particular model during the robot’s motion in the environment. From the set of possible waypoints, the decision on where to navigate next is made based on the solution of the generalized traveling salesman problem that allows taking into account a planning horizon longer than a single myopic decision. The proposed approach has been verified in simulated scenarios and experimental deployments with a real hexapod walking robot with two locomotion gaits, suitable for different terrains. Based on the achieved results, the proposed method exploits the online learned traversability models and further supports the selection of the most appropriate locomotion gait for the particular terrain types.},
  archive      = {J_FROBT},
  author       = {Prágr, Miloš and Bayer, Jan and Faigl, Jan},
  doi          = {10.3389/frobt.2022.910113},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {910113},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous robotic exploration with simultaneous environment and traversability models learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A study of interactive robot architecture through the
practical implementation of conversational android. <em>FROBT</em>,
<em>9</em>, 905030. (<a
href="https://doi.org/10.3389/frobt.2022.905030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study shows an autonomous android robot that can have a natural daily dialogue with humans. The dialogue system for daily dialogue is different from a task-oriented dialogue system in that it is not given a clear purpose or the necessary information. That is, it needs to generate an utterance in a situation where there is no clear request from humans. Therefore, to continue a dialogue with a consistent content, it is necessary to essentially change the design policy of dialogue management compared with the existing dialogue system. The purpose of our study is to constructively find out the dialogue system architecture for realizing daily dialogue through implementing an autonomous dialogue robot capable of daily natural dialogue. We defined the android’s desire necessary for daily dialogue and the dialogue management system in which the android changes its internal (mental) states in accordance to the desire and partner’s behavior and chooses a dialogue topic suitable for the current situation. The developed android could continue daily dialogue for about 10 min in the scene where the robot and partner met for the first time in the experiment. Moreover, a multimodal Turing test has shown that half of the participants had felt that the android was remotely controlled to some degree, that is, the android’s behavior was humanlike. This result suggests that the system construction method assumed in this study is an effective approach to realize daily dialogue, and the study discusses the system architecture for daily dialogue.},
  archive      = {J_FROBT},
  author       = {Minato, Takashi and Sakai, Kurima and Uchida, Takahisa and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2022.905030},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {905030},
  shortjournal = {Front. Robot. AI},
  title        = {A study of interactive robot architecture through the practical implementation of conversational android},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Treatise on analytic nonlinear optimal guidance and control
amplification of strictly analytic (non-numerical) methods.
<em>FROBT</em>, <em>9</em>, 884669. (<a
href="https://doi.org/10.3389/frobt.2022.884669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal control is seen by researchers from a different perspective than that from which the industry practitioners see it. Either type of user can easily become confounded when deciding which manner of optimal control should be used for guidance and control of mechanics. Such optimization methods are useful for autonomous navigation, guidance, and control, but their performance is hampered by noisy multi-sensor technologies and poorly modeled system equations, and real-time on-board utilization is generally computationally burdensome. Some methods proposed here use noisy sensor data to learn the optimal guidance and control solutions in real-time (online), where non-iterative instantiations are preferred to reduce computational burdens. This study aimed to highlight the efficacy and limitations of several common methods for optimizing guidance and control while proposing a few more, where all methods are applied to the full, nonlinear, coupled equations of motion including cross-products of motion from the transport theorem. While the reviewed literature introduces quantitative studies that include parametric uncertainty in nonlinear terms, this article proposes accommodating such uncertainty with time-varying solutions to Hamiltonian systems of equations solved in real-time. Five disparate types of optimum guidance and control algorithms are presented and compared to a classical benchmark. Comparative analysis is based on tracking errors (both states and rates), fuel usage, and computational burden. Real-time optimization with singular switching plus nonlinear transport theorem decoupling is newly introduced and proves superior by matching open-loop solutions to the constrained optimization problem (in terms of state and rate errors and fuel usage), while robustness is validated in the utilization of mixed, noisy state and rate sensors and uniformly varying mass and mass moments of inertia. Compared to benchmark, state-of-the-art methods state tracking errors are reduced one-hundred ten percent. Rate tracking errors are reduced one-hundred thirteen percent. Control utilization (fuel) is reduced eighty-four percent, while computational burden is reduced ten percent, simultaneously, where the proposed methods have no control gains and no linearization.},
  archive      = {J_FROBT},
  author       = {Sands, Timothy},
  doi          = {10.3389/frobt.2022.884669},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {884669},
  shortjournal = {Front. Robot. AI},
  title        = {Treatise on analytic nonlinear optimal guidance and control amplification of strictly analytic (Non-numerical) methods},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Children’s learning-by-teaching with a social robot versus a
younger child: Comparing interactions and tutoring styles.
<em>FROBT</em>, <em>9</em>, 875704. (<a
href="https://doi.org/10.3389/frobt.2022.875704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human peer tutoring is known to be effective for learning, and social robots are currently being explored for robot-assisted peer tutoring. In peer tutoring, not only the tutee but also the tutor benefit from the activity. Exploiting the learning-by-teaching mechanism, robots as tutees can be a promising approach for tutor learning. This study compares robots and humans by examining children’s learning-by-teaching with a social robot and younger children, respectively. The study comprised a small-scale field experiment in a Swedish primary school, following a within-subject design. Ten sixth-grade students (age 12–13) assigned as tutors conducted two 30 min peer tutoring sessions each, one with a robot tutee and one with a third-grade student (age 9–10) as the tutee. The tutoring task consisted of teaching the tutee to play a two-player educational game designed to promote conceptual understanding and mathematical thinking. The tutoring sessions were video recorded, and verbal actions were transcribed and extended with crucial game actions and user gestures, to explore differences in interaction patterns between the two conditions. An extension to the classical initiation–response–feedback framework for classroom interactions, the IRFCE tutoring framework, was modified and used as an analytic lens. Actors, tutoring actions, and teaching interactions were examined and coded as they unfolded in the respective child–robot and child–child interactions during the sessions. Significant differences between the robot tutee and child tutee conditions regarding action frequencies and characteristics were found, concerning tutee initiatives, tutee questions, tutor explanations, tutee involvement, and evaluation feedback. We have identified ample opportunities for the tutor to learn from teaching in both conditions, for different reasons. The child tutee condition provided opportunities to engage in explanations to the tutee, experience smooth collaboration, and gain motivation through social responsibility for the younger child. The robot tutee condition provided opportunities to answer challenging questions from the tutee, receive plenty of feedback, and communicate using mathematical language. Hence, both conditions provide good learning opportunities for a tutor, but in different ways.},
  archive      = {J_FROBT},
  author       = {Pareto, Lena and Ekström, Sara and Serholt, Sofia},
  doi          = {10.3389/frobt.2022.875704},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {875704},
  shortjournal = {Front. Robot. AI},
  title        = {Children’s learning-by-teaching with a social robot versus a younger child: Comparing interactions and tutoring styles},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent task allocation for harvest management.
<em>FROBT</em>, <em>9</em>, 864745. (<a
href="https://doi.org/10.3389/frobt.2022.864745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent task allocation methods seek to distribute a set of tasks fairly amongst a set of agents. In real-world settings, such as soft fruit farms, human labourers undertake harvesting tasks. The harvesting workforce is typically organised by farm manager(s) who assign workers to the fields that are ready to be harvested and team leaders who manage the workers in the fields. Creating these assignments is a dynamic and complex problem, as the skill of the workforce and the yield (quantity of ripe fruit picked) are variable and not entirely predictable. The work presented here posits that multi-agent task allocation methods can assist farm managers and team leaders to manage the harvesting workforce effectively and efficiently. There are three key challenges faced when adapting multi-agent approaches to this problem: (i) staff time (and thus cost) should be minimised; (ii) tasks must be distributed fairly to keep staff motivated; and (iii) the approach must be able to handle incremental (incomplete) data as the season progresses. An adapted variation of Round Robin (RR) is proposed for the problem of assigning workers to fields, and market-based task allocation mechanisms are applied to the challenge of assigning tasks to workers within the fields. To evaluate the approach introduced here, experiments are performed based on data that was supplied by a large commercial soft fruit farm for the past two harvesting seasons. The results demonstrate that our approach produces appropriate worker-to-field allocations. Moreover, simulated experiments demonstrate that there is a “sweet spot” with respect to the ratio between two types of in-field workers.},
  archive      = {J_FROBT},
  author       = {Harman, Helen and Sklar, Elizabeth I.},
  doi          = {10.3389/frobt.2022.864745},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {864745},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-agent task allocation for harvest management},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-organized learning from synthetic and real-world data
for a humanoid exercise robot. <em>FROBT</em>, <em>9</em>, 669719. (<a
href="https://doi.org/10.3389/frobt.2022.669719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a neural learning approach for a humanoid exercise robot that can automatically analyze and correct physical exercises. Such an exercise robot should be able to train many different human partners over time and thus requires the ability for lifelong learning. To this end, we develop a modified Grow-When-Required (GWR) network with recurrent connections, episodic memory and a novel subnode mechanism for learning spatiotemporal relationships of body movements and poses. Once an exercise is successfully demonstrated, the information of pose and movement per frame is stored in the Subnode-GWR network. For every frame, the current pose and motion pair is compared against a predicted output of the GWR, allowing for feedback not only on the pose but also on the velocity of the motion. Since both the pose and motion depend on a user’s body morphology, the exercise demonstration by one individual cannot easily be used as a reference for further users. We allow the GWR to grow online with each further demonstration. The subnode mechanism ensures that exercise information for individual humans is stored and retrieved correctly and is not forgotten over time. In the application scenario, a physical exercise is performed in the presence of an expert like a physiotherapist and then used as a reference for a humanoid robot like Pepper to give feedback on further executions of the same exercise. For evaluation, we developed a new synthetic exercise dataset with virtual avatars. We also test our method on real-world data recorded in an office scenario. Overall, we claim that our novel GWR-based architecture can use a learned exercise reference for different body variations through incremental online learning while preventing catastrophic forgetting, enabling an engaging long-term human-robot experience with a humanoid robot.},
  archive      = {J_FROBT},
  author       = {Duczek, Nicolas and Kerzel, Matthias and Allgeuer , Philipp and Wermter , Stefan},
  doi          = {10.3389/frobt.2022.669719},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {669719},
  shortjournal = {Front. Robot. AI},
  title        = {Self-organized learning from synthetic and real-world data for a humanoid exercise robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Applying robotics and AI in pandemics (COVID-19):
Detection, diagnosis and delivery. <em>FROBT</em>, <em>9</em>, 1039273.
(<a href="https://doi.org/10.3389/frobt.2022.1039273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Fang, Bin and Su, Hang and Oyekan, John},
  doi          = {10.3389/frobt.2022.1039273},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1039273},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: applying robotics and AI in pandemics (COVID-19): detection, diagnosis and delivery},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A biologically inspired spiking neural p system in selective
visual attention for efficient feature extraction from human motion.
<em>FROBT</em>, <em>9</em>, 1028271. (<a
href="https://doi.org/10.3389/frobt.2022.1028271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, human action recognition has become an essential task in health care and other fields. During the last decade, several authors have developed algorithms for human activity detection and recognition by exploiting at the maximum the high-performance computing devices to improve the quality and efficiency of their results. However, in real-time and practical human action recognition applications, the simulation of these algorithms exceed the capacity of current computer systems by considering several factors, such as camera movement, complex scene and occlusion. One potential solution to decrease the computational complexity in the human action detection and recognition can be found in the nature of the human visual perception. Specifically, this process is called selective visual attention. Inspired by this neural phenomena, we propose for the first time a spiking neural P system for efficient feature extraction from human motion. Specifically, we propose this neural structure to carry out a pre-processing stage since many studies have revealed that an analysis of visual information of the human brain proceeds in a sequence of operations, in which each one is applied to a specific location or locations. In this way, this specialized processing have allowed to focus the recognition of the objects in a simpler manner. To create a compact and high speed spiking neural P system, we use their cutting-edge variants, such as rules on the synapses, communication on request and astrocyte-like control. Our results have demonstrated that the use of the proposed neural P system increases significantly the performance of low-computational complexity neural classifiers up to more 97% in the human action recognition.},
  archive      = {J_FROBT},
  author       = {Anides, Esteban and Garcia, Luis and Sanchez, Giovanny and Avalos, Juan-Gerardo and Abarca, Marco and Frias, Thania and Vazquez, Eduardo and Juarez, Emmanuel and Trejo, Carlos and Hernandez, Derlis},
  doi          = {10.3389/frobt.2022.1028271},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1028271},
  shortjournal = {Front. Robot. AI},
  title        = {A biologically inspired spiking neural p system in selective visual attention for efficient feature extraction from human motion},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Interaction in robot-assistive elderly care.
<em>FROBT</em>, <em>9</em>, 1020103. (<a
href="https://doi.org/10.3389/frobt.2022.1020103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sumioka, Hidenobu and Torresen, Jim and Shiomi, Masahiro and Chen, Liang-Kung and Nakazawa, Atsushi},
  doi          = {10.3389/frobt.2022.1020103},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1020103},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Interaction in robot-assistive elderly care},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Robot-assisted rehabilitation for neurological
disorders. <em>FROBT</em>, <em>9</em>, 1014681. (<a
href="https://doi.org/10.3389/frobt.2022.1014681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Carbone, Giuseppe and Gonçalves, Rogério Sales},
  doi          = {10.3389/frobt.2022.1014681},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1014681},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robot-assisted rehabilitation for neurological disorders},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Control of cooperative drones and their
applications. <em>FROBT</em>, <em>9</em>, 1014510. (<a
href="https://doi.org/10.3389/frobt.2022.1014510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Jamisola, Rodrigo S.},
  doi          = {10.3389/frobt.2022.1014510},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1014510},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Control of cooperative drones and their applications},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Flexible skill-based control for robot cells in
manufacturing. <em>FROBT</em>, <em>9</em>, 1014476. (<a
href="https://doi.org/10.3389/frobt.2022.1014476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decreasing batch sizes lead to an increasing demand for flexible automation systems in manufacturing industries. Robot cells are one solution for automating manufacturing tasks more flexibly. Besides the ongoing unifications in the hardware components, the controllers are still programmed application specifically and non-uniform. Only specialized experts can reconfigure and reprogram the controllers when process changes occur. To provide a more flexible control, this paper presents a new method for programming flexible skill-based controls for robot cells. In comparison to the common programming in logic controllers, operators independently adapt and expand the automated process sequence without modifying the controller code. For a high flexibility, the paper summarizes the software requirements in terms of an extensibility, flexible usability, configurability, and reusability of the control. Therefore, the skill-based control introduces a modularization of the assets in the control and parameterizable skills as abstract template class methodically. An orchestration system is used to call the skills with the corresponding parameter set and combine them into automated process sequences. A mobile flexible robot cell is used for the validation of the skill-based control architecture. Finally, the main benefits and limitations of the concept are discussed and future challenges of flexible skill-based controls for robot cells are provided.},
  archive      = {J_FROBT},
  author       = {Wiese, Torben and Abicht, Johannes and Friedrich, Christian and Hellmich, Arvid and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2022.1014476},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1014476},
  shortjournal = {Front. Robot. AI},
  title        = {Flexible skill-based control for robot cells in manufacturing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An ensemble deep learning approach to evaluate haptic delay
from a single trial EEG data. <em>FROBT</em>, <em>9</em>, 1013043. (<a
href="https://doi.org/10.3389/frobt.2022.1013043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haptic technologies are becoming increasingly valuable in Human-Computer interaction systems as they provide means of physical interaction with a remote or virtual environment. One of the persistent challenges in tele-haptic systems, communicating haptic information over a computer network, is the synchrony of the delivered haptic information with the rest of the sensory modalities. Delayed haptic feedback can have serious implications on the user performance and overall experience. Limited research efforts have been devoted to studying the implication of haptic delay on the human neural response and relating it to the overall haptic experience. Deep learning could offer autonomous brain activity interpretation in response to a haptic experience such as haptic delay. In this work, we propose an ensemble of 2D CNN and transformer models that is capable of detecting the presence and redseverity of haptic delay from a single-trial Electroencephalography data. Two EEG-based experiments involving visuo-haptic interaction tasks are proposed. The first experiment aims to collect data for detecting the presence of haptic delay during discrete force feedback using a bouncing ball on a racket simulation, while the second aims to collect data for detecting the severity level (none, mild, moderate, severe) of the haptic delay during continuous force feedback via grasping/releasing of an object in a bucket. The ensemble model showed a promising performance with an accuracy of 0.9142 ± 0.0157 for detecting haptic delay during discrete force feedback and 0.6625 ± 0.0067 for classifying the severity of haptic delay during continuous force feedback (4 levels). These results were obtained based on training the model with raw EEG data as well as their wavelet transform using several wavelet kernels. This study is a step forward towards developing cognitive evaluation of the user experience while interaction with haptic interfaces.},
  archive      = {J_FROBT},
  author       = {Alsuradi, Haneen and Eid, Mohamad},
  doi          = {10.3389/frobt.2022.1013043},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1013043},
  shortjournal = {Front. Robot. AI},
  title        = {An ensemble deep learning approach to evaluate haptic delay from a single trial EEG data},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Assuring trustworthiness of autonomous systems as
intelligent and ethical teammates. <em>FROBT</em>, <em>9</em>, 1004094.
(<a href="https://doi.org/10.3389/frobt.2022.1004094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bhattacharyya, Siddhartha and Carroll, Meredith},
  doi          = {10.3389/frobt.2022.1004094},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1004094},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Assuring trustworthiness of autonomous systems as intelligent and ethical teammates},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Advancements in trajectory optimization and model
predictive control for legged systems. <em>FROBT</em>, <em>9</em>,
1002552. (<a href="https://doi.org/10.3389/frobt.2022.1002552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mingo Hoffman, Enrico and Zhou, Chengxu and Parigi Polverini, Matteo},
  doi          = {10.3389/frobt.2022.1002552},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1002552},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advancements in trajectory optimization and model predictive control for legged systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards safety4.0: A novel approach for flexible
human-robot-interaction based on safety-related dynamic finite-state
machine with multilayer operation modes. <em>FROBT</em>, <em>9</em>,
1002226. (<a href="https://doi.org/10.3389/frobt.2022.1002226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of Industry 4.0 and agile manufacturing, the conventional methodologies for risk assessment, risk reduction, and safety procedures may not fulfill the End-User requirements, especially the SMEs with their product diversity and changeable production lines and processes. This work proposes a novel approach for planning and implementing safe and flexible Human-Robot-Interaction (HRI) workspaces using multilayer HRI operation modes. The collaborative operation modes are grouped in different clusters and categorized at various levels systematically. In addition to that, this work proposes a safety-related finite-state machine for describing the transitions between these modes dynamically and properly. The proposed approach is integrated into a new dynamic risk assessment tool as a promising solution toward a new safety horizon in line with industry 4.0.},
  archive      = {J_FROBT},
  author       = {Bdiwi, Mohamad and Al Naser, Ibrahim and Halim, Jayanto and Bauer, Sophie and Eichler, Paul and Ihlenfeldt, Steffen},
  doi          = {10.3389/frobt.2022.1002226},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1002226},
  shortjournal = {Front. Robot. AI},
  title        = {Towards safety4.0: A novel approach for flexible human-robot-interaction based on safety-related dynamic finite-state machine with multilayer operation modes},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collaborating eye to eye: Effects of workplace design on the
perception of dominance of collaboration robots. <em>FROBT</em>,
<em>9</em>, 999308. (<a
href="https://doi.org/10.3389/frobt.2022.999308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of Human-Robot Collaboration (HRC) describes innovative industrial work procedures, in which human staff works in close vicinity with robots on a shared task. Current HRC scenarios often deploy hand-guided robots or remote controls operated by the human collaboration partner. As HRC envisions active collaboration between both parties, ongoing research efforts aim to enhance the capabilities of industrial robots not only in the technical dimension but also in the robot’s socio-interactive features. Apart from enabling the robot to autonomously complete the respective shared task in conjunction with a human partner, one essential aspect lifted from the group collaboration among humans is the communication between both entities. State-of-the-art research has identified communication as a significant contributor to successful collaboration between humans and industrial robots. Non-verbal gestures have been shown to be contributing aspect in conveying the respective state of the robot during the collaboration procedure. Research indicates that, depending on the viewing perspective, the usage of non-verbal gestures in humans can impact the interpersonal attribution of certain characteristics. Applied to collaborative robots such as the Yumi IRB 14000, which is equipped with two arms, specifically to mimic human actions, the perception of the robots’ non-verbal behavior can affect the collaboration. Most important in this context are dominance emitting gestures by the robot that can reinforce negative attitudes towards robots, thus hampering the users’ willingness and effectiveness to collaborate with the robot. By using a 3 × 3 within-subjects design online study, we investigated the effect of dominance gestures (Akimbo, crossing arms, and large arm spread) working in a standing position with an average male height, working in a standing position with an average female height, and working in a seated position on the perception of dominance of the robot. Overall 115 participants (58 female and 57 male) with an average age of 23 years evaluated nine videos of the robot. Results indicated that all presented gestures affect a person’s perception of the robot in regards to its perceived characteristics and willingness to cooperate with the robot. The data also showed participants’ increased attribution of dominance based on the presented viewing perspective.},
  archive      = {J_FROBT},
  author       = {Arntz, Alexander and Straßmann, Carolin and Völker, Stefanie and Eimler, Sabrina C.},
  doi          = {10.3389/frobt.2022.999308},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {999308},
  shortjournal = {Front. Robot. AI},
  title        = {Collaborating eye to eye: Effects of workplace design on the perception of dominance of collaboration robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Advanced cutting strategy for navigated, robot-driven laser
craniotomy for stereoelectroencephalography: An in vivo non-recovery
animal study. <em>FROBT</em>, <em>9</em>, 997413. (<a
href="https://doi.org/10.3389/frobt.2022.997413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives: In this study we aimed to present an updated cutting strategy and updated hardware for a new camera system that can increase cut-through detection using a cold ablation robot-guided laser osteotome.Methods: We performed a preoperative computed tomography scan of each animal. The laser was mounted on a robotic arm and guided by a navigation system based on a tracking camera. Surgery was performed with animals in the prone position. A new cutting strategy was implemented consisting of two circular paths involving inner (full cylindric) and outer (hollow cylindric) sections, with three different ablation phases. The depth electrodes were inserted after cut-through detection was confirmed on either the coaxial camera system or optical coherence tomography signal.Results: A total of 71 precision bone channels were cut in four pig specimens using a robot-guided laser. No signs of hemodynamic or respiratory irregularities were observed during anesthesia. All bone channels were created using the advanced cutting strategy. The new cutting strategy showed no irregularities in either cylindrical (parallel walled; n = 38, 45° = 10, 60° = 14, 90° = 14) or anticonical (walls widening by 2 degrees; n = 33, 45° = 11, 60° = 13, 90° = 9) bone channels. The entrance hole diameters ranged from 2.25–3.7 mm and the exit hole diameters ranged from 1.25 to 2.82 mm. Anchor bolts were successfully inserted in all bone channels. No unintended damage to the cortex was detected after laser guided craniotomy.Conclusion: The new cutting strategy showed promising results in more than 70 precision angulated cylindrical and anti-conical bone channels in this large, in vivo non-recovery animal study. Our findings indicate that the coaxial camera system is feasible for cut-through detection.},
  archive      = {J_FROBT},
  author       = {Winter, Fabian and Beer, Daniel and Gono, Patrick and Medagli, Stefano and Morawska, Marta and Dorfer, Christian and Roessler, Karl},
  doi          = {10.3389/frobt.2022.997413},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {997413},
  shortjournal = {Front. Robot. AI},
  title        = {Advanced cutting strategy for navigated, robot-driven laser craniotomy for stereoelectroencephalography: An in vivo non-recovery animal study},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The influence of interdependence and a transparent or
explainable communication style on human-robot teamwork. <em>FROBT</em>,
<em>9</em>, 993997. (<a
href="https://doi.org/10.3389/frobt.2022.993997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans and robots are increasingly working together in human-robot teams. Teamwork requires communication, especially when interdependence between team members is high. In previous work, we identified a conceptual difference between sharing what you are doing (i.e., being transparent) and why you are doing it (i.e., being explainable). Although the second might sound better, it is important to avoid information overload. Therefore, an online experiment (n = 72) was conducted to study the effect of communication style of a robot (silent, transparent, explainable, or adaptive based on time pressure and relevancy) on human-robot teamwork. We examined the effects of these communication styles on trust in the robot, workload during the task, situation awareness, reliance on the robot, human contribution during the task, human communication frequency, and team performance. Moreover, we included two levels of interdependence between human and robot (high vs. low), since mutual dependency might influence which communication style is best. Participants collaborated with a virtual robot during two simulated search and rescue tasks varying in their level of interdependence. Results confirm that in general robot communication results in more trust in and understanding of the robot, while showing no evidence of a higher workload when the robot communicates or adds explanations to being transparent. Providing explanations, however, did result in more reliance on RescueBot. Furthermore, compared to being silent, only being explainable results a higher situation awareness when interdependence is high. Results further show that being highly interdependent decreases trust, reliance, and team performance while increasing workload and situation awareness. High interdependence also increases human communication if the robot is not silent, human rescue contribution if the robot does not provide explanations, and the strength of the positive association between situation awareness and team performance. From these results, we can conclude that robot communication is crucial for human-robot teamwork, and that important differences exist between being transparent, explainable, or adaptive. Our findings also highlight the fundamental importance of interdependence in studies on explainability in robots.},
  archive      = {J_FROBT},
  author       = {Verhagen, Ruben S. and Neerincx , Mark A. and Tielman , Myrthe L.},
  doi          = {10.3389/frobt.2022.993997},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {993997},
  shortjournal = {Front. Robot. AI},
  title        = {The influence of interdependence and a transparent or explainable communication style on human-robot teamwork},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Actuation, sensing and control systems for soft
wearable assistive devices. <em>FROBT</em>, <em>9</em>, 992699. (<a
href="https://doi.org/10.3389/frobt.2022.992699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ortiz, Jesús and Grioli , Giorgio and Rossiter , Jonathan and Helps , Tim and Sadeghi , Ali and Xiloyannis , Michele},
  doi          = {10.3389/frobt.2022.992699},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {992699},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Actuation, sensing and control systems for soft wearable assistive devices},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterization of bending balloon actuators.
<em>FROBT</em>, <em>9</em>, 991748. (<a
href="https://doi.org/10.3389/frobt.2022.991748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging field of soft robotics often relies on soft actuators powered by pressurized fluids to obtain a variety of movements. Strategic incorporation of soft actuators can greatly increase the degree of freedom of soft robots thereby bestowing them with a range of movements. Balloon actuators are extensively used to achieve various motions such as bending, twisting, and expanding. A detailed understanding of how material properties and architectural designs of balloon actuators influence their motions will greatly enable the application of these soft actuators. In this study, we developed a framework involving experimental and theoretical analyses, including computational analysis, delineating material and geometrical parameters of balloon actuators to their bending motions. Furthermore, we provide a simple analytical model to predict and control the degree of bending of these actuators. The described analytical tool could be used to predict the actuating function of balloon actuators and thereby help generate optimal actuators for functions which require control over the extent and direction of actuation.},
  archive      = {J_FROBT},
  author       = {Ko, Ung Hyun and Kumar, Vardhman and Rosen, Benjamin and Varghese, Shyni},
  doi          = {10.3389/frobt.2022.991748},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {991748},
  shortjournal = {Front. Robot. AI},
  title        = {Characterization of bending balloon actuators},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated design of an aerial soft-continuum manipulator
for predictive maintenance. <em>FROBT</em>, <em>9</em>, 980800. (<a
href="https://doi.org/10.3389/frobt.2022.980800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an integrated concept of an aerial robot used for predictive maintenance in the construction sector. The latter can be remotely controlled, allowing the localization of cracks on wall surfaces and the adaptive deposit of the material for in situ repairs. The use of an aerial robot is motivated by fast intervention, allowing time and cost minimizing of overhead repairs without the need for scaffolding. It is composed of a flying mobile platform positioned in stationary mode to guide a soft continuum arm that allows to reach the area of cracks with different access points. Indeed, some constructions have complex geometries that present problems for access using rigid mechanical arms. The aerial robot uses visual sensors to automatically identify and localize cracks in walls, based on deep learning convolutional neural networks. A centerline representing the structural feature of the crack is computed. The soft continuum manipulator is used to guide the continuous deposit of the putty material to fill the microscopic crack. For this purpose, an inverse kinematic model-based control of the soft arm is developed, allowing to estimate the length of the bending tubes. The latter are then used as inputs for a neural network to predict the desired input pressure to bend the actuated soft tubes. A set of experiments was carried out on cracks located on flat and oblique surfaces, to evaluate the actual performances of the predictive maintenance mechatronic robot.},
  archive      = {J_FROBT},
  author       = {Yang, Xinrui and Kahouadji, Mouad and Lakhal , Othman and Merzouki , Rochdi},
  doi          = {10.3389/frobt.2022.980800},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {980800},
  shortjournal = {Front. Robot. AI},
  title        = {Integrated design of an aerial soft-continuum manipulator for predictive maintenance},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design, characterisation and validation of a haptic
interface based on twisted string actuation. <em>FROBT</em>, <em>9</em>,
977367. (<a href="https://doi.org/10.3389/frobt.2022.977367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design and experimental characterisation of a wrist haptic interface based on a twisted string actuator. The interface is designed for controlled actuation of wrist flexion/extension and is capable of rendering torque feedback through a rotary handle driven by the twisted string actuator and spring-loaded cable mechanisms. The interface was characterised to obtain its static and dynamic haptic feedback rendering capabilities. Compliance in the spring and actuation mechanism makes the interface suitable for smooth rendering of haptic feedback of large magnitudes due to the high motion transmission ratio of the twisted strings. Haptic virtual wall rendering capabilities are demonstrated.},
  archive      = {J_FROBT},
  author       = {Skvortsova, Valeria and Nedelchev, Simeon and Brown, Joshua and Farkhatdinov, Ildar and Gaponov, Igor},
  doi          = {10.3389/frobt.2022.977367},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {977367},
  shortjournal = {Front. Robot. AI},
  title        = {Design, characterisation and validation of a haptic interface based on twisted string actuation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computational transcendence: Responsibility and agency.
<em>FROBT</em>, <em>9</em>, 977303. (<a
href="https://doi.org/10.3389/frobt.2022.977303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergence of responsible behavior is explored in non-cooperative games involving autonomous agents. Rather than imposing constraints or external reinforcements, agents are endowed with an elastic “sense of self” or an elastic identity that they curate based on rational considerations. This approach is called “computational transcendence (CT).” We show that agents using this model make choices for collective welfare instead of individual benefit. First, relevance of this model in game theoretic contexts like Prisoners’ dilemma and collusion is presented. Next, a generic multi-agent framework for simulating dilemmas around responsible agency is also proposed. CT implemented on this framework, is shown to be versatile in acting responsibly to different kinds of circumstances–including modifying their strategy based on their interaction with other agents in the system as well as interacting with adversaries that are rational maximizers, and who have a rationale to exploit responsible behavior from other agents. CT is also shown to outperform reciprocity as a strategy for responsible autonomy. Thus, we present CT as a framework for building autonomous agents which can intrinsically act responsibly in multi-agent systems. The core model for computational ethics presented in this paper can potentially be adapted to the needs of applications in areas like supply chains, traffic management, and autonomous vehicles. This paper hopes to motivate further research on responsible AI, by exploring computational modeling of this elusive concept called the “sense of self” that is a central element of existential inquiry in humans.},
  archive      = {J_FROBT},
  author       = {Deshmukh, Jayati and Srinivasa, Srinath},
  doi          = {10.3389/frobt.2022.977303},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {977303},
  shortjournal = {Front. Robot. AI},
  title        = {Computational transcendence: Responsibility and agency},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-expert synthesis for versatile locomotion and
manipulation skills. <em>FROBT</em>, <em>9</em>, 970890. (<a
href="https://doi.org/10.3389/frobt.2022.970890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on generating multiple coordinated motor skills for intelligent systems and studies a Multi-Expert Synthesis (MES) approach to achieve versatile robotic skills for locomotion and manipulation. MES embeds and uses expert skills to solve new composite tasks, and is able to synthesise and coordinate different and multiple skills smoothly. We proposed essential and effective design guidelines for training successful MES policies in simulation, which were deployed on both floating- and fixed-base robots. We formulated new algorithms to systematically determine task-relevant state variables for each individual experts which improved robustness and learning efficiency, and an explicit enforcement objective to diversify skills among different experts. The capabilities of MES policies were validated in both simulation and real experiments for locomotion and bi-manual manipulation. We demonstrated that the MES policies achieved robust locomotion on the quadruped ANYmal by fusing the gait recovery and trotting skills. For object manipulation, the MES policies learned to first reconfigure an object in an ungraspable pose and then grasp it through cooperative dual-arm manipulation.},
  archive      = {J_FROBT},
  author       = {Yuan, Kai and Li, Zhibin},
  doi          = {10.3389/frobt.2022.970890},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {970890},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-expert synthesis for versatile locomotion and manipulation skills},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Progress in symmetry preserving robot perception and control
through geometry and learning. <em>FROBT</em>, <em>9</em>, 969380. (<a
href="https://doi.org/10.3389/frobt.2022.969380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reports on recent progress in robot perception and control methods developed by taking the symmetry of the problem into account. Inspired by existing mathematical tools for studying the symmetry structures of geometric spaces, geometric sensor registration, state estimator, and control methods provide indispensable insights into the problem formulations and generalization of robotics algorithms to challenging unknown environments. When combined with computational methods for learning hard-to-measure quantities, symmetry-preserving methods unleash tremendous performance. The article supports this claim by showcasing experimental results of robot perception, state estimation, and control in real-world scenarios.},
  archive      = {J_FROBT},
  author       = {Ghaffari, Maani and Zhang, Ray and Zhu, Minghan and Lin, Chien Erh and Lin, Tzu-Yuan and Teng, Sangli and Li, Tingjun and Liu, Tianyi and Song, Jingwei},
  doi          = {10.3389/frobt.2022.969380},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {969380},
  shortjournal = {Front. Robot. AI},
  title        = {Progress in symmetry preserving robot perception and control through geometry and learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Haptic training simulation, volume II.
<em>FROBT</em>, <em>9</em>, 965113. (<a
href="https://doi.org/10.3389/frobt.2022.965113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Chen, Xiaojun and Lelevé, Arnaud and McDaniel, Troy and Rossa, Carlos},
  doi          = {10.3389/frobt.2022.965113},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {965113},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Haptic training simulation, volume II},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint elasticity produces energy efficiency in underwater
locomotion: Verification with deep reinforcement learning.
<em>FROBT</em>, <em>9</em>, 957931. (<a
href="https://doi.org/10.3389/frobt.2022.957931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater snake robots have received attention because of their unique mechanics and locomotion patterns. Given their highly redundant degrees of freedom, designing an energy-efficient gait has been a main challenge for the long-term autonomy of underwater snake robots. We propose a gait design method for an underwater snake robot based on deep reinforcement learning and curriculum learning. For comparison, we consider the gait generated by a conventional parametric gait equation controller as the baseline. Furthermore, inspired by the joints of living organisms, we consider elasticity (stiffness) in the joints of the snake robot to verify whether it contributes to the generation of energy efficiency in the underwater gait. We first demonstrate that the deep reinforcement learning controller can produce a more energy-efficient gait than the gait equation controller in underwater locomotion, by finding the control patterns which maximize the effect of energy efficiency through the exploitation of joint elasticity. In addition, appropriate joint elasticity can increase the maximum velocity achievable by a snake robot. Finally, simulation results in different liquid environments confirm that the deep reinforcement learning controller is superior to the gait equation controller, and it can find adaptive energy-efficient motion even when the liquid environment is changed. The video can be viewed at https://youtu.be/wpwQihhntEY.},
  archive      = {J_FROBT},
  author       = {Zheng, Chu and Li , Guanda and Hayashibe, Mitsuhiro},
  doi          = {10.3389/frobt.2022.957931},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {957931},
  shortjournal = {Front. Robot. AI},
  title        = {Joint elasticity produces energy efficiency in underwater locomotion: Verification with deep reinforcement learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrating computer vision to prosthetic hand control with
sEMG: Preliminary results in grasp classification. <em>FROBT</em>,
<em>9</em>, 948238. (<a
href="https://doi.org/10.3389/frobt.2022.948238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The myoelectric prosthesis is a promising tool to restore the hand abilities of amputees, but the classification accuracy of surface electromyography (sEMG) is not high enough for real-time application. Researchers proposed integrating sEMG signals with another feature that is not affected by amputation. The strong coordination between vision and hand manipulation makes us consider including visual information in prosthetic hand control. In this study, we identified a sweet period during the early reaching phase in which the vision data could yield a higher accuracy in classifying the grasp patterns. Moreover, the visual classification results from the sweet period could be naturally integrated with sEMG data collected during the grasp phase. After the integration, the accuracy of grasp classification increased from 85.5% (only sEMG) to 90.06% (integrated). Knowledge gained from this study encourages us to further explore the methods for incorporating computer vision into myoelectric data to enhance the movement control of prosthetic hands.},
  archive      = {J_FROBT},
  author       = {Wang, Shuo and Zheng, Jingjing and Huang, Ziwei and Zhang, Xiaoqin and Prado da Fonseca, Vinicius and Zheng, Bin and Jiang, Xianta},
  doi          = {10.3389/frobt.2022.948238},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {948238},
  shortjournal = {Front. Robot. AI},
  title        = {Integrating computer vision to prosthetic hand control with sEMG: Preliminary results in grasp classification},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Influence of task decision autonomy on physical ergonomics
and robot performances in an industrial human–robot collaboration
scenario. <em>FROBT</em>, <em>9</em>, 943261. (<a
href="https://doi.org/10.3389/frobt.2022.943261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adoption of human–robot collaboration is hindered by barriers in collaborative task design. A new approach for solving these problems is to empower operators in the design of their tasks. However, how this approach may affect user welfare or performance in industrial scenarios has not yet been studied. Therefore, in this research, the results of an experiment designed to identify the influences of the operator’s self-designed task on physical ergonomics and task performance are presented. At first, a collaborative framework able to accept operator task definition via parts’ locations and monitor the operator’s posture is presented. Second, the framework is used to tailor a collaborative experience favoring decision autonomy using the SHOP4CF architecture. Finally, the framework is used to investigate how this personalization influences collaboration through a user study with untrained personnel on physical ergonomics. The results from this study are twofold. On one hand, a high degree of decision autonomy was felt by the operators when they were allowed to allocate the parts. On the other hand, high decision autonomy was not found to vary task efficiency nor the MSD risk level. Therefore, this study emphasizes that allowing operators to choose the position of the parts may help task acceptance and does not vary operators’ physical ergonomics or task efficiency. Unfortunately, the test was limited to 16 participants and the measured risk level was medium. Therefore, this study also stresses that operators should be allowed to choose their own work parameters, but some guidelines should be followed to further reduce MSD risk levels.},
  archive      = {J_FROBT},
  author       = {Pantano, Matteo and Yang, Qiaoyue and Blumberg, Adrian and Reisch, Raven and Hauser, Tobias and Lutz, Benjamin and Regulin, Daniel and Kamps, Tobias and Traganos, Konstantinos and Lee, Dongheui},
  doi          = {10.3389/frobt.2022.943261},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {943261},
  shortjournal = {Front. Robot. AI},
  title        = {Influence of task decision autonomy on physical ergonomics and robot performances in an industrial human–robot collaboration scenario},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Can a robot laugh with you?: Shared laughter generation for
empathetic spoken dialogue. <em>FROBT</em>, <em>9</em>, 933261. (<a
href="https://doi.org/10.3389/frobt.2022.933261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spoken dialogue systems must be able to express empathy to achieve natural interaction with human users. However, laughter generation requires a high level of dialogue understanding. Thus, implementing laughter in existing systems, such as in conversational robots, has been challenging. As a first step toward solving this problem, rather than generating laughter from user dialogue, we focus on “shared laughter,” where a user laughs using either solo or speech laughs (initial laugh), and the system laughs in turn (response laugh). The proposed system consists of three models: 1) initial laugh detection, 2) shared laughter prediction, and 3) laugh type selection. We trained each model using a human-robot speed dating dialogue corpus. For the first model, a recurrent neural network was applied, and the detection performance achieved an F1 score of 82.6%. The second model used the acoustic and prosodic features of the initial laugh and achieved a prediction accuracy above that of the random prediction. The third model selects the type of system’s response laugh as social or mirthful laugh based on the same features of the initial laugh. We then implemented the full shared laughter generation system in an attentive listening dialogue system and conducted a dialogue listening experiment. The proposed system improved the impression of the dialogue system such as empathy perception compared to a naive baseline without laughter and a reactive system that always responded with only social laughs. We propose that our system can be used for situated robot interaction and also emphasize the need for integrating proper empathetic laughs into conversational robots and agents.},
  archive      = {J_FROBT},
  author       = {Inoue, Koji and Lala, Divesh and Kawahara, Tatsuya},
  doi          = {10.3389/frobt.2022.933261},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {933261},
  shortjournal = {Front. Robot. AI},
  title        = {Can a robot laugh with you?: Shared laughter generation for empathetic spoken dialogue},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and realization of a novel haptic graspable interface
for augmenting touch sensations. <em>FROBT</em>, <em>9</em>, 927660. (<a
href="https://doi.org/10.3389/frobt.2022.927660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel haptic grasper that renders touch sensations to the user in 3-DoF (degrees of freedom), namely linear, rotary, and grasping motions, is presented. The touch sensations of the grasper include the combination of kinesthetic and tactile modalities such as stiffness, texture, and shape. The device is equipped with two swappable modular segments that provide stiffness and shape sensations. To increase the haptic fidelity, the textural surfaces that surround the outer surface of the segments are equipped with vibro-actuators underneath them. These vibro-actuators contribute to increasing the number of perceivable textures by varying amplitude, frequency, duration, and envelope of vibrations. The proposed device is characterized in terms of stiffness, shape and texture rendering capabilities. The experimental results validate the effectiveness of the developed haptic grasper in virtual/remote interactions. Also, the user studies and statistical analysis demonstrate that the users could perceive the high-fidelity haptic feedback with the unified sensations of kinesthetic and tactile cues.},
  archive      = {J_FROBT},
  author       = {Pediredla, Vijay Kumar and Chandrasekaran, Karthik and Annamraju, Srikar and Thondiyath, Asokan},
  doi          = {10.3389/frobt.2022.927660},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {927660},
  shortjournal = {Front. Robot. AI},
  title        = {Design and realization of a novel haptic graspable interface for augmenting touch sensations},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unobtrusive, natural support control of an adaptive
industrial exoskeleton using force myography. <em>FROBT</em>,
<em>9</em>, 919370. (<a
href="https://doi.org/10.3389/frobt.2022.919370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Repetitive or tiring tasks and movements during manual work can lead to serious musculoskeletal disorders and, consequently, to monetary damage for both the worker and the employer. Among the most common of these tasks is overhead working while operating a heavy tool, such as drilling, painting, and decorating. In such scenarios, it is desirable to provide adaptive support in order to take some of the load off the shoulder joint as needed. However, even to this day, hardly any viable approaches have been tested, which could enable the user to control such assistive devices naturally and in real time. Here, we present and assess the adaptive Paexo Shoulder exoskeleton, an unobtrusive device explicitly designed for this kind of industrial scenario, which can provide a variable amount of support to the shoulders and arms of a user engaged in overhead work. The adaptive Paexo Shoulder exoskeleton is controlled through machine learning applied to force myography. The controller is able to determine the lifted mass and provide the required support in real time. Twelve subjects joined a user study comparing the Paexo driven through this adaptive control to the Paexo locked in a fixed level of support. The results showed that the machine learning algorithm can successfully adapt the level of assistance to the lifted mass. Specifically, adaptive assistance can sensibly reduce the muscle activity’s sensitivity to the lifted mass, with an observed relative reduction of up to 31% of the muscular activity observed when lifting 2 kg normalized by the baseline when lifting no mass.},
  archive      = {J_FROBT},
  author       = {Sierotowicz, Marek and Brusamento, Donato and Schirrmeister, Benjamin and Connan, Mathilde and Bornmann, Jonas and Gonzalez-Vargas, Jose and Castellini, Claudio},
  doi          = {10.3389/frobt.2022.919370},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {919370},
  shortjournal = {Front. Robot. AI},
  title        = {Unobtrusive, natural support control of an adaptive industrial exoskeleton using force myography},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrated design-sense-plan architecture for autonomous
geometric-semantic mapping with UAVs. <em>FROBT</em>, <em>9</em>,
911974. (<a href="https://doi.org/10.3389/frobt.2022.911974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a complete solution for autonomous mapping and inspection tasks, namely a lightweight multi-camera drone design coupled with computationally efficient planning algorithms and environment representations for enhanced autonomous navigation in exploration and mapping tasks. The proposed system utilizes state-of-the-art Next-Best-View (NBV) planning techniques, with geometric and semantic segmentation information computed with Deep Convolutional Neural Networks (DCNNs) to improve the environment map representation. The main contributions of this article are the following. First, we propose a novel efficient sensor observation model and a utility function that encodes the expected information gains from observations taken from specific viewpoints. Second, we propose a reward function that incorporates both geometric and semantic probabilistic information provided by a DCNN for semantic segmentation that operates in close to real-time. The incorporation of semantics in the environment representation enables biasing exploration towards specific object categories while disregarding task-irrelevant ones during path planning. Experiments in both a virtual and a real scenario demonstrate the benefits on reconstruction accuracy of using semantics for biasing exploration towards task-relevant objects, when compared with purely geometric state-of-the-art methods. Finally, we present a unified approach for the selection of the number of cameras on a UAV, to optimize the balance between power consumption, flight-time duration, and exploration and mapping performance trade-offs. Unlike previous design optimization approaches, our method is couples with the sense and plan algorithms. The proposed system and general formulations can be be applied in the mapping, exploration, and inspection of any type of environment, as long as environment dependent semantic training data are available, with demonstrated successful applicability in the inspection of dry dock shipyard environments.},
  archive      = {J_FROBT},
  author       = {Pimentel de Figueiredo, Rui and Le Fevre Sejersen, Jonas and Grimm Hansen, Jakob and Brandão, Martim},
  doi          = {10.3389/frobt.2022.911974},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {911974},
  shortjournal = {Front. Robot. AI},
  title        = {Integrated design-sense-plan architecture for autonomous geometric-semantic mapping with UAVs},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatio-temporal categorization for first-person-view videos
using a convolutional variational autoencoder and gaussian processes.
<em>FROBT</em>, <em>9</em>, 903450. (<a
href="https://doi.org/10.3389/frobt.2022.903450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, HcVGH, a method that learns spatio-temporal categories by segmenting first-person-view (FPV) videos captured by mobile robots, is proposed. Humans perceive continuous high-dimensional information by dividing and categorizing it into significant segments. This unsupervised segmentation capability is considered important for mobile robots to learn spatial knowledge. The proposed HcVGH combines a convolutional variational autoencoder (cVAE) with HVGH, a past method, which follows the hierarchical Dirichlet process-variational autoencoder-Gaussian process-hidden semi-Markov model comprising deep generative and statistical models. In the experiment, FPV videos of an agent were used in a simulated maze environment. FPV videos contain spatial information, and spatial knowledge can be learned by segmenting them. Using the FPV-video dataset, the segmentation performance of the proposed model was compared with previous models: HVGH and hierarchical recurrent state space model. The average segmentation F-measure achieved by HcVGH was 0.77; therefore, HcVGH outperformed the baseline methods. Furthermore, the experimental results showed that the parameters that represent the movability of the maze environment can be learned.},
  archive      = {J_FROBT},
  author       = {Nagano, Masatoshi and Nakamura, Tomoaki and Nagai, Takayuki and Mochihashi, Daichi and Kobayashi, Ichiro},
  doi          = {10.3389/frobt.2022.903450},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {903450},
  shortjournal = {Front. Robot. AI},
  title        = {Spatio-temporal categorization for first-person-view videos using a convolutional variational autoencoder and gaussian processes},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Endoscopic capsule robot-based diagnosis, navigation and
localization in the gastrointestinal tract. <em>FROBT</em>, <em>9</em>,
896028. (<a href="https://doi.org/10.3389/frobt.2022.896028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of video capsule endoscopy (VCE) would not have been possible without continued technological improvements in imaging and locomotion. Advancements in imaging include both software and hardware improvements but perhaps the greatest software advancement in imaging comes in the form of artificial intelligence (AI). Current research into AI in VCE includes the diagnosis of tumors, gastrointestinal bleeding, Crohn’s disease, and celiac disease. Other advancements have focused on the improvement of both camera technologies and alternative forms of imaging. Comparatively, advancements in locomotion have just started to approach clinical use and include onboard controlled locomotion, which involves miniaturizing a motor to incorporate into the video capsule, and externally controlled locomotion, which involves using an outside power source to maneuver the capsule itself. Advancements in locomotion hold promise to remove one of the major disadvantages of VCE, namely, its inability to obtain targeted diagnoses. Active capsule control could in turn unlock additional diagnostic and therapeutic potential, such as the ability to obtain targeted tissue biopsies or drug delivery. With both advancements in imaging and locomotion has come a corresponding need to be better able to process generated images and localize the capsule’s position within the gastrointestinal tract. Technological advancements in computation performance have led to improvements in image compression and transfer, as well as advancements in sensor detection and alternative methods of capsule localization. Together, these advancements have led to the expansion of VCE across a number of indications, including the evaluation of esophageal and colon pathologies including esophagitis, esophageal varices, Crohn’s disease, and polyps after incomplete colonoscopy. Current research has also suggested a role for VCE in acute gastrointestinal bleeding throughout the gastrointestinal tract, as well as in urgent settings such as the emergency department, and in resource-constrained settings, such as during the COVID-19 pandemic. VCE has solidified its role in the evaluation of small bowel bleeding and earned an important place in the practicing gastroenterologist’s armamentarium. In the next few decades, further improvements in imaging and locomotion promise to open up even more clinical roles for the video capsule as a tool for non-invasive diagnosis of lumenal gastrointestinal pathologies.},
  archive      = {J_FROBT},
  author       = {Hanscom, Mark and Cave, David R.},
  doi          = {10.3389/frobt.2022.896028},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {896028},
  shortjournal = {Front. Robot. AI},
  title        = {Endoscopic capsule robot-based diagnosis, navigation and localization in the gastrointestinal tract},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterization of continuum robot arms under reinforcement
learning and derived improvements. <em>FROBT</em>, <em>9</em>, 895388.
(<a href="https://doi.org/10.3389/frobt.2022.895388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotics, soft continuum robot arms are a promising prospect owing to their redundancy and passivity; however, no comprehensive study exists that examines their characteristics compared to rigid manipulators. In this study, we examined the advantages of a continuum robot arm as compared to a typical and rigid seven-degree-of-freedom (7-DoF) robot manipulator in terms of performing various tasks through reinforcement learning. We conducted simulations for tasks with different characteristics that require control over position and force. Common tasks in robot manipulators, such as reaching, crank rotation, object throwing, and peg-in-hole were considered. The initial conditions of the robot and environment were randomized, aiming for evaluations including robustness. The results indicate that the continuum robot arm excels in the crank-rotation task, which is characterized by uncertainty in environmental conditions and cumulative rewards. However, the rigid robot arm learned better motions for the peg-in-hole task than the other tasks, which requires fine motion control of the end-effector. In the throwing task, the continuum robot arm scored well owing to its good handling of anisotropy. Moreover, we developed a reinforcement-learning method based on the comprehensive experimental results. The proposed method successfully improved the motion learning of a continuum robot arm by adding a technique to regulate the initial state of the robot. To the best of our knowledge, ours is the first reinforcement-learning experiment with multiple tasks on a single continuum robot arm and is the first report of a comparison between a single continuum robot arm and rigid manipulator on a wide range of tasks. This simulation study can make a significant contribution to the design of continuum arms and specification of their applications, and development of control and reinforcement learning methods.},
  archive      = {J_FROBT},
  author       = {Morimoto, Ryota and Ikeda, Masahiro and Niiyama, Ryuma and Kuniyoshi, Yasuo},
  doi          = {10.3389/frobt.2022.895388},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {895388},
  shortjournal = {Front. Robot. AI},
  title        = {Characterization of continuum robot arms under reinforcement learning and derived improvements},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep q-network for social robotics using emotional social
signals. <em>FROBT</em>, <em>9</em>, 880547. (<a
href="https://doi.org/10.3389/frobt.2022.880547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robotics represents a branch of human-robot interaction dedicated to developing systems to control the robots to operate in unstructured environments with the presence of human beings. Social robots must interact with human beings by understanding social signals and responding appropriately to them. Most social robots are still pre-programmed, not having great ability to learn and respond with actions adequate during an interaction with humans. Recently more elaborate methods use body movements, gaze direction, and body language. However, these methods generally neglect vital signs present during an interaction, such as the human emotional state. In this article, we address the problem of developing a system to turn a robot able to decide, autonomously, what behaviors to emit in the function of the human emotional state. From one side, the use of Reinforcement Learning (RL) represents a way for social robots to learn advanced models of social cognition, following a self-learning paradigm, using characteristics automatically extracted from high-dimensional sensory information. On the other side, Deep Learning (DL) models can help the robots to capture information from the environment, abstracting complex patterns from the visual information. The combination of these two techniques is known as Deep Reinforcement Learning (DRL). The purpose of this work is the development of a DRL system to promote a natural and socially acceptable interaction among humans and robots. For this, we propose an architecture, Social Robotics Deep Q-Network (SocialDQN), for teaching social robots to behave and interact appropriately with humans based on social signals, especially on human emotional states. This constitutes a relevant contribution for the area since the social signals must not only be recognized by the robot but help him to take action appropriated according to the situation presented. Characteristics extracted from people’s faces are considered for extracting the human emotional state aiming to improve the robot perception. The development and validation of the system are carried out with the support of SimDRLSR simulator. Results obtained through several tests demonstrate that the system learned satisfactorily to maximize the rewards, and consequently, the robot behaves in a socially acceptable way.},
  archive      = {J_FROBT},
  author       = {Belo, José Pedro R. and Azevedo, Helio and Ramos, Josué J. G. and Romero, Roseli A. F.},
  doi          = {10.3389/frobt.2022.880547},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {880547},
  shortjournal = {Front. Robot. AI},
  title        = {Deep Q-network for social robotics using emotional social signals},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating spatio-temporal fields through reinforcement
learning. <em>FROBT</em>, <em>9</em>, 878246. (<a
href="https://doi.org/10.3389/frobt.2022.878246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction and estimation of phenomena of interest in aquatic environments are challenging since they present complex spatio-temporal dynamics. Over the past few decades, advances in machine learning and data processing contributed to ocean exploration and sampling using autonomous robots. In this work, we formulate a reinforcement learning framework to estimate spatio-temporal fields modeled by partial differential equations. The proposed framework addresses problems of the classic methods regarding the sampling process to determine the path to be used by the agent to collect samples. Simulation results demonstrate the applicability of our approach and show that the error at the end of the learning process is close to the expected error given by the fitting process due to added noise.},
  archive      = {J_FROBT},
  author       = {Padrao, Paulo and Fuentes, Jose and Bobadilla, Leonardo and Smith, Ryan N.},
  doi          = {10.3389/frobt.2022.878246},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {878246},
  shortjournal = {Front. Robot. AI},
  title        = {Estimating spatio-temporal fields through reinforcement learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and validation of a medical robotic device system to
control two collaborative robots for ultrasound-guided needle
insertions. <em>FROBT</em>, <em>9</em>, 875845. (<a
href="https://doi.org/10.3389/frobt.2022.875845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The percutaneous biopsy is a critical intervention for diagnosis and staging in cancer therapy. Robotic systems can improve the efficiency and outcome of such procedures while alleviating stress for physicians and patients. However, the high complexity of operation and the limited possibilities for robotic integration in the operating room (OR) decrease user acceptance and the number of deployed robots. Collaborative systems and standardized device communication may provide approaches to overcome named problems. Derived from the IEEE 11073 SDC standard terminology of medical device systems, we designed and validated a medical robotic device system (MERODES) to access and control a collaborative setup of two KUKA robots for ultrasound-guided needle insertions. The system is based on a novel standard for service-oriented device connectivity and utilizes collaborative principles to enhance user experience. Implementing separated workflow applications allows for a flexible system setup and configuration. The system was validated in three separate test scenarios to measure accuracies for 1) co-registration, 2) needle target planning in a water bath and 3) in an abdominal phantom. The co-registration accuracy averaged 0.94 ± 0.42 mm. The positioning errors ranged from 0.86 ± 0.42 to 1.19 ± 0.70 mm in the water bath setup and from 1.69 ± 0.92 to 1.96 ± 0.86 mm in the phantom. The presented results serve as a proof-of-concept and add to the current state of the art to alleviate system deployment and fast configuration for percutaneous robotic interventions.},
  archive      = {J_FROBT},
  author       = {Berger, Johann and Unger, Michael and Keller, Johannes and Reich, C. Martin and Neumuth, Thomas and Melzer, Andreas},
  doi          = {10.3389/frobt.2022.875845},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {875845},
  shortjournal = {Front. Robot. AI},
  title        = {Design and validation of a medical robotic device system to control two collaborative robots for ultrasound-guided needle insertions},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Getting acquainted: First steps for child-robot relationship
formation. <em>FROBT</em>, <em>9</em>, 853665. (<a
href="https://doi.org/10.3389/frobt.2022.853665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we discuss two studies of children getting acquainted with an autonomous socially assistive robot. The success of the first encounter is key for a sustainable long-term supportive relationship. We provide four validated behavior design elements that enable the robot to robustly get acquainted with the child. The first are five conversational patterns that allow children to comfortably self-disclose to the robot. The second is a reciprocation strategy that enables the robot to adequately respond to the children’s self-disclosures. The third is a ‘how to talk to me’ tutorial. The fourth is a personality profile for the robot that creates more rapport and comfort between the child and the robot. The designs were validated with two user studies (N1 = 30, N2 = 75, 8–11 years. o. children). The results furthermore showed similarities between how children form relationships with people and how children form relationships with robots. Most importantly, self-disclosure, and specifically how intimate the self-disclosures are, is an important predictor for the success of child-robot relationship formation. Speech recognition errors reduces the intimacy and feeling similar to the robot increases the intimacy of self-disclosures.},
  archive      = {J_FROBT},
  author       = {Ligthart, Mike E. U. and Neerincx, Mark A. and Hindriks, Koen V.},
  doi          = {10.3389/frobt.2022.853665},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {853665},
  shortjournal = {Front. Robot. AI},
  title        = {Getting acquainted: First steps for child-robot relationship formation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coding and educational robotics with peers: The C0D1NC
experience to foster inclusion. <em>FROBT</em>, <em>9</em>, 825536. (<a
href="https://doi.org/10.3389/frobt.2022.825536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present paper, the experience of the C0D1NC project (Coding for inclusion) is described. In this project an innovative methodology based on peer-education is the core of the educational approach. High school students become “teachers” as they are trained to teach coding and robotics to younger students. This approach favors inclusion and digital inclusion. To affirm this, we evaluated different aspects: relations between peers, perceived self-efficacy, and attitude towards technology at the beginning of activities (pre-test) and the end (post-test). Results indicate that this approach can be effective to favor personal growth, improved relations between peers, and increased self-efficacy too.},
  archive      = {J_FROBT},
  author       = {Ponticorvo, Michela and Rubinacci, Franco and Dell’Aquila, Elena and Marocco, Davide},
  doi          = {10.3389/frobt.2022.825536},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {825536},
  shortjournal = {Front. Robot. AI},
  title        = {Coding and educational robotics with peers: The C0D1NC experience to foster inclusion},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining unsupervised and supervised learning for sample
efficient continuous language grounding. <em>FROBT</em>, <em>9</em>,
701250. (<a href="https://doi.org/10.3389/frobt.2022.701250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural and efficient communication with humans requires artificial agents that are able to understand the meaning of natural language. However, understanding natural language is non-trivial and requires proper grounding mechanisms to create links between words and corresponding perceptual information. Since the introduction of the “Symbol Grounding Problem” in 1990, many different grounding approaches have been proposed that either employed supervised or unsupervised learning mechanisms. The latter have the advantage that no other agent is required to learn the correct groundings, while the former are often more sample-efficient and accurate but require the support of another agent, like a human or another artificial agent. Although combining both paradigms seems natural, it has not achieved much attention. Therefore, this paper proposes a hybrid grounding framework which combines both learning paradigms so that it is able to utilize support from a tutor, if available, while it can still learn when no support is provided. Additionally, the framework has been designed to learn in a continuous and open-ended manner so that no explicit training phase is required. The proposed framework is evaluated through two different grounding scenarios and its unsupervised grounding component is compared to a state-of-the-art unsupervised Bayesian grounding framework, while the benefit of combining both paradigms is evaluated through the analysis of different feedback rates. The obtained results show that the employed unsupervised grounding mechanism outperforms the baseline in terms of accuracy, transparency, and deployability and that combining both paradigms increases both the sample-efficiency as well as the accuracy of purely unsupervised grounding, while it ensures that the framework is still able to learn the correct mappings, when no supervision is available.},
  archive      = {J_FROBT},
  author       = {Roesler, Oliver},
  doi          = {10.3389/frobt.2022.701250},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {701250},
  shortjournal = {Front. Robot. AI},
  title        = {Combining unsupervised and supervised learning for sample efficient continuous language grounding},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The long-term efficacy of “social buffering” in artificial
social agents: Contextual affective perception matters. <em>FROBT</em>,
<em>9</em>, 699573. (<a
href="https://doi.org/10.3389/frobt.2022.699573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic (social) environments, an affective state of “stress” can be adaptive and promote agent wellbeing, but maladaptive if not appropriately regulated. The presence of (and interactions with) affect-based social support has been hypothesised to provide mechanisms to regulate stress (the “social buffering” hypothesis), though the precise, underlying mechanisms are still unclear. However, the hormone oxytocin has been implicated in mediating these effects in at least two ways: by improving social appraisals and reducing the short-term release of stress hormones (i.e., cortisol), and adapting an agent’s long-term stress tolerance. These effects likely facilitate an agent’s long-term adaptive ability by grounding their physiological and behavioural adaptation in the (affective) social environment, though these effects also appear to be context-dependent. In this paper, we investigate whether two of the hypothesised hormonal mechanisms that underpin the “social buffering” phenomenon affect the long-term wellbeing of (artificial) social agents who share affective social bonds, across numerous social and physical environmental contexts. Building on previous findings, we hypothesise that “social buffering” effects can improve the long-term wellbeing of agents who share affective social bonds in dynamic environments, through regular prosocial interactions with social bond partners. We model some of the effects associated with oxytocin and cortisol that underpin these hypothesised mechanisms in our biologically-inspired, socially-adaptive agent model, and conduct our investigation in a small society of artificial agents whose goal is to survive in challenging environments. Our results find that, while stress can be adaptive and regulated through affective social support, long-term behavioural and physiological adaptation is determined by the contextual perception of affective social bonds, which is influenced by early-stage interactions between affective social bond partners as well as the degree of the physical and social challenges. We also show how these low-level effects associated with oxytocin and cortisol can be used as “biomarkers” of social support and environmental stress. For socially-situated artificial agents, we suggest that these “social buffering” mechanisms can adapt the (adaptive) stress mechanisms, but that the long-term efficacy of this adaptation is related to the temporal dynamics of social interactions and the contextual perception of the affective social and physical environments.},
  archive      = {J_FROBT},
  author       = {Khan, Imran and Cañamero, Lola},
  doi          = {10.3389/frobt.2022.699573},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {699573},
  shortjournal = {Front. Robot. AI},
  title        = {The long-term efficacy of “Social buffering” in artificial social agents: Contextual affective perception matters},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Human movement understanding for intelligent
robots and systems. <em>FROBT</em>, <em>9</em>, 994167. (<a
href="https://doi.org/10.3389/frobt.2022.994167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Yoshikawa, Taizo and Demircan, Emel and Fraisse, Philippe and Petrič, Tadej},
  doi          = {10.3389/frobt.2022.994167},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {994167},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Human movement understanding for intelligent robots and systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Saltwater-responsive bubble artificial muscles using
superabsorbent polymers. <em>FROBT</em>, <em>9</em>, 960372. (<a
href="https://doi.org/10.3389/frobt.2022.960372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots operating in changing underwater environments may be required to adapt to these varying conditions. In tidal estuaries, for example, where the degree of salinity cycles in step with the level of the water, a robot may need to adapt its behaviour depending on the position of the tide. In freshwater bodies, the unexpected presence of a pollutant may also require the robot to respond by altering its behaviour. Embodying this sensing and response in the body of the robot means that adaptivity to the environment can be achieved without resorting to centralised control. This can also allow direct responsivity using ‘free’ environmental energy, actuating without requiring stored onboard energy. In this work we present a soft artificial muscle, the contraction of which varies in response to the salinity the water surrounding it. The novel actuator uses a super-absorbent polymer gel encapsulated within a series of discrete cells. This gel readily absorbs water through the membrane wall of the actuator, and can swell to over 300 times its initial volume. This swelling generates significant pressure, changing the shape of the cells and driving the contraction of the muscle. The degree of swelling is significantly reduced by the presence of salts and pollutants in the surrounding water, so transitioning from a freshwater to a saltwater environment causes the muscle to relax. In this paper, we discuss the design and fabrication of these superabsorbent polymer-based Bubble Artificial Muscle (SAP-BAM) actuators. The tensile properties of the muscle under actuated (fresh water) and relaxed (salt water) conditions are characterised, showing a maximum generated force of 10.96N. The length response under constant load for a full actuation cycle is given, showing a maximum contraction of 27.5% of the initial length at 1N load, and the performance over repeated actuation and relaxation cycles is shown. The SAP-BAM muscles are straightforward to fabricate and are composed of low-cost, freely-available materials. Many existing pneumatically-actuated muscles can be modified to use the approach taken for this muscle. The muscle presented in this work represents the first example of a new class of super-absorbent polymer-driven environmental soft artificial muscles.},
  archive      = {J_FROBT},
  author       = {Gosden, Daniel and Diteesawat, Richard Suphapol and Studley, Matthew and Rossiter, Jonathan},
  doi          = {10.3389/frobt.2022.960372},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {960372},
  shortjournal = {Front. Robot. AI},
  title        = {Saltwater-responsive bubble artificial muscles using superabsorbent polymers},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Path planning with the derivative of heuristic angle based
on the GBFS algorithm. <em>FROBT</em>, <em>9</em>, 958930. (<a
href="https://doi.org/10.3389/frobt.2022.958930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots used in extreme environments need a high reactivity on their scene. For fast response, they need the ability to find the optimal path in a short time. In order to achieve this goal, this study introduces WA*DH+, an improved version of WA*DH (weighted A* with the derivative of heuristic angle). In some path planning scenes, WA*DH cannot find suboptimal nodes with the small inflation factor called the critical value due to its filtering method. It is hard to develop a new filtering method, so this study inflated the suboptimality of the initial solution instead. Critical values vary in every path planning scene, so increasing the inflation factor for the initial solution will not be the solution to our problem. Thus, WA*DH + uses the GBFS algorithm with the infinitely bounded suboptimal solution for its initial solution. Simulation results demonstrate that WA*DH + can return a better solution faster than WA*DH by finding suboptimal nodes in the given environment.},
  archive      = {J_FROBT},
  author       = {Lim, Daehee and Jo, Jungwook},
  doi          = {10.3389/frobt.2022.958930},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {958930},
  shortjournal = {Front. Robot. AI},
  title        = {Path planning with the derivative of heuristic angle based on the GBFS algorithm},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Making bipedal robot experiments reproducible and
comparable: The eurobench software approach. <em>FROBT</em>, <em>9</em>,
951663. (<a href="https://doi.org/10.3389/frobt.2022.951663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study describes the software methodology designed for systematic benchmarking of bipedal systems through the computation of performance indicators from data collected during an experimentation stage. Under the umbrella of the European project Eurobench, we collected approximately 30 protocols with related testbeds and scoring algorithms, aiming at characterizing the performances of humanoids, exoskeletons, and/or prosthesis under different conditions. The main challenge addressed in this study concerns the standardization of the scoring process to permit a systematic benchmark of the experiments. The complexity of this process is mainly due to the lack of consistency in how to store and organize experimental data, how to define the input and output of benchmarking algorithms, and how to implement these algorithms. We propose a simple but efficient methodology for preparing scoring algorithms, to ensure reproducibility and replicability of results. This methodology mainly constrains the interface of the software and enables the engineer to develop his/her metric in his/her favorite language. Continuous integration and deployment tools are then used to verify the replicability of the software and to generate an executable instance independent of the language through dockerization. This article presents this methodology and points at all the metrics and documentation repositories designed with this policy in Eurobench. Applying this approach to other protocols and metrics would ease the reproduction, replication, and comparison of experiments.},
  archive      = {J_FROBT},
  author       = {Remazeilles, Anthony and Dominguez, Alfonso and Barralon, Pierre and Torres-Pardo, Adriana and Pinto, David and Aller, Felix and Mombaur, Katja and Conti, Roberto and Saccares, Lorenzo and Thorsteinsson, Freygardur and Prinsen, Erik and Cantón, Alberto and Castilla, Javier and Sanz-Morère, Clara B. and Tornero, Jesús and Torricelli, Diego},
  doi          = {10.3389/frobt.2022.951663},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {951663},
  shortjournal = {Front. Robot. AI},
  title        = {Making bipedal robot experiments reproducible and comparable: The eurobench software approach},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved weighting in particle filters applied to precise
state estimation in GNSS. <em>FROBT</em>, <em>9</em>, 950427. (<a
href="https://doi.org/10.3389/frobt.2022.950427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, the increasing complexity of the fusion of proprioceptive and exteroceptive sensors with Global Navigation Satellite System (GNSS) has motivated the exploration of Artificial Intelligence related strategies for the implementation of the navigation filters. In order to meet the strict requirements of accuracy and precision for Intelligent Transportation Systems (ITS) and Robotics, Bayesian inference algorithms are at the basis of current Positioning, Navigation, and Timing (PNT). Some scientific and technical contributions resort to Sequential Importance Resampling (SIR) Particle Filters (PF) to overcome the theoretical weaknesses of the more popular and efficient Kalman Filters (KFs) when the application relies on non-linear measurements models and non-Gaussian measurements errors. However, due to its higher computational burden, SIR PF is generally discarded. This paper presents a methodology named Multiple Weighting (MW) that reduces the computational burden of PF by considering the mutual information provided by the input measurements about the unknown state. An assessment of the proposed scheme is shown through an application to standalone GNSS estimation as a baseline of more complex multi-sensors, integrated solutions. By relying on the a-priori knowledge of the relationship between states and measurements, a change in the conventional PF routine allows performing a more efficient sampling of the posterior distribution. Results show that the proposed strategy can achieve any desired accuracy with a considerable reduction in the number of particles. Given a fixed and reasonable available computational effort, the proposed scheme allows for an accuracy improvement of the state estimate in the range of 20–40%.},
  archive      = {J_FROBT},
  author       = {Zocca, Simone and Guo, Yihan and Minetto , Alex and Dovis , Fabio},
  doi          = {10.3389/frobt.2022.950427},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {950427},
  shortjournal = {Front. Robot. AI},
  title        = {Improved weighting in particle filters applied to precise state estimation in GNSS},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive robot climbing with magnetic feet in unknown
slippery structure. <em>FROBT</em>, <em>9</em>, 949460. (<a
href="https://doi.org/10.3389/frobt.2022.949460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firm foot contact is the top priority of climbing robots to avoid catastrophic events, especially when working at height. This study proposes a robust planning and control framework for climbing robots that provides robustness to slippage in unknown environments. The framework includes 1) a center of mass (CoM) trajectory optimization under the estimated contact condition, 2) Kalman filter–like approach for uncertain environment parameter estimation and subsequent CoM trajectory re-planing, and 3) an online weight adaptation approach for whole-body control (WBC) framework that can adjust the ground reaction force (GRF) distribution in real time. Though the friction and adhesion characteristics are often assumed to be known, the presence of several factors that lead to a reduction in adhesion may cause critical problems for climbing robots. To address this issue safely and effectively, this study suggests estimating unknown contact parameters in real time and using the evaluated contact information to optimize climbing motion. Since slippage is a crucial behavior and requires instant recovery, the computation time for motion re-planning is also critical. The proposed CoM trajectory optimization algorithm achieved state-of-art fast computation via trajectory parameterization with several reasonable assumptions and linear algebra tricks. Last, an online weight adaptation approach is presented in the study to stabilize slippery motions within the WBC framework. This can help a robot to manage the slippage at the very last control step by redistributing the desired GRF. In order to verify the effectiveness of our method, we have tested our algorithm and provided benchmarks in simulation using a magnetic-legged climbing robot Manegto.},
  archive      = {J_FROBT},
  author       = {Lee, Jee-eun and Bandyopadhyay, Tirthankar and Sentis, Luis},
  doi          = {10.3389/frobt.2022.949460},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {949460},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive robot climbing with magnetic feet in unknown slippery structure},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Special issue on energy sustainability in marine
robotics. <em>FROBT</em>, <em>9</em>, 948374. (<a
href="https://doi.org/10.3389/frobt.2022.948374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Qian, Huihuan and Lam, Tin Lun and Zhang, Fumin and Maurelli, Francesco},
  doi          = {10.3389/frobt.2022.948374},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {948374},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Special issue on energy sustainability in marine robotics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two ways to make your robot proactive: Reasoning about human
intentions or reasoning about possible futures. <em>FROBT</em>,
<em>9</em>, 929267. (<a
href="https://doi.org/10.3389/frobt.2022.929267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots sharing their space with humans need to be proactive to be helpful. Proactive robots can act on their own initiatives in an anticipatory way to benefit humans. In this work, we investigate two ways to make robots proactive. One way is to recognize human intentions and to act to fulfill them, like opening the door that you are about to cross. The other way is to reason about possible future threats or opportunities and to act to prevent or to foster them, like recommending you to take an umbrella since rain has been forecast. In this article, we present approaches to realize these two types of proactive behavior. We then present an integrated system that can generate proactive robot behavior by reasoning on both factors: intentions and predictions. We illustrate our system on a sample use case including a domestic robot and a human. We first run this use case with the two separate proactive systems, intention-based and prediction-based, and then run it with our integrated system. The results show that the integrated system is able to consider a broader variety of aspects that are required for proactivity.},
  archive      = {J_FROBT},
  author       = {Buyukgoz, Sera and Grosinger, Jasmin and Chetouani, Mohamed and Saffiotti, Alessandro},
  doi          = {10.3389/frobt.2022.929267},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {929267},
  shortjournal = {Front. Robot. AI},
  title        = {Two ways to make your robot proactive: Reasoning about human intentions or reasoning about possible futures},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable and heterogenous mobile robot fleet-based task
automation in crowded hospital environments—a field test.
<em>FROBT</em>, <em>9</em>, 922835. (<a
href="https://doi.org/10.3389/frobt.2022.922835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hospitals, trained medical staff are often, in addition to performing complex procedures, spending valuable time on secondary tasks such as transporting samples and medical equipment; or even guiding patients and visitors around the premises. If these non-medical tasks were automated by deploying mobile service robots, more time can be focused on treating patients or allowing well-deserved rest for the potentially overworked healthcare professionals. Automating such tasks requires a human-aware robotic mobility system that can among other things navigate the hallways of the hospital; predictively avoid collisions with humans and other dynamic obstacles; coordinate task distribution and area coverage within a fleet of robots and other IoT devices; and interact with the staff, patients and visitors in an intuitive way. This work presents the results, lessons-learned and the source code of deploying a heterogeneous mobile robot fleet at the Tartu University Hospital, performing object transportation tasks in areas of intense crowd movement and narrow hallways. The primary use-case is defined as transporting time-critical samples from an intensive care unit to the hospital lab. Our work builds upon Robotics Middleware Framework (RMF), an open source, actively growing and highly capable fleet management platform which is yet to reach full maturity. Thus this paper demonstrates and validates the real-world deployment of RMF in an hospital setting and describes the integration efforts.},
  archive      = {J_FROBT},
  author       = {Valner, Robert and Masnavi, Houman and Rybalskii, Igor and Põlluäär, Rauno and Kõiv, Erik and Aabloo, Alvo and Kruusamäe, Karl and Singh, Arun Kumar},
  doi          = {10.3389/frobt.2022.922835},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {922835},
  shortjournal = {Front. Robot. AI},
  title        = {Scalable and heterogenous mobile robot fleet-based task automation in crowded hospital environments—a field test},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Moving robotics competitions virtual: The case study of
RoboCupJunior soccer simulation (SoccerSim). <em>FROBT</em>, <em>9</em>,
915322. (<a href="https://doi.org/10.3389/frobt.2022.915322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For almost 25 years, the goal of the RoboCup has been to build soccer robots capable of winning against the FIFA World Champion of 2050. To foster the participation of the next generation of roboticists, the RoboCupJunior competition takes place in parallel and provides a similar challenge of appropriate difficulty for high school students. RoboCupJunior has three main categories: Soccer, Rescue and OnStage. For the Soccer category, participants need to design, build and program a team of autonomous robots to play soccer against an opponent team of robots. The competition is physical in nature, since it assumes physical robots playing against one another. In 2020 and 2021, the COVID-19 pandemic has made it difficult for a competition of this type to take place, due to obvious restrictions on physical gatherings. To allow for some sort of participation, and inspired by positive experience of the larger RoboCup community, the Organizing Committee of RoboCupJunior Soccer has explored porting a portion of the challenge to a simulated environment. Many of the existing environments, however, are built for higher education/research teams competitions or research, making them complex to deploy and generally unsuitable for high school students. In this paper we present the development of SoccerSim, a simulated environment for RoboCupJunior Soccer, based on the Webots open-source robotics simulator. We also discuss how the participation of students was key for its development and present a summary of the competition rules. We further describe the case study of utilizing SoccerSim first as a testbed for a Demo competition, and later as part of RoboCup Worldwide 2021. The participation of more than 60 teams from over 20 countries suggests that SoccerSim provides an affordable alternative to physical robotics platforms, while being stable enough to support a diverse userbase. The experience of using SoccerSim at RoboCupJunior Worldwide 2021 suggests that a simulated environment significantly lowers the barrier to entry, as evidenced by the participation of many teams that have not participated before. To make it easy for similar competitions to take place in the future, we made the code of SoccerSim available as open-source, as well as the associated tooling required for using it in a tournament.},
  archive      = {J_FROBT},
  author       = {Martins, Felipe N. and Matejov, Adrián and Šuppa, Marek},
  doi          = {10.3389/frobt.2022.915322},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {915322},
  shortjournal = {Front. Robot. AI},
  title        = {Moving robotics competitions virtual: The case study of RoboCupJunior soccer simulation (SoccerSim)},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automatic drug injection device with spatial micro-force
perception guided by an microscopic image for robot-assisted ophthalmic
surgery. <em>FROBT</em>, <em>9</em>, 913930. (<a
href="https://doi.org/10.3389/frobt.2022.913930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vein injection guided by microscopic image is an innovative procedure for treating retinal vein occlusion. However, the retina organization is complex, fine, and weak, and the operation scale and force are small. Surgeons’ limited operation and force-sensing accuracy make it difficult to perform precise and stable drug injection operations on the retina in a magnified field of image vision. In this paper, a 3-DOF automatic drug injection mechanism was designed for microscopic image guiding robot-assisted needle delivery and automatic drug injection. Additionally, the robot-assisted real-time three-dimensional micro-force-sensing method for retinal vein injection was proposed. Based on the layout of three FBG sensors on the hollow outer wall of the nested needle tube in a circular array of nickel-titanium alloys, the real-time sensing of the contact force between the intraoperative instrument and the blood vessel was realized. The experimental data of 15 groups of porcine eyeball retinal veins with diameters of 100–200 μm showed that the piercing force of surgical instruments and blood vessels is 5.95∼12.97 mN, with an average value of 9.98 mN. Furthermore, 20 groups of experimental measurements on chicken embryo blood vessels with diameters of 150–500 μm showed that the piercing force was 4.02∼23.4 mN, with an average value of 12.05 mN.},
  archive      = {J_FROBT},
  author       = {Li, Zhen and Fu, Pan and Wei, Bing-Ting and Wang, Jie and Li, An-Long and Li, Ming-Jun and Bian, Gui-Bin},
  doi          = {10.3389/frobt.2022.913930},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {913930},
  shortjournal = {Front. Robot. AI},
  title        = {An automatic drug injection device with spatial micro-force perception guided by an microscopic image for robot-assisted ophthalmic surgery},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel immersive virtual reality environment for the motor
rehabilitation of stroke patients: A feasibility study. <em>FROBT</em>,
<em>9</em>, 906424. (<a
href="https://doi.org/10.3389/frobt.2022.906424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We designed and implemented an immersive virtual reality (VR) environment for upper limb rehabilitation, which possesses several notable features. First, by exploiting modern computer graphics its can present a variety of scenarios that make the rehabilitation routines challenging yet enjoyable for patients, thus enhancing their adherence to the therapy. Second, immersion in a virtual 3D space allows the patients to execute tasks that are closely related to everyday gestures, thus enhancing the transfer of the acquired motor skills to real-life routines. Third, in addition to the VR environment, we also developed a client app running on a PC that allows to monitor in real-time and remotely the patients’ routines thus paving the way for telerehabilitation scenarios. Here, we report the results of a feasibility study in a cohort of 16 stroke patients. All our patients showed a high degree of comfort in our immersive VR system and they reported very high scores of ownership and agency in embodiment and satisfaction questionnaires. Furthermore, and notably, we found that behavioral performances in our VR tasks correlated with the patients’ clinical scores (Fugl-Meyer scale) and they could thus be used to assess improvements during the rehabilitation program. While further studies are needed, our results clearly support the feasibility and effectiveness of VR-based motor rehabilitation processes.},
  archive      = {J_FROBT},
  author       = {Fregna, Giulia and Schincaglia, Nicola and Baroni, Andrea and Straudi, Sofia and Casile, Antonino},
  doi          = {10.3389/frobt.2022.906424},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {906424},
  shortjournal = {Front. Robot. AI},
  title        = {A novel immersive virtual reality environment for the motor rehabilitation of stroke patients: A feasibility study},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic selection of coordinate systems for learning
relative and absolute spatial concepts. <em>FROBT</em>, <em>9</em>,
904751. (<a href="https://doi.org/10.3389/frobt.2022.904751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots employed in homes and offices need to adaptively learn spatial concepts using user utterances. To learn and represent spatial concepts, the robot must estimate the coordinate system used by humans. For example, to represent spatial concept “left,” which is one of the relative spatial concepts (defined as a spatial concept depending on the object’s location), humans use a coordinate system based on the direction of a reference object. As another example, to represent spatial concept “living room,” which is one of the absolute spatial concepts (defined as a spatial concept that does not depend on the object’s location), humans use a coordinate system where a point on a map constitutes the origin. Because humans use these concepts in daily life, it is important for the robot to understand the spatial concepts in different coordinate systems. However, it is difficult for robots to learn these spatial concepts because humans do not clarify the coordinate system. Therefore, we propose a method (RASCAM) that enables a robot to simultaneously estimate the coordinate system and spatial concept. The proposed method is based on ReSCAM+O, which is a learning method for relative spatial concepts based on a probabilistic model. The proposed method introduces a latent variable that represents a coordinate system for simultaneous learning. This method can simultaneously estimate three types of unspecified information: coordinate systems, reference objects, and the relationship between concepts and words. No other method can estimate all these three types. Experiments using three different coordinate systems demonstrate that the proposed method can learn both relative and absolute spatial concepts while accurately selecting the coordinate system. The proposed approach can be beneficial for service robots to flexibly understand a new environment through the interactions with humans.},
  archive      = {J_FROBT},
  author       = {Sagara, Rikunari and Taguchi, Ryo and Taniguchi, Akira and Taniguchi, Tadahiro},
  doi          = {10.3389/frobt.2022.904751},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {904751},
  shortjournal = {Front. Robot. AI},
  title        = {Automatic selection of coordinate systems for learning relative and absolute spatial concepts},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aerial continuum manipulation: A new platform for compliant
aerial manipulation. <em>FROBT</em>, <em>9</em>, 903877. (<a
href="https://doi.org/10.3389/frobt.2022.903877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional aerial manipulation systems were usually composed of rigid-link manipulators attached to an aerial platform, arising several rigidity-related issues such as difficulties of reach, compliant motion, adaptability to object’s shape and pose uncertainties, and safety of human-manipulator interactions, especially in unstructured and confined environments. To address these issues, partially compliant manipulators, composed of rigid links and compliant/flexible joints, were proposed; however, they still suffer from insufficient dexterity and maneuverability. In this article, a new set of compliant aerial manipulators is suggested. For this purpose, the concept of aerial continuum manipulation system (ACMS) is introduced, several conceptual configurations are proposed, and the functionalities of ACMSs for different applications are discussed. Then, the performances of proposed aerial manipulators are compared with conventional aerial manipulators by implementing available benchmarks in the literature. To enhance the comparison, new features with related benchmarks are presented and used for evaluation purposes. In this study, the advantages of ACMSs over their rigid-link counterparts are illustrated and the potential applications of ACMSs are suggested. The open problems such as those related to dynamic coupling and control of ACMSs are also highlighted.},
  archive      = {J_FROBT},
  author       = {Jalali, Amir and Janabi-Sharifi, Farrokh},
  doi          = {10.3389/frobt.2022.903877},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {903877},
  shortjournal = {Front. Robot. AI},
  title        = {Aerial continuum manipulation: A new platform for compliant aerial manipulation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Therapeutic educational robot enhancing social interactions
in the management of obesity. <em>FROBT</em>, <em>9</em>, 895039. (<a
href="https://doi.org/10.3389/frobt.2022.895039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obesity is a chronic multifactorial pathology determined by many factors, including incorrect eating habits and a low level of physical activity. There is an urgent need to promote a persistent change in lifestyle in obese subjects, but very few individuals maintain long-term results achieved after diet therapies. Therapeutic Education (TE) has taken over an important role as a multidisciplinary intervention aimed at improving lifestyle and at acquiring new skills for the management of the disease. However, only a small portion of patients can maintain participation in such programs and fully benefit from them. Assistive technologies, and in particular assistive social robots, are powerful tools to boost independence and improve participation in educational activities. The aim of the research work described in this article is to evaluate the effect of employing a social robot as a therapeutic educational robot helping the expert therapist in the education activity. This article describes the implementation, deployment, and evaluation of a social educational robot used as a TE assistant. Although we cannot provide statistically significant results due to the limited number of people involved in the experimental protocol, all experimental results show a positive trend, indicating that the robot can enhance the social interactions between the patients and the therapist and among the patients, thus bringing to better overall results of the TE sessions, measured with standard tests for obesity management.},
  archive      = {J_FROBT},
  author       = {Prosperi, Enrico and Guidi, Giada and Napoli, Christian and Gnessi, Lucio and Iocchi, Luca},
  doi          = {10.3389/frobt.2022.895039},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {895039},
  shortjournal = {Front. Robot. AI},
  title        = {Therapeutic educational robot enhancing social interactions in the management of obesity},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3D printing of liquid crystal elastomers-based actuator for
an inchworm-inspired crawling soft robot. <em>FROBT</em>, <em>9</em>,
889848. (<a href="https://doi.org/10.3389/frobt.2022.889848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liquid crystal elastomers (LCEs) have shown great potential as soft actuating materials in soft robots, with large actuation strain and fast response speed. However, to achieve the unique features of actuation, the liquid crystal mesogens should be well aligned and permanently fixed by polymer networks, limiting their practical applications. The recent progress in the 3D printing technologies of LCEs overcame the shortcomings in conventional processing techniques. In this study, the relationship between the 3D printing parameters and the actuation performance of LCEs is studied in detail. Furthermore, a type of inchworm-inspired crawling soft robot based on a liquid crystal elastomeric actuator is demonstrated, coupled with tilted fish-scale-like microstructures with anisotropic friction as the foot for moving forwards. In addition, the anisotropic friction of inclined scales with different angles is measured to demonstrate the performance of anisotropic friction. Lastly, the kinematic performance of the inchworm-inspired robot is tested on different surfaces.},
  archive      = {J_FROBT},
  author       = {Song, Xiaowen and Zhang, Weitian and Liu, Haoran and Zhao, Limeng and Chen, Qi and Tian, Hongmiao},
  doi          = {10.3389/frobt.2022.889848},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {889848},
  shortjournal = {Front. Robot. AI},
  title        = {3D printing of liquid crystal elastomers-based actuator for an inchworm-inspired crawling soft robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Traversability analysis with vision and terrain probing for
safe legged robot navigation. <em>FROBT</em>, <em>9</em>, 887910. (<a
href="https://doi.org/10.3389/frobt.2022.887910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by human behavior when traveling over unknown terrain, this study proposes the use of probing strategies and integrates them into a traversability analysis framework to address safe navigation on unknown rough terrain. Our framework integrates collapsibility information into our existing traversability analysis, as vision and geometric information alone could be misled by unpredictable non-rigid terrains such as soft soil, bush area, or water puddles. With the new traversability analysis framework, our robot has a more comprehensive assessment of unpredictable terrain, which is critical for its safety in outdoor environments. The pipeline first identifies the terrain’s geometric and semantic properties using an RGB-D camera and desired probing locations on questionable terrains. These regions are probed using a force sensor to determine the risk of terrain collapsing when the robot steps over it. This risk is formulated as a collapsibility metric, which estimates an unpredictable region’s ground collapsibility. Thereafter, the collapsibility metric, together with geometric and semantic spatial data, is combined and analyzed to produce global and local traversability grid maps. These traversability grid maps tell the robot whether it is safe to step over different regions of the map. The grid maps are then utilized to generate optimal paths for the robot to safely navigate to its goal. Our approach has been successfully verified on a quadrupedal robot in both simulation and real-world experiments.},
  archive      = {J_FROBT},
  author       = {Haddeler, Garen and Chuah, Meng Yee (Michael) and You, Yangwei and Chan, Jianle and Adiwahono, Albertus H. and Yau, Wei Yun and Chew, Chee-Meng},
  doi          = {10.3389/frobt.2022.887910},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {887910},
  shortjournal = {Front. Robot. AI},
  title        = {Traversability analysis with vision and terrain probing for safe legged robot navigation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From walking to running: 3D humanoid gait generation via
MPC. <em>FROBT</em>, <em>9</em>, 876613. (<a
href="https://doi.org/10.3389/frobt.2022.876613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a real time algorithm for humanoid 3D walking and/or running based on a Model Predictive Control (MPC) approach. The objective is to generate a stable gait that replicates a footstep plan as closely as possible, that is, a sequence of candidate footstep positions and orientations with associated timings. For each footstep, the plan also specifies an associated reference height for the Center of Mass (CoM) and whether the robot should reach the footstep by walking or running. The scheme makes use of the Variable-Height Inverted Pendulum (VH-IP) as a prediction model, generating in real time both a CoM trajectory and adapted footsteps. The VH-IP model relates the position of the CoM to that of the Zero Moment Point (ZMP); to avoid falling, the ZMP must be inside a properly defined support region (a 3D extension of the 2D support polygon) whenever the robot is in contact with the ground. The nonlinearity of the VH-IP is handled by splitting the gait generation into two consecutive stages, both requiring to solve a quadratic program. Thanks to a particular triangular structure of the VH-IP dynamics, the first stage deals with the vertical dynamics using the Ground Reaction Force (GRF) as a decision variable. Using the prediction given by the first stage, the horizontal dynamics become linear time-varying. During the flight phases, the VH-IP collapses to a free-falling mass model. The proposed formulation incorporates constraints in order to maintain physically meaningful values of the GRF, keep the ZMP in the support region during contact phases, and ensure that the adapted footsteps are kinematically realizable. Most importantly, a stability constraint is enforced on the time-varying horizontal dynamics to guarantee a bounded evolution of the CoM with respect to the ZMP. Furthermore, we show how to extend the technique in order to perform running on tilted surfaces. We also describe a simple technique that receives input high-level velocity commands and generates a footstep plan in the form required by the proposed MPC scheme. The algorithm is validated via dynamic simulations on the full-scale humanoid robot HRP-4, as well as experiments on the small-sized robot OP3.},
  archive      = {J_FROBT},
  author       = {Smaldone, Filippo M. and Scianca, Nicola and Lanari, Leonardo and Oriolo, Giuseppe},
  doi          = {10.3389/frobt.2022.876613},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {876613},
  shortjournal = {Front. Robot. AI},
  title        = {From walking to running: 3D humanoid gait generation via MPC},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable stiffness locomotion with guaranteed stability for
quadruped robots traversing uneven terrains. <em>FROBT</em>, <em>9</em>,
874290. (<a href="https://doi.org/10.3389/frobt.2022.874290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadruped robots are widely applied in real-world environments where they have to face the challenges of walking on unknown rough terrains. This paper presents a control pipeline that generates robust and compliant legged locomotion for torque-controlled quadruped robots on uneven terrains. The Cartesian motion planner is designed to be reactive to unexpected early and late contacts using the estimated contact forces. Moreover, we present a novel scheme of optimal stiffness modulation that aims to coordinate desired compliance and tracking performance. It optimizes joint stiffness and contact forces coordinately in a quadratic programming (QP) formulation, where the constraints of non-slipping contacts and torque limits are imposed as well. In addition, the issue of stability under variable stiffness control is solved by imposing a tank-based passivity constraint explicitly. We finally validate the proposed control pipeline on our quadruped robot CENTAURO in experiments on uneven terrains and, through comparative tests, demonstrate the improvements of the variable stiffness locomotion.},
  archive      = {J_FROBT},
  author       = {Zhao, Xinyuan and Wu, Yuqiang and You, Yangwei and Laurenzi, Arturo and Tsagarakis, Nikos},
  doi          = {10.3389/frobt.2022.874290},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {874290},
  shortjournal = {Front. Robot. AI},
  title        = {Variable stiffness locomotion with guaranteed stability for quadruped robots traversing uneven terrains},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Different models of anthropomorphism across cultures and
ontological limits in current frameworks the integrative framework of
anthropomorphism. <em>FROBT</em>, <em>9</em>, 863319. (<a
href="https://doi.org/10.3389/frobt.2022.863319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anthropomorphism describes the tendency to ascribe human characteristics to nonhuman agents. Due to the increased interest in social robotics, anthropomorphism has become a core concept of human-robot interaction (HRI) studies. However, the wide use of this concept resulted in an interchangeability of its definition. In the present study, we propose an integrative framework of anthropomorphism (IFA) encompassing three levels: cultural, individual general tendencies, and direct attributions of human-like characteristics to robots. We also acknowledge the Western bias of the state-of-the-art view of anthropomorphism and develop a cross-cultural approach. In two studies, participants from various cultures completed tasks and questionnaires assessing their animism beliefs, individual tendencies to endow robots with mental properties, spirit, and consider them as more or less human. We also evaluated their attributions of mental anthropomorphic characteristics towards robots (i.e., cognition, emotion, intention). Our results demonstrate, in both experiments, that a three-level model (as hypothesized in the IFA) reliably explains the collected data. We found an overall influence of animism (cultural level) on the two lower levels, and an influence of the individual tendencies to mentalize, spiritualize and humanize (individual level) on the attribution of cognition, emotion and intention. In addition, in Experiment 2, the analyses show a more anthropocentric view of the mind for Western than East-Asian participants. As such, Western perception of robots depends more on humanization while East-Asian on mentalization. We further discuss these results in relation to the anthropomorphism literature and argue for the use of integrative cross-cultural model in HRI research.},
  archive      = {J_FROBT},
  author       = {Spatola, Nicolas and Marchesi, Serena and Wykowska, Agnieszka},
  doi          = {10.3389/frobt.2022.863319},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {863319},
  shortjournal = {Front. Robot. AI},
  title        = {Different models of anthropomorphism across cultures and ontological limits in current frameworks the integrative framework of anthropomorphism},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven vermiculite distribution modelling for UAV-based
precision pest management. <em>FROBT</em>, <em>9</em>, 854381. (<a
href="https://doi.org/10.3389/frobt.2022.854381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, unmanned aerial vehicles (UAVs) have gained considerable popularity in the agricultural sector, in which UAV-based actuation is used to spray pesticides and release biological control agents. A key challenge in such UAV-based actuation is to account for wind speed and UAV flight parameters to maximize precision-delivery of pesticides and biological control agents. This paper describes a data-driven framework to predict density distribution patterns of vermiculite dispensed from a hovering UAV as a function of UAV’s movement state, wind condition, and dispenser setting. The model, derived by our proposed learning algorithm, is able to accurately predict the vermiculite distribution pattern evaluated in terms of both training and test data. Our framework and algorithm can be easily translated to other precision pest management problems with different UAVs and dispensers and for difference pesticides and crops. Moreover, our model, due to its simple analytical form, can be incorporated into the design of a controller that can optimize autonomous UAV delivery of desired amount of predatory mites to multiple target locations.},
  archive      = {J_FROBT},
  author       = {Ma , Na and Mantri , Anil and Bough , Graham and Patnaik , Ayush and Yadav , Siddhesh and Nansen , Christian and Kong , Zhaodan},
  doi          = {10.3389/frobt.2022.854381},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {854381},
  shortjournal = {Front. Robot. AI},
  title        = {Data-driven vermiculite distribution modelling for UAV-based precision pest management},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-free reinforcement learning for robust locomotion
using demonstrations from trajectory optimization. <em>FROBT</em>,
<em>9</em>, 854212. (<a
href="https://doi.org/10.3389/frobt.2022.854212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general, two-stage reinforcement learning approach to create robust policies that can be deployed on real robots without any additional training using a single demonstration generated by trajectory optimization. The demonstration is used in the first stage as a starting point to facilitate initial exploration. In the second stage, the relevant task reward is optimized directly and a policy robust to environment uncertainties is computed. We demonstrate and examine in detail the performance and robustness of our approach on highly dynamic hopping and bounding tasks on a quadruped robot.},
  archive      = {J_FROBT},
  author       = {Bogdanovic, Miroslav and Khadiv , Majid and Righetti , Ludovic},
  doi          = {10.3389/frobt.2022.854212},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {854212},
  shortjournal = {Front. Robot. AI},
  title        = {Model-free reinforcement learning for robust locomotion using demonstrations from trajectory optimization},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel encoding element for robust pose estimation using
planar fiducials. <em>FROBT</em>, <em>9</em>, 838128. (<a
href="https://doi.org/10.3389/frobt.2022.838128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pose estimation in robotics is often achieved using images from known and purposefully applied markers or fiducials taken by a monocular camera. This low-cost system architecture can provide accurate and precise pose estimation measurements. However, to prevent the restriction of robotic movement and occlusions of features, the fiducial markers are often planar. While numerous planar fiducials exist, the performance of these markers suffers from pose ambiguities and loss of precision under frontal observations. These issues are most prevalent in systems with less-than-ideal specifications such as low-resolution detectors, low field of view optics, far-range measurements etc. To mitigate these issues, encoding markers have been proposed in literature. These markers encode an extra dimension of information in the signal between marker and sensor, thus increasing the robustness of the pose solution. In this work, we provide a survey of these encoding markers and show that existing solutions are complex, require optical elements and are not scalable. Therefore, we present a novel encoding element based on the compound eye of insects such as the Mantis. The encoding element encodes a virtual point in space in its signal without the use of optical elements. The features provided by the encoding element are mathematically equivalent to those of a protrusion. Where existing encoding fiducials require custom software, the projected virtual point can be used with standard pose solving algorithms. The encoding element is simple, can be produced using a consumer 3D printer and is fully scalable. The end-to-end implementation of the encoding element proposed in this work significantly increases the pose estimation performance of existing planar fiducials, enabling robust pose estimation for robotic systems.},
  archive      = {J_FROBT},
  author       = {Rijlaarsdam, David D. W. and Zwick, Martin and Kuiper, J.M. (Hans)},
  doi          = {10.3389/frobt.2022.838128},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {838128},
  shortjournal = {Front. Robot. AI},
  title        = {A novel encoding element for robust pose estimation using planar fiducials},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual state estimation in unseen environments through
domain adaptation and metric learning. <em>FROBT</em>, <em>9</em>,
833173. (<a href="https://doi.org/10.3389/frobt.2022.833173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotics, deep learning models are used in many visual perception applications, including the tracking, detection and pose estimation of robotic manipulators. The state of the art methods however are conditioned on the availability of annotated training data, which may in practice be costly or even impossible to collect. Domain augmentation is one popular method to improve generalization to out-of-domain data by extending the training data set with predefined sources of variation, unrelated to the primary task. While this typically results in better performance on the target domain, it is not always clear that the trained models are capable to accurately separate the signals relevant to solving the task (e.g., appearance of an object of interest) from those associated with differences between the domains (e.g., lighting conditions). In this work we propose to improve the generalization capabilities of models trained with domain augmentation by formulating a secondary structured metric-space learning objective. We concentrate on one particularly challenging domain transfer task—visual state estimation for an articulated underground mining machine—and demonstrate the benefits of imposing structure on the encoding space. Our results indicate that the proposed method has the potential to transfer feature embeddings learned on the source domain, through a suitably designed augmentation procedure, and on to an unseen target domain.},
  archive      = {J_FROBT},
  author       = {Güler, Püren and Stork, Johannes A. and Stoyanov, Todor},
  doi          = {10.3389/frobt.2022.833173},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {833173},
  shortjournal = {Front. Robot. AI},
  title        = {Visual state estimation in unseen environments through domain adaptation and metric learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Children-robot friendship, moral agency, and aristotelian
virtue development. <em>FROBT</em>, <em>9</em>, 818489. (<a
href="https://doi.org/10.3389/frobt.2022.818489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots are increasingly developed for the companionship of children. In this article we explore the moral implications of children-robot friendships using the Aristotelian framework of virtue ethics. We adopt a moderate position and argue that, although robots cannot be virtue friends, they can nonetheless enable children to exercise ethical and intellectual virtues. The Aristotelian requirements for true friendship apply only partly to children: unlike adults, children relate to friendship as an educational play of exploration, which is constitutive of the way they acquire and develop virtues. We highlight that there is a relevant difference between the way we evaluate adult-robot friendship compared to children-robot friendship, which is rooted in the difference in moral agency and moral responsibility that generate the asymmetries in the moral status ascribed to adults versus children. We look into the role played by imaginary companions (IC) and personified objects (PO) in children’s moral development and claim that robots, understood as Personified Robotic Objects (PROs), play a similar role with such fictional entities, enabling children to exercise affection, moral imagination and reasoning, thus contributing to their development as virtuous adults. Nonetheless, we argue that adequate use of robots for children’s moral development is conditioned by several requirements related to design, technology and moral responsibility.},
  archive      = {J_FROBT},
  author       = {Constantinescu, Mihaela and Uszkai, Radu and Vică, Constantin and Voinea, Cristina},
  doi          = {10.3389/frobt.2022.818489},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {818489},
  shortjournal = {Front. Robot. AI},
  title        = {Children-robot friendship, moral agency, and aristotelian virtue development},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human–robot creative interactions: Exploring creativity in
artificial agents using a storytelling game. <em>FROBT</em>, <em>9</em>,
695162. (<a href="https://doi.org/10.3389/frobt.2022.695162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creativity in social robots requires further attention in the interdisciplinary field of human–robot interaction (HRI). This study investigates the hypothesized connection between the perceived creative agency and the animacy of social robots. The goal of this work is to assess the relevance of robot movements in the attribution of creativity to robots. The results of this work inform the design of future human–robot creative interactions (HRCI). The study uses a storytelling game based on visual imagery inspired by the game “Story Cubes” to explore the perceived creative agency of social robots. This game is used to tell a classic story for children with an alternative ending. A 2 × 2 experiment was designed to compare two conditions: the robot telling the original version of the story and the robot plot twisting the end of the story. A Robotis Mini humanoid robot was used for the experiment, and we adapted the Short Scale of Creative Self (SSCS) to measure perceived creative agency in robots. We also used the Godspeed scale to explore different attributes of social robots in this setting. We did not obtain significant main effects of the robot movements or the story in the participants’ scores. However, we identified significant main effects of the robot movements in features of animacy, likeability, and perceived safety. This initial work encourages further studies experimenting with different robot embodiment and movements to evaluate the perceived creative agency in robots and inform the design of future robots that participate in creative interactions.},
  archive      = {J_FROBT},
  author       = {Sandoval, Eduardo Benítez and Sosa, Ricardo and Cappuccio, Massimiliano and Bednarz, Tomasz},
  doi          = {10.3389/frobt.2022.695162},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {695162},
  shortjournal = {Front. Robot. AI},
  title        = {Human–robot creative interactions: Exploring creativity in artificial agents using a storytelling game},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Envisioning social drones in education. <em>FROBT</em>,
<em>9</em>, 666736. (<a
href="https://doi.org/10.3389/frobt.2022.666736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Johal, Wafa and Gatos, Doğa and Yantac, Asim Evren and Obaid, Mohammad},
  doi          = {10.3389/frobt.2022.666736},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {666736},
  shortjournal = {Front. Robot. AI},
  title        = {Envisioning social drones in education},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Current challenges and future developments in
robot grasping. <em>FROBT</em>, <em>9</em>, 973208. (<a
href="https://doi.org/10.3389/frobt.2022.973208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Morales, Antonio and León, Beatriz and Chinellato, Eris and Suárez, Raúl},
  doi          = {10.3389/frobt.2022.973208},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {973208},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Current challenges and future developments in robot grasping},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Corrigendum: A music-therapy robotic platform for children
with autism: A pilot study. <em>FROBT</em>, <em>9</em>, 965369. (<a
href="https://doi.org/10.3389/frobt.2022.965369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Feng, Huanghao and Mahoor, Mohammad H. and Dino, Francesca},
  doi          = {10.3389/frobt.2022.965369},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {965369},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: a music-therapy robotic platform for children with autism: a pilot study},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Robotics to understand animal behaviour.
<em>FROBT</em>, <em>9</em>, 963416. (<a
href="https://doi.org/10.3389/frobt.2022.963416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Li, Liang and Ravi, Sridhar and Wang, Chen},
  doi          = {10.3389/frobt.2022.963416},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {963416},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotics to understand animal behaviour},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Developing intelligent robots that grasp affordance.
<em>FROBT</em>, <em>9</em>, 951293. (<a
href="https://doi.org/10.3389/frobt.2022.951293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans and robots operating in unstructured environments both need to classify objects through haptic exploration and use them in various tasks, but currently they differ greatly in their strategies for acquiring such capabilities. This review explores nascent technologies that promise more convergence. A novel form of artificial intelligence classifies objects according to sensory percepts during active exploration and decides on efficient sequences of exploratory actions to identify objects. Representing objects according to the collective experience of manipulating them provides a substrate for discovering causality and affordances. Such concepts that generalize beyond explicit training experiences are an important aspect of human intelligence that has eluded robots. For robots to acquire such knowledge, they will need an extended period of active exploration and manipulation similar to that employed by infants. The efficacy, efficiency and safety of such behaviors depends on achieving smooth transitions between movements that change quickly from exploratory to executive to reflexive. Animals achieve such smoothness by using a hierarchical control scheme that is fundamentally different from those of conventional robotics. The lowest level of that hierarchy, the spinal cord, starts to self-organize during spontaneous movements in the fetus. This allows its connectivity to reflect the mechanics of the musculoskeletal plant, a bio-inspired process that could be used to adapt spinal-like middleware for robots. Implementation of these extended and essential stages of fetal and infant development is impractical, however, for mechatronic hardware that does not heal and replace itself like biological tissues. Instead such development can now be accomplished in silico and then cloned into physical robots, a strategy that could transcend human performance.},
  archive      = {J_FROBT},
  author       = {Loeb, Gerald E.},
  doi          = {10.3389/frobt.2022.951293},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {951293},
  shortjournal = {Front. Robot. AI},
  title        = {Developing intelligent robots that grasp affordance},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Safety in collaborative robotics and autonomous
systems. <em>FROBT</em>, <em>9</em>, 949214. (<a
href="https://doi.org/10.3389/frobt.2022.949214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dani, Ashwin and Kan, Zhen and Kamalapurkar, Rushikesh and Gans, Nicholas},
  doi          = {10.3389/frobt.2022.949214},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {949214},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Safety in collaborative robotics and autonomous systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A modular vision language navigation and manipulation
framework for long horizon compositional tasks in indoor environment.
<em>FROBT</em>, <em>9</em>, 930486. (<a
href="https://doi.org/10.3389/frobt.2022.930486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new framework—MoViLan (Modular Vision and Language) for execution of visually grounded natural language instructions for day to day indoor household tasks. While several data-driven, end-to-end learning frameworks have been proposed for targeted navigation tasks based on the vision and language modalities, performance on recent benchmark data sets revealed the gap in developing comprehensive techniques for long horizon, compositional tasks (involving manipulation and navigation) with diverse object categories, realistic instructions and visual scenarios with non reversible state changes. We propose a modular approach to deal with the combined navigation and object interaction problem without the need for strictly aligned vision and language training data (e.g., in the form of expert demonstrated trajectories). Such an approach is a significant departure from the traditional end-to-end techniques in this space and allows for a more tractable training process with separate vision and language data sets. Specifically, we propose a novel geometry-aware mapping technique for cluttered indoor environments, and a language understanding model generalized for household instruction following. We demonstrate a significant increase in success rates for long horizon, compositional tasks over recent works on the recently released benchmark data set -ALFRED.},
  archive      = {J_FROBT},
  author       = {Saha, Homagni and Fotouhi, Fateme and Liu, Qisai and Sarkar, Soumik},
  doi          = {10.3389/frobt.2022.930486},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {930486},
  shortjournal = {Front. Robot. AI},
  title        = {A modular vision language navigation and manipulation framework for long horizon compositional tasks in indoor environment},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How the environment shapes tactile sensing: Understanding
the relationship between tactile filters and surrounding environment.
<em>FROBT</em>, <em>9</em>, 930405. (<a
href="https://doi.org/10.3389/frobt.2022.930405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanical properties of a sensor strongly affect its tactile sensing capabilities. By exploiting tactile filters, mechanical structures between the sensing unit and the environment, it is possible to tune the interaction dynamics with the surrounding environment. But how can we design a good tactile filter? Previously, the role of filters’ geometry and stiffness on the quality of the tactile data has been the subject of several studies, both implementing static filters and adaptable filters. State-of-the-art works on online adaptive stiffness highlight a crucial role of the filters’ mechanical behavior in the structure of the recorded tactile data. However, the relationship between the filter’s and the environment’s characteristics is still largely unknown. We want to show the effect of the environment’s mechanical properties on the structure of the acquired tactile data and the performance of a classification task while testing a wide range of static tactile filters. Moreover, we fabricated the filters using four materials commonly exploited in soft robotics, to merge the gap between tactile sensing and robotic applications. We collected data from the interaction with a standard set of twelve objects of different materials, shapes, and textures, and we analyzed the effect of the filter’s material on the structure of such data and the performance of nine common machine learning classifiers, both considering the overall test set and the three individual subsets made by all objects of the same material. We showed that depending on the material of the test objects, there is a drastic change in the performance of the four tested filters, and that the filter that matches the mechanical properties of the environment always outperforms the others.},
  archive      = {J_FROBT},
  author       = {Costi, Leone and Maiolino, Perla and Iida, Fumiya},
  doi          = {10.3389/frobt.2022.930405},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {930405},
  shortjournal = {Front. Robot. AI},
  title        = {How the environment shapes tactile sensing: Understanding the relationship between tactile filters and surrounding environment},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interaction matters: The effect of touching the social robot
PARO on pain and stress is stronger when turned ON vs. OFF.
<em>FROBT</em>, <em>9</em>, 926185. (<a
href="https://doi.org/10.3389/frobt.2022.926185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social touch between humans, as well as between humans and animals, was previously found to reduce pain and stress. We previously reported that touching a social robot can also induce a reduction in pain ratings. However, it is unclear if the effect that touching a robot has on pain perception is due to its appearance and its pleasant touch, or due to its ability to socially interact with humans. In the current experiment, we aimed to assess the contribution of the interactive quality to pain perception. We assessed the effect of touching the social robot PARO on mild and strong pain ratings and on stress perception, on a total of 60 healthy young participants. The robot either interacted with participants (ON group, n = 30) or was turned off (OFF group, n = 30). Touching the robot induced a decrease in mild pain ratings (compared to baseline) only in the ON group while strong pain ratings decreased similarly in both the ON and the OFF groups. The decrease in mild pain ratings in the ON group was significantly greater in participants with a higher positive perception of the interaction with PARO. We conclude that part of the effect that touching the robot has on pain stems from its interactive features.},
  archive      = {J_FROBT},
  author       = {Geva, Nirit and Hermoni, Netta and Levy-Tzedek, Shelly},
  doi          = {10.3389/frobt.2022.926185},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {926185},
  shortjournal = {Front. Robot. AI},
  title        = {Interaction matters: The effect of touching the social robot PARO on pain and stress is stronger when turned ON vs. OFF},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The effect of robot speed on comfortable passing distances.
<em>FROBT</em>, <em>9</em>, 915972. (<a
href="https://doi.org/10.3389/frobt.2022.915972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots navigate ever more often in close proximity to people. In the current work, we focused on two distinctive navigational scenarios: passing and overtaking a person who is walking. In the first experiment, we compared nine different passing distances for a humanoid robot and found that human comfort increased with passing distance and that their relationship could be described by an inverted Gaussian. In the second experiment, we validated this relationship for an industrial autonomous robot and extended the study to also include overtaking distances and different robot moving speeds. The results showed that overtaking was considered to be less comfortable than passing but that the overtaking distance had a similar relationship with human comfort. Human comfort decreases with a higher robot movement speed. Results obtained through location trackers furthermore showed that people actively take a larger distance from the robot when it starts its trajectory closer to them. The current results can be used to quantify human comfort in environments where humans and robots co-exist and they can be used as input for human-aware navigational models for autonomous robots.},
  archive      = {J_FROBT},
  author       = {Neggers, Margot M. E. and Cuijpers, Raymond H. and Ruijten, Peter A. M. and IJsselsteijn, Wijnand A.},
  doi          = {10.3389/frobt.2022.915972},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {915972},
  shortjournal = {Front. Robot. AI},
  title        = {The effect of robot speed on comfortable passing distances},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bio-inspired vision and gesture-based robot-robot
interaction for human-cooperative package delivery. <em>FROBT</em>,
<em>9</em>, 915884. (<a
href="https://doi.org/10.3389/frobt.2022.915884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a novel bio-inspired framework for two robots interacting together for a cooperative package delivery task with a human-in the-loop. It contributes to eliminating the need for network-based robot-robot interaction in constrained environments. An individual robot is instructed to move in specific shapes with a particular orientation at a certain speed for the other robot to infer using object detection (custom YOLOv4) and depth perception. The shape is identified by calculating the area occupied by the detected polygonal route. A metric for the area’s extent is calculated and empirically used to assign regions for specific shapes and gives an overall accuracy of 93.3% in simulations and 90% in a physical setup. Additionally, gestures are analyzed for their accuracy of intended direction, distance, and the target coordinates in the map. The system gives an average positional RMSE of 0.349 in simulation and 0.461 in a physical experiment. A video demonstration of the problem statement along with the simulations and experiments for real world applications has been given here and in Supplementary Material.},
  archive      = {J_FROBT},
  author       = {Joshi, Kaustubh and Roy Chowdhury, Abhra},
  doi          = {10.3389/frobt.2022.915884},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {915884},
  shortjournal = {Front. Robot. AI},
  title        = {Bio-inspired vision and gesture-based robot-robot interaction for human-cooperative package delivery},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Responsible robotics design–a systems approach to developing
design guides for robotics in pasture-grazed dairy farming.
<em>FROBT</em>, <em>9</em>, 914850. (<a
href="https://doi.org/10.3389/frobt.2022.914850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Application of robotics and automation in pasture-grazed agriculture is in an emergent phase. Technology developers face significant challenges due to aspects such as the complex and dynamic nature of biological systems, relative cost of technology versus farm labor costs, and specific market characteristics in agriculture. Overlaying this are socio-ethical issues around technology development, and aspects of responsible research and innovation. There are numerous examples of technology being developed but not adopted in pasture-grazed farming, despite the potential benefits to farmers and/or society, highlighting a disconnect in the innovation system. In this perspective paper, we propose a “responsibility by design” approach to robotics and automation innovation, using development of batch robotic milking in pasture-grazed dairy farming as a case study. The framework we develop is used to highlight the wider considerations that technology developers and policy makers need to consider when envisaging future innovation trajectories for robotics in smart farming. These considerations include the impact on work design, worker well-being and safety, changes to farming systems, and the influences of market and regulatory constraints.},
  archive      = {J_FROBT},
  author       = {Eastwood, C. R. and Dela Rue, B. and Edwards, J. P. and Jago, J.},
  doi          = {10.3389/frobt.2022.914850},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {914850},
  shortjournal = {Front. Robot. AI},
  title        = {Responsible robotics design–A systems approach to developing design guides for robotics in pasture-grazed dairy farming},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “No chit chat!” A warning from a physical versus virtual
robot invigilator: Which matters most? <em>FROBT</em>, <em>9</em>,
908013. (<a href="https://doi.org/10.3389/frobt.2022.908013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Past work has not considered social robots as proctors or monitors to prevent cheating or maintain discipline in the context of exam invigilation with adults. Further, we do not see an investigation into the role of invigilation for the robot presented in two different embodiments (physical vs. virtual). We demonstrate a system that enables a robot (physical and virtual) to act as an invigilator and deploy an exam setup with two participants completing a programming task. We conducted two studies (an online video-based survey and an in-person evaluation) to understand participants’ perceptions of the invigilator robot presented in two different embodiments. Additionally, we investigated whether participants showed cheating behaviours in one condition more than the other. The findings showed that participants’ ratings did not differ significantly. Further, participants were more talkative in the virtual robot condition compared to the physical robot condition. These findings are promising and call for further research into the invigilation role of social robots in more subtle and complex exam-like settings.},
  archive      = {J_FROBT},
  author       = {Ahmad , Muneeb I. and Refik , Reem},
  doi          = {10.3389/frobt.2022.908013},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {908013},
  shortjournal = {Front. Robot. AI},
  title        = {“No chit chat!” a warning from a physical versus virtual robot invigilator: Which matters most?},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “Design of a suspension lever mechanism in biomedical
robotic system”. <em>FROBT</em>, <em>9</em>, 906691. (<a
href="https://doi.org/10.3389/frobt.2022.906691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article discusses the design of a suspended lever mechanism with elastic elements, which is used as a safety device in a robotic system for the rehabilitation of the lower limbs. The article analyzes the existing mechanical structures of devices for rehabilitation, identifies the problems of operation, design, and safety systems and suggests a new design of the device. The process of reverse development of a lever mechanism scheme to ensure safety during rehabilitation of the lower limbs is presented. The design of the lever mechanism consists of movable levers connected by elastic elements. The device allows you to dampen the force during active rehabilitation. The power calculation of the lever mechanism in the rehabilitation system was carried out. The article addresses the issues present in the current mechanical designs with a brief discussion on the system architecture.},
  archive      = {J_FROBT},
  author       = {Voloshkin, A. and Tereshchenko, A. and Carbone, G. and Rybak, L. and Nozdracheva, A.},
  doi          = {10.3389/frobt.2022.906691},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {906691},
  shortjournal = {Front. Robot. AI},
  title        = {&quot;Design of a suspension lever mechanism in biomedical robotic system&quot;},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Horizon: A trajectory optimization framework for robotic
systems. <em>FROBT</em>, <em>9</em>, 899025. (<a
href="https://doi.org/10.3389/frobt.2022.899025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Horizon, an open-source framework for trajectory optimization tailored to robotic systems that implements a set of tools to simplify the process of dynamic motion generation. Its user-friendly Python-based API allows designing the most complex robot motions using a simple and intuitive syntax. At the same time, the modular structure of Horizon allows for easy customization on many levels, providing several recipes to handle fixed and floating-base systems, contact switching, variable time nodes, multiple transcriptions, integrators and solvers to guarantee flexibility towards diverse tasks. The proposed framework relies on direct simultaneous methods to transcribe the optimal problem into a nonlinear programming problem that can be solved by state-of-the-art solvers. In particular, it provides several off-the-shelf solvers, as well as two custom-implemented solvers, i.e. GN-SQP and Iterative Linear-Quadratic Regulator. Solutions of optimized problems can be stored for warm-starting, and re-sampled at a different frequency while enforcing dynamic feasibility. The proposed framework is validated through a number of use-case scenarios involving several robotic platforms. Finally, an in-depth analysis of a specific case study is carried out, where a highly dynamic motion (i.e., a twisting jump using the quadruped robot Spot® from BostonDynamics1) is generated, in order to highlight the main features of the framework and demonstrate its capabilities.},
  archive      = {J_FROBT},
  author       = {Ruscelli, Francesco and Laurenzi, Arturo and Tsagarakis, Nikos G. and Mingo Hoffman, Enrico},
  doi          = {10.3389/frobt.2022.899025},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {899025},
  shortjournal = {Front. Robot. AI},
  title        = {Horizon: A trajectory optimization framework for robotic systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast joint multi-robot trajectory optimization by GPU
accelerated batch solution of distributed sub-problems. <em>FROBT</em>,
<em>9</em>, 890385. (<a
href="https://doi.org/10.3389/frobt.2022.890385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a joint multi-robot trajectory optimizer that can compute trajectories for tens of robots in aerial swarms within a small fraction of a second. The computational efficiency of our approach is built on breaking the per-iteration computation of the joint optimization into smaller, decoupled sub-problems and solving them in parallel through a custom batch optimizer. We show that each of the sub-problems can be reformulated to have a special Quadratic Programming structure, wherein the matrices are shared across all the problems and only the associated vector varies. As result, the batch solution update rule reduces to computing just large matrix vector products which can be trivially accelerated using GPUs. We validate our optimizer’s performance in difficult benchmark scenarios and compare it against existing state-of-the-art approaches. We demonstrate remarkable improvements in computation time its scaling with respect to the number of robots. Moreover, we also perform better in trajectory quality as measured by smoothness and arc-length metrics.},
  archive      = {J_FROBT},
  author       = {Guhathakurta, Dipanwita and Rastgar , Fatemeh and Sharma , M. Aditya and Krishna , K. Madhava and Singh , Arun Kumar},
  doi          = {10.3389/frobt.2022.890385},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {890385},
  shortjournal = {Front. Robot. AI},
  title        = {Fast joint multi-robot trajectory optimization by GPU accelerated batch solution of distributed sub-problems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward benchmarking of long-term spatio-temporal maps of
pedestrian flows for human-aware navigation. <em>FROBT</em>, <em>9</em>,
890013. (<a href="https://doi.org/10.3389/frobt.2022.890013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the advances in mobile robotics, the introduction of autonomous robots in human-populated environments is rather slow. One of the fundamental reasons is the acceptance of robots by people directly affected by a robot’s presence. Understanding human behavior and dynamics is essential for planning when and how robots should traverse busy environments without disrupting people’s natural motion and causing irritation. Research has exploited various techniques to build spatio-temporal representations of people’s presence and flows and compared their applicability to plan optimal paths in the future. Many comparisons of how dynamic map-building techniques show how one method compares on a dataset versus another, but without consistent datasets and high-quality comparison metrics, it is difficult to assess how these various methods compare as a whole and in specific tasks. This article proposes a methodology for creating high-quality criteria with interpretable results for comparing long-term spatio-temporal representations for human-aware path planning and human-aware navigation scheduling. Two criteria derived from the methodology are then applied to compare the representations built by the techniques found in the literature. The approaches are compared on a real-world, long-term dataset, and the conception is validated in a field experiment on a robotic platform deployed in a human-populated environment. Our results indicate that continuous spatio-temporal methods independently modeling spatial and temporal phenomena outperformed other modeling approaches. Our results provide a baseline for future work to compare a wide range of methods employed for long-term navigation and provide researchers with an understanding of how these various methods compare in various scenarios.},
  archive      = {J_FROBT},
  author       = {Vintr, Tomáš and Blaha, Jan and Rektoris, Martin and Ulrich, Jiří and Rouček, Tomáš and Broughton, George and Yan, Zhi and Krajník, Tomáš},
  doi          = {10.3389/frobt.2022.890013},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {890013},
  shortjournal = {Front. Robot. AI},
  title        = {Toward benchmarking of long-term spatio-temporal maps of pedestrian flows for human-aware navigation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local-to-global hypotheses for robust robot localization.
<em>FROBT</em>, <em>9</em>, 887261. (<a
href="https://doi.org/10.3389/frobt.2022.887261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many robust state-of-the-art localization methods rely on pose-space sample sets that are evaluated against individual sensor measurements. While these methods can work effectively, they often provide limited mechanisms to control the amount of hypotheses based on their similarity. Furthermore, they do not explicitly use associations to create or remove these hypotheses. We propose a global localization strategy that allows a mobile robot to localize using explicit symbolic associations with annotated geometric features. The feature measurements are first combined locally to form a consistent local feature map that is accurate in the vicinity of the robot. Based on this local map, an association tree is maintained that pairs local map features with global map features. The leaves of the tree represent distinct hypotheses on the data associations that allow for globally unmapped features appearing in the local map. We propose a registration step to check if an association hypothesis is supported. Our implementation considers a robot equipped with a 2D LiDAR and we compare the proposed method to a particle filter. We show that maintaining a smaller set of data association hypotheses results in better performance and explainability of the robot’s assumptions, as well as allowing more control over hypothesis bookkeeping. We provide experimental evaluations with a physical robot in a real environment using an annotated geometric building model that contains only the static part of the indoor scene. The result shows that our method outperforms a particle filter implementation in most cases by using fewer hypotheses with more descriptive power.},
  archive      = {J_FROBT},
  author       = {Hendrikx, R. W. M. and Bruyninckx, H. and Elfring, J. and Van De Molengraft, M. J. G.},
  doi          = {10.3389/frobt.2022.887261},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {887261},
  shortjournal = {Front. Robot. AI},
  title        = {Local-to-global hypotheses for robust robot localization},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control of a wheelchair-mounted 6DOF assistive robot with
chin and finger joysticks. <em>FROBT</em>, <em>9</em>, 885610. (<a
href="https://doi.org/10.3389/frobt.2022.885610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throughout the last decade, many assistive robots for people with disabilities have been developed; however, researchers have not fully utilized these robotic technologies to entirely create independent living conditions for people with disabilities, particularly in relation to activities of daily living (ADLs). An assistive system can help satisfy the demands of regular ADLs for people with disabilities. With an increasing shortage of caregivers and a growing number of individuals with impairments and the elderly, assistive robots can help meet future healthcare demands. One of the critical aspects of designing these assistive devices is to improve functional independence while providing an excellent human–machine interface. People with limited upper limb function due to stroke, spinal cord injury, cerebral palsy, amyotrophic lateral sclerosis, and other conditions find the controls of assistive devices such as power wheelchairs difficult to use. Thus, the objective of this research was to design a multimodal control method for robotic self-assistance that could assist individuals with disabilities in performing self-care tasks on a daily basis. In this research, a control framework for two interchangeable operating modes with a finger joystick and a chin joystick is developed where joysticks seamlessly control a wheelchair and a wheelchair-mounted robotic arm. Custom circuitry was developed to complete the control architecture. A user study was conducted to test the robotic system. Ten healthy individuals agreed to perform three tasks using both (chin and finger) joysticks for a total of six tasks with 10 repetitions each. The control method has been tested rigorously, maneuvering the robot at different velocities and under varying payload (1–3.5 lb) conditions. The absolute position accuracy was experimentally found to be approximately 5 mm. The round-trip delay we observed between the commands while controlling the xArm was 4 ms. Tests performed showed that the proposed control system allowed individuals to perform some ADLs such as picking up and placing items with a completion time of less than 1 min for each task and 100% success.},
  archive      = {J_FROBT},
  author       = {Rulik, Ivan and Sunny, Md Samiul Haque and Sanjuan De Caro, Javier Dario and Zarif, Md Ishrak Islam and Brahmi, Brahim and Ahamed, Sheikh Iqbal and Schultz, Katie and Wang, Inga and Leheng, Tony and Longxiang, Jason Peng and Rahman, Mohammad H.},
  doi          = {10.3389/frobt.2022.885610},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {885610},
  shortjournal = {Front. Robot. AI},
  title        = {Control of a wheelchair-mounted 6DOF assistive robot with chin and finger joysticks},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deviant behavior of pedestrians: A risk gamble or just
against automated vehicles? How about social control? <em>FROBT</em>,
<em>9</em>, 885319. (<a
href="https://doi.org/10.3389/frobt.2022.885319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent evidence suggests that the assumed conflict-avoidant programming of autonomous vehicles will incentivize pedestrians to bully them. However, this frequent argument disregards the embedded nature of social interaction. Rule violations are socially sanctioned by different forms of social control, which could moderate the rational incentive to abuse risk-avoidant vehicles. Drawing on a gamified virtual reality (VR) experiment (n = 36) of urban traffic scenarios, we tested how vehicle type, different forms of social control, and monetary benefit of rule violations affect pedestrians’ decision to jaywalk. In a second step, we also tested whether differences in those effects exist when controlling for the risk of crashes in conventional vehicles. We find that individuals do indeed jaywalk more frequently when faced with an automated vehicle (AV), and this effect largely depends on the associated risk and not their automated nature. We further show that social control, especially in the form of formal traffic rules and norm enforcement, can reduce jaywalking behavior for any vehicle. Our study sheds light on the interaction dynamics between humans and AVs and how this is influenced by different forms of social control. It also contributes to the small gamification literature in this human–computer interaction.},
  archive      = {J_FROBT},
  author       = {Şahin, Hatice and Hemesath, Sebastian and Boll, Susanne},
  doi          = {10.3389/frobt.2022.885319},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {885319},
  shortjournal = {Front. Robot. AI},
  title        = {Deviant behavior of pedestrians: A risk gamble or just against automated vehicles? how about social control?},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalizing care through robotic assistance and clinical
supervision. <em>FROBT</em>, <em>9</em>, 883814. (<a
href="https://doi.org/10.3389/frobt.2022.883814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By 2030, the World Health Organization (WHO) foresees a worldwide workforce shortfall of healthcare professionals, with dramatic consequences for patients, economies, and communities. Research in assistive robotics has experienced an increasing attention during the last decade demonstrating its utility in the realization of intelligent robotic solutions for healthcare and social assistance, also to compensate for such workforce shortages. Nevertheless, a challenge for effective assistive robots is dealing with a high variety of situations and contextualizing their interactions according to living contexts and habits (or preferences) of assisted people. This study presents a novel cognitive system for assistive robots that rely on artificial intelligence (AI) representation and reasoning features/services to support decision-making processes of healthcare assistants. We proposed an original integration of AI-based features, that is, knowledge representation and reasoning and automated planning to 1) define a human-in-the-loop continuous assistance procedure that helps clinicians in evaluating and managing patients and; 2) to dynamically adapt robot behaviors to the specific needs and interaction abilities of patients. The system is deployed in a realistic assistive scenario to demonstrate its feasibility to support a clinician taking care of several patients with different conditions and needs.},
  archive      = {J_FROBT},
  author       = {Sorrentino, Alessandra and Fiorini, Laura and Mancioppi, Gianmaria and Cavallo, Filippo and Umbrico, Alessandro and Cesta, Amedeo and Orlandini, Andrea},
  doi          = {10.3389/frobt.2022.883814},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {883814},
  shortjournal = {Front. Robot. AI},
  title        = {Personalizing care through robotic assistance and clinical supervision},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A critical analysis of industrial human-robot communication
and its quest for naturalness through the lens of complexity theory.
<em>FROBT</em>, <em>9</em>, 870477. (<a
href="https://doi.org/10.3389/frobt.2022.870477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot communication is one of the actively researched fields to enable efficient and seamless collaboration between a human and an intelligent industrial robotic system. The field finds its roots in human communication with the aim to achieve the “naturalness” inherent in the latter. Industrial human-robot communication pursues communication with simplistic commands and gestures, which is not representative of an uncontrolled real-world industrial environment. In addition, naturalness in communication is a consequence of its dynamism, typically ignored as a design criterion in industrial human-robot communication. Complexity Theory-based natural communication models allow for a more accurate representation of human communication which, when adapted, could also benefit the field of human-robot communication. This paper presents a perspective by reviewing the state of human-robot communication in industrial settings and then presents a critical analysis of the same through the lens of Complexity Theory. Furthermore, the work identifies research gaps in the aforementioned field, fulfilling which, would propel the field towards a truly natural form of communication. Finally, the work briefly discusses a general framework that leverages the experiential learning of data-based techniques and naturalness of human knowledge.},
  archive      = {J_FROBT},
  author       = {Mukherjee, Debasmita and Gupta, Kashish and Najjaran, Homayoun},
  doi          = {10.3389/frobt.2022.870477},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {870477},
  shortjournal = {Front. Robot. AI},
  title        = {A critical analysis of industrial human-robot communication and its quest for naturalness through the lens of complexity theory},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lessons for robotics from the control architecture of the
octopus. <em>FROBT</em>, <em>9</em>, 862391. (<a
href="https://doi.org/10.3389/frobt.2022.862391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological and artificial agents are faced with many of the same computational and mechanical problems, thus strategies evolved in the biological realm can serve as inspiration for robotic development. The octopus in particular represents an attractive model for biologically-inspired robotic design, as has been recognized for the emerging field of soft robotics. Conventional global planning-based approaches to controlling the large number of degrees of freedom in an octopus arm would be computationally intractable. Instead, the octopus appears to exploit a distributed control architecture that enables effective and computationally efficient arm control. Here we will describe the neuroanatomical organization of the octopus peripheral nervous system and discuss how this distributed neural network is specialized for effectively mediating decisions made by the central brain and the continuous actuation of limbs possessing an extremely large number of degrees of freedom. We propose top-down and bottom-up control strategies that we hypothesize the octopus employs in the control of its soft body. We suggest that these strategies can serve as useful elements in the design and development of soft-bodied robotics.},
  archive      = {J_FROBT},
  author       = {Sivitilli, Dominic M. and Smith, Joshua R. and Gire, David H.},
  doi          = {10.3389/frobt.2022.862391},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {862391},
  shortjournal = {Front. Robot. AI},
  title        = {Lessons for robotics from the control architecture of the octopus},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design optimization for rough terrain traversal using a
compliant, continuum-joint, quadruped robot. <em>FROBT</em>, <em>9</em>,
860020. (<a href="https://doi.org/10.3389/frobt.2022.860020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robots have the potential to cover terrain not accessible to wheel-based robots and vehicles. This makes them better suited to perform tasks such as search and rescue in real-world unstructured environments. In addition, pneumatically-actuated, compliant robots may be more suited than their rigid counterparts to real-world unstructured environments with humans where unintentional contact or impact may occur. In this work, we define design metrics for legged robots that evaluate their ability to traverse unstructured terrain, carry payloads, find stable footholds, and move in desired directions. These metrics are demonstrated and validated in a multi-objective design optimization of 10 variables for a 16 degree of freedom, pneumatically actuated, continuum joint quadruped. We also present and validate approximations to preserve numerical tractability for any similar high degree of freedom optimization problem. Finally, we show that the design trends uncovered by our optimization hold in two hardware experiments using robot legs with continuum joints that are built based on the optimization results.},
  archive      = {J_FROBT},
  author       = {Sherrod , Vallan and Johnson , Curtis C. and Killpack, Marc D.},
  doi          = {10.3389/frobt.2022.860020},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {860020},
  shortjournal = {Front. Robot. AI},
  title        = {Design optimization for rough terrain traversal using a compliant, continuum-joint, quadruped robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning state-variable relationships in POMCP: A framework
for mobile robots. <em>FROBT</em>, <em>9</em>, 819107. (<a
href="https://doi.org/10.3389/frobt.2022.819107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of learning relationships on state variables in Partially Observable Markov Decision Processes (POMDPs) to improve planning performance. Specifically, we focus on Partially Observable Monte Carlo Planning (POMCP) and represent the acquired knowledge with a Markov Random Field (MRF). We propose, in particular, a method for learning these relationships on a robot as POMCP is used to plan future actions. Then, we present an algorithm that deals with cases in which the MRF is used on episodes having unlikely states with respect to the equality relationships represented by the MRF. Our approach acquires information from the agent’s action outcomes to adapt online the MRF if a mismatch is detected between the MRF and the true state. We test this technique on two domains, rocksample, a standard rover exploration task, and a problem of velocity regulation in industrial mobile robotic platforms, showing that the MRF adaptation algorithm improves the planning performance with respect to the standard approach, which does not adapt the MRF online. Finally, a ROS-based architecture is proposed, which allows running the MRF learning, the MRF adaptation, and MRF usage in POMCP on real robotic platforms. In this case, we successfully tested the architecture on a Gazebo simulator of rocksample. A video of the experiments is available in the Supplementary Material, and the code of the ROS-based architecture is available online.},
  archive      = {J_FROBT},
  author       = {Zuccotto, Maddalena and Piccinelli, Marco and Castellini, Alberto and Marchesini, Enrico and Farinelli, Alessandro},
  doi          = {10.3389/frobt.2022.819107},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {819107},
  shortjournal = {Front. Robot. AI},
  title        = {Learning state-variable relationships in POMCP: A framework for mobile robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bridging reinforcement learning and iterative learning
control: Autonomous motion learning for unknown, nonlinear dynamics.
<em>FROBT</em>, <em>9</em>, 793512. (<a
href="https://doi.org/10.3389/frobt.2022.793512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the problem of reference tracking in autonomously learning robots with unknown, nonlinear dynamics. Existing solutions require model information or extensive parameter tuning, and have rarely been validated in real-world experiments. We propose a learning control scheme that learns to approximate the unknown dynamics by a Gaussian Process (GP), which is used to optimize and apply a feedforward control input on each trial. Unlike existing approaches, the proposed method neither requires knowledge of the system states and their dynamics nor knowledge of an effective feedback control structure. All algorithm parameters are chosen automatically, i.e. the learning method works plug and play. The proposed method is validated in extensive simulations and real-world experiments. In contrast to most existing work, we study learning dynamics for more than one motion task as well as the robustness of performance across a large range of learning parameters. The method’s plug and play applicability is demonstrated by experiments with a balancing robot, in which the proposed method rapidly learns to track the desired output. Due to its model-agnostic and plug and play properties, the proposed method is expected to have high potential for application to a large class of reference tracking problems in systems with unknown, nonlinear dynamics.},
  archive      = {J_FROBT},
  author       = {Meindl, Michael and Lehmann, Dustin and Seel, Thomas},
  doi          = {10.3389/frobt.2022.793512},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {793512},
  shortjournal = {Front. Robot. AI},
  title        = {Bridging reinforcement learning and iterative learning control: Autonomous motion learning for unknown, nonlinear dynamics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of a real-time thermoplastic mask compression
force monitoring system using capacitive force sensor. <em>FROBT</em>,
<em>9</em>, 778594. (<a
href="https://doi.org/10.3389/frobt.2022.778594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: Thermoplastic masks keep patients in an appropriate position to ensure accurate radiation delivery. For a thermoplastic mask to maintain clinical efficacy, the mask should wrap the patient&#39;s surface properly and provide uniform pressure to all areas. However, to our best knowledge, no explicit method for achieving such a goal currently exists. Therefore, in this study, we intended to develop a real-time thermoplastic mask compression force (TMCF) monitoring system to measure compression force quantitatively. A prototype system was fabricated, and the feasibility of the proposed method was evaluated.Methods: The real-time TMCF monitoring system basically consists of four force sensor units, a microcontroller board (Arduino Bluno Mega 2560), a control PC, and an in-house software program. To evaluate the reproducibility of the TMCF monitoring system, both a reproducibility test using a micrometer and a setup reproducibility test using a head phantom were performed. Additionally, the reproducibility tests of mask setup and motion detection tests were carried out with a cohort of six volunteers.Results: The system provided stable pressure readings in all 10 trials during the sensor unit reproducibility test. The largest standard deviation (SD) among trials was about 36 gf/cm2 (∼2.4% of the full-scale range). For five repeated mask setups on the phantom, the compression force variation of the mask was less than 39 gf/cm2 (2.6% of the full-scale range). We were successful in making masks together with the monitoring system connected and demonstrated feasible utilization of the system. Compression force variations were observed among the volunteers and according to the location of the sensor (among forehead, both cheekbones, and chin). The TMCF monitoring system provided the information in real time on whether the mask was properly pressing the human subject as an immobilization tool.Conclusion: With the developed system, it is possible to monitor the effectiveness of the mask in real time by continuously measuring the compression force between the mask and patient during the treatment. The graphical user interface (GUI) of the monitoring system developed provides a warning signal when the compression force of the mask is insufficient. Although the number of volunteers participated in the study was small, the obtained preliminary results suggest that the system could ostensibly improve the setup accuracy of a thermoplastic mask.},
  archive      = {J_FROBT},
  author       = {Kim, Tae-Ho and Cho, Min-Seok and Shin, Dong-Seok and Shin, Dong Ho and Kim, Siyong},
  doi          = {10.3389/frobt.2022.778594},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {778594},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a real-time thermoplastic mask compression force monitoring system using capacitive force sensor},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Should robots have standing? The moral and legal
status of social robots. <em>FROBT</em>, <em>9</em>, 946529. (<a
href="https://doi.org/10.3389/frobt.2022.946529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gunkel, David and Coeckelbergh, Mark and Gerdes, Anne},
  doi          = {10.3389/frobt.2022.946529},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {946529},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Should robots have standing? the moral and legal status of social robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Corrigendum: Task roadmaps: Speeding up task replanning.
<em>FROBT</em>, <em>9</em>, 940811. (<a
href="https://doi.org/10.3389/frobt.2022.940811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lager, Anders and Spampinato, Giacomo and Papadopoulos, Alessandro V. and Nolte, Thomas},
  doi          = {10.3389/frobt.2022.940811},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {940811},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: task roadmaps: speeding up task replanning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Humanoid robots for real-world applications.
<em>FROBT</em>, <em>9</em>, 938775. (<a
href="https://doi.org/10.3389/frobt.2022.938775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kanehiro, Fumio and Suleiman, Wael and Griffin, Robert},
  doi          = {10.3389/frobt.2022.938775},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {938775},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Humanoid robots for real-world applications},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Responsible robotics. <em>FROBT</em>, <em>9</em>,
937612. (<a href="https://doi.org/10.3389/frobt.2022.937612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Brandão, Martim and Mansouri, Masoumeh and Magnusson, Martin},
  doi          = {10.3389/frobt.2022.937612},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {937612},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Responsible robotics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corrigendum: Optical see-through head-mounted displays with
short focal distance: Conditions for mitigating parallax-related
registration error. <em>FROBT</em>, <em>9</em>, 930382. (<a
href="https://doi.org/10.3389/frobt.2022.930382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Cutolo, Fabrizio and Cattari, Nadia and Fontana, Umberto and Ferrari, Vincenzo},
  doi          = {10.3389/frobt.2022.930382},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {930382},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: optical see-through head-mounted displays with short focal distance: conditions for mitigating parallax-related registration error},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Next generation user-adaptive wearable robots.
<em>FROBT</em>, <em>9</em>, 920655. (<a
href="https://doi.org/10.3389/frobt.2022.920655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bulea, Thomas C. and Sharma, Nitin and Sikdar, Siddhartha and Su, Hao},
  doi          = {10.3389/frobt.2022.920655},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {920655},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Next generation user-adaptive wearable robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: The art of human-robot interaction: Creative
perspectives from design and the arts. <em>FROBT</em>, <em>9</em>,
910253. (<a href="https://doi.org/10.3389/frobt.2022.910253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Herath, Damith and Jochum, Elizabeth and St-Onge, David},
  doi          = {10.3389/frobt.2022.910253},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {910253},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: the art of human-robot interaction: creative perspectives from design and the arts},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A meta-agent based approach to exploit the collective
product of mobile cyber-physical collectives. <em>FROBT</em>,
<em>9</em>, 904819. (<a
href="https://doi.org/10.3389/frobt.2022.904819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A cyber-physical system (CPS) is a system with integrated computational and physical abilities. Deriving the notion of cyber-physical collective (CPC) from a social view of CPS, we consider the nodes of a CPS as individuals (agents) that interact to overcome their limits in the collective. When CPC agents are able to move in their environment, the CPC is considered as a Mobile CPC (MCPC). The interactions of the agents give rise to the appearance of a phenomenon collectively generated by the agents of the CPC that we call a collective product. This phenomenon is not recorded as “a whole” in the CPC because an agent has only a partial view of its environment. This paper presents COPE (COllective Product Exploitation), an approach that allows one MCPC to exploit the collective product of another one. The approach is based on the deployment of meta-agents in both systems. A meta-agent is an agent that is external to a MCPC but is associated with one of its agents. Each meta-agent is able to monitor the agent with which it is associated and can fake its perceptions to influence its behavior. The meta-agents deployed in the system from which the collective product emerges provide indicators related to this product. Utilizing these indicators, the meta-agents deployed in the other system can act on the agents in order to adapt the global dynamics of the whole system. The proposed coupling approach is evaluated in a “fire detection and control” use case. It allows a system of UAVs to use the collective product of a network of sensors to monitor the fire.},
  archive      = {J_FROBT},
  author       = {Khenifar, Afra and Jamont, Jean-Paul and Occello, Michel and Ben-Yelles, Choukri-Bey and Koudil, Mouloud},
  doi          = {10.3389/frobt.2022.904819},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {904819},
  shortjournal = {Front. Robot. AI},
  title        = {A meta-agent based approach to exploit the collective product of mobile cyber-physical collectives},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bidirectional locomotion of soft inchworm crawler using
dynamic gaits. <em>FROBT</em>, <em>9</em>, 899850. (<a
href="https://doi.org/10.3389/frobt.2022.899850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inchworm-styled locomotion is one of the simplest gaits for mobile robots, which enables easy actuation, effective movement, and strong adaptation in nature. However, an agile inchworm-like robot that realizes versatile locomotion usually requires effective friction force manipulation with a complicated actuation structure and control algorithm. In this study, we embody a friction force controller based on the deformation of the robot body, to realize bidirectional locomotion. Two kinds of differential friction forces are integrated into a beam-like soft robot body, and along with the cyclical actuation of the robot body, two locomotion gaits with opposite locomotion directions can be generated and controlled by the deformation process of the robot body, that is, the dynamic gaits. Based on these dynamic gaits, two kinds of locomotion control schemes, the amplitude-based control and the frequency-based control, are proposed, analyzed, and validated with both theoretical simulations and prototype experiments. The soft inchworm crawler achieves the versatile locomotion result via a simple system configuration and minimalist actuation input. This work is an example of using soft structure vibrations for challenging robotic tasks.},
  archive      = {J_FROBT},
  author       = {Du, Liang and Ma, Shugen and Tokuda, Keisuke and Tian, Yang and Li, Longchuan},
  doi          = {10.3389/frobt.2022.899850},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {899850},
  shortjournal = {Front. Robot. AI},
  title        = {Bidirectional locomotion of soft inchworm crawler using dynamic gaits},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization-based motion generation for buzzwire tasks with
the REEM-c humanoid robot. <em>FROBT</em>, <em>9</em>, 898890. (<a
href="https://doi.org/10.3389/frobt.2022.898890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Buzzwire tasks are often used as benchmarks and as training environments for fine motor skills and high precision path following. These tasks require moving a wire loop along an arbitrarily shaped wire obstacle in a collision-free manner. While there have been some demonstrations of buzzwire tasks with robotic manipulators using reinforcement learning and admittance control, there does not seem to be any examples with humanoid robots. In this work, we consider the scenario where we control one arm of the REEM-C humanoid robot, with other joints fixed, as groundwork for eventual full-body control. In pursuit of this, we contribute by designing an optimal control problem that generates trajectories to solve the buzzwire in a time optimized manner. This is composed of task-space constraints to prevent collisions with the buzzwire obstacle, the physical limits of the robot, and an objective function to trade-off reducing time and increasing margins from collision. The formulation can be applied to a very general set of wire shapes and the objective and task constraints can be adapted to other hardware configurations. We evaluate this formulation using the arm of a REEM-C humanoid robot and provide an analysis of how the generated trajectories perform both in simulation and on hardware.},
  archive      = {J_FROBT},
  author       = {Lee, Peter Q. and Rajendran, Vidyasagar and Mombaur, Katja},
  doi          = {10.3389/frobt.2022.898890},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {898890},
  shortjournal = {Front. Robot. AI},
  title        = {Optimization-based motion generation for buzzwire tasks with the REEM-C humanoid robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimization of dynamic sit-to-stand trajectories to assess
whole-body motion performance of the humanoid robot
REEM-c. <em>FROBT</em>, <em>9</em>, 898696. (<a
href="https://doi.org/10.3389/frobt.2022.898696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enable the application of humanoid robots outside of laboratory environments, the biped must meet certain requirements. These include, in particular, coping with dynamic motions such as climbing stairs or ramps or walking over irregular terrain. Sit-to-stand transitions also belong to this category. In addition to their actual application such as getting out of vehicles or standing up after sitting, for example, at a table, these motions also provide benefits in terms of performance assessment. Therefore, they have long been used as a sports medical and geriatric assessment for humans. Here, we develop optimized sit-to-stand trajectories using optimal control, which are characterized by their dynamic and humanlike nature. We implement these motions on the humanoid robot REEM-C. Based on the obtained sensor data, we present a unified benchmarking procedure based on two different experimental protocols. These protocols are characterized by their increasing level of difficulty for quantifying different aspects of lower limb performance. We report performance results obtained by REEM-C using two categories of indicators: primary, scenario-specific indicators that assess overall performance (chair height and ankle-to-chair distance) and subsidiary, general indicators that further describe performance. The latter provide a more detailed analysis of the applied motion and are based on metrics such as the angular momentum, zero moment point, capture point, or foot placement estimator. In the process, we identify performance deficiencies of the robot based on the collected data. Thus, this work is an important step toward a unified quantification of bipedal performance in the execution of humanlike and dynamically demanding motions.},
  archive      = {J_FROBT},
  author       = {Aller, Felix and Harant, Monika and Mombaur, Katja},
  doi          = {10.3389/frobt.2022.898696},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {898696},
  shortjournal = {Front. Robot. AI},
  title        = {Optimization of dynamic sit-to-stand trajectories to assess whole-body motion performance of the humanoid robot REEM-C},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalized behavior framework for mobile robots teaming
with humans in harsh environments. <em>FROBT</em>, <em>9</em>, 898366.
(<a href="https://doi.org/10.3389/frobt.2022.898366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial contexts, typically characterized by highly unstructured environments, where task sequences are difficult to hard-code and unforeseen events occur daily (e.g., oil and gas, energy generation, aeronautics) cannot completely rely upon automation to substitute the human dexterity and judgment skills. Robots operating in these conditions have the common requirement of being able to deploy appropriate behaviours in highly dynamic and unpredictable environments, while aiming to achieve a more natural human-robot interaction and a broad range of acceptability in providing useful and efficient services. The goal of this paper is to introduce a deliberative framework able to acquire, reuse and instantiate a collection of behaviours that promote an extension of the autonomy periods of mobile robotic platforms, with a focus on maintenance, repairing and overhaul applications. Behavior trees are employed to design the robotic system’s high-level deliberative intelligence, which integrates: social behaviors, aiming to capture the human’s emotional state and intention; the ability to either perform or support various process tasks; seamless planning and execution of human-robot shared work plans. In particular, the modularity, reactiveness and deliberation capacity that characterize the behaviour tree formalism are leveraged to interpret the human’s health and cognitive load for supporting her/him, and to complete a shared mission by collaboration or complete take-over. By enabling mobile robotic platforms to take-over risky jobs which the human cannot, should not or do not want to perform the proposed framework bears high potential to significantly improve the safety, productivity and efficiency in harsh working environments.},
  archive      = {J_FROBT},
  author       = {Avram, Oliver and Baraldo, Stefano and Valente, Anna},
  doi          = {10.3389/frobt.2022.898366},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {898366},
  shortjournal = {Front. Robot. AI},
  title        = {Generalized behavior framework for mobile robots teaming with humans in harsh environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GradTac: Spatio-temporal gradient based tactile sensing.
<em>FROBT</em>, <em>9</em>, 898075. (<a
href="https://doi.org/10.3389/frobt.2022.898075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactile sensing for robotics is achieved through a variety of mechanisms, including magnetic, optical-tactile, and conductive fluid. Currently, the fluid-based sensors have struck the right balance of anthropomorphic sizes and shapes and accuracy of tactile response measurement. However, this design is plagued by a low Signal to Noise Ratio (SNR) due to the fluid based sensing mechanism “damping” the measurement values that are hard to model. To this end, we present a spatio-temporal gradient representation on the data obtained from fluid-based tactile sensors, which is inspired from neuromorphic principles of event based sensing. We present a novel algorithm (GradTac) that converts discrete data points from spatial tactile sensors into spatio-temporal surfaces and tracks tactile contours across these surfaces. Processing the tactile data using the proposed spatio-temporal domain is robust, makes it less susceptible to the inherent noise from the fluid based sensors, and allows accurate tracking of regions of touch as compared to using the raw data. We successfully evaluate and demonstrate the efficacy of GradTac on many real-world experiments performed using the Shadow Dexterous Hand, equipped with the BioTac SP sensors. Specifically, we use it for tracking tactile input across the sensor’s surface, measuring relative forces, detecting linear and rotational slip, and for edge tracking. We also release an accompanying task-agnostic dataset for the BioTac SP, which we hope will provide a resource to compare and quantify various novel approaches, and motivate further research.},
  archive      = {J_FROBT},
  author       = {Ganguly, Kanishka and Mantripragada, Pavan and Parameshwara, Chethan M. and Fermüller, Cornelia and Sanket, Nitin J. and Aloimonos, Yiannis},
  doi          = {10.3389/frobt.2022.898075},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {898075},
  shortjournal = {Front. Robot. AI},
  title        = {GradTac: Spatio-temporal gradient based tactile sensing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards autonomous robotic biopsy—design, modeling and
control of a robot for needle insertion of a commercial full core biopsy
instrument. <em>FROBT</em>, <em>9</em>, 896267. (<a
href="https://doi.org/10.3389/frobt.2022.896267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design, control, and experimental evaluation of a novel fully automated robotic-assisted system for the positioning and insertion of a commercial full core biopsy instrument under guidance by ultrasound imaging. The robotic system consisted of a novel 4 Degree of freedom (DOF) add-on robot for the positioning and insertion of the biopsy instrument that is attached to a UR5-based teleoperation system with 6 DOF. The robotic system incorporates the advantages of both freehand and probe-guided biopsy techniques. The proposed robotic system can be used as a slave robot in a teleoperation configuration or as an autonomous or semi-autonomous robot in the future. While the UR5 manipulator was controlled using a teleoperation scheme with force controller, a reinforcement learning based controller using the Deep Deterministic Policy Gradient (DDPG) algorithm was developed for the add-on robotic system. The dexterous workspace analysis of the add-on robotic system demonstrated that the system has a suitable workspace within the US image. Two sets of comprehensive experiments including four experiments were performed to evaluate the robotic system’s performance in terms of the biopsy instrument positioning, and the insertion of the needle inside the ultrasound plane. The experimental results showed the ability of the robotic system for in-plane needle insertion. The overall mean error of all four experiments in the tracking of the needle angle was 0.446°, and the resolution of the needle insertion was 0.002 mm.},
  archive      = {J_FROBT},
  author       = {Sajadi, Seyed MohammadReza and Karbasi, Seyed Mojtaba and Brun, Henrik and Tørresen, Jim and Elle, Ole Jacob and Mathiassen, Kim},
  doi          = {10.3389/frobt.2022.896267},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {896267},
  shortjournal = {Front. Robot. AI},
  title        = {Towards autonomous robotic Biopsy—Design, modeling and control of a robot for needle insertion of a commercial full core biopsy instrument},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Facing the FACS—using AI to evaluate and control facial
action units in humanoid robot face development. <em>FROBT</em>,
<em>9</em>, 887645. (<a
href="https://doi.org/10.3389/frobt.2022.887645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach for evaluating and controlling expressive humanoid robotic faces using open-source computer vision and machine learning methods. Existing research in Human-Robot Interaction lacks flexible and simple tools that are scalable for evaluating and controlling various robotic faces; thus, our goal is to demonstrate the use of readily available AI-based solutions to support the process. We use a newly developed humanoid robot prototype intended for medical training applications as a case example. The approach automatically captures the robot’s facial action units through a webcam during random motion, which are components traditionally used to describe facial muscle movements in humans. Instead of manipulating the actuators individually or training the robot to express specific emotions, we propose using action units as a means for controlling the robotic face, which enables a multitude of ways to generate dynamic motion, expressions, and behavior. The range of action units achieved by the robot is thus analyzed to discover its expressive capabilities and limitations and to develop a control model by correlating action units to actuation parameters. Because the approach is not dependent on specific facial attributes or actuation capabilities, it can be used for different designs and continuously inform the development process. In healthcare training applications, our goal is to establish a prerequisite of expressive capabilities of humanoid robots bounded by industrial and medical design constraints. Furthermore, to mediate human interpretation and thus enable decision-making based on observed cognitive, emotional, and expressive cues, our approach aims to find the minimum viable expressive capabilities of the robot without having to optimize for realism. The results from our case example demonstrate the flexibility and efficiency of the presented AI-based solutions to support the development of humanoid facial robots.},
  archive      = {J_FROBT},
  author       = {Auflem, Marius and Kohtala, Sampsa and Jung, Malte and Steinert, Martin},
  doi          = {10.3389/frobt.2022.887645},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {887645},
  shortjournal = {Front. Robot. AI},
  title        = {Facing the FACS—Using AI to evaluate and control facial action units in humanoid robot face development},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Robotics, autonomous systems and AI for
nonurgent/nonemergent healthcare delivery during and after the COVID-19
pandemic. <em>FROBT</em>, <em>9</em>, 886926. (<a
href="https://doi.org/10.3389/frobt.2022.886926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Trejos, A. L. and Atashzar, S. F. and DiMaio, S. P. and Pilarski, P. M. and Tavakoli, M.},
  doi          = {10.3389/frobt.2022.886926},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {886926},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotics, autonomous systems and AI for Nonurgent/Nonemergent healthcare delivery during and after the COVID-19 pandemic},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Promoting social engagement with a multi-role dancing robot
for in-home autism care. <em>FROBT</em>, <em>9</em>, 880691. (<a
href="https://doi.org/10.3389/frobt.2022.880691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work describes the design of real-time dance-based interaction with a humanoid robot, where the robot seeks to promote physical activity in children by taking on multiple roles as a dance partner. It acts as a leader by initiating dances but can also act as a follower by mimicking a child’s dance movements. Dances in the leader role are produced by a sequence-to-sequence (S2S) Long Short-Term Memory (LSTM) network trained on children’s music videos taken from YouTube. On the other hand, a music orchestration platform is implemented to generate background music in the follower mode as the robot mimics the child’s poses. In doing so, we also incorporated the largely unexplored paradigm of learning-by-teaching by including multiple robot roles that allow the child to both learn from and teach to the robot. Our work is among the first to implement a largely autonomous, real-time full-body dance interaction with a bipedal humanoid robot that also explores the impact of the robot roles on child engagement. Importantly, we also incorporated in our design formal constructs taken from autism therapy, such as the least-to-most prompting hierarchy, reinforcements for positive behaviors, and a time delay to make behavioral observations. We implemented a multimodal child engagement model that encompasses both affective engagement (displayed through eye gaze focus and facial expressions) as well as task engagement (determined by the level of physical activity) to determine child engagement states. We then conducted a virtual exploratory user study to evaluate the impact of mixed robot roles on user engagement and found no statistically significant difference in the children’s engagement in single-role and multiple-role interactions. While the children were observed to respond positively to both robot behaviors, they preferred the music-driven leader role over the movement-driven follower role, a result that can partly be attributed to the virtual nature of the study. Our findings support the utility of such a platform in practicing physical activity but indicate that further research is necessary to fully explore the impact of each robot role.},
  archive      = {J_FROBT},
  author       = {Javed, Hifza and Park, Chung Hyuk},
  doi          = {10.3389/frobt.2022.880691},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {880691},
  shortjournal = {Front. Robot. AI},
  title        = {Promoting social engagement with a multi-role dancing robot for in-home autism care},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simulative evaluation of a joint-cartesian hybrid motion
mapping for robot hands based on spatial in-hand information.
<em>FROBT</em>, <em>9</em>, 878364. (<a
href="https://doi.org/10.3389/frobt.2022.878364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two sub-problems are typically identified for the replication of human finger motions on artificial hands: the measurement of the motions on the human side and the mapping method of human hand movements (primary hand) on the robotic hand (target hand). In this study, we focus on the second sub-problem. During human to robot hand mapping, ensuring natural motions and predictability for the operator is a difficult task, since it requires the preservation of the Cartesian position of the fingertips and the finger shapes given by the joint values. Several approaches have been presented to deal with this problem, which is still unresolved in general. In this work, we exploit the spatial information available in-hand, in particular, related to the thumb-finger relative position, for combining joint and Cartesian mappings. In this way, it is possible to perform a large range of both volar grasps (where the preservation of finger shapes is more important) and precision grips (where the preservation of fingertip positions is more important) during primary-to-target hand mappings, even if kinematic dissimilarities are present. We therefore report on two specific realizations of this approach: a distance-based hybrid mapping, in which the transition between joint and Cartesian mapping is driven by the approaching of the fingers to the current thumb fingertip position, and a workspace-based hybrid mapping, in which the joint–Cartesian transition is defined on the areas of the workspace in which thumb and fingertips can get in contact. The general mapping approach is presented, and the two realizations are tested. In order to report the results of an evaluation of the proposed mappings for multiple robotic hand kinematic structures (both industrial grippers and anthropomorphic hands, with a variable number of fingers), a simulative evaluation was performed.},
  archive      = {J_FROBT},
  author       = {Meattini, Roberto and Chiaravalli, Davide and Palli, Gianluca and Melchiorri, Claudio},
  doi          = {10.3389/frobt.2022.878364},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {878364},
  shortjournal = {Front. Robot. AI},
  title        = {Simulative evaluation of a joint-cartesian hybrid motion mapping for robot hands based on spatial in-hand information},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable fabrication and actuation of a human inspired hand
through 3D printed flexures and combinatorial actuation. <em>FROBT</em>,
<em>9</em>, 878111. (<a
href="https://doi.org/10.3389/frobt.2022.878111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fabrication and control of robot hands with biologically inspired structure remains challenging due to its cost and complexity. In this paper we explore how widely available FDM printers can be used to fabricate complex hand structures by leveraging compliant PLA flexures. In particular, we focus on the fabrication of fingers printed as a single piece with tunable compliance, a multi degree of freedom thumb joint, and sensorized compliant fingertips. To address the challenge of control and actuation, we model the behavior of the flexure joints and propose a new method for control: combinatorial actuation. This control method combines the use of a single continuous actuated tendon per finger with two shared “combinatorial” actuators which act across all fingers. We demonstrate that the fingertip workspace using this method is comparable to fully actuated fingers while using significantly less independent actuators. The proposed approach of fabrication and combinatorial actuation provides a rapid and scalable method of designing and controlling complex manipulators.},
  archive      = {J_FROBT},
  author       = {Bosio, Carlo and Junge, Kai and Hughes, Josie},
  doi          = {10.3389/frobt.2022.878111},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {878111},
  shortjournal = {Front. Robot. AI},
  title        = {Scalable fabrication and actuation of a human inspired hand through 3D printed flexures and combinatorial actuation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Assisting forearm function in children with movement
disorders via a soft wearable robot with equilibrium-point control.
<em>FROBT</em>, <em>9</em>, 877041. (<a
href="https://doi.org/10.3389/frobt.2022.877041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable robots are envisioned to amplify the independence of people with movement impairments by providing daily physical assistance. For portable, comfortable, and safe devices, soft pneumatic-based robots are emerging as a potential solution. However, due to the inherent complexities, including compliance and nonlinear mechanical behavior, feedback control for facilitating human–robot interaction remains a challenge. Herein, we present the design, fabrication, and control architecture of a soft wearable robot that assists in supination and pronation of the forearm. The soft wearable robot integrates an antagonistic pair of pneumatic-based helical actuators to provide active pronation and supination torques. Our main contribution is a bio-inspired equilibrium-point control scheme for integrating proprioceptive feedback and exteroceptive input (e.g., the user’s muscle activation signals) directly with the on/off valve behavior of the soft pneumatic actuators. The proposed human–robot controller is directly inspired by the equilibrium-point hypothesis of motor control, which suggests that voluntary movements arise through shifts in the equilibrium state of the antagonistic muscle pair spanning a joint. We hypothesized that the proposed method would reduce the required effort during dynamic manipulation without affecting the error. In order to evaluate our proposed method, we recruited seven pediatric participants with movement disorders to perform two dynamic interaction tasks with a haptic manipulandum. Each task required the participant to track a sinusoidal trajectory while the haptic manipulandum behaved as a Spring-Dominate system or Inertia-Dominate system. Our results reveal that the soft wearable robot, when active, reduced user effort on average by 14%. This work demonstrates the practical implementation of an equilibrium-point volitional controller for wearable robots and provides a foundational path toward versatile, low-cost, and soft wearable robots.},
  archive      = {J_FROBT},
  author       = {Realmuto, Jonathan and Sanger, Terence D.},
  doi          = {10.3389/frobt.2022.877041},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {877041},
  shortjournal = {Front. Robot. AI},
  title        = {Assisting forearm function in children with movement disorders via a soft wearable robot with equilibrium-point control},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the modeling and verification of collective and
cooperative systems. <em>FROBT</em>, <em>9</em>, 866649. (<a
href="https://doi.org/10.3389/frobt.2022.866649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The formal description and verification of networks of cooperative and interacting agents is made difficult by the interplay of several different behavioral patterns, models of communication, scalability issues. In this paper, we will explore the functionalities and the expressiveness of a general-purpose process algebraic framework for the specification and model checking based analysis of collective and cooperative systems. The proposed syntactic and semantic schemes are general enough to be adapted with small modifications to heterogeneous application domains, like, e.g., crowdsourcing systems, trustworthy networks, and distributed ledger technologies.},
  archive      = {J_FROBT},
  author       = {Aldini, Alessandro},
  doi          = {10.3389/frobt.2022.866649},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {866649},
  shortjournal = {Front. Robot. AI},
  title        = {On the modeling and verification of collective and cooperative systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond bio-inspired robotics: How multi-robot systems can
support research on collective animal behavior. <em>FROBT</em>,
<em>9</em>, 865414. (<a
href="https://doi.org/10.3389/frobt.2022.865414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study of collective animal behavior, researchers usually rely on gathering empirical data from animals in the wild. While the data gathered can be highly accurate, researchers have limited control over both the test environment and the agents under study. Further aggravating the data gathering problem is the fact that empirical studies of animal groups typically involve a large number of conspecifics. In these groups, collective dynamics may occur over long periods of time interspersed with excessively rapid events such as collective evasive maneuvers following a predator’s attack. All these factors stress the steep challenges faced by biologists seeking to uncover the fundamental mechanisms and functions of social organization in a given taxon. Here, we argue that beyond commonly used simulations, experiments with multi-robot systems offer a powerful toolkit to deepen our understanding of various forms of swarming and other social animal organizations. Indeed, the advances in multi-robot systems and swarm robotics over the past decade pave the way for the development of a new hybrid form of scientific investigation of social organization in biology. We believe that by fostering such interdisciplinary research, a feedback loop can be created where agent behaviors designed and tested in robotico can assist in identifying hypotheses worth being validated through the observation of animal collectives in nature. In turn, these observations can be used as a novel source of inspiration for even more innovative behaviors in engineered systems, thereby perpetuating the feedback loop.},
  archive      = {J_FROBT},
  author       = {Horsevad, Nikolaj and Kwa, Hian Lee and Bouffanais, Roland},
  doi          = {10.3389/frobt.2022.865414},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {865414},
  shortjournal = {Front. Robot. AI},
  title        = {Beyond bio-inspired robotics: How multi-robot systems can support research on collective animal behavior},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DIMASS: A delaunay-inspired, hybrid approach to a team of
agents search strategy. <em>FROBT</em>, <em>9</em>, 851846. (<a
href="https://doi.org/10.3389/frobt.2022.851846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes an approach for multiagent search planning for a team of agents. A team of UAVs tasked to conduct a forest fire search was selected as the use case, although solutions are applicable to other domains. Fixed-path (e.g., parallel track) methods for multiagent search can produce predictable and structured paths, with the main limitation being poor management of agents’ resources and limited adaptability (i.e., based on predefined geometric paths, e.g., parallel track, expanding square, etc.). On the other hand, pseudorandom methods allow agents to generate well-separated paths; but methods can be computationally expensive and can result in a lack of coordination of agents’ activities. We present a hybrid solution that exploits the complementary strengths of fixed-pattern and pseudorandom methods, i.e., an approach that is resource-efficient, predictable, adaptable, and scalable. Our approach evolved from the Delaunay triangulation of systematically selected waypoints to allocate agents to explore a specific region while optimizing a given set of mission constraints. We implement our approach in a simulation environment, comparing the performance of the proposed algorithm with fixed-path and pseudorandom baselines. Results proved agents’ resource utilization, predictability, scalability, and adaptability of the developed path. We also demonstrate the proposed algorithm’s application on real UAVs.},
  archive      = {J_FROBT},
  author       = {Yusuf, Sagir M. and Baber, Chris},
  doi          = {10.3389/frobt.2022.851846},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {851846},
  shortjournal = {Front. Robot. AI},
  title        = {DIMASS: A delaunay-inspired, hybrid approach to a team of agents search strategy},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-session visual SLAM for illumination-invariant
re-localization in indoor environments. <em>FROBT</em>, <em>9</em>,
801886. (<a href="https://doi.org/10.3389/frobt.2022.801886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For robots navigating using only a camera, illumination changes in indoor environments can cause re-localization failures during autonomous navigation. In this paper, we present a multi-session visual SLAM approach to create a map made of multiple variations of the same locations in different illumination conditions. The multi-session map can then be used at any hour of the day for improved re-localization capability. The approach presented is independent of the visual features used, and this is demonstrated by comparing re-localization performance between multi-session maps created using the RTAB-Map library with SURF, SIFT, BRIEF, BRISK, KAZE, DAISY, and SuperPoint visual features. The approach is tested on six mapping and six localization sessions recorded at 30 min intervals during sunset using a Google Tango phone in a real apartment.},
  archive      = {J_FROBT},
  author       = {Labbé, Mathieu and Michaud, François},
  doi          = {10.3389/frobt.2022.801886},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {801886},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-session visual SLAM for illumination-invariant re-localization in indoor environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network layer analysis for a RL-based robotic reaching task.
<em>FROBT</em>, <em>9</em>, 799644. (<a
href="https://doi.org/10.3389/frobt.2022.799644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent experiments indicate that pretraining of end-to-end reinforcement learning neural networks on general tasks can speed up the training process for specific robotic applications. However, it remains open if these networks form general feature extractors and a hierarchical organization that can be reused as in, for example, convolutional neural networks. In this study, we analyze the intrinsic neuron activation in networks trained for target reaching of robot manipulators with increasing joint number and analyze the individual neuron activation distribution within the network. We introduce a pruning algorithm to increase network information density and depict correlations of neuron activation patterns. Finally, we search for projections of neuron activation among networks trained for robot kinematics of different complexity. As a result, we show that the input and output network layers entail more distinct neuron activation in contrast to inner layers. Our pruning algorithm reduces the network size significantly and increases the distance of neuron activation while keeping a high performance in training and evaluation. Our results demonstrate that robots with small difference in joint number show higher layer-wise projection accuracy, whereas more distinct robot kinematics reveal dominant projections to the first layer.},
  archive      = {J_FROBT},
  author       = {Feldotto, Benedikt and Lengenfelder, Heiko and Röhrbein, Florian and Knoll, Alois C.},
  doi          = {10.3389/frobt.2022.799644},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {799644},
  shortjournal = {Front. Robot. AI},
  title        = {Network layer analysis for a RL-based robotic reaching task},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Koopman operator–based knowledge-guided reinforcement
learning for safe human–robot interaction. <em>FROBT</em>, <em>9</em>,
779194. (<a href="https://doi.org/10.3389/frobt.2022.779194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We developed a novel framework for deep reinforcement learning (DRL) algorithms in task constrained path generation problems of robotic manipulators leveraging human demonstrated trajectories. The main contribution of this article is to design a reward function that can be used with generic reinforcement learning algorithms by utilizing the Koopman operator theory to build a human intent model from the human demonstrated trajectories. In order to ensure that the developed reward function produces the correct reward, the demonstrated trajectories are further used to create a trust domain within which the Koopman operator–based human intent prediction is considered. Otherwise, the proposed algorithm asks for human feedback to receive rewards. The designed reward function is incorporated inside the deep Q-learning (DQN) framework, which results in a modified DQN algorithm. The effectiveness of the proposed learning algorithm is demonstrated using a simulated robotic arm to learn the paths for constrained end-effector motion and considering the safety of the human in the surroundings of the robot.},
  archive      = {J_FROBT},
  author       = {Sinha, Anirban and Wang, Yue},
  doi          = {10.3389/frobt.2022.779194},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {779194},
  shortjournal = {Front. Robot. AI},
  title        = {Koopman Operator–Based knowledge-guided reinforcement learning for safe Human–Robot interaction},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Perception is only real when shared: A mathematical model
for collaborative shared perception in human-robot interaction.
<em>FROBT</em>, <em>9</em>, 733954. (<a
href="https://doi.org/10.3389/frobt.2022.733954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partners have to build a shared understanding of their environment in everyday collaborative tasks by aligning their perceptions and establishing a common ground. This is one of the aims of shared perception: revealing characteristics of the individual perception to others with whom we share the same environment. In this regard, social cognitive processes, such as joint attention and perspective-taking, form a shared perception. From a Human-Robot Interaction (HRI) perspective, robots would benefit from the ability to establish shared perception with humans and a common understanding of the environment with their partners. In this work, we wanted to assess whether a robot, considering the differences in perception between itself and its partner, could be more effective in its helping role and to what extent this improves task completion and the interaction experience. For this purpose, we designed a mathematical model for a collaborative shared perception that aims to maximise the collaborators’ knowledge of the environment when there are asymmetries in perception. Moreover, we instantiated and tested our model via a real HRI scenario. The experiment consisted of a cooperative game in which participants had to build towers of Lego bricks, while the robot took the role of a suggester. In particular, we conducted experiments using two different robot behaviours. In one condition, based on shared perception, the robot gave suggestions by considering the partners’ point of view and using its inference about their common ground to select the most informative hint. In the other condition, the robot just indicated the brick that would have yielded a higher score from its individual perspective. The adoption of shared perception in the selection of suggestions led to better performances in all the instances of the game where the visual information was not a priori common to both agents. However, the subjective evaluation of the robot’s behaviour did not change between conditions.},
  archive      = {J_FROBT},
  author       = {Matarese, Marco and Rea, Francesco and Sciutti, Alessandra},
  doi          = {10.3389/frobt.2022.733954},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {733954},
  shortjournal = {Front. Robot. AI},
  title        = {Perception is only real when shared: A mathematical model for collaborative shared perception in human-robot interaction},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving inclusivity in robotics design: An exploration of
methods for upstream co-creation. <em>FROBT</em>, <em>9</em>, 731006.
(<a href="https://doi.org/10.3389/frobt.2022.731006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disabled people are often involved in robotics research as potential users of technologies which address specific needs. However, their more generalised lived expertise is not usually included when planning the overall design trajectory of robots for health and social care purposes. This risks losing valuable insight into the lived experience of disabled people, and impinges on their right to be involved in the shaping of their future care. This project draws upon the expertise of an interdisciplinary team to explore methodologies for involving people with disabilities in the early design of care robots in a way that enables incorporation of their broader values, experiences and expectations. We developed a comparative set of focus group workshops using Community Philosophy, LEGO® Serious Play® and Design Thinking to explore how people with a range of different physical impairments used these techniques to envision a “useful robot”. The outputs were then workshopped with a group of roboticists and designers to explore how they interacted with the thematic map produced. Through this process, we aimed to understand how people living with disability think robots might improve their lives and consider new ways of bringing the fullness of lived experience into earlier stages of robot design. Secondary aims were to assess whether and how co-creative methodologies might produce actionable information for designers (or why not), and to deepen the exchange of social scientific and technical knowledge about feasible trajectories for robotics in health-social care. Our analysis indicated that using these methods in a sequential process of workshops with disabled people and incorporating engineers and other stakeholders at the Design Thinking stage could potentially produce technologically actionable results to inform follow-on proposals.},
  archive      = {J_FROBT},
  author       = {de Saille, Stevienna and Kipnis, Eva and Potter, Stephen and Cameron, David and Webb, Calum J. R. and Winter, Peter and O’Neill, Peter and Gold, Richard and Halliwell, Kate and Alboul, Lyuba and Bell, Andy J. and Stratton, Andrew and McNamara, Jon},
  doi          = {10.3389/frobt.2022.731006},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {731006},
  shortjournal = {Front. Robot. AI},
  title        = {Improving inclusivity in robotics design: An exploration of methods for upstream co-creation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Connecting the dots of social robot design from interviews
with robot creators. <em>FROBT</em>, <em>9</em>, 720799. (<a
href="https://doi.org/10.3389/frobt.2022.720799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite promises about the near-term potential of social robots to share our daily lives, they remain unable to form autonomous, lasting, and engaging relationships with humans. Many companies are deploying social robots into the consumer and commercial market; however, both the companies and their products are relatively short lived for many reasons. For example, current social robots succeed in interacting with humans only within controlled environments, such as research labs, and for short time periods since longer interactions tend to provoke user disengagement. We interviewed 13 roboticists from robot manufacturing companies and research labs to delve deeper into the design process for social robots and unearth the many challenges robot creators face. Our research questions were: 1) What are the different design processes for creating social robots? 2) How are users involved in the design of social robots? 3) How are teams of robot creators constituted? Our qualitative investigation showed that varied design practices are applied when creating social robots but no consensus exists about an optimal or standard one. Results revealed that users have different degrees of involvement in the robot creation process, from no involvement to being a central part of robot development. Results also uncovered the need for multidisciplinary and international teams to work together to create robots. Drawing upon these insights, we identified implications for the field of Human-Robot Interaction that can shape the creation of best practices for social robot design.},
  archive      = {J_FROBT},
  author       = {Alves-Oliveira, Patrícia and Orr, Alaina and Björling, Elin A. and Cakmak, Maya},
  doi          = {10.3389/frobt.2022.720799},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {720799},
  shortjournal = {Front. Robot. AI},
  title        = {Connecting the dots of social robot design from interviews with robot creators},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Getting neuroprosthetics out of the lab:
Improving the human-machine interactions to restore sensory-motor
functions. <em>FROBT</em>, <em>9</em>, 928383. (<a
href="https://doi.org/10.3389/frobt.2022.928383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dingle, Aaron M. and Moxon, Karen and Shokur, Solaiman and Strauss, Ivo},
  doi          = {10.3389/frobt.2022.928383},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {928383},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: getting neuroprosthetics out of the lab: improving the human-machine interactions to restore sensory-motor functions},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Navigation and perception for autonomous surface
vessels. <em>FROBT</em>, <em>9</em>, 918464. (<a
href="https://doi.org/10.3389/frobt.2022.918464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ferreira, Fausto and Quattrini Li, Alberto and Rødseth, Ørnulf J.},
  doi          = {10.3389/frobt.2022.918464},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {918464},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Navigation and perception for autonomous surface vessels},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). In-situ sensing and dynamics predictions for
electrothermally-actuated soft robot limbs. <em>FROBT</em>, <em>9</em>,
888261. (<a href="https://doi.org/10.3389/frobt.2022.888261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Untethered soft robots that locomote using electrothermally-responsive materials like shape memory alloy (SMA) face challenging design constraints for sensing actuator states. At the same time, modeling of actuator behaviors faces steep challenges, even with available sensor data, due to complex electrical-thermal-mechanical interactions and hysteresis. This article proposes a framework for in-situ sensing and dynamics modeling of actuator states, particularly temperature of SMA wires, which is used to predict robot motions. A planar soft limb is developed, actuated by a pair of SMA coils, that includes compact and robust sensors for temperature and angular deflection. Data from these sensors are used to train a neural network-based on the long short-term memory (LSTM) architecture to model both unidirectional (single SMA) and bidirectional (both SMAs) motion. Predictions from the model demonstrate that data from the temperature sensor, combined with control inputs, allow for dynamics predictions over extraordinarily long open-loop timescales (10 min) with little drift. Prediction errors are on the order of the soft deflection sensor’s accuracy. This architecture allows for compact designs of electrothermally-actuated soft robots that include sensing sufficient for motion predictions, helping to bring these robots into practical application.},
  archive      = {J_FROBT},
  author       = {Sabelhaus, Andrew P. and Mehta, Rohan K. and Wertz, Anthony T. and Majidi, Carmel},
  doi          = {10.3389/frobt.2022.888261},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {888261},
  shortjournal = {Front. Robot. AI},
  title        = {In-situ sensing and dynamics predictions for electrothermally-actuated soft robot limbs},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing the explanatory power of bionic systems with the
minimal cognitive grid. <em>FROBT</em>, <em>9</em>, 888199. (<a
href="https://doi.org/10.3389/frobt.2022.888199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, I argue that the artificial components of hybrid bionic systems do not play a direct explanatory role, i.e., in simulative terms, in the overall context of the systems in which they are embedded in. More precisely, I claim that the internal procedures determining the output of such artificial devices, replacing biological tissues and connected to other biological tissues, cannot be used to directly explain the corresponding mechanisms of the biological component(s) they substitute (and therefore cannot be used to explain the local mechanisms determining an overall biological or cognitive function replicated by such bionic models). I ground this analysis on the use of the Minimal Cognitive Grid (MCG), a novel framework proposed in Lieto (Cognitive design for artificial minds, 2021) to rank the epistemological and explanatory status of biologically and cognitively inspred artificial systems. Despite the lack of such a direct mechanistic explanation from the artificial component, however, I also argue that the hybrid bionic systems can have an indirect explanatory role similar to the one played by some AI systems built by using an overall structural design approach (but including the partial adoption of functional components). In particular, the artificial replacement of part(s) of a biological system can provide i) a local functional account of that part(s) in the context of the overall functioning of the hybrid biological–artificial system and ii) global insights about the structural mechanisms of the biological elements connected to such artificial devices.},
  archive      = {J_FROBT},
  author       = {Lieto, Antonio},
  doi          = {10.3389/frobt.2022.888199},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {888199},
  shortjournal = {Front. Robot. AI},
  title        = {Analyzing the explanatory power of bionic systems with the minimal cognitive grid},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Potentials of low-budget microdrones: Processing 3D point
clouds and images for representing post-industrial landmarks in
immersive virtual environments. <em>FROBT</em>, <em>9</em>, 886240. (<a
href="https://doi.org/10.3389/frobt.2022.886240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-industrial areas in Europe, such as the Rhine-Ruhr Metropolitan region in Germany, include cultural heritage sites fostering local and regional identities with the industrial past. Today, these landmarks are popular places of interest for visitors. In addition to portable camera devices, low-budget ultra-lightweight unmanned aerial vehicles, such as micro quadcopter drones, are on their way to being established as mass photography equipment. This low-cost hardware is not only useful for recreational usage but also supports individualized remote sensing with optical images and facilitates the acquisition of 3D point clouds of the targeted object(s). Both data sets are valuable and accurate geospatial data resources for further processing of textured 3D models. To experience these 3D models in a timely way, these 3D visualizations can directly be imported into game engines. They can be extended with modern interaction techniques and additional (semantic) information. The visualization of the data can be explored in immersive virtual environments, which allows, for instance, urban planners to use low-cost microdrones to 3D map the human impact on the environment and preserve this status in a 3D model that can be analyzed and explored in following steps. A case example of the old wage hall of the Zeche “Bonifacius” (Essen, Germany) with its simple building structure showed that it is possible to generate a detailed and accurate 3D model based on the microdrone data. The point cloud which the 3D model of the old wage hall was based on represented partly better data accuracy than the point clouds derived from airborne laser scanning and offered by public agencies as open data. On average, the distance between the point clouds was 0.7 m, while the average distance between the airborne laser scanning point cloud and the 3D model was −0.02 m. Matching high-quality textures of the building facades brings in a new aspect of 3D data quality which can be adopted when creating immersive virtual environments using the Unity engine. The example of the wage hall makes it clear that the use of low-cost drones and the subsequent data processing can result in valuable sources of point clouds and textured 3D models.},
  archive      = {J_FROBT},
  author       = {Weißmann, Marco and Edler, Dennis and Rienow, Andreas},
  doi          = {10.3389/frobt.2022.886240},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {886240},
  shortjournal = {Front. Robot. AI},
  title        = {Potentials of low-budget microdrones: Processing 3D point clouds and images for representing post-industrial landmarks in immersive virtual environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mastication-enhanced taste-based classification of
multi-ingredient dishes for robotic cooking. <em>FROBT</em>, <em>9</em>,
886074. (<a href="https://doi.org/10.3389/frobt.2022.886074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chefs frequently rely on their taste to assess the content and flavor of dishes during cooking. While tasting the food, the mastication process also provides continuous feedback by exposing the taste receptors to food at various stages of chewing. Since different ingredients of the dish undergo specific changes during chewing, the mastication helps to understand the food content. The current methods of electronic tasting, on the contrary, always use a single taste snapshot of a homogenized sample. We propose a robotic setup that uses the mixing to imitate mastication and tastes the dish at two different mastication phases. Each tasting is done using a conductance probe measuring conductance at multiple, spatially distributed points. This data is used to classify 9 varieties of scrambled eggs with tomatoes. We test four different tasting methods and analyze the resulting classification performance, showing a significant improvement over tasting homogenized samples. The experimental results show that tasting at two states of mechanical processing of the food increased classification F1 score to 0.93 in comparison to the traditional tasting of a homogenized sample resulting in F1 score of 0.55. We attribute this performance increase to the fact that different dishes are affected differently by the mixing process, and have different spatial distributions of the salinity. It helps the robot to distinguish between dishes of the same average salinity, but different content of ingredients. This work demonstrates that mastication plays an important role in robotic tasting and implementing it can improve the tasting ability of robotic chefs.},
  archive      = {J_FROBT},
  author       = {Sochacki, Grzegorz and Abdulali, Arsen and Iida, Fumiya},
  doi          = {10.3389/frobt.2022.886074},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {886074},
  shortjournal = {Front. Robot. AI},
  title        = {Mastication-enhanced taste-based classification of multi-ingredient dishes for robotic cooking},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated 2D, 2.5D, and 3D segmentation of coral reef
pointclouds and orthoprojections. <em>FROBT</em>, <em>9</em>, 884317.
(<a href="https://doi.org/10.3389/frobt.2022.884317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enabled by advancing technology, coral reef researchers increasingly prefer use of image-based surveys over approaches depending solely upon in situ observations, interpretations, and recordings of divers. The images collected, and derivative products such as orthographic projections and 3D models, allow researchers to study a comprehensive digital twin of their field sites. Spatio-temporally located twins can be compared and annotated, enabling researchers to virtually return to sites long after they have left them. While these new data expand the variety and specificity of biological investigation that can be pursued, they have introduced the much-discussed Big Data Problem: research labs lack the human and computational resources required to process and analyze imagery at the rate it can be collected. The rapid development of unmanned underwater vehicles suggests researchers will soon have access to an even greater volume of imagery and other sensor measurements than can be collected by diver-piloted platforms, further exacerbating data handling limitations. Thoroughly segmenting (tracing the extent of and taxonomically identifying) organisms enables researchers to extract the information image products contain, but is very time-consuming. Analytic techniques driven by neural networks offer the possibility that the segmentation process can be greatly accelerated through automation. In this study, we examine the efficacy of automated segmentation on three different image-derived data products: 3D models, and 2D and 2.5D orthographic projections thereof; we also contrast their relative accessibility and utility to different avenues of biological inquiry. The variety of network architectures and parameters tested performed similarly, ∼80% IoU for the genus Porites, suggesting that the primary limitations to an automated workflow are 1) the current capabilities of neural network technology, and 2) consistency and quality control in image product collection and human training/testing dataset generation.},
  archive      = {J_FROBT},
  author       = {Runyan, Hugh and Petrovic, Vid and Edwards, Clinton B. and Pedersen, Nicole and Alcantar, Esmeralda and Kuester, Falko and Sandin, Stuart A.},
  doi          = {10.3389/frobt.2022.884317},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {884317},
  shortjournal = {Front. Robot. AI},
  title        = {Automated 2D, 2.5D, and 3D segmentation of coral reef pointclouds and orthoprojections},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic calibration of the adaptive 3D scanner-based robot
welding system. <em>FROBT</em>, <em>9</em>, 876717. (<a
href="https://doi.org/10.3389/frobt.2022.876717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An advanced automatic calibration procedure and its versatile usage in the context of the adaptive robot welding technology are presented. The 3D scanner-based robot welding system calibration is composed of the measurement of the reference plate and numerical optimization of the hand-eye and intrinsic parameters by minimizing the deviation between the measured and reference plate. The measurements of the reference plate are acquired from various robot poses (typically 15). The shape features of the reference plate are then detected, and finally, the calculation of hand-eye and intrinsic parameters is performed using Powell’s optimization algorithm, where the merit function presents an average deviation between the measured and reference geometry. Validation experiments show appropriate system accuracy which is better than 0.06 mm perpendicular to the scanning direction. This calibration procedure’s important features are complete automation and fast execution times (approximately 90 s). This enables its implementation into a regular daily robot self-maintenance and monitoring plan. The universal use of such a robot welding system is demonstrated in multi-layer heavy-duty welding of thick pipes on cast machined hollow parts and in precise laser welding of thin sheet metal parts.},
  archive      = {J_FROBT},
  author       = {Arko, Peter and Jezeršek, Matija},
  doi          = {10.3389/frobt.2022.876717},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {876717},
  shortjournal = {Front. Robot. AI},
  title        = {Automatic calibration of the adaptive 3D scanner-based robot welding system},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling and simulation of robotic grasping in simulink
through simscape multibody. <em>FROBT</em>, <em>9</em>, 873558. (<a
href="https://doi.org/10.3389/frobt.2022.873558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping and dexterous manipulation remain fundamental challenges in robotics, above all when performed with multifingered robotic hands. Having simulation tools to design and test grasp and manipulation control strategies is paramount to get functional robotic manipulation systems. In this paper, we present a framework for modeling and simulating grasps in the Simulink environment, by connecting SynGrasp, a well established MATLAB toolbox for grasp simulation and analysis, and Simscape Multibody, a Simulink Library allowing the simulation of physical systems. The proposed approach can be used to simulate the grasp dynamics in Simscape, and then analyse the obtained grasps in SynGrasp. The devised functions and blocks can be easily customized to simulate different hands and objects.},
  archive      = {J_FROBT},
  author       = {Pozzi, Maria and Achilli, Gabriele Maria and Valigi, Maria Cristina and Malvezzi, Monica},
  doi          = {10.3389/frobt.2022.873558},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {873558},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling and simulation of robotic grasping in simulink through simscape multibody},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Curvilinear kirigami skins let soft bending actuators
slither faster. <em>FROBT</em>, <em>9</em>, 872007. (<a
href="https://doi.org/10.3389/frobt.2022.872007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The locomotion of soft snake robots is dependent on frictional interactions with the environment. Frictional anisotropy is a morphological characteristic of snakeskin that allows snakes to engage selectively with surfaces and generate propulsive forces. The prototypical slithering gait of most snakes is lateral undulation, which requires a significant lateral resistance that is lacking in artificial skins of existing soft snake robots. We designed a set of kirigami lattices with curvilinearly-arranged cuts to take advantage of in-plane rotations of the 3D structures when wrapped around a soft bending actuator. By changing the initial orientation of the scales, the kirigami skin produces high lateral friction upon engagement with surface asperities, with lateral to cranial anisotropic friction ratios above 4. The proposed design increased the overall velocity of the soft snake robot more than fivefold compared to robots without skin.},
  archive      = {J_FROBT},
  author       = {Branyan, Callie and Rafsanjani, Ahmad and Bertoldi, Katia and Hatton, Ross L. and Mengüç, Yiğit},
  doi          = {10.3389/frobt.2022.872007},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {872007},
  shortjournal = {Front. Robot. AI},
  title        = {Curvilinear kirigami skins let soft bending actuators slither faster},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design of a super twisting sliding mode controller for an MR
damper-based semi-active prosthetic knee. <em>FROBT</em>, <em>9</em>,
870018. (<a href="https://doi.org/10.3389/frobt.2022.870018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of transfemoral amputees living in low-income countries could not access a much-needed prosthesis. Hence, affordable semi-active prosthetic knees have been designed in recent years. As the swing phase of the gait cycle is unstable as compared to the stance phase, these designs could not perfectly mimic this phase of a healthy human being. In contribution toward such a gap, this study proposes the modeling and design of a robust controller for magnetorheological (MR) damper-based semi-active prosthetic knee. A dynamic model representation for the swing phase of the single-axis knee is derived first. Subsequently, an MR damper valve model is developed. Then, a higher-order sliding mode controller is designed and evaluated for its stability and performance. The numerical simulation results show that the super twisting sliding mode controller improves the semi-active prosthetic knee’s tracking efficiency. The design exhibited the finest performance, providing a low normalized mean square error as compared to previous designs. The variable speed performance and robustness evaluation for this controller also showed its ability to continue providing excellent performance in the presence of disturbances.},
  archive      = {J_FROBT},
  author       = {Assfaw, Dawit and Seid, Solomon},
  doi          = {10.3389/frobt.2022.870018},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {870018},
  shortjournal = {Front. Robot. AI},
  title        = {Design of a super twisting sliding mode controller for an MR damper-based semi-active prosthetic knee},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A scientometric review of soft robotics: Intellectual
structures and emerging trends analysis (2010–2021). <em>FROBT</em>,
<em>9</em>, 868682. (<a
href="https://doi.org/10.3389/frobt.2022.868682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the last decade, soft robotics has attracted an increasing attention from both academia and industry. Although multiple literature reviews of the whole soft robotics field have been conducted, there still appears to be a lack of systematic investigation of the intellectual structure and evolution of this field considering the increasing amount of publications. This paper conducts a scientometric review of the progressively synthesized network derived from 10,504 bibliographic records using a topic search on soft robotics from 2010 to 2021 based on the Web of Science (WoS) core database. The results are presented from both the general data analysis of included papers (e.g., relevant journals, citation, h-index, year, institution, country, disciplines) and the specific data analysis corresponding to main disciplines and topics, and more importantly, emerging trends. CiteSpace, a data visualization software, which can construct the co-citation network maps and provide citation bursts, is used to explore the intellectual structures and emerging trends of the soft robotics field. In addition, this paper offers a demonstration of an effective analytical method for evaluating enormous publication citation and co-citation data. Findings of this review can be used as a reference for future research in soft robotics and relevant topics.},
  archive      = {J_FROBT},
  author       = {Zhou, Yitong and Li, Haonan},
  doi          = {10.3389/frobt.2022.868682},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {868682},
  shortjournal = {Front. Robot. AI},
  title        = {A scientometric review of soft robotics: Intellectual structures and emerging trends analysis (2010–2021)},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GNSS NLOS signal classification based on machine learning
and pseudorange residual check. <em>FROBT</em>, <em>9</em>, 868608. (<a
href="https://doi.org/10.3389/frobt.2022.868608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global navigation satellite system (GNSS) positioning has recently garnered attention for autonomous driving, machine control, and construction sites. With the development of low-cost multi-GNSS receivers and the advent of new types of GNSS, such as Japan’s Quasi-Zenith Satellite System, the potential of GNSS positioning has increased. New types of GNSS directly increase the number of line-of-sight (LOS) signals in dense urban areas and improve positioning accuracy. However, GNSS receivers can observe both LOS and non-line-of-sight (NLOS) signals in dense urban areas, and more NLOS signals are observed under static conditions than under dynamic conditions. The classification of LOS and NLOS signals is important, and various methods have been proposed, such as C/N0, using three-dimensional maps, fish-eye view, and GNSS/inertial navigation system integration. Multipath detection based on machine learning has also been reported in recent years. In this study, we propose a method for detecting NLOS signals using a support vector machine (SVM) classifier modeled with unique features that are calculated by receiver independent exchange format-based information and GNSS pseudorange residual check. We found that using both the SVM classifier and GNSS pseudorange residual check effectively reduced the error due to NLOS signals. Several static tests were conducted near high-rise buildings that are likely to receive some NLOS signals in downtown Tokyo. For all static tests, the percentage of positioning errors within 10 m in the horizontal positioning error was improved by &amp;gt;80% by detecting and eliminating satellites receiving NLOS signals.},
  archive      = {J_FROBT},
  author       = {Ozeki, Tomohiro and Kubo, Nobuaki},
  doi          = {10.3389/frobt.2022.868608},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {868608},
  shortjournal = {Front. Robot. AI},
  title        = {GNSS NLOS signal classification based on machine learning and pseudorange residual check},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anti-disturbance sliding mode control of a novel variable
stiffness actuator for the rehabilitation of neurologically disabled
patients. <em>FROBT</em>, <em>9</em>, 864684. (<a
href="https://doi.org/10.3389/frobt.2022.864684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower limb exoskeletons are widely used for rehabilitation training of patients suffering from neurological disorders. To improve the human–robot interaction performance, series elastic actuators (SEAs) with low output impedance have been developed. However, the adaptability and control performance are limited by the constant spring stiffness used in current SEAs. In this study, a novel load-adaptive variable stiffness actuator (LaVSA) is used to design an ankle exoskeleton. To overcome the problems of the LaVSA with a larger mechanical gap and more complex dynamic model, a sliding mode controller based on a disturbance observer is proposed. During the interaction process, due to the passive joints at the load side of the ankle exoskeleton, the dynamic parameters on the load side of the ankle exoskeleton will change continuously. To avoid this problem, the designed controller treats it and the model error as a disturbance and observes it with the disturbance observer (DOB) in real time. The first-order derivative of the disturbance set is treated as a bounded value. Subsequently, the parameter adaptive law is used to find the upper bound of the observation error and make corresponding compensation in the control law. On these bases, a sliding mode controller based on a disturbance observer is designed, and Lyapunov stability analysis is given. Finally, simulation and experimental verification are performed. The wearing experiment shows that the resistance torque suffered by humans under human–robot interaction is lower than 120 Nmm, which confirms that the controller can realize zero-impedance control of the designed ankle exoskeleton.},
  archive      = {J_FROBT},
  author       = {Mo, Lufan and Feng, Pengbo and Shao, Yixin and Shi, Di and Ju, Linhang and Zhang, Wuxiang and Ding, Xilun},
  doi          = {10.3389/frobt.2022.864684},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {864684},
  shortjournal = {Front. Robot. AI},
  title        = {Anti-disturbance sliding mode control of a novel variable stiffness actuator for the rehabilitation of neurologically disabled patients},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A music-therapy robotic platform for children with autism:
A pilot study. <em>FROBT</em>, <em>9</em>, 855819. (<a
href="https://doi.org/10.3389/frobt.2022.855819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children with Autism Spectrum Disorder (ASD) experience deficits in verbal and nonverbal communication skills including motor control, turn-taking, and emotion recognition. Innovative technology, such as socially assistive robots, has shown to be a viable method for Autism therapy. This paper presents a novel robot-based music-therapy platform for modeling and improving the social responses and behaviors of children with ASD. Our autonomous social interactive system consists of three modules. Module one provides an autonomous initiative positioning system for the robot, NAO, to properly localize and play the instrument (Xylophone) using the robot’s arms. Module two allows NAO to play customized songs composed by individuals. Module three provides a real-life music therapy experience to the users. We adopted Short-time Fourier Transform and Levenshtein distance to fulfill the design requirements: 1) “music detection” and 2) “smart scoring and feedback”, which allows NAO to understand music and provide additional practice and oral feedback to the users as applicable. We designed and implemented six Human-Robot-Interaction (HRI) sessions including four intervention sessions. Nine children with ASD and seven Typically Developing participated in a total of fifty HRI experimental sessions. Using our platform, we collected and analyzed data on social behavioral changes and emotion recognition using Electrodermal Activity (EDA) signals. The results of our experiments demonstrate most of the participants were able to complete motor control tasks with 70% accuracy. Six out of the nine ASD participants showed stable turn-taking behavior when playing music. The results of automated emotion classification using Support Vector Machines illustrates that emotional arousal in the ASD group can be detected and well recognized via EDA bio-signals. In summary, the results of our data analyses, including emotion classification using EDA signals, indicate that the proposed robot-music based therapy platform is an attractive and promising assistive tool to facilitate the improvement of fine motor control and turn-taking skills in children with ASD.},
  archive      = {J_FROBT},
  author       = {Feng, Huanghao and Mahoor, Mohammad H. and Dino, Francesca},
  doi          = {10.3389/frobt.2022.855819},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {855819},
  shortjournal = {Front. Robot. AI},
  title        = {A music-therapy robotic platform for children with autism: A pilot study},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ODAS: Open embeddeD audition system. <em>FROBT</em>,
<em>9</em>, 854444. (<a
href="https://doi.org/10.3389/frobt.2022.854444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial audition aims at providing hearing capabilities to machines, computers and robots. Existing frameworks in robot audition offer interesting sound source localization, tracking and separation performance, although involve a significant amount of computations that limit their use on robots with embedded computing capabilities. This paper presents ODAS, the Open embeddeD Audition System framework, which includes strategies to reduce the computational load and perform robot audition tasks on low-cost embedded computing systems. It presents key features of ODAS, along with cases illustrating its uses in different robots and artificial audition applications.},
  archive      = {J_FROBT},
  author       = {Grondin, François and Létourneau, Dominic and Godin, Cédric and Lauzon, Jean-Samuel and Vincent, Jonathan and Michaud, Simon and Faucher, Samuel and Michaud, François},
  doi          = {10.3389/frobt.2022.854444},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {854444},
  shortjournal = {Front. Robot. AI},
  title        = {ODAS: Open embeddeD audition system},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ICT solutions in the d-sys-com research: Analysis of the
needs and attitudes of the frail elderly person. <em>FROBT</em>,
<em>9</em>, 851473. (<a
href="https://doi.org/10.3389/frobt.2022.851473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction and use of innovative technological devices to support the aging of frail elderly people does not necessarily correspond to an improvement in people’s quality of life. The strong technical curvature resulting from the use of telemedicine models often highlights limits in the usability of technologies in responding to the real needs of users. The theoretical framework of special pedagogy allows the assumption of the bio-psycho-social perspective and the constructs of quality of life and participation and opens up to inclusive logics that implement a profound and questioning reflection on all contexts of life, with the goal of exposing the set of disabling processes and indicating a valid support in the use of technological resources. The study, retracing the research phases of the Data System Platform for Smart Communities project (project admitted for funding in the Innolabs 2018–2019 call), completed in 2020, investigates the needs of strategic stakeholders and explores the factors that influence the adoption and diffusion of telemedicine devices by frail elderly people.},
  archive      = {J_FROBT},
  author       = {Pinnelli, Stefania},
  doi          = {10.3389/frobt.2022.851473},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {851473},
  shortjournal = {Front. Robot. AI},
  title        = {ICT solutions in the D-sys-com research: Analysis of the needs and attitudes of the frail elderly person},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual rewards from observation for sequential tasks:
Autonomous pile loading. <em>FROBT</em>, <em>9</em>, 838059. (<a
href="https://doi.org/10.3389/frobt.2022.838059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key challenges in implementing reinforcement learning methods for real-world robotic applications is the design of a suitable reward function. In field robotics, the absence of abundant datasets, limited training time, and high variation of environmental conditions complicate the task further. In this paper, we review reward learning techniques together with visual representations commonly used in current state-of-the-art works in robotics. We investigate a practical approach proposed in prior work to associate the reward with the stage of the progress in task completion based on visual observation. This approach was demonstrated in controlled laboratory conditions. We study its potential for a real-scale field application, autonomous pile loading, tested outdoors in three seasons: summer, autumn, and winter. In our framework, the cumulative reward combines the predictions about the process stage and the task completion (terminal stage). We use supervised classification methods to train prediction models and investigate the most common state-of-the-art visual representations. We use task-specific contrastive features for terminal stage prediction.},
  archive      = {J_FROBT},
  author       = {Strokina, Nataliya and Yang, Wenyan and Pajarinen, Joni and Serbenyuk, Nikolay and Kämäräinen, Joni and Ghabcheloo, Reza},
  doi          = {10.3389/frobt.2022.838059},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {838059},
  shortjournal = {Front. Robot. AI},
  title        = {Visual rewards from observation for sequential tasks: Autonomous pile loading},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Serious games: A new approach to foster information and
practices about covid-19? <em>FROBT</em>, <em>9</em>, 830950. (<a
href="https://doi.org/10.3389/frobt.2022.830950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current Covid-19 pandemic poses an unprecedented global challenge in the field of education and training. As we have seen, the lack of proper information about the virus and its transmission has forced the general population and healthcare workers to rapidly acquire knowledge and learn new practices. Clearly, a well-informed population is more likely to adopt the correct precautionary measures, thus reducing the transmission of the infection; likewise, properly educated healthcare workers are better equipped to manage the emergency. However, the need to maintain physical distancing has made it impossible to provide in-presence information and training. In this regard, new technologies have proved to be an invaluable resource by facilitating distance learning. Indeed, e-learning offers significant advantages because it does not require the physical presence of learners and teachers. This innovative method applied to serious games has been considered potentially effective in enabling rapid and large-scale dissemination of information and learning through content interactivity. We will review studies that have observed the development and use of serious games to foster information and practices about Covid-19 aimed at promoting behavioral changes in the population and the healthcare personnel involved on the front line.},
  archive      = {J_FROBT},
  author       = {Montalbano, L. and Gallo, L. and Ferrante, G. and Malizia, V. and Cilluffo, G. and Fasola, S. and Alesi, M. and La Grutta, S.},
  doi          = {10.3389/frobt.2022.830950},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {830950},
  shortjournal = {Front. Robot. AI},
  title        = {Serious games: A new approach to foster information and practices about covid-19?},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A study on the effects of cognitive overloading and
distractions on human movement during robot-assisted dressing.
<em>FROBT</em>, <em>9</em>, 815871. (<a
href="https://doi.org/10.3389/frobt.2022.815871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For robots that can provide physical assistance, maintaining synchronicity of the robot and human movement is a precursor for interaction safety. Existing research on collaborative HRI does not consider how synchronicity can be affected if humans are subjected to cognitive overloading and distractions during close physical interaction. Cognitive neuroscience has shown that unexpected events during interactions not only affect action cognition but also human motor control Gentsch et al. (Cognition, 2016, 146, 81–89). If the robot is to safely adapt its trajectory to distracted human motion, quantitative changes in the human movement should be evaluated. The main contribution of this study is the analysis and quantification of disrupted human movement during a physical collaborative task that involves robot-assisted dressing. Quantifying disrupted movement is the first step in maintaining the synchronicity of the human-robot interaction. The human movement data collected from a series of experiments where participants are subjected to cognitive loading and distractions during the human-robot interaction, are projected in a 2-D latent space that efficiently represents the high-dimensionality and non-linearity of the data. The quantitative data analysis is supported by a qualitative study of user experience, using the NASA Task Load Index to measure perceived workload, and the PeRDITA questionnaire to represent the human psychological state during these interactions. In addition, we present an experimental methodology to collect interaction data in this type of human-robot collaboration that provides realism, experimental rigour and high fidelity of the human-robot interaction in the scenarios.},
  archive      = {J_FROBT},
  author       = {Camilleri, Antonella and Dogramadzi, Sanja and Caleb-Solly, Praminda},
  doi          = {10.3389/frobt.2022.815871},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {815871},
  shortjournal = {Front. Robot. AI},
  title        = {A study on the effects of cognitive overloading and distractions on human movement during robot-assisted dressing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The effects of learning in morphologically evolving robot
systems. <em>FROBT</em>, <em>9</em>, 797393. (<a
href="https://doi.org/10.3389/frobt.2022.797393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneously evolving morphologies (bodies) and controllers (brains) of robots can cause a mismatch between the inherited body and brain in the offspring. To mitigate this problem, the addition of an infant learning period has been proposed relatively long ago by the so-called Triangle of Life approach. However, an empirical assessment is still lacking to-date. In this paper, we investigate the effects of such a learning mechanism from different perspectives. Using extensive simulations we show that learning can greatly increase task performance and reduce the number of generations required to reach a certain fitness level compared to the purely evolutionary approach. Furthermore, we demonstrate that the evolved morphologies will be also different, even though learning only directly affects the controllers. This provides a quantitative demonstration that changes in the brain can induce changes in the body. Finally, we examine the learning delta defined as the performance difference between the inherited and the learned brain, and find that it is growing throughout the evolutionary process. This shows that evolution produces robots with an increasing plasticity, that is, consecutive generations become better learners and, consequently, they perform better at the given task. Moreover, our results demonstrate that the Triangle of Life is not only a concept of theoretical interest, but a system methodology with practical benefits.},
  archive      = {J_FROBT},
  author       = {Luo, Jie and Stuurman, Aart C. and Tomczak, Jakub M. and Ellers, Jacintha and Eiben, Agoston E.},
  doi          = {10.3389/frobt.2022.797393},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {797393},
  shortjournal = {Front. Robot. AI},
  title        = {The effects of learning in morphologically evolving robot systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Teammates instead of tools: The impacts of level of autonomy
on mission performance and human–agent teaming dynamics in multi-agent
distributed teams. <em>FROBT</em>, <em>9</em>, 782134. (<a
href="https://doi.org/10.3389/frobt.2022.782134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–agent teaming (HAT) is becoming more commonplace across industry, military, and consumer settings. Agents are becoming more advanced, more integrated, and more responsible for tasks previously assigned to humans. In addition, the dyadic human–agent teaming nature is evolving from a one–one pair to one–many, in which the human is working with numerous agents to accomplish a task. As capabilities become more advanced and humanlike, the best method for humans and agents to effectively coordinate is still unknown. Therefore, current research must start diverting focus from how many agents can a human manage to how can agents and humans work together effectively. Levels of autonomy (LOAs), or varying levels of responsibility given to the agents, implemented specifically in the decision-making process could potentially address some of the issues related to workload, stress, performance, and trust. This study sought to explore the effects of different LOAs on human–machine team coordination, performance, trust, and decision making in hand with assessments of operator workload and stress in a simulated multi-unmanned aircraft vehicle (UAV) intelligence surveillance and reconnaissance (ISR) task. The results of the study can be used to identify human factor roadblocks to effective HAT and provide guidance for future designs of HAT. Additionally, the unique impacts of LOA and autonomous decision making by agents on trust are explored.},
  archive      = {J_FROBT},
  author       = {Rebensky, Summer and Carmody, Kendall and Ficke, Cherrise and Carroll, Meredith and Bennett, Winston},
  doi          = {10.3389/frobt.2022.782134},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {782134},
  shortjournal = {Front. Robot. AI},
  title        = {Teammates instead of tools: The impacts of level of autonomy on mission performance and Human–Agent teaming dynamics in multi-agent distributed teams},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novelty knows no boundaries: Why a proper investigation of
novelty effects within SHRI should begin by addressing the scientific
plurality of the field. <em>FROBT</em>, <em>9</em>, 741478. (<a
href="https://doi.org/10.3389/frobt.2022.741478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on psychological novelty effects within the fields of Social Robotics and Human-Robot Interaction (together: SHRI) so far has failed to gather the momentum it deserves. With the aid of exemplary descriptions of how psychological novelty is currently approached and researched across (certain main regions of) the larger scientific landscape, I argue that the treatment of novelty effects within the multidisciplinary SHRI reflects larger circumstances of fragmentation and heterogeneity in novelty research in general. I further propose that while the concept of novelty may currently function as a Boundary Object between the contributing domains of SHRI, a properly integrated, interdisciplinary concept of novelty is needed in order to capture and investigate the scope and scale of novelty effects within research on social human-robot interaction. Building on research on the New Ontological Category Hypothesis and related studies, I argue that the novelty of social robots can be understood as radical to the extent that their comprehension requires revisions of traditional core categories of being. In order to investigate the sui generis effects of such novelty, which should not be narrowly understood as mere “noise” in the data, it is paramount that the field of SHRI begin by working out a shared, integrative framework of psychological novelty and novelty effects.},
  archive      = {J_FROBT},
  author       = {Smedegaard, Catharina V.},
  doi          = {10.3389/frobt.2022.741478},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {741478},
  shortjournal = {Front. Robot. AI},
  title        = {Novelty knows no boundaries: Why a proper investigation of novelty effects within SHRI should begin by addressing the scientific plurality of the field},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A compliance–reactance framework for evaluating human-robot
interaction. <em>FROBT</em>, <em>9</em>, 733504. (<a
href="https://doi.org/10.3389/frobt.2022.733504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When do we follow requests and recommendations and which ones do we choose not to comply with? This publication combines definitions of compliance and reactance as behaviours and as affective processes in one model for application to human-robot interaction. The framework comprises three steps: human perception, comprehension, and selection of an action following a cue given by a robot. The paper outlines the application of the model in different study settings such as controlled experiments that allow for the assessment of cognition as well as observational field studies that lack this possibility. Guidance for defining and measuring compliance and reactance is outlined and strategies for improving robot behaviour are derived for each step in the process model. Design recommendations for each step are condensed into three principles on information economy, adequacy, and transparency. In summary, we suggest that in order to maximise the probability of compliance with a cue and to avoid reactance, interaction designers should aim for a high probability of perception, a high probability of comprehension and prevent negative affect. Finally, an example application is presented that uses existing data from a laboratory experiment in combination with data collected in an online survey to outline how the model can be applied to evaluate a new technology or interaction strategy using the concepts of compliance and reactance as behaviours and affective constructs.},
  archive      = {J_FROBT},
  author       = {Boos, Annika and Herzog, Olivia and Reinhardt, Jakob and Bengler, Klaus and Zimmermann, Markus},
  doi          = {10.3389/frobt.2022.733504},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {733504},
  shortjournal = {Front. Robot. AI},
  title        = {A Compliance–Reactance framework for evaluating human-robot interaction},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards a personality AI for robots: Potential colony
capacity of a goal-shaped generative personality model when used for
expressing personalities via non-verbal behaviour of humanoid robots.
<em>FROBT</em>, <em>9</em>, 728776. (<a
href="https://doi.org/10.3389/frobt.2022.728776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering robot personalities is a challenge of multiple folds. Every robot that interacts with humans is an individual physical presence that may require their own personality. Thus, robot personalities engineers face a problem that is the reverse of that of personality psychologists: robot personalities engineers need to make batches of identical robots into individual personalities, as oppose to formulating comprehensive yet parsimonious descriptions of individual personalities that already exist. The robot personality research so far has been fruitful in demonstrating the positive effects of robot personality but unfruitful in insights into how robot personalities can be engineered in significant quantities. To engineer robot personalities for mass-produced robots we need a generative personality model with a structure to encode a robot’s individual characteristics as personality traits and generate behaviour with inter- and intra-individual differences that reflect those characteristics. We propose a generative personality model shaped by goals as part of a personality AI for robots towards which we have been working, and we conducted tests to investigate how many individual personalities the model can practically support when it is used for expressing personalities via non-verbal behaviour on the heads of humanoid robots.},
  archive      = {J_FROBT},
  author       = {Luo, Liangyi and Ogawa, Kohei and Peebles, Graham and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2022.728776},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {728776},
  shortjournal = {Front. Robot. AI},
  title        = {Towards a personality AI for robots: Potential colony capacity of a goal-shaped generative personality model when used for expressing personalities via non-verbal behaviour of humanoid robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Shared control for tele-operation systems.
<em>FROBT</em>, <em>9</em>, 915187. (<a
href="https://doi.org/10.3389/frobt.2022.915187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Li, Yanan and Takagi, Atsushi and Tee, Keng Peng},
  doi          = {10.3389/frobt.2022.915187},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {915187},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Shared control for tele-operation systems},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Corrigendum: Artificial intelligence based patient-specific
preoperative planning algorithm for total knee arthroplasty.
<em>FROBT</em>, <em>9</em>, 899349. (<a
href="https://doi.org/10.3389/frobt.2022.899349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lambrechts, Adriaan and Wirix-Speetjens, Roel and Maes, Frederik and Van Huffel, Sabine},
  doi          = {10.3389/frobt.2022.899349},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {899349},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: Artificial intelligence based patient-specific preoperative planning algorithm for total knee arthroplasty},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using deep neural networks to improve contact wrench
estimation of serial robotic manipulators in static tasks.
<em>FROBT</em>, <em>9</em>, 892916. (<a
href="https://doi.org/10.3389/frobt.2022.892916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable force-driven robot-interaction requires precise contact wrench measurements. In most robot systems these measurements are severely incorrect and in most manipulation tasks expensive additional force sensors are installed. We follow a learning approach to train the dependencies between joint torques and end-effector contact wrenches. We used a redundant serial light-weight manipulator (KUKA iiwa 7 R800) with integrated force estimation based on the joint torques measured in each of the robot’s seven axes. Firstly, a simulated dataset is created to let a feed-forward net learn the relationship between end-effector contact wrenches and joint torques for a static case. Secondly, an extensive real training dataset was acquired with 330,000 randomized robot positions and end-effector contact wrenches and used for retraining the simulated trained feed-forward net. We can show that the wrench prediction error could be reduced by around 57% for the forces compared to the manufacturer’s proprietary force estimation model. In addition, we show that the number of high outliers can be reduced substantially. Furthermore we prove that the approach could be also transferred to another robot (KUKA iiwa 14 R820) with reasonable prediction accuracy and without the need of acquiring new robot specific data.},
  archive      = {J_FROBT},
  author       = {Osburg, Jonas and Kuhlemann, Ivo and Hagenah, Jannis and Ernst, Floris},
  doi          = {10.3389/frobt.2022.892916},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {892916},
  shortjournal = {Front. Robot. AI},
  title        = {Using deep neural networks to improve contact wrench estimation of serial robotic manipulators in static tasks},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Learning, perception, and collaboration for
robots in industrial environments. <em>FROBT</em>, <em>9</em>, 888971.
(<a href="https://doi.org/10.3389/frobt.2022.888971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Aleotti, Jacopo and Saveriano, Matteo and Monica, Riccardo},
  doi          = {10.3389/frobt.2022.888971},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {888971},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Learning, perception, and collaboration for robots in industrial environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Evolving robotic morphologies. <em>FROBT</em>,
<em>9</em>, 874853. (<a
href="https://doi.org/10.3389/frobt.2022.874853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Howard, David and Glette, Kyrre and Cheney, Nick},
  doi          = {10.3389/frobt.2022.874853},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {874853},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Evolving robotic morphologies},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAS—a fully actuated segment for tendon-driven continuum
robots. <em>FROBT</em>, <em>9</em>, 873446. (<a
href="https://doi.org/10.3389/frobt.2022.873446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a segment design that combines two distinct characteristics of tendon-driven continuum robots, i.e. variable length and non-straight tendon routing, into a single segment by enabling rotation of its backbone. As a result, this segment can vary its helical tendon routing and has four degrees-of-freedom, while maintaining a small-scale design with an overall outer diameter of 7 mm thanks to an extrinsic actuation principle. In simulation and on prototypes, we observe improved motion capabilities, as evidenced by position redundancy and follow-the-leader deployment along spatially tortuous paths. To demonstrate the latter on a physical prototype, a simple, yet effective area-based error measure for follow-the-leader deployment is proposed to evaluate the performance. Furthermore, we derive a static model which is used to underpin the observed motion capabilities. In summary, our segment design extends previous designs with minimal hardware overhead, while either archiving similar accuracy in position errors and planar follow-the-leader deployment, or exhibiting superior motion capabilities due to position redundancy and spatial follow-the-leader deployment.},
  archive      = {J_FROBT},
  author       = {Grassmann, Reinhard M. and Rao, Priyanka and Peyron, Quentin and Burgner-Kahrs, Jessica},
  doi          = {10.3389/frobt.2022.873446},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {873446},
  shortjournal = {Front. Robot. AI},
  title        = {FAS—A fully actuated segment for tendon-driven continuum robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Object surface recognition based on standing waves in
acoustic signals. <em>FROBT</em>, <em>9</em>, 872964. (<a
href="https://doi.org/10.3389/frobt.2022.872964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the use of the standing waves created by the interference between transmitted and reflected acoustic signals to recognize the size and the shape of a target object. This study shows that the profile of the distance spectrum generated by the interference encodes not only the distance to the target, but also the distance to the edges of the target surface. To recognize the extent of the surface, a high-resolution distance spectrum is proposed, and a method to estimate the points on the edges by incorporating observations from multiple measurement is introduced. Numerical simulations validated the approach and showed that the method worked even in the presence of noise. Experimental results are also shown to verify that the method works in a real environment.},
  archive      = {J_FROBT},
  author       = {Kumon, Makoto and Fukunaga, Rikuto and Manabe, Tomoya and Nakatsuma, Kei},
  doi          = {10.3389/frobt.2022.872964},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {872964},
  shortjournal = {Front. Robot. AI},
  title        = {Object surface recognition based on standing waves in acoustic signals},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-day EMG-based knee joint torque estimation using
hybrid neuromusculoskeletal modelling and convolutional neural networks.
<em>FROBT</em>, <em>9</em>, 869476. (<a
href="https://doi.org/10.3389/frobt.2022.869476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proportional control using surface electromyography (EMG) enables more intuitive control of a transfemoral prosthesis. However, EMG is a noisy signal which can vary over time, giving rise to the question what approach for knee torque estimation is most suitable for multi-day control. In this study we compared three different modelling frameworks to estimate knee torque in non-weight-bearing situations. The first model contained a convolutional neural network (CNN) which mapped EMG to knee torque directly. The second used a neuromusculoskeletal model (NMS) which used EMG, muscle tendon unit lengths and moment arms to compute knee torque. The third model (Hybrid) used a CNN to map EMG to specific muscle activation, which was used together with NMS components to compute knee torque. Multi-day measurements were conducted on ten able-bodied participants who performed non-weight bearing activities. CNN had the best performance in general and on each day (Normalized Root Mean Squared Error (NRMSE) 9.2 ± 4.4%). The Hybrid model (NRMSE 12.4 ± 3.4%) was able to outperform NMS (NRMSE 14.3 ± 4.2%). The NMS model showed no significant difference between measurement days. The CNN model and Hybrid models had significant performance differences between the first day and all other days. CNNs are suited for multi-day torque estimation in terms of error rate, outperforming the other two model types. NMS was the only model type which was robust over all days. This study investigated the behavior of three model types over multiple days, giving insight in the most suited modelling approach for multi-day torque estimation to be used in prosthetic control.},
  archive      = {J_FROBT},
  author       = {Schulte , Robert V. and Zondag , Marijke and Buurke , Jaap H. and Prinsen , Erik C.},
  doi          = {10.3389/frobt.2022.869476},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {869476},
  shortjournal = {Front. Robot. AI},
  title        = {Multi-day EMG-based knee joint torque estimation using hybrid neuromusculoskeletal modelling and convolutional neural networks},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive deformation control for elastic linear objects.
<em>FROBT</em>, <em>9</em>, 868459. (<a
href="https://doi.org/10.3389/frobt.2022.868459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the general problem of deformable linear object manipulation. The main application we consider is in the field of agriculture, for plant grasping, but may have interests in other tasks such as human daily activities and industrial production. We specifically consider an elastic linear object where one of its endpoints is fixed, and another point can be grasped by a robotic arm. To deal with the mentioned problem, we propose a model-free method to control the state of an arbitrary point that can be at any place along the object’s length. Our approach allows the robot to manipulate the object without knowing any model parameters or offline information of the object’s deformation. An adaptive control strategy is proposed for regulating the state of any point automatically deforming the object into the desired location. A control law is developed to regulate the object’s shape thanks to the adaptive estimation of the system parameters and its states. This method can track a desired manipulation trajectory to reach the target point, which leads to a smooth deformation without drastic changes. A Lyapunov-based argument is presented for the asymptotic convergence of the system that shows the process’s stability and convergence to desired state values. To validate the controller, numerical simulations involving two different deformation models are conducted, and performances of the proposed algorithm are investigated through full-scale experiments.},
  archive      = {J_FROBT},
  author       = {Aghajanzadeh, Omid and Aranda, Miguel and Corrales Ramon, Juan Antonio and Cariou, Christophe and Lenain, Roland and Mezouar, Youcef},
  doi          = {10.3389/frobt.2022.868459},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {868459},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive deformation control for elastic linear objects},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effects of upper-limb exoskeletons designed for use in the
working environment—a literature review. <em>FROBT</em>, <em>9</em>,
858893. (<a href="https://doi.org/10.3389/frobt.2022.858893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Many employees report high physical strain from overhead work and resulting musculoskeletal disorders. The consequences of these conditions extend far beyond everyday working life and can severely limit the quality of life of those affected. One solution to this problem may be the use of upper-limb exoskeletons, which are supposed to relieve the shoulder joint in particular. The aim of this literature review was to provide an overview of the use and efficacy of exoskeletons for upper extremities in the working environment.Methods: A literature review was conducted using the PICO scheme and the PRISMA statement. To this end, a systematic search was performed in the PubMed, Web of Science and Scopus databases in May 2020 and updated in February 2022. The obtained studies were screened using previously defined inclusion and exclusion criteria and assessed for quality. Pertinent data were then extracted from the publications and analyzed with regard to type of exoskeleton used as well as efficacy of exoskeleton use.Results: 35 suitable studies were included in the review. 18 different exoskeletons were examined. The majority of the exoskeletons only supported the shoulder joint and were used to assist individuals working at or above shoulder level. The main focus of the studies was the reduction of muscle activity in the shoulder area. Indeed, 16 studies showed a reduced activity in the deltoid and trapezius muscles after exoskeleton use. Kinematically, a deviation of the movement behavior could be determined in some models. In addition, study participants reported perceived reduction in exertion and discomfort.Discussion: Exoskeletons for upper extremities may generate significant relief for the intended tasks, but the effects in the field (i.e., working environment) are less pronounced than in the laboratory setting. This may be due to the fact that not only overhead tasks but also secondary tasks have to be performed in the field. In addition, currently available exoskeletons do not seem to be suitable for all overhead workplaces and should always be assessed in the human-workplace context. Further studies in various settings are required that should also include more females and older people.},
  archive      = {J_FROBT},
  author       = {Moeller, Tobias and Krell-Roesch, Janina and Woll, Alexander and Stein, Thorsten},
  doi          = {10.3389/frobt.2022.858893},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {858893},
  shortjournal = {Front. Robot. AI},
  title        = {Effects of upper-limb exoskeletons designed for use in the working Environment—A literature review},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auditory survey of endangered eurasian bittern using
microphone arrays and robot audition. <em>FROBT</em>, <em>9</em>,
854572. (<a href="https://doi.org/10.3389/frobt.2022.854572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bioacoustics monitoring has become increasingly popular for studying the behavior and ecology of vocalizing birds. This study aims to verify the practical effectiveness of localization technology for auditory monitoring of endangered Eurasian bittern (Botaurus stellaris) which inhabits wetlands in remote areas with thick vegetation. Their crepuscular and highly secretive nature, except during the breeding season when they vocalize advertisement calls, make them difficult to monitor. Because of the increasing rates of habitat loss, surveying accurate numbers and their habitat needs are both important conservation tasks. We investigated the feasibility of localizing their booming calls, at a low frequency range between 100–200 Hz, using microphone arrays and robot audition HARK (Honda Research Institute, Audition for Robots with Kyoto University). We first simulated sound source localization of actual bittern calls for microphone arrays of radii 10 cm, 50 cm, 1 m, and 10 m, under different noise levels. Second, we monitored bitterns in an actual field environment using small microphone arrays (height = 12 cm; width = 8 cm), in the Sarobetsu Mire, Hokkaido Island, Japan. The simulation results showed that the spectral detectability was higher for larger microphone arrays, whereas the temporal detectability was higher for smaller microphone arrays. We identified that false detection in smaller microphone arrays, which was coincidentally generated in the calculation proximate to the transfer function for the opposite side. Despite technical limitations, we successfully localized booming calls of at least two males in a reverberant wetland, surrounded by thick vegetation and riparian trees. This study is the first case of localizing such rare birds using small-sized microphone arrays in the field, thereby presenting how this technology could contribute to auditory surveys of population numbers, behaviors, and microhabitat selection, all of which are difficult to investigate using other observation methods. This methodology is not only useful for the better understanding of bitterns, but it can also be extended to investigate other rare nocturnal birds with low-frequency vocalizations, without direct ringing or tagging. Our results also suggest a future necessity for a robust localization system to avoid reverberation and echoing in the field, resulting in the false detection of the target birds.},
  archive      = {J_FROBT},
  author       = {Matsubayashi, Shiho and Nakadai, Kazuhiro and Suzuki, Reiji and Ura, Tatsuya and Hasebe, Makoto and Okuno, Hiroshi G.},
  doi          = {10.3389/frobt.2022.854572},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {854572},
  shortjournal = {Front. Robot. AI},
  title        = {Auditory survey of endangered eurasian bittern using microphone arrays and robot audition},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active stabilization of interventional tasks utilizing a
magnetically manipulated endoscope. <em>FROBT</em>, <em>9</em>, 854081.
(<a href="https://doi.org/10.3389/frobt.2022.854081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetically actuated robots have become increasingly popular in medical endoscopy over the past decade. Despite the significant improvements in autonomy and control methods, progress within the field of medical magnetic endoscopes has mainly been in the domain of enhanced navigation. Interventional tasks such as biopsy, polyp removal, and clip placement are a major procedural component of endoscopy. Little advancement has been done in this area due to the problem of adequately controlling and stabilizing magnetically actuated endoscopes for interventional tasks. In the present paper we discuss a novel model-based Linear Parameter Varying (LPV) control approach to provide stability during interventional maneuvers. This method linearizes the non-linear dynamic interaction between the external actuation system and the endoscope in a set of equilibria, associated to different distances between the magnetic source and the endoscope, and computes different controllers for each equilibrium. This approach provides the global stability of the overall system and robustness against external disturbances. The performance of the LPV approach is compared to an intelligent teleoperation control method (based on a Proportional Integral Derivative (PID) controller), on the Magnetic Flexible Endoscope (MFE) platform. Four biopsies in different regions of the colon and at two different system equilibria are performed. Both controllers are asked to stabilize the endoscope in the presence of external disturbances (i.e. the introduction of the biopsy forceps through the working channel of the endoscope). The experiments, performed in a benchtop colon simulator, show a maximum reduction of the mean orientation error of the endoscope of 45.8% with the LPV control compared to the PID controller.},
  archive      = {J_FROBT},
  author       = {Barducci, Lavinia and Scaglioni, Bruno and Martin, James and Obstein, Keith L. and Valdastri, Pietro},
  doi          = {10.3389/frobt.2022.854081},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {854081},
  shortjournal = {Front. Robot. AI},
  title        = {Active stabilization of interventional tasks utilizing a magnetically manipulated endoscope},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Flexible surgical robotics: Design, modeling,
sensing and control. <em>FROBT</em>, <em>9</em>, 854024. (<a
href="https://doi.org/10.3389/frobt.2022.854024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Li, Zheng and Wang, Long and Wu, Liao and Alambeigi, Farshid and Cheng, Shing Shin},
  doi          = {10.3389/frobt.2022.854024},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {854024},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: flexible surgical robotics: design, modeling, sensing and control},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human–machine telecollaboration accelerates the safe
deployment of large-scale autonomous robots during the COVID-19
pandemic. <em>FROBT</em>, <em>9</em>, 853828. (<a
href="https://doi.org/10.3389/frobt.2022.853828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hu, Zhongxu and Zhang, Yiran and Li, Qinghua and Lv, Chen},
  doi          = {10.3389/frobt.2022.853828},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {853828},
  shortjournal = {Front. Robot. AI},
  title        = {Human–Machine telecollaboration accelerates the safe deployment of large-scale autonomous robots during the COVID-19 pandemic},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hands to hexapods, wearable user interface design for
specifying leg placement for legged robots. <em>FROBT</em>, <em>9</em>,
852270. (<a href="https://doi.org/10.3389/frobt.2022.852270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specifying leg placement is a key element for legged robot control, however current methods for specifying individual leg motions with human-robot interfaces require mental concentration and the use of both arm muscles. In this paper, a new control interface is discussed to specify leg placement for hexapod robot by using finger motions. Two mapping methods are proposed and tested with lab staff, Joint Angle Mapping (JAM) and Tip Position Mapping (TPM). The TPM method was shown to be more efficient. Then a manual controlled gait based on TPM is compared with fixed gait and camera-based autonomous gait in a Webots simulation to test the obstacle avoidance performance on 2D terrain. Number of Contacts (NOC) for each gait are recorded during the tests. The results show that both the camera-based autonomous gait and the TPM are effective methods in adjusting step size to avoid obstacles. In high obstacle density environments, TPM reduces the number of contacts to 25% of the fixed gaits, which is even better than some of the autonomous gaits with longer step size. This shows that TPM has potential in environments and situations where autonomous footfall planning fails or is unavailable. In future work, this approach can be improved by combining with haptic feedback, additional degrees of freedom and artificial intelligence.},
  archive      = {J_FROBT},
  author       = {Zhou, Jianfeng and Nguyen, Quan and Kamath, Sanjana and Hacohen, Yaneev and Zhu, Chunchu and Fu, Michael J. and Daltorio, Kathryn A.},
  doi          = {10.3389/frobt.2022.852270},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {852270},
  shortjournal = {Front. Robot. AI},
  title        = {Hands to hexapods, wearable user interface design for specifying leg placement for legged robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robots and AI as legal subjects? Disentangling the
ontological and functional perspective. <em>FROBT</em>, <em>9</em>,
842213. (<a href="https://doi.org/10.3389/frobt.2022.842213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics and AI-based applications (RAI) are often said to be so technologically advanced that they should be held responsible for their actions, instead of the human who designs or operates them. The paper aims to prove that this thesis (“the exceptionalist claim”)—as it stands—is both theoretically incorrect and practically inadequate. Indeed, the paper argues that such claim is based on a series of misunderstanding over the very notion and functions of “legal responsibility”, which it then seeks to clarify by developing and interdisciplinary conceptual taxonomy. In doing so, it aims to set the premises for a more constructive debate over the feasibility of granting legal standing to robotic application. After a short Introduction setting the stage of the debate, the paper addresses the ontological claim, distinguishing the philosophical from the legal debate on the notion of i) subjectivity and ii) agency, with their respective implications. The analysis allows us to conclude that the attribution of legal subjectivity and agency are purely fictional and technical solutions to facilitate legal interactions, and is not dependent upon the intrinsic nature of the RAI. A similar structure is maintained with respect to the notion of responsibility, addressed first in a philosophical and then legal perspective, to demonstrate how the latter is often utilized to both pursue ex ante deterrence and ex post compensation. The focus on the second objective allows us to bridge the analysis towards functional (law and economics based) considerations, to discuss how even the attribution of legal personhood may be conceived as an attempt to simplify certain legal interactions and relations. Within such a framework, the discussion whether to attribute legal subjectivity to the machine needs to be kept entirely within the legal domain, and grounded on technical (legal) considerations, to be argued on a functional, bottom-up analysis of specific classes of RAI. That does not entail the attribution of animacy or the ascription of a moral status to the entity itself.},
  archive      = {J_FROBT},
  author       = {Bertolini, Andrea and Episcopo, Francesca},
  doi          = {10.3389/frobt.2022.842213},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {842213},
  shortjournal = {Front. Robot. AI},
  title        = {Robots and AI as legal subjects? disentangling the ontological and functional perspective},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Endowing a NAO robot with practical social-touch perception.
<em>FROBT</em>, <em>9</em>, 840335. (<a
href="https://doi.org/10.3389/frobt.2022.840335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social touch is essential to everyday interactions, but current socially assistive robots have limited touch-perception capabilities. Rather than build entirely new robotic systems, we propose to augment existing rigid-bodied robots with an external touch-perception system. This practical approach can enable researchers and caregivers to continue to use robotic technology they have already purchased and learned about, but with a myriad of new social-touch interactions possible. This paper presents a low-cost, easy-to-build, soft tactile-perception system that we created for the NAO robot, as well as participants’ feedback on touching this system. We installed four of our fabric-and-foam-based resistive sensors on the curved surfaces of a NAO’s left arm, including its hand, lower arm, upper arm, and shoulder. Fifteen adults then performed five types of affective touch-communication gestures (hitting, poking, squeezing, stroking, and tickling) at two force intensities (gentle and energetic) on the four sensor locations; we share this dataset of four time-varying resistances, our sensor patterns, and a characterization of the sensors’ physical performance. After training, a gesture-classification algorithm based on a random forest identified the correct combined touch gesture and force intensity on windows of held-out test data with an average accuracy of 74.1%, which is more than eight times better than chance. Participants rated the sensor-equipped arm as pleasant to touch and liked the robot’s presence significantly more after touch interactions. Our promising results show that this type of tactile-perception system can detect necessary social-touch communication cues from users, can be tailored to a variety of robot body parts, and can provide HRI researchers with the tools needed to implement social touch in their own systems.},
  archive      = {J_FROBT},
  author       = {Burns, Rachael Bevill and Lee, Hyosang and Seifi, Hasti and Faulkner, Robert and Kuchenbecker, Katherine J.},
  doi          = {10.3389/frobt.2022.840335},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {840335},
  shortjournal = {Front. Robot. AI},
  title        = {Endowing a NAO robot with practical social-touch perception},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A wearable soft robotic exoskeleton for hip flexion
rehabilitation. <em>FROBT</em>, <em>9</em>, 835237. (<a
href="https://doi.org/10.3389/frobt.2022.835237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leg motion is essential to everyday tasks, yet many face a daily struggle due to leg motion impairment. Traditional robotic solutions for lower limb rehabilitation have arisen, but they may bare some limitations due to their cost. Soft robotics utilizes soft, pliable materials which may afford a less costly robotic solution. This work presents a soft-pneumatic-actuator-driven exoskeleton for hip flexion rehabilitation. An array of soft pneumatic rotary actuators is used for torque generation. An analytical model of the actuators is validated and used to determine actuator parameters for the target application of hip flexion. The performance of the assembly is assessed, and it is found capable of the target torque for hip flexion, 19.8 Nm at 30°, requiring 86 kPa to reach that torque output. The assembly exhibits a maximum torque of 31 Nm under the conditions tested. The full exoskeleton assembly is then assessed with healthy human subjects as they perform a set of lower limb motions. For one motion, the Leg Raise, a muscle signal reduction of 43.5% is observed during device assistance, as compared to not wearing the device. This reduction in muscle effort indicates that the device is effective in providing hip flexion assistance and suggests that pneumatic-rotary-actuator-driven exoskeletons are a viable solution to realize more accessible options for those who suffer from lower limb immobility.},
  archive      = {J_FROBT},
  author       = {Miller-Jackson, Tiana M. and Natividad, Rainier F. and Lim, Daniel Yuan Lee and Hernandez-Barraza, Luis and Ambrose, Jonathan W. and Yeow, Raye Chen-Hua},
  doi          = {10.3389/frobt.2022.835237},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {835237},
  shortjournal = {Front. Robot. AI},
  title        = {A wearable soft robotic exoskeleton for hip flexion rehabilitation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Implementation of NAO robot maze navigation based on
computer vision and collaborative learning. <em>FROBT</em>, <em>9</em>,
834021. (<a href="https://doi.org/10.3389/frobt.2022.834021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maze navigation using one or more robots has become a recurring challenge in scientific literature and real life practice, with fleets having to find faster and better ways to navigate environments such as a travel hub, airports, or for evacuation of disaster zones. Many methodologies have been explored to solve this issue, including the implementation of a variety of sensors and other signal receiving systems. Most interestingly, camera-based techniques have become more popular in this kind of scenarios, given their robustness and scalability. In this paper, we implement an end-to-end strategy to address this scenario, allowing a robot to solve a maze in an autonomous way, by using computer vision and path planning. In addition, this robot shares the generated knowledge to another by means of communication protocols, having to adapt its mechanical characteristics to be capable of solving the same challenge. The paper presents experimental validation of the four components of this solution, namely camera calibration, maze mapping, path planning and robot communication. Finally, we showcase some initial experimentation in a pair of robots with different mechanical characteristics. Further implementations of this work include communicating the robots for other tasks, such as teaching assistance, remote classes, and other innovations in higher education.},
  archive      = {J_FROBT},
  author       = {Magallán-Ramírez, Daniela and Martínez-Aguilar, Jorge David and Rodríguez-Tirado, Areli and Balderas, David and López-Caudana, Edgar Omar and Moreno-García, Carlos Francisco},
  doi          = {10.3389/frobt.2022.834021},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {834021},
  shortjournal = {Front. Robot. AI},
  title        = {Implementation of NAO robot maze navigation based on computer vision and collaborative learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of robotic systems for nursing care.
<em>FROBT</em>, <em>9</em>, 832248. (<a
href="https://doi.org/10.3389/frobt.2022.832248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increase of the aging population with a decrease in the available nursing staff has been seen in recent years. These two factors combined present a challenging problem for the future and has since become a political issue in many countries. Technological advances in robotics have made its use possible in new application fields like care and thus it appears to be a viable technological avenue to address the projected nursing labor shortage. The introduction of robots in nursing care creates an active triangular collaboration between the patient, nurse, and robot, which makes this area significantly different from traditional human–robot interaction (HRI) settings. In this review, we identify 133 robotic systems addressing nursing. We classify them according to two schemes: 1) a technical classification extended to include both patient and nurse and 2) a novel data-derived hierarchical classification based on use cases. We then analyze their intersection and build a multidimensional view of the state of technology. With this analytical tool, we describe an observed skew of the distribution of systems and identify gaps for future research. We also describe a link between the novel hierarchical use case classification and the typical phases of nursing care from admission to recovery.},
  archive      = {J_FROBT},
  author       = {Nieto Agraz, Celia and Pfingsthorn, Max and Gliesche, Pascal and Eichelberg, Marco and Hein, Andreas},
  doi          = {10.3389/frobt.2022.832248},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {832248},
  shortjournal = {Front. Robot. AI},
  title        = {A survey of robotic systems for nursing care},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic endoscope control via autonomous instrument
tracking. <em>FROBT</em>, <em>9</em>, 832208. (<a
href="https://doi.org/10.3389/frobt.2022.832208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many keyhole interventions rely on bi-manual handling of surgical instruments, forcing the main surgeon to rely on a second surgeon to act as a camera assistant. In addition to the burden of excessively involving surgical staff, this may lead to reduced image stability, increased task completion time and sometimes errors due to the monotony of the task. Robotic endoscope holders, controlled by a set of basic instructions, have been proposed as an alternative, but their unnatural handling may increase the cognitive load of the (solo) surgeon, which hinders their clinical acceptance. More seamless integration in the surgical workflow would be achieved if robotic endoscope holders collaborated with the operating surgeon via semantically rich instructions that closely resemble instructions that would otherwise be issued to a human camera assistant, such as “focus on my right-hand instrument.” As a proof of concept, this paper presents a novel system that paves the way towards a synergistic interaction between surgeons and robotic endoscope holders. The proposed platform allows the surgeon to perform a bimanual coordination and navigation task, while a robotic arm autonomously performs the endoscope positioning tasks. Within our system, we propose a novel tooltip localization method based on surgical tool segmentation and a novel visual servoing approach that ensures smooth and appropriate motion of the endoscope camera. We validate our vision pipeline and run a user study of this system. The clinical relevance of the study is ensured through the use of a laparoscopic exercise validated by the European Academy of Gynaecological Surgery which involves bi-manual coordination and navigation. Successful application of our proposed system provides a promising starting point towards broader clinical adoption of robotic endoscope holders.},
  archive      = {J_FROBT},
  author       = {Gruijthuijsen, Caspar and Garcia-Peraza-Herrera, Luis C. and Borghesan, Gianni and Reynaerts, Dominiek and Deprest, Jan and Ourselin, Sebastien and Vercauteren, Tom and Vander Poorten, Emmanuel},
  doi          = {10.3389/frobt.2022.832208},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {832208},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic endoscope control via autonomous instrument tracking},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Where does it belong? Autonomous object mapping in
open-world settings. <em>FROBT</em>, <em>9</em>, 828732. (<a
href="https://doi.org/10.3389/frobt.2022.828732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting changes such as moved, removed, or new objects is the essence for numerous indoor applications in robotics such as tidying-up, patrolling, and fetch/carry tasks. The problem is particularly challenging in open-world scenarios where novel objects may appear at any time. The main idea of this paper is to detect objects from partial 3D reconstructions of interesting areas in the environment. In our pipeline we first identify planes, consider clusters on top as objects, and compute their point-pair-features. They are used to match potential objects and categorize them robustly into static, moved, removed, and novel objects even in the presence of partial object reconstructions and clutter. Our approach dissolves heaps of objects without specific object knowledge, but only with the knowledge acquired from change detection. The evaluation is performed on real-world data that includes challenges affecting the quality of the reconstruction as a result of noisy input data. We present the novel dataset ObChange for quantitative evaluation, and we compare our method against a baseline using learning-based object detection. The results show that, even with a targeted training set, our approach outperforms the baseline for most test cases. Lastly, we also demonstrate our method’s effectiveness in real robot experiments.},
  archive      = {J_FROBT},
  author       = {Langer, Edith and Patten, Timothy and Vincze, Markus},
  doi          = {10.3389/frobt.2022.828732},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {828732},
  shortjournal = {Front. Robot. AI},
  title        = {Where does it belong? autonomous object mapping in open-world settings},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social drone sharing to increase UAV patrolling autonomy in
pre- and post-emergency scenarios. <em>FROBT</em>, <em>9</em>, 820239.
(<a href="https://doi.org/10.3389/frobt.2022.820239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multirotor drones are becoming increasingly popular in a number of application fields, with a unique appeal to the scientific community and the general public. Applications include security, monitoring and surveillance, environmental mapping, and emergency scenario management: in all these areas, two of the main issues to address are the availability of appropriate software architectures to coordinate teams of drones and solutions to cope with the short-term battery life. This article proposes the novel concepts of Social Drone Sharing (SDS) and Social Charging Station (SCS), which provide the basis to address these problems. Specifically, the article focuses on teams of drones in pre- and post-event monitoring and assessment. Using multirotor drones in these situations can be difficult due to the limited flight autonomy when multiple targets need to be inspected. The idea behind the SDS concept is that citizens can volunteer to recharge a drone or replace its batteries if it lands on their property. The computation of paths to inspect multiple targets will then take into account the availability of SCSs to find solutions compatible with the required inspection and flight times. The main contribution of this article is the development of a cloud-based software architecture for SDS mission management, which includes a multi-drone path-optimization algorithm taking the SDS and SCS concepts into account. Experiments in simulation and a lab environment are discussed, paving the path to a larger trial in a real scenario.},
  archive      = {J_FROBT},
  author       = {Bisio, Isabella-Sole and Morando, Luca and Recchiuto, Carmine Tommaso and Sgorbissa, Antonio},
  doi          = {10.3389/frobt.2022.820239},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {820239},
  shortjournal = {Front. Robot. AI},
  title        = {Social drone sharing to increase UAV patrolling autonomy in pre- and post-emergency scenarios},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Task roadmaps: Speeding up task replanning. <em>FROBT</em>,
<em>9</em>, 816355. (<a
href="https://doi.org/10.3389/frobt.2022.816355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern industrial robots are increasingly deployed in dynamic environments, where unpredictable events are expected to impact the robot’s operation. Under these conditions, runtime task replanning is required to avoid failures and unnecessary stops, while keeping up productivity. Task replanning is a long-sighted complement to path replanning, which is mostly concerned with avoiding unexpected obstacles that can lead to potentially unsafe situations. This paper focuses on task replanning as a way to dynamically adjust the robot behaviour to the continuously evolving environment in which it is deployed. Analogously to probabilistic roadmaps used in path planning, we propose the concept of Task roadmaps as a method to replan tasks by leveraging an offline generated search space. A graph-based model of the robot application is converted to a task scheduling problem to be solved by a proposed Branch and Bound (B&amp;amp;B) approach and two benchmark approaches: Mixed Integer Linear Programming (MILP) and Planning Domain Definition Language (PDDL). The B&amp;amp;B approach is proposed to compute the task roadmap, which is then reused to replan for unforeseeable events. The optimality and efficiency of this replanning approach are demonstrated in a simulation-based experiment with a mobile manipulator in a kitting application. In this study, the proposed B&amp;amp;B Task Roadmap replanning approach is significantly faster than a MILP solver and a PDDL based planner.},
  archive      = {J_FROBT},
  author       = {Lager, Anders and Spampinato, Giacomo and Papadopoulos, Alessandro V. and Nolte, Thomas},
  doi          = {10.3389/frobt.2022.816355},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {816355},
  shortjournal = {Front. Robot. AI},
  title        = {Task roadmaps: Speeding up task replanning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bipedal walking of underwater soft robot based on
data-driven model inspired by octopus. <em>FROBT</em>, <em>9</em>,
815435. (<a href="https://doi.org/10.3389/frobt.2022.815435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The soft organisms in nature have always been a source of inspiration for the design of soft arms and this paper draws inspiration from the octopus’s tentacle, aiming at a soft robot for moving flexibly in three-dimensional space. In the paper, combined with the characteristics of an octopus’s tentacle, a cable-driven soft arm is designed and fabricated, which can motion flexibly in three-dimensional space. Based on the TensorFlow framework, a data-driven model is established, and the data-driven model is trained using deep reinforcement learning strategy to realize posture control of a single soft arm. Finally, two trained soft arms are assembled into an octopus-inspired biped walking robot, which can go forward and turn around. Experimental analysis shows that the robot can achieve an average speed of 7.78 cm/s, and the maximum instantaneous speed can reach 12.8 cm/s.},
  archive      = {J_FROBT},
  author       = {Wu, Qiuxuan and Wu, Yan and Yang, Xiaochen and Zhang, Botao and Wang, Jian and Chepinskiy, Sergey A and Zhilenkov, Anton A},
  doi          = {10.3389/frobt.2022.815435},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {815435},
  shortjournal = {Front. Robot. AI},
  title        = {Bipedal walking of underwater soft robot based on data-driven model inspired by octopus},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Framework for armature-based 3D shape reconstruction of
sensorized soft robots in eXtended reality. <em>FROBT</em>, <em>9</em>,
810328. (<a href="https://doi.org/10.3389/frobt.2022.810328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots are typically intended to operate in highly unpredictable and unstructured environments. Although their soft bodies help them to passively conform to their environment, the execution of specific tasks within such environments often requires the help of an operator that supervises the interaction between the robot and its environment and adjusts the actuation inputs in order to successfully execute the task. However, direct observation of the soft robot is often impeded by the environment in which it operates. Therefore, the operator has to depend on a real-time simulation of the soft robot based on the signals from proprioceptive sensors. However, the complicated three-dimensional (3D) configurations of the soft robot can be difficult to interpret using traditional visualization techniques. In this work, we present an open-source framework for real-time 3D reconstruction of soft robots in eXtended Reality (Augmented and Virtual Reality), based on signals from their proprioceptive sensors. This framework has a Robot Operating System (ROS) backbone, allowing for easy integration with existing soft robot control algorithms for intuitive and real-time teleoperation. This approach is demonstrated in Augmented Reality using a Microsoft Hololens device and runs at up to 60 FPS. We explore the influence that system parameters such as mesh density and armature complexity have on the reconstruction&#39;s key performance metrics (i.e., speed, scalability). The open-source framework is expected to function as a platform for future research and developments on real-time remote control of soft robots operating in environments that impede direct observation of the robot.},
  archive      = {J_FROBT},
  author       = {Borges, Elvis I. A. and Rieder, Jonas S. I. and Aschenbrenner, Doris and Scharff, Rob B. N.},
  doi          = {10.3389/frobt.2022.810328},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {810328},
  shortjournal = {Front. Robot. AI},
  title        = {Framework for armature-based 3D shape reconstruction of sensorized soft robots in eXtended reality},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trend technologies for robotic fertilization process in row
crops. <em>FROBT</em>, <em>9</em>, 808484. (<a
href="https://doi.org/10.3389/frobt.2022.808484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of new sensory and robotic technologies in recent years and the increase in the consumption of organic vegetables have allowed the generation of specific applications around precision agriculture seeking to satisfy market demand. This article analyzes the use and advantages of specific optical sensory systems for data acquisition and processing in precision agriculture for Robotic Fertilization process. The SUREVEG project evaluates the benefits of growing vegetables in rows, using different technological tools like sensors, embedded systems, and robots, for this purpose. A robotic platform has been developed consisting of Laser Sick AG LMS100 × 3, Multispectral, RGB sensors, and a robotic arm equipped with a fertilization system. Tests have been developed with the robotic platform in cabbage and red cabbage crops, information captured with the different sensors, allowed to reconstruct rows crops and extract information for fertilization with the robotic arm. The main advantages of each sensory have been analyzed with an quantitative comparison, based on information provided by each one; such as Normalized Difference Vegetation Index index, RGB Histograms, Point Cloud Clusters). Robot Operating System processes this information to generate trajectory planning with the robotic arm and apply the individual treatment in plants. Main results show that the vegetable characterization has been carried out with an efficiency of 93.1% using Point Cloud processing, while the vegetable detection has obtained an error of 4.6% through RGB images.},
  archive      = {J_FROBT},
  author       = {Cruz Ulloa, Christyan and Krus, Anne and Barrientos, Antonio and del Cerro, Jaime and Valero, Constantino},
  doi          = {10.3389/frobt.2022.808484},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {808484},
  shortjournal = {Front. Robot. AI},
  title        = {Trend technologies for robotic fertilization process in row crops},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An accessible, open-source dexterity test: Evaluating the
grasping and dexterous manipulation capabilities of humans and robots.
<em>FROBT</em>, <em>9</em>, 808154. (<a
href="https://doi.org/10.3389/frobt.2022.808154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the dexterity of human and robotic hands through appropriate benchmarks, scores, and metrics is of paramount importance for determining how skillful humans are and for designing and developing new bioinspired or even biomimetic end-effectors (e.g., robotic grippers and hands). Dexterity tests have been used in industrial and medical settings to assess how dexterous the hands of workers and surgeons are as well as in robotic rehabilitation settings to determine the improvement or deterioration of the hand function after a stroke or a surgery. In robotics, having a comprehensive dexterity test can allow us to evaluate and compare grippers and hands irrespectively of their design characteristics. However, there is a lack of well defined metrics, benchmarks, and tests that quantify robot dexterity. Previous work has focused on a number of widely accepted functional tests that are used for the evaluation of manual dexterity and human hand function improvement post injury. Each of these tests focuses on a different set of specific tasks and objects. Deriving from these tests, this work proposes a new modular, affordable, accessible, open-source dexterity test for both humans and robots. This test evaluates the grasping and manipulation capabilities by combining the features and best practices of the aforementioned tests, as well as new task categories specifically designed to evaluate dexterous manipulation capabilities. The dexterity test and the accompanying benchmarks allow us to determine the overall hand function recovery and dexterity of robotic end-effectors with ease. More precisely, a dexterity score that ranges from 0 (simplistic, non-dexterous system) to 1 (human-like system) is calculated using the weighted sum of the accuracy and task execution speed subscores. It should also be noted that the dexterity of a robotic system can be evaluated assessing the efficiency of either the robotic hardware, or the robotic perception system, or both. The test and the benchmarks proposed in the study have been validated using extensive human and robot trials. The human trials have been used to determine the baseline scores for the evaluation system. The results show that the time required to complete the tasks reduces significantly with trials indicating a clear learning curve in mastering the dexterous manipulation capabilities associated with the imposed tasks. Finally, the time required to complete the tasks with restricted tactile feedback is significantly higher indicating its importance.},
  archive      = {J_FROBT},
  author       = {Elangovan, Nathan and Chang, Che-Ming and Gao, Geng and Liarokapis, Minas},
  doi          = {10.3389/frobt.2022.808154},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {808154},
  shortjournal = {Front. Robot. AI},
  title        = {An accessible, open-source dexterity test: Evaluating the grasping and dexterous manipulation capabilities of humans and robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bending properties of an extensile fluidic artificial
muscle. <em>FROBT</em>, <em>9</em>, 804095. (<a
href="https://doi.org/10.3389/frobt.2022.804095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low stiffness, large stroke, and axial force capabilities make Extensile Fluidic Artificial Muscles (EFAMs) a feasible soft actuator for continuum soft robots. EFAMs can be used to construct soft actuated structures that feature large deformation and enable soft robots to access large effective workspaces. Although FAM axial properties have been well studied, their bending behavior is not well characterized in the literature. Static and dynamic bending properties of a cantilevered EFAM specimen were investigated over a pressure range of 5–100 psi. The static properties were then estimated using an Euler-Bernoulli beam model and discrete elastic rod models. The experiments provided data for the determination of bending stiffness, damping ratio, and natural frequency of the tested specimen. The bending stiffness and the damping ratio were found to change fourfold over the pressure range. Experimentally validated bending properties of the EFAM presented insights into structural and control considerations of soft robots. Future work will utilize the data and models obtained in this study to predict the behavior of an EFAM-actuated continuum robot carrying payloads.},
  archive      = {J_FROBT},
  author       = {Garbulinski, Jacek and Wereley, Norman M.},
  doi          = {10.3389/frobt.2022.804095},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {804095},
  shortjournal = {Front. Robot. AI},
  title        = {Bending properties of an extensile fluidic artificial muscle},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robot learning from randomized simulations: A review.
<em>FROBT</em>, <em>9</em>, 799893. (<a
href="https://doi.org/10.3389/frobt.2022.799893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of deep learning has caused a paradigm shift in robotics research, favoring methods that require large amounts of data. Unfortunately, it is prohibitively expensive to generate such data sets on a physical platform. Therefore, state-of-the-art approaches learn in simulation where data generation is fast as well as inexpensive and subsequently transfer the knowledge to the real robot (sim-to-real). Despite becoming increasingly realistic, all simulators are by construction based on models, hence inevitably imperfect. This raises the question of how simulators can be modified to facilitate learning robot control policies and overcome the mismatch between simulation and reality, often called the “reality gap.” We provide a comprehensive review of sim-to-real research for robotics, focusing on a technique named “domain randomization” which is a method for learning from randomized simulations.},
  archive      = {J_FROBT},
  author       = {Muratore, Fabio and Ramos, Fabio and Turk, Greg and Yu, Wenhao and Gienger, Michael and Peters, Jan},
  doi          = {10.3389/frobt.2022.799893},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {799893},
  shortjournal = {Front. Robot. AI},
  title        = {Robot learning from randomized simulations: A review},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive centipede walking via synergetic coupling between
decentralized control and flexible body dynamics. <em>FROBT</em>,
<em>9</em>, 797566. (<a
href="https://doi.org/10.3389/frobt.2022.797566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-legged animals such as myriapods can locomote on unstructured rough terrain using their flexible bodies and legs. This highly adaptive locomotion emerges through the dynamic interactions between an animal’s nervous system, its flexible body, and the environment. Previous studies have primarily focused on either adaptive leg control or the passive compliance of the body parts and have shown how each enhanced adaptability to complex terrains in multi-legged locomotion. However, the essential mechanism considering both the adaptive locomotor circuits and bodily flexibility remains unclear. In this study, we focused on centipedes and aimed to understand the well-balanced coupling between the two abovementioned mechanisms for rough terrain walking by building a neuromechanical model based on behavioral findings. In the behavioral experiment, we observed a centipede walking when part of the terrain was temporarily removed and thereafter restored. We found that the ground contact sense of each leg was essential for generating rhythmic leg motions and also for establishing adaptive footfall patterns between adjacent legs. Based on this finding, we proposed decentralized control mechanisms using ground contact sense and implemented them into a physical centipede model with flexible bodies and legs. In the simulations, our model self-organized the typical gait on flat terrain and adaptive walking during gap crossing, which were similar to centipedes. Furthermore, we demonstrated that the locomotor performance deteriorated on rough terrain when adaptive leg control was removed or when the body was rigid, which indicates that both the adaptive leg control and the flexible body are essential for adaptive locomotion. Thus, our model is expected to capture the possible essential mechanisms underlying adaptive centipede walking and pave the way for designing multi-legged robots with high adaptability to irregular terrain.},
  archive      = {J_FROBT},
  author       = {Yasui, Kotaro and Takano , Shunsuke and Kano , Takeshi and Ishiguro , Akio},
  doi          = {10.3389/frobt.2022.797566},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {797566},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive centipede walking via synergetic coupling between decentralized control and flexible body dynamics},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active inference and epistemic value in graphical models.
<em>FROBT</em>, <em>9</em>, 794464. (<a
href="https://doi.org/10.3389/frobt.2022.794464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Free Energy Principle (FEP) postulates that biological agents perceive and interact with their environment in order to minimize a Variational Free Energy (VFE) with respect to a generative model of their environment. The inference of a policy (future control sequence) according to the FEP is known as Active Inference (AIF). The AIF literature describes multiple VFE objectives for policy planning that lead to epistemic (information-seeking) behavior. However, most objectives have limited modeling flexibility. This paper approaches epistemic behavior from a constrained Bethe Free Energy (CBFE) perspective. Crucially, variational optimization of the CBFE can be expressed in terms of message passing on free-form generative models. The key intuition behind the CBFE is that we impose a point-mass constraint on predicted outcomes, which explicitly encodes the assumption that the agent will make observations in the future. We interpret the CBFE objective in terms of its constituent behavioral drives. We then illustrate resulting behavior of the CBFE by planning and interacting with a simulated T-maze environment. Simulations for the T-maze task illustrate how the CBFE agent exhibits an epistemic drive, and actively plans ahead to account for the impact of predicted outcomes. Compared to an EFE agent, the CBFE agent incurs expected reward in significantly more environmental scenarios. We conclude that CBFE optimization by message passing suggests a general mechanism for epistemic-aware AIF in free-form generative models.},
  archive      = {J_FROBT},
  author       = {van de Laar, Thijs and Koudahl, Magnus and van Erp, Bart and de Vries, Bert},
  doi          = {10.3389/frobt.2022.794464},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {794464},
  shortjournal = {Front. Robot. AI},
  title        = {Active inference and epistemic value in graphical models},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A minimally invasive approach towards “ecosystem hacking”
with honeybees. <em>FROBT</em>, <em>9</em>, 791921. (<a
href="https://doi.org/10.3389/frobt.2022.791921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Honey bees live in colonies of thousands of individuals, that not only need to collaborate with each other but also to interact intensively with their ecosystem. A small group of robots operating in a honey bee colony and interacting with the queen bee, a central colony element, has the potential to change the collective behavior of the entire colony and thus also improve its interaction with the surrounding ecosystem. Such a system can be used to study and understand many elements of bee behavior within hives that have not been adequately researched. We discuss here the applicability of this technology for ecosystem protection: A novel paradigm of a minimally invasive form of conservation through “Ecosystem Hacking”. We discuss the necessary requirements for such technology and show experimental data on the dynamics of the natural queen’s court, initial designs of biomimetic robotic surrogates of court bees, and a multi-agent model of the queen bee court system. Our model is intended to serve as an AI-enhanceable coordination software for future robotic court bee surrogates and as a hardware controller for generating nature-like behavior patterns for such a robotic ensemble. It is the first step towards a team of robots working in a bio-compatible way to study honey bees and to increase their pollination performance, thus achieving a stabilizing effect at the ecosystem level.},
  archive      = {J_FROBT},
  author       = {Stefanec, Martin and Hofstadler, Daniel N. and Krajník, Tomáš and Turgut, Ali Emre and Alemdar, Hande and Lennox, Barry and Şahin, Erol and Arvin, Farshad and Schmickl, Thomas},
  doi          = {10.3389/frobt.2022.791921},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {791921},
  shortjournal = {Front. Robot. AI},
  title        = {A minimally invasive approach towards “Ecosystem hacking” with honeybees},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Formal verification of real-time autonomous robots: An
interdisciplinary approach. <em>FROBT</em>, <em>9</em>, 791757. (<a
href="https://doi.org/10.3389/frobt.2022.791757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the severe consequences of their possible failure, robotic systems must be rigorously verified as to guarantee that their behavior is correct and safe. Such verification, carried out on a model, needs to cover various behavioral properties (e.g., safety and liveness), but also, given the timing constraints of robotic missions, real-time properties (e.g., schedulability and bounded response). In addition, in order to obtain valid and useful verification results, the model must faithfully represent the underlying robotic system and should therefore take into account all possible behaviors of the robotic software under the actual hardware and OS constraints (e.g., the scheduling policy and the number of cores). These requirements put the rigorous verification of robotic systems at the intersection of at least three communities: the robotic community, the formal methods community, and the real-time systems community. Verifying robotic systems is thus a complex, interdisciplinary task that involves a number of disciplines/techniques (e.g., model checking, schedulability analysis, component-based design) and faces a number of challenges (e.g., formalization, automation, scalability). For instance, the use of formal verification (formal methods community) is hindered by the state-space explosion problem, whereas schedulability analysis (real-time systems) is not suitable for behavioral properties. Moreover, current real-time implementations of robotic software are limited in terms of predictability and efficiency, leading to, e.g., unnecessary latencies. This is flagrant, in particular, at the level of locking protocols in robotic software. Such situation may benefit from major theoretical and practical findings of the real-time systems community. In this paper, we propose an interdisciplinary approach that, by joining forces of the different communities, provides a scalable and unified means to efficiently implement and rigorously verify real-time robots. First, we propose a scalable two-step verification solution that combines formal methods and schedulability analysis to verify both behavioral and real-time properties. Second, we devise a new multi-resource locking mechanism that is efficient, predictable, and suitable for real-time robots and show how it improves the latter’s real-time behavior. In both cases, we show, using a real drone example, how our approach compares favorably to that in the literature. This paper is a major extension of the RTCSA 2020 publication “A Two-Step Hybrid Approach for Verifying Real-Time Robotic Systems.”},
  archive      = {J_FROBT},
  author       = {Foughali, Mohammed and Zuepke, Alexander},
  doi          = {10.3389/frobt.2022.791757},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {791757},
  shortjournal = {Front. Robot. AI},
  title        = {Formal verification of real-time autonomous robots: An interdisciplinary approach},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AEROS: AdaptivE RObust least-squares for graph-based SLAM.
<em>FROBT</em>, <em>9</em>, 789444. (<a
href="https://doi.org/10.3389/frobt.2022.789444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robot localisation and mapping, outliers are unavoidable when loop-closure measurements are taken into account. A single false-positive loop-closure can have a very negative impact on SLAM problems causing an inferior trajectory to be produced or even for the optimisation to fail entirely. To address this issue, popular existing approaches define a hard switch for each loop-closure constraint. This paper presents AEROS, a novel approach to adaptively solve a robust least-squares minimisation problem by adding just a single extra latent parameter. It can be used in the back-end component of the SLAM system to enable generalised robust cost minimisation by simultaneously estimating the continuous latent parameter along with the set of sensor poses in a single joint optimisation. This leads to a very closely curve fitting on the distribution of the residuals, thereby reducing the effect of outliers. Additionally, we formulate the robust optimisation problem using standard Gaussian factors so that it can be solved by direct application of popular incremental estimation approaches such as iSAM. Experimental results on publicly available synthetic datasets and real LiDAR-SLAM datasets collected from the 2D and 3D LiDAR systems show the competitiveness of our approach with the state-of-the-art techniques and its superiority on real world scenarios.},
  archive      = {J_FROBT},
  author       = {Ramezani, Milad and Mattamala, Matias and Fallon, Maurice},
  doi          = {10.3389/frobt.2022.789444},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {789444},
  shortjournal = {Front. Robot. AI},
  title        = {AEROS: AdaptivE RObust least-squares for graph-based SLAM},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sustainable solutions for sea monitoring with robotic
sailboats: N-boat and f-boat twins. <em>FROBT</em>, <em>9</em>, 788212.
(<a href="https://doi.org/10.3389/frobt.2022.788212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic management and production of internal energy in autonomous robots is becoming a research topic with growing importance, especially for platforms that target long-endurance missions, with long-range and duration. It is fundamental for autonomous vehicles to have energy self-generation capability to improve energy autonomy, especially in situations where refueling is not viable, such as an autonomous sailboat in ocean traversing. Hence, the development of energy estimation and management solutions is an important research topic to better optimize the use of available energy supply and generation potential. In this work, we revisit the challenges behind the project design and construction for two fully autonomous sailboats and propose a methodology based on the Restricted Boltzmann Machine (RBM) in order to find the best way to manage the supplementary energy generated by solar panels. To verify the approach, we introduce a case study with our two developed sailboats that have planned payload with electric and electronics, and one of them is equipped with an electrical engine that may eventually help with the sailboat propulsion. Our current results show that it is possible to augment the system confidence level for the potential energy that can be harvested from the environment and the remaining energy stored, optimizing the energy usage of autonomous vehicles and improving their energy robustness.},
  archive      = {J_FROBT},
  author       = {Negreiros, Alvaro P. F. and Correa, Wanderson S. and de Araujo, André P. D. and Santos, Davi H. and Vilas-Boas, João M. and Dias, Daniel H. N. and Clua, Esteban W. G. and Gonçalves, Luiz M. G.},
  doi          = {10.3389/frobt.2022.788212},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {788212},
  shortjournal = {Front. Robot. AI},
  title        = {Sustainable solutions for sea monitoring with robotic sailboats: N-boat and F-boat twins},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Embodied digital technologies: First insights in the social
and legal perception of robots and users of prostheses. <em>FROBT</em>,
<em>9</em>, 787970. (<a
href="https://doi.org/10.3389/frobt.2022.787970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New bionic technologies and robots are becoming increasingly common in workspaces and private spheres. It is thus crucial to understand concerns regarding their use in social and legal terms and the qualities they should possess to be accepted as ‘co-workers’. Previous research in these areas used the Stereotype Content Model to investigate, for example, attributions of Warmth and Competence towards people who use bionic prostheses, cyborgs, and robots. In the present study, we propose to differentiate the Warmth dimension into the dimensions of Sociability and Morality to gain deeper insight into how people with or without bionic prostheses are perceived. In addition, we extend our research to the perception of robots. Since legal aspects need to be considered if robots are expected to be ‘co-workers’, for the first time, we also evaluated current perceptions of robots in terms of legal aspects. We conducted two studies: In Study 1, participants rated visual stimuli of individuals with or without disabilities and low- or high-tech prostheses, and robots of different levels of Anthropomorphism in terms of perceived Competence, Sociability, and Morality. In Study 2, participants rated robots of different levels of Anthropomorphism in terms of perceived Competence, Sociability, and Morality, and additionally, Legal Personality, and Decision-Making Authority. We also controlled for participants’ personality. Results showed that attributions of Competence and Morality varied as a function of the technical sophistication of the prostheses. For robots, Competence attributions were negatively related to Anthropomorphism. Perception of Sociability, Morality, Legal Personality, and Decision-Making Authority varied as functions of Anthropomorphism. Overall, this study contributes to technological design, which aims to ensure high acceptance and minimal undesirable side effects, both with regard to the application of bionic instruments and robotics. Additionally, first insights into whether more anthropomorphized robots will need to be considered differently in terms of legal practice are given.},
  archive      = {J_FROBT},
  author       = {Mandl, Sarah and Bretschneider, Maximilian and Meyer, Stefanie and Gesmann-Nuissl, Dagmar and Asbrock, Frank and Meyer, Bertolt and Strobel, Anja},
  doi          = {10.3389/frobt.2022.787970},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {787970},
  shortjournal = {Front. Robot. AI},
  title        = {Embodied digital technologies: First insights in the social and legal perception of robots and users of prostheses},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-smooth control barrier navigation functions for STL
motion planning. <em>FROBT</em>, <em>9</em>, 782783. (<a
href="https://doi.org/10.3389/frobt.2022.782783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports on a new approach to Signal Temporal Logic (STL) control synthesis, that 1) utilizes a navigation function as the basis to construct a Control Barrier Function (CBF), and 2) composes navigation function-based barrier functions using nonsmooth mappings to encode Boolean operations between the predicates that those barrier functions encode. Because of these two key features, the reported approach 1) covers a larger fragment of STL compared to existing approaches, 2) alleviates the computational cost associated with evaluation of the control law for the system in existing STL control barrier function methodologies, and 3) simultaneously relaxes some of the conservativeness of smooth combinations of barrier functions as a means of implementing Boolean operators. The paper demonstrates the efficacy of this new approach with three simulation case studies, one aiming at illustrating how complex STL motion planning specification can be realized, the second highlights the less-conservativeness of the approach in comparison to the existing methods, and another that shows how this technology can be brought to bear to push the envelope in the context of human-robot social interaction.},
  archive      = {J_FROBT},
  author       = {Zehfroosh, Ashkan and Tanner, Herbert G.},
  doi          = {10.3389/frobt.2022.782783},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {782783},
  shortjournal = {Front. Robot. AI},
  title        = {Non-smooth control barrier navigation functions for STL motion planning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of a step-and-brake controller of a human
based on prediction of capturability. <em>FROBT</em>, <em>9</em>,
729593. (<a href="https://doi.org/10.3389/frobt.2022.729593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An explicit mathematical form of a human’s step-and-brake controller is identified through motion measurement of the human subject. The controller was originally designed for biped robots based on the reduced-order dynamics and the model predictive control scheme with the terminal capturability condition, and is compatible with both stand-still and stepping motions. The minimal number of parameters facilitates the identification from measured trajectories of the center of mass and the zero-moment point of the human subject. In spite of the minimality, the result only suited the human’s behaviors well with slight modifications of the model by taking direction-dependency of the natural falling speed and the inertial torque about the center of mass into account. Furthermore, the parameters are successfully identified even from the first half of motion sequence, which means that the proposed method is available in designing on-the-fly systems to evaluate balancing abilities of humans and to assist balances of humans in walking.},
  archive      = {J_FROBT},
  author       = {Kojima, Miharu and Sugihara, Tomomichi},
  doi          = {10.3389/frobt.2022.729593},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {729593},
  shortjournal = {Front. Robot. AI},
  title        = {Identification of a step-and-brake controller of a human based on prediction of capturability},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Designing expandable-structure robots for human-robot
interaction. <em>FROBT</em>, <em>9</em>, 719639. (<a
href="https://doi.org/10.3389/frobt.2022.719639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we survey the emerging design space of expandable structures in robotics, with a focus on how such structures may improve human-robot interactions. We detail various implementation considerations for researchers seeking to integrate such structures in their own work and describe how expandable structures may lead to novel forms of interaction for a variety of different robots and applications, including structures that enable robots to alter their form to augment or gain entirely new capabilities, such as enhancing manipulation or navigation, structures that improve robot safety, structures that enable new forms of communication, and structures for robot swarms that enable the swarm to change shape both individually and collectively. To illustrate how these considerations may be operationalized, we also present three case studies from our own research in expandable structure robots, sharing our design process and our findings regarding how such structures enable robots to produce novel behaviors that may capture human attention, convey information, mimic emotion, and provide new types of dynamic affordances.},
  archive      = {J_FROBT},
  author       = {Hedayati, Hooman and Suzuki, Ryo and Rees, Wyatt and Leithinger, Daniel and Szafir, Daniel},
  doi          = {10.3389/frobt.2022.719639},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {719639},
  shortjournal = {Front. Robot. AI},
  title        = {Designing expandable-structure robots for human-robot interaction},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards robot-assisted therapy for children with autism—the
ontological knowledge models and reinforcement learning-based
algorithms. <em>FROBT</em>, <em>9</em>, 713964. (<a
href="https://doi.org/10.3389/frobt.2022.713964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are more and more present in our lives, particularly in the health sector. In therapeutic centers, some therapists are beginning to explore various tools like video games, Internet exchanges, and robot-assisted therapy. These tools will be at the disposal of these professionals as additional resources that can support them to assist their patients intuitively and remotely. The humanoid robot can capture young children’s attention and then attract the attention of researchers. It can be considered as a play partner and can directly interact with children or without a third party’s presence. It can equally perform repetitive tasks that humans cannot achieve in the same way. Moreover, humanoid robots can assist a therapist by allowing him to teleoperated and interact from a distance. In this context, our research focuses on robot-assisted therapy and introduces a humanoid social robot in a pediatric hospital care unit. That will be performed by analyzing many aspects of the child’s behavior, such as verbal interactions, gestures and facial expressions, etc. Consequently, the robot can reproduce consistent experiences and actions for children with communication capacity restrictions. This work is done by applying a novel approach based on deep learning and reinforcement learning algorithms supported by an ontological knowledge base that contains relevant information and knowledge about patients, screening tests, and therapies. In this study, we realized a humanoid robot that will assist a therapist by equipping the robot NAO: 1) to detect whether a child is autistic or not using a convolutional neural network, 2) to recommend a set of therapies based on a selection algorithm using a correspondence matrix between screening test and therapies, and 2) to assist and monitor autistic children by executing tasks that require those therapies.},
  archive      = {J_FROBT},
  author       = {Salhi, Intissar and Qbadou, Mohammed and Gouraguine, Soukaina and Mansouri, Khalifa and Lytridis, Chris and Kaburlasos, Vassilis},
  doi          = {10.3389/frobt.2022.713964},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {713964},
  shortjournal = {Front. Robot. AI},
  title        = {Towards robot-assisted therapy for children with Autism—The ontological knowledge models and reinforcement learning-based algorithms},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trust and cooperation. <em>FROBT</em>, <em>9</em>, 676767.
(<a href="https://doi.org/10.3389/frobt.2022.676767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We AI researchers are concerned about the potential impact of artificially intelligent systems on humanity. In the first half of this essay, I argue that ethics is an evolved body of cultural knowledge that (among other things) encourages individual behavior that promotes the welfare of the society (which in turn promotes the welfare of its individual members). The causal paths involved suggest that trust and cooperation play key roles in this process. In the second half of the essay, I consider whether the key role of trust exposes our society to existential threats. This possibility arises because decision-making agents (humans, AIs, and others) necessarily rely on simplified models to cope with the unbounded complexity of our physical and social world. By selecting actions to maximize a utility measure, a well-formulated game theory model can be a powerful and valuable tool. However, a poorly-formulated game theory model may be uniquely harmful, in cases where the action it recommends deliberately exploits the vulnerability and violates the trust of cooperative partners. Widespread use of such models can erode the overall levels of trust in the society. Cooperation is reduced, resources are constrained, and there is less ability to meet challenges or take advantage of opportunities. Loss of trust will affect humanity’s ability to respond to existential threats such as climate change.},
  archive      = {J_FROBT},
  author       = {Kuipers, Benjamin},
  doi          = {10.3389/frobt.2022.676767},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {676767},
  shortjournal = {Front. Robot. AI},
  title        = {Trust and cooperation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Robotic in-situ servicing, assembly and
manufacturing. <em>FROBT</em>, <em>9</em>, 887506. (<a
href="https://doi.org/10.3389/frobt.2022.887506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Carignan, Craig R. and Detry, Renaud and Saaj, Mini Chakravarthini and Marani, Giacomo and Vander Hook, Joshua D.},
  doi          = {10.3389/frobt.2022.887506},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {887506},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotic in-situ servicing, assembly and manufacturing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An invitation to greater use of matthews correlation
coefficient in robotics and artificial intelligence. <em>FROBT</em>,
<em>9</em>, 876814. (<a
href="https://doi.org/10.3389/frobt.2022.876814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Chicco, Davide and Jurman, Giuseppe},
  doi          = {10.3389/frobt.2022.876814},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {876814},
  shortjournal = {Front. Robot. AI},
  title        = {An invitation to greater use of matthews correlation coefficient in robotics and artificial intelligence},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Biological and robotic inter-limb coordination.
<em>FROBT</em>, <em>9</em>, 875493. (<a
href="https://doi.org/10.3389/frobt.2022.875493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Owaki, Dai and Manoonpong, Poramate and Ayali, Amir},
  doi          = {10.3389/frobt.2022.875493},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {875493},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Biological and robotic inter-limb coordination},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and prototyping of an underactuated hand exoskeleton
with fingers coupled by a gear-based differential. <em>FROBT</em>,
<em>9</em>, 862340. (<a
href="https://doi.org/10.3389/frobt.2022.862340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeletons and more in general wearable mechatronic devices represent a promising opportunity for rehabilitation and assistance to people presenting with temporary and/or permanent diseases. However, there are still some limits in the diffusion of robotic technologies for neuro-rehabilitation, notwithstanding their technological developments and evidence of clinical effectiveness. One of the main bottlenecks that constrain the complexity, weight, and costs of exoskeletons is represented by the actuators. This problem is particularly evident in devices designed for the upper limb, and in particular for the hand, in which dimension limits and kinematics complexity are particularly challenging. This study presents the design and prototyping of a hand finger exoskeleton. In particular, we focus on the design of a gear-based differential mechanism aimed at coupling the motion of two adjacent fingers and limiting the complexity and costs of the system. The exoskeleton is able to actuate the flexion/extension motion of the fingers and apply bidirectional forces, that is, it is able to both open and close the fingers. The kinematic structure of the finger actuation system has the peculiarity to present three DoFs when the exoskeleton is not worn and one DoF when it is worn, allowing better adaptability and higher wearability. The design of the gear-based differential is inspired by the mechanism widely used in the automotive field; it allows actuating two fingers with one actuator only, keeping their movements independent.},
  archive      = {J_FROBT},
  author       = {Dragusanu, Mihai and Troisi, Danilo and Villani, Alberto and Prattichizzo, Domenico and Malvezzi, Monica},
  doi          = {10.3389/frobt.2022.862340},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {862340},
  shortjournal = {Front. Robot. AI},
  title        = {Design and prototyping of an underactuated hand exoskeleton with fingers coupled by a gear-based differential},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time avoidance of ionising radiation using layered
costmaps for mobile robots. <em>FROBT</em>, <em>9</em>, 862067. (<a
href="https://doi.org/10.3389/frobt.2022.862067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans in hazardous environments take actions to reduce unnecessary risk, including limiting exposure to radioactive materials where ionising radiation can be a threat to human health. Robots can adopt the same approach of risk avoidance to minimise exposure to radiation, therefore limiting damage to electronics and materials. Reducing a robot’s exposure to radiation results in longer operational lifetime and better return on investment for nuclear sector stakeholders. This work achieves radiation avoidance through the use of layered costmaps, to inform path planning algorithms of this additional risk. Interpolation of radiation observations into the configuration space of the robot is accomplished using an inverse distance weighting approach. This technique was successfully demonstrated using an unmanned ground vehicle running the Robot Operating System equipped with compatible gamma radiation sensors, both in simulation and in real-world mock inspection missions, where the vehicle was exposed to radioactive materials in Lancaster University’s Neutron Laboratory. The addition of radiation avoidance functionality was shown to reduce total accumulated dose to background levels in real-world deployment and up to a factor of 10 in simulation.},
  archive      = {J_FROBT},
  author       = {West, Andrew and Wright, Thomas and Tsitsimpelis, Ioannis and Groves, Keir and Joyce, Malcolm J. and Lennox, Barry},
  doi          = {10.3389/frobt.2022.862067},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {862067},
  shortjournal = {Front. Robot. AI},
  title        = {Real-time avoidance of ionising radiation using layered costmaps for mobile robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Humans can’t resist robot eyes – reflexive cueing with
pseudo-social stimuli. <em>FROBT</em>, <em>9</em>, 848295. (<a
href="https://doi.org/10.3389/frobt.2022.848295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint attention is a key mechanism for humans to coordinate their social behavior. Whether and how this mechanism can benefit the interaction with pseudo-social partners such as robots is not well understood. To investigate the potential use of robot eyes as pseudo-social cues that ease attentional shifts we conducted an online study using a modified spatial cueing paradigm. The cue was either a non-social (arrow), a pseudo-social (two versions of an abstract robot eye), or a social stimulus (photographed human eyes) that was presented either paired (e.g. two eyes) or single (e.g. one eye). The latter was varied to separate two assumed triggers of joint attention: the social nature of the stimulus, and the additional spatial information that is conveyed only by paired stimuli. Results support the assumption that pseudo-social stimuli, in our case abstract robot eyes, have the potential to facilitate human-robot interaction as they trigger reflexive cueing. To our surprise, actual social cues did not evoke reflexive shifts in attention. We suspect that the robot eyes elicited the desired effects because they were human-like enough while at the same time being much easier to perceive than human eyes, due to a design with strong contrasts and clean lines. Moreover, results indicate that for reflexive cueing it does not seem to make a difference if the stimulus is presented single or paired. This might be a first indicator that joint attention depends rather on the stimulus’ social nature or familiarity than its spatial expressiveness. Overall, the study suggests that using paired abstract robot eyes might be a good design practice for fostering a positive perception of a robot and to facilitate joint attention as a precursor for coordinated behavior.},
  archive      = {J_FROBT},
  author       = {Onnasch, Linda and Kostadinova, Eleonora and Schweidler, Paul},
  doi          = {10.3389/frobt.2022.848295},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {848295},
  shortjournal = {Front. Robot. AI},
  title        = {Humans can’t resist robot eyes – reflexive cueing with pseudo-social stimuli},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Power amplification for jumping soft robots actuated by
artificial muscles. <em>FROBT</em>, <em>9</em>, 844282. (<a
href="https://doi.org/10.3389/frobt.2022.844282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots composed of soft materials can passively adapt to constrained environments and mitigate damage due to impact. Given these features, jumping has been explored as a mode of locomotion for soft robots. However, for mesoscale jumping robots, lightweight and compact actuation are required. Previous work focused on systems powered by fluids, combustion, smart materials, electromagnetic, or electrostatic motors, which require one or more of the following: large rigid components, external power supplies, components of specific, pre-defined sizes, or fast actuation. In this work, we propose an approach to design and fabricate an electrically powered soft amplification mechanism to enable untethered mesoscale systems with continuously tunable performance. We used the tunable geometry of a liquid crystal elastomer actuator, an elastic hemispherical shell, and a pouch motor for active latching to achieve rapid motions for jumping despite the slow contraction rate of the actuator. Our system amplified the power output of the LCE actuator by a factor of 8.12 × 103 with a specific power of 26.4 W/kg and jumped to a height of 55.6 mm (with a 20 g payload). This work enables future explorations for electrically untethered soft systems capable of rapid motions (e.g., jumping).},
  archive      = {J_FROBT},
  author       = {Fernandes Minori, Adriane and Jadhav, Saurabh and Chen, Haojin and Fong, Samantha and Tolley, Michael T.},
  doi          = {10.3389/frobt.2022.844282},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {844282},
  shortjournal = {Front. Robot. AI},
  title        = {Power amplification for jumping soft robots actuated by artificial muscles},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning-based complete coverage path planning with
re-joint and obstacle fusion paradigm. <em>FROBT</em>, <em>9</em>,
843816. (<a href="https://doi.org/10.3389/frobt.2022.843816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of autonomy into the precision agriculture process, environmental exploration, disaster response, and other fields, one of the global demands is to navigate autonomous vehicles to completely cover entire unknown environments. In the previous complete coverage path planning (CCPP) research, however, autonomous vehicles need to consider mapping, obstacle avoidance, and route planning simultaneously during operating in the workspace, which results in an extremely complicated and computationally expensive navigation system. In this study, a new framework is developed in light of a hierarchical manner with the obtained environmental information and gradually solving navigation problems layer by layer, consisting of environmental mapping, path generation, CCPP, and dynamic obstacle avoidance. The first layer based on satellite images utilizes a deep learning method to generate the CCPP trajectory through the position of the autonomous vehicle. In the second layer, an obstacle fusion paradigm in the map is developed based on the unmanned aerial vehicle (UAV) onboard sensors. A nature-inspired algorithm is adopted for obstacle avoidance and CCPP re-joint. Equipped with the onboard LIDAR equipment, autonomous vehicles, in the third layer, dynamically avoid moving obstacles. Simulated experiments validate the effectiveness and robustness of the proposed framework.},
  archive      = {J_FROBT},
  author       = {Lei, Tingjun and Luo, Chaomin and Jan, Gene Eu and Bi, Zhuming},
  doi          = {10.3389/frobt.2022.843816},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {843816},
  shortjournal = {Front. Robot. AI},
  title        = {Deep learning-based complete coverage path planning with re-joint and obstacle fusion paradigm},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Artificial intelligence based patient-specific preoperative
planning algorithm for total knee arthroplasty. <em>FROBT</em>,
<em>9</em>, 840282. (<a
href="https://doi.org/10.3389/frobt.2022.840282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies have shown that the manufacturer’s default preoperative plans for total knee arthroplasty with patient-specific guides require frequent, time-consuming changes by the surgeon. Currently, no research has been done on predicting preoperative plans for orthopedic surgery using machine learning. Therefore, this study aims to evaluate whether artificial intelligence (AI) driven planning tools can create surgeon and patient-specific preoperative plans that require fewer changes by the surgeon. A dataset of 5409 preoperative plans, including the manufacturer’s default and the plans corrected by 39 surgeons, was collected. Features were extracted from the preoperative plans that describe the implant sizes, position, and orientation in a surgeon- and patient-specific manner. Based on these features, non-linear regression models were employed to predict the surgeon’s corrected preoperative plan. The average number of corrections a surgeon has to make to the preoperative plan generated using AI was reduced by 39.7% compared to the manufacturer’s default plan. The femoral and tibial implant size in the manufacturer’s plan was correct in 68.4% and 73.1% of the cases, respectively, while the AI-based plan was correct in 82.2% and 85.0% of the cases, respectively, compared to the surgeon approved plan. Our method successfully demonstrated the use of machine learning to create preoperative plans in a surgeon- and patient-specific manner for total knee arthroplasty.},
  archive      = {J_FROBT},
  author       = {Lambrechts, Adriaan and Wirix-Speetjens, Roel and Maes, Frederik and Van Huffel, Sabine},
  doi          = {10.3389/frobt.2022.840282},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {840282},
  shortjournal = {Front. Robot. AI},
  title        = {Artificial intelligence based patient-specific preoperative planning algorithm for total knee arthroplasty},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Branching vine robots for unmapped environments.
<em>FROBT</em>, <em>9</em>, 838913. (<a
href="https://doi.org/10.3389/frobt.2022.838913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While exploring complex unmapped spaces is a persistent challenge for robots, plants are able to reliably accomplish this task. In this work we develop branching robots that deploy through an eversion process that mimics key features of plant growth (i.e., apical extension, branching). We show that by optimizing the design of these robots, we can successfully traverse complex terrain even in unseen instances of an environment. By simulating robot growth through a set of known training maps and evaluating performance with a reward heuristic specific to the intended application (i.e., exploration, anchoring), we optimized robot designs with a particle swarm algorithm. We show these optimization efforts transfer from training on known maps to performance on unseen maps in the same type of environment, and that the resulting designs are specialized to the environment used in training. Furthermore, we fabricated several optimized branching everting robot designs and demonstrated key aspects of their performance in hardware. Our branching designs replicated three properties found in nature: anchoring, coverage, and reachability. The branching designs were able to reach 25% more of a given space than non-branching robots, improved anchoring forces by 12.55×, and were able to hold greater than 100× their own mass (i.e., a device weighing 5 g held 575 g). We also demonstrated anchoring with a robot that held a load of over 66.7 N at an internal pressure of 50 kPa. These results show the promise of using branching vine robots for traversing complex and unmapped terrain.},
  archive      = {J_FROBT},
  author       = {Glick, Paul E. and Adibnazari, Iman and Drotman, Dylan and Ruffatto III, Donald and Tolley, Michael T.},
  doi          = {10.3389/frobt.2022.838913},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {838913},
  shortjournal = {Front. Robot. AI},
  title        = {Branching vine robots for unmapped environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crisis ahead? Why human-robot interaction user studies may
have replicability problems and directions for improvement.
<em>FROBT</em>, <em>9</em>, 838116. (<a
href="https://doi.org/10.3389/frobt.2022.838116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a confidence crisis in many scientific disciplines, in particular disciplines researching human behavior, as many effects of original experiments have not been replicated successfully in large-scale replication studies. While human-robot interaction (HRI) is an interdisciplinary research field, the study of human behavior, cognition and emotion in HRI plays also a vital part. Are HRI user studies facing the same problems as other fields and if so, what can be done to overcome them? In this article, we first give a short overview of the replicability crisis in behavioral sciences and its causes. In a second step, we estimate the replicability of HRI user studies mainly 1) by structural comparison of HRI research processes and practices with those of other disciplines with replicability issues, 2) by systematically reviewing meta-analyses of HRI user studies to identify parameters that are known to affect replicability, and 3) by summarizing first replication studies in HRI as direct evidence. Our findings suggest that HRI user studies often exhibit the same problems that caused the replicability crisis in many behavioral sciences, such as small sample sizes, lack of theory, or missing information in reported data. In order to improve the stability of future HRI research, we propose some statistical, methodological and social reforms. This article aims to provide a basis for further discussion and a potential outline for improvements in the field.},
  archive      = {J_FROBT},
  author       = {Leichtmann, Benedikt and Nitsch, Verena and Mara, Martina},
  doi          = {10.3389/frobt.2022.838116},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {838116},
  shortjournal = {Front. Robot. AI},
  title        = {Crisis ahead? why human-robot interaction user studies may have replicability problems and directions for improvement},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social robots in applied settings: A long-term study on
adaptive robotic tutors in higher education. <em>FROBT</em>, <em>9</em>,
831633. (<a href="https://doi.org/10.3389/frobt.2022.831633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning in higher education scenarios requires self-directed learning and the challenging task of self-motivation while individual support is rare. The integration of social robots to support learners has already shown promise to benefit the learning process in this area. In this paper, we focus on the applicability of an adaptive robotic tutor in a university setting. To this end, we conducted a long-term field study implementing an adaptive robotic tutor to support students with exam preparation over three sessions during one semester. In a mixed design, we compared the effect of an adaptive tutor to a control condition across all learning sessions. With the aim to benefit not only motivation but also academic success and the learning experience in general, we draw from research in adaptive tutoring, social robots in education, as well as our own prior work in this field. Our results show that opting in for the robotic tutoring is beneficial for students. We found significant subjective knowledge gain and increases in intrinsic motivation regarding the content of the course in general. Finally, participation resulted in a significantly better exam grade compared to students not participating. However, the extended adaptivity of the robotic tutor in the experimental condition did not seem to enhance learning, as we found no significant differences compared to a non-adaptive version of the robot.},
  archive      = {J_FROBT},
  author       = {Donnermann, Melissa and Schaper, Philipp and Lugrin, Birgit},
  doi          = {10.3389/frobt.2022.831633},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {831633},
  shortjournal = {Front. Robot. AI},
  title        = {Social robots in applied settings: A long-term study on adaptive robotic tutors in higher education},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to centralize dual-arm assembly. <em>FROBT</em>,
<em>9</em>, 830007. (<a
href="https://doi.org/10.3389/frobt.2022.830007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulators are widely used in modern manufacturing processes. However, their deployment in unstructured environments remains an open problem. To deal with the variety, complexity, and uncertainty of real-world manipulation tasks, it is essential to develop a flexible framework with reduced assumptions on the environment characteristics. In recent years, reinforcement learning (RL) has shown great results for single-arm robotic manipulation. However, research focusing on dual-arm manipulation is still rare. From a classical control perspective, solving such tasks often involves complex modeling of interactions between two manipulators and the objects encountered in the tasks, as well as the two robots coupling at a control level. Instead, in this work, we explore the applicability of model-free RL to dual-arm assembly. As we aim to contribute toward an approach that is not limited to dual-arm assembly but dual-arm manipulation in general, we keep modeling efforts at a minimum. Hence, to avoid modeling the interaction between the two robots and the used assembly tools, we present a modular approach with two decentralized single-arm controllers, which are coupled using a single centralized learned policy. We reduce modeling effort to a minimum by using sparse rewards only. Our architecture enables successful assembly and simple transfer from simulation to the real world. We demonstrate the effectiveness of the framework on dual-arm peg-in-hole and analyze sample efficiency and success rates for different action spaces. Moreover, we compare results on different clearances and showcase disturbance recovery and robustness when dealing with position uncertainties. Finally, we zero-shot transfer policies trained in simulation to the real world and evaluate their performance. Videos of the experiments are available at the project website (https://sites.google.com/view/dual-arm-assembly/home).},
  archive      = {J_FROBT},
  author       = {Alles, Marvin and Aljalbout, Elie},
  doi          = {10.3389/frobt.2022.830007},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {830007},
  shortjournal = {Front. Robot. AI},
  title        = {Learning to centralize dual-arm assembly},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Benchmarking whole‐body controllers on the TALOS humanoid
robot. <em>FROBT</em>, <em>9</em>, 826491. (<a
href="https://doi.org/10.3389/frobt.2022.826491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a comparison of three control schemes applied on the commercially available TALOS humanoid robot. The aim is to highlight the advantages and drawbacks of each model applied on three locomotion problems: walking on flat and non-flat terrain and climbing stairs. The different models are based on position control (first and second models) or torque control (third model). The first one uses a hierarchical quadratic program at velocity level. The second one uses a weighted quadratic program named Task Space Inverse Dynamic (TSID) at acceleration level. Finally, the last one also uses TSID but at torque level. The controller performances are compared in simulation, using Gazebo, on the accuracy of their tracking, their energy consumption, and their computational time execution.},
  archive      = {J_FROBT},
  author       = {Ramuzat, N. and Stasse, O. and Boria, S.},
  doi          = {10.3389/frobt.2022.826491},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {826491},
  shortjournal = {Front. Robot. AI},
  title        = {Benchmarking Whole‐Body controllers on the TALOS humanoid robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shared control schemes for middle ear surgery.
<em>FROBT</em>, <em>9</em>, 824716. (<a
href="https://doi.org/10.3389/frobt.2022.824716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the control of a redundant cobot arm to accomplish peg-in-hole insertion tasks in the context of middle ear surgery. It mainly focuses on the development of two shared control laws that combine local measurements provided by position or force sensors with the globally observed visual information. We first investigate the two classical and well-established control modes, i.e., a position-based end-frame tele-operation controller and a comanipulation controller. Based on these two control architectures, we then propose a combination of visual feedback and position/force-based inputs in the same control scheme. In contrast to the conventional control designs where all degrees of freedom (DoF) are equally controlled, the proposed shared controllers allow teleoperation of linear/translational DoFs while the rotational ones are simultaneously handled by a vision-based controller. Such controllers reduce the task complexity, e.g., a complex peg-in-hole task is simplified for the operator to basic translations in the space where tool orientations are automatically controlled. Various experiments are conducted, using a 7-DoF robot arm equipped with a force/torque sensor and a camera, validating the proposed controllers in the context of simulating a minimally invasive surgical procedure. The obtained results in terms of accuracy, ergonomics and rapidity are discussed in this paper.},
  archive      = {J_FROBT},
  author       = {So, Jae-Hun and Sobucki, Stéphane and Szewczyk, Jérôme and Marturi, Naresh and Tamadazte, Brahim},
  doi          = {10.3389/frobt.2022.824716},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {824716},
  shortjournal = {Front. Robot. AI},
  title        = {Shared control schemes for middle ear surgery},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-based nonlinear feedback controllers for pressure
control of soft pneumatic actuators using on/off valves. <em>FROBT</em>,
<em>9</em>, 818187. (<a
href="https://doi.org/10.3389/frobt.2022.818187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes the application and comparison of three nonlinear feedback controllers for low-level control of soft actuators driven by a pressure source and single high-speed on/off solenoid valve. First, a mathematical model of the pneumatic system is established and the limitations of the open-loop system are evaluated. Next, a model of the pneumatic system is developed using Simscape Fluids to evaluate the performance of various control strategies. In this article, State-Dependent Riccati Equation control, sliding mode control, and feedback linearization are considered. To improve robustness to model uncertainties, the sliding mode and feedback linearization control strategies are augmented with integral action. The model of the pneumatic system is also used to develop a feedforward component, which is added to a PI controller with anti-windup. The simulation and experimental results demonstrate the effectiveness of the proposed controllers for pressure tracking.},
  archive      = {J_FROBT},
  author       = {Xavier, Matheus S. and Fleming, Andrew J. and Yong, Yuen K.},
  doi          = {10.3389/frobt.2022.818187},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {818187},
  shortjournal = {Front. Robot. AI},
  title        = {Model-based nonlinear feedback controllers for pressure control of soft pneumatic actuators using On/Off valves},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactions between heavy trucks and vulnerable road
users—a systematic review to inform the interactive capabilities of
highly automated trucks. <em>FROBT</em>, <em>9</em>, 818019. (<a
href="https://doi.org/10.3389/frobt.2022.818019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates interactive behaviors and communication cues of heavy goods vehicles (HGVs) and vulnerable road users (VRUs) such as pedestrians and cyclists as a means of informing the interactive capabilities of highly automated HGVs. Following a general framing of road traffic interaction, we conducted a systematic literature review of empirical HGV-VRU studies found through the databases Scopus, ScienceDirect and TRID. We extracted reports of interactive road user behaviors and communication cues from 19 eligible studies and categorized these into two groups: 1) the associated communication channel/mechanism (e.g., nonverbal behavior), and 2) the type of communication cue (implicit/explicit). We found the following interactive behaviors and communication cues: 1) vehicle-centric (e.g., HGV as a larger vehicle, adapting trajectory, position relative to the VRU, timing of acceleration to pass the VRU, displaying information via human-machine interface), 2) driver-centric (e.g., professional driver, present inside/outside the cabin, eye-gaze behavior), and 3) VRU-centric (e.g., racer cyclist, adapting trajectory, position relative to the HGV, proximity to other VRUs, eye-gaze behavior). These cues are predominantly based on road user trajectories and movements (i.e., kinesics/proxemics nonverbal behavior) forming implicit communication, which indicates that this is the primary mechanism for HGV-VRU interactions. However, there are also reports of more explicit cues such as cyclists waving to say thanks, the use of turning indicators, or new types of external human-machine interfaces (eHMI). Compared to corresponding scenarios with light vehicles, HGV-VRU interaction patterns are to a high extent formed by the HGV’s size, shape and weight. For example, this can cause VRUs to feel less safe, drivers to seek to avoid unnecessary decelerations and accelerations, or lead to strategic behaviors due to larger blind-spots. Based on these findings, it is likely that road user trajectories and kinematic behaviors will form the basis for communication also for highly automated HGV-VRU interaction. However, it might also be beneficial to use additional eHMI to compensate for the loss of more social driver-centric cues or to signal other types of information. While controlled experiments can be used to gather such initial insights, deeper understanding of highly automated HGV-VRU interactions will also require naturalistic studies.},
  archive      = {J_FROBT},
  author       = {Fabricius, Victor and Habibovic, Azra and Rizgary, Daban and Andersson, Jonas and Wärnestål, Pontus},
  doi          = {10.3389/frobt.2022.818019},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {818019},
  shortjournal = {Front. Robot. AI},
  title        = {Interactions between heavy trucks and vulnerable road Users—A systematic review to inform the interactive capabilities of highly automated trucks},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Morphing-enabled path planning for flying tensegrity robots
as a semidefinite program. <em>FROBT</em>, <em>9</em>, 812849. (<a
href="https://doi.org/10.3389/frobt.2022.812849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of deformable drones is of high importance but presents significant challenges. Such drones can be based on tensegrity structures, which leaves open the questions of configuration-space path planning for such robots. In this paper we propose a method that takes advantage of a simplified encoding of the drone’s shape, allowing to turn the path planning into a sequence of semidefinite programs. The mapping from the simplified description and the actual tensegrity configuration is done via a data-driven method, using a pre-computed dataset of statically stable configurations and their outer Löwner-John ellipsoids, as well as eigendecompositions of the ellipsoid matrices. Together it allows rapid containment check, whose computational cost depends linearly on the number of dataset entries. Thus, the proposed method offloads computationally-intensive parts to the offline dataset generation procedure, speeding up the algorithm execution.},
  archive      = {J_FROBT},
  author       = {Savin, Sergei and Klimchik, Alexandr},
  doi          = {10.3389/frobt.2022.812849},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {812849},
  shortjournal = {Front. Robot. AI},
  title        = {Morphing-enabled path planning for flying tensegrity robots as a semidefinite program},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid PAC reinforcement learning algorithm for
human-robot interaction. <em>FROBT</em>, <em>9</em>, 797213. (<a
href="https://doi.org/10.3389/frobt.2022.797213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper offers a new hybrid probably approximately correct (PAC) reinforcement learning (RL) algorithm for Markov decision processes (MDPs) that intelligently maintains favorable features of both model-based and model-free methodologies. The designed algorithm, referred to as the Dyna-Delayed Q-learning (DDQ) algorithm, combines model-free Delayed Q-learning and model-based R-max algorithms while outperforming both in most cases. The paper includes a PAC analysis of the DDQ algorithm and a derivation of its sample complexity. Numerical results are provided to support the claim regarding the new algorithm’s sample efficiency compared to its parents as well as the best known PAC model-free and model-based algorithms in application. A real-world experimental implementation of DDQ in the context of pediatric motor rehabilitation facilitated by infant-robot interaction highlights the potential benefits of the reported method.},
  archive      = {J_FROBT},
  author       = {Zehfroosh, Ashkan and Tanner , Herbert G.},
  doi          = {10.3389/frobt.2022.797213},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {797213},
  shortjournal = {Front. Robot. AI},
  title        = {A hybrid PAC reinforcement learning algorithm for human-robot interaction},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computer-implemented articulatory models for speech
production: A review. <em>FROBT</em>, <em>9</em>, 796739. (<a
href="https://doi.org/10.3389/frobt.2022.796739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling speech production and speech articulation is still an evolving research topic. Some current core questions are: What is the underlying (neural) organization for controlling speech articulation? How to model speech articulators like lips and tongue and their movements in an efficient but also biologically realistic way? How to develop high-quality articulatory-acoustic models leading to high-quality articulatory speech synthesis? Thus, on the one hand computer-modeling will help us to unfold underlying biological as well as acoustic-articulatory concepts of speech production and on the other hand further modeling efforts will help us to reach the goal of high-quality articulatory-acoustic speech synthesis based on more detailed knowledge on vocal tract acoustics and speech articulation. Currently, articulatory models are not able to reach the quality level of corpus-based speech synthesis. Moreover, biomechanical and neuromuscular based approaches are complex and still not usable for sentence-level speech synthesis. This paper lists many computer-implemented articulatory models and provides criteria for dividing articulatory models in different categories. A recent major research question, i.e., how to control articulatory models in a neurobiologically adequate manner is discussed in detail. It can be concluded that there is a strong need to further developing articulatory-acoustic models in order to test quantitative neurobiologically based control concepts for speech articulation as well as to uncover the remaining details in human articulatory and acoustic signal generation. Furthermore, these efforts may help us to approach the goal of establishing high-quality articulatory-acoustic as well as neurobiologically grounded speech synthesis.},
  archive      = {J_FROBT},
  author       = {Kröger, Bernd J.},
  doi          = {10.3389/frobt.2022.796739},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {796739},
  shortjournal = {Front. Robot. AI},
  title        = {Computer-implemented articulatory models for speech production: A review},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepClaw 2.0: A data collection platform for learning human
manipulation. <em>FROBT</em>, <em>9</em>, 787291. (<a
href="https://doi.org/10.3389/frobt.2022.787291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Besides direct interaction, human hands are also skilled at using tools to manipulate objects for typical life and work tasks. This paper proposes DeepClaw 2.0 as a low-cost, open-sourced data collection platform for learning human manipulation. We use an RGB-D camera to visually track the motion and deformation of a pair of soft finger networks on a modified kitchen tong operated by human teachers. These fingers can be easily integrated with robotic grippers to bridge the structural mismatch between humans and robots during learning. The deformation of soft finger networks, which reveals tactile information in contact-rich manipulation, is captured passively. We collected a comprehensive sample dataset involving five human demonstrators in ten manipulation tasks with five trials per task. As a low-cost, open-sourced platform, we also developed an intuitive interface that converts the raw sensor data into state-action data for imitation learning problems. For learning-by-demonstration problems, we further demonstrated our dataset’s potential by using real robotic hardware to collect joint actuation data or using a simulated environment when limited access to the hardware.},
  archive      = {J_FROBT},
  author       = {Wang, Haokun and Liu, Xiaobo and Qiu, Nuofan and Guo, Ning and Wan, Fang and Song, Chaoyang},
  doi          = {10.3389/frobt.2022.787291},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {787291},
  shortjournal = {Front. Robot. AI},
  title        = {DeepClaw 2.0: A data collection platform for learning human manipulation},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “Sequencing matters”: Investigating suitable action
sequences in robot-assisted autism therapy. <em>FROBT</em>, <em>9</em>,
784249. (<a href="https://doi.org/10.3389/frobt.2022.784249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots have been shown to be promising tools for delivering therapeutic tasks for children with Autism Spectrum Disorder (ASD). However, their efficacy is currently limited by a lack of flexibility of the robot’s social behavior to successfully meet therapeutic and interaction goals. Robot-assisted interventions are often based on structured tasks where the robot sequentially guides the child towards the task goal. Motivated by a need for personalization to accommodate a diverse set of children profiles, this paper investigates the effect of different robot action sequences in structured socially interactive tasks targeting attention skills in children with different ASD profiles. Based on an autism diagnostic tool, we devised a robotic prompting scheme on a NAO humanoid robot, aimed at eliciting goal behaviors from the child, and integrated it in a novel interactive storytelling scenario involving screens. We programmed the robot to operate in three different modes: diagnostic-inspired (Assess), personalized therapy-inspired (Therapy), and random (Explore). Our exploratory study with 11 young children with ASD highlights the usefulness and limitations of each mode according to different possible interaction goals, and paves the way towards more complex methods for balancing short-term and long-term goals in personalized robot-assisted therapy.},
  archive      = {J_FROBT},
  author       = {Baraka, Kim and Couto, Marta and Melo, Francisco S. and Paiva, Ana and Veloso, Manuela},
  doi          = {10.3389/frobt.2022.784249},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {784249},
  shortjournal = {Front. Robot. AI},
  title        = {“Sequencing matters”: Investigating suitable action sequences in robot-assisted autism therapy},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Safe robot trajectory control using probabilistic movement
primitives and control barrier functions. <em>FROBT</em>, <em>9</em>,
772228. (<a href="https://doi.org/10.3389/frobt.2022.772228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel means of control design for probabilistic movement primitives (ProMPs). Our proposed approach makes use of control barrier functions and control Lyapunov functions defined by a ProMP distribution. Thus, a robot may move along a trajectory within the distribution while guaranteeing that the system state never leaves more than a desired distance from the distribution mean. The control employs feedback linearization to handle nonlinearities in the system dynamics and real-time quadratic programming to ensure a solution exists that satisfies all safety constraints while minimizing control effort. Furthermore, we highlight how the proposed method may allow a designer to emphasize certain safety objectives that are more important than the others. A series of simulations and experiments demonstrate the efficacy of our approach and show it can run in real time.},
  archive      = {J_FROBT},
  author       = {Davoodi, Mohammadreza and Iqbal, Asif and Cloud, Joseph M. and Beksi, William J. and Gans, Nicholas R.},
  doi          = {10.3389/frobt.2022.772228},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {772228},
  shortjournal = {Front. Robot. AI},
  title        = {Safe robot trajectory control using probabilistic movement primitives and control barrier functions},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward an attentive robotic architecture: Learning-based
mutual gaze estimation in human–robot interaction. <em>FROBT</em>,
<em>9</em>, 770165. (<a
href="https://doi.org/10.3389/frobt.2022.770165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robotics is an emerging field that is expected to grow rapidly in the near future. In fact, it is increasingly more frequent to have robots that operate in close proximity with humans or even collaborate with them in joint tasks. In this context, the investigation of how to endow a humanoid robot with social behavioral skills typical of human–human interactions is still an open problem. Among the countless social cues needed to establish a natural social attunement, this article reports our research toward the implementation of a mechanism for estimating the gaze direction, focusing in particular on mutual gaze as a fundamental social cue in face-to-face interactions. We propose a learning-based framework to automatically detect eye contact events in online interactions with human partners. The proposed solution achieved high performance both in silico and in experimental scenarios. Our work is expected to be the first step toward an attentive architecture able to endorse scenarios in which the robots are perceived as social partners.},
  archive      = {J_FROBT},
  author       = {Lombardi, Maria and Maiettini, Elisa and De Tommaso, Davide and Wykowska, Agnieszka and Natale, Lorenzo},
  doi          = {10.3389/frobt.2022.770165},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {770165},
  shortjournal = {Front. Robot. AI},
  title        = {Toward an attentive robotic architecture: Learning-based mutual gaze estimation in Human–Robot interaction},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated dynamic closed loop simulation platform for
elbow flexion augmentation using an upper limb exosuit model.
<em>FROBT</em>, <em>9</em>, 768841. (<a
href="https://doi.org/10.3389/frobt.2022.768841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable robotic devices are designed to assist, enhance or restore human muscle performance. Understanding how a wearable robotic device changes human biomechanics through complex interaction is important to guide its proper design, parametric optimization and functional success. The present work develops a human-machine-interaction simulation platform for closed loop dynamic analysis with feedback control and to study the effect of soft-robotic wearables on human physiology. The proposed simulation platform incorporates Computed Muscle Control (CMC) algorithm and is implemented using the MATLAB -OpenSim interface. The framework is generic and will allow incorporation of any advanced control strategy for the wearable devices. As a demonstration, a Gravity Compensation (GC) controller has been implemented on the wearable device and the resulting decrease in the joint moments, muscle activations and metabolic costs during a simple repetitive load lifting task with two different speeds is investigated.},
  archive      = {J_FROBT},
  author       = {Sambhav, Ratna and Jena, Shreeshan and Chatterjee, Ankit and Bhasin, Shubhendu and Santapuri, Sushma and Kumar, Lalan and Muthukrishnan, Suriya Prakash and Roy, Sitikantha},
  doi          = {10.3389/frobt.2022.768841},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {768841},
  shortjournal = {Front. Robot. AI},
  title        = {An integrated dynamic closed loop simulation platform for elbow flexion augmentation using an upper limb exosuit model},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel and more efficient oscillating foil for wave-driven
unmanned surface vehicles. <em>FROBT</em>, <em>9</em>, 759200. (<a
href="https://doi.org/10.3389/frobt.2022.759200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the wave-driven unmanned surface vehicles (WUSVs), oscillating-foils are the most straightforward and widely used wave energy conversion mechanism, like the wave glider. However, WUSVs usually sail slowly compared with other types of USVs. Improving the thrust of the oscillating foil to increase its speed can help WUSVs improve their maneuverability and shorten the completion of ocean missions. This paper proposed a novel method to enhance oscillating foils’ thrust force using asymmetric cross-section shape and asymmetric oscillating motion. The thrust enhancement effect is verified by CFD simulation and pool experiment. The experimental results show that the asymmetric wing can enhance the propulsive force by at least 13.75%. The speed enhancement of WUSVs brought by this enhanced thrust is at least 7.6%, which has also been verified by simulation and sea experiment. The asymmetric foil only needs to make low-cost modifications on the traditional rigid symmetric foil to achieve the desired thrust enhancement effect.},
  archive      = {J_FROBT},
  author       = {Gao, Yan and Xie, Lvcheng and Lam, Tin Lun},
  doi          = {10.3389/frobt.2022.759200},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {759200},
  shortjournal = {Front. Robot. AI},
  title        = {A novel and more efficient oscillating foil for wave-driven unmanned surface vehicles},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Guidelines for robot-to-human handshake from the movement
nuances in human-to-human handshake. <em>FROBT</em>, <em>9</em>, 758519.
(<a href="https://doi.org/10.3389/frobt.2022.758519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The handshake is the most acceptable gesture of greeting in many cultures throughout many centuries. To date, robotic arms are not capable of fully replicating this typical human gesture. Using multiple sensors that detect contact forces and displacements, we characterized the movements that occured during handshakes. A typical human-to-human handshake took around 3.63 s (SD = 0.45 s) to perform. It can be divided into three phases: reaching (M = 0.92 s, SD = 0.45 s), contact (M = 1.96 s, SD = 0.46 s), and return (M = 0.75 s, SD = 0.12 s). The handshake was further investigated to understand its subtle movements. Using a multiphase jerk minimization model, a smooth human-to-human handshake can be modelled with fifth or fourth degree polynomials at the reaching and return phases, and a sinusoidal function with exponential decay at the contact phase. We show that the contact phase (1.96 s) can be further divided according to the following subphases: preshake (0.06 s), main shake (1.31 s), postshake (0.06 s), and a period of no movement (0.52 s) just before both hands are retracted. We compared these to the existing handshake models that were proposed for physical human-robot interaction (pHRI). From our findings in human-to-human handshakes, we proposed guidelines for a more natural handshake movement between humanoid robots and their human partners.},
  archive      = {J_FROBT},
  author       = {Cabibihan, John-John and El-Noamany, Ahmed and Ahmed, Abdelrahman Mohamed Ragab M. and Ang, Marcelo H.},
  doi          = {10.3389/frobt.2022.758519},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {758519},
  shortjournal = {Front. Robot. AI},
  title        = {Guidelines for robot-to-human handshake from the movement nuances in human-to-human handshake},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transparent interaction based learning for human-robot
collaboration. <em>FROBT</em>, <em>9</em>, 754955. (<a
href="https://doi.org/10.3389/frobt.2022.754955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of collaborative robots that perform different tasks in close proximity to humans is increasing. Previous studies showed that enabling non-expert users to program a cobot reduces the cost of robot maintenance and reprogramming. Since this approach is based on an interaction between the cobot and human partners, in this study, we investigate whether making this interaction more transparent can improve the interaction and lead to better performance for non-expert users. To evaluate the proposed methodology, an experiment with 67 participants is conducted. The obtained results show that providing explanation leads to higher performance, in terms of efficiency and efficacy, i.e., the number of times the task is completed without teaching a wrong instruction to the cobot is two times higher when explanations are provided. In addition, providing explanation also increases users’ satisfaction and trust in working with the cobot.},
  archive      = {J_FROBT},
  author       = {Bagheri, Elahe and De Winter, Joris and Vanderborght , Bram},
  doi          = {10.3389/frobt.2022.754955},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {754955},
  shortjournal = {Front. Robot. AI},
  title        = {Transparent interaction based learning for human-robot collaboration},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Novelty experience in prolonged interaction: A qualitative
study of socially-isolated college students’ in-home use of a robot
companion animal. <em>FROBT</em>, <em>9</em>, 733078. (<a
href="https://doi.org/10.3389/frobt.2022.733078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social distancing policies such as limits on public gatherings and contact with others were utilized around the world to slow the spread of COVID-19. Yet, decreased social interactions may also threaten people’s well-being. In this project, we sought to understand novelty-relevant experiences surrounding in-home companion robot pets for adults that were living in some degree of social isolation due to the COVID-19 pandemic. After 6-weeks of participants living with the robot companion, we conducted semi-structured interviews (N = 9) and six themes emerged from our iterative analysis (expectations versus reality, ontological comparisons, interactions, third-party influence, identity, and comfort). Findings suggest that novelty is a complex phenomenon consisting of various elements (i.e., imagined novelty, technology novelty, and relational novelty). Each component influences the user’s experience. Our findings also suggest that our understanding of novelty as a nonlinear resource may hold important implications for how we view human-robot relationships beyond initial encounters.},
  archive      = {J_FROBT},
  author       = {Abendschein, Bryan and Edwards, Autumn and Edwards, Chad},
  doi          = {10.3389/frobt.2022.733078},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {733078},
  shortjournal = {Front. Robot. AI},
  title        = {Novelty experience in prolonged interaction: A qualitative study of socially-isolated college students’ in-home use of a robot companion animal},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robot-mediated inclusive processes in groups of children:
From gaze aversion to mutual smiling gaze. <em>FROBT</em>, <em>9</em>,
729146. (<a href="https://doi.org/10.3389/frobt.2022.729146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our work is motivated by the idea that social robots can help inclusive processes in groups of children, focusing on the case of children who have newly arrived from a foreign country and their peers at school. Building on an initial study where we tested different robot behaviours and recorded children’s interactions mediated by a robot in a game, we present in this paper the findings from a subsequent analysis of the same video data drawing from ethnomethodology and conversation analysis. We describe how this approach differs from predominantly quantitative video analysis in HRI; how mutual gaze appeared as a challenging interactional accomplishment between unacquainted children, and why we focused on this phenomenon. We identify two situations and trajectories in which children make eye contact: asking for or giving instructions, and sharing an emotional reaction. Based on detailed analyses of a selection of extracts in the empirical section, we describe patterns and discuss the links between the different situations and trajectories, and relationship building. Our findings inform HRI and robot design by identifying complex interactional accomplishments between two children, as well as group dynamics which support these interactions. We argue that social robots should be able to perceive such phenomena in order to better support inclusion of outgroup children. Lastly, by explaining how we combined approaches and showing how they build on each other, we also hope to demonstrate the value of interdisciplinary research, and encourage it.},
  archive      = {J_FROBT},
  author       = {Tuncer, Sylvaine and Gillet, Sarah and Leite, Iolanda},
  doi          = {10.3389/frobt.2022.729146},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {729146},
  shortjournal = {Front. Robot. AI},
  title        = {Robot-mediated inclusive processes in groups of children: From gaze aversion to mutual smiling gaze},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diversity training with robots: Perspective-taking
backfires, while sterotype-suppression decreases negative attitudes
towards robots. <em>FROBT</em>, <em>9</em>, 728923. (<a
href="https://doi.org/10.3389/frobt.2022.728923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present research investigated the effects of a diversity training intervention on robot-related attitudes to test whether this could help to manage the diversity inherent in hybrid human-robot teams in the work context. Previous research in the human-human context has shown that stereotypes and prejudice, i.e., negative attitudes, may impair productivity and job satisfaction in teams high in diversity (e.g., regarding age, gender, or ethnicity). Relatedly, in hybrid human-robot teams, robots likely represent an “outgroup” to their human co-workers. The latter may have stereotypes towards robots and may hold negative attitudes towards them. Both aspects might have detrimental effects on subjective and objective performance in human-robot interactions (HRI). In an experiment, we tested the effect of an economic and easy to apply diversity training intervention for use in the work context: The so-called enlightenment approach. This approach utilizes perspective-taking to reduce prejudice and discrimination in human-human contexts. We adapted this intervention to the HRI context and explored its impact on participants’ implicit and explicit robot-related attitudes. However, contrary to our predictions, taking the perspective of a robot resulted in more negative robot-related attitudes, whereas actively suppressing stereotypes about social robots and their characteristics produced positive effects on robot attitudes. Therefore, we recommend considering potential pre-existing aversions against taking the perspective of a robot when designing interventions to improve human-robot collaboration at the workplace. Instead, it might be useful to provide information about existing stereotypes and their consequences, thereby making people aware of their potential biases against social robots.},
  archive      = {J_FROBT},
  author       = {Wullenkord, Ricarda and Eyssel, Friederike},
  doi          = {10.3389/frobt.2022.728923},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {728923},
  shortjournal = {Front. Robot. AI},
  title        = {Diversity training with robots: Perspective-taking backfires, while sterotype-suppression decreases negative attitudes towards robots},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A project based learning approach for improving students’
computational thinking skills. <em>FROBT</em>, <em>9</em>, 720448. (<a
href="https://doi.org/10.3389/frobt.2022.720448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An educational robotics lab has been planned for undergraduate students in an Electronic Engineering degree, using the Project Based Learning (PBL) approach and the NAO robot. Students worked in a research context, with the aim of making the functions of the NAO robot as social and autonomous as possible, adopting in the design process the Wolfram Language (WL), from the Mathematica software. Interfacing the programming environment of the NAO with Mathematica, they solved in part the problem of autonomy of the NAO, thus realizing enhanced functions of autonomous movement, recognition of human faces and speech for improving the system social interaction. An external repository was created to streamline processes and stow data that the robot can easily access. Self-assessment processes demonstrated that the course provided students with useful skills to cope with real life problems. Cognitive aspects of programming by WL have also been collected in the students’ feedback.},
  archive      = {J_FROBT},
  author       = {Bertacchini, Francesca and Scuro, Carmelo and Pantano, Pietro and Bilotta, Eleonora},
  doi          = {10.3389/frobt.2022.720448},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {720448},
  shortjournal = {Front. Robot. AI},
  title        = {A project based learning approach for improving students’ computational thinking skills},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating electromyography and sonomyography sensor fusion
to estimate lower-limb kinematics using gaussian process regression.
<em>FROBT</em>, <em>9</em>, 716545. (<a
href="https://doi.org/10.3389/frobt.2022.716545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on robotic lower-limb assistive devices over the past decade has generated autonomous, multiple degree-of-freedom devices to augment human performance during a variety of scenarios. However, the increase in capabilities of these devices is met with an increase in the complexity of the overall control problem and requirement for an accurate and robust sensing modality for intent recognition. Due to its ability to precede changes in motion, surface electromyography (EMG) is widely studied as a peripheral sensing modality for capturing features of muscle activity as an input for control of powered assistive devices. In order to capture features that contribute to muscle contraction and joint motion beyond muscle activity of superficial muscles, researchers have introduced sonomyography, or real-time dynamic ultrasound imaging of skeletal muscle. However, the ability of these sonomyography features to continuously predict multiple lower-limb joint kinematics during widely varying ambulation tasks, and their potential as an input for powered multiple degree-of-freedom lower-limb assistive devices is unknown. The objective of this research is to evaluate surface EMG and sonomyography, as well as the fusion of features from both sensing modalities, as inputs to Gaussian process regression models for the continuous estimation of hip, knee and ankle angle and velocity during level walking, stair ascent/descent and ramp ascent/descent ambulation. Gaussian process regression is a Bayesian nonlinear regression model that has been introduced as an alternative to musculoskeletal model-based techniques. In this study, time-intensity features of sonomyography on both the anterior and posterior thigh along with time-domain features of surface EMG from eight muscles on the lower-limb were used to train and test subject-dependent and task-invariant Gaussian process regression models for the continuous estimation of hip, knee and ankle motion. Overall, anterior sonomyography sensor fusion with surface EMG significantly improved estimation of hip, knee and ankle motion for all ambulation tasks (level ground, stair and ramp ambulation) in comparison to surface EMG alone. Additionally, anterior sonomyography alone significantly improved errors at the hip and knee for most tasks compared to surface EMG. These findings help inform the implementation and integration of volitional control strategies for robotic assistive technologies.},
  archive      = {J_FROBT},
  author       = {Rabe, Kaitlin G. and Fey, Nicholas P.},
  doi          = {10.3389/frobt.2022.716545},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {716545},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluating electromyography and sonomyography sensor fusion to estimate lower-limb kinematics using gaussian process regression},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Still not solved: A call for renewed focus on user-centered
teleoperation interfaces. <em>FROBT</em>, <em>9</em>, 704225. (<a
href="https://doi.org/10.3389/frobt.2022.704225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teleoperation is one of the oldest applications of human-robot interaction, yet decades later, robots are still difficult to control in a variety of situations, especially when used by non-expert robot operators. That difficulty has relegated teleoperation to mostly expert-level use cases, though everyday jobs and lives could benefit from teleoperated robots by enabling people to get tasks done remotely. Research has made great progress by improving the capabilities of robots, and exploring a variety of interfaces to improve operator performance, but many non-expert applications of teleoperation are limited by the operator’s ability to understand and control the robot effectively. We discuss the state of the art of user-centered research for teleoperation interfaces along with challenges teleoperation researchers face and discuss how an increased focus on human-centered teleoperation research can help push teleoperation into more everyday situations.},
  archive      = {J_FROBT},
  author       = {Rea, Daniel J. and Seo, Stela H.},
  doi          = {10.3389/frobt.2022.704225},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {704225},
  shortjournal = {Front. Robot. AI},
  title        = {Still not solved: A call for renewed focus on user-centered teleoperation interfaces},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trajectory generation for flexible-joint space manipulators.
<em>FROBT</em>, <em>9</em>, 687595. (<a
href="https://doi.org/10.3389/frobt.2022.687595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space manipulator arms often exhibit significant joint flexibility and limited motor torque. Future space missions, including satellite servicing and large structure assembly, may involve the manipulation of massive objects, which will accentuate these limitations. Currently, astronauts use visual feedback on-orbit to mitigate oscillations and trajectory following issues. Large time delays between orbit and Earth make ground teleoperation difficult in these conditions, so more autonomous operations must be considered to remove the astronaut resource requirement and expand robotic capabilities in space. Trajectory planning for autonomous systems must therefore be considered to prevent poor trajectory tracking performance. We provide a model-based trajectory generation methodology that incorporates constraints on joint speed, motor torque, and base actuation for flexible-joint space manipulators while minimizing total trajectory time. Full spatial computer simulation results, as well as physical experiment results with a single-joint robot on an air bearing table, show the efficacy of our methodology.},
  archive      = {J_FROBT},
  author       = {Carabis, David S. and Wen, John T.},
  doi          = {10.3389/frobt.2022.687595},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {687595},
  shortjournal = {Front. Robot. AI},
  title        = {Trajectory generation for flexible-joint space manipulators},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mind your manners! A dataset and a continual learning
approach for assessing social appropriateness of robot actions.
<em>FROBT</em>, <em>9</em>, 669420. (<a
href="https://doi.org/10.3389/frobt.2022.669420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, endowing robots with an ability to assess social appropriateness of their actions has not been possible. This has been mainly due to (i) the lack of relevant and labelled data and (ii) the lack of formulations of this as a lifelong learning problem. In this paper, we address these two issues. We first introduce the Socially Appropriate Domestic Robot Actions dataset (MANNERS-DB), which contains appropriateness labels of robot actions annotated by humans. Secondly, we train and evaluate a baseline Multi Layer Perceptron and a Bayesian Neural Network (BNN) that estimate social appropriateness of actions in MANNERS-DB. Finally, we formulate learning social appropriateness of actions as a continual learning problem using the uncertainty of Bayesian Neural Network parameters. The experimental results show that the social appropriateness of robot actions can be predicted with a satisfactory level of precision. To facilitate reproducibility and further progress in this area, MANNERS-DB, the trained models and the relevant code are made publicly available at https://github.com/jonastjoms/MANNERS-DB.},
  archive      = {J_FROBT},
  author       = {Tjomsland, Jonas and Kalkan, Sinan and Gunes, Hatice},
  doi          = {10.3389/frobt.2022.669420},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {669420},
  shortjournal = {Front. Robot. AI},
  title        = {Mind your manners! a dataset and a continual learning approach for assessing social appropriateness of robot actions},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A programmable liquid crystal elastomer metamaterials with
soft elasticity. <em>FROBT</em>, <em>9</em>, 849516. (<a
href="https://doi.org/10.3389/frobt.2022.849516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liquid crystal elastomers (LCEs) are a rubbery network of polymers with ordered liquid crystal mesogens. The combination of rubber elasticity and the anisotropic liquid crystalline order gives exceptional mechanical properties, like soft elasticity, where near-constant stress accompanies large elastic deformation in the material. However, the soft elasticity in LCEs is often bounded by the intrinsic molecular interactions and structures, limiting the range of programmable mechanical properties and functionalities. Here, we demonstrate that the semi-soft elasticity of LCEs can be integrated into the framework of metamaterials to realize markedly programmabilities. Under uniaxial deformation, each state of the building blocks in metamaterials and the molecular composition of the nematic LCEs is associated with a distinctly different stress-strain relation that is fully elastic. Taking advantage of the tunable bending and stretching deformation enabled by the geometry of the building blocks and the semi-soft elasticity of the nematic LCE in the metamaterials, we can engineer the local stretch and stress at an unmet level of their counterpart composed by elastomers. Numerical simulations and analytical models are developed to relate the metamaterial geometries and the LCE soft elasticity to the mechanical responses. In addition, an elastic region with near-zero stiffness up to a stretch of 1.4 can be designed by connecting the compliant responses due to bending deformation and the soft elasticity in the LCE. We expect that the specialized mechanical tunability enabled by the LCE metamaterials can facilitate the development of advanced forms of mechanical metamaterials and impact the design of robotic systems.},
  archive      = {J_FROBT},
  author       = {Liang, Xudong and Li, Dongfeng},
  doi          = {10.3389/frobt.2022.849516},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {849516},
  shortjournal = {Front. Robot. AI},
  title        = {A programmable liquid crystal elastomer metamaterials with soft elasticity},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Robotic manipulation and capture in space.
<em>FROBT</em>, <em>9</em>, 849288. (<a
href="https://doi.org/10.3389/frobt.2022.849288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Papadopoulos, Evangelos and Aghili, Farhad and Ma, Ou and Lampariello, Roberto},
  doi          = {10.3389/frobt.2022.849288},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {849288},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Robotic manipulation and capture in space},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparing a robot tutee to a human tutee in a
learning-by-teaching scenario with children. <em>FROBT</em>, <em>9</em>,
836462. (<a href="https://doi.org/10.3389/frobt.2022.836462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots are increasingly being studied in educational roles, including as tutees in learning-by-teaching applications. To explore the benefits and drawbacks of using robots in this way, it is important to study how robot tutees compare to traditional learning-by-teaching situations. In this paper, we report the results of a within-subjects field experiment that compared a robot tutee to a human tutee in a Swedish primary school. Sixth-grade students participated in the study as tutors in a collaborative mathematics game where they were responsible for teaching a robot tutee as well as a third-grade student in two separate sessions. Their teacher was present to provide support and guidance for both sessions. Participants’ perceptions of the interactions were then gathered through a set of quantitative instruments measuring their enjoyment and willingness to interact with the tutees again, communication and collaboration with the tutees, their understanding of the task, sense of autonomy as tutors, and perceived learning gains for tutor and tutee. The results showed that the two scenarios were comparable with respect to enjoyment and willingness to play again, as well as perceptions of learning gains. However, significant differences were found for communication and collaboration, which participants considered easier with a human tutee. They also felt significantly less autonomous in their roles as tutors with the robot tutee as measured by their stated need for their teacher’s help. Participants further appeared to perceive the activity as somewhat clearer and working better when playing with the human tutee. These findings suggest that children can enjoy engaging in peer tutoring with a robot tutee. However, the interactive capabilities of robots will need to improve quite substantially before they can potentially engage in autonomous and unsupervised interactions with children.},
  archive      = {J_FROBT},
  author       = {Serholt, Sofia and Ekström, Sara and Küster, Dennis and Ljungblad, Sara and Pareto, Lena},
  doi          = {10.3389/frobt.2022.836462},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {836462},
  shortjournal = {Front. Robot. AI},
  title        = {Comparing a robot tutee to a human tutee in a learning-by-teaching scenario with children},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Magnetic-field-inspired navigation for robots in complex and
unknown environments. <em>FROBT</em>, <em>9</em>, 834177. (<a
href="https://doi.org/10.3389/frobt.2022.834177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the course of the past decade, we have witnessed a huge expansion in robotic applications, most notably from well-defined industrial environments into considerably more complex environments. The obstacles that these environments often contain present robotics with a new challenge - to equip robots with a real-time capability of avoiding them. In this paper, we propose a magnetic-field-inspired navigation method that significantly has several advantages over alternative systems. Most importantly, 1) it guarantees obstacle avoidance for both convex and non-convex obstacles, 2) goal convergence is still guaranteed for point-like robots in environments with convex obstacles and non-maze concave obstacles, 3) no prior knowledge of the environment, such as the position and geometry of the obstacles, is needed, 4) it only requires temporally and spatially local environmental sensor information, and 5) it can be implemented on a wide range of robotic platforms in both 2D and 3D environments. The proposed navigation algorithm is validated in simulation scenarios as well as through experimentation. The results demonstrate that robotic platforms, ranging from planar point-like robots to robot arm structures such as the Baxter robot, can successfully navigate toward desired targets within an obstacle-laden environment.},
  archive      = {J_FROBT},
  author       = {Ataka, Ahmad and Lam, Hak-Keung and Althoefer, Kaspar},
  doi          = {10.3389/frobt.2022.834177},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {834177},
  shortjournal = {Front. Robot. AI},
  title        = {Magnetic-field-inspired navigation for robots in complex and unknown environments},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hydrodynamical fingerprint of a neighbour in a fish lateral
line. <em>FROBT</em>, <em>9</em>, 825889. (<a
href="https://doi.org/10.3389/frobt.2022.825889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For fish, swimming in group may be favorable to individuals. Several works reported that in a fish school, individuals sense and adjust their relative position to prevent collisions and maintain the group formation. Also, from a hydrodynamic perspective, relative-position and kinematic synchronisation between adjacent fish may considerably influence their swimming performance. Fish may sense the relative-position and tail-beat phase difference with their neighbors using both vision and the lateral-line system, however, when swimming in dark or turbid environments, visual information may become unavailable. To understand how lateral-line sensing can enable fish to judge the relative-position and phase-difference with their neighbors, in this study, based on a verified three-dimensional computational fluid dynamics approach, we simulated two fish swimming adjacently with various configurations. The lateral-line signal was obtained by sampling the surface hydrodynamic stress. The sensed signal was processed by Fast Fourier Transform (FFT), which is robust to turbulence and environmental flow. By examining the lateral-line pressure and shear-stress signals in the frequency domain, various states of the neighboring fish were parametrically identified. Our results reveal that the FFT-processed lateral-line signals in one fish may potentially reflect the relative-position, phase-differences, and the tail-beat frequency of its neighbor. Our results shed light on the fluid dynamical aspects of the lateral-line sensing mechanism used by fish. Furthermore, the presented approach based on FFT is especially suitable for applications in bioinspired swimming robotics. We provide suggestions for the design of artificial systems consisting of multiple stress sensors for robotic fish to improve their performance in collective operation.},
  archive      = {J_FROBT},
  author       = {Li, Gen and Kolomenskiy, Dmitry and Liu, Hao and Thiria, Benjamin and Godoy-Diana, Ramiro},
  doi          = {10.3389/frobt.2022.825889},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {825889},
  shortjournal = {Front. Robot. AI},
  title        = {Hydrodynamical fingerprint of a neighbour in a fish lateral line},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Squeezing more juice out of dielectric elastomer generators.
<em>FROBT</em>, <em>9</em>, 825148. (<a
href="https://doi.org/10.3389/frobt.2022.825148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dielectric elastomer generators are soft structures capable of converting mechanical energy into electrical energy. Here, we develop a theoretical model of the triangular harvesting cycle that enables the harvesting of most of the available electrical energy while not requiring active monitoring of the charge-voltage state on the DEG. This cycle is therefore interesting for small-scale generators for which a monitoring circuit would be energetically too costly. Our model enables the identification of the optimal value of the circuit’s parameters such as storage capacitor and priming voltage values and show that for capacitance swings up to 6, 94% of the available electrical energy can be harvested. The model is experimentally validated with a conical generator, and the effect of non-constant deformation amplitudes is examined. Energy densities up to 46 mJcm−3 were obtained for an electric field of 50 V µm−1.},
  archive      = {J_FROBT},
  author       = {Rosset , Samuel and Anderson , Iain A.},
  doi          = {10.3389/frobt.2022.825148},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {825148},
  shortjournal = {Front. Robot. AI},
  title        = {Squeezing more juice out of dielectric elastomer generators},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Flying into the wind: Insects and bio-inspired
micro-air-vehicles with a wing-stroke dihedral steer passively into
wind-gusts. <em>FROBT</em>, <em>9</em>, 820363. (<a
href="https://doi.org/10.3389/frobt.2022.820363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural fliers utilize passive and active flight control strategies to cope with windy conditions. This capability makes them incredibly agile and resistant to wind gusts. Here, we study how insects achieve this, by combining Computational Fluid Dynamics (CFD) analyses of flying fruit flies with freely-flying robotic experiments. The CFD analysis shows that flying flies are partly passively stable in side-wind conditions due to their dorsal-ventral wing-beat asymmetry defined as wing-stroke dihedral. Our robotic experiments confirm that this mechanism also stabilizes free-moving flapping robots with similar asymmetric dihedral wing-beats. This shows that both animals and robots with asymmetric wing-beats are dynamically stable in sideways wind gusts. Based on these results, we developed an improved model for the aerodynamic yaw and roll torques caused by the coupling between lateral motion and the stroke dihedral. The yaw coupling passively steers an asymmetric flapping flyer into the direction of a sideways wind gust; in contrast, roll torques are only stabilizing at high air gust velocities, due to non-linear coupling effects. The combined CFD simulations, robot experiments, and stability modeling help explain why the majority of flying insects exhibit wing-beats with positive stroke dihedral and can be used to develop more stable and robust flapping-wing Micro-Air-Vehicles.},
  archive      = {J_FROBT},
  author       = {Olejnik, Diana A. and Muijres, Florian T. and Karásek, Matěj and Honfi Camilo, Leonardo and De Wagter, Christophe and de Croon, Guido C.H.E.},
  doi          = {10.3389/frobt.2022.820363},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {820363},
  shortjournal = {Front. Robot. AI},
  title        = {Flying into the wind: Insects and bio-inspired micro-air-vehicles with a wing-stroke dihedral steer passively into wind-gusts},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HR1 robot: An assistant for healthcare applications.
<em>FROBT</em>, <em>9</em>, 813843. (<a
href="https://doi.org/10.3389/frobt.2022.813843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the World Health Organization1,2 the percentage of healthcare dependent population, such as elderly and people with disabilities, among others, will increase over the next years. This trend will put a strain on the health and social systems of most countries. The adoption of robots could assist these health systems in responding to this increased demand, particularly in high intensity and repetitive tasks. In a previous work, we compared a Socially Assistive Robot (SAR) with a Virtual Agent (VA) during the execution of a rehabilitation task. The SAR consisted of a humanoid R1 robot, while the Virtual Agent represented its simulated counter-part. In both cases, the agents evaluated the participants’ motions and provided verbal feedback. Participants reported higher levels of engagement when training with the SAR. Given that the architecture has been proven to be successful for a rehabilitation task, other sets of repetitive tasks could also take advantage of the platform, such as clinical tests. A commonly performed clinical trial is the Timed Up and Go (TUG), where the patient has to stand up, walk 3 m to a goal line and back, and sit down. To handle this test, we extended the architecture to evaluate lower limbs’ motions, follow the participants while continuously interacting with them, and verify that the test is completed successfully. We implemented the scenario in Gazebo, by simulating both participants and the interaction with the robot3. A full interactive report is created when the test is over, providing the extracted information to the specialist. We validate the architecture in three different experiments, each with 1,000 trials, using the Gazebo simulation. These experiments evaluate the ability of this architecture to analyse the patient, verify if they are able to complete the TUG test, and the accuracy of the measurements obtained during the test. This work provides the foundations towards more thorough clinical experiments with a large number of participants with a physical platform in the future. The software is publicly available in the assistive-rehab repository4 and fully documented.},
  archive      = {J_FROBT},
  author       = {Vasco, Valentina and Antunes, Alexandre G. P. and Tikhanoff, Vadim and Pattacini, Ugo and Natale, Lorenzo and Gower, Valerio and Maggiali, Marco},
  doi          = {10.3389/frobt.2022.813843},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {813843},
  shortjournal = {Front. Robot. AI},
  title        = {HR1 robot: An assistant for healthcare applications},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast online optimization for terrain-blind bipedal robot
walking with a decoupled actuated SLIP model. <em>FROBT</em>,
<em>9</em>, 812258. (<a
href="https://doi.org/10.3389/frobt.2022.812258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an online optimization algorithm which enables bipedal robots to blindly walk over various kinds of uneven terrains while resisting pushes. The proposed optimization algorithm performs high-level motion planning of footstep locations and center-of-mass height variations using the decoupled actuated spring-loaded inverted pendulum (aSLIP) model. The decoupled aSLIP model simplifies the original aSLIP with linear inverted pendulum (LIP) dynamics in horizontal states and spring dynamics in the vertical state. The motion planning can be formulated as a discrete-time model predictive control (MPC) problem and solved at a frequency of 1 kHz. The output of the motion planner is fed into an inverse-dynamics–based whole body controller for execution on the robot. A key result of this controller is that the feet of the robot are compliant, which further extends the robot’s ability to be robust to unobserved terrain variations. We evaluate our method in simulation with the bipedal robot SLIDER. The results show that the robot can blindly walk over various uneven terrains including slopes, wave fields, and stairs. It can also resist pushes of up to 40 N for a duration of 0.1 s while walking on uneven terrains.},
  archive      = {J_FROBT},
  author       = {Wang, Ke and Fei, Hengyi and Kormushev, Petar},
  doi          = {10.3389/frobt.2022.812258},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {812258},
  shortjournal = {Front. Robot. AI},
  title        = {Fast online optimization for terrain-blind bipedal robot walking with a decoupled actuated SLIP model},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kinematic-model-free predictive control for robotic
manipulator target reaching with obstacle avoidance. <em>FROBT</em>,
<em>9</em>, 809114. (<a
href="https://doi.org/10.3389/frobt.2022.809114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control is a widely used optimal control method for robot path planning and obstacle avoidance. This control method, however, requires a system model to optimize control over a finite time horizon and possible trajectories. Certain types of robots, such as soft robots, continuum robots, and transforming robots, can be challenging to model, especially in unstructured or unknown environments. Kinematic-model-free control can overcome these challenges by learning local linear models online. This paper presents a novel perception-based robot motion controller, the kinematic-model-free predictive controller, that is capable of controlling robot manipulators without any prior knowledge of the robot’s kinematic structure and dynamic parameters and is able to perform end-effector obstacle avoidance. Simulations and physical experiments were conducted to demonstrate the ability and adaptability of the controller to perform simultaneous target reaching and obstacle avoidance.},
  archive      = {J_FROBT},
  author       = {AlAttar, Ahmad and Chappell, Digby and Kormushev, Petar},
  doi          = {10.3389/frobt.2022.809114},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {809114},
  shortjournal = {Front. Robot. AI},
  title        = {Kinematic-model-free predictive control for robotic manipulator target reaching with obstacle avoidance},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The impact of cognition on motor learning and skill
acquisition using a robot intervention in infants with cerebral palsy.
<em>FROBT</em>, <em>9</em>, 805258. (<a
href="https://doi.org/10.3389/frobt.2022.805258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Cerebral Palsy (CP) is a neurodevelopmental disorder that encompasses multiple neurological disorders that appear in infancy or early childhood and persist through the lifespan of the individual. Early interventions for infants with CP utilizing assisted-motion robotic devices have shown promising effects in rehabilitation of the motor function skills. The impact of cognitive function during motor learning and skill acquisition in infants using robotic technologies is unclear.Purpose: To assess the impact of cognitive function of infants with and without CP on their motor learning using the Self-Initiated Prone Progression Crawler (SIPPC) robot.Methods: Statistical analysis was conducted on the data obtained from a randomized control trial in which the movement learning strategies in infants with or at risk for CP was assessed during a 16-week SIPPC robot intervention. Cognitive function was measured by the Bayley scales of Infant and Toddler Development–Third edition (Bayley-III) and motor function was measured by the Movement Observation Coding Scheme (MOCS). The infants were categorized into three distinct groups based on their cognitive scores at baseline: “above average” (n1 = 11), “below average” (n2 = 10), and “average” (n3 = 26). Tri-weekly averages of the MOCS scores (observations at five time points) were used for the analyses. This study involved computing descriptive statistics, data visualization, repeated measures analysis of variances (rmANOVA), and survival analyses.Results: The descriptive statistics were calculated for the MOCS and Bayley III scores. The repeated measures ANOVAs revealed that there was a statistically significant effect of time (p &amp;lt; 0.0001) on scores of all subscales of the MOCS. A statistically significant effect of interaction between group and time (p &amp;lt; 0.05) was found in MOCS scores of subscales 1 and 2. The survival analyses indicated that infants in different cognition groups significantly differed (p &amp;lt; 0.0001) in their ability to achieve the crawling milestone within the 16-week intervention period.Conclusion: The findings in this study reveal the key movement strategies required to move the SIPPC robot, assessed by the MOCS, vary depending on the infants’ cognition. The SIPPC robot is well-matched to cognitive ability of infants with CP. However, lower cognitive ability was related to delayed improvement in their motor skills.},
  archive      = {J_FROBT},
  author       = {Chandrashekhar, Raghuveer and Wang, Hongwu and Rippetoe, Josiah and James, Shirley A. and Fagg, Andrew H. and Kolobe, Thubi H. A.},
  doi          = {10.3389/frobt.2022.805258},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {805258},
  shortjournal = {Front. Robot. AI},
  title        = {The impact of cognition on motor learning and skill acquisition using a robot intervention in infants with cerebral palsy},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual haptic feedback for training of robotic suturing.
<em>FROBT</em>, <em>9</em>, 800232. (<a
href="https://doi.org/10.3389/frobt.2022.800232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current surgical robotic systems are teleoperated and do not have force feedback. Considerable practice is required to learn how to use visual input such as tissue deformation upon contact as a substitute for tactile sense. Thus, unnecessarily high forces are observed in novices, prior to specific robotic training, and visual force feedback studies demonstrated reduction of applied forces. Simulation exercises with realistic suturing tasks can provide training outside the operating room. This paper presents contributions to realistic interactive suture simulation for training of suturing and knot-tying tasks commonly used in robotically-assisted surgery. To improve the realism of the simulation, we developed a global coordinate wire model with a new constraint development for the elongation. We demonstrated that a continuous modeling of the contacts avoids instabilities during knot tightening. Visual cues are additionally provided, based on the computation of mechanical forces or constraints, to support learning how to dose the forces. The results are integrated into a powerful system-agnostic simulator, and the comparison with equivalent tasks performed with the da Vinci Xi system confirms its realism.},
  archive      = {J_FROBT},
  author       = {Jourdes, François and Valentin, Brice and Allard, Jérémie and Duriez, Christian and Seeliger, Barbara},
  doi          = {10.3389/frobt.2022.800232},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {800232},
  shortjournal = {Front. Robot. AI},
  title        = {Visual haptic feedback for training of robotic suturing},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human factors considerations and metrics in shared space
human-robot collaboration: A systematic review. <em>FROBT</em>,
<em>9</em>, 799522. (<a
href="https://doi.org/10.3389/frobt.2022.799522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degree of successful human-robot collaboration is dependent on the joint consideration of robot factors (RF) and human factors (HF). Depending on the state of the operator, a change in a robot factor, such as the behavior or level of autonomy, can be perceived differently and affect how the operator chooses to interact with and utilize the robot. This interaction can affect system performance and safety in dynamic ways. The theory of human factors in human-automation interaction has long been studied; however, the formal investigation of these HFs in shared space human-robot collaboration (HRC) and the potential interactive effects between covariate HFs (HF-HF) and HF-RF in shared space collaborative robotics requires additional investigation. Furthermore, methodological applications to measure or manipulate these factors can provide insights into contextual effects and potential for improved measurement techniques. As such, a systematic literature review was performed to evaluate the most frequently addressed operator HF states in shared space HRC, the methods used to quantify these states, and the implications of the states on HRC. The three most frequently measured states are: trust, cognitive workload, and anxiety, with subjective questionnaires universally the most common method to quantify operator states, excluding fatigue where electromyography is more common. Furthermore, the majority of included studies evaluate the effect of manipulating RFs on HFs, but few explain the effect of the HFs on system attributes or performance. For those that provided this information, HFs have been shown to impact system efficiency and response time, collaborative performance and quality of work, and operator utilization strategy.},
  archive      = {J_FROBT},
  author       = {Hopko, Sarah and Wang, Jingkun and Mehta, Ranjana},
  doi          = {10.3389/frobt.2022.799522},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {799522},
  shortjournal = {Front. Robot. AI},
  title        = {Human factors considerations and metrics in shared space human-robot collaboration: A systematic review},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weight shift movements of a social mediator robot make it
being recognized as serious and suppress anger, revenge and avoidance
motivation of the user. <em>FROBT</em>, <em>9</em>, 790209. (<a
href="https://doi.org/10.3389/frobt.2022.790209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans can become aggressive during text messaging. To maintain a healthy interpersonal relationship through text messaging, our negative mental states, such as anger, have to be well-controlled. This paper discusses the use of a handheld social robot deployed as a mediator in text messaging between humans. The robot is equipped with a movable weight inside its body. By controlling the movement of the internal weight during the time when the robot speaks out messages received from a human sender, we hypothesize that the psychological state of a receiver who holds the robot can be affected (for example, he/she will listen to the messages more seriously). In a controlled study (n = 94), in which participants were manipulated to be frustrated by using a context scenario, we studied the effect of three dialogue scripts with/without weight shifts. Results showed that introducing weight shifts together with the robot speech suppressed on average 23% of the user’s anger. However, only 3.5% of the anger was suppressed when the weight shifts were not applied. Additionally, in cases where the robot showed empathy to the user in words with weight shifts, the user’s revenge urge was successfully reduced by 22%. There was almost no effect confirmed when the weight shifts were not applied. A similar effect was also found in avoidance motivation: 15% of the avoidance motivation was reduced if weight shifts were applied. The reductions in revenge and avoidance motivation are considered important factors for human forgiveness. Therefore, our findings provide experimental evidence that weight shifts can be an effective expression modality for mediator robots, from the perspective of not only suppressing the user’s anger but also by inducing forgiveness during messaging.},
  archive      = {J_FROBT},
  author       = {Noguchi, Yohei and Kamide, Hiroko and Tanaka, Fumihide},
  doi          = {10.3389/frobt.2022.790209},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {790209},
  shortjournal = {Front. Robot. AI},
  title        = {Weight shift movements of a social mediator robot make it being recognized as serious and suppress anger, revenge and avoidance motivation of the user},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conveying intention by motions with awareness of information
asymmetry. <em>FROBT</em>, <em>9</em>, 783863. (<a
href="https://doi.org/10.3389/frobt.2022.783863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Fukuchi, Yosuke and Osawa, Masahiko and Yamakawa, Hiroshi and Takahashi, Tatsuji and Imai, Michita},
  doi          = {10.3389/frobt.2022.783863},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {783863},
  shortjournal = {Front. Robot. AI},
  title        = {Conveying intention by motions with awareness of information asymmetry},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploratory state representation learning. <em>FROBT</em>,
<em>9</em>, 762051. (<a
href="https://doi.org/10.3389/frobt.2022.762051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Not having access to compact and meaningful representations is known to significantly increase the complexity of reinforcement learning (RL). For this reason, it can be useful to perform state representation learning (SRL) before tackling RL tasks. However, obtaining a good state representation can only be done if a large diversity of transitions is observed, which can require a difficult exploration, especially if the environment is initially reward-free. To solve the problems of exploration and SRL in parallel, we propose a new approach called XSRL (eXploratory State Representation Learning). On one hand, it jointly learns compact state representations and a state transition estimator which is used to remove unexploitable information from the representations. On the other hand, it continuously trains an inverse model, and adds to the prediction error of this model a k-step learning progress bonus to form the maximization objective of a discovery policy. This results in a policy that seeks complex transitions from which the trained models can effectively learn. Our experimental results show that the approach leads to efficient exploration in challenging environments with image observations, and to state representations that significantly accelerate learning in RL tasks.},
  archive      = {J_FROBT},
  author       = {Merckling, Astrid and Perrin-Gilbert, Nicolas and Coninx, Alex and Doncieux, Stéphane},
  doi          = {10.3389/frobt.2022.762051},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {762051},
  shortjournal = {Front. Robot. AI},
  title        = {Exploratory state representation learning},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of human walking balance controller based on
COM-ZMP model of humanoid robot. <em>FROBT</em>, <em>9</em>, 757630. (<a
href="https://doi.org/10.3389/frobt.2022.757630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this research is to build a technology that enables wearable robotic systems that support human movement to maintain stable balance. By expanding our knowledge of conventional human gait analysis technology and robotics technology, we will build a technology that can estimate the state of human balance. In order to build a technology for estimating the human balance state based on the balance control technology of humanoid robots, we conducted joint research with Osaka University. We applied our knowledge of humanoid robot control to human stepping and braking motions, and confirmed the effectiveness of the balance control model using data measured by a motion capture system and a floor reaction force sensor system. In order to build a technology for estimating the human balance state based on the balance control technology of humanoid robots, we conducted joint research with Osaka University. We applied our knowledge of humanoid robot control to human stepping and braking motions to build a human balance control model. We confirmed the effectiveness of the balance control model using data measured by a motion capture system and a floor reaction force sensor system. In order to understand the state of human walking, the human walking motion was measured by motion capture and analyzed in detail. Following the norms of gait analysis techniques, we extended the balance control model of human foot-stepping and braking motions to a gait model that includes continuous straight-line walking and change of direction during walking. The effectiveness of the constructed balance control model was confirmed using a motion capture system and a floor reaction force sensor system.},
  archive      = {J_FROBT},
  author       = {Yoshikawa, Taizo},
  doi          = {10.3389/frobt.2022.757630},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {757630},
  shortjournal = {Front. Robot. AI},
  title        = {Identification of human walking balance controller based on COM-ZMP model of humanoid robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Precise motion control of a power line inspection robot
using hybrid time delay and state feedback control. <em>FROBT</em>,
<em>9</em>, 746991. (<a
href="https://doi.org/10.3389/frobt.2022.746991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent robotic inspection of power transmission lines has proved to be an excellent alternative to the traditional manual inspection methods, which are often tedious, expensive, and dangerous. However, to achieve effective automation of the robots under different working environments, the dynamic analysis and control of the robots need to be investigated for an efficient inspection process. Nonetheless, the application of control techniques for the position, speed and vibration control of these robots has not been explored in detail by the existing literature. Thus, an approach for precise motion control of the sliding inspection robot is presented in this paper. The main contribution of the study is that the chattering problem associated with the traditional command shaping time delay control (TDC) was minimized by smoothing the chattered input signal. Then, the improved control (iTDC) which is effective for oscillation control is hybridized with a pole placement based feedback control (PPC) to achieve both position and the sway angle control of the robot. The nonlinear and the linearized models of the sliding robot were established for the control design and analysis. Three parameters of the robot, namely, the length of the suspended arm, the mass of the payload, and the friction coefficient of different surfaces, were used to assess the robustness of the controller to model uncertainties. The iTDC + PPC has improved the velocity of TDC by 201% and minimizes the angular oscillation of PPC by 209%. Thus, the results demonstrate that the hybridized iTDC + PPC approach could be effectively applied for precise motion control of the sliding inspection robot.},
  archive      = {J_FROBT},
  author       = {Alhassan, Ahmad Bala and Zhang, Xiaodong and Shen, Haiming and Xu, Haibo and Hamza, Khaled and Masengo, Gilbert},
  doi          = {10.3389/frobt.2022.746991},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {746991},
  shortjournal = {Front. Robot. AI},
  title        = {Precise motion control of a power line inspection robot using hybrid time delay and state feedback control},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterization of indicators for adaptive human-swarm
teaming. <em>FROBT</em>, <em>9</em>, 745958. (<a
href="https://doi.org/10.3389/frobt.2022.745958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm systems consist of large numbers of agents that collaborate autonomously. With an appropriate level of human control, swarm systems could be applied in a variety of contexts ranging from urban search and rescue situations to cyber defence. However, the successful deployment of the swarm in such applications is conditioned by the effective coupling between human and swarm. While adaptive autonomy promises to provide enhanced performance in human-machine interaction, distinct factors must be considered for its implementation within human-swarm interaction. This paper reviews the multidisciplinary literature on different aspects contributing to the facilitation of adaptive autonomy in human-swarm interaction. Specifically, five aspects that are necessary for an adaptive agent to operate properly are considered and discussed, including mission objectives, interaction, mission complexity, automation levels, and human states. We distill the corresponding indicators in each of the five aspects, and propose a framework, named MICAH (i.e., Mission-Interaction-Complexity-Automation-Human), which maps the primitive state indicators needed for adaptive human-swarm teaming.},
  archive      = {J_FROBT},
  author       = {Hussein, Aya and Ghignone, Leo and Nguyen, Tung and Salimi, Nima and Nguyen, Hung and Wang, Min and Abbass, Hussein A.},
  doi          = {10.3389/frobt.2022.745958},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {745958},
  shortjournal = {Front. Robot. AI},
  title        = {Characterization of indicators for adaptive human-swarm teaming},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Serious games strategies with cable-driven robots for
bimanual rehabilitation: A randomized controlled trial with post-stroke
patients. <em>FROBT</em>, <em>9</em>, 739088. (<a
href="https://doi.org/10.3389/frobt.2022.739088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cable-driven robots can be an ideal fit for performing post-stroke rehabilitation due to their specific features. For example, they have small and lightweight moving parts and a relatively large workspace. They also allow safe human-robot interactions and can be easily adapted to different patients and training protocols. However, the existing cable-driven robots are mostly unilateral devices that can allow only the rehabilitation of the most affected limb. This leaves unaddressed the rehabilitation of bimanual activities, which are predominant within the common Activities of Daily Living (ADL). Serious games can be integrated with cable-driven robots to further enhance their features by providing an interactive experience and by generating a high level of engagement in patients, while they can turn monotonous and repetitive therapy exercises into entertainment tasks. Additionally, serious game interfaces can collect detailed quantitative treatment information such as exercise time, velocities, and force, which can be very useful to monitor a patient’s progress and adjust the treatment protocols. Given the above-mentioned strong advantages of both cable driven robots, bimanual rehabilitation and serious games, this paper proposes and discusses a combination of them, in particular, for performing bilateral/bimanual rehabilitation tasks. The main design characteristics are analyzed for implementing the design of both the hardware and software components. The hardware design consists of a specifically developed cable-driven robot. The software design consists of a specifically developed serious game for performing bimanual rehabilitation exercises. The developed software also includes BiEval. This specific software allows to quantitatively measure and assess the rehabilitation therapy effects. An experimental validation is reported with 15 healthy subjects and a RCT (Randomized Controlled Trial) has been performed with 10 post-stroke patients at the Physiotherapy’s Clinic of the Federal University of Uberlândia (Minas Gerais, Brazil). The RCT results demonstrate the engineering feasibility and effectiveness of the proposed cable-driven robot in combination with the proposed BiEval software as a valuable tool to augment the conventional physiotherapy protocols and for providing reliable measurements of the patient’s rehabilitation performance and progress. The clinical trial was approved by the Research Ethics Committee of the UFU (Brazil) under the CAAE N° 00914818.5.0000.5152 on plataformabrasil@saude.gov.br.},
  archive      = {J_FROBT},
  author       = {Alves, Thiago and Gonçalves, Rogério Sales and Carbone, Giuseppe},
  doi          = {10.3389/frobt.2022.739088},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {739088},
  shortjournal = {Front. Robot. AI},
  title        = {Serious games strategies with cable-driven robots for bimanual rehabilitation: A randomized controlled trial with post-stroke patients},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Agree to disagree: Subjective fairness in privacy-restricted
decentralised conflict resolution. <em>FROBT</em>, <em>9</em>, 733876.
(<a href="https://doi.org/10.3389/frobt.2022.733876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness is commonly seen as a property of the global outcome of a system and assumes centralisation and complete knowledge. However, in real decentralised applications, agents only have partial observation capabilities. Under limited information, agents rely on communication to divulge some of their private (and unobservable) information to others. When an agent deliberates to resolve conflicts, limited knowledge may cause its perspective of a correct outcome to differ from the actual outcome of the conflict resolution. This is subjective unfairness. As human systems and societies are organised by rules and norms, hybrid human-agent and multi-agent environments of the future will require agents to resolve conflicts in a decentralised and rule-aware way. Prior work achieves such decentralised, rule-aware conflict resolution through cultures: explainable architectures that embed human regulations and norms via argumentation frameworks with verification mechanisms. However, this prior work requires agents to have full state knowledge of each other, whereas many distributed applications in practice admit partial observation capabilities, which may require agents to communicate and carefully opt to release information if privacy constraints apply. To enable decentralised, fairness-aware conflict resolution under privacy constraints, we have two contributions: 1) a novel interaction approach and 2) a formalism of the relationship between privacy and fairness. Our proposed interaction approach is an architecture for privacy-aware explainable conflict resolution where agents engage in a dialogue of hypotheses and facts. To measure the privacy-fairness relationship, we define subjective and objective fairness on both the local and global scope and formalise the impact of partial observability due to privacy in these different notions of fairness. We first study our proposed architecture and the privacy-fairness relationship in the abstract, testing different argumentation strategies on a large number of randomised cultures. We empirically demonstrate the trade-off between privacy, objective fairness, and subjective fairness and show that better strategies can mitigate the effects of privacy in distributed systems. In addition to this analysis across a broad set of randomised abstract cultures, we analyse a case study for a specific scenario: we instantiate our architecture in a multi-agent simulation of prioritised rule-aware collision avoidance with limited information disclosure.},
  archive      = {J_FROBT},
  author       = {Raymond , Alex and Malencia , Matthew and Paulino-Passos , Guilherme and Prorok , Amanda},
  doi          = {10.3389/frobt.2022.733876},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {733876},
  shortjournal = {Front. Robot. AI},
  title        = {Agree to disagree: Subjective fairness in privacy-restricted decentralised conflict resolution},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Introducing a smart city component in a robotic competition:
A field report. <em>FROBT</em>, <em>9</em>, 728628. (<a
href="https://doi.org/10.3389/frobt.2022.728628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, two fields have become more prominent in our everyday life: smart cities and service robots. In a smart city, information is collected from distributed sensors around the city into centralised data hubs and used to improve the efficiency of the city systems and provide better services to citizens. Exploiting major advances in Computer Vision and Machine Learning, service robots have evolved from performing simple tasks to playing the role of hotel concierges, museum guides, waiters in cafes and restaurants, home assistants, automated delivery drones, and more. As digital agents, robots can be prime members of the smart city vision. On the one hand, smart city data can be accessed by robots to gain information that is relevant to the task in hand. On the other hand, robots can act as mobile sensors and actuators on behalf of the smart city, thus contributing to the data acquisition process. However, the connection between service robots and smart cities is surprisingly under-explored. In an effort to stimulate advances on the integration between robots and smart cities, we turned to robot competitions and hosted the first Smart Cities Robotics Challenge (SciRoc). The contest included activities specifically designed to require cooperation between robots and the MK Data Hub, a Smart City data infrastructure. In this article, we report on the competition held in Milton Keynes (UK) in September 2019, focusing in particular on the role played by the MK Data Hub in simulating a Smart City Data Infrastructure for service robots. Additionally, we discuss the feedback we received from the various people involved in the SciRoc Challenge, including participants, members of the public and organisers, and summarise the lessons learnt from this experience.},
  archive      = {J_FROBT},
  author       = {Bardaro, Gianluca and Daga, Enrico and Carvalho, Jason and Chiatti, Agnese and Motta, Enrico},
  doi          = {10.3389/frobt.2022.728628},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {728628},
  shortjournal = {Front. Robot. AI},
  title        = {Introducing a smart city component in a robotic competition: A field report},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Affect-driven learning of robot behaviour for collaborative
human-robot interactions. <em>FROBT</em>, <em>9</em>, 717193. (<a
href="https://doi.org/10.3389/frobt.2022.717193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative interactions require social robots to share the users’ perspective on the interactions and adapt to the dynamics of their affective behaviour. Yet, current approaches for affective behaviour generation in robots focus on instantaneous perception to generate a one-to-one mapping between observed human expressions and static robot actions. In this paper, we propose a novel framework for affect-driven behaviour generation in social robots. The framework consists of (i) a hybrid neural model for evaluating facial expressions and speech of the users, forming intrinsic affective representations in the robot, (ii) an Affective Core, that employs self-organising neural models to embed behavioural traits like patience and emotional actuation that modulate the robot’s affective appraisal, and (iii) a Reinforcement Learning model that uses the robot’s appraisal to learn interaction behaviour. We investigate the effect of modelling different affective core dispositions on the affective appraisal and use this affective appraisal as the motivation to generate robot behaviours. For evaluation, we conduct a user study (n = 31) where the NICO robot acts as a proposer in the Ultimatum Game. The effect of the robot’s affective core on its negotiation strategy is witnessed by participants, who rank a patient robot with high emotional actuation higher on persistence, while an impatient robot with low emotional actuation is rated higher on its generosity and altruistic behaviour.},
  archive      = {J_FROBT},
  author       = {Churamani, Nikhil and Barros, Pablo and Gunes, Hatice and Wermter, Stefan},
  doi          = {10.3389/frobt.2022.717193},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {717193},
  shortjournal = {Front. Robot. AI},
  title        = {Affect-driven learning of robot behaviour for collaborative human-robot interactions},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Primitive action based combined task and motion planning for
the service robot. <em>FROBT</em>, <em>9</em>, 713470. (<a
href="https://doi.org/10.3389/frobt.2022.713470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for combined task and motion planning (CTAMP) in robotics is well known as robotic technologies become more mature. The goal of CTAMP is to determine a proper sequence of a robot’s actions based on symbolic and geometric reasoning. Because of the fundamental difference in symbolic and geometric reasoning, a CTAMP system often requires an interface module between the two reasoning modules. We propose a CTAMP system in which a symbolic action sequence is generated in task planning, and each action is verified geometrically in motion planning using the off-the-shelf planners and reasoners. The approach is that a set of action models is defined with PDDL in the interface module (action library) and the required information to each planner is automatically provided by the interface module. The proposed method was successfully implemented in three simulated experiments that involve manipulation tasks. According to our findings, the proposed method is effective in responding to changes in the environment and uncertainty with errors in recognition of the environment and the robot motion control.},
  archive      = {J_FROBT},
  author       = {Jeon, Jeongmin and Jung, Hong-ryul and Yumbla, Francisco and Luong, Tuan Anh and Moon, Hyungpil},
  doi          = {10.3389/frobt.2022.713470},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {713470},
  shortjournal = {Front. Robot. AI},
  title        = {Primitive action based combined task and motion planning for the service robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An autonomous task assignment paradigm for autonomous
robotic in-space assembly. <em>FROBT</em>, <em>9</em>, 709905. (<a
href="https://doi.org/10.3389/frobt.2022.709905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of autonomous robotic systems is a key component in the expansion of space exploration and the development of infrastructures for in-space applications. An important capability for these robotic systems is the ability to maintain and repair structures in the absence of human input by autonomously generating valid task sequences and task to robot allocations. To this end, a novel stochastic problem formulation paired with a mixed integer programming assembly schedule generator has been developed to articulate the elements, constraints, and state of an assembly project and solve for an optimal assembly schedule. The developed formulations were tested with a set of hardware experiments that included generating an optimal schedule for an assembly and rescheduling during an assembly to plan a repair. This formulation and validation work provides a path forward for future research in the development of an autonomous system capable of building and maintaining in-space infrastructures.},
  archive      = {J_FROBT},
  author       = {Moser, Joshua and Hoffman, Julia and Hildebrand, Robert and Komendera, Erik},
  doi          = {10.3389/frobt.2022.709905},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {709905},
  shortjournal = {Front. Robot. AI},
  title        = {An autonomous task assignment paradigm for autonomous robotic in-space assembly},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Localization and mapping on agriculture based on
point-feature extraction and semiplanes segmentation from 3D LiDAR data.
<em>FROBT</em>, <em>9</em>, 832165. (<a
href="https://doi.org/10.3389/frobt.2022.832165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing ground robots for agriculture is a demanding task. Robots should be capable of performing tasks like spraying, harvesting, or monitoring. However, the absence of structure in the agricultural scenes challenges the implementation of localization and mapping algorithms. Thus, the research and development of localization techniques are essential to boost agricultural robotics. To address this issue, we propose an algorithm called VineSLAM suitable for localization and mapping in agriculture. This approach uses both point- and semiplane-features extracted from 3D LiDAR data to map the environment and localize the robot using a novel Particle Filter that considers both feature modalities. The numeric stability of the algorithm was tested using simulated data. The proposed methodology proved to be suitable to localize a robot using only three orthogonal semiplanes. Moreover, the entire VineSLAM pipeline was compared against a state-of-the-art approach considering three real-world experiments in a woody-crop vineyard. Results show that our approach can localize the robot with precision even in long and symmetric vineyard corridors outperforming the state-of-the-art algorithm in this context.},
  archive      = {J_FROBT},
  author       = {Aguiar, André Silva and Neves dos Santos, Filipe and Sobreira, Héber and Boaventura-Cunha, José and Sousa, Armando Jorge},
  doi          = {10.3389/frobt.2022.832165},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {832165},
  shortjournal = {Front. Robot. AI},
  title        = {Localization and mapping on agriculture based on point-feature extraction and semiplanes segmentation from 3D LiDAR data},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating the usability, efficacy and accuracy of a
medication entering software system for a healthcare robot.
<em>FROBT</em>, <em>9</em>, 814268. (<a
href="https://doi.org/10.3389/frobt.2022.814268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: This research aimed to evaluate medication software for a healthcare robot. Study I compared two software versions (RoboGen and RoboGen2) for system usability, speed and accuracy of medication entry; Study II evaluated system usability and community pharmacists’ views of RoboGen2.Methods: Study I had a within-subjects experimental design and recruited 40 Health Sciences students to enter different, comparable sets of prescriptions into the two systems, in randomized order, within a limit of 15 min. Screen activity was recorded to observe prescription errors. Study II had a cross-sectional observational design and recruited 20 community pharmacists using convenience sampling. Pharmacists entered three prescriptions using RoboGen2. Participants in both studies completed the System Usability Scale (SUS) following each task. Study I participants completed a questionnaire on system preference, and Study II participants a semi-structured interview.Results: Study I participants preferred Robogen2 (p &amp;lt; 0.001) due to its sleek and modern layout, good flow, ease of use, and intuitive design. SUS scores [t (40) = −3.40, p = 0.002] and speed of medication entry favored Robogen2 (t = 3.65, p &amp;lt; 0.001). No significance was found in accuracy (t = 1.12, p = 0.27). In study 2, pharmacists rated the usability of RoboGen2 below average. Themes from interviews were navigation and streamlining the system, ease of use, and integration with pharmacy software systems.Conclusion: Adding safety features and better aesthetics can improve the usability and safety of a medication prescription system. Streamlining workflow and pre-populating data can increase speed of prescription entry without compromising patient safety. However, a better approach is integration with pre-existing pharmacy systems to reduce workload while incorporating safety features built into existing dispensing systems.},
  archive      = {J_FROBT},
  author       = {Martini, Nataly and Broadbent, Elizabeth and Koo, Jasmine and Lam, Laurence and Verches, Diane and Zeng, Sophie and Montgomery-Walsh, Rhea and Sutherland, Craig},
  doi          = {10.3389/frobt.2022.814268},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {814268},
  shortjournal = {Front. Robot. AI},
  title        = {Investigating the usability, efficacy and accuracy of a medication entering software system for a healthcare robot},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Do robotic tutors compromise the social-emotional
development of children? <em>FROBT</em>, <em>9</em>, 734955. (<a
href="https://doi.org/10.3389/frobt.2022.734955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots are reported to hold great potential for education. However, both scholars and key stakeholders worry about children’s social-emotional development being compromised. In aiming to provide new insights into the impact that social robots can have on the social-emotional development of children, the current study interviewed teachers who use social robots in their day-to-day educational practice. The results of our interviews with these experienced teachers indicate that the social robots currently used in education pose little threat to the social-emotional development of children. Children with special needs seem to be more sensitive to social-affective bonding with a robot compared to regular children. This bond seems to have positive effects in enabling them to more easily connect with their human peers and teachers. However, when robots are being introduced more regularly, daily, without the involvement of a human teacher, new issues could arise. For now, given the current state of technology and the way social robots are being applied, other (ethical) issues seem to be more urgent, such as privacy, security and the workload of teachers. Future studies should focus on these issues first, to ensure a safe and effective educational environment for both children and teachers.},
  archive      = {J_FROBT},
  author       = {Smakman, Matthijs H. J. and Konijn, Elly A. and Vogt, Paul A.},
  doi          = {10.3389/frobt.2022.734955},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {734955},
  shortjournal = {Front. Robot. AI},
  title        = {Do robotic tutors compromise the social-emotional development of children?},
  volume       = {9},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Towards real-world deployment of legged robots.
<em>FROBT</em>, <em>8</em>, 829403. (<a
href="https://doi.org/10.3389/frobt.2021.829403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kottege, Navinda and Sentis, Luis and Kanoulas, Dimitrios},
  doi          = {10.3389/frobt.2021.829403},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {829403},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Towards real-world deployment of legged robots},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design, modeling, and visual learning-based control of soft
robotic fish driven by super-coiled polymers. <em>FROBT</em>,
<em>8</em>, 809427. (<a
href="https://doi.org/10.3389/frobt.2021.809427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rapidly growing field of aquatic bio-inspired soft robotics takes advantage of the underwater animals’ bio-mechanisms, where its applications are foreseen in a vast domain such as underwater exploration, environmental monitoring, search and rescue, oil-spill detection, etc. Improved maneuverability and locomotion of such robots call for designs with higher level of biomimicry, reduced order of complex modeling due to continuum elastic dynamics, and challenging robust nonlinear controllers. This paper presents a novel design of a soft robotic fish actively actuated by a newly developed kind of artificial muscles—super-coiled polymers (SCP) and passively propelled by a caudal fin. Besides SCP exhibiting several advantages in terms of flexibility, cost and fabrication duration, this design benefits from the SCP’s significantly quicker recovery due to water-based cooling. The soft robotic fish is approximated as a 3-link representation and mathematically modeled from its geometric and dynamic perspectives to constitute the combined system dynamics of the SCP actuators and hydrodynamics of the fish, thus realizing two-dimensional fish-swimming motion. The nonlinear dynamic model of the SCP driven soft robotic fish, ignoring uncertainties and unmodeled dynamics, necessitates the development of robust/intelligent control which serves as the motivation to not only mimic the bio-mechanisms, but also mimic the cognitive abilities of a real fish. Therefore, a learning-based control design is proposed to meet the yaw control objective and study its performance in path following via various swimming patterns. The proposed learning-based control design employs the use of deep-deterministic policy gradient (DDPG) reinforcement learning algorithm to train the agent. To overcome the limitations of sensing the soft robotic fish’s states by designing complex embedded sensors, overhead image-based observations are generated and input to convolutional neural networks (CNNs) to deduce the curvature dynamics of the soft robot. A linear quadratic regulator (LQR) based multi-objective reward is proposed to reinforce the learning feedback of the agent during training. The DDPG-based control design is simulated and the corresponding results are presented.},
  archive      = {J_FROBT},
  author       = {Rajendran, Sunil Kumar and Zhang, Feitian},
  doi          = {10.3389/frobt.2021.809427},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {809427},
  shortjournal = {Front. Robot. AI},
  title        = {Design, modeling, and visual learning-based control of soft robotic fish driven by super-coiled polymers},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On aerial robots with grasping and perching capabilities: A
comprehensive review. <em>FROBT</em>, <em>8</em>, 739173. (<a
href="https://doi.org/10.3389/frobt.2021.739173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, there has been an increased interest in developing aerial robotic platforms that exhibit grasping and perching capabilities not only within the research community but also in companies across different industry sectors. Aerial robots range from standard multicopter vehicles/drones, to autonomous helicopters, and fixed-wing or hybrid devices. Such devices rely on a range of different solutions for achieving grasping and perching. These solutions can be classified as: 1) simple gripper systems, 2) arm-gripper systems, 3) tethered gripping mechanisms, 4) reconfigurable robot frames, 5) adhesion solutions, and 6) embedment solutions. Grasping and perching are two crucial capabilities that allow aerial robots to interact with the environment and execute a plethora of complex tasks, facilitating new applications that range from autonomous package delivery and search and rescue to autonomous inspection of dangerous or remote environments. In this review paper, we present the state-of-the-art in aerial grasping and perching mechanisms and we provide a comprehensive comparison of their characteristics. Furthermore, we analyze these mechanisms by comparing the advantages and disadvantages of the proposed technologies and we summarize the significant achievements in these two research topics. Finally, we conclude the review by suggesting a series of potential future research directions that we believe that are promising.},
  archive      = {J_FROBT},
  author       = {Meng, Jiawei and Buzzatto, Joao and Liu, Yuanchang and Liarokapis, Minas},
  doi          = {10.3389/frobt.2021.739173},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {739173},
  shortjournal = {Front. Robot. AI},
  title        = {On aerial robots with grasping and perching capabilities: A comprehensive review},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exodex adam—a reconfigurable dexterous haptic user interface
for the whole hand. <em>FROBT</em>, <em>8</em>, 716598. (<a
href="https://doi.org/10.3389/frobt.2021.716598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications for dexterous robot teleoperation and immersive virtual reality are growing. Haptic user input devices need to allow the user to intuitively command and seamlessly “feel” the environment they work in, whether virtual or a remote site through an avatar. We introduce the DLR Exodex Adam, a reconfigurable, dexterous, whole-hand haptic input device. The device comprises multiple modular, three degrees of freedom (3-DOF) robotic fingers, whose placement on the device can be adjusted to optimize manipulability for different user hand sizes. Additionally, the device is mounted on a 7-DOF robot arm to increase the user’s workspace. Exodex Adam uses a front-facing interface, with robotic fingers coupled to two of the user’s fingertips, the thumb, and two points on the palm. Including the palm, as opposed to only the fingertips as is common in existing devices, enables accurate tracking of the whole hand without additional sensors such as a data glove or motion capture. By providing “whole-hand” interaction with omnidirectional force-feedback at the attachment points, we enable the user to experience the environment with the complete hand instead of only the fingertips, thus realizing deeper immersion. Interaction using Exodex Adam can range from palpation of objects and surfaces to manipulation using both power and precision grasps, all while receiving haptic feedback. This article details the concept and design of the Exodex Adam, as well as use cases where it is deployed with different command modalities. These include mixed-media interaction in a virtual environment, gesture-based telemanipulation, and robotic hand–arm teleoperation using adaptive model-mediated teleoperation. Finally, we share the insights gained during our development process and use case deployments.},
  archive      = {J_FROBT},
  author       = {Lii, Neal Y. and Pereira, Aaron and Dietl, Julian and Stillfried, Georg and Schmidt, Annika and Beik-Mohammadi, Hadi and Baker, Thomas and Maier, Annika and Pleintinger, Benedikt and Chen, Zhaopeng and Elawad, Amal and Mentzer , Lauren and Pineault, Austin and Reisich, Philipp and Albu-Schäffer, Alin},
  doi          = {10.3389/frobt.2021.716598},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {716598},
  shortjournal = {Front. Robot. AI},
  title        = {Exodex Adam—A reconfigurable dexterous haptic user interface for the whole hand},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A robotic test rig for performance assessment of prosthetic
joints. <em>FROBT</em>, <em>8</em>, 613579. (<a
href="https://doi.org/10.3389/frobt.2021.613579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Movement within the human body is made possible by joints connecting two or more elements of the musculoskeletal system. Losing one or more of these connections can seriously limit mobility, which in turn can lead to depression and other mental issues. This is particularly pertinent due to a dramatic increase in the number of lower limb amputations resulting from trauma and diseases such as diabetes. The ideal prostheses should re-establish the functions and movement of the missing body part of the patient. As a result, the prosthetic solution has to be tested stringently to ensure effective and reliable usage. This paper elaborates on the development, features, and suitability of a testing rig that can evaluate the performance of prosthetic and robotic joints via cyclic dynamic loading on their complex movements. To establish the rig’s validity, the knee joint was chosen as it provides both compound support and movement, making it one of the major joints within the human body, and an excellent subject to ensure the quality of the prosthesis. Within the rig system, a motorised lead-screw simulates the actuation provided by the hamstring-quadricep antagonist muscle pair and the flexion experienced by the joint. Loads and position are monitored by a load cell and proximity sensors respectively, ensuring the dynamics conform with the geometric model and gait analysis.Background: Robotics, Prosthetics, Mechatronics, Assisted Living.Methods: Gait Analysis, Computer Aided Design, Geometry Models.Conclusion: Modular Device, Streamlining Rehabilitation.},
  archive      = {J_FROBT},
  author       = {Etoundi, Appolinaire C. and Dobner, Alexander and Agrawal, Subham and Semasinghe, Chathura L. and Georgilas, Ioannis and Jafari, Aghil},
  doi          = {10.3389/frobt.2021.613579},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {613579},
  shortjournal = {Front. Robot. AI},
  title        = {A robotic test rig for performance assessment of prosthetic joints},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A method for measuring contact points in human–object
interaction utilizing infrared cameras. <em>FROBT</em>, <em>8</em>,
800131. (<a href="https://doi.org/10.3389/frobt.2021.800131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel method for measuring contact points in human–object interaction. Research in multiple prehension-related fields, e.g., action planning, affordance, motor function, ergonomics, and robotic grasping, benefits from accurate and precise measurements of contact points between a subject’s hands and objects. During interaction, the subject’s hands occlude the contact points, which poses a major challenge for direct optical measurement methods. Our method solves the occlusion problem by exploiting thermal energy transfer from the subject’s hand to the object surface during interaction. After the interaction, we measure the heat emitted by the object surface with four high-resolution infrared cameras surrounding the object. A computer-vision algorithm detects the areas in the infrared images where the subject’s fingers have touched the object. A structured light 3D scanner produces a point cloud of the scene, which enables the localization of the object in relation to the infrared cameras. We then use the localization result to project the detected contact points from the infrared camera images to the surface of the 3D model of the object. Data collection with this method is fast, unobtrusive, contactless, markerless, and automated. The method enables accurate measurement of contact points in non-trivially complex objects. Furthermore, the method is extendable to measuring surface contact areas, or patches, instead of contact points. In this article, we present the method and sample grasp measurement results with publicly available objects.},
  archive      = {J_FROBT},
  author       = {Hakala, Jussi and Häkkinen, Jukka},
  doi          = {10.3389/frobt.2021.800131},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {800131},
  shortjournal = {Front. Robot. AI},
  title        = {A method for measuring contact points in Human–Object interaction utilizing infrared cameras},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An augmented multiple imputation particle filter for river
state estimation with missing observation. <em>FROBT</em>, <em>8</em>,
788125. (<a href="https://doi.org/10.3389/frobt.2021.788125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a new form of data assimilation (DA) method namely multiple imputation particle filter with smooth variable structure filter (MIPF–SVSF) is proposed for river state estimation. This method is introduced to perform estimation during missing observation by presenting new sets of data. The contribution of this work is to overcome the missing observation, and at the same time improve the estimation performance. The convergence analysis of the MIPF–SVF is discussed and shows that the method depends on the number of particles and imputations. However, the number of particles and imputations is influenced by the error difference in the likelihood function. By bounding the error, the ability of the method can be improved and the number of particles and computational time are reduced. The comparison between the proposed method with EKF during complete data and multiple imputation particle filter shows the effectiveness of the MIPF–SVSF. The percentage improvement of the proposed method compared to MIPF in terms of root mean square error is between 12 and 13.5%, standard deviation is between 14 and 15%, mean absolute error is between 2 and 7%, and the computational error is reduced between 73 and 90% of the length of time required to perform the estimation process.},
  archive      = {J_FROBT},
  author       = {Ismail, Z. H. and Jalaludin, N. A.},
  doi          = {10.3389/frobt.2021.788125},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {788125},
  shortjournal = {Front. Robot. AI},
  title        = {An augmented multiple imputation particle filter for river state estimation with missing observation},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Balancing collective exploration and exploitation in
multi-agent and multi-robot systems: A review. <em>FROBT</em>,
<em>8</em>, 771520. (<a
href="https://doi.org/10.3389/frobt.2021.771520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent systems and multi-robot systems have been recognized as unique solutions to complex dynamic tasks distributed in space. Their effectiveness in accomplishing these tasks rests upon the design of cooperative control strategies, which is acknowledged to be challenging and nontrivial. In particular, the effectiveness of these strategies has been shown to be related to the so-called exploration–exploitation dilemma: i.e., the existence of a distinct balance between exploitative actions and exploratory ones while the system is operating. Recent results point to the need for a dynamic exploration–exploitation balance to unlock high levels of flexibility, adaptivity, and swarm intelligence. This important point is especially apparent when dealing with fast-changing environments. Problems involving dynamic environments have been dealt with by different scientific communities using theory, simulations, as well as large-scale experiments. Such results spread across a range of disciplines can hinder one’s ability to understand and manage the intricacies of the exploration–exploitation challenge. In this review, we summarize and categorize the methods used to control the level of exploration and exploitation carried out by an multi-agent systems. Lastly, we discuss the critical need for suitable metrics and benchmark problems to quantitatively assess and compare the levels of exploration and exploitation, as well as the overall performance of a system with a given cooperative control algorithm.},
  archive      = {J_FROBT},
  author       = {Kwa , Hian Lee and Leong Kit , Jabez and Bouffanais , Roland},
  doi          = {10.3389/frobt.2021.771520},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {771520},
  shortjournal = {Front. Robot. AI},
  title        = {Balancing collective exploration and exploitation in multi-agent and multi-robot systems: A review},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How to be helpful? Supportive behaviors and personalization
for human-robot collaboration. <em>FROBT</em>, <em>8</em>, 725780. (<a
href="https://doi.org/10.3389/frobt.2021.725780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Human-Robot Collaboration (HRC) has seen a considerable amount of progress in recent years. Thanks in part to advances in control and perception algorithms, robots have started to work in increasingly unstructured environments, where they operate side by side with humans to achieve shared tasks. However, little progress has been made toward the development of systems that are truly effective in supporting the human, proactive in their collaboration, and that can autonomously take care of part of the task. In this work, we present a collaborative system capable of assisting a human worker despite limited manipulation capabilities, incomplete model of the task, and partial observability of the environment. Our framework leverages information from a high-level, hierarchical model that is shared between the human and robot and that enables transparent synchronization between the peers and mutual understanding of each other’s plan. More precisely, we firstly derive a partially observable Markov model from the high-level task representation; we then use an online Monte-Carlo solver to compute a short-horizon robot-executable plan. The resulting policy is capable of interactive replanning on-the-fly, dynamic error recovery, and identification of hidden user preferences. We demonstrate that the system is capable of robustly providing support to the human in a realistic furniture construction task.},
  archive      = {J_FROBT},
  author       = {Mangin, Olivier and Roncone, Alessandro and Scassellati, Brian},
  doi          = {10.3389/frobt.2021.725780},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {725780},
  shortjournal = {Front. Robot. AI},
  title        = {How to be helpful? supportive behaviors and personalization for human-robot collaboration},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LPMP: A bio-inspired model for visual localization in
challenging environments. <em>FROBT</em>, <em>8</em>, 703811. (<a
href="https://doi.org/10.3389/frobt.2021.703811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles require precise and reliable self-localization to cope with dynamic environments. The field of visual place recognition (VPR) aims to solve this challenge by relying on the visual modality to recognize a place despite changes in the appearance of the perceived visual scene. In this paper, we propose to tackle the VPR problem following a neuro-cybernetic approach. To this end, the Log-Polar Max-Pi (LPMP) model is introduced. This bio-inspired neural network allows building a neural representation of the environment via an unsupervised one-shot learning. Inspired by the spatial cognition of mammals, visual information in the LPMP model are processed through two distinct pathways: a “what” pathway that extracts and learns the local visual signatures (landmarks) of a visual scene and a “where” pathway that computes their azimuth. These two pieces of information are then merged to build a visuospatial code that is characteristic of the place where the visual scene was perceived. Three main contributions are presented in this article: 1) the LPMP model is studied and compared with NetVLAD and CoHog, two state-of-the-art VPR models; 2) a test benchmark for the evaluation of VPR models according to the type of environment traveled is proposed based on the Oxford car dataset; and 3) the impact of the use of a novel detector leading to an uneven paving of an environment is evaluated in terms of the localization performance and compared to a regular paving. Our experiments show that the LPMP model can achieve comparable or better localization performance than NetVLAD and CoHog.},
  archive      = {J_FROBT},
  author       = {Colomer, Sylvain and Cuperlier, Nicolas and Bresson, Guillaume and Gaussier, Philippe and Romain, Olivier},
  doi          = {10.3389/frobt.2021.703811},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {703811},
  shortjournal = {Front. Robot. AI},
  title        = {LPMP: A bio-inspired model for visual localization in challenging environments},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A statistical model to determine biomechanical limits for
physically safe interactions with collaborative robots. <em>FROBT</em>,
<em>8</em>, 667818. (<a
href="https://doi.org/10.3389/frobt.2021.667818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robots (cobots) provide a wide range of opportunities to improve the ergonomics and efficiency of manual work stations. ISO/TS 15066 defines power and force limiting (PFL) as one of four safeguarding modes for these robots. PFL specifies biomechanical limits for hazardous impacts and pinching contacts that a cobot must not exceed to protect humans from serious injuries. Most of the limits in ISO/TS 15066 are preliminary, since they are based on unverified data from a literature survey. This article presents a human-subject study that provides new and experimentally verified limits for biomechanically safe interactions between humans and cobots. The new limits are specifically tailored to impact and pinching transferred through blunt and semi-sharp surfaces as they can occur in the event of human error or technical failures. Altogether 112 subjects participated in the study and were subjected to tests with emulated impact and pinching loads at 28 different body locations. During the experiments, the contact force was gradually increased until the load evoked a slightly painful feeling on the subject’s body location under test. The results confirm that the pain thresholds of males and females are different in specific body regions. Therefore, when defining biomechanical limits, the gender difference must be taken into account. A regression model was utilized to incorporate the gender effect as a covariate into a conventional statistical distribution model that can be used to calculate individual limits, precisely fitted to a specific percentile of a mixed group of male and female workers which interacting with cobots.},
  archive      = {J_FROBT},
  author       = {Behrens , R. and Pliske , G. and Umbreit , M. and Piatek , S. and Walcher , F. and Elkmann , N.},
  doi          = {10.3389/frobt.2021.667818},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {667818},
  shortjournal = {Front. Robot. AI},
  title        = {A statistical model to determine biomechanical limits for physically safe interactions with collaborative robots},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-stabilized inverted pendulum made of optically
responsive liquid crystal elastomers. <em>FROBT</em>, <em>8</em>,
808262. (<a href="https://doi.org/10.3389/frobt.2021.808262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverted pendulum system has great potential for various engineering applications, and its stabilization is challenging because of its unstable characteristic. The well-known Kapitza’s pendulum adopts the parametrically excited oscillation to stabilize itself, which generally requires a complex controller. In this paper, self-sustained oscillation is utilized to stabilize an inverted pendulum, which is made of a V-shaped, optically responsive liquid crystal elastomer (LCE) bar under steady illumination. Based on the well-established dynamic LCE model, a theoretical model of the LCE inverted pendulum is formulated, and numerical calculations show that it always develops into the unstable static state or the self-stabilized oscillation state. The mechanism of the self-stabilized oscillation originates from the reversal of the gravity moment of the inverted pendulum accompanied with its own movement. The critical condition for triggering self-stabilized oscillation is fully investigated, and the effects of the system parameters on the stability of the inverted pendulum are explored. The self-stabilized inverted pendulum does not need an additional controller and offers new designs of self-stabilized inverted pendulum systems for potential applications in robotics, military industry, aerospace, and other fields.},
  archive      = {J_FROBT},
  author       = {Cheng, Quanbao and Zhou, Lin and Li, Kai},
  doi          = {10.3389/frobt.2021.808262},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {808262},
  shortjournal = {Front. Robot. AI},
  title        = {A self-stabilized inverted pendulum made of optically responsive liquid crystal elastomers},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A 3D printed modular soft gripper integrated with
metamaterials for conformal grasping. <em>FROBT</em>, <em>8</em>,
799230. (<a href="https://doi.org/10.3389/frobt.2021.799230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A single universal robotic gripper with the capacity to fulfill a wide variety of gripping and grasping tasks has always been desirable. A three-dimensional (3D) printed modular soft gripper with highly conformal soft fingers that are composed of positive pressure soft pneumatic actuators along with a mechanical metamaterial was developed. The fingers of the soft gripper along with the mechanical metamaterial, which integrates a soft auxetic structure and compliant ribs, was 3D printed in a single step, without requiring support material and postprocessing, using a low-cost and open-source fused deposition modeling (FDM) 3D printer that employs a commercially available thermoplastic poly (urethane) (TPU). The soft fingers of the gripper were optimized using finite element modeling (FEM). The FE simulations accurately predicted the behavior and performance of the fingers in terms of deformation and tip force. Also, FEM was used to predict the contact behavior of the mechanical metamaterial to prove that it highly decreases the contact pressure by increasing the contact area between the soft fingers and the grasped objects and thus proving its effectiveness in enhancing the grasping performance of the gripper. The contact pressure can be decreased by up to 8.5 times with the implementation of the mechanical metamaterial. The configuration of the highly conformal gripper can be easily modulated by changing the number of fingers attached to its base to tailor it for specific manipulation tasks. Two-dimensional (2D) and 3D grasping experiments were conducted to assess the grasping performance of the soft modular gripper and to prove that the inclusion of the metamaterial increases its conformability and reduces the out-of-plane deformations of the soft monolithic fingers upon grasping different objects and consequently, resulting in the gripper in three different configurations including two, three and four-finger configurations successfully grasping a wide variety of objects.},
  archive      = {J_FROBT},
  author       = {Tawk, Charbel and Mutlu, Rahim and Alici, Gursel},
  doi          = {10.3389/frobt.2021.799230},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {799230},
  shortjournal = {Front. Robot. AI},
  title        = {A 3D printed modular soft gripper integrated with metamaterials for conformal grasping},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Editorial: Interfacing humans and machines for
rehabilitation and assistive devices. <em>FROBT</em>, <em>8</em>,
796431. (<a href="https://doi.org/10.3389/frobt.2021.796431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Cifuentes, Carlos A. and Veneman, Jan F. and Rocon, Eduardo and Rodriguez-Guerrero, Carlos},
  doi          = {10.3389/frobt.2021.796431},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {796431},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Interfacing humans and machines for rehabilitation and assistive devices},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One soft step: Bio-inspired artificial muscle mechanisms for
space applications. <em>FROBT</em>, <em>8</em>, 792831. (<a
href="https://doi.org/10.3389/frobt.2021.792831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots, devices with deformable bodies and powered by soft actuators, may fill a hitherto unexplored niche in outer space. All space-bound payloads are heavily limited in terms of mass and volume, due to the cost of launch and the size of spacecraft. Being constructed from stretchable materials allows many possibilities for compacting soft robots for launch and later deploying into a much larger volume, through folding, rolling, and inflation. This morphability can also be beneficial for adapting to operation in different environments, providing versatility, and robustness. To be truly soft, a robot must be powered by soft actuators. Dielectric elastomer transducers (DETs) offer many advantages as artificial muscles. They are lightweight, have a high work density, and are capable of artificial proprioception. Taking inspiration from nature, in particular the starfish podia, we present here bio-inspired inflatable DET actuators powering low-mass robots capable of performing complex motion that can be compacted to a fraction of their operating size.},
  archive      = {J_FROBT},
  author       = {Ashby, Joseph and Rosset, Samuel and Henke, E.-F. Markus and Anderson, Iain A.},
  doi          = {10.3389/frobt.2021.792831},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {792831},
  shortjournal = {Front. Robot. AI},
  title        = {One soft step: Bio-inspired artificial muscle mechanisms for space applications},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Undulatory swimming performance explored with a biorobotic
fish and measured by soft sensors and particle image velocimetry.
<em>FROBT</em>, <em>8</em>, 791722. (<a
href="https://doi.org/10.3389/frobt.2021.791722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the difficulty of manipulating muscle activation in live, freely swimming fish, a thorough examination of the body kinematics, propulsive performance, and muscle activity patterns in fish during undulatory swimming motion has not been conducted. We propose to use soft robotic model animals as experimental platforms to address biomechanics questions and acquire understanding into subcarangiform fish swimming behavior. We extend previous research on a bio-inspired soft robotic fish equipped with two pneumatic actuators and soft strain sensors to investigate swimming performance in undulation frequencies between 0.3 and 0.7 Hz and flow rates ranging from 0 to 20 &lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;c&lt;/mml:mi&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:math&gt; in a recirculating flow tank. We demonstrate the potential of eutectic gallium–indium (eGaIn) sensors to measure the lateral deflection of a robotic fish in real time, a controller that is able to keep a constant undulatory amplitude in varying flow conditions, as well as using Particle Image Velocimetry (PIV) to characterizing swimming performance across a range of flow speeds and give a qualitative measurement of thrust force exerted by the physical platform without the need of externally attached force sensors. A detailed wake structure was then analyzed with Dynamic Mode Decomposition (DMD) to highlight different wave modes present in the robot’s swimming motion and provide insights into the efficiency of the robotic swimmer. In the future, we anticipate 3D-PIV with DMD serving as a global framework for comparing the performance of diverse bio-inspired swimming robots against a variety of swimming animals.},
  archive      = {J_FROBT},
  author       = {Schwab, Fabian and Wiesemüller, Fabian and Mucignat, Claudio and Park, Yong-Lae and Lunati, Ivan and Kovac, Mirko and Jusufi, Ardian},
  doi          = {10.3389/frobt.2021.791722},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {791722},
  shortjournal = {Front. Robot. AI},
  title        = {Undulatory swimming performance explored with a biorobotic fish and measured by soft sensors and particle image velocimetry},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empathizing and sympathizing with robots: Implications for
moral standing. <em>FROBT</em>, <em>8</em>, 791527. (<a
href="https://doi.org/10.3389/frobt.2021.791527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the ethical nature of empathetic and sympathetic engagement with social robots, ultimately arguing that an entity which is engaged with through empathy or sympathy is engaged with as an “experiencing Other” and is as such due at least “minimal” moral consideration. Additionally, it is argued that extant HRI research often fails to recognize the complexity of empathy and sympathy, such that the two concepts are frequently treated as synonymous. The arguments for these claims occur in two steps. First, it is argued that there are at least three understandings of empathy, such that particular care is needed when researching “empathy” in human-robot interactions. The phenomenological approach to empathy—perhaps the least utilized of the three discussed understandings—is the approach with the most direct implications for moral standing. Furthermore, because “empathy” and “sympathy” are often conflated, a novel account of sympathy which makes clear the difference between the two concepts is presented, and the importance for these distinctions is argued for. In the second step, the phenomenological insights presented before regarding the nature of empathy are applied to the problem of robot moral standing to argue that empathetic and sympathetic engagement with an entity constitute an ethical engagement with it. The paper concludes by offering several potential research questions that result from the phenomenological analysis of empathy in human-robot interactions.},
  archive      = {J_FROBT},
  author       = {Quick, Oliver Santiago},
  doi          = {10.3389/frobt.2021.791527},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {791527},
  shortjournal = {Front. Robot. AI},
  title        = {Empathizing and sympathizing with robots: Implications for moral standing},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary inverse material identification: Bespoke
characterization of soft materials using a metaheuristic algorithm.
<em>FROBT</em>, <em>8</em>, 790571. (<a
href="https://doi.org/10.3389/frobt.2021.790571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing interest in soft robotics has resulted in an increased demand for accurate and reliable material modelling. As soft robots experience high deformations, highly nonlinear behavior is possible. Several analytical models that are able to capture this nonlinear behavior have been proposed, however, accurately calibrating them for specific materials and applications can be challenging. Multiple experimental testbeds may be required for material characterization which can be expensive and cumbersome. In this work, we propose an alternative framework for parameter fitting established hyperelastic material models, with the aim of improving their utility in the modelling of soft continuum robots. We define a minimization problem to reduce fitting errors between a soft continuum robot deformed experimentally and its equivalent finite element simulation. The soft material is characterized using four commonly employed hyperelastic material models (Neo Hookean; Mooney–Rivlin; Yeoh; and Ogden). To meet the complexity of the defined problem, we use an evolutionary algorithm to navigate the search space and determine optimal parameters for a selected material model and a specific actuation method, naming this approach as Evolutionary Inverse Material Identification (EIMI). We test the proposed approach with a magnetically actuated soft robot by characterizing two polymers often employed in the field: Dragon Skin™ 10 MEDIUM and Ecoflex™ 00-50. To determine the goodness of the FEM simulation for a specific set of model parameters, we define a function that measures the distance between the mesh of the FEM simulation and the experimental data. Our characterization framework showed an improvement greater than 6% compared to conventional model fitting approaches at different strain ranges based on the benchmark defined. Furthermore, the low variability across the different models obtained using our approach demonstrates reduced dependence on model and strain-range selection, making it well suited to application-specific soft robot modelling.},
  archive      = {J_FROBT},
  author       = {Di Lecce, Michele and Onaizah, Onaizah and Lloyd, Peter and Chandler, James H. and Valdastri, Pietro},
  doi          = {10.3389/frobt.2021.790571},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {790571},
  shortjournal = {Front. Robot. AI},
  title        = {Evolutionary inverse material identification: Bespoke characterization of soft materials using a metaheuristic algorithm},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Challenges and opportunities in robotic food handling: A
review. <em>FROBT</em>, <em>8</em>, 789107. (<a
href="https://doi.org/10.3389/frobt.2021.789107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite developments in robotics and automation technologies, several challenges need to be addressed to fulfill the high demand for automating various manufacturing processes in the food industry. In our opinion, these challenges can be classified as: the development of robotic end-effectors to cope with large variations of food products with high practicality and low cost, recognition of food products and materials in 3D scenario, better understanding of fundamental information of food products including food categorization and physical properties from the viewpoint of robotic handling. In this review, we first introduce the challenges in robotic food handling and then highlight the advances in robotic end-effectors, food recognition, and fundamental information of food products related to robotic food handling. Finally, future research directions and opportunities are discussed based on an analysis of the challenges and state-of-the-art developments.},
  archive      = {J_FROBT},
  author       = {Wang, Zhongkui and Hirai, Shinichi and Kawamura, Sadao},
  doi          = {10.3389/frobt.2021.789107},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {789107},
  shortjournal = {Front. Robot. AI},
  title        = {Challenges and opportunities in robotic food handling: A review},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online gain adaptation of whole-body control for legged
robots with unknown disturbances. <em>FROBT</em>, <em>8</em>, 788902.
(<a href="https://doi.org/10.3389/frobt.2021.788902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an online gain adaptation approach to enhance the robustness of whole-body control (WBC) framework for legged robots under unknown external force disturbances. Without properly accounting for external forces, the closed-loop control system incorporating WBC may become unstable, and therefore the desired task goals may not be achievable. To study the effects of external disturbances, we analyze the behavior of our current WBC framework via the use of both full-body and centroidal dynamics. In turn, we propose a way to adapt feedback gains for stabilizing the controlled system automatically. Based on model approximations and stability theory, we propose three conditions to ensure that the adjusted gains are suitable for stabilizing a robot under WBC. The proposed approach has four contributions. We make it possible to estimate the unknown disturbances without force/torque sensors. We then compute adaptive gains based on theoretic stability analysis incorporating the unknown forces at the joint actuation level. We demonstrate that the proposed method reduces task tracking errors under the effect of external forces on the robot. In addition, the proposed method is easy-to-use without further modifications of the controllers and task specifications. The resulting gain adaptation process is able to run in real-time. Finally, we verify the effectiveness of our method both in simulations and experiments using the bipedal robot Draco2 and the humanoid robot Valkyrie.},
  archive      = {J_FROBT},
  author       = {Lee, Jaemin and Ahn, Junhyeok and Kim, Donghyun and Bang, Seung Hyeon and Sentis, Luis},
  doi          = {10.3389/frobt.2021.788902},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {788902},
  shortjournal = {Front. Robot. AI},
  title        = {Online gain adaptation of whole-body control for legged robots with unknown disturbances},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Does the correspondence bias apply to social robots?:
Dispositional and situational attributions of human versus robot
behavior. <em>FROBT</em>, <em>8</em>, 788242. (<a
href="https://doi.org/10.3389/frobt.2021.788242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasingly, people interact with embodied machine communicators and are challenged to understand their natures and behaviors. The Fundamental Attribution Error (FAE, sometimes referred to as the correspondence bias) is the tendency for individuals to over-emphasize personality-based or dispositional explanations for other people’s behavior while under-emphasizing situational explanations. This effect has been thoroughly examined with humans, but do people make the same causal inferences when interpreting the actions of a robot? As compared to people, social robots are less autonomous and agentic because their behavior is wholly determined by humans in the loop, programming, and design choices. Nonetheless, people do assign robots agency, intentionality, personality, and blame. Results of an experiment showed that participants made correspondent inferences when evaluating both human and robot speakers, attributing their behavior to underlying attitudes even when it was clearly coerced. However, they committed a stronger correspondence bias in the case of the robot–an effect driven by the greater dispositional culpability assigned to robots committing unpopular behavior–and they were more confident in their attitudinal judgments of robots than humans. Results demonstrated some differences in the global impressions of humans and robots based on behavior valence and choice. Judges formed more generous impressions of the robot agent when its unpopular behavior was coerced versus chosen; a tendency not displayed when forming impressions of the human agent. Implications of attributing robot behavior to disposition, or conflating robot actors with their actions, are addressed.},
  archive      = {J_FROBT},
  author       = {Edwards, Autumn and Edwards, Chad},
  doi          = {10.3389/frobt.2021.788242},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {788242},
  shortjournal = {Front. Robot. AI},
  title        = {Does the correspondence bias apply to social robots?: Dispositional and situational attributions of human versus robot behavior},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gradient legal personhood for AI systems—painting
continental legal shapes made to fit analytical molds. <em>FROBT</em>,
<em>8</em>, 788179. (<a
href="https://doi.org/10.3389/frobt.2021.788179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What I propose in the present article are some theoretical adjustments for a more coherent answer to the legal “status question” of artificial intelligence (AI) systems. I arrive at those by using the new “bundle theory” of legal personhood, together with its accompanying conceptual and methodological apparatus as a lens through which to look at a recent such answer inspired from German civil law and named Teilrechtsfähigkeit or partial legal capacity. I argue that partial legal capacity is a possible solution to the status question only if we understand legal personhood according to this new theory. Conversely, I argue that if indeed Teilrechtsfähigkeit lends itself to being applied to AI systems, then such flexibility further confirms the bundle theory paradigm shift. I then go on to further analyze and exploit the particularities of Teilrechtsfähigkeit to inform a reflection on the appropriate conceptual shape of legal personhood and suggest a slightly different answer from the bundle theory framework in what I term a “gradient theory” of legal personhood.},
  archive      = {J_FROBT},
  author       = {Mocanu, Diana Mădălina},
  doi          = {10.3389/frobt.2021.788179},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {788179},
  shortjournal = {Front. Robot. AI},
  title        = {Gradient legal personhood for AI Systems—Painting continental legal shapes made to fit analytical molds},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Morphological control of cilia-inspired asymmetric movements
using nonlinear soft inflatable actuators. <em>FROBT</em>, <em>8</em>,
788067. (<a href="https://doi.org/10.3389/frobt.2021.788067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robotic systems typically follow conventional control schemes, where actuators are supplied with dedicated inputs that are regulated through software. However, in recent years an alternative trend is being explored, where the control architecture can be simplified by harnessing the passive mechanical characteristics of the soft robotic system. This approach is named “morphological control”, and it can be used to decrease the number of components (tubing, valves and regulators) required by the controller. In this paper, we demonstrate morphological control of bio-inspired asymmetric motions for systems of soft bending actuators that are interconnected with passive flow restrictors. We introduce bending actuators consisting out of a cylindrical latex balloon in a flexible PVC shell. By tuning the radii of the tube and the shell, we obtain a nonlinear relation between internal pressure and volume in the actuator with a peak and valley in pressure. Because of the nonlinear characteristics of the actuators, they can be assembled in a system with a single pressure input where they bend in a discrete, preprogrammed sequence. We design and analyze two such systems inspired by the asymmetric movements of biological cilia. The first replicates the swept area of individual cilia, having a different forward and backward stroke, and the second generates a travelling wave across an array of cilia.},
  archive      = {J_FROBT},
  author       = {Milana, Edoardo and Van Raemdonck, Bert and Casla, Andrea Serrano and De Volder, Michael and Reynaerts, Dominiek and Gorissen, Benjamin},
  doi          = {10.3389/frobt.2021.788067},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {788067},
  shortjournal = {Front. Robot. AI},
  title        = {Morphological control of cilia-inspired asymmetric movements using nonlinear soft inflatable actuators},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward long-term sailing robots: State of the art from
energy perspectives. <em>FROBT</em>, <em>8</em>, 787253. (<a
href="https://doi.org/10.3389/frobt.2021.787253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sailing robots can contribute significantly to maritime surface exploration, due to its potential for long-range and long-duration motions in the environment with abundant wind. However, energy, the critical factor for their long-term missions, shall be carefully investigated, so as to achieve sustainability in distance and time. In this survey, we have conducted a comprehensive investigation on numerous sailing robots, developed in academia and industry. Some of them have achieved long-term operation, and some are motivated by, but still on the way to this ambitious goal. Prototypes are grouped in each team, so as to view the development path. We further investigate the existing design and control strategies for energy sufficiency from three perspectives: actuation, harvesting, and energy management. In propulsion and steering, i.e., two major actuations, researchers have accumulated effective sail and rudder designs. The motorized propeller and wave-glider–inspired mechanism also contribute as compliments for propulsion. Electricity harvesting based on solar or wind energies is also discussed to gather more power from nature. Pros and cons in strategies of energy management, which are valuable tools to enhance power utilization efficiency, are elaborated. This article is hoped to provide researchers in long-term robotic sailing with a comprehensive reference from the perspectives of energy.},
  archive      = {J_FROBT},
  author       = {Sun, Qinbo and Qi, Weimin and Liu, Hengli and Ji, Xiaoqiang and Qian, Huihuan},
  doi          = {10.3389/frobt.2021.787253},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {787253},
  shortjournal = {Front. Robot. AI},
  title        = {Toward long-term sailing robots: State of the art from energy perspectives},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mediating between contact feasibility and robustness of
trajectory optimization through chance complementarity constraints.
<em>FROBT</em>, <em>8</em>, 785925. (<a
href="https://doi.org/10.3389/frobt.2021.785925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As robots move from the laboratory into the real world, motion planning will need to account for model uncertainty and risk. For robot motions involving intermittent contact, planning for uncertainty in contact is especially important, as failure to successfully make and maintain contact can be catastrophic. Here, we model uncertainty in terrain geometry and friction characteristics, and combine a risk-sensitive objective with chance constraints to provide a trade-off between robustness to uncertainty and constraint satisfaction with an arbitrarily high feasibility guarantee. We evaluate our approach in two simple examples: a push-block system for benchmarking and a single-legged hopper. We demonstrate that chance constraints alone produce trajectories similar to those produced using strict complementarity constraints; however, when equipped with a robust objective, we show the chance constraints can mediate a trade-off between robustness to uncertainty and strict constraint satisfaction. Thus, our study may represent an important step towards reasoning about contact uncertainty in motion planning.},
  archive      = {J_FROBT},
  author       = {Drnach , Luke and Zhang , John Z. and Zhao, Ye},
  doi          = {10.3389/frobt.2021.785925},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {785925},
  shortjournal = {Front. Robot. AI},
  title        = {Mediating between contact feasibility and robustness of trajectory optimization through chance complementarity constraints},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preliminary study on a novel protocol for improving
familiarity with a lower-limb robotic exoskeleton in able-bodied,
first-time users. <em>FROBT</em>, <em>8</em>, 785251. (<a
href="https://doi.org/10.3389/frobt.2021.785251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower-limb exoskeletons have been created for different healthcare needs, but no research has been done on developing a proper protocol for users to get accustomed to moving with one. The user manuals provided also do not include such instructions. A pre-test was conducted with the TWIN (IIT), which is a lower-limb exoskeleton made for persons with spinal cord injury. In the pre-test, two healthy, able-bodied graduate students indicated a need for a protocol that can better prepare able-bodied, first-time users to move with an exoskeleton. TWIN was used in this preliminary study and nine users were divided to receive a tutorial or no tutorial before walking with the exoskeleton. Due to COVID-19 regulations, the study could only be performed with healthy, young-to-middle-aged lab members that do not require walking support. The proposed protocol was evaluated with the System Usability Scale, NASA Raw Task Load Index, and two custom surveys. The members who received the tutorial found it easy to follow and helpful, but the tutorial seemed to come at a price of higher perceived mental and physical demands, which could stem from the longer testing duration and the need to constantly recall and apply the things learned from the tutorial. All results presented are preliminary, and it is recommended to include biomechanical analysis and conduct the experiment with more participants in the future. Nonetheless, this proof-of-concept study lays groundwork for future related studies and the protocol will be adjusted, applied, and validated to patients and geriatric users.},
  archive      = {J_FROBT},
  author       = {Lau, Jan C. L. and Mombaur, Katja},
  doi          = {10.3389/frobt.2021.785251},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {785251},
  shortjournal = {Front. Robot. AI},
  title        = {Preliminary study on a novel protocol for improving familiarity with a lower-limb robotic exoskeleton in able-bodied, first-time users},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Who wants to grant robots rights? <em>FROBT</em>,
<em>8</em>, 781985. (<a
href="https://doi.org/10.3389/frobt.2021.781985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robot rights debate has thus far proceeded without any reliable data concerning the public opinion about robots and the rights they should have. We have administered an online survey (n = 439) that investigates layman’s attitudes toward granting particular rights to robots. Furthermore, we have asked them the reasons for their willingness to grant them those rights. Finally, we have administered general perceptions of robots regarding appearance, capacities, and traits. Results show that rights can be divided in sociopolitical and robot dimensions. Reasons can be distinguished along cognition and compassion dimensions. People generally have a positive view about robot interaction capacities. We found that people are more willing to grant basic robot rights such as access to energy and the right to update to robots than sociopolitical rights such as voting rights and the right to own property. Attitudes toward granting rights to robots depend on the cognitive and affective capacities people believe robots possess or will possess in the future. Our results suggest that the robot rights debate stands to benefit greatly from a common understanding of the capacity potentials of future robots.},
  archive      = {J_FROBT},
  author       = {De Graaf, Maartje M. A. and Hindriks, Frank A. and Hindriks, Koen V.},
  doi          = {10.3389/frobt.2021.781985},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {781985},
  shortjournal = {Front. Robot. AI},
  title        = {Who wants to grant robots rights?},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual collaboration leader-follower UAV-formation for
indoor exploration. <em>FROBT</em>, <em>8</em>, 777535. (<a
href="https://doi.org/10.3389/frobt.2021.777535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UAVs operating in a leader-follower formation demand the knowledge of the relative pose between the collaborating members. This necessitates the RF-communication of this information which increases the communication latency and can easily result in lost data packets. In this work, rather than relying on this autopilot data exchange, a visual scheme using passive markers is presented. Each formation-member carries passive markers in a RhOct configuration. These markers are visually detected and the relative pose of the members is on-board determined, thus eliminating the need for RF-communication. A reference path is then evaluated for each follower that tracks the leader and maintains a constant distance between the formation-members. Experimental studies show a mean position detection error (5 × 5 × 10cm) or less than 0.0031% of the available workspace [0.5 up to 5m, 50.43° × 38.75° Field of View (FoV)]. The efficiency of the suggested scheme against varying delays are examined in these studies, where it is shown that a delay up to 1.25s can be tolerated for the follower to track the leader as long as the latter one remains within its FoV.},
  archive      = {J_FROBT},
  author       = {Evangeliou, Nikolaos and Chaikalis, Dimitris and Tsoukalas, Athanasios and Tzes, Anthony},
  doi          = {10.3389/frobt.2021.777535},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {777535},
  shortjournal = {Front. Robot. AI},
  title        = {Visual collaboration leader-follower UAV-formation for indoor exploration},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive imitation learning framework for robotic complex
contact-rich insertion tasks. <em>FROBT</em>, <em>8</em>, 777363. (<a
href="https://doi.org/10.3389/frobt.2021.777363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex contact-rich insertion is a ubiquitous robotic manipulation skill and usually involves nonlinear and low-clearance insertion trajectories as well as varying force requirements. A hybrid trajectory and force learning framework can be utilized to generate high-quality trajectories by imitation learning and find suitable force control policies efficiently by reinforcement learning. However, with the mentioned approach, many human demonstrations are necessary to learn several tasks even when those tasks require topologically similar trajectories. Therefore, to reduce human repetitive teaching efforts for new tasks, we present an adaptive imitation framework for robot manipulation. The main contribution of this work is the development of a framework that introduces dynamic movement primitives into a hybrid trajectory and force learning framework to learn a specific class of complex contact-rich insertion tasks based on the trajectory profile of a single task instance belonging to the task class. Through experimental evaluations, we validate that the proposed framework is sample efficient, safer, and generalizes better at learning complex contact-rich insertion tasks on both simulation environments and on real hardware.},
  archive      = {J_FROBT},
  author       = {Wang, Yan and Beltran-Hernandez, Cristian C. and Wan, Weiwei and Harada, Kensuke},
  doi          = {10.3389/frobt.2021.777363},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {777363},
  shortjournal = {Front. Robot. AI},
  title        = {An adaptive imitation learning framework for robotic complex contact-rich insertion tasks},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of a robotic surgery training system.
<em>FROBT</em>, <em>8</em>, 773830. (<a
href="https://doi.org/10.3389/frobt.2021.773830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic Surgery is getting widely spread and applied to more and more clinical cases due to its advantages compared to open surgery, for both the patients and surgeons. However, Robotic Surgery requires a different set of skills and learning compared to open and also laparoscopic surgery. Tele-operation for a robotic system with hand controllers, the delay in the hand commands to be translated into robotic movements, slowness of the robotic movements, remote 2D or 3D vision of the actual operation, and lack of haptic feedback are some of the challenges that Robotic Surgery poses. Surgeons need to go through an intensive training for Robotic Surgery, and the learning and skill development continues throughout their early professional years. Despite the importance of training for Robotic Surgery, there are not yet dedicated, low-cost, and widespread training platforms; rather, surgeons mostly train with the same Robotic Surgery system they use in surgery; hence institutions need to invest on a separate surgical setup for training purposes. This is expensive for the institutions, it provides very limited access to the surgeons for training, and very limited, if any, access to researchers for experimentation. To address these, we have developed in our laboratory a low-cost, and experimental Robotic Surgery Trainer. This setup replicates the challenges that a Robotic Surgery system poses and further provides widespread access through internet connected control of the actual physical system. The overall system is composed of equipment that a standard engineering laboratory can afford. In this paper, we introduce the Robotic Surgery Training System and explain its development, parts, and functionality.},
  archive      = {J_FROBT},
  author       = {Trute, Robin Julia and Zapico, Carlos Suárez and Christou, Andreas and Layeghi, Daniel and Craig, Stewart and Erden, Mustafa Suphi},
  doi          = {10.3389/frobt.2021.773830},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {773830},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a robotic surgery training system},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optical-waveguide based tactile sensing for surgical
instruments of minimally invasive surgery. <em>FROBT</em>, <em>8</em>,
773166. (<a href="https://doi.org/10.3389/frobt.2021.773166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of minimally invasive surgery (MIS), the lack of force sensing associated with the surgical instrument used in MIS has been increasingly a desirable technology amongst clinicians. However, it is still an open technical challenge to date since most existing tactile sensing principles are not suitable to small 3-dimensional (3D) curved surfaces often seen in surgical instruments, and as a result multi-point force detection cannot be realized. In this paper, a novel optical waveguide-based sensor was proposed to deal with the above research gap. A sensor prototype for curved surfaces resembling the surface of dissection forceps was developed and experimentally evaluated. The static parameters and dynamic response characteristics of the sensor were measured. Results show that the static hysteresis error is less than 3%, the resolution is 0.026 N, and the repeatability is less than 1.5%. Under a frequency of 12.5 Hz, the sensor could quickly measure the variation of the force signal. We demonstrated that this small and high-precision sensitive sensor design is promising to be used for creating multiple-point tactile sensing for minimally invasive surgical instruments with 3D surfaces.},
  archive      = {J_FROBT},
  author       = {Li, Yue and Hu, Jian and Cao, Danqian and Wang, Stephen and Dasgupta, Prokar and Liu, Hongbin},
  doi          = {10.3389/frobt.2021.773166},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {773166},
  shortjournal = {Front. Robot. AI},
  title        = {Optical-waveguide based tactile sensing for surgical instruments of minimally invasive surgery},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics-informed modeling and control of multi-actuator soft
catheter robots. <em>FROBT</em>, <em>8</em>, 772628. (<a
href="https://doi.org/10.3389/frobt.2021.772628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catheter-based endovascular interventional procedures have become increasingly popular in recent years as they are less invasive and patients spend less time in the hospital with less recovery time and less pain. These advantages have led to a significant growth in the number of procedures that are performed annually. However, it is still challenging to position a catheter in a target vessel branch within the highly complicated and delicate vascular structure. In fact, vessel tortuosity and angulation, which cause difficulties in catheterization and reaching the target site, have been reported as the main causes of failure in endovascular procedures. Maneuverability of a catheter for intravascular navigation is a key to reaching the target area; ability of a catheter to move within the target vessel during trajectory tracking thus affects to a great extent the length and success of the procedure. To address this issue, this paper models soft catheter robots with multiple actuators and provides a time-dependent model for characterizing the dynamics of multi-actuator soft catheter robots. Built on this model, an efficient and scalable optimization-based framework is developed for guiding the catheter to pass through arteries and reach the target where an aneurysm is located. The proposed framework models the deflection of the multi-actuator soft catheter robot and develops a control strategy for movement of catheter along a desired trajectory. This provides a simulation-based framework for selection of catheters prior to endovascular catheterization procedures, assuring that given a fixed design, the catheter is able to reach the target location. The results demonstrate the benefits that can be achieved by design and control of catheters with multiple number of actuators for navigation into small vessels.},
  archive      = {J_FROBT},
  author       = {Ghoreishi, Seyede Fatemeh and Sochol, Ryan D. and Gandhi, Dheeraj and Krieger, Axel and Fuge, Mark},
  doi          = {10.3389/frobt.2021.772628},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {772628},
  shortjournal = {Front. Robot. AI},
  title        = {Physics-informed modeling and control of multi-actuator soft catheter robots},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Calib-net: Calibrating the low-cost IMU via deep
convolutional neural network. <em>FROBT</em>, <em>8</em>, 772583. (<a
href="https://doi.org/10.3389/frobt.2021.772583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-cost Inertial Measurement Unit (IMU) can provide orientation information and is widely used in our daily life. However, IMUs with bad calibration will provide inaccurate angular velocity and lead to rapid drift of integral orientation in a short time. In this paper, we present the Calib-Net which can achieve the accurate calibration of low-cost IMU via a simple deep convolutional neural network. Following a carefully designed mathematical calibration model, Calib-Net can output compensation components for gyroscope measurements dynamically. Dilation convolution is adopted in Calib-Net for spatio-temporal feature extraction of IMU measurements. We evaluate our proposed system on public datasets quantitively and qualitatively. The experimental results demonstrate that our Calib-Net achieves better calibration performance than other methods, what is more, and the estimated orientation with our Calib-Net is even comparable with the results from visual inertial odometry (VIO) systems.},
  archive      = {J_FROBT},
  author       = {Li , Ruihao and Fu, Chunlian and Yi , Wei and Yi , Xiaodong},
  doi          = {10.3389/frobt.2021.772583},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {772583},
  shortjournal = {Front. Robot. AI},
  title        = {Calib-net: Calibrating the low-cost IMU via deep convolutional neural network},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lessons learned about designing and conducting studies from
HRI experts. <em>FROBT</em>, <em>8</em>, 772141. (<a
href="https://doi.org/10.3389/frobt.2021.772141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of human-robot interaction (HRI) research is multidisciplinary and requires researchers to understand diverse fields including computer science, engineering, informatics, philosophy, psychology, and more disciplines. However, it is hard to be an expert in everything. To help HRI researchers develop methodological skills, especially in areas that are relatively new to them, we conducted a virtual workshop, Workshop Your Study Design (WYSD), at the 2021 International Conference on HRI. In this workshop, we grouped participants with mentors, who are experts in areas like real-world studies, empirical lab studies, questionnaire design, interview, participatory design, and statistics. During and after the workshop, participants discussed their proposed study methods, obtained feedback, and improved their work accordingly. In this paper, we present 1) Workshop attendees’ feedback about the workshop and 2) Lessons that the participants learned during their discussions with mentors. Participants’ responses about the workshop were positive, and future scholars who wish to run such a workshop can consider implementing their suggestions. The main contribution of this paper is the lessons learned section, where the workshop participants contributed to forming this section based on what participants discovered during the workshop. We organize lessons learned into themes of 1) Improving study design for HRI, 2) How to work with participants - especially children -, 3) Making the most of the study and robot’s limitations, and 4) How to collaborate well across fields as they were the areas of the papers submitted to the workshop. These themes include practical tips and guidelines to assist researchers to learn about fields of HRI research with which they have limited experience. We include specific examples, and researchers can adapt the tips and guidelines to their own areas to avoid some common mistakes and pitfalls in their research.},
  archive      = {J_FROBT},
  author       = {Fraune, Marlena R. and Leite, Iolanda and Karatas, Nihan and Amirova, Aida and Legeleux, Amélie and Sandygulova, Anara and Neerincx, Anouk and Dilip Tikas, Gaurav and Gunes, Hatice and Mohan, Mayumi and Abbasi, Nida Itrat and Shenoy, Sudhir and Scassellati, Brian and de Visser, Ewart J. and Komatsu, Takanori},
  doi          = {10.3389/frobt.2021.772141},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {772141},
  shortjournal = {Front. Robot. AI},
  title        = {Lessons learned about designing and conducting studies from HRI experts},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic assembly of timber structures in a human-robot
collaboration setup. <em>FROBT</em>, <em>8</em>, 768038. (<a
href="https://doi.org/10.3389/frobt.2021.768038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction sector is investigating wood as a highly sustainable material for fabrication of architectural elements. Several researchers in the field of construction are currently designing novel timber structures as well as novel solutions for fabricating such structures, i.e. robot technologies which allow for automation of a domain dominated by skilled craftsman. In this paper, we present a framework for closing the loop between the design and robotic assembly of timber structures. On one hand, we illustrate an extended automation process that incorporates learning by demonstration to learn and execute a complex assembly of an interlocking wooden joint. On the other hand, we describe a design case study that builds upon the specificity of this process, to achieve new designs of construction elements, which were previously only possible to be assembled by skilled craftsmen. The paper provides an overview of a process with different levels of focus, from the integration of a digital twin to timber joint design and the robotic assembly execution, to the development of a flexible robotic setup and novel assembly procedures for dealing with the complexity of the designed timber joints. We discuss synergistic results on both robotic and construction design innovation, with an outlook on future developments.},
  archive      = {J_FROBT},
  author       = {Kramberger, Aljaz and Kunic, Anja and Iturrate, Iñigo and Sloth, Christoffer and Naboni, Roberto and Schlette, Christian},
  doi          = {10.3389/frobt.2021.768038},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {768038},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic assembly of timber structures in a human-robot collaboration setup},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Configuring ADAS platforms for automotive applications using
metaheuristics. <em>FROBT</em>, <em>8</em>, 762227. (<a
href="https://doi.org/10.3389/frobt.2021.762227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern Advanced Driver-Assistance Systems (ADAS) combine critical real-time and non-critical best-effort tasks and messages onto an integrated multi-core multi-SoC hardware platform. The real-time safety-critical software tasks have complex interdependencies in the form of end-to-end latency chains featuring, e.g., sensing, processing/sensor fusion, and actuating. The underlying real-time operating systems running on top of the multi-core platform use static cyclic scheduling for the software tasks, while the communication backbone is either realized through PCIe or Time-Sensitive Networking (TSN). In this paper, we address the problem of configuring ADAS platforms for automotive applications, which means deciding the mapping of tasks to processing cores and the scheduling of tasks and messages. Time-critical messages are transmitted in a scheduled manner via the timed-gate mechanism described in IEEE 802.1Qbv according to the pre-computed Gate Control List (GCL) schedule. We study the computation of the assignment of tasks to the available platform CPUs/cores, the static schedule tables for the real-time tasks, as well as the GCLs, such that task and message deadlines, as well as end-to-end task chain latencies, are satisfied. This is an intractable combinatorial optimization problem. As the ADAS platforms and applications become increasingly complex, such problems cannot be optimally solved and require problem-specific heuristics or metaheuristics to determine good quality feasible solutions in a reasonable time. We propose two metaheuristic solutions, a Genetic Algorithm (GA) and one based on Simulated Annealing (SA), both creating static schedule tables for tasks by simulating Earliest Deadline First (EDF) dispatching with different task deadlines and offsets. Furthermore, we use a List Scheduling-based heuristic to create the GCLs in platforms featuring a TSN backbone. We evaluate the proposed solution with real-world and synthetic test cases scaled to fit the future requirements of ADAS systems. The results show that our heuristic strategy can find correct solutions that meet the complex timing and dependency constraints at a higher rate than the related work approaches, i.e., the jitter constraints are satisfied in over 6 times more cases, and the task chain constraints are satisfied in 41% more cases on average. Our method scales well with the growing trend of ADAS platforms.},
  archive      = {J_FROBT},
  author       = {McLean, Shane D. and Juul Hansen, Emil Alexander and Pop, Paul and Craciunas, Silviu S.},
  doi          = {10.3389/frobt.2021.762227},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {762227},
  shortjournal = {Front. Robot. AI},
  title        = {Configuring ADAS platforms for automotive applications using metaheuristics},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of human gait-based artificial intelligence
applications. <em>FROBT</em>, <em>8</em>, 749274. (<a
href="https://doi.org/10.3389/frobt.2021.749274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We performed an electronic database search of published works from 2012 to mid-2021 that focus on human gait studies and apply machine learning techniques. We identified six key applications of machine learning using gait data: 1) Gait analysis where analyzing techniques and certain biomechanical analysis factors are improved by utilizing artificial intelligence algorithms, 2) Health and Wellness, with applications in gait monitoring for abnormal gait detection, recognition of human activities, fall detection and sports performance, 3) Human Pose Tracking using one-person or multi-person tracking and localization systems such as OpenPose, Simultaneous Localization and Mapping (SLAM), etc., 4) Gait-based biometrics with applications in person identification, authentication, and re-identification as well as gender and age recognition 5) “Smart gait” applications ranging from smart socks, shoes, and other wearables to smart homes and smart retail stores that incorporate continuous monitoring and control systems and 6) Animation that reconstructs human motion utilizing gait data, simulation and machine learning techniques. Our goal is to provide a single broad-based survey of the applications of machine learning technology in gait analysis and identify future areas of potential study and growth. We discuss the machine learning techniques that have been used with a focus on the tasks they perform, the problems they attempt to solve, and the trade-offs they navigate.},
  archive      = {J_FROBT},
  author       = {Harris, Elsa J. and Khoo, I-Hung and Demircan, Emel},
  doi          = {10.3389/frobt.2021.749274},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {749274},
  shortjournal = {Front. Robot. AI},
  title        = {A survey of human gait-based artificial intelligence applications},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual and hearing sensitivity affect robot-based training
for children diagnosed with autism spectrum disorder. <em>FROBT</em>,
<em>8</em>, 748853. (<a
href="https://doi.org/10.3389/frobt.2021.748853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the impact of sensory sensitivity during robot-assisted training for children diagnosed with Autism Spectrum Disorder (ASD). Indeed, user-adaptation for robot-based therapies could help users to focus on the training, and thus improve the benefits of the interactions. Children diagnosed with ASD often suffer from sensory sensitivity, and can show hyper or hypo-reactivity to sensory events, such as reacting strongly or not at all to sounds, movements, or touch. Considering it during robot therapies may improve the overall interaction. In the present study, thirty-four children diagnosed with ASD underwent a joint attention training with the robot Cozmo. The eight session training was embedded in the standard therapy. The children were screened for their sensory sensitivity with the Sensory Profile Checklist Revised. Their social skills were screened before and after the training with the Early Social Communication Scale. We recorded their performance and the amount of feedback they were receiving from the therapist through animations of happy and sad emotions played on the robot. Our results showed that visual and hearing sensitivity influenced the improvements of the skill to initiate joint attention. Also, the therapists of individuals with a high sensitivity to hearing chose to play fewer animations of the robot during the training phase of the robot activity. The animations did not include sounds, but the robot was producing motor noise. These results are supporting the idea that sensory sensitivity of children diagnosed with ASD should be screened prior to engaging the children in robot-assisted therapy.},
  archive      = {J_FROBT},
  author       = {Chevalier, P. and Ghiglino, D. and Floris, F. and Priolo, T. and Wykowska, A.},
  doi          = {10.3389/frobt.2021.748853},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {748853},
  shortjournal = {Front. Robot. AI},
  title        = {Visual and hearing sensitivity affect robot-based training for children diagnosed with autism spectrum disorder},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic semantic world models and increased situational
awareness for highly automated inland waterway transport.
<em>FROBT</em>, <em>8</em>, 739062. (<a
href="https://doi.org/10.3389/frobt.2021.739062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated surface vessels must integrate many tasks and motions at the same time. Moreover, vessels as well as monitoring and control services need to react to physical disturbances, to dynamically allocate software resources available within a particular environment, and to communicate with various other actors in particular navigation and traffic situations. In this work, the responsibility for the situational awareness is given to a mediator that decides how: 1) to assess the impact of the actual physical environment on the quality and performance of the ongoing task executions; 2) to make sure these tasks satisfy the system requirements; and 3) to be robust against disturbances. This paper proposes a set of semantic world models within the context of inland waterway transport, and discusses policies and methodologies to compose, use, and connect these models. Model-conform entities and relations are composed dynamically, that is, corresponding to the opportunities and challenges offered by the actual situation. The semantic world models discussed in this work are divided into two main categories: 1) the semantic description of a vessel’s own properties and relationships, called the internal world model, or body model, and 2) the semantic description of its local environment, called the external world model, or map. A range of experiments illustrate the potential of using such models to decide the reactions of the application at runtime. Furthermore, three dynamic, context-dependent, ship domains are integrated in the map as two-dimensional geometric entities around a moving vessel to increase the situational awareness of automated vessels. Their geometric representations depend on the associated relations; for example, with: 1) the motion of the vessel, 2) the actual, desired, or hypothesised tasks, 3) perception sensor information, and 4) other geometries, e.g., features from the Inland Electronic Navigational Charts. The ability to unambiguously understand the environmental context, as well as the motion or position of surrounding entities, allows for resource-efficient and straightforward control decisions. The semantic world models facilitate knowledge sharing between actors, and significantly enhance explainability of the actors’ behaviour and control decisions.},
  archive      = {J_FROBT},
  author       = {Van Baelen, Senne and Peeters, Gerben and Bruyninckx, Herman and Pilozzi, Paolo and Slaets, Peter},
  doi          = {10.3389/frobt.2021.739062},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {739062},
  shortjournal = {Front. Robot. AI},
  title        = {Dynamic semantic world models and increased situational awareness for highly automated inland waterway transport},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Designing persuasive food conversational recommender systems
with nudging and socially-aware conversational strategies.
<em>FROBT</em>, <em>8</em>, 733835. (<a
href="https://doi.org/10.3389/frobt.2021.733835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unhealthy eating behavior is a major public health issue with serious repercussions on an individual’s health. One potential solution to overcome this problem, and help people change their eating behavior, is to develop conversational systems able to recommend healthy recipes. One challenge for such systems is to deliver personalized recommendations matching users’ needs and preferences. Beyond the intrinsic quality of the recommendation itself, various factors might also influence users’ perception of a recommendation. In this paper, we present Cora, a conversational system that recommends recipes aligned with its users’ eating habits and current preferences. Users can interact with Cora in two different ways. They can select pre-defined answers by clicking on buttons to talk to Cora or write text in natural language. Additionally, Cora can engage users through a social dialogue, or go straight to the point. Cora is also able to propose different alternatives and to justify its recipes recommendation by explaining the trade-off between them. We conduct two experiments. In the first one, we evaluate the impact of Cora’s conversational skills and users’ interaction mode on users’ perception and intention to cook the recommended recipes. Our results show that a conversational recommendation system that engages its users through a rapport-building dialogue improves users’ perception of the interaction as well as their perception of the system. In the second evaluation, we evaluate the influence of Cora’s explanations and recommendation comparisons on users’ perception. Our results show that explanations positively influence users’ perception of a recommender system. However, comparing healthy recipes with a decoy is a double-edged sword. Although such comparison is perceived as significantly more useful compared to one single healthy recommendation, explaining the difference between the decoy and the healthy recipe would actually make people less likely to use the system.},
  archive      = {J_FROBT},
  author       = {Pecune, Florian and Callebert, Lucile and Marsella, Stacy},
  doi          = {10.3389/frobt.2021.733835},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {733835},
  shortjournal = {Front. Robot. AI},
  title        = {Designing persuasive food conversational recommender systems with nudging and socially-aware conversational strategies},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Soft robotic deployable origami actuators for neurosurgical
brain retraction. <em>FROBT</em>, <em>8</em>, 731010. (<a
href="https://doi.org/10.3389/frobt.2021.731010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metallic tools such as graspers, forceps, spatulas, and clamps have been used in proximity to delicate neurological tissue and the risk of damage to this tissue is a primary concern for neurosurgeons. Novel soft robotic technologies have the opportunity to shift the design paradigm for these tools towards safer and more compliant, minimally invasive methods. Here, we present a pneumatically actuated, origami-inspired deployable brain retractor aimed at atraumatic surgical workspace generation inside the cranial cavity. We discuss clinical requirements, design, fabrication, analytical modeling, experimental characterization, and in-vitro validation of the proposed device on a brain model.},
  archive      = {J_FROBT},
  author       = {Amadeo, Tomas and Van Lewen, Daniel and Janke, Taylor and Ranzani, Tommaso and Devaiah, Anand and Upadhyay, Urvashi and Russo, Sheila},
  doi          = {10.3389/frobt.2021.731010},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {731010},
  shortjournal = {Front. Robot. AI},
  title        = {Soft robotic deployable origami actuators for neurosurgical brain retraction},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Speed dating with voice user interfaces: Understanding how
families interact and perceive voice user interfaces in a group setting.
<em>FROBT</em>, <em>8</em>, 730992. (<a
href="https://doi.org/10.3389/frobt.2021.730992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As voice-user interfaces (VUIs), such as smart speakers like Amazon Alexa or social robots like Jibo, enter multi-user environments like our homes, it is critical to understand how group members perceive and interact with these devices. VUIs engage socially with users, leveraging multi-modal cues including speech, graphics, expressive sounds, and movement. The combination of these cues can affect how users perceive and interact with these devices. Through a set of three elicitation studies, we explore family interactions (N = 34 families, 92 participants, ages 4–69) with three commercially available VUIs with varying levels of social embodiment. The motivation for these three studies began when researchers noticed that families interacted differently with three agents when familiarizing themselves with the agents and, therefore, we sought to further investigate this trend in three subsequent studies designed as a conceptional replication study. Each study included three activities to examine participants’ interactions with and perceptions of the three VUIS in each study, including an agent exploration activity, perceived personality activity, and user experience ranking activity. Consistent for each study, participants interacted significantly more with an agent with a higher degree of social embodiment, i.e., a social robot such as Jibo, and perceived the agent as more trustworthy, having higher emotional engagement, and having higher companionship. There were some nuances in interaction and perception with different brands and types of smart speakers, i.e., Google Home versus Amazon Echo, or Amazon Show versus Amazon Echo Spot between the studies. In the last study, a behavioral analysis was conducted to investigate interactions between family members and with the VUIs, revealing that participants interacted more with the social robot and interacted more with their family members around the interactions with the social robot. This paper explores these findings and elaborates upon how these findings can direct future VUI development for group settings, especially in familial settings.},
  archive      = {J_FROBT},
  author       = {Ostrowski, Anastasia K. and Fu, Jenny and Zygouras, Vasiliki and Park, Hae Won and Breazeal, Cynthia},
  doi          = {10.3389/frobt.2021.730992},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {730992},
  shortjournal = {Front. Robot. AI},
  title        = {Speed dating with voice user interfaces: Understanding how families interact and perceive voice user interfaces in a group setting},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ExGenNet: Learning to generate robotic facial expression
using facial expression recognition. <em>FROBT</em>, <em>8</em>, 730317.
(<a href="https://doi.org/10.3389/frobt.2021.730317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of a robot to generate appropriate facial expressions is a key aspect of perceived sociability in human-robot interaction. Yet many existing approaches rely on the use of a set of fixed, preprogrammed joint configurations for expression generation. Automating this process provides potential advantages to scale better to different robot types and various expressions. To this end, we introduce ExGenNet, a novel deep generative approach for facial expressions on humanoid robots. ExGenNets connect a generator network to reconstruct simplified facial images from robot joint configurations with a classifier network for state-of-the-art facial expression recognition. The robots’ joint configurations are optimized for various expressions by backpropagating the loss between the predicted expression and intended expression through the classification network and the generator network. To improve the transfer between human training images and images of different robots, we propose to use extracted features in the classifier as well as in the generator network. Unlike most studies on facial expression generation, ExGenNets can produce multiple configurations for each facial expression and be transferred between robots. Experimental evaluations on two robots with highly human-like faces, Alfie (Furhat Robot) and the android robot Elenoide, show that ExGenNet can successfully generate sets of joint configurations for predefined facial expressions on both robots. This ability of ExGenNet to generate realistic facial expressions was further validated in a pilot study where the majority of human subjects could accurately recognize most of the generated facial expressions on both the robots.},
  archive      = {J_FROBT},
  author       = {Rawal, Niyati and Koert, Dorothea and Turan, Cigdem and Kersting, Kristian and Peters, Jan and Stock-Homburg, Ruth},
  doi          = {10.3389/frobt.2021.730317},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {730317},
  shortjournal = {Front. Robot. AI},
  title        = {ExGenNet: Learning to generate robotic facial expression using facial expression recognition},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of COM controller of a human in stance based
on motion measurement and phase-space analysis. <em>FROBT</em>,
<em>8</em>, 729575. (<a
href="https://doi.org/10.3389/frobt.2021.729575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a process to identify the standing stabilizer, namely, the controller in humans to keep upright posture stable against perturbations. We model the controller as a piecewise-linear feedback system, where the state of the center of mass (COM) is regulated by coordinating the whole body so as to locate the zero-moment point (ZMP) at the desired position. This was developed for humanoid robots and is possibly able to elaborate the fundamental control scheme used by humans to stabilize themselves. Difficulties lie on how to collect motion trajectories in a wide area of the state space for reliable identification and how to identify the piecewise-affine dynamical system. For the former problem, a motion measurement protocol is devised based on the theoretical phase portrait of the system. Regarding the latter problem, some clustering techniques including K-means method and EM (Expectation-and-Maximization) algorithm were examined. We found that a modified K-means method produced the most accurate result in this study. The method was applied to the identification of a lateral standing controller of a human subject. The result of the identification quantitatively supported a hypothesis that the COM-ZMP regulator reasonably models the human’s controller when deviations of the angular momentum about the COM are limited.},
  archive      = {J_FROBT},
  author       = {Sugihara, Tomomichi and Kaneta, Daishi and Murai, Nobuyuki},
  doi          = {10.3389/frobt.2021.729575},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {729575},
  shortjournal = {Front. Robot. AI},
  title        = {Identification of COM controller of a human in stance based on motion measurement and phase-space analysis},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation of socially-aware robot navigation.
<em>FROBT</em>, <em>8</em>, 721317. (<a
href="https://doi.org/10.3389/frobt.2021.721317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As mobile robots are increasingly introduced into our daily lives, it grows ever more imperative that these robots navigate with and among people in a safe and socially acceptable manner, particularly in shared spaces. While research on enabling socially-aware robot navigation has expanded over the years, there are no agreed-upon evaluation protocols or benchmarks to allow for the systematic development and evaluation of socially-aware navigation. As an effort to aid more productive development and progress comparisons, in this paper we review the evaluation methods, scenarios, datasets, and metrics commonly used in previous socially-aware navigation research, discuss the limitations of existing evaluation protocols, and highlight research opportunities for advancing socially-aware robot navigation.},
  archive      = {J_FROBT},
  author       = {Gao, Yuxiang and Huang, Chien-Ming},
  doi          = {10.3389/frobt.2021.721317},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {721317},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of socially-aware robot navigation},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Helping people through space and time: Assistance as a
perspective on human-robot interaction. <em>FROBT</em>, <em>8</em>,
720319. (<a href="https://doi.org/10.3389/frobt.2021.720319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As assistive robotics has expanded to many task domains, comparing assistive strategies among the varieties of research becomes increasingly difficult. To begin to unify the disparate domains into a more general theory of assistance, we present a definition of assistance, a survey of existing work, and three key design axes that occur in many domains and benefit from the examination of assistance as a whole. We first define an assistance perspective that focuses on understanding a robot that is in control of its actions but subordinate to a user’s goals. Next, we use this perspective to explore design axes that arise from the problem of assistance more generally and explore how these axes have comparable trade-offs across many domains. We investigate how the assistive robot handles other people in the interaction, how the robot design can operate in a variety of action spaces to enact similar goals, and how assistive robots can vary the timing of their actions relative to the user’s behavior. While these axes are by no means comprehensive, we propose them as useful tools for unifying assistance research across domains and as examples of how taking a broader perspective on assistance enables more cross-domain theorizing about assistance.},
  archive      = {J_FROBT},
  author       = {Newman, Benjamin A. and Aronson, Reuben M. and Kitani, Kris and Admoni, Henny},
  doi          = {10.3389/frobt.2021.720319},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {720319},
  shortjournal = {Front. Robot. AI},
  title        = {Helping people through space and time: Assistance as a perspective on human-robot interaction},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Morphological evolution: Bioinspired methods for analyzing
bioinspired robots. <em>FROBT</em>, <em>8</em>, 717214. (<a
href="https://doi.org/10.3389/frobt.2021.717214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To fully understand the evolution of complex morphologies, analyses cannot stop at selection: It is essential to investigate the roles and interactions of multiple processes that drive evolutionary outcomes. The challenges of undertaking such analyses have affected both evolutionary biologists and evolutionary roboticists, with their common interests in complex morphologies. In this paper, we present analytical techniques from evolutionary biology, selection gradient analysis and morphospace walks, and we demonstrate their applicability to robot morphologies in analyses of three evolutionary mechanisms: randomness (genetic mutation), development (an explicitly implemented genotype-to-phenotype map), and selection. In particular, we applied these analytical techniques to evolved populations of simulated biorobots—embodied robots designed specifically as models of biological systems, for the testing of biological hypotheses—and we present a variety of results, including analyses that do all of the following: illuminate different evolutionary dynamics for different classes of morphological traits; illustrate how the traits targeted by selection can vary based on the likelihood of random genetic mutation; demonstrate that selection on two selected sets of morphological traits only partially explains the variance in fitness in our biorobots; and suggest that biases in developmental processes could partially explain evolutionary dynamics of morphology. When combined, the complementary analytical approaches discussed in this paper can enable insight into evolutionary processes beyond selection and thereby deepen our understanding of the evolution of robotic morphologies.},
  archive      = {J_FROBT},
  author       = {Aaron, Eric and Hawthorne-Madell, Joshua and Livingston, Ken and Long, John H.},
  doi          = {10.3389/frobt.2021.717214},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {717214},
  shortjournal = {Front. Robot. AI},
  title        = {Morphological evolution: Bioinspired methods for analyzing bioinspired robots},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cardiac patch transplantation instruments for robotic
minimally invasive cardiac surgery: Initial proof-of-concept designs and
surgery in a porcine cadaver. <em>FROBT</em>, <em>8</em>, 714356. (<a
href="https://doi.org/10.3389/frobt.2021.714356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Damaged cardiac tissues could potentially be regenerated by transplanting bioengineered cardiac patches to the heart surface. To be fully paradigm-shifting, such patches may need to be transplanted using minimally invasive robotic cardiac surgery (not only traditional open surgery). Here, we present novel robotic designs, initial prototyping and a new surgical operation for instruments to transplant patches via robotic minimally invasive heart surgery.Methods: Robotic surgical instruments and automated control systems were designed, tested with simulation software and prototyped. Surgical proof-of-concept testing was performed on a pig cadaver.Results: Three robotic instrument designs were developed. The first (called “Claw” for the claw-like patch holder at the tip) operates on a rack and pinion mechanism. The second design (“Shell-Beak”) uses adjustable folding plates and rods with a bevel gear mechanism. The third (“HeartStamp”) utilizes a stamp platform protruding through an adjustable ring. For the HeartStamp, rods run through a cylindrical structure designed to fit a uniportal Video-Assisted Thorascopic Surgery (VATS) surgical port. Designed to work with or without a sterile sheath, the patch is pushed out by the stamp platform as it protrudes. Two instrument robotic control systems were designed, simulated in silico and one of these underwent early ‘sizing and learning’ prototyping as a proof-of-concept. To reflect real surgical conditions, surgery was run “live” and reported exactly (as-it-happened). We successfully picked up, transferred and released a patch onto the heart using the HeartStamp in a pig cadaver model.Conclusion: These world-first designs, early prototypes and a novel surgical operation pave the way for robotic instruments for automated keyhole patch transplantation to the heart. Our novel approach is presented for others to build upon free from restrictions or cost—potentially a significant moment in myocardial regeneration surgery which may open a therapeutic avenue for patients unfit for traditional open surgery.},
  archive      = {J_FROBT},
  author       = {Roche, Christopher D. and Iyer, Gautam R. and Nguyen, Minh H. and Mabroora, Sohaima and Dome, Anthony and Sakr, Kareem and Pawar, Rohan and Lee, Vincent and Wilson, Christopher C. and Gentile, Carmine},
  doi          = {10.3389/frobt.2021.714356},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {714356},
  shortjournal = {Front. Robot. AI},
  title        = {Cardiac patch transplantation instruments for robotic minimally invasive cardiac surgery: Initial proof-of-concept designs and surgery in a porcine cadaver},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tactile sensing for minimally invasive surgery: Conventional
methods and potential emerging tactile technologies. <em>FROBT</em>,
<em>8</em>, 705662. (<a
href="https://doi.org/10.3389/frobt.2021.705662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As opposed to open surgery procedures, minimally invasive surgery (MIS) utilizes small skin incisions to insert a camera and surgical instruments. MIS has numerous advantages such as reduced postoperative pain, shorter hospital stay, faster recovery time, and reduced learning curve for surgical trainees. MIS comprises surgical approaches, including laparoscopic surgery, endoscopic surgery, and robotic-assisted surgery. Despite the advantages that MIS provides to patients and surgeons, it remains limited by the lost sense of touch due to the indirect contact with tissues under operation, especially in robotic-assisted surgery. Surgeons, without haptic feedback, could unintentionally apply excessive forces that may cause tissue damage. Therefore, incorporating tactile sensation into MIS tools has become an interesting research topic. Designing, fabricating, and integrating force sensors onto different locations on the surgical tools are currently under development by several companies and research groups. In this context, electrical force sensing modality, including piezoelectric, resistive, and capacitive sensors, is the most conventionally considered approach to measure the grasping force, manipulation force, torque, and tissue compliance. For instance, piezoelectric sensors exhibit high sensitivity and accuracy, but the drawbacks of thermal sensitivity and the inability to detect static loads constrain their adoption in MIS tools. Optical-based tactile sensing is another conventional approach that facilitates electrically passive force sensing compatible with magnetic resonance imaging. Estimations of applied loadings are calculated from the induced changes in the intensity, wavelength, or phase of light transmitted through optical fibers. Nonetheless, new emerging technologies are also evoking a high potential of contributions to the field of smart surgical tools. The recent development of flexible, highly sensitive tactile microfluidic-based sensors has become an emerging field in tactile sensing, which contributed to wearable electronics and smart-skin applications. Another emerging technology is imaging-based tactile sensing that achieved superior multi-axial force measurements by implementing image sensors with high pixel densities and frame rates to track visual changes on a sensing surface. This article aims to review the literature on MIS tactile sensing technologies in terms of working principles, design requirements, and specifications. Moreover, this work highlights and discusses the promising potential of a few emerging technologies towards establishing low-cost, high-performance MIS force sensing.},
  archive      = {J_FROBT},
  author       = {Othman, Wael and Lai, Zhi-Han A. and Abril, Carlos and Barajas-Gamboa, Juan S. and Corcelles, Ricard and Kroh, Matthew and Qasaimeh, Mohammad A.},
  doi          = {10.3389/frobt.2021.705662},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {705662},
  shortjournal = {Front. Robot. AI},
  title        = {Tactile sensing for minimally invasive surgery: Conventional methods and potential emerging tactile technologies},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pose generation for social robots in conversational group
formations. <em>FROBT</em>, <em>8</em>, 703807. (<a
href="https://doi.org/10.3389/frobt.2021.703807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study two approaches for predicting an appropriate pose for a robot to take part in group formations typical of social human conversations subject to the physical layout of the surrounding environment. One method is model-based and explicitly encodes key geometric aspects of conversational formations. The other method is data-driven. It implicitly models key properties of spatial arrangements using graph neural networks and an adversarial training regimen. We evaluate the proposed approaches through quantitative metrics designed for this problem domain and via a human experiment. Our results suggest that the proposed methods are effective at reasoning about the environment layout and conversational group formations. They can also be used repeatedly to simulate conversational spatial arrangements despite being designed to output a single pose at a time. However, the methods showed different strengths. For example, the geometric approach was more successful at avoiding poses generated in nonfree areas of the environment, but the data-driven method was better at capturing the variability of conversational spatial formations. We discuss ways to address open challenges for the pose generation problem and other interesting avenues for future work.},
  archive      = {J_FROBT},
  author       = {Vázquez, Marynel and Lew, Alexander and Gorevoy, Eden and Connolly, Joe},
  doi          = {10.3389/frobt.2021.703807},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {703807},
  shortjournal = {Front. Robot. AI},
  title        = {Pose generation for social robots in conversational group formations},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Closed-loop torque and kinematic control of a hybrid
lower-limb exoskeleton for treadmill walking. <em>FROBT</em>,
<em>8</em>, 702860. (<a
href="https://doi.org/10.3389/frobt.2021.702860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring and improving the ability to walk is a top priority for individuals with movement impairments due to neurological injuries. Powered exoskeletons coupled with functional electrical stimulation (FES), called hybrid exoskeletons, exploit the benefits of activating muscles and robotic assistance for locomotion. In this paper, a cable-driven lower-limb exoskeleton is integrated with FES for treadmill walking at a constant speed. A nonlinear robust controller is used to activate the quadriceps and hamstrings muscle groups via FES to achieve kinematic tracking about the knee joint. Moreover, electric motors adjust the knee joint stiffness throughout the gait cycle using an integral torque feedback controller. For the hip joint, a robust sliding-mode controller is developed to achieve kinematic tracking using electric motors. The human-exoskeleton dynamic model is derived using Lagrangian dynamics and incorporates phase-dependent switching to capture the effects of transitioning from the stance to the swing phase, and vice versa. Moreover, low-level control input switching is used to activate individual muscles and motors to achieve flexion and extension about the hip and knee joints. A Lyapunov-based stability analysis is developed to ensure exponential tracking of the kinematic and torque closed-loop error systems, while guaranteeing that the control input signals remain bounded. The developed controllers were tested in real-time walking experiments on a treadmill in three able-bodied individuals at two gait speeds. The experimental results demonstrate the feasibility of coupling a cable-driven exoskeleton with FES for treadmill walking using a switching-based control strategy and exploiting both kinematic and force feedback.},
  archive      = {J_FROBT},
  author       = {Chang, Chen-Hao and Casas, Jonathan and Brose, Steven W. and Duenas, Victor H.},
  doi          = {10.3389/frobt.2021.702860},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {702860},
  shortjournal = {Front. Robot. AI},
  title        = {Closed-loop torque and kinematic control of a hybrid lower-limb exoskeleton for treadmill walking},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Formal modelling and runtime verification of autonomous
grasping for active debris removal. <em>FROBT</em>, <em>8</em>, 639282.
(<a href="https://doi.org/10.3389/frobt.2021.639282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active debris removal in space has become a necessary activity to maintain and facilitate orbital operations. Current approaches tend to adopt autonomous robotic systems which are often furnished with a robotic arm to safely capture debris by identifying a suitable grasping point. These systems are controlled by mission-critical software, where a software failure can lead to mission failure which is difficult to recover from since the robotic systems are not easily accessible to humans. Therefore, verifying that these autonomous robotic systems function correctly is crucial. Formal verification methods enable us to analyse the software that is controlling these systems and to provide a proof of correctness that the software obeys its requirements. However, robotic systems tend not to be developed with verification in mind from the outset, which can often complicate the verification of the final algorithms and systems. In this paper, we describe the process that we used to verify a pre-existing system for autonomous grasping which is to be used for active debris removal in space. In particular, we formalise the requirements for this system using the Formal Requirements Elicitation Tool (FRET). We formally model specific software components of the system and formally verify that they adhere to their corresponding requirements using the Dafny program verifier. From the original FRET requirements, we synthesise runtime monitors using ROSMonitoring and show how these can provide runtime assurances for the system. We also describe our experimentation and analysis of the testbed and the associated simulation. We provide a detailed discussion of our approach and describe how the modularity of this particular autonomous system simplified the usually complex task of verifying a system post-development.},
  archive      = {J_FROBT},
  author       = {Farrell, Marie and Mavrakis, Nikos and Ferrando, Angelo and Dixon, Clare and Gao, Yang},
  doi          = {10.3389/frobt.2021.639282},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {639282},
  shortjournal = {Front. Robot. AI},
  title        = {Formal modelling and runtime verification of autonomous grasping for active debris removal},
  volume       = {8},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
