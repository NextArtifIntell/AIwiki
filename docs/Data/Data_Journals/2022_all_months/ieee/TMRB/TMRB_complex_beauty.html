<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMRB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmrb---104">TMRB - 104</h2>
<ul>
<li><details>
<summary>
(2022). Deep learning for instrument detection and assessment of
operative skill in surgical videos. <em>TMRB</em>, <em>4</em>(4),
1068–1071. (<a href="https://doi.org/10.1109/TMRB.2022.3214377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical performance has been shown to be directly related to patient outcomes. There is significant variation in surgical performance and therefore a need to measure operative skill accurately and reliably. Despite this, current means of surgical performance assessment rely on expert observation which is labor-intensive, prone to rater bias and unreliable. We present an automatic approach to surgical performance assessment through the tracking of instruments in endoscopic video. We annotate the spatial bounds of surgical instruments in 2600 images and use this new dataset to train Mask R-CNN, a state-of-the-art instance segmentation framework. We show that we can successfully achieve spatial detection of surgical instruments by generating a pixel-by-pixel mask over the detected instrument and achieving an overall mAP of 0.839 for an IoU of 0.5. We leverage the results from our instrument detection framework to assess surgical performance through the generation of instrument trajectory maps and instrument metrics such as moving distance, smoothness of instrument movement and concentration of instrument movement.},
  archive      = {J_TMRB},
  author       = {Kyle Lam and Frank P.-W. Lo and Yujian An and Ara Darzi and James M. Kinross and Sanjay Purkayastha and Benny Lo},
  doi          = {10.1109/TMRB.2022.3214377},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1068-1071},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Deep learning for instrument detection and assessment of operative skill in surgical videos},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling and high-definition control of a smart
electroadhesive actuator: Toward application in rehabilitation.
<em>TMRB</em>, <em>4</em>(4), 1057–1067. (<a
href="https://doi.org/10.1109/TMRB.2022.3216906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart actuators with tunable dynamical characteristics have shown significant potential to improve the performance of physical human-robot interaction systems, such as exoskeletons. In this regard, electroadhesive clutches, which function based on a controllable dry kinetic friction between the discs, have attracted a great deal of interest for semi-passive actuation that has a high force-to-weight ratio and low power consumption. However, the complex dynamical behavior of such an actuator has limited the potential application in dynamic tasks. This paper, for the first time, presents a robust nonlinear control law for torque-adjustable rotary electroadhesive clutches in order to guarantee smooth, agile, and stable behavior in the presence of significant unmodeled dynamics. For this, a nonlinear Lyapunov-redesign approach is proposed based on a partially-identified model, which can guarantee convergence and robustness to unmodeled dynamics. The performance of the proposed algorithm is validated through a comprehensive set of experiments, including active-resistive and coordination-assisted rehabilitation using an elbow exoskeleton designed based on the rotary electroadhesive clutch. The proposed approach shows potential for application in dynamic scenarios such as those involving assistive and wearable robots.},
  archive      = {J_TMRB},
  author       = {Navid Feizi and S. Farokh Atashzar and Mehrdad R. Kermani and Rajni V. Patel},
  doi          = {10.1109/TMRB.2022.3216906},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1057-1067},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Modeling and high-definition control of a smart electroadhesive actuator: Toward application in rehabilitation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A model-based multi-point tissue manipulation for enhancing
breast brachytherapy. <em>TMRB</em>, <em>4</em>(4), 1046–1056. (<a
href="https://doi.org/10.1109/TMRB.2022.3214439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In surgical operations, tissue manipulation can be automated to reduce the surgeon’s workload. This work addresses the application of tissue manipulation in breast brachytherapy, which involves manipulating an internal target inside the breast. Unassisted breast brachytherapy causes excessive target movement that reduces seed implantation accuracy. To address this target movement in breast brachytherapy, first, the internal target point will be manipulated accurately and then the brachytherapy needle will be inserted into the immobilized tissue. In this paper, a model-based tissue manipulation method is introduced. To simulate nonlinear large tissue deformation for the first time, a minimum-energy-based deformable tissue solver is utilized. Based on the theory of positive bases, the optimal number of actuators is determined to guarantee controllability of the internal target. A model predictive controller (MPC) is designed to implement multi-point tissue manipulation. A breast phantom is used to test the accuracy of the deformation model and the effectiveness of the proposed control method. The results show that the tissue deformation simulation error is 1.6 mm and the internal target can be regulated with negligible steady-state errors using an MPC controller.},
  archive      = {J_TMRB},
  author       = {Mehrnoosh Afshar and Jay Carriere and Tyler Meyer and Ron S. Sloboda and Siraj Husain and Nawaid Usmani and Mahdi Tavakoli},
  doi          = {10.1109/TMRB.2022.3214439},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1046-1056},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A model-based multi-point tissue manipulation for enhancing breast brachytherapy},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A power-capable knee prosthesis with ballistic swing-phase.
<em>TMRB</em>, <em>4</em>(4), 1034–1045. (<a
href="https://doi.org/10.1109/TMRB.2022.3216475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new approach to the design of a power-capable prosthesis; namely, one that expands the behavioral capability of a knee prosthesis into the powered quadrants of the power plane, without sacrificing the range of capable behaviors in the passive quadrants, relative to existing passive microprocessor-controlled knee prostheses (MPKs). It is well-known that swing-phase knee motion during walking in healthy human gait results from the combination of inertial coupling between the thigh and shank, gravitational effects, and passive behavior at the knee. Motor-actuated prostheses with powered stance and swing capabilities have recently emerged, but none have been shown to provide a strictly-passive biomimetic swing-phase. This paper describes an approach that enables expansion of knee behavior into the powered quadrants of the power plane, without sacrificing the ability to provide a strictly-passive biomimetic swing-phase, or the passive stance-phase behaviors provided by passive MPKs.},
  archive      = {J_TMRB},
  author       = {Steve C. Culver and Leo G. Vailati and Michael Goldfarb},
  doi          = {10.1109/TMRB.2022.3216475},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1034-1045},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A power-capable knee prosthesis with ballistic swing-phase},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biomechanical trajectory optimization of human sit-to-stand
motion with stochastic motion planning framework. <em>TMRB</em>,
<em>4</em>(4), 1022–1033. (<a
href="https://doi.org/10.1109/TMRB.2022.3205509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory optimization has been an important approach in biomechanics for the analysis and prediction of the limb movement. Such approaches have paved the way for the motion planning of biped and quadruped robots as well. Most of these methods are deterministic, utilizing first-order iterative gradient-based algorithms incorporating the constrained differentiable objective functions. However, the limitation of prevailing methods concerning differentiability hinders the implementation of non-differentiable objective functions such as metabolic energy expenditure (MEE) function, which is highly relevant for physiological systems and can even be implemented across the muscular space. This paper consolidates the implementation of the prevalent direct collocation-based optimal control method with the stochastic trajectory optimization method based on Policy Improvement with Path Integral (PI2) for comprehending the human sit-to-stand (STS) motion. PI2 method, which utilizes reinforcement learning of Dynamic Movement Primitive (DMP) to learn a goal-based trajectory is implemented and validated by comparing with the experimental result in joint-space and muscle-space.},
  archive      = {J_TMRB},
  author       = {Bibhu Sharma and Branesh M. Pillai and Jackrit Suthakorn},
  doi          = {10.1109/TMRB.2022.3205509},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1022-1033},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Biomechanical trajectory optimization of human sit-to-stand motion with stochastic motion planning framework},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Depth vision-based terrain detection algorithm during human
locomotion. <em>TMRB</em>, <em>4</em>(4), 1010–1021. (<a
href="https://doi.org/10.1109/TMRB.2022.3206602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In locomotion tasks like walking or stair ascending, leg joints produce mechanical energy with task-specific kinematic and kinetic patterns. Consequently, locomotion assistive devices should be active and adaptive to the task being executed; and these tasks should be detected early enough for guaranteeing smooth transitions by the device controller. Wearable vision sensors can predict future tasks by detecting locomotion affordances in the environment. We implemented such a vision-based terrain detection system for flat ground, steps, and ramps, using a depth camera mounted on the user’s chest, and a machine learning classifier. A validation study was conducted with eight participants moving through indoor and outdoor paths combining a rich set of terrains, and under two clearance conditions: clear and occluded by another walker moving ahead. Our method can predict the locomotion modes up to three steps in front of the user and can estimate the geometrical features of the terrain (i.e., step height for stairs and slope inclination for ramps and grounds). Our system achieved more than 95% of accuracy for all locomotion modes in first upcoming step in clear path condition. The paper further reports how these results degrade for next steps ahead of the user, or with partial occlusion.},
  archive      = {J_TMRB},
  author       = {Ali H. A. Al-Dabbagh and Renaud Ronsse},
  doi          = {10.1109/TMRB.2022.3206602},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1010-1021},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Depth vision-based terrain detection algorithm during human locomotion},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preference-based assistance map learning with robust
adaptive oscillators. <em>TMRB</em>, <em>4</em>(4), 1000–1009. (<a
href="https://doi.org/10.1109/TMRB.2022.3206609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, lower-limb exoskeletons have demonstrated the ability to enhance human mobility by reducing biological efforts with human-in-the-loop (HIL) optimization. However, this technology is confined to the laboratory, and it is difficult to generalize to daily applications where gaits are more complex and professional equipment is not accessible. To solve this issue, firstly, we present a robust adaptive oscillator (RAO) to synchronize the human-robot movement and extract gait features. Then, we use the Gaussian process regression (GPR) to map the subjects’ preferred assistance parameters to gait features. Experiments show that the RAO has a faster convergence rate compared with the traditional adaptive oscillators. Meanwhile, the learning efficiency of the proposed method shows superiority compared with the HIL optimization. The effectiveness of the proposed method is validated by a hip exoskeleton at a speed of 5 km/h with 7 participants. Three muscles which include rectus femoris, tibialis anterior, and medial gastrocnemius are investigated in three conditions: user-preferred assistance (ASS), zero torque (ZT), and normal walking (NW). The results show that all muscles achieve an activity reduction in ASS mode compared with ZT or NW. Meanwhile, there is a statistically significant difference on medial gastrocnemius in ASS mode with respect to both ZT and NW (−15.63 ± 6.51% and −8.73 ± 6.40%, respectively).},
  archive      = {J_TMRB},
  author       = {Shilei Li and Wulin Zou and Pu Duan and Ling Shi},
  doi          = {10.1109/TMRB.2022.3206609},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1000-1009},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Preference-based assistance map learning with robust adaptive oscillators},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DLPR: Deep learning-based enhanced pattern recognition
frame-work for improved myoelectric prosthesis control. <em>TMRB</em>,
<em>4</em>(4), 991–999. (<a
href="https://doi.org/10.1109/TMRB.2022.3216957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In EMG based pattern recognition (EMG-PR), deep learning-based techniques have become more prominent for their self-regulating capability to extract discriminant features from large data-sets. Moreover, the performance of traditional machine learning-based methods show limitation to categorize over a certain number of classes and degrades over a period of time. In this paper, an accurate, robust, and fast convolutional neural network-based framework for EMG pattern identification is presented. To assess the performance of the proposed system, five publicly available and benchmark data-sets of upper limb activities were used. This data-set contains 49 to 52 upper limb motions (NinaPro DB1, NinaPro DB2, and NinaPro DB3), Data with force variation, and data with arm position variation for intact and amputated subjects. The classification accuracies of 92.18% (53 classes), 91.56% (49 classes), 84.98% (49 classes of amputees), 95.67% (6 classes with force variation), and 99.12% (8 classes with arm position variation) have been observed during the testing. The performance of the proposed system is compared with the state of art techniques in the literature. The findings demonstrate that classification accuracy and time complexity have been improved significantly. For signal pre-processing and deep learning techniques, Keras which is a high-level API for TensorFlow is utilised to build profound learning models. The proposed method has been tested on the Intel Core i7 3.5GHz, 7th Gen CPU with 8GB DDR4 RAM.},
  archive      = {J_TMRB},
  author       = {Sidharth Pancholi and Amit M. Joshi and Deepak Joshi},
  doi          = {10.1109/TMRB.2022.3216957},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {991-999},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {DLPR: Deep learning-based enhanced pattern recognition frame-work for improved myoelectric prosthesis control},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic generation of autonomous ultrasound scanning
trajectory based on 3-d point cloud. <em>TMRB</em>, <em>4</em>(4),
976–990. (<a href="https://doi.org/10.1109/TMRB.2022.3214493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of robotics and ultrasound scanning has been used to overcome the shortcomings of traditional ultrasound examinations, such as high variability and low repeatability of ultrasound images acquired by operators. However, there are huge differences in the surface morphology of different human bodies, and the current clinical practice still relies heavily on the manually generating a suitable scanning trajectory for the free-form surface. In this paper, a practical strategy for automatic generation of ultrasound scanning trajectory on breast surfaces is proposed, which can automatically and efficiently generate scanning trajectory for any free-form breast surface. First, the probe attitude and contact model of ultrasound automatic scanning are analyzed. Second, an end-to-end automatic trajectory generation workflow based on 3D point clouds is proposed. Furthermore, a trajectory point offset strategy considering skin deformation and a simultaneous double breast scanning strategy are proposed. In addition, a probe attitude normal admittance controller based on position inner loop control is designed. The experimental results show that the overall time of trajectory generation is less than 4 s. The automatic scanning is 30.84 times more stable in controlling the contact force than the manual scanning, which effectively improves the repeatability of the scanning.},
  archive      = {J_TMRB},
  author       = {Jiyong Tan and Yuanwei Li and Bing Li and Yuquan Leng and Junhua Peng and Jiayi Wu and Baoming Luo and Xinxing Chen and Yiming Rong and Chenglong Fu},
  doi          = {10.1109/TMRB.2022.3214493},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {976-990},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Automatic generation of autonomous ultrasound scanning trajectory based on 3-D point cloud},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kinematic modeling and jacobian-based control of the COAST
guidewire robot. <em>TMRB</em>, <em>4</em>(4), 967–975. (<a
href="https://doi.org/10.1109/TMRB.2022.3216026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual guidewire navigation and placement for minimally invasive surgeries suffer from technical challenges due to imprecise tip motion control to traverse highly tortuous vasculature. Robotically steerable guidewires can address these challenges by actuating a compliant tip through multiple degrees-of-freedom for maneuvering through vascular pathways. In this paper, we detail the kinematic mapping of a COaxially Aligned STeerable (COAST) guidewire robot that is capable of executing follow-the-leader motion in three dimensional vascular pathways. We also develop an analytical Jacobian model to perform velocity kinematics for the robot and finally, we implement Jacobian-based control to demonstrate follow-the-leader motion of the guidewire in free space, within 3D-printed phantoms, and within ex vivo animal vasculature.},
  archive      = {J_TMRB},
  author       = {Achraj Sarma and Timothy A. Brumfiel and Yash Chitalia and Jaydev P. Desai},
  doi          = {10.1109/TMRB.2022.3216026},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {967-975},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Kinematic modeling and jacobian-based control of the COAST guidewire robot},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of a high-sensitivity proximal force/torque
sensor based on optical sensing for intravascular robots. <em>TMRB</em>,
<em>4</em>(4), 957–966. (<a
href="https://doi.org/10.1109/TMRB.2022.3214373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a proximal force/torque sensor with high sensitivity, adjustable measurement range, and decoupled force and torque detection for intravascular robots. The proposed sensor design primary consists of a force/torque-sensitive flexure that comprises a series of ortho-planar springs and an annulus cross-beam structure, an optical sensing unit with wireless communication. The ortho-planar component demonstrates equivalent functions as a parallel mechanism and achieves an outstanding linear force-displacement relationship along its axial direction. The rotational cross-beam structure has been parallelly arranged to form the torque-sensing component and enhanced sensing range. The utilized optical sensing unit can precisely detect the linear and angular displacement from the sensitive flexure based on a series of coherent CMOS images and support simultaneous detection and decoupling of force and torque. The FEM simulation has been performed for structure design and performance investigation. The prototyped sensor achieved a high force resolution of 8.7 mN within [−2.5, 2.5 N] and 0.13 $\text{N}\cdot $ mm within [−60, 60 $\text{N}\cdot $ mm] for torque, with the corresponding linearity error values of 1.43% and 1.95%. The average crosstalk error values are 0.32% for force detection and 2.8% for torque measurement, indicating excellent anti-interference performance. To investigate the practicability of the proposed sensor, the phantom experiment has been conducted to evaluate its effectiveness for intravascular catheterization.},
  archive      = {J_TMRB},
  author       = {Chaoyang Shi and Dezhi Song and Dewei Lai and Shuxin Wang},
  doi          = {10.1109/TMRB.2022.3214373},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {957-966},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of a high-sensitivity proximal Force/Torque sensor based on optical sensing for intravascular robots},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control of magnetic surgical robots with model-based
simulators and reinforcement learning. <em>TMRB</em>, <em>4</em>(4),
945–956. (<a href="https://doi.org/10.1109/TMRB.2022.3214426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetically manipulated medical robots are a promising alternative to current robotic platforms, allowing for miniaturization and tetherless actuation. Controlling such systems autonomously may enable safe, accurate operation. However, classical control methods require rigorous models of magnetic fields, robot dynamics, and robot environments, which can be difficult to generate. Model-free reinforcement learning (RL) offers an alternative that can bypass these requirements. We apply RL to a robotic magnetic needle manipulation system. Reinforcement learning algorithms often require long runtimes, making them impractical for many surgical robotics applications, most of which require careful, constant monitoring. Our approach first constructs a model-based simulation (MBS) on guided real-world exploration, learning the dynamics of the environment. After intensive MBS environment training, we transfer the learned behavior from the MBS environment to the real-world. Our MBS method applies RL roughly 200 times faster than doing so in the real world, and achieves a 6 mm root-mean-square (RMS) error for a square reference trajectory. In comparison, pure simulation-based approaches fail to transfer, producing a 31 mm RMS error. These results demonstrate that MBS environments are a good solution for domains where running model-free RL is impractical, especially if an accurate simulation is not available.},
  archive      = {J_TMRB},
  author       = {Yotam Barnoy and Onder Erin and Suraj Raval and Will Pryor and Lamar O. Mair and Irving N. Weinberg and Yancy Diaz-Mercado and Axel Krieger and Gregory D. Hager},
  doi          = {10.1109/TMRB.2022.3214426},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {945-956},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Control of magnetic surgical robots with model-based simulators and reinforcement learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic telepresence based on augmented reality and human
motion mapping for interventional medicine. <em>TMRB</em>,
<em>4</em>(4), 935–944. (<a
href="https://doi.org/10.1109/TMRB.2022.3201652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic telemedicine has a high potential to promote the development of future medicine. It enables the treatment of critical patients in geographically remote locations in time, and also particularly useful for avoiding infection risks during pandemics of infectious diseases. However, visual feedback from the patient’s side to the clinician’s side is often unintuitive due to a lack of depth information, occlusion, and viewing angles. This paper develops a robotic telepresence method based on augmented reality and human motion mapping for interventional medicine. An optical see-through head-mounted display (OST-HMD) is mounted at the distal end of a redundant manipulator, which can provide views from different directions, and the clinician can see through key anatomies and instruments located inside the patient body. The control of the manipulator is accomplished via human motion mapping, with both the end-effector and manifold of the human arm being mapped to the manipulator. A simple evaluation method is developed to assess the accuracy of head localization of the OST-HMD. Telepresence experiments are carried out to verify the effectiveness of the proposed method, with which the operator can see through a human airway phantom.},
  archive      = {J_TMRB},
  author       = {Zecai Lin and Tianxue Zhang and Zhenglong Sun and Hongyan Gao and Xiaojie Ai and Weidong Chen and Guang-Zhong Yang and Anzhu Gao},
  doi          = {10.1109/TMRB.2022.3201652},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {935-944},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic telepresence based on augmented reality and human motion mapping for interventional medicine},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward the design and development of a robotic transcatheter
delivery system for mitral valve implant. <em>TMRB</em>, <em>4</em>(4),
922–934. (<a href="https://doi.org/10.1109/TMRB.2022.3215522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally-invasive surgeries using transcatheter approaches and sophisticated imaging modalities are gaining popularity to treat mitral regurgitation (MR). This paper proposes the next generation of a robotic catheter to deliver an implant onto the mitral valve (MV) through a transseptal approach. The proposed robot has an outer diameter (OD) of 5.7 mm, a rigid distal end length of 20 mm, a prismatic tube that can be advanced by 50-60 mm, and a bending joint that can easily bend 120° to reach the valve opening. The implant can be rotated 75° bidirectionally by the distal torsion joint to orient it with the MV leaflet for precise implantation. The robotic joints are modeled individually, the forward and inverse kinematics are derived, and the robot motion validation is carried out through experimentation. A modified kinematics (MK) model, Prandtl-Ishlinskii (PI) hysteresis model, and hybrid of MK and PI model are used to compensate for the catheter nonlinearities. A preliminary study is conducted to evaluate if force sensing can be used to compensate for the effects of fluid flow. Also, the implantation procedure is demonstrated in a phantom heart.},
  archive      = {J_TMRB},
  author       = {Namrata U. Nayar and Ronghuai Qi and Jaydev P. Desai},
  doi          = {10.1109/TMRB.2022.3215522},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {922-934},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward the design and development of a robotic transcatheter delivery system for mitral valve implant},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design, sensing, and control of a magnetic compliant
continuum manipulator. <em>TMRB</em>, <em>4</em>(4), 910–921. (<a
href="https://doi.org/10.1109/TMRB.2022.3204577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuum manipulators coupled with magnetic actuation have great potential as steerable instruments for diverse surgical applications. They can be maneuvered inside the human body to reach difficult-to-access surgical sites with contactless actuation. This paper presents a new design of a compliant continuum manipulator of diameter 3 mm and length 70 mm, capable of spatial bending under magnetic actuation. A quasi-static model is developed to estimate the 3D motion of the manipulator. Experiments report an overall mean error in whole shape estimation of the manipulator between the model and the ground truth of 1.7 mm and 4.8 mm, when suspended vertically and horizontally from its base, respectively. Furthermore, fiber Bragg grating (FBG) sensors are integrated with the manipulator to enable shape sensing. Closed-loop control is demonstrated to trace different trajectories with the tip of the manipulator. A square trajectory and a straight line trajectory are generated with an average error in tip position of 4.1 mm between the desired and estimated positions. The potential of the manipulator as a steerable instrument is validated by maneuvering it inside phantoms of a bifurcating arterial system and a heart with visual guidance from a miniature camera.},
  archive      = {J_TMRB},
  author       = {Theodosia Lourdes Thomas and Jakub Sikorski and G. K. Ananthasuresh and Venkatasubramanian Kalpathy Venkiteswaran and Sarthak Misra},
  doi          = {10.1109/TMRB.2022.3204577},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {910-921},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design, sensing, and control of a magnetic compliant continuum manipulator},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fluoroscopy-guided robotic system for transforaminal lumbar
epidural injections. <em>TMRB</em>, <em>4</em>(4), 901–909. (<a
href="https://doi.org/10.1109/TMRB.2022.3196321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an autonomous robotic spine needle injection system using fluoroscopic image-based navigation. Our system includes patient-specific planning, intra-operative image-based 2D/3D registration and navigation, and automatic robot-guided needle injection. We performed intensive simulation studies to validate the registration accuracy. We achieved a mean spine vertebrae registration error of 0.8± 0.3 mm, 0.9± 0.7 degrees, mean injection device registration error of 0.2± 0.6 mm, 1.2± 1.3 degrees, in translation and rotation, respectively. We then conducted cadaveric studies comparing our system to an experienced clinician’s free-hand injections. We achieved a mean needle tip translational error of $5.1~\pm ~2.4$ mm and needle orientation error of $3.6~\pm ~1.9$ degrees for robotic injections, compared to 7.6± 2.8 mm and 9.9± 4.7 degrees for clinician’s free-hand injections, respectively. During injections, all needle tips were placed within the defined safety zones for this application. The results suggest the feasibility of using our image-guided robotic injection system for spinal orthopedic applications.},
  archive      = {J_TMRB},
  author       = {Cong Gao and Henry Phalen and Adam Margalit and Justin H. Ma and Ping-Cheng Ku and Mathias Unberath and Russell H. Taylor and Amit Jain and Mehran Armand},
  doi          = {10.1109/TMRB.2022.3196321},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {901-909},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Fluoroscopy-guided robotic system for transforaminal lumbar epidural injections},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and performance evaluation of a novel compliant wrist
for minimally invasive middle ear surgery. <em>TMRB</em>, <em>4</em>(4),
889–900. (<a href="https://doi.org/10.1109/TMRB.2022.3196837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: To present the design choices, modelling of bending stiffness and experimental validation of a novel notched Nitinol compliant wrist that enables tip articulation and suction during endoscopic and robotic middle ear surgery. Methods: The wrist consists of an inner wrist tube (IWT) assembled within an outer wrist tube (OWT). The OWT was selected from five concept designs that were evaluated based on stiffness and compact bending. An analytical model was developed based on Castigliano’s $2^{nd}$ Theorem and a finite element model (FEM) was developed to predict tip stiffness under soft-tissue surgical interactions and compared to experimental results. Results: The FEM and analytical models predicted tip displacement due to an applied force within 25% and 12 % of the experimental results, respectively. The complete wrist prototype withstood 700–1000 cycles before fracture when it was articulated up to 145° – 178°, corresponding to 9.6 N – 12.4 N of cable tension. Conclusion: A wristed tool is presented to facilitate endoscopic ear surgery and its mechanical behaviour in surgically relevant loading conditions. Significance: This instrument could be adapted to provide suction and soft tissue dissection capabilities for future minimally invasive endoscopic or robotic surgery, through the ear canal or other natural orifices.},
  archive      = {J_TMRB},
  author       = {Arushri Swarup and Jongwoo Kim and Peter Francis and Kyle W. Eastwood and Lueder A. Kahrs and Nichtima Chayaopas and James Drake and Adrian L. James},
  doi          = {10.1109/TMRB.2022.3196837},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {889-900},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design and performance evaluation of a novel compliant wrist for minimally invasive middle ear surgery},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Review of bioinspired vision-tactile fusion perception
(VTFP): From humans to humanoids. <em>TMRB</em>, <em>4</em>(4), 875–888.
(<a href="https://doi.org/10.1109/TMRB.2022.3215749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots are designed and expected to resemble humans in structure and behavior, showing increasing application potentials in various fields. Like their biological counterparts, their environmental perception ability is fundamental. In particular, the visual and tactile perception are the two main sensory modes that humanoids use to understand and interact with the environment. Vision-Tactile Fusion Perception (VTFP) has shown multiple possibilities for better sensing understanding in challenging conditions, causing new research interests and questions. The overlap between visual and tactile perception in humanoids is continually growing. This work has reviewed the current state of the art of VTFP. It starts with the physiological basis of biological vision and tactile systems as well as the VTFP mechanisms as inspirations for humanoid perception. Then, the bioinspired visual-tactile fusion systems for humanoids are reviewed as the emphasis. After the survey on the vision and tactile sensors of robots, seven currently publicly available VTFP datasets are introduced. They are the data sources for several studies on neural network-inspired fusion algorithms. Furthermore, the applications of VTFP on humanoids are summarized. Finally, the challenges and future work are discussed. This review aims to provide several references for further exploitation of VTFP and its applications on humanoids.},
  archive      = {J_TMRB},
  author       = {Bin He and Qihang Miao and Yanmin Zhou and Zhipeng Wang and Gang Li and Shoulin Xu},
  doi          = {10.1109/TMRB.2022.3215749},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {875-888},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Review of bioinspired vision-tactile fusion perception (VTFP): From humans to humanoids},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic ultrasonography for autonomous non-invasive
diagnosis—a systematic literature review. <em>TMRB</em>, <em>4</em>(4),
863–874. (<a href="https://doi.org/10.1109/TMRB.2022.3201651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This systematic review was conducted to synthesize and critically appraise the current evidence on the automation of non-invasive diagnostic ultrasonography using robots. Medline, Scopus, EMBASE, Web of Science, and PubMed databases were searched using a defined search strategy. Eighteen studies were included for consideration after reviewing 1,932 studies. Through appraisal, the selected studies were found to be of high quality. An automated ultrasound examination can be divided into two stages. The first stage involves localization of the region of interest and moving the probe close to that region, while the second stage involves manipulating the probe configuration around the region of interest to scan and acquire an optimized image. Although the second stage was fully automated in all the analyzed systems, the first initialization stage requires full or partial assistance from the sonographer in 11 of the systems. Future studies should propose novel methods to perform these procedures without the sonographer’s aid. Fourteen studies used a combination of visual and force feedback to control the scanning and optimization. The utilization of ultrasound image feedback for probe manipulation during this process has the potential to improve the accuracy and robustness of the system.},
  archive      = {J_TMRB},
  author       = {Mariadas Capsran Roshan and Adrian Pranata and Mats Isaksson},
  doi          = {10.1109/TMRB.2022.3201651},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {863-874},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic ultrasonography for autonomous non-invasive Diagnosis—A systematic literature review},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A remotely controlled oropharyngeal swab sampling robot and
its application in COVID-19 prevention. <em>TMRB</em>, <em>4</em>(3),
852–861. (<a href="https://doi.org/10.1109/TMRB.2022.3192906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oropharyngeal swab sampling is the major viral nucleic acid detection method to diagnose COVID-19. Medical staff exposes themselves to the respiratory secretions of patients, which makes them vulnerable to infection. To protect medical staff, we summarize the clinical requirements for robot into five considerations (standardization, ergonomics, safety, isolation, and task allocation) and developed a remotely operated oropharyngeal swab sampling robot. With robot assistance, spatial isolation between medical staff and the patients can be achieved. We designed a hybrid force/position control scheme for the sampling robot to achieve intuitive operation and stable contact force. The experiment results on phantom tissue show that the sampling robot can achieve intuitive operation and stable contact on the soft posterior pharyngeal. Clinical trials for 20 volunteers and 2 patients diagnosed with COVID-19 are carried out. The results of the clinical trial indicated that the sampling robot can collect samples stably and effectively, and the contact force is gentler and more uniform. For two patients diagnosed with COVID-19, the robot sampling results are consistent with manual sampling.},
  archive      = {J_TMRB},
  author       = {Hao Liu and Zhenxing Wang and Tao Yu and Chongyang Wang and Shaoqiang Li and Wenliang Guo and Yongming Yang and Yuanyuan Zhou and Lianqing Liu and Shiyue Li and Haibin Yu},
  doi          = {10.1109/TMRB.2022.3192906},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {852-861},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A remotely controlled oropharyngeal swab sampling robot and its application in COVID-19 prevention},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling the transitional kinematics between
variable-incline walking and stair climbing. <em>TMRB</em>,
<em>4</em>(3), 840–851. (<a
href="https://doi.org/10.1109/TMRB.2022.3185405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although emerging powered prostheses can enable people with lower-limb amputation to walk and climb stairs over different task conditions (e.g., speeds and inclines), the control architecture typically uses a finite-state machine to switch between activity-specific controllers. Because these controllers focus on steady-state locomotion, powered prostheses abruptly switch between controllers during gait transitions rather than continuously adjusting leg biomechanics in synchrony with the users. This paper introduces a new framework for powered prosthesis control by modeling the lower-limb joint kinematics over a continuum of variable-incline walking and stair climbing, including steady-state and transitional gaits. Steady-state models for walking and stair climbing represent joint kinematics as continuous functions of gait phase, forward speed, and incline. Transition models interpolate kinematics as convex combinations of the two steady-state models, with an additional term to account for kinematics that fall outside their convex hull. The coefficients of this convex combination denote the similarity of the transitional kinematics to each steady-state mode, providing insight into how able-bodied individuals continuously transition between ambulation modes. Cross-validation demonstrates that the model predictions of untrained kinematics have errors within the range of physiological variability for all joints. Simulation results demonstrate the model’s robustness to incline estimation and mode classification errors.},
  archive      = {J_TMRB},
  author       = {Shihao Cheng and Edgar Bolívar-Nieto and Cara Gonzalez Welker and Robert D. Gregg},
  doi          = {10.1109/TMRB.2022.3185405},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {840-851},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Modeling the transitional kinematics between variable-incline walking and stair climbing},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental learning and fault-tolerant classifier for
myoelectric pattern recognition against multiple bursting interferences.
<em>TMRB</em>, <em>4</em>(3), 830–839. (<a
href="https://doi.org/10.1109/TMRB.2022.3176095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bursting interference that causes a sudden and significant change in surface electromyography (sEMG) characteristics, can reduce the stability and security of myoelectric assistive robots. Current adaptation strategies for progressive-generated interference are incapable of dealing with bursting interference. To address this problem, an incremental learning and fault-tolerant classifier (ILFTC) was proposed by combining a Gaussian mixture model (GMM) ensemble and linear discriminant analysis (LDA), in conjunction with online update and marginalization schemes. Subsequently, an ILFTC-based myoelectric pattern recognition (MPR) strategy was developed to improve the robustness of MPR against multiple interferences, including outlier motion and missing/fault data owing to electrode loosening. Experiments on hand/wrist motions were conducted to validate the anti-interference performance of the ILFTC. Experimental results showed that the ILFTC could effectively resist the two types of bursting interference and produce a significant improvement in the recognition performance over traditional classifiers, as well as the methods presented in previous studies. The results show that the proposed method has the potential to enhance the robustness of myoelectric assistive robots.},
  archive      = {J_TMRB},
  author       = {Qichuan Ding and Xiaoliang Zhang and Xingang Zhao and Chengdong Wu},
  doi          = {10.1109/TMRB.2022.3176095},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {830-839},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Incremental learning and fault-tolerant classifier for myoelectric pattern recognition against multiple bursting interferences},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sparse sonomyography-based estimation of isometric force: A
comparison of methods and features. <em>TMRB</em>, <em>4</em>(3),
821–829. (<a href="https://doi.org/10.1109/TMRB.2022.3172680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noninvasive methods for estimation of joint and muscle forces have widespread clinical and research applications. Surface electromyography (sEMG) provides a measure of the neural activation of muscles which can be used to estimate the force produced by the muscle. However, sEMG based measures of force suffer from poor signal-to-noise ratio and limited spatiotemporal specificity. In this paper, we propose a sonomyography or ultrasound imaging-based offline approach for estimating continuous isometric force from a sparse set of ultrasound scanlines. Our approach isolates anatomically relevant features from A-mode scanlines isolated from B-mode images, thus greatly reducing the dimensionality of the feature space and the computational complexity involved in traditional ultrasound-based methods. We evaluate the performance of four regression methodologies for force prediction using the reduced sonomyographic feature set. We also evaluate the feasibility of a practical wearable sonomyography-based system by simulating the effect of transducer placement and varying the number of transducers used in force prediction. Our results demonstrate that Gaussian process regression models outperform other regression methods in predicting continuous force levels from just four equispaced transducers in offline settings. We believe that these findings will aid in the design of wearable, robust and computationally efficient sonomyography-based force prediction systems.},
  archive      = {J_TMRB},
  author       = {Anne Tryphosa Kamatham and Meena Alzamani and Allison Dockum and Siddhartha Sikdar and Biswarup Mukherjee},
  doi          = {10.1109/TMRB.2022.3172680},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {821-829},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Sparse sonomyography-based estimation of isometric force: A comparison of methods and features},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The yale MyoAdapt hand: A highly functional and adaptive
single actuator prosthesis. <em>TMRB</em>, <em>4</em>(3), 807–820. (<a
href="https://doi.org/10.1109/TMRB.2022.3193305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drawbacks of many commercially available multi-actuator prosthetic hands have led to high rejection rates in both adults and children. For an active lifestyle, there is a need for a device that is both lightweight and easy to control. Underactuation has quickly become an attractive solution in prosthetics by reducing the control burden and the weight of multi-actuator hands while still providing a compliant anthropomorphic grasp. In this paper we present the design and evaluation of a novel single actuator prosthetic hand. The hand uses adaptive mechanisms to allow for three unique grasp types with varying grasp rates, force output and thumb positions. The hand kinematics and geometry are optimized to prevent against common grasp failure modes of underactuated grippers. The hand was evaluated through benchtop and human subject testing to evaluate its effectiveness on activities of daily living. Additionally, we compared the performance of the hand to previously published results from a powered hook, a single actuator anthropomorphic robotic hand, and several commercial multi-actuator anthropomorphic robotic hands. The results show that the hand is comparable even to multiactuator commercial devices with users who have trained on these devices for several months to years.},
  archive      = {J_TMRB},
  author       = {Michael T. Leddy and Aaron M. Dollar},
  doi          = {10.1109/TMRB.2022.3193305},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {807-820},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {The yale MyoAdapt hand: A highly functional and adaptive single actuator prosthesis},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impedance control of a wrist rehabilitation robot based on
autodidact stiffness learning. <em>TMRB</em>, <em>4</em>(3), 796–806.
(<a href="https://doi.org/10.1109/TMRB.2022.3194528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic control of an intrinsically compliant robot is paramount to ensuring safe and synergistic assistance to the patient. This paper presents an impedance controller for the rehabilitation of stroke patients with compromised wrist motor functions. The control design employs a Koopman operator-based autodidactic system identification model to predict the anatomical stiffness of the wrist joint during its various degrees of rotational motion. The proposed impedance controller, perceiving the level of the subjects’ participation from their joint stiffness, can modify the applied force. The end-effector robot has a parallel structure that uses four biomimetic muscle actuators as parallel links between the end-effector and the base platform. The controller performance is corroborated by testing the end-effector robot with three healthy subjects.},
  archive      = {J_TMRB},
  author       = {Tanishka Goyal and Shahid Hussain and Elisa Martinez-Marroquin and Nicholas A. T. Brown and Prashant K. Jamwal},
  doi          = {10.1109/TMRB.2022.3194528},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {796-806},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Impedance control of a wrist rehabilitation robot based on autodidact stiffness learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Field-based human-centred control on SO(3) for
assist-as-needed robotic rehabilitation. <em>TMRB</em>, <em>4</em>(3),
785–795. (<a href="https://doi.org/10.1109/TMRB.2022.3194372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assist-as-needed (AAN) control can effectively improve the participation of the patient. However, the current research on attitude control in a manifold and also a special orthogonal group, SO(3), adapted to three-dimensional (3D) gait training and three-degree-of-freedom joint training is insufficient. The controller drives the patients to follow a timed trajectory and have the disadvantage of imposing a defined timing of movement. The deviation between patient and robot is neglected and the actual movement of human is not considered. Therefore, this study proposes a human-centred control method on SO(3) for AAN robotic rehabilitation. First, a feedback-stabilized closest attitude tracking algorithm is proposed to establish the angular velocity field and moment field on SO(3). And the framework of the field-based double-loop control is realised. The posture information of the human limbs is fed back to the controller through the sensing system, and the motion state of the human body is sensed in real-time, which is used as the basis for adjusting the torque to realise human-centred control. The experimental results show that different levels of adjustment torque are generated based on attitude deviations between the human and robot to verify the effectiveness of the designed controller.},
  archive      = {J_TMRB},
  author       = {Di Shi and Long Li and Wuxiang Zhang and Xilun Ding},
  doi          = {10.1109/TMRB.2022.3194372},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {785-795},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Field-based human-centred control on SO(3) for assist-as-needed robotic rehabilitation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint-angle adaptive coordination control of a
serial-parallel lower limb rehabilitation exoskeleton. <em>TMRB</em>,
<em>4</em>(3), 775–784. (<a
href="https://doi.org/10.1109/TMRB.2022.3178520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A serial–parallel lower limb rehabilitation exoskeleton can achieve a kinematic function similar to that of the human lower limb. Based on this bionic structure, joint-angle coordination is needed for model-based control. Because the kinematics of the parallel mechanism is difficult to solve, real-time attitude control of the task space cannot be realized. Moreover, owing to structural errors and parameter uncertainty, accurate modeling cannot be realized, which causes difficulties in system control. Therefore, based on existing modeling methods, adaptive control of a serial–parallel lower limb rehabilitation exoskeleton is proposed. The sensor of the parallel mechanism can realize accurate perception of the attitude, and the controller is designed to solve the control problem of the task space of the parallel component. A radial basis function neural network adaptive controller is used to compensate for the uncertainty and external disturbance of the model. Experiments were conducted to verify the effectiveness of the dynamic modeling and control system.},
  archive      = {J_TMRB},
  author       = {Di Shi and Wei Zhang and Liduan Wang and Wuxiang Zhang and Yanggang Feng and Xilun Ding},
  doi          = {10.1109/TMRB.2022.3178520},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {775-784},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Joint-angle adaptive coordination control of a serial-parallel lower limb rehabilitation exoskeleton},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reducing migration of knee exoskeletons with dynamic waist
strap. <em>TMRB</em>, <em>4</em>(3), 764–774. (<a
href="https://doi.org/10.1109/TMRB.2022.3185416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Downward migration of knee exoskeletons under external forces is one major concern against their normal operations. It may be reduced by increasing the friction between exoskeletons and the human thigh. However, the effectiveness of friction control remains questionable, as the natural inverted-cone shape of the human thigh will aggravate downward migration, and the overwhelming strapping intensity will degrade the activation level of muscles. In this paper, we propose a new suspension system called the Dynamic Waist Strap. Theoretical analysis and experimental validations on multiple subjects are conducted to show its advantages over the three mainstream suspension systems commonly used for knee exoskeletons in terms of the reduction of migration, interaction torque, and maximum dip angle. This study highlights the importance of the suspension system when attaching a knee exoskeleton to the human and introduces a new dynamic interaction interface to improve the coupling from a knee exoskeleton to an individual.},
  archive      = {J_TMRB},
  author       = {Ming Xu and Zhihao Zhou and Jinyan Shao and Lecheng Ruan and Qining Wang},
  doi          = {10.1109/TMRB.2022.3185416},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {764-774},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Reducing migration of knee exoskeletons with dynamic waist strap},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gait deviation correction method for gait rehabilitation
with a lower limb exoskeleton robot. <em>TMRB</em>, <em>4</em>(3),
754–763. (<a href="https://doi.org/10.1109/TMRB.2022.3194360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeleton robots play an essential role in the gait rehabilitation of lower limbs in stroke patients. Existing lower limb exoskeleton robots commonly employ reference trajectories to perform gait rehabilitation training for patients. However, a significant gait deviation may occur between the gait trajectory of the wearer and the reference trajectory due to the following reasons. They are the physically flexible connection and the applied compliance control strategy between the wearer and the exoskeleton. This paper proposes a gait deviation correction method (GDCM) to decrease the gait deviation for lower limb exoskeleton robots. First, the gait curves of the exoskeleton and the wearer were obtained by using the clinical gait analysis (CGA) curve as a reference trajectory for the exoskeleton. Then, a gait correction model was trained by a database containing the CGA curve, the gait trajectory of both the exoskeleton and wearer obtained from 15 participants, and their body feature parameters such as height, weight, and hip-length. Finally, the gait correction model was introduced into the control system to modify the input trajectory of the exoskeleton. The experimental results showed that the gait trajectories of the wearer’s hip and knee after correction were closer to the CGA curve than without modification. The minor gait trajectory deviation should lead to a better efficacy of the training with the robot if the reference trajectory is assumed to be optimal.},
  archive      = {J_TMRB},
  author       = {Shisheng Zhang and Xiao Guan and Jing Ye and Gong Chen and Zhimian Zhang and Yuquan Leng},
  doi          = {10.1109/TMRB.2022.3194360},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {754-763},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Gait deviation correction method for gait rehabilitation with a lower limb exoskeleton robot},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gait-symmetry-based human-in-the-loop optimization for
unilateral transtibial amputees with robotic prostheses. <em>TMRB</em>,
<em>4</em>(3), 744–753. (<a
href="https://doi.org/10.1109/TMRB.2022.3176476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait asymmetry due to unilateral limb loss increases the risk of injury or progressive joint degeneration. The devel- opment of wearable robotic devices paves the way for improving the gait symmetry of unilateral amputees. However, the state-of-the-art studies on human-in-the-loop optimization strategies with an optimization task of reducing the metabolic cost face several challenges, e.g., an excessively long optimization period and the infeasibility of optimization for unilateral amputees who have a deficit of gait symmetry. Herein, we propose a gait-symmetry-based human-in-the-loop optimization method to reduce the risk of injury or progressive joint degeneration for unilateral transtibial amputees. Experimental results ( ${N} =3$ ) indicated that convergence took the range of $388{s}$ to 821 ${s}$ . After optimization, compared with using passive prostheses, the gait-symmetry indicator of subjects wearing the robotic prostheses was improved by the range of 6.0% to 52.0%, and the net metabolic energy consumption was reduced by the range of 3.0% to 13.4%. Additionally, the rationality of gait indicators based on kinematics rather than kinetics was assessed. The results indicated that the human-in-the-loop strategy can improve the gait symmetry by reducing the metabolic cost and thus reduce the risk of joint injury for unilateral amputees.},
  archive      = {J_TMRB},
  author       = {Yanggang Feng and Chengqiang Mao and Wuxiang Zhang and Qining Wang},
  doi          = {10.1109/TMRB.2022.3176476},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {744-753},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Gait-symmetry-based human-in-the-loop optimization for unilateral transtibial amputees with robotic prostheses},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supporting and stabilizing the scapulohumeral rhythm with a
body- or robot-powered orthosis. <em>TMRB</em>, <em>4</em>(3), 729–743.
(<a href="https://doi.org/10.1109/TMRB.2022.3176728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The versatile functionality of the human upper limb is owed to the coordinated rotation of the scapula and humerus, a pattern called the scapulohumeral rhythm (SHR). Various medical conditions can alter the SHR, frequently leading to limitations in activities of daily living. However, to date, supporting the SHR in practice is often not feasible. We present a textile orthosis that assists the SHR both in stand-alone use and in combination with the ANYexo, a therapy exoskeleton, or the Myoshirt, an assistive exomuscle. The SHR Orthosis comprised a textile harness and a scapula interface that was coupled with the upper arm to promote scapular upward rotation. In a technical evaluation including four participants without impairments and one with a partial hemiparesis, the SHR Orthosis followed the desired scapular rotation with an average deviation of less than 5°, thus providing accurate support and guidance towards the physiological SHR. The SHR Orthosis substituted for ≤ 42.0 % of the normal forces, and ≤ 19.6 % of the tangential forces required for scapular stabilization and rotation, providing sufficient support for patients with remaining muscular function. At last, the SHR Orthosis provides practicable scapula support in daily life, during conventional therapy, and in combination with assistive and therapy robots.},
  archive      = {J_TMRB},
  author       = {Anna-Maria Georgarakis and Yves Zimmermann and Peter Wolf and Marco Hutter and Robert Riener},
  doi          = {10.1109/TMRB.2022.3176728},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {729-743},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Supporting and stabilizing the scapulohumeral rhythm with a body- or robot-powered orthosis},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel childbirth simulator for real-time monitoring of
fetal head during the active phase of the labor. <em>TMRB</em>,
<em>4</em>(3), 720–728. (<a
href="https://doi.org/10.1109/TMRB.2022.3191494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A correct evaluation of the fetus progress into the birth canal during labor is often a complicated task, but it is of fundamental importance for a proper delivery management. Indeed, incorrect assessment of fetal presentation, position and station could lead to severe complications for both the fetus and the mother. Currently, fetus progress assessment during the delivery phase is still performed in the same way of last centuries, namely with a manual vaginal exploration assessed only using two fingers (index and medium fingers). This evaluation is therefore strongly subjective and dependent on clinical experience of the medical doctor; thus, reproducibility is very limited. In this framework, simulation-based training is a valuable instrument for obstetrics and gynecologists learning process, thus for evaluating and improving their abilities. In this work, we introduce a novel integrated childbirth platform which offers a real-time monitoring of fetal head during the active phase of labor. A real-time evaluation of fetal head presentation, position and station is provided, along with a 3D virtual visualization of the childbirth simulation. This kind of platform was conceived as a valid instrument for gynecological teaching and training. Preliminary results demonstrated its usefulness as an instrument for training in obstetrics and gynecology.},
  archive      = {J_TMRB},
  author       = {L. Morchi and Selene Tognarelli and Arianna Menciassi},
  doi          = {10.1109/TMRB.2022.3191494},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {720-728},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A novel childbirth simulator for real-time monitoring of fetal head during the active phase of the labor},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A high fidelity and high frequency physical simulator for
mitral annulus kinematics. <em>TMRB</em>, <em>4</em>(3), 708–719. (<a
href="https://doi.org/10.1109/TMRB.2022.3193425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular medical devices that operate within the heart are subjected to millions of loading cycles that can compromise the structural integrity of the implant over time. Accelerated structural testing is a major challenge in the design of implantable cardiac devices, particularly in the emerging realm of catheter-based devices used to treat conditions like mitral valve regurgitation (MR). In this work, we design a bench-top simulator for accelerated structural testing of devices that operate in or near the mitral valve. We first use four-dimensional computed tomography (4DCT) data to create a molded replica of the mitral valve and identify the most deformation-inducing time points in the cardiac cycle. We then kinematically analyze the motion of the mitral annulus using screw theory and create an electromechanical simulation device that mimics this motion at high frequencies. The final apparatus allows for multiple patient-specific scenarios and accurate closed loop displacement control of the screw-based kinematics of the mitral annulus. The test apparatus operates with less than 1 dB of passband ripple up to its 25.7 Hz bandwidth. The proposed device moves toward a desirable paradigm in accelerated structural testing that is less reliant on computational models, animal models, and high-risk early feasibility clinical trials.},
  archive      = {J_TMRB},
  author       = {Thomas W. Secord and Marija Vukicevic and Carter J. Gaulke and Charlie L. Eldredge and Erin I. Westman and Kelly A. Coyne and Drew J. Winkoski and Stephen H. Little},
  doi          = {10.1109/TMRB.2022.3193425},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {708-719},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A high fidelity and high frequency physical simulator for mitral annulus kinematics},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DRR-net: A dense-connected residual recurrent convolutional
network for surgical instrument segmentation from endoscopic images.
<em>TMRB</em>, <em>4</em>(3), 696–707. (<a
href="https://doi.org/10.1109/TMRB.2022.3193420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise segmentation of surgical instruments is the key link for the stable and reasonable operation of surgical robots. However, accurate surgical instrument segmentation is still a challenging task due to the complex surgical environment in endoscopic images, low contrast between surgical instruments and tissues, and the diversity of surgical instruments and their morphological variability. In recent years, deep learning has been widely applied into medical image segmentation and achieved a certain achievements, especially U-Net and its variants. However, existing surgical instrument segmentation networks still suffer from some shortcomings, such as insufficient processing of local feature maps, lack of temporal modeling information, etc. To address the above issues, in order to effectively improve the segmentation accuracy of surgical instruments, based on an encoder-decoder network structure, a novel dense residual recurrent convolutional network, called DRR-Net, is proposed in this paper for automatic and accurate surgical instrument segmentation from endoscopic images. Faced with lack of temporal modeling information, inspired by the recurrent neural networks (RNNs), an attention dense-connected recurrent convolutional block (ADRCB) is proposed to optimize the backbone network to obtain temporal information and learn the correspond pixel relationship between frames. To address the insufficient processing issue of local feature maps, to replace the simple skip connections, a residual path is proposed to enhance the context feature representation. Meanwhile, it could also reduce the effect of semantic gap issue. Further, to improve the segmentation accuracy on segmented objects with different sizes, a context fusion block (CFB) is proposed to embed into the bottleneck layer to extract multi-scale attention context features. Multiple public data sets on surgical instrument segmentation are adopted for model evaluation and comparison, including kvasir-instrument set and UW-Sinus-Surgery-C/L set. Experimental results demonstrate that proposed DRR-Net network could achieve an excellent performance compared with other advanced segmentation models.},
  archive      = {J_TMRB},
  author       = {Lei Yang and Yuge Gu and Guibin Bian and Yanhong Liu},
  doi          = {10.1109/TMRB.2022.3193420},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {696-707},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {DRR-net: A dense-connected residual recurrent convolutional network for surgical instrument segmentation from endoscopic images},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring operators’ natural behaviors to predict
catheterization trial outcomes in robot-assisted intravascular
interventions. <em>TMRB</em>, <em>4</em>(3), 682–695. (<a
href="https://doi.org/10.1109/TMRB.2022.3190211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, robotic catheterization has enhanced the outcomes of cardiovascular interventions. Meanwhile, the roles of operator’s natural behavior in the robot-assisted intravascular procedures need more attention. In this paper, operators’ hand activities related to endovascular tool manipulation are studied to explore how operators’ hand motions aid robotic catheterization. Controlled in-vivo studies were set up to acquire four types of operators’ natural behaviors during 60 robotic catheterization trials, and activity signals were recorded to proxy operators’ skills. A multi-layer recognition model is developed for recognizing the hand motions made during the procedures. The model operates convolution and dense layers to multiplex features extracted in single to multiple data modalities. Starting with initial-decision layer, the model is built to train and classify catheterization trials recorded from nine interventionists as successful and unsuccessful. Next, a motion-decision layer is built to recognize interventionists’ hand motions using features from different data modalities. Lastly, a mixed-decision layer is integrated to recognize the motion patterns of the successful and unsuccessful trials. Results show that the initial-decision layer has an accuracy of 99.44% in predicting the catheterization trials as successful and unsuccessful, while the motion-decision layer shows accuracies of 98.55% and 98.44% in classifying the seven types of hand motions that operators engage during successful and unsuccessful trials, respectively. Also, the mixed-decision layer has an accuracy of 93.96% in recognizing 14 mixed patterns from both trial classes. This study provides an objective template for skill training and evaluation in robot-assisted catheterization.},
  archive      = {J_TMRB},
  author       = {Wenjing Du and Olatunji Mumini Omisore and Wenke Duan and Lu Gan and Toluwanimi Oluwadra Akinyemi and Boon-Giin Lee and Jiang Liu and Lei Wang},
  doi          = {10.1109/TMRB.2022.3190211},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {682-695},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Exploring operators’ natural behaviors to predict catheterization trial outcomes in robot-assisted intravascular interventions},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cooperative brachytherapy robotic concept for localized
cancer treatment under real-time MRI. <em>TMRB</em>, <em>4</em>(3),
667–681. (<a href="https://doi.org/10.1109/TMRB.2022.3185796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, localized cancer treatment is one of the focused research interests of Physicians. Indeed, with the advent of sensor and actuator technologies with the feasibility of integrating multiple systems, treatment and diagnosis have gained more interest in incorporating Magnetic Resonance Imaging (MRI) due to better soft-tissue contrast. In this paper, the authors report the development of the MR-based Cooperative Brachytherapy (CoBra) robot design for in-bore patient prostate intervention, in terms of diagnosis and treatment of localized cancers. The presented CoBra system is characterized by three main MR-compatible components: a suitable leg-support ensuring patient stabilization, a versatile robotized needle guide, and an automated implant driver to deposit precisely radioactive seeds. In fact, ergonomically in-bore needle placement is a challenging problem, whereas the CoBra robot aims to help in in-bore intra-operative intervention under closed-loop control based on imagery feedback. This feedback might be exploited judiciously for tracking online the biological target during changes after needle insertions. Within this framework, the paper discusses the CoBra robot with a focus on kinematics design, modeling, instrumentation, control, and MRI in-bore robot tests, with respect to the adopted clinical workflow. Also, Preliminary experimental results simulating an adaptive prostate LDR-BT under 3 Tesla MRI are given to validate the proposed concept.},
  archive      = {J_TMRB},
  author       = {Abdelkader Belarouci and Sepaldeep Singh Dhaliwal and Mario Sanz-Lopez and Fabien Verbrugghe and Othman Lakhal and Taha Chettibi and Rochdi Merzouki},
  doi          = {10.1109/TMRB.2022.3185796},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {667-681},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Cooperative brachytherapy robotic concept for localized cancer treatment under real-time MRI},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robot-enabled uterus manipulator for laparoscopic
hysterectomy with soft RCM constraints: Design, control, and evaluation.
<em>TMRB</em>, <em>4</em>(3), 656–666. (<a
href="https://doi.org/10.1109/TMRB.2022.3181497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laparoscopic hysterectomy is a common minimally invasive gynecologic surgery in which an assistant is required to manipulate the uterus during the procedure according to the verbal commands of the primary surgeon. However, uterus manipulation is a lengthy and laborious task, where human fatigue may lower operating safety. This paper presents a novel robot-enabled uterus manipulation system that provides accurate, tireless, and direct uterus manipulation. The system consists primarily of a 7-DoF robotic arm tailored for uterus manipulation in laparoscopic hysterectomy. The primary surgeon can directly control the robot using a footswitch pedal to move within the constraint of the Remote Center of Motion (RCM) via software and achieve the desired range of pitch and yaw motion. An additional rotational motion around the instrument axis is provided for twisting the uterus to enhance the exposure of the ligaments and peritoneum for resection. In addition, the robot arm consists of 7 compact modular actuators that provide the target payload for holding the uterus while maintaining a small footprint in a constrained operating environment. To facilitate operation, a passive mobile base is provided for supporting and positioning the robot. A 6-D force sensor is equipped that allows the assistant to quickly guide the robot into the work area and move the robot under RCM constraint using an admittance control approach. The uterus manipulation rod can be easily detached from the robot body by a quick pluggable mechanism for preoperative sterilization. A quick pluggable mechanism was proposed for easy separation and mounting of the uterus manipulation rod from the robot body for preoperative sterilization. Experiments were performed to measure the performance of the modular joints, RCM repeatability, and evaluate the feasibility of the robot in the simulated laparoscopic hysterectomy.},
  archive      = {J_TMRB},
  author       = {Jiahao Wu and Wei Chen and Dezhao Guo and Gan Ma and Zerui Wang and Yucheng He and Fangxun Zhong and Bo Lu and Yudong Wang and Tak Hong Cheung and Yun-Hui Liu},
  doi          = {10.1109/TMRB.2022.3181497},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {656-666},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robot-enabled uterus manipulator for laparoscopic hysterectomy with soft RCM constraints: Design, control, and evaluation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitive remote robotic nasal sampling by orientation
control with variable RCM in limited space. <em>TMRB</em>,
<em>4</em>(3), 646–655. (<a
href="https://doi.org/10.1109/TMRB.2022.3176100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When performing polymerase chain reaction testing, collecting nasopharyngeal swabs from patients is necessary. Hence, the development of a noncontact specimen collection system is desired to avoid the risk of secondary infection from direct contact between the medical personnel and patients. This study aims to develop a master-follower-type remote specimen collection system to achieve infection protection through adequate isolation. A teleoperated robot is used for specimen collection work instead of a human; the teleoperated robot moves remotely, and a cotton swab is grasped and inserted into the nostril by the robot. A remote center of motion (RCM) mechanism was implemented to prevent the cotton swabs from making excessive contact with the nostril during specimen collection. Further, a variable RCM constraint that combines safety and operability is proposed as the conventional RCM control modification. The evaluation results indicated that the variable RCM restraint allowed a quicker and safer collection of specimens than the conventional RCM constraint.},
  archive      = {J_TMRB},
  author       = {Masaru Takeuchi and Yuma Hironaka and Tadayoshi Aoyama and Yasuhisa Hasegawa},
  doi          = {10.1109/TMRB.2022.3176100},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {646-655},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Intuitive remote robotic nasal sampling by orientation control with variable RCM in limited space},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A virtual reality and haptic simulator for ultrasound-guided
needle insertion. <em>TMRB</em>, <em>4</em>(3), 634–645. (<a
href="https://doi.org/10.1109/TMRB.2022.3175095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Articular and soft tissue punctions or injections are widely used for the diagnosis and the treatment of rheumatic disorders. Ultrasound is increasingly used to guide these interventions in order to correctly position the needle in the target area, and thereby improve the efficiency and safety of the procedure. During their learning, medical students need to practice in order to master the manipulation of the needle and the ultrasound probe at the same time and acquire enough skills before practicing in a real patient. To offer a risk-free training for apprentices, we present in this paper the design and development of a simulator based on Haptics and Virtual Reality. We described in particular two main aspects of our prototype: (i) the model of forces involved in the needle insertion and their haptic rendering; (ii) the 2D ultrasound image rendering of the virtual environment. Their combination provides the student with a realistic experience. An additional 3D view is also presented, that serves as pedagogical tool useful in the learning process. Experimental validation and preliminary evaluation by the medical partner show that our prototype exhibits sufficient stability and realism for a good immersion in the training scene.},
  archive      = {J_TMRB},
  author       = {Ma. Angeles Alamilla and Charles Barnouin and Richard Moreau and Florence Zara and Fabrice Jaillet and Hervé Tanneguy Redarce and Fabienne Coury},
  doi          = {10.1109/TMRB.2022.3175095},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {634-645},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A virtual reality and haptic simulator for ultrasound-guided needle insertion},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic endoscope system for future application in minimally
invasive laser osteotomy: First concept evaluation. <em>TMRB</em>,
<em>4</em>(3), 621–633. (<a
href="https://doi.org/10.1109/TMRB.2022.3172471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are developing a robotic system for future application in minimally invasive laser osteotomy. This paper presents the mechanical system concept as a macro-milli-micro system and focuses on designing and evaluating the milli-system. The milli-system consists of an articulated tendon-driven robotic endoscope with seven rigid links with an outer diameter of 8mm connected by six discrete rotational joints (±30°). These joints can be controlled individually, however, controlling one joint’s motion influences all joints located more distally, making joint control an interesting challenge. Controlling each joint as desired will allow positioning the micro-system mounted at the endoscope’s tip. The micro-system is itself a robot that will accurately position the laser. The robotic endoscope incorporates a hollow core with a diameter of 4.8mm that holds a supply channel for the micro-system with the necessary means for actuation and surgical intervention. We demonstrated the functionality of the robotic endoscope in tracking experiments. Despite the joints’ mutual influence, the articulated robotic endoscope could be handled successfully and achieved an angular settling error of less than 1° in the individual joints. The overall robotic system’s functionality was successfully demonstrated with a time-synchronized joint movement of the macro-system (serial manipulator) and the robotic endoscope.},
  archive      = {J_TMRB},
  author       = {Manuela Eugster and Cédric Duverney and Murali Karnam and Nicolas Gerig and Philippe C. Cattin and Georg Rauter},
  doi          = {10.1109/TMRB.2022.3172471},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {621-633},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic endoscope system for future application in minimally invasive laser osteotomy: First concept evaluation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An in-office hysteroscopy VR/haptic simulation platform for
training in spatial navigation and passage of the cervical canal.
<em>TMRB</em>, <em>4</em>(3), 608–620. (<a
href="https://doi.org/10.1109/TMRB.2022.3188438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hysteroscopy is a type of gynecological procedure that enables diagnosis and treatment of intrauterine pathologies using a minimally-invasive approach. Recent advancements, especially in optics, made it possible to perform this procedure in an ambulatory, outpatient setting without anaesthesia. Yet, such approach introduces additional challenges to gynecologists, as the surgical instruments have to pass through the cervix, a narrow curved canal. This process can be traumatic and even cause tissue damage or rupture. Current training curricula mainly focus on general minimally-invasive surgical skills or on inpatient hysteroscopy. This paper describes the first virtual reality training system designed purposely for in-office hysteroscopy training featuring both passive and active haptic feedback. Design requirements were defined through a literature review and a survey of clinical experts. A dedicated platform was developed and tested with clinicians and medical students. The results of the conducted experiments verified the skill acquisition capabilities of the platform showing a.o. shorter execution time and path length, lower integral forces in most of non-expert participants. The results also demonstrated the capability of the system to differentiate between experts and non-expert groups. Reported findings suggest that the platform has the potential to evolve into an effective solution for in-office hysteroscopy training.},
  archive      = {J_TMRB},
  author       = {Vladimir Poliakov and Kenan Niu and Dzmitry Tsetserukou and Emmanuel Vander Poorten},
  doi          = {10.1109/TMRB.2022.3188438},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {608-620},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {An in-office hysteroscopy VR/Haptic simulation platform for training in spatial navigation and passage of the cervical canal},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic autonomy for magnetic endoscope biopsy.
<em>TMRB</em>, <em>4</em>(3), 599–607. (<a
href="https://doi.org/10.1109/TMRB.2022.3187028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetically actuated endoscopes are currently transitioning in to clinical use for procedures such as colonoscopy, presenting numerous benefits over their conventional counterparts. Intelligent and easy-to-use control strategies are an essential part of their clinical effectiveness due to the un-intuitive nature of magnetic field interaction. However, work on developing intelligent control for these devices has mainly been focused on general purpose endoscope navigation. In this work, we investigate the use of autonomous robotic control for magnetic colonoscope intervention via biopsy, another major component of clinical viability. We have developed control strategies with varying levels of robotic autonomy, including semi-autonomous routines for identifying and performing targeted biopsy, as well as random quadrant biopsy. We present and compare the performance of these approaches to magnetic endoscope biopsy against the use of a standard flexible endoscope on bench-top using a colonoscopy training simulator and silicone colon model. The semi-autonomous routines for targeted and random quadrant biopsy were shown to reduce user workload with comparable times to using a standard flexible endoscope.},
  archive      = {J_TMRB},
  author       = {James W. Martin and Lavinia Barducci and Bruno Scaglioni and Joseph C. Norton and Conchubhair Winters and Venkataraman Subramanian and Alberto Arezzo and Keith L. Obstein and Pietro Valdastri},
  doi          = {10.1109/TMRB.2022.3187028},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {599-607},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic autonomy for magnetic endoscope biopsy},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic-assisted automatic orientation and insertion for
bronchoscopy based on image guidance. <em>TMRB</em>, <em>4</em>(3),
588–598. (<a href="https://doi.org/10.1109/TMRB.2022.3194320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the large number and complex structure of bronchial branches, frequent orientation and insertions during bronchoscopy are likely to cause surgeon fatigue and errors. Therefore, we designed a robotic-assisted automatic intervention system (RAIS) based on image guidance, which aims to realize automatic orientation and insertion of bronchoscope, for improving the intelligence and efficiency of the bronchoscopy. To realize image guidance, we proposed a highly robust and accurate lumen center detection method, which combines deep learning-based object detection and histogram back-projection. With image guidance of lumen center, RAIS automatically completes the orientation and insertion of bronchoscope. The results of human phantom lung experiments show that the accuracy and recall of proposed lumen center method can respectively reach 94.12% and 86.23% when the bronchoscope is being localized by RAIS. Moreover, the results show that it is feasible to automate the orientation and insertion of bronchoscope using RAIS, which is more efficient than the manual operating the robot. The proposed RAIS could replace the surgeon in performing a large number of repetitive and simple tasks, which can efficiently reduce the workload of the surgeon and improve the safety and efficiency of the procedure.},
  archive      = {J_TMRB},
  author       = {Yuelin Zou and Bo Guan and Jianchang Zhao and Shuxin Wang and Xinan Sun and Jianmin Li},
  doi          = {10.1109/TMRB.2022.3194320},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {588-598},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic-assisted automatic orientation and insertion for bronchoscopy based on image guidance},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Force-based control for safe robot-assisted retinal
interventions: In vivo evaluation in animal studies. <em>TMRB</em>,
<em>4</em>(3), 578–587. (<a
href="https://doi.org/10.1109/TMRB.2022.3191441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, robotic assistance in vitreoretinal surgery has moved from a benchtop environment to the operating rooms. Emerging robotic systems improve tool manoeuvrability and provide precise tool motions in a constrained intraocular environment and reduce/remove hand tremor. However, often due to their stiff and bulky mechanical structure, they diminish the perception of tool-to-sclera (scleral) forces, on which the surgeon relies, for eyeball manipulation. In this paper we measure these scleral forces and actively control the robot to keep them under a predefined threshold. Scleral forces are measured using a Fiber Bragg Grating (FBG) based force sensing instrument in an in vivo rabbit eye model in manual, cooperative robotic assistance with no scleral force control (NC), adaptive scleral force norm control (ANC) and adaptive scleral force component control (ACC) methods. To the best of our knowledge, this is the first time that the scleral forces are measured in an in vivo eye model during robot assisted vitreoretinal procedures. An experienced retinal surgeon repeated an intraocular tool manipulation (ITM) task 10 times in four in vivo rabbit eyes and a phantom eyeball, for a total of 50 repetitions in each control mode. Statistical analysis shows that the ANC and ACC control schemes restrict the duration of the undesired scleral forces to 4.41% and 14.53% as compared to 43.30% and 35.28% in manual and NC cases, respectively during the in vivo studies. These results show that the active robot control schemes can maintain applied scleral forces below a desired threshold during robot-assisted vitreoretinal surgery. The scleral forces measurements in this study may enable a better understanding of tool-to-sclera interactions during vitreoretinal surgery and the proposed control strategies could be extended to other microsurgery and robot-assisted interventions.},
  archive      = {J_TMRB},
  author       = {Niravkumar Patel and Muller Urias and Ali Ebrahimi and Russell H. Taylor and Peter Gehlbach and Iulian Iordachita},
  doi          = {10.1109/TMRB.2022.3191441},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {578-587},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Force-based control for safe robot-assisted retinal interventions: In vivo evaluation in animal studies},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bioinspired soft bendable peristaltic pump exploiting
ballooning for high volume throughput. <em>TMRB</em>, <em>4</em>(3),
570–577. (<a href="https://doi.org/10.1109/TMRB.2022.3192763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interest in bioinspired peristaltic pumps has grown in popularity among the scientific community in the last decade thanks to their extreme flexibility and their intrinsic compliance. In this paper, we propose a soft peristaltic pump exploiting ballooning. Our aim is to promote and propel forward the ballooned region by controlling the air pressure between the balloon and an external flexible containment tube, to achieve a peristaltic pumping motion with a simple design and using only one control signal. This paper describes the implementation of the pump and the inlet-pump-outlet system, provides an analytical model to predict the pump performance, and showcases experimental results. We also implement a computer simulation to further characterize the device. We show that it is possible to achieve high volumetric flow rates, up to $4.4\;mL/s$ , with only a single control signal, paving the way for more flexible and easy to manufacture peristaltic pumps.},
  archive      = {J_TMRB},
  author       = {Leone Costi and Josephine Hughes and John Biggins and Fumiya Iida},
  doi          = {10.1109/TMRB.2022.3192763},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {570-577},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Bioinspired soft bendable peristaltic pump exploiting ballooning for high volume throughput},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis and preliminary design of a passive upper limb
exoskeleton. <em>TMRB</em>, <em>4</em>(3), 558–569. (<a
href="https://doi.org/10.1109/TMRB.2022.3186903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reports the analysis and preliminary design of a passive, wearable, upper limb exoskeleton to support workers in industrial environments in a vast range of repetitive tasks, offering an effective strategy to reduce the risk of injuries in production lines. The system primary purpose is to compensate for gravity loads acting on the human upper limb. The proposed exoskeleton is based on 6 Degrees-of-Freedom (DoFs) kinematics with 5-DoFs for the shoulder joint (two displacements plus three rotations) and 1-DoF for the elbow. Gravity compensation is implemented with passive elastic elements to minimize weight and reduce cost. A detailed analytical tool is developed to support the designer in the preliminary design stage, investigating the exoskeleton kinetic-static behaviour and deriving optimal design parameters for the springs over the human arm workspace. By defining specific functional requirements (i.e., the user’s features and simulated movements), computationally efficient optimization studies may be carried out to determine the optimal coefficients and positions of the springs, thus, maximizing the accuracy of the gravity balancing. Two different solutions for the arrangement of the elastic elements are investigated, and obtained results are validated with a commercial multi-body tool for some relevant movements of the user’s arm.},
  archive      = {J_TMRB},
  author       = {Greta Vazzoler and Pietro Bilancia and Giovanni Berselli and Marco Fontana and Antonio Frisoli},
  doi          = {10.1109/TMRB.2022.3186903},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {558-569},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Analysis and preliminary design of a passive upper limb exoskeleton},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptation of walking-patterns to damage for the six-legged
walking robot LAURON v. <em>TMRB</em>, <em>4</em>(3), 550–557. (<a
href="https://doi.org/10.1109/TMRB.2022.3185425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are brought to more and more remote locations. Not only worldwide, but also in- and outside our solar system. They have proven to be a great tool to get tasks done without endangering humans in life-hostile environments. One downside of those environments and locations is the impossibility of repairs and mechanical maintenance. Inspired by insects and other walking forms of life this work uses the redundancy of a six-legged robot to increase mobility in case of damages. Without detaching any parts of the robot it is reconfigured to minimize the impact of damage and remains walking sparing one leg. A statically stable position is hold at all times so potential cargo is always kept safe. The method is implemented and tested with the six-legged walking robot LAURON V.},
  archive      = {J_TMRB},
  author       = {C. Plasberg and A. Roennau and R. Dillmann},
  doi          = {10.1109/TMRB.2022.3185425},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {550-557},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Adaptation of walking-patterns to damage for the six-legged walking robot LAURON v},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tactile-based assistive method to support physical therapy
routines in a lightweight upper-limb exoskeleton. <em>TMRB</em>,
<em>4</em>(3), 541–549. (<a
href="https://doi.org/10.1109/TMRB.2022.3188429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical therapy is the pillar of rehabilitation for disabilities caused by neurological disorders, however not every patient has access to it due to the lack of human resources. Robot-based rehabilitation can contribute to the solution of this challenge with benefits such as task-oriented exercise routines. In order to increase therapy frequency and intensity, we propose the use of robot skin as multi-sensory interface to maximize the wearability and support of a lightweight elbow flexion/extension exoskeleton. The robot skin exoskeleton detects the motion intention by measuring acceleration, proximity, and interaction forces. This allows the implementation of control modes which are inspired by physical therapy such as passive movement, active support, resistance training, and corrective therapy. To assess every therapy-inspired control mode, a study analyzing force readings and sEMG recordings of the biceps during exoskeleton use was conducted with four healthy subjects to test the exoskeleton functionality. Our results show that higher assistive levels under the supportive therapy control modes result in larger reductions of normalized sEMG ( $&amp;gt;$ 40% in passive exercises), whereas higher resistive levels result in an increase of normalized sEMG ( $&amp;gt;$ 30% in resistive exercises). Thus, enabling the exoskeleton to use multi-sensory interfaces to implement therapy routines based on user intention.},
  archive      = {J_TMRB},
  author       = {Natalia Paredes-Acuña and Nicolas Berberich and Emmanuel Dean-León and Gordon Cheng},
  doi          = {10.1109/TMRB.2022.3188429},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {541-549},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Tactile-based assistive method to support physical therapy routines in a lightweight upper-limb exoskeleton},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Special section on the 20th international conference on
advanced robotics—ICAR2021. <em>TMRB</em>, <em>4</em>(3), 539–540. (<a
href="https://doi.org/10.1109/TMRB.2022.3194785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {THE IEEE TRANSACTIONS ON MEDICAL ROBOTICS AND BIONICS (T-MRB) is a joint initiative of the two IEEE Societies for Robotics and Automation - RAS - and Engineering in Medicine and Biology - EMBS.},
  archive      = {J_TMRB},
  author       = {Alícia Casals and Marko Munih},
  doi          = {10.1109/TMRB.2022.3194785},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {539-540},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Special section on the 20th international conference on advanced Robotics—ICAR2021},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). IEEE robotics and automation society information.
<em>TMRB</em>, <em>4</em>(2), C3. (<a
href="https://doi.org/10.1109/TMRB.2022.3171120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.},
  archive      = {J_TMRB},
  doi          = {10.1109/TMRB.2022.3171120},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {C3},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {IEEE robotics and automation society information},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-surgical removal of partially absorbable bionic
implants. <em>TMRB</em>, <em>4</em>(2), 530–537. (<a
href="https://doi.org/10.1109/TMRB.2022.3155291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bionic implants offer the potential to augment human performance and to assist the body in recovering functions lost to disease. While some may be permanently implanted, others provide temporary support. The challenge for the second case is how to remove the device from the body once its task is complete without forcing the patient to undergo a second surgical procedure. While some devices may be fabricated entirely from absorbable materials, this may not always be possible. This paper investigates a strategy in which an implant is fabricated from a combination of absorbable and non-absorbable materials with the latter connected by a tether to the skin. At the time of removal, the device is disassembled in situ such that the absorbable components can remain in place while the non-absorbable components can be removed non-surgically by pulling them out of the body by the tether. The concept is demonstrated in the context of an implant that induces bowel growth by applying traction forces over a several-week period. In vivo experiments in swine are used to validate the approach.},
  archive      = {J_TMRB},
  author       = {Viola Del Bono and Joseph Peine and Martina Finocchiaro and Karl D. Price and Margherita Mencattelli and Yash Chitalia and Victoria H. Ko and Lumeng Yu and Jordan Secor and Amy Pan and Zurab Machaidze and Mark Puder and Alessio Artoni and Pierre E. Dupont},
  doi          = {10.1109/TMRB.2022.3155291},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {530-537},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Non-surgical removal of partially absorbable bionic implants},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A spiking neural network mimics the oculomotor system to
control a biomimetic robotic head without learning on a neuromorphic
hardware. <em>TMRB</em>, <em>4</em>(2), 520–529. (<a
href="https://doi.org/10.1109/TMRB.2022.3155278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilitated by the emergence of neuromorphic hardware, neuromorphic algorithms mimic the brain’s asynchronous computation to improve energy efficiency, low latency, and robustness, which are crucial for a wide variety of real-time robotic applications. However, the limited on-chip learning abilities hinder the applicability of neuromorphic computing to real-world robotic tasks. Biomimetism can overcome this limitation by complementing or replacing training with the knowledge of the brain’s connectome associated with the targeted behavior. By drawing inspiration from the human oculomotor network, we designed a spiking neural network (SNN) that tracked visual targets in real-time. We deployed the biomimetic controller on Intel’s Loihi neuromorphic processor to control an in-house robotic head. The robot’s behavior resembled the smooth pursuit and saccadic eye movements observed in humans, while the SNN on Loihi exhibited similar performance to a CPU-run PID controller. Interestingly, this behavior emerged from the SNN without training, which places the biomimetic design as an alternative to the energy- and data-greedy learning-based methods. This work reinforces our on-going efforts to devise energy-efficient autonomous robots that mimic the robustness and versatility of their biological counterparts.},
  archive      = {J_TMRB},
  author       = {Ioannis Polykretis and Guangzhi Tang and Praveenram Balachandar and Konstantinos P. Michmizos},
  doi          = {10.1109/TMRB.2022.3155278},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {520-529},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A spiking neural network mimics the oculomotor system to control a biomimetic robotic head without learning on a neuromorphic hardware},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and testing of a novel, high-performance two DoF
prosthetic wrist. <em>TMRB</em>, <em>4</em>(2), 502–519. (<a
href="https://doi.org/10.1109/TMRB.2022.3155279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extrinsically powered prosthetic wrists have the potential to offer significant improvements to the functionality and dexterity of a prosthetic hand. They can also reduce a user’s overreliance on their intact limb and help prevent injury from overuse of upper limb (both intact and residual) and trunk joints. Despite these potential advantages, there are very few prosthetic wrist options that are commercially available and these devices are not commonly used by prosthetic hand users due to several factors including inadequate performance specifications. In this paper, we first seek to establish the target specifications for a prosthetic wrist suitable for both median men and women. We then complete a comprehensive review of the state-of-the-art in extrinsically powered prosthetic wrists in the research, commercial, and patent literature. This review determines that no existing prosthetic wrist meets the target specifications due to the presence of actuators and transmissions that do not offer sufficient torque density, power density, and specific power. In order to address this challenge and produce a prosthesis that achieves target specifications, we next review the performance of existing actuators and transmissions and determine that Brushless DC motors with planetary gearboxes and ball screws offer the best potential to achieve the target specifications. We then present the design of a novel two Degree of Freedom parallel kinematic prosthetic wrist that incorporates this actuator-transmission combination. This first iteration of the proposed prosthetic wrist meets the target torque, speed, and weight but does not meet the target dimensions or range of motion yet. We propose design improvements in subsequent iterations that could lead to a prosthetic wrist that meets all the target specifications of torque, speed, weight, and volume.},
  archive      = {J_TMRB},
  author       = {Revanth Damerla and Kevin Rice and Daniel Rubio-Ejchel and Maurice Miro and Enrico Braucher and Juliet Foote and Issam Bourai and Aaryan Singhal and Kang Yang and Hongju Guang and Vasil Iakimovitch and Evelyn Sorgenfrei and Shorya Awtar},
  doi          = {10.1109/TMRB.2022.3155279},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {502-519},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design and testing of a novel, high-performance two DoF prosthetic wrist},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and assist-as-needed control of a lightly powered
prosthetic knee. <em>TMRB</em>, <em>4</em>(2), 490–501. (<a
href="https://doi.org/10.1109/TMRB.2022.3161068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design of a swing-assist prosthetic knee capable of providing stabilizing passive torques during the stance phase of walking and supplementing the passive swing phase behavior of the prosthetic knee with small active torques. The prosthesis design utilizes a novel actuator which integrates a symmetric multi-chamber hydraulic cylinder and a highly backdrivable linear electromechanical drive system into a single compact package. This actuator is implemented in a self-contained prosthesis design (including batteries and embedded system) which weighs 1.7 kg and is 28 cm in length, making this design comparable in size/mass to commercially available microprocessor-controlled prosthetic knees. The device is controlled using a finite state machine with a novel assist-as-needed controller operating during the swing phase. This assist-as-needed controller supplements a nominally passive swing phase behavior with small amounts of active power to enhance user safety. The device and controller were assessed on a single participant who took part in level ground walking experiments with both the swing-assist prosthesis and his daily-use device. Results indicate that the swing-assist prosthesis increases maximum swing phase knee flexion angle relative to the subject’s daily-use device. Furthermore, the swing-assist prosthesis was shown to automatically vary its assistance across walking speeds.},
  archive      = {J_TMRB},
  author       = {Harrison Logan Bartlett and Shane T. King and Michael Goldfarb and Brian Edward Lawson},
  doi          = {10.1109/TMRB.2022.3161068},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {490-501},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design and assist-as-needed control of a lightly powered prosthetic knee},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Kinematic modeling of human forearm rotation with distal
radio-ulnar circumduction. <em>TMRB</em>, <em>4</em>(2), 480–489. (<a
href="https://doi.org/10.1109/TMRB.2022.3155292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A circumduction of the distal ulna as a complex movement has been observed at the distal radio-ulnar joint during forearm rotation and it has been reported that a stationary ulna makes postures of the hand to be transposed or tilted in the pro-supination. In this paper, a new forearm model reflecting the ulnar circumduction is proposed by changing the joint types of a spatial linkage mechanism. For this purpose, a conventional forearm model with R-R-U-S joint types (established by Whiteley in 2000) which generates the horizontal movement of the distal ulna is firstly analyzed to figure out a kinematic feature for its joint motions. And then this model is reconstructed as an equivalent model with R-R-U-U joints. At the same time, its joint types are realigned as U-R-U-R joints to realize the ulnar circumduction. Finally, a structural design based on the proposed forearm model with the U-R-U-R joints is presented, and its overall movements are described.},
  archive      = {J_TMRB},
  author       = {Dukchan Yoon and Minsang Seo and Youngjin Choi},
  doi          = {10.1109/TMRB.2022.3155292},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {480-489},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Kinematic modeling of human forearm rotation with distal radio-ulnar circumduction},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Metric learning for robust gait phase recognition for a
lower limb exoskeleton robot based on sEMG. <em>TMRB</em>,
<em>4</em>(2), 472–479. (<a
href="https://doi.org/10.1109/TMRB.2022.3166543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop a robust myoelectric control method for gait phase recognition in a lower-limb exoskeleton robot. In the proposed method, a metric learning-based temporal convolution network (ML-TCN) was utilized to extract discriminative features of the surface electromyography (sEMG) signals and recognize four gait phases: heel strike (HS), foot flat (FF), heel off (HO), and swing (SW). Vicon validated the effectiveness of the sEMG data-acquisition system. The proposed method acquires significantly more discriminative features than long short-term memory (LSTM) or common temporal convolutional network (TCN). The experimental results show that the proposed model has a higher prediction accuracy and stronger robustness against disturbances in complex terrain. Finally, under the complex terrain of level ground-ramp ascending-ramp descending walking, the proposed model’s accuracy of gait phase recognition is 96.22%, which is better than LSTM’s 91.20%. Noise disturbances of 10%, 20%, 30%, 40%, and 50% were added to the test set. Compared with LSTM, the resistance to disturbances of the proposed method increased by 8.15%, 8.79%, 9.67%, 10.6%, and 10.61%, respectively.},
  archive      = {J_TMRB},
  author       = {Jiaqing Liu and Can Wang and Bailin He and Pengbo Li and Xinyu Wu},
  doi          = {10.1109/TMRB.2022.3166543},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {472-479},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Metric learning for robust gait phase recognition for a lower limb exoskeleton robot based on sEMG},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mobile robot assisted gait monitoring and dynamic margin of
stability estimation. <em>TMRB</em>, <em>4</em>(2), 460–471. (<a
href="https://doi.org/10.1109/TMRB.2022.3162148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To assess balance control and fall risk, it is desirable to continuously monitor dynamic stability during walking tasks. Dynamic Margin of Stability (MoS) is widely recognized as a quantitative measure for human walking stability and gait balance strategies. We propose a mobile robot assisted gait monitoring system that precedes human subjects in overground walking. Real-time data from the RGB-D Kinect sensor on the robot are fused with measurement from pressure sensors and inertial measurement units in a pair of instrumented footwear, and Kalman filter based methods are developed to estimate MoS and spatiotemporal gait parameters in real time. Experimental results with 10 subjects are compared with those obtained by a gold-standard motion capture system. Results show that the proposed method achieves acceptable accuracy of MoS estimation and high accuracy for spatio-temporal gait parameters. Whereas existing works on MoS assessment use wearable sensors that can only provide offline analysis, our proposed system provides real time gait monitoring and MoS estimation that could potentially assess fall risk during walking in out-of-lab conditions.},
  archive      = {J_TMRB},
  author       = {Zhuo Chen and Huanghe Zhang and Antonia Zaferiou and Damiano Zanotto and Yi Guo},
  doi          = {10.1109/TMRB.2022.3162148},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {460-471},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Mobile robot assisted gait monitoring and dynamic margin of stability estimation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gravity balancing flexure spring mechanisms for shoulder
support in assistive orthoses. <em>TMRB</em>, <em>4</em>(2), 448–459.
(<a href="https://doi.org/10.1109/TMRB.2022.3155293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive shoulder supports show large potential for a wide range of applications, such as assisting activities of daily living and supporting work-related tasks. The rigid-link architecture used in currently available devices, however, may pose an obstacle to finding designs that offer low protrusion and close-to-body alignment. This study explores the use of mechanisms that employ a flexible element which connects the supported arm to an attachment at the back and acts as energy storage, transmission and part of the load bearing structure. Based on the synthesis method explained in this paper, a large scope investigation into possible flexure-based mechanism topologies is conducted. Thereby, many potential designs are discovered, which are presented, categorized and compared. Two promising designs are developed into prototypes, and are built and tested on a dedicated test bench. These two mechanisms reduce the necessary moment to lift the arm by more than 80 % throughout 85 % of the range of motion, while staying within 18 cm and 10 cm distance from the body, respectively. The study indicates that, due to its lower protrusion and interface loads, a design with a tapered flexure connecting the upper arm via a hinge to a spring-loaded slider at the back offers the most promising solution.},
  archive      = {J_TMRB},
  author       = {Martin Tschiersky and Edsko E. G. Hekman and Just L. Herder and Dannis M. Brouwer},
  doi          = {10.1109/TMRB.2022.3155293},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {448-459},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Gravity balancing flexure spring mechanisms for shoulder support in assistive orthoses},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Curve fitting-based dynamic path planning and tracking
control for flexible needle insertion. <em>TMRB</em>, <em>4</em>(2),
436–447. (<a href="https://doi.org/10.1109/TMRB.2022.3170945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Needle insertion is widely used in modern clinical practice, and flexible needles enable surgeons to adjust the needle insertion path to avoid obstacles and compensate for target drift. To increase the accuracy and safety of the needle insertion procedure, a path planning and tracking control method for flexible needle steering in dynamic environment is proposed in this paper. The path planning method is based on the artificial potential field algorithm and curve fitting algorithm, after several feasible paths with variant curvatures is obtained, they are furtherly optimized based on path length, obstacle clearance and control effort to select the best one. Simulations show that the proposed path planning method performs better than the current constant curvature method and the rapidly-exploring random tree (RRT) based method. By finely tuning the initial planned path, an intraoperative path replanning method is proposed, which are used to compensate for the drift of target and obstacles. Then to ensure the needle is inserted along the planned path, a tracking control method is adopted based on fuzzy logic algorithm. With the proposed intraoperative path planning and tracking control method, the robustness and accuracy of needle insertion in congested environment can be improved, and experiments also show that our proposed method achieves satisfactory insertion safety and targeting accuracy in dynamic environment. The obtained accuracy of 1.57 mm is sufficient for most clinical needle insertion applications.},
  archive      = {J_TMRB},
  author       = {Baoliang Zhao and Shiping Shao and Long Lei and Xiangwei Wang and Xiaojun Yang and Qiong Wang and Ying Hu},
  doi          = {10.1109/TMRB.2022.3170945},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {436-447},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Curve fitting-based dynamic path planning and tracking control for flexible needle insertion},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surgical procedure understanding, evaluation, and
interpretation: A dictionary factorization approach. <em>TMRB</em>,
<em>4</em>(2), 423–435. (<a
href="https://doi.org/10.1109/TMRB.2022.3170210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a novel machine learning-based technique to help surgical mentors assess surgical motion trajectories and corresponding surgical skills levels in surgical training programs. The proposed method is a variation of sparse coding and dictionary learning that is straightforward to optimize and produces approximate trajectory decomposition for structured tasks. Our approach is superior to existing stochastic or deep learning-based methods in terms of transparency of the model and interpretability of the results. We introduce a dual-sparse coding algorithm which encourages the elimination of redundant and unnecessary atoms and targets to reach the most informative dictionary, representing the most important temporal variations within a given surgical trajectory. Since surgical tool trajectories are time series signals, we further incorporate the idea of floating atoms along the temporal axis in trajectory analysis, which improves the model’s accuracy and prevents information loss in downstream tasks. Using JIGSAWS data set, we present preliminary results showing the feasibility of the proposed method for clustering and interpreting surgical trajectories in terms of user’s skills-related behaviors.},
  archive      = {J_TMRB},
  author       = {Abed Soleymani and Xingyu Li and Mahdi Tavakoli},
  doi          = {10.1109/TMRB.2022.3170210},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {423-435},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Surgical procedure understanding, evaluation, and interpretation: A dictionary factorization approach},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameter estimation and tracking of an expandable
cable-driven parallel mechanism for minimally invasive interventions.
<em>TMRB</em>, <em>4</em>(2), 414–422. (<a
href="https://doi.org/10.1109/TMRB.2022.3161065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional catheter-based procedures suffer from inaccurate device steering, and navigation limitations as the long and flexible devices are manipulated remotely from outside the patient body. A recently developed approach aims to overcome these limitations by using an expandable cable-driven parallel mechanism for local device manipulation and tracking relative to the anatomy. However, as the frame of this system is flexible and may be constrained by unknown anatomical constraints inside the patient body, accurate system identification is a key and critical step which would ultimately determine the accuracy in device steering and tracking. In this paper, we present an optimization approach to identify the parameters of an expandable cable-driven parallel mechanism deployed in an unknown environment, merely based on measurements of the cable length variations that would be available outside the patient body. We have verified and validated the proposed approach in terms of accuracy in the prediction of the frame shape and cable anchor locations, as well as its tracking accuracy. Both simulations and experimental studies have been performed, and we have demonstrated that the proposed method allows for rapid frame shape and anchor position estimation with unknown anatomical constraints and permits localized device tracking and steering with submillimeter accuracy.},
  archive      = {J_TMRB},
  author       = {Amaar Quadri and James Zhou and Alykhan Sewani and M. Ali Tavallaei},
  doi          = {10.1109/TMRB.2022.3161065},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {414-422},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Parameter estimation and tracking of an expandable cable-driven parallel mechanism for minimally invasive interventions},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An automatic path planning method of pedicle screw placement
based on preoperative CT images. <em>TMRB</em>, <em>4</em>(2), 403–413.
(<a href="https://doi.org/10.1109/TMRB.2022.3155288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to good fixation and obvious clinical advantages in the treatment of spinal diseases, pedicle screw technology is widely employed in spinal surgery. However, most screw placement paths are manually selected, which is a complicated and time-consuming process. Therefore, various kinds of spine surgery robots have been invented to assist during surgeries. An automatic path planning method of pedicle screw placement is proposed in this article. First, based on preoperative CT scans, the spine of the patient can be segmented and each individual vertebra is classified by using a trained deep learning network model. Additionally, a local coordinate system in every single vertebra is established according to its anatomical characteristics. Second, after analyzing the images to recognize the feature points, the pedicle region and route of screw placement are identified, which renders completion of the surgical path planning automatic. The experimental results show that 93% of the planning results can be directly applied in surgeries after surgeon evaluation. In addition to the improvement in accuracy, the whole algorithm does not rely on any human assistance. This fully automatic process greatly reduces the time required for surgical planning.},
  archive      = {J_TMRB},
  author       = {Xiaozhi Qi and Jin Meng and Meng Li and Yuanyuan Yang and Ying Hu and Bing Li and Jianwei Zhang and Wei Tian},
  doi          = {10.1109/TMRB.2022.3155288},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {403-413},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {An automatic path planning method of pedicle screw placement based on preoperative CT images},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting the timing of camera movements from the
kinematics of instruments in robotic-assisted surgery using artificial
neural networks. <em>TMRB</em>, <em>4</em>(2), 391–402. (<a
href="https://doi.org/10.1109/TMRB.2022.3156635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic surgeries offer many benefits, however do not allow for simultaneous control of the endoscopic camera and the surgical instruments. This leads to frequent interruptions as surgeons adjust their viewpoints. Autonomous camera control could help overcome this challenge. We propose a predictive approach for anticipating when camera movements will occur using artificial neural networks. We used kinematic data of surgical instruments from robotic surgical training. We split the data into segments, and labeled if each segment immediately preceded a camera movement or did not. Due to the large class imbalance, we trained an ensemble of networks on balanced sub-sets of the data. We found that the instruments’ kinematics can be used to predict when camera movements will occur, and evaluated the performance on different segment durations and ensemble sizes. We also studied how much in advance upcoming camera movements can be predicted, and found that predicting camera movements up to 0.5 s in advance led to only a small decrease in performance relative to predicting imminent camera movements. These results serve as a proof-of-concept for predicting the timing of camera movements in robotic surgeries and suggest that an autonomous camera controller for robotic surgeries may someday be feasible.},
  archive      = {J_TMRB},
  author       = {Hanna Kossowsky and Ilana Nisky},
  doi          = {10.1109/TMRB.2022.3156635},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {391-402},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Predicting the timing of camera movements from the kinematics of instruments in robotic-assisted surgery using artificial neural networks},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A weakly supervised framework for 2D/3D vascular
registration oriented to incomplete 2D blood vessels. <em>TMRB</em>,
<em>4</em>(2), 381–390. (<a
href="https://doi.org/10.1109/TMRB.2022.3171310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Registering preoperative 3D computed tomography (CT) to intraoperative 2D digital subtraction angiography (DSA) can complete the missing part of 2D vessels by 3D-2D projection, which is useful for the guidance of vascular interventional surgery. However, vessel excalation in DSAs remains hard for registration in clinical circumstances. To overcome this challenge, we proposed a weakly supervised 2D/3D vascular registration framework to improve the performance on DSAs with incomplete vessels. We combined a CNN regressor with a novel 3D-2D mask projection module to build the full network. Then a two-step training procedure is employed, including supervised pre-training on simulated images and weakly supervised finetuning on DSAs. In addition, a patch-based content loss is introduced in the finetuning step to give an appropriate similarity measure for images with incomplete vessels. We evaluated our method on both simulated and real images. Experiments prove that our proposed method is effective to improve the backbone regressor’s registration performance on incomplete vessels and has the ability to complete vessels in DSAs with high recall.},
  archive      = {J_TMRB},
  author       = {Cai Meng and Yanggang Li and Yizhou Xu and Ning Li and Kun Xia},
  doi          = {10.1109/TMRB.2022.3171310},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {381-390},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A weakly supervised framework for 2D/3D vascular registration oriented to incomplete 2D blood vessels},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Numerical calculation method for brain shift based on
hydrostatics and dynamic FEM. <em>TMRB</em>, <em>4</em>(2), 368–380. (<a
href="https://doi.org/10.1109/TMRB.2022.3168075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During neurosurgery, brain deformation occurs because of gravity and leakage of the cerebrospinal fluid (CSF), which is referred to as brain shift. Brain shift is a serious problem in neuronavigation because neuronavigation relies on preoperatively taken medical images. This paper presents a brain shift estimation method based on hydrostatics and dynamic FEM, assuming that gravity and leakage of CSF are the main reasons for brain shift. The accuracy of the proposed method was verified via basic experiments conducted using elastic gelatin cubes. In addition, a 3D brain model was created using preoperative medical images of a patient and brain shift estimation simulations were performed. Their accuracy was verified by comparing the simulation results with the actual brain shift during neurosurgery. Assuming that the node in the most anterior position of the frontal lobe and the node in the highest position of the parietal lobe before the brain shift respectively remain in the most anterior position and the highest position even after the brain shift, the corresponding regions before and after the brain shift were searched and the deformations were evaluated. In this error analysis, the maximum estimation error was 4.4 mm. Furthermore, a region of 40 mm $\times $ 30 mm in the frontal lobe was chosen as the region of interest (ROI), and the surface errors in the ROI between the intraoperative MRI images and the simulated shifted brain were analyzed. The mean absolute error (MAE) between the surfaces along the z-axis (the direction of gravity) in the ROI was 3.7 mm (maximum absolute error was 8.8 mm). The proposed method was sufficiently simple for computing the brain shift in real-time. The expected contribution of this study toward improving the neuronavigational error and enhancing the safety of neurosurgery will be beneficial for hospitals, especially when the intraoperative MRI cannot be performed.},
  archive      = {J_TMRB},
  author       = {Xiaoshuai Chen and Ryosuke Shirai and Ken Masamune and Manabu Tamura and Yoshihiro Muragaki and Kazuya Sase and Teppei Tsujita and Atsushi Konno},
  doi          = {10.1109/TMRB.2022.3168075},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {368-380},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Numerical calculation method for brain shift based on hydrostatics and dynamic FEM},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmented reality-assisted autonomous view adjustment of a
6-DOF robotic stereo flexible endoscope. <em>TMRB</em>, <em>4</em>(2),
356–367. (<a href="https://doi.org/10.1109/TMRB.2022.3155254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo visual servo based surgical instruments tracking enables quicker adjustment of the view and depth of the robotic stereo flexible endoscope (RSFE). However, there are two main drawbacks: 1) when the lesion is covered by organs, the observation angles, from which the endoscope observes it, need to be adjusted independently. But this cannot be achieved by only tracking surgical instruments; 2) the field of view is restricted by the shared area of the two cameras, which limits the tracking area. Therefore, a 6-DOF augmented reality visualizing robotic stereo flexible endoscope (ARSFE), which integrates a pair of HoloLens with the RSFE, is proposed. The Hololens is used for tracking the surgeon’s head and providing head-mounted display. In the ARSFE, the endoscope can be controlled in two modes: 1) The view and depth of the endoscope can be controlled by tracking surgical instruments; 2) The observation angles can be adjusted independently by tracking the surgeon’s head. Modes switching is realized via the foot pedals. Besides, a hybrid control method for tracking instruments is proposed, which significantly enlarges the control field for instruments tracking. In the experiment section, the performance of the proposed hybrid visual servoing control and the ARSFE is verified.},
  archive      = {J_TMRB},
  author       = {Xin Ma and Chengzhi Song and Long Qian and Weixiao Liu and Philip Waiyan Chiu and Zheng Li},
  doi          = {10.1109/TMRB.2022.3155254},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {356-367},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Augmented reality-assisted autonomous view adjustment of a 6-DOF robotic stereo flexible endoscope},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning-based control framework for
multilateral telesurgery. <em>TMRB</em>, <em>4</em>(2), 352–355. (<a
href="https://doi.org/10.1109/TMRB.2022.3170786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The upper boundary of time delay is often required in traditional telesurgery control design, which would result in infeasibility of telesurgery across regions. To overcome this issue, this paper introduces a new control framework based on deep deterministic policy gradient (DDPG) reinforcement learning (RL) algorithm. The developed framework effectively overcomes the phase difference and data loss caused by time delays, which facilitates the restoration of surgeon’s intention and interactive force. Kalman filter (KF) is employed to blend multiple surgeons’ commands and predict the final local commands, respectively. The control framework ensures synchronization tracking performance and transparency. Prior knowledge of time delay is therefore not required. Simulation and experiment results have demonstrated the merits of the proposed framework.},
  archive      = {J_TMRB},
  author       = {Sarah Chams Bacha and Weibang Bai and Ziwei Wang and Bo Xiao and Eric M. Yeatman},
  doi          = {10.1109/TMRB.2022.3170786},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {352-355},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Deep reinforcement learning-based control framework for multilateral telesurgery},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identification of multiple limbs coordination strategies in
a three-goal independent task. <em>TMRB</em>, <em>4</em>(2), 348–351.
(<a href="https://doi.org/10.1109/TMRB.2021.3124263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many surgical tasks require three or more tools operating together. A supernumerary robotic arm under the surgeon’s control could enable one surgeon to control three surgical tools simultaneously without assistance, thereby avoiding the common communication errors of the operation room. However, how do humans consider the complexity of controlling more than two arms together? In this paper, the coordination strategy used during three limb independent motion tasks is studied. The level of coordination increased over a two-day pilot study, and the resulting coordination pattern was in general consistent within subjects. Whether the subject used a fixed order of targets or a random sequence was found to reduce the improvement of pattern consistency after practice. The foot-controlled third hand exhibited less consistent patterns.},
  archive      = {J_TMRB},
  author       = {Yanpei Huang and Ekaterina Ivanova and Jonathan Eden and Etienne Burdet},
  doi          = {10.1109/TMRB.2021.3124263},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {348-351},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Identification of multiple limbs coordination strategies in a three-goal independent task},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of an optical shape sensing method using
optoelectronic sensors for soft flexible robotic manipulators in MIS.
<em>TMRB</em>, <em>4</em>(2), 343–347. (<a
href="https://doi.org/10.1109/TMRB.2022.3155200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the novel design of an optical shape sensing method using optoelectronic sensors, for integration into flexible soft robotic manipulators, to measure pose in two orientations. Shape sensing in soft robotic tools that allow stable and accurate position control in Minimally Invasive Surgery is critical, although innovations are yet to be explored in a simple, cost-effective sensing technique. Presented in this work is a continuation of the work of Koh et al. (2019), with demonstration of the use of a designed 4-plate tendon-actuated flexible manipulator and optimised design parameters for the sensing principle. Developed calibration platform shows an increase in accuracy for shape sensing using linear and non-linear regression models. Further development is required on miniaturisation to refine accuracy and targeted application.},
  archive      = {J_TMRB},
  author       = {Dalia Osman and Xinli Du and Wanlin Li and Yohan Noh},
  doi          = {10.1109/TMRB.2022.3155200},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {343-347},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of an optical shape sensing method using optoelectronic sensors for soft flexible robotic manipulators in MIS},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Task-based LSTM kinematic modeling for a tendon-driven
flexible surgical robot. <em>TMRB</em>, <em>4</em>(2), 339–342. (<a
href="https://doi.org/10.1109/TMRB.2021.3127366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon-driven flexible surgical robots are normally suffering from the inaccurate modeling and imprecise motion control problems due to the nonlinearities of tendon transmission. Learning-based approaches are experimental data-driven with uncertainties modeled empirically, which can be adopted to improve the inevitable issues. This work proposes a LSTM-based kinematic modeling approach with task-based data for a flexible tendon-driven surgical robot to improve the control accuracy. Real experiments demonstrated the effectiveness and superiority of the proposed learned model when completing path following tasks, especially compared to the traditional modeling.},
  archive      = {J_TMRB},
  author       = {Weibang Bai and Francesco Cursi and Xiaotong Guo and Baoru Huang and Benny Lo and Guang-Zhong Yang and Eric M. Yeatman},
  doi          = {10.1109/TMRB.2021.3127366},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {339-342},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Task-based LSTM kinematic modeling for a tendon-driven flexible surgical robot},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous depth estimation and surgical tool segmentation
in laparoscopic images. <em>TMRB</em>, <em>4</em>(2), 335–338. (<a
href="https://doi.org/10.1109/TMRB.2022.3170215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical instrument segmentation and depth estimation are crucial steps to improve autonomy in robotic surgery. Most recent works treat these problems separately, making the deployment challenging. In this paper, we propose a unified framework for depth estimation and surgical tool segmentation in laparoscopic images. The network has an encoder-decoder architecture and comprises two branches for simultaneously performing depth estimation and segmentation. To train the network end to end, we propose a new multi-task loss function that effectively learns to estimate depth in an unsupervised manner, while requiring only semi-ground truth for surgical tool segmentation. We conducted extensive experiments on different datasets to validate these findings. The results showed that the end-to-end network successfully improved the state-of-the-art for both tasks while reducing the complexity during their deployment.},
  archive      = {J_TMRB},
  author       = {Baoru Huang and Anh Nguyen and Siyao Wang and Ziyang Wang and Erik Mayer and David Tuch and Kunal Vyas and Stamatia Giannarou and Daniel S. Elson},
  doi          = {10.1109/TMRB.2022.3170215},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {335-338},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Simultaneous depth estimation and surgical tool segmentation in laparoscopic images},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised monocular depth estimation with 3-d
displacement module for laparoscopic images. <em>TMRB</em>,
<em>4</em>(2), 331–334. (<a
href="https://doi.org/10.1109/TMRB.2022.3170206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel self-supervised training framework with 3D displacement (3DD) module for accurately estimating per-pixel depth maps from single laparoscopic images. Recently, several self-supervised learning based monocular depth estimation models have achieved good results on the KITTI dataset, under the hypothesis that the camera is dynamic and the objects are stationary, however this hypothesis is often reversed in the surgical setting (laparoscope is stationary, the surgical instruments and tissues are dynamic). Therefore, a 3DD module is proposed to establish the relation between frames instead of ego-motion estimation. In the 3DD module, a convolutional neural network (CNN) analyses source and target frames to predict the 3D displacement of a 3D point cloud from a target frame to a source frame in the coordinates of the camera. Since it is difficult to constrain the depth displacement from two 2D images, a novel depth consistency module is proposed to maintain depth consistency between displacement-updated depth and model-estimated depth to constrain 3D displacement effectively. Our proposed method achieves remarkable performance for monocular depth estimation on the Hamlyn surgical dataset and acquired ground truth depth maps, outperforming monodepth, monodepth2 and packnet models.},
  archive      = {J_TMRB},
  author       = {Chi Xu and Baoru Huang and Daniel S. Elson},
  doi          = {10.1109/TMRB.2022.3170206},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {331-334},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Self-supervised monocular depth estimation with 3-D displacement module for laparoscopic images},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cortical vessel segmentation for neuronavigation using
vesselness-enforced deep neural networks. <em>TMRB</em>, <em>4</em>(2),
327–330. (<a href="https://doi.org/10.1109/TMRB.2021.3122337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose in this paper an efficient method to segment cortical vessels in craniotomy images acquired by the surgical microscope. Our method uses a vesselness-enforced convolutional neural network to classify each pixel of a craniotomy image as a vessel or surrounding tissue. This permits training the network not only on appearance-based features but also on geometrical-based constraints that will ensure the continuity of the vascular trees. Our solution uses neural style transfer to generate new instances of images from manually labeled data leading to augment the training dataset in an anatomically semantic manner. The generated images improve the generalization of our model to various types of cortical surface appearances and vascular geometries. We conducted experiments on real images from human patients that demonstrate that accurate intraoperative cortical vessel segmentation can be achieved.},
  archive      = {J_TMRB},
  author       = {Nazim Haouchine and Michael Nercessian and Parikshit Juvekar and Alexandra Golby and Sarah Frisken},
  doi          = {10.1109/TMRB.2021.3122337},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {327-330},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Cortical vessel segmentation for neuronavigation using vesselness-enforced deep neural networks},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PROST-net: A deep learning approach to support real-time
fusion in prostate biopsy. <em>TMRB</em>, <em>4</em>(2), 323–326. (<a
href="https://doi.org/10.1109/TMRB.2022.3145667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate biopsy fusion systems employ manual segmentation of the prostate before the procedure, therefore the image registration is static. To pave the way for dynamic fusion, we introduce PROST-Net, a deep learning (DL) based method to segment the prostate in real-time. The algorithm works in three steps: firstly, it detects the presence of the prostate, secondly defines a region of interest around it, discharging other pixels of the image before the last step which is the segmentation. This approach reduces the amount of data to be processed during segmentation and allows to contour the prostate regardless of the image modality (e.g., magnetic resonance (MRI) or ultrasound (US)) and, in the case of US, regardless of the geometric disposition of the sensor array (e.g., linear or convex). PROST-Net produced a mean Dice similarity coefficient of 86% in US images and 77% in MRI images and outperformed other CNN-based techniques. PROST-Net is integrated in a robotic system–PROST– for trans-perineal fusion biopsy. The robot with PROST-Net gives the potential to track the prostate in real-time, thus reducing human errors during the biopsy procedure.},
  archive      = {J_TMRB},
  author       = {Luigi Palladino and Bogdan Maris and Alessandro Antonelli and Paolo Fiorini},
  doi          = {10.1109/TMRB.2022.3145667},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {323-326},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {PROST-net: A deep learning approach to support real-time fusion in prostate biopsy},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preclinical validation of a semi-autonomous robot for
transperineal prostate biopsy. <em>TMRB</em>, <em>4</em>(2), 311–322.
(<a href="https://doi.org/10.1109/TMRB.2022.3159737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate biopsy is a manual procedure carried out mostly under ultrasound (US) guidance to confirm the presence of cancer. The standard biopsy is random and includes at least 12 insertions; targeted biopsy makes use of dedicated hardware and software, but is still performed manually. We present here the pre-clinical validation of PROST, a robot primarily designed to automate targeted transperineal biopsy. The overall validation of the system was performed on cadavers, while some features, such as image segmentation, were tested on human tissue. PROST is designed to minimize human error by introducing some autonomy in the execution of key steps of the procedure, i.e., target selection, image fusion and needle positioning. The protocol was approved by the ethics committee; 10 cadavers were included in the study. We envision that PROST has the potential to increase the detection of clinically significant prostate cancer, to simplify the procedure, to reduce human errors and to shorten training time. The use of a robot for the biopsy of the prostate will create the possibility to include also a treatment, such as focal ablation, to be delivered through the same system.},
  archive      = {J_TMRB},
  author       = {Bogdan Maris and Maria-Camilla Fiazza and Michela De Piccoli and Chiara Tenga and Luigi Palladino and Stefano Puliatti and Andrea Iseppi and Riccardo Ferrari and Adele Piro and Luca Reggiani Bonetti and Guido Ligabue and Alessandro Tafuri and Salvatore Micali and Paolo Fiorini},
  doi          = {10.1109/TMRB.2022.3159737},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {311-322},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Preclinical validation of a semi-autonomous robot for transperineal prostate biopsy},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A bio-inspired active prostate phantom for adaptive
interventions. <em>TMRB</em>, <em>4</em>(2), 300–310. (<a
href="https://doi.org/10.1109/TMRB.2021.3123385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel concept for a phantom of the prostate is introduced. To study and improve automated, robotized medical interventions, reliable phantoms are essential. During brachytherapy and biopsy, the prostate will undergo displacements and changes in orientation due to the needle insertion. Therefore, there is a shift in the target regions for radioactive seed deposition or biopsy acquisition. These shifts need to be taken into account for precise dosimetry. Furthermore, the organ can undergo deformations due to edemas causing further spatial changes in the target structure. Therefore, in this paper, we propose a bio-inspired phantom (BIP) for the prostate that is equipped with sensors and coupled with a numerical simulation for estimating deformations due to external forces. There is also a cavity within the phantom where pressure can be applied to simulate prostate growth due to inflammation. The phantom has been conceived to be MRI-safe. It can thus be deployed for the in-bore study of automated brachytherapy and biopsy. In our evaluation, we verify that changes in position of the phantom target can be correctly estimated and that these motions are plausible from a clinical point of view.},
  archive      = {J_TMRB},
  author       = {Stefan Escaida Navarro and Sepaldeep Singh Dhaliwal and Mario Sanz Lopez and Sarah Wilby and Antony L. Palmer and Wojciech Polak and Rochdi Merzouki and Christian Duriez},
  doi          = {10.1109/TMRB.2021.3123385},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {300-310},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A bio-inspired active prostate phantom for adaptive interventions},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From bench to bedside. <em>TMRB</em>, <em>4</em>(2),
297–299. (<a href="https://doi.org/10.1109/TMRB.2022.3172013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The IEEE Transactions on Medical Robotics and Bionics (T-MRB) is an initiative shared by the two IEEE Societies of Robotics and Automation – RAS – and Engineering in Medicine and Biology – EMBS.},
  archive      = {J_TMRB},
  author       = {Alberto Arezzo and Maarja Kruusmaa and George Mylonas},
  doi          = {10.1109/TMRB.2022.3172013},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {297-299},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {From bench to bedside},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). IEEE robotics and automation society information.
<em>TMRB</em>, <em>4</em>(1), C3. (<a
href="https://doi.org/10.1109/TMRB.2022.3141924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.},
  archive      = {J_TMRB},
  doi          = {10.1109/TMRB.2022.3141924},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {C3},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {IEEE robotics and automation society information},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Influence of electrode positions on performance of hand
motion capture using EIT. <em>TMRB</em>, <em>4</em>(1), 285–288. (<a
href="https://doi.org/10.1109/TMRB.2021.3125321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports the influence of electrode positions on the performance of hand motion capture conducted by using an electrical impedance tomography (EIT) device. We developed a simulator using a linear elastic and conductive model of the forearm and evaluated the sensitivity and redundancy of the EIT signals for various electrode configurations. The results of the simulation indicated that electrode positions affect the sensitivity and redundancy; specifically, the placement of grounding and sensing electrodes on the anterior side with high density has twice the sensitivity of the equally spaced placement. Furthermore, results of the subjective experiment where 1 healthy male participated matched the simulation results and suggested that the two-row electrode placement on the anterior side with high density has high sensitivity. These findings are useful for future accurate hand motion capture using an EIT device.},
  archive      = {J_TMRB},
  author       = {Shunsuke Yoshimoto and Yumi Toyoda and Akio Yamamoto},
  doi          = {10.1109/TMRB.2021.3125321},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {285-288},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Influence of electrode positions on performance of hand motion capture using EIT},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intuitive environmental perception assistance for blind
amputees using spatial audio rendering. <em>TMRB</em>, <em>4</em>(1),
274–284. (<a href="https://doi.org/10.1109/TMRB.2022.3146743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision and touch are essential sensory systems for human to interact with the environment. For the blind amputees, how to quickly and intuitively convey the environmental information to them is one of the key issues for recovering their daily living ability. Inspired by the auditory localization ability of human, we constructed a virtual scene almost identical to reality, and concurrently added a virtual sound source to the interactive object. Leveraging the method of spatial audio rendering (SAR), the three-dimensional motion of the virtual sound source can be vividly simulated in real-time. Finally, a myoelectric prosthetic control system was developed to assist blind amputees in their daily activities, The Fitts’ law test on target localization was conducted on both SAR and voice prompt (VP) based path guidance methods, the results indicate that SAR significantly improves the information transfer rate. The results of prosthetic control test show that SAR reduces the completion time by half than the VP, while restoring the natural grasping path. With the advantage of intuitive and rich perception, the SAR demonstrated the potential applications for blind amputees to reconstruct the control and sensory loops.},
  archive      = {J_TMRB},
  author       = {Xuhui Hu and Aiguo Song and Hong Zeng and Dapeng Chen},
  doi          = {10.1109/TMRB.2022.3146743},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {274-284},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Intuitive environmental perception assistance for blind amputees using spatial audio rendering},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TinyLFP: A tiny local-field-potential sensor. <em>TMRB</em>,
<em>4</em>(1), 266–273. (<a
href="https://doi.org/10.1109/TMRB.2022.3145650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient acquisition and analysis of neural signals play a significant role in enhancing our understanding of the brain function and its abnormalities. Neural interfaces involve electrodes inserted into the brain tissues, and also hardware circuits and software to record neural activities and analyze them. Local field potentials (LFPs) are the low frequency neural signals recorded invasively capturing the dynamic extracellular neuronal activities. The information on different bands of neural oscillations (alpha, beta, theta, and gamma) in LFP signals has been used to determine brain abnormalities. LFP signals contain components with amplitudes in the range of 10- $100 ~\mu \text{V}$ , which are small and can be easily distorted by external noise sources. With the advancements in closed-loop brain stimulation paradigms, there is a need for miniaturized sensors to capture and monitor LFP signals. The sensed LFP signals can then be used to close the feedback loop in a control system to adjust stimulation parameters in a closed-loop brain stimulation device. A LFP sensor requires a low power circuit to ensure prolonged operation. In addition, an area-efficient and low-noise front end stage needs to be formed. Considering these requirements, a single-channel, power-efficient, low-noise, compact neural sensor for acquisition of LFP signals is presented. The miniaturized LFP sensor, named TinyLFP, has a low-noise first stage instrumentation amplifier for providing a pre-amplification of 100 V/V, a band pass filter with a pass band of 4–200 Hz, and a post amplifier stage with an amplification factor of 200 V/V. Overall, the device provides a gain of around 85 dB for the signals in the range of 4 to 200 Hz to be used as the first stage of a closed loop optogenetic brain stimulation device.},
  archive      = {J_TMRB},
  author       = {Lekshmy Sudha Kumari and Abbas Z. Kouzani},
  doi          = {10.1109/TMRB.2022.3145650},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {266-273},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {TinyLFP: A tiny local-field-potential sensor},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simulation of spinal muscle control in human gait using
OpenSim. <em>TMRB</em>, <em>4</em>(1), 254–265. (<a
href="https://doi.org/10.1109/TMRB.2022.3143263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a neuro-musculoskeletal simulation approach to human gait based on an original model of central pattern generator and the muscle synergy approach. The controller, shown here, aims at simplifying movement control by reducing the number of parameters to optimize. The model of the simplified motor coordination chain was built, from the midbrain through spinal neurons to the muscles allowing of simulating some neural and muscular values of gait, hard to obtain otherwise. The work also includes a bio-inspired reflex-based balance controller designed from knowledge of spinal gait. The used anatomic musculoskeletal model has been implemented in OpenSim platform. Time simulations show the ability of the platform to be able to produce different gait patterns including nominal and disturbed. Both gaits are controlled by the same bio-inspired closed-loop CPG- and reflex-based circuitries. After 2 second standing phase, the model was able to walk for about 5 meters with 10 steps. 2 steps were disrupted in the second simulation.},
  archive      = {J_TMRB},
  author       = {Andrii Shachykov and Julien Frère and Patrick Hénaff},
  doi          = {10.1109/TMRB.2022.3143263},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {254-265},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Simulation of spinal muscle control in human gait using OpenSim},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning a generic olfactory search strategy from silk moths
by deep inverse reinforcement learning. <em>TMRB</em>, <em>4</em>(1),
241–253. (<a href="https://doi.org/10.1109/TMRB.2021.3129113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their simple nervous systems, insects efficiently search for and find sources of odorants. Hence, it is necessary to model and implement such behavior in artificial agents (robots), to enable them to detect dangerous substances such as drugs, gas leaks, and explosives. Previous studies have approached behavioral modeling with either statistical or machine-learning methods. In this study, we determined the behavior trajectories of male silk moths using a virtual reality (VR) system. We then modeled these trajectories as a Markov decision process (MDP) and employed inverse reinforcement learning (IRL) to learn their reward function. Furthermore, we estimated the optimal policy from the learned reward function. We then conducted olfactory search simulations and determined that the IRL-based policy could locate odor sources with a high success rate. This was also investigated under environmental conditions different from those faced by real moths on the VR system. The obtained results indicate that IRL can generically represent olfactory search strategies that are adaptable to various environments.},
  archive      = {J_TMRB},
  author       = {Cesar Hernandez-Reyes and Shunsuke Shigaki and Mayu Yamada and Takeshi Kondo and Daisuke Kurabayashi},
  doi          = {10.1109/TMRB.2021.3129113},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {241-253},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Learning a generic olfactory search strategy from silk moths by deep inverse reinforcement learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simulated performance of an energy storage and return
prosthetic ankle based on cams and miniature hydraulics. <em>TMRB</em>,
<em>4</em>(1), 230–240. (<a
href="https://doi.org/10.1109/TMRB.2022.3146628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prosthetic feet are limited in their ability to mimic the energy-recycling behavior of an intact ankle, negatively affecting lower-limb amputees’ gait in terms of metabolic cost and walking speed. To overcome these weaknesses, a novel prosthetic ankle based on hydraulics is described here. The ankle joint drives two cams, which in turn drive two hydraulic rams. One cam-ram system captures the negative work done from foot-flat until maximum dorsiflexion, by pumping oil into an accumulator, while the other returns positive work during push-off providing forward propulsion through fluid flowing from the accumulator to the ram. Simulation results are promising: of the total negative work done by the prosthetic ankle over the gait cycle (i.e., the maximum amount of energy available to be stored), 78% is returned, mainly during push-off; 14% is carried forward for future gait cycles; and 8% is lost. The estimated prosthesis height and mass are approximately ${26}.{5} {cm}$ and ${2}.{3} {kg}$ . Nonetheless, further work is necessary to realise a prototype for bench and in-vivo testing. By mimicking intact ankle torque and efficiently storing and returning energy at the ankle joint, this new design may contribute to reducing amputees’ metabolic cost of walking.},
  archive      = {J_TMRB},
  author       = {Anna Pace and James Gardiner and Laurence Kenney and David Howard},
  doi          = {10.1109/TMRB.2022.3146628},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {230-240},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Simulated performance of an energy storage and return prosthetic ankle based on cams and miniature hydraulics},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subject-independent, biological hip moment estimation during
multimodal overground ambulation using deep learning. <em>TMRB</em>,
<em>4</em>(1), 219–229. (<a
href="https://doi.org/10.1109/TMRB.2022.3144025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating biological joint moments using wearable sensors could enable out-of-lab biomechanical analyses and exoskeletons that assist throughout daily life. To realize these possibilities, this study introduced a subject-independent hip moment estimator using a temporal convolutional network (TCN) and validated its performance and generalizability during multimodal ambulation. Electrogoniometer and simulated IMU data from sixteen participants walking on level ground, ramps and stairs were used to evaluate our approach when benchmarked against a fully-connected neural network, a long short-term memory network, and a baseline method (i.e., using subject-average moment curves based on ambulation mode and gait phase). Additionally, the generalizability of our approach was evaluated by testing on ground slopes, stair heights, and gait transitions withheld during model training. The TCN outperformed the benchmark approaches on the hold-out data (p &lt; 0.05), with an average RMSE of 0.131±0.018 Nm/kg and R2 of 0.880±0.030 during steady-state ambulation. When tested on the 20 leave-one-out slope and stair height conditions, the TCN significantly increased RMSE only on the steepest (+18°) incline (p &lt; 0.05). Finally, the TCN RMSE and R2 was 0.152±0.027 Nm/kg and 0.786±0.055, respectively, during mode transitions. Thus, our approach accurately estimated hip moments and generalized to unseen gait contexts using data from three wearable sensors.},
  archive      = {J_TMRB},
  author       = {Dean D. Molinaro and Inseung Kang and Jonathan Camargo and Matthew C. Gombolay and Aaron J. Young},
  doi          = {10.1109/TMRB.2022.3144025},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {219-229},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Subject-independent, biological hip moment estimation during multimodal overground ambulation using deep learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic parameter identification of a human-exoskeleton
system with the motor torque data. <em>TMRB</em>, <em>4</em>(1),
206–218. (<a href="https://doi.org/10.1109/TMRB.2021.3137970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this paper is to identify dynamic parameters of the human-exoskeleton system (HES) with the motor torque data considering modeling the passive elastic joint torque of the user. Based on a lower limb exoskeleton prototype we recently developed, the dynamics of the joint actuators and two degrees of freedom link-based swing leg are firstly modeled. The passive elasticity of the human joint is modeled by double-exponential equations. Systematic experiments are then conducted, during which the motor current is measured to compute the motor torque for identification. Finally, the dynamic parameters of the joint actuators, the exoskeleton leg and the human-exoskeleton leg are successively identified. The identification is implemented through the off-line inverse dynamic model simulation with the measured motor torque data. A consistent tendency is found between the simulated motor torque after identification and the measured one. This demonstrates the validity of the identification method proposed. This paper provides a systemic method of identifying the HES with the motor torque data and enriches the experimental proof that the double-exponential model is feasible to describe the passive elastic joint torque.},
  archive      = {J_TMRB},
  author       = {Yinbo Li and Xinyu Guan and Wei Li and Bernhard Penzlin and Kaiqi Liu and Ze Yang and Bing Liu and Steffen Leonhardt and Linhong Ji},
  doi          = {10.1109/TMRB.2021.3137970},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {206-218},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Dynamic parameter identification of a human-exoskeleton system with the motor torque data},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shaping individualized impedance landscapes for gait
training via reinforcement learning. <em>TMRB</em>, <em>4</em>(1),
194–205. (<a href="https://doi.org/10.1109/TMRB.2021.3137971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assist-as-needed (AAN) control aims at promoting therapeutic outcomes in robot-assisted rehabilitation by encouraging patients’ active participation. Impedance control is used by most AAN controllers to create a compliant force field around a target motion to ensure tracking accuracy while allowing moderate kinematic errors. However, since the parameters governing the shape of the force field are often tuned manually or adapted online based on simplistic assumptions about subjects’ learning abilities, the effectiveness of conventional AAN controllers may be limited. In this work, we propose a novel adaptive AAN controller that is capable of autonomously reshaping the force field in a phase-dependent manner according to each individual’s motor abilities and task requirements. The proposed controller consists of a modified Policy Improvement with Path Integral algorithm, a model-free, sampling-based reinforcement learning method that learns a subject-specific impedance landscape in real-time, and a hierarchical policy parameter evaluation structure that embeds the AAN paradigm by specifying performance-driven learning goals. The adaptability of the proposed control strategy to subjects’ motor responses and its ability to promote short-term motor adaptations are experimentally validated through treadmill training sessions with able-bodied subjects who learned altered gait patterns with the assistance of a powered ankle-foot orthosis.},
  archive      = {J_TMRB},
  author       = {Yufeng Zhang and Shuai Li and Karen J. Nolan and Damiano Zanotto},
  doi          = {10.1109/TMRB.2021.3137971},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {194-205},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Shaping individualized impedance landscapes for gait training via reinforcement learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of the x-perce—a universal FBG-based force
sensing kit for laparoscopic surgical robot. <em>TMRB</em>,
<em>4</em>(1), 183–193. (<a
href="https://doi.org/10.1109/TMRB.2022.3145618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For surgical robot, an independent contact sensing system can always provide intuitive operation reference in parallel to non-contact information. As one of them, force sensing system developed based on fiber Bragg grating sensor (FBGs) has been at the forefront of gaining force information from surgical device in the past decade. Application span from vitrectomy, cerebral surgery to cardiac ablation yet still rarely seen in laparoscopic surgery. In this paper, we present the development of the X-Perce—a force sensing kit that can be universally deployed on the laparoscopic surgical robot. By the design of a 3D-printed biocompatible joint combining with six FBGs layout, the proposed kit is able to perform tri-axial force sensing with temperature compensation and dual-thread mechanism. Modular design and standardized integration process are able to reduce the cost of manufacture, which allow the X-Perce to be consumable and commercial. Optimization based on mechanical modelling is implemented to enhance the system performance. Testing and evaluation is conducted to assess the resolution, static indexes and tracking performance of the prototype. Overall, we provide here a mechanical force sensing solution for the instrument that can be integrated on the Da-Vinci-like laparoscopic robotic system, along with a complete design paradigm for FBG sensing system alike.},
  archive      = {J_TMRB},
  author       = {Chengjin Du and Dehao Wei and Han Wang and Weidong Wang and Jian Dong and Haitao Huo and Yingtian Li},
  doi          = {10.1109/TMRB.2022.3145618},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {183-193},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of the X-Perce—A universal FBG-based force sensing kit for laparoscopic surgical robot},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A surgical robotic system for long-bone fracture alignment:
Prototyping and cadaver study. <em>TMRB</em>, <em>4</em>(1), 172–182.
(<a href="https://doi.org/10.1109/TMRB.2021.3129277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design, develop, and validate a surgical robotic system, entitled Robossis, to assist long-bone fracture reduction, i.e., alignment, surgeries. Unlike traditional long-bone fracture surgeries, Robossis enables the surgeon to precisely align the fractured bone in the presence of large traction forces and torques. The proposed surgical system includes a novel 3-armed robot, a bone-gripping mechanism, and a master controller. The 6-DOF 3-armed wide-open parallel robot has a unique architecture, which facilitates positioning the bone inside the robot, providing a large workspace for surgical maneuvers. Kinematic analysis shows that the symmetric 3-armed mechanism provides a significant advantage over the Gough-Stewart platform, i.e., 15 times larger rotational workspace, which is a vital advantage for fracture alignment. Theoretical and experimental testing are performed to demonstrate Robossis performance, including high accuracy and force insertion capabilities. A successful cadaver test was performed using a Robossis prototype, which shows that guided by intraoperative X-ray imaging, Robossis is able to manipulate bone in all translational and rotational directions while encountering the muscle payload surrounding the femur. Robossis is designed to balance accuracy, payload, and workspace, and its innovative design presents major advantages over the existing robot designs for the reduction of long-bone fractures.},
  archive      = {J_TMRB},
  author       = {Marzieh S. Saeedi-Hosseiny and Fayez Alruwaili and Sean McMillan and Iulian Iordachita and Mohammad H. Abedin-Nasab},
  doi          = {10.1109/TMRB.2021.3129277},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {172-182},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A surgical robotic system for long-bone fracture alignment: Prototyping and cadaver study},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Autonomous coordinated control of the light guide for
positioning in vitreoretinal surgery. <em>TMRB</em>, <em>4</em>(1),
156–171. (<a href="https://doi.org/10.1109/TMRB.2022.3147033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vitreoretinal surgery is challenging even for expert surgeons owing to the delicate target tissues and the diminutive workspace in the retina. In addition to improved dexterity and accuracy, robot assistance allows for (partial) task automation. In this work, we propose a strategy to automate the motion of the light guide with respect to the surgical instrument. This automation allows the instrument’s shadow to always be inside the microscopic view, which is an important cue for the accurate positioning of the instrument in the retina. We show simulations and experiments demonstrating that the proposed strategy is effective in a 700-point grid in the retina of a surgical phantom. Furthermore, we integrated the proposed strategy with image processing and succeeded in positioning the surgical instrument’s tip in the retina, relying on only the robot’s geometric information and microscopic images.},
  archive      = {J_TMRB},
  author       = {Yuki Koyama and Murilo M. Marinho and Mamoru Mitsuishi and Kanako Harada},
  doi          = {10.1109/TMRB.2022.3147033},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {156-171},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Autonomous coordinated control of the light guide for positioning in vitreoretinal surgery},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Development of a distal tri-axial force sensor for minimally
invasive surgical palpation. <em>TMRB</em>, <em>4</em>(1), 145–155. (<a
href="https://doi.org/10.1109/TMRB.2022.3142361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current study highlights the development of a novel and high-accuracy Fiber Bragg Grating (FBG)-enabled tri-axial distal force sensor for minimally invasive surgical palpation. This tri-axial sensor designs the primary flexure/elastomer consisting of axial and radial force-sensitive structures in a serial configuration, based on the method of freedom and constraint topology (FACT) from the perspective of the mechanism. This method provides general guidelines for designing multi-dimensional sensor design, achieving excellent sensitivity and a large measurement range, depressing crosstalks and couplings among different axes, and keeping the sensitivity of the three directions at the same order of magnitude. Five tightly suspended optical fibers embedded with one FBG element each have been assembled with the proposed flexure. They are configured with one arranged at the axial flexure’s central line and four distributed along the circumference of the radial flexure. This tight suspension configuration generates uniform and constant strain distribution on the FBG element, thus improving resolution and repeatability and further avoiding FBG chirping. Finite element modeling (FEM)-based simulation has been conducted for performance investigation and design optimization to improve the sensor sensitivity. Static calibration experiments and in-vitro and ex-vivo palpation experiments have been performed to investigate the proposed design’s performances and feasibility. The optimized sensor prototype achieves excellent resolution values of 1.18mN and 1.81mN in the x- and y-directions within [−5N, 5N], and 2.61mN in the z-direction within [0, 5N], realizing the same order of sensitivity magnitude at each axis.},
  archive      = {J_TMRB},
  author       = {Zhongxin Tang and Shuxin Wang and Ming Li and Chaoyang Shi},
  doi          = {10.1109/TMRB.2022.3142361},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {145-155},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of a distal tri-axial force sensor for minimally invasive surgical palpation},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image-guided navigation of a robotic ultrasound probe for
autonomous spinal sonography using a shadow-aware dual-agent framework.
<em>TMRB</em>, <em>4</em>(1), 130–144. (<a
href="https://doi.org/10.1109/TMRB.2021.3127015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound (US) imaging is commonly used to assist in the diagnosis and interventions of spine diseases, while the standardized US acquisitions performed by manually operating the probe require substantial experience and training of sonographers. In this work, we propose a novel dual-agent framework that integrates a reinforcement learning (RL) agent and a deep learning (DL) agent to jointly determine the movement of the US probe based on the real-time US images, in order to mimic the decision-making process of an expert sonographer to achieve autonomous standard view acquisitions in spinal sonography. Moreover, inspired by the nature of US propagation and the characteristics of the spinal anatomy, we introduce a view-specific acoustic shadow reward to utilize the shadow information to implicitly guide the navigation of the probe toward different standard views of the spine. Our method is validated in both quantitative and qualitative experiments in a simulation environment built with US data acquired from 17 volunteers. The average navigation accuracy toward different standard views achieves $5.18mm/5.25^{\circ }$ and $12.87mm/17.49^{\circ }$ in the intra- and inter-subject settings, respectively. The results demonstrate that our method can effectively interpret the US images and navigate the probe to acquire multiple standard views of the spine.},
  archive      = {J_TMRB},
  author       = {Keyu Li and Yangxin Xu and Jian Wang and Dong Ni and Li Liu and Max Q.-H. Meng},
  doi          = {10.1109/TMRB.2021.3127015},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {130-144},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Image-guided navigation of a robotic ultrasound probe for autonomous spinal sonography using a shadow-aware dual-agent framework},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A systematic literature review of intent sensing for control
of medical devices. <em>TMRB</em>, <em>4</em>(1), 118–129. (<a
href="https://doi.org/10.1109/TMRB.2021.3135704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usefulness of medical devices, which require user input, is often limited by the control schemes that operate them. The recognition of user intent could enable far more intuitive control schemes that respond automatically to what the user wants the device to do. This paper provides a definition for intent, and then aims to systematically review current methods for sensing intent. It compares the accuracy of different methods and discusses how they might be combined. A systematic literature search was performed using IEEE Xplore, PubMed and Web of Science databases. 2311 papers were considered, reduced to 155 after review. All selected papers were assessed for quality using a checklist. The results identified and compared 15 sensing modalities used for intent sensing in a range of situations and applications that broadly fell into 12 distinct categories, with highly varying levels of accuracy. Several papers reached accuracy levels that could be suitable for everyday clinical application, but most work done on intent sensing to date has focused on activity transition classification, with fewer papers addressing task goal interference or predicting future actions. Further work can focus on the implementation of these kind of methods into a combined, context-aware intent-sensing control system.},
  archive      = {J_TMRB},
  author       = {Joseph Russell and Jeroen Bergmann},
  doi          = {10.1109/TMRB.2021.3135704},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {118-129},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A systematic literature review of intent sensing for control of medical devices},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GuLiM: A hybrid motion mapping technique for teleoperation
of medical assistive robot in combating the COVID-19 pandemic.
<em>TMRB</em>, <em>4</em>(1), 106–117. (<a
href="https://doi.org/10.1109/TMRB.2022.3146621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the demand to largely mitigate nosocomial infection problems in combating the coronavirus disease 2019 (COVID-19) pandemic, the trend of developing technologies for teleoperation of medical assistive robots is emerging. However, traditional teleoperation of robots requires professional training and sophisticated manipulation, imposing a burden on healthcare workers, taking a long time to deploy, and conflicting the urgent demand for a timely and effective response to the pandemic. This paper presents a novel motion synchronization method enabled by the hybrid mapping technique of hand gesture and upper-limb motion (GuLiM). It tackles a limitation that the existing motion mapping scheme has to be customized according to the kinematic configuration of operators. The operator awakes the robot from any initial pose state without extra calibration procedure, thereby reducing operational complexity and relieving unnecessary pre-training, making it user-friendly for healthcare workers to master teleoperation skills. Experimenting with robotic grasping tasks verifies the outperformance of the proposed GuLiM method compared with the traditional direct mapping method. Moreover, a field investigation of GuLiM illustrates its potential for the teleoperation of medical assistive robots in the isolation ward as the Second Body of healthcare workers for telehealthcare, avoiding exposure of healthcare workers to the COVID-19.},
  archive      = {J_TMRB},
  author       = {Honghao Lyu and Depeng Kong and Gaoyang Pang and Baicun Wang and Zhangwei Yu and Zhibo Pang and Geng Yang},
  doi          = {10.1109/TMRB.2022.3146621},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {106-117},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {GuLiM: A hybrid motion mapping technique for teleoperation of medical assistive robot in combating the COVID-19 pandemic},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robotic tissue sampling for safe post-mortem biopsy in
infectious corpses. <em>TMRB</em>, <em>4</em>(1), 94–105. (<a
href="https://doi.org/10.1109/TMRB.2022.3146440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pathology and legal medicine, the histopathological and microbiological analysis of tissue samples from infected deceased is a valuable information for developing treatment strategies during a pandemic such as COVID-19. However, a conventional autopsy carries the risk of disease transmission and may be rejected by relatives. We propose minimally invasive biopsy with robot assistance under CT guidance to minimize the risk of disease transmission during tissue sampling and to improve accuracy. A flexible robotic system for biopsy sampling is presented, which is applied to human corpses placed inside protective body bags. An automatic planning and decision system estimates optimal insertion point. Heat maps projected onto the segmented skin visualize the distance and angle of insertions and estimate the minimum cost of a puncture while avoiding bone collisions. Further, we test multiple insertion paths concerning feasibility and collisions. A custom end effector is designed for inserting needles and extracting tissue samples under robotic guidance. Our robotic post-mortem biopsy (RPMB) system is evaluated in a study during the COVID-19 pandemic on 20 corpses and 10 tissue targets, 5 of them being infected with SARS-CoV-2. The mean planning time including robot path planning is 5.72±167s. Mean needle placement accuracy is 7.19± 422mm.},
  archive      = {J_TMRB},
  author       = {Maximilian Neidhardt and Stefan Gerlach and Robin Mieling and Max-Heinrich Laves and Thorben Weiß and Martin Gromniak and Antonia Fitzek and Dustin Möbius and Inga Kniep and Alexandra Ron and Julia Schädler and Axel Heinemann and Klaus Püschel and Benjamin Ondruschka and Alexander Schlaefer},
  doi          = {10.1109/TMRB.2022.3146440},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {94-105},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic tissue sampling for safe post-mortem biopsy in infectious corpses},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Magnetically assisted robotic fetal surgery for the
treatment of spina bifida. <em>TMRB</em>, <em>4</em>(1), 85–93. (<a
href="https://doi.org/10.1109/TMRB.2022.3146351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spina bifida is a congenital defect that occurs on the vertebral spine of a fetus. The most severe form causes exposure of the spinal cord and spinal nerve and has important repercussions on the life of the newborn child. Current prenatal operative procedures require laparotomy of the abdomen as well as hysterotomy of the uterus, which can result in severe consequences and risks for the mother. Here, we propose a robotically assisted endoscopic procedure based on magnetically steerable catheters to treat spina bifida defects in a minimally invasive way. The procedure can be performed in a fully remote manner using magnetic guidance and a haptic controller. Four custom magnetic catheter designs are presented to image, sever, grasp and close the lesion on the fetus back. We demonstrate our approach in vitro using phantom models of the abdomen, the uterus, and the defected fetus.},
  archive      = {J_TMRB},
  author       = {Simone Gervasoni and Jonas Lussi and Silvia Viviani and Quentin Boehler and Nicole Ochsenbein and Ueli Moehrlen and Bradley J. Nelson},
  doi          = {10.1109/TMRB.2022.3146351},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {85-93},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Magnetically assisted robotic fetal surgery for the treatment of spina bifida},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anthropomorphic dual-arm coordinated control for a
single-port surgical robot based on dual-step optimization.
<em>TMRB</em>, <em>4</em>(1), 72–84. (<a
href="https://doi.org/10.1109/TMRB.2022.3145673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective teleoperation of the small-scale and highly-integrated robots for single-port surgery (SPS) imposes unique control and human-robot interaction challenges. Traditional isometric teleoperation schemes mainly focus on end-to-end trajectory mapping, which is problematic when applied to SPS robotic control, especially for dual-arm coordinated operation. Inspired by the human arm configuration in boxing maneuvers, an optimized anthropomorphic coordinated control strategy based on a dual-step optimization approach is proposed. Theoretical derivation and solvability of the problem are addressed, and the effectiveness of the method is further demonstrated in detailed simulation and in-vitro experiments. The proposed control strategy has been shown to perform dexterous SPS bimanual manipulation more effectively, involving less instrument-interference and is free from singularities, thereby improving the safety and efficiency of SPS operations.},
  archive      = {J_TMRB},
  author       = {Weibang Bai and Ziwei Wang and Qixin Cao and Hiroshi Yokoi and Masakatsu G. Fujie and Eric M. Yeatman and Guang-Zhong Yang},
  doi          = {10.1109/TMRB.2022.3145673},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {72-84},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Anthropomorphic dual-arm coordinated control for a single-port surgical robot based on dual-step optimization},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards surgical tools detection and operative skill
assessment based on deep learning. <em>TMRB</em>, <em>4</em>(1), 62–71.
(<a href="https://doi.org/10.1109/TMRB.2022.3145672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical tool detection and automatic operation skill assessment (AOSA) have important and extensive application scenarios in minimally invasive surgery (MIS). However, most of the deep learning methods currently used for surgical tool detection cannot achieve a good balance between speed and accuracy. We propose a new real-time detection algorithm for MIS tools, which called depth-wise separable convolutional network with convolutional long short-term memory (DSCNet-CLSTM). The network combines the advantages of the one-stage multi-scale feature maps’ concept in the state-of-art detection methods and the convolutional variant of the LSTM. This combination makes full use of the complementary information of spatial and temporal features learned from the laparoscopic video frames. In addition, we have established AOSA system. By processing the output information of the MIS tool detection algorithm, we can obtain the operation tool usage information in the laparoscopic video. Then, this information is taken as the dataset of AOSA system, which makes it possible to realize AOSA based on convolutional neural network (CNN). The proposed method achieved the mAP values of 100, 90.07 and 89.96% at a speed of 50.0 fps for the Endovis Challenge, ATLAS Dione, and Cholec80-locations datasets, respectively. The AOSA system obtained the mean squared error of 2.281, 0.987, 0.069, and 0.009 for the action timeline, heat map, motion trajectory, and all, respectively. The experimental results prove that the framework can be efficiently trained in an end-to-end manner and improves the algorithm’s detection accuracy and speed. Finally, we verify the feasibility of the designed AOSA system through experiments.},
  archive      = {J_TMRB},
  author       = {Yuying Liu and Zijian Zhao and Pan Shi and Feng Li},
  doi          = {10.1109/TMRB.2022.3145672},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {62-71},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Towards surgical tools detection and operative skill assessment based on deep learning},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surgical skill assessment based on dynamic warping
manipulations. <em>TMRB</em>, <em>4</em>(1), 50–61. (<a
href="https://doi.org/10.1109/TMRB.2022.3141313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Percutaneous coronary intervention (PCI) has become a popular treatment for coronary artery disease. Highly dexterous skills are necessary to procedure success. However, few effective methods can be applied to PCI skill assessment. In this study, ten interventional cardiologists (four experts and six novices) were recruited. In vivo studies were performed via delivering a medical guidewire into distal left circumflex artery (target vessel I) and obtuse marginal artery (target vessel II) of a porcine model. Regarded as a type of manipulation data, the guidewire motion is simultaneously acquired with an electromagnetic (EM) sensor attached to guidewire tail. To address the deficiency of conventional dynamic time warping (DTW) limited to two-sequence matching, a novel warping algorithm is proposed to match multiple manipulation data. Then the intra-similarity is calculated to evaluate consistencies among each subject’s different manipulations, while the inter-similarity is further analyzed to find skill differences among different subjects. Extensive statistical analysis demonstrates that the proposed algorithm can effectively distinguish between the manipulations made by different skill-level subjects with significant differences on the target vessel I ( $P = 3.25\times 10^{-4}$ ) and II ( $P = 7.30\times 10^{-3}$ ). These promising results show the proposed technique’s great potential to facilitate skill assessment in clinical practice and skill learning in surgical robotics.},
  archive      = {J_TMRB},
  author       = {Xiao-Hu Zhou and Xiao-Liang Xie and Shi-Qi Liu and Zhen-Qiu Feng and Mei-Jiang Gui and Jin-Li Wang and Hao Li and Tian-Yu Xiang and Gui-Bin Bian and Zeng-Guang Hou},
  doi          = {10.1109/TMRB.2022.3141313},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {50-61},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Surgical skill assessment based on dynamic warping manipulations},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Design and optimization of a 3D printed distal flexible
joint for endoscopic surgery. <em>TMRB</em>, <em>4</em>(1), 38–49. (<a
href="https://doi.org/10.1109/TMRB.2022.3142516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a flexible joint with excellent motion range, outstanding constant curvature characteristics, tiny hysteresis, and high loading capacity to support distal operation and observation for flexible endoscopy and natural orifice transluminal endoscopic surgery (NOTES). It adopts a rigid-flexible coupling design based on the 3D printing technique and mainly consists of multiple helical segments and rigid segments in a staggered arrangement. This flexible joint relies on the uniform stress distribution on the helical segments to generate a smooth bending shape and is configurated with a central hollow channel to carry surgical instruments instead of the central backbone configuration. Both kinematic modeling and simplified static modeling have been derived. Design optimization has been subsequently conducted to investigate the structural parameters for further performance improvement. Both flexible joints in a single-section and two-section configurations have been utilized for experiments to analyze and validate their performances. The experimental results show that the proposed flexible joints achieve excellent distal end positioning accuracy within [−180°, 180°] with a small distal average positioning error of 2.20% and a tiny hysteresis error of 0.95%. The modeling error between the derived kinematics and experimental results is only 3.8%. Meanwhile, the proposed joint can withstand a large surgical operation loading of 5N. The obstacle avoidance and colorectal phantom experiments have also been performed to demonstrate the great potentials for endoscopic surgery and NOTES.},
  archive      = {J_TMRB},
  author       = {Yongxiang Song and Shuxin Wang and Xiangyu Luo and Chaoyang Shi},
  doi          = {10.1109/TMRB.2022.3142516},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {38-49},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design and optimization of a 3D printed distal flexible joint for endoscopic surgery},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pre-clinical development of robot-assisted ventriculoscopy
for 3-d image reconstruction and guidance of deep brain neurosurgery.
<em>TMRB</em>, <em>4</em>(1), 28–37. (<a
href="https://doi.org/10.1109/TMRB.2021.3125322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional neuro-navigation can be challenged in targeting deep brain structures via transventricular neuroendoscopy due to unresolved geometric error following soft-tissue deformation. Current robot-assisted endoscopy techniques are fairly limited, primarily serving to planned trajectories and provide a stable scope holder. We report the implementation of a robot-assisted ventriculoscopy (RAV) system for 3D reconstruction, registration, and augmentation of the neuroendoscopic scene with intraoperative imaging, enabling guidance even in the presence of tissue deformation and providing visualization of structures beyond the endoscopic field-of-view. Phantom studies were performed to quantitatively evaluate image sampling requirements, registration accuracy, and computational runtime for two reconstruction methods and a variety of clinically relevant ventriculoscope trajectories. A median target registration error of 1.2 mm was achieved with an update rate of 2.34 frames per second, validating the RAV concept and motivating translation to future clinical studies.},
  archive      = {J_TMRB},
  author       = {Prasad Vagdargi and Ali Uneri and Craig K. Jones and Pengwei Wu and Runze Han and Mark G. Luciano and William S. Anderson and Patrick A. Helm and Gregory D. Hager and Jeffrey H. Siewerdsen},
  doi          = {10.1109/TMRB.2021.3125322},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {28-37},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Pre-clinical development of robot-assisted ventriculoscopy for 3-D image reconstruction and guidance of deep brain neurosurgery},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A preliminary exploration to make stereotactic surgery
robots aware of the semantic 2D/3D working scene. <em>TMRB</em>,
<em>4</em>(1), 17–27. (<a
href="https://doi.org/10.1109/TMRB.2021.3124160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene perceptual ability is key to developing autonomy and intelligence in surgical robots. This study helps stereotactic surgical robots detect and segment key objects in unstructured surgical scenes. First, we construct a neurosurgery robot working scene dataset. Next, we propose a 2Dimage-scene-aware pipeline that integrates a Mask R-CNN (mask region-based convolutional neural network) with a conditional random field and a superpixel method; the pipeline detects and segments key objects, such as the patient’s head, head frame, and body. Then, we establish a multiview projection voting and supervoxel fusion pipeline that extracts further information from a 3D point cloud scene. The proposed method was tested in different clinical scenarios, and the results show that the method can detect and segment specific surgical objects and achieves comparable accuracy and stability on both 2D images and 3D point cloud data. The average precision (AP) and average 2D and 3D Dice scores for the patient’s head were 97.65, 91.6, and 92.6, respectively. Better segmentation performances can be achieved when the data-based neural network method further integrates the traditional color and contour-based image processing methods. The proposed solution allows stereotactic surgical robots to better understand their surroundings, provides semantic information useful for subsequent tasks, and lays a foundation for autonomous stereotactic surgical robots.},
  archive      = {J_TMRB},
  author       = {Liang Li and Pengfei Feng and Hui Ding and Guangzhi Wang},
  doi          = {10.1109/TMRB.2021.3124160},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {17-27},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A preliminary exploration to make stereotactic surgery robots aware of the semantic 2D/3D working scene},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incorporating uncertainty into path planning for minimally
invasive robotic neurosurgery. <em>TMRB</em>, <em>4</em>(1), 5–16. (<a
href="https://doi.org/10.1109/TMRB.2021.3122357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New robotics devices can provide minimally invasive access to deep lesions in the brain through small openings in the skull, which can reduce infection risk and improve recovery times when compared to larger craniotomies. Several groups have introduced semi and fully automatic path planning tools to optimize lesion access while avoiding damage to critical structures along the path. These tools utilize preoperative imaging and intraoperative neuronavigation to plan and execute lesion access. However, several factors can introduce uncertainty into path planning, including segmentation, patient-to-image registration, brain shift during surgery, and mechanical uncertainty in the robotic device during path following. Most systems handle uncertainty by adding a ‘safety margin’ (typically 2–3 mm) around structures to be avoided or around the path. However, safety margins are somewhat arbitrary. We propose using more rigorous models of uncertainty during path planning. We explore two sources of uncertainty in path planning, namely segmentation uncertainty and uncertainty due to brain shift, propose a method for computing brain shift uncertainty, show how to combine these uncertainties into a single risk volume, and provide clinical motivation by presenting our approach in the context of a path planning system for robotic neurosurgery designed for treating mesial temporal lobe epilepsy.},
  archive      = {J_TMRB},
  author       = {Sarah Frisken and Jie Luo and Nazim Haouchine and Steve Pieper and Yixin Wang and William M. Wells and Alexandra J. Golby},
  doi          = {10.1109/TMRB.2021.3122357},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {5-16},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Incorporating uncertainty into path planning for minimally invasive robotic neurosurgery},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Guest editorial special section on surgical vision,
navigation, and robotics. <em>TMRB</em>, <em>4</em>(1), 2–4. (<a
href="https://doi.org/10.1109/TMRB.2022.3147605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The IEEE Transactions on Medical Robotics and Bionics (T-MRB) is an initiative shared by the two IEEE Societies of Robotics and Automation – RAS – and Engineering in Medicine and Biology – EMBS.},
  archive      = {J_TMRB},
  author       = {Xiongbiao Luo and Danail Stoyanov and Nobuhiko Hata and Alejandro F. Frangi and Russell H. Taylor and Terry M. Peters},
  doi          = {10.1109/TMRB.2022.3147605},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {2-4},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Guest editorial special section on surgical vision, navigation, and robotics},
  volume       = {4},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
