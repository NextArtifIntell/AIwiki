<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkde---430">TKDE - 430</h2>
<ul>
<li><details>
<summary>
(2022). Walking with attention: Self-guided walking for
heterogeneous graph embedding. <em>TKDE</em>, <em>34</em>(12),
6047–6060. (<a href="https://doi.org/10.1109/TKDE.2021.3069983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph embedding aims at learning low-dimensional representations from a graph featuring nodes and edges of diverse natures, and meanwhile preserving the underlying topology. Existing approaches along this line have largely relied on meta-paths , which are by nature hand-crafted and pre-defined transition rules, so as to explore the semantics of a graph. Despite the promising results, defining meta-paths requires domain knowledge, and thus when the test distribution deviates from the priors, such methods are prone to errors. In this paper, we propose a self-learning scheme for heterogeneous graph embedding, termed as self-guided walk (SILK), that bypasses meta-paths and learns adaptive attentions for node walking. SILK assumes no prior knowledge or annotation is provided, and conducts a customized random walk to encode the contexts of the heterogeneous graph of interest. Specifically, this is achieved via maintaining a dynamically-updated guidance matrix that records the node-conditioned transition potentials. Experimental results on four real-world datasets demonstrate that SILK significantly outperforms state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Yunzhi Hao and Xinchao Wang and Xingen Wang and Xinyu Wang and Chun Chen and Mingli Song},
  doi          = {10.1109/TKDE.2021.3069983},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {6047-6060},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Walking with attention: Self-guided walking for heterogeneous graph embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding WeChat user preferences and “wow” diffusion.
<em>TKDE</em>, <em>34</em>(12), 6033–6046. (<a
href="https://doi.org/10.1109/TKDE.2021.3064233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WeChat is the largest social instant messaging platform in China, with 1.1 billion monthly active users. “Top Stories” is a novel friend-enhanced recommendation engine in WeChat, in which users can read articles based on preferences of both their own and their friends. Specifically, when a user reads an article by opening it, the “click” behavior is private. Moreover, if the user clicks the “wow” button, (only) her/his direct connections will be aware of this action/preference. Based on the unique WeChat data, we aim to understand user preferences and “wow” diffusion in Top Stories at different levels. We have made some interesting discoveries. For instance, the “wow” probability of one user is negatively correlated with the number of connected components that are formed by her/his active friends, but the click probability is the opposite. We further study to what extent users’ “wow” and click behavior can be predicted from their social connections. To address this problem, we present a hierarchical graph representation learning based model DiffuseGNN, which is capable of capturing the structure-based social observations discovered above. Our experiments show that the proposed method can significantly improve the prediction performance compared with alternative methods.},
  archive      = {J_TKDE},
  author       = {Fanjin Zhang and Jie Tang and Xueyi Liu and Zhenyu Hou and Yuxiao Dong and Jing Zhang and Xiao Liu and Ruobing Xie and Kai Zhuang and Xu Zhang and Leyu Lin and Philip S. Yu},
  doi          = {10.1109/TKDE.2021.3064233},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {6033-6046},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Understanding WeChat user preferences and “Wow” diffusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards one-size-fits-many: Multi-context attention network
for diversity of entity resolution tasks. <em>TKDE</em>,
<em>34</em>(12), 6018–6032. (<a
href="https://doi.org/10.1109/TKDE.2021.3060790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity resolution (ER) identifies data instances referring to the same real-world entity and has received enormous research attention. In this paper, we examine the task of ER from a broader perspective, with its input extended from textual records, which are conventionally studied in the literature, to other modalities such as check-in sequences, GPS trajectories and surveillance video frames to generate new applications. Our goal in this paper is to design an effective model to uniformly support all these ER applications with different input formats. Technically, we fully exploit the semantic contexts of embedding vectors for the pair of input instances. In particular, we propose an integrated multi-context attention framework that takes into account self-attention, pair-attention and global-attention from three types of context. The idea can be further extended to incorporate attribute attention in order to support structured datasets. We conduct extensive experiments on a diverse class of entity resolutions tasks, including tasks on unstructured, structured and dirty textual records, check-in sequences, GPS trajectories and surveillance video frames. The experimental results verified the effectiveness and generality of our model. When compared with strong baselines in these applications, our model can achieve superior or comparative performance.},
  archive      = {J_TKDE},
  author       = {Dongxiang Zhang and Zepeng Li and Xiaoli Wang and Kian-Lee Tan and Gang Chen},
  doi          = {10.1109/TKDE.2021.3060790},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {6018-6032},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards one-size-fits-many: Multi-context attention network for diversity of entity resolution tasks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward tweet entity linking with heterogeneous information
networks. <em>TKDE</em>, <em>34</em>(12), 6003–6017. (<a
href="https://doi.org/10.1109/TKDE.2021.3068093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter, a microblogging platform, has developed into an increasingly invaluable information source, where millions of users post a great quantity of tweets with various topics per day. Heterogeneous information networks consisting of multi-type objects and relations are becoming more and more prevalent as an organization form of knowledge and information. The task of linking an entity mention in a tweet with its corresponding entity in a heterogeneous information network is of great importance, for the purpose of enriching heterogeneous information networks with the abundant and fresh knowledge embedded in tweets. However, the entity mention is ambiguous. Additionally, tweets are short and informal, making it difficult to mine enough information from a single tweet for entity linking. In this paper, we propose an unsupervised iterative clustering framework TELHIN to link multiple similar tweets with a heterogeneous information network jointly. Our framework takes three dimensions of tweet similarity into consideration: (1) content similarity, (2) temporal similarity, and (3) user similarity. The appropriate weights of different similarity dimensions for each entity mention are learned iteratively based on the metric learning algorithm by leveraging the pairwise constraints generated automatically. Experiments on real data demonstrate the effectiveness of our framework in comparison with the baselines.},
  archive      = {J_TKDE},
  author       = {Wei Shen and Yuwei Yin and Yang Yang and Jiawei Han and Jianyong Wang and Xiaojie Yuan},
  doi          = {10.1109/TKDE.2021.3068093},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {6003-6017},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Toward tweet entity linking with heterogeneous information networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-propagation graph neural network for recommendation.
<em>TKDE</em>, <em>34</em>(12), 5993–6002. (<a
href="https://doi.org/10.1109/TKDE.2021.3076772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommendation tasks, we model user preferences by learning node representations (i.e., user and item embeddings) based on the observed user-item interaction data, which is a bipartite graph. G raph N eural N etworks ( GNN s) are widely used to refine the representations by exploring the topology of the graph: embeddings of neighbors are propagated to each node to reconstruct its embeddings. However, the propagation strategy in existing GNNs is empirical and defective: (1) a substantial proportion of links are missed in the sparse observed graph, which causes ineffective and biased propagation; and (2) the propagation weights are determined by a coarse pre-defined rule, which only takes the degree of nodes into consideration. In this paper, we propose a dense and data-driven propagation mechanism for GNNs. Considering the graph we use to propagate embeddings in recommendation tasks is extremely sparse, we complement it and use the predicted graph as the new propagation tool. We learn the propagation matrix from the data, and propose a S elf-propagation G raph N eural N etwork ( SGNN ). Since it is very space- and time-consuming to maintain a large and dense propagation matrix, we factorize it for storing and updating. In this paper, we propose three methods to complete the sparse graph and construct the propagation matrix: (1) we complete the graph based on a recommendation model; (2) we measure the node distance based on spectral clustering; (3) we predict missing links of the graph based on predictive embeddings. In SGNN, the embeddings can be propagated to not only the observed neighbors, but also the potential yet unobserved neighbors, and the propagation weights are learned based on the connection strength. Comprehensive experiments on three real-world datasets demonstrate the effectiveness and efficiency of our proposed model: SGNN outperforms recent state-of-the-art GNNs significantly. Codes are available on https://github.com/Wenhui-Yu/LCFN .},
  archive      = {J_TKDE},
  author       = {Wenhui Yu and Xiao Lin and Jinfei Liu and Junfeng Ge and Wenwu Ou and Zheng Qin},
  doi          = {10.1109/TKDE.2021.3076772},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5993-6002},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Self-propagation graph neural network for recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SCPM-CR: A novel method for spatial co-location pattern
mining with coupling relation consideration. <em>TKDE</em>,
<em>34</em>(12), 5979–5992. (<a
href="https://doi.org/10.1109/TKDE.2021.3060119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial co-location pattern mining (SCPM) aims to discover subsets of spatial features frequently located together in proximate areas. Previous studies of SCPM solely concern the inter-features association of a pattern, but neglect the interesting intra-feature behavior. In this paper, we propose the task of spatial co-location pattern mining with coupling relation consideration (SCPM-CR) to capture complex relations embedded in a co-location. Specifically, InterPCI measure is designed to capture the inter-features coupling by considering the comprehensive interaction of objects for the features in a pattern, and luckily it possesses the anti-monotone property. Another measure, IntraCAI, is proposed to capture the congregating behavior of intra-feature objects under the restriction of a co-location. A general framework is designed for SCPM-CR task and experiments show that a large fraction of computation time is devoted to identifying the participating objects of a candidate pattern. To tackle this calculation bottleneck, a novel candidate-and-search algorithm is suggested, CS-HBS, equipped with heuristic backtracking search. Extensive experiments are conducted on real and synthetic datasets to demonstrate the superiority of SCPM-CR compared with traditional SCPM methods, and also to validate the efficiency and scalability of CS-HBS. Experimental results show that CS-HBS outperforms the baselines by several times or even orders of magnitude.},
  archive      = {J_TKDE},
  author       = {Peizhong Yang and Lizhen Wang and Xiaoxuan Wang and Lihua Zhou},
  doi          = {10.1109/TKDE.2021.3060119},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5979-5992},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SCPM-CR: A novel method for spatial co-location pattern mining with coupling relation consideration},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable label propagation for multi-relational learning on
the tensor product of graphs. <em>TKDE</em>, <em>34</em>(12), 5964–5978.
(<a href="https://doi.org/10.1109/TKDE.2021.3063985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-relational learning on knowledge graphs infers high-order relations among the entities across the graphs. This learning task can be solved by label propagation on the tensor product of the knowledge graphs to learn the high-order relations as a tensor. In this paper, we generalize a widely used label propagation model to the normalized tensor product graph, and propose an optimization formulation and the scalable Low-rank Tensor-based Label Propagation algorithm (LowrankTLP) to infer multi-relations for two learning tasks, hyperlink prediction and multiple graph alignment. The optimization formulation minimizes the upper bound of the noisy-tensor estimating error for multiple graph alignment, by learning with a subset of the eigen-pairs in the spectrum of the normalized tensor product graph. We also provide a data-dependent transductive Rademacher bound for binary hyperlink prediction. We accelerate LowrankTLP with parallel tensor computation which enables label propagation on a tensor product of 100 graphs each of size 1000 in less than half hour in the simulation. LowrankTLP was also applied to predicting the author-paper-venue hyperlinks in publication records, alignment of segmented regions across up to 26 CT-scan images and alignment of protein-protein interaction networks across multiple species. The experiments demonstrate that LowrankTLP indeed well approximates the original label propagation with better scalability and accuracy.},
  archive      = {J_TKDE},
  author       = {Zhuliu Li and Raphael Petegrosso and Shaden Smith and David Sterling and George Karypis and Rui Kuang},
  doi          = {10.1109/TKDE.2021.3063985},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5964-5978},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Scalable label propagation for multi-relational learning on the tensor product of graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ranking-based implicit regularization for one-class
collaborative filtering. <em>TKDE</em>, <em>34</em>(12), 5951–5963. (<a
href="https://doi.org/10.1109/TKDE.2021.3069057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class collaborative filtering (OCCF) problems are ubiquitous in real-world recommendation systems, such as news recommendation, but suffer from data sparsity and lack of negative items. To address the challenge, the state-of-the-art algorithm assigns uninteracted items with smaller weights of being negative and performs low-rank approximation over the user-item interaction matrix. However, the prior ratings are usually suggested to be zero but may not be well-defined. To avert the direct utilization of prior ratings for uninteracted items, we propose a novel ranking-based implicit regularizer by hypothesizing that users’ preference scores for uninteracted items should not deviate a lot from each other. The regularizer is then used in a ranking-based OCCF framework to penalize large differences of preference scores between uninteracted items. To efficiently optimize model parameters in this framework, we develop the scalable alternating least square algorithm and coordinate descent algorithm, whose time complexity is linearly proportional to the data size. Finally, we extensively evaluate the proposed algorithms on six public real-world datasets. The results show that the proposed regularizer significantly improves the recommendation quality of ranking-based OCCF algorithms, such as BPRMF and RankALS. Moreover, the ranking-based framework with the proposed regularizer outperforms the state-of-the-art recommendation algorithms for implicit feedback.},
  archive      = {J_TKDE},
  author       = {Defu Lian and Jin Chen and Kai Zheng and Enhong Chen and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2021.3069057},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5951-5963},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Ranking-based implicit regularization for one-class collaborative filtering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Possibilistic data cleaning. <em>TKDE</em>, <em>34</em>(12),
5939–5950. (<a href="https://doi.org/10.1109/TKDE.2021.3062318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical data cleaning performs a minimal set of operations on the data to satisfy the given integrity constraints. Often, this minimization is equivalent to vertex cover, for example when tuples can be removed due to the violation of functional dependencies. Classically, the uncertainty of tuples and constraints is ignored. We propose not to view data as dirty but the uncertainty information about data. Since probabilities are often unavailable and their treatment is limited due to correlations in the data, we investigate a qualitative approach to uncertainty. Tuples are assigned degrees of possibility with which they occur, and constraints are assigned degrees of certainty that say to which tuples they apply. Our approach is non-invasive to the data as we lower the possibility degree of tuples as little as possible. The new resulting qualitative version of vertex cover remains NP-hard. We establish an algorithm that is fixed-parameter tractable in the size of the qualitative vertex cover. Experiments with synthetic and real-world data show that our algorithm outperforms the classical algorithm proportionally to the available number of uncertainty degrees. By mining the certainty degrees with which constraints hold, our framework becomes applicable even when uncertainty information is unavailable.},
  archive      = {J_TKDE},
  author       = {Henning Koehler and Sebastian Link},
  doi          = {10.1109/TKDE.2021.3062318},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5939-5950},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Possibilistic data cleaning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Point-of-interest recommendation for users-businesses with
uncertain check-ins. <em>TKDE</em>, <em>34</em>(12), 5925–5938. (<a
href="https://doi.org/10.1109/TKDE.2021.3060818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing studies on next point-of-interest (POI) recommendation assume that users deliver certain check-ins over individual POIs. In reality, we typically obtain uncertain check-ins due to the presence of collective POIs, which are gathering places of multiple individual POIs (e.g., shopping malls). On one hand, such uncertain check-ins over collective POIs hinder more accurate next POI recommendation for users due to the transition vanishing issue; on the other hand, the presence of collective POIs poses the challenge for businesses to select which collective POIs to locate in due to complicated competition and cooperation relations between businesses. As such, these collective POIs bring an unprecedented opportunity and necessity on recommendation for both users and businesses. Therefore, we propose novel solutions of location service beneficial for users-businesses. For users, we propose the STSP equipped with category- and location-aware encoders, to deliver more accurate next POI prediction by fusing rich context features. Regarding businesses, we explore their competition and cooperation relations from check-in records, based on which we derive the living environment (LE) of a business. Insight on site selection for businesses is provided by exploiting the LE, aiming to bring in more profits. Extensive empirical studies demonstrate the efficiency of our solutions.},
  archive      = {J_TKDE},
  author       = {Zhu Sun and Chen Li and Yu Lei and Lu Zhang and Jie Zhang and Shunpan Liang},
  doi          = {10.1109/TKDE.2021.3060818},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5925-5938},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Point-of-interest recommendation for users-businesses with uncertain check-ins},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalized route recommendation with neural network
enhanced search algorithm. <em>TKDE</em>, <em>34</em>(12), 5910–5924.
(<a href="https://doi.org/10.1109/TKDE.2021.3068479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study an important task in location-based services, namely Personalized Route Recommendation (PRR) . Given a road network, the PRR task aims to generate user-specific route suggestions for replying to users’ route queries. A classic approach is to adapt search algorithms to construct pathfinding-like solutions. These methods typically focus on reducing search space with suitable heuristic strategies. For these search algorithms, heuristic strategies are often handcrafted, which are not flexible to work in complicated task settings. In addition, it is difficult to utilize useful context information in the search procedure. To develop a more principled solution to the PRR task, we propose to improve search algorithms with neural networks for solving the PRR task based on the widely used $A^{*}$ algorithm. The main idea of our solution is to automatically learn the cost functions in $A^{*}$ algorithms, which is the key of heuristic search algorithms. Our model consists of two main components. First, we employ attention-based Recurrent Neural Networks (RNN) to model the cost from the source to the candidate location by incorporating useful context information. Instead of learning a single cost value, the RNN component is able to learn a time-varying vectorized representation for the moving state of a user. Second, we propose to use an estimation network for predicting the cost from a candidate location to the destination. For capturing structural characteristics, the estimation network is built on top of position-aware graph attention networks. The two components are integrated in a principled way for deriving a more accurate cost of a candidate location for the $A^{*}$ algorithm. Extensive experiment results on three real-world datasets have shown the effectiveness and robustness of the proposed model.},
  archive      = {J_TKDE},
  author       = {Jingyuan Wang and Ning Wu and Wayne Xin Zhao},
  doi          = {10.1109/TKDE.2021.3068479},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5910-5924},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Personalized route recommendation with neural network enhanced search algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Periodic weather-aware LSTM with event mechanism for
parking behavior prediction. <em>TKDE</em>, <em>34</em>(12), 5896–5909.
(<a href="https://doi.org/10.1109/TKDE.2021.3070202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are plenty of parking spaces in big cities, but we often find nowhere to park. For example, New York has 1.4 million cars and 4.4 million on-street parking spaces, but it is still not easy to find a parking place near our destination, especially during peak hours. The reason is the lack of prediction of parking behavior. If we could provide parking behavior in advance, we can ease this parking problem that affects human well-being. We observe that parking lots have periodic parking patterns, which is an important factor for parking behavior prediction. Unfortunately, existing work ignores such periodic parking patterns in parking behavior prediction, and thus incurs low accuracy. To solve this problem, we propose PewLSTM, a novel periodic weather-aware LSTM model that successfully predicts the parking behavior based on historical records, weather, environments, weekdays, and events. PewLSTM includes a periodic weather-aware LSTM prediction module and an event prediction module, for predicting parking behaviors in regular days and events. PewLSTM is extremely useful for drivers and parking lot owners to improve customer experience. For example, the probability of parking space that will be available soon can be provided even if the parking lot is full. Based on 910,477 real parking records in 904 days from 13 parking lots, PewLSTM yields 93.84\% parking prediction accuracy, which is about 30\% higher than the state-of-the-art parking behavior prediction method. Additionally, we have analyzed parking behaviors in events like holidays and COVID-19. PewLSTM can handle parking behavior prediction in events and reaches 90.68 percent accuracy.},
  archive      = {J_TKDE},
  author       = {Feng Zhang and Yani Liu and Ningxuan Feng and Cheng Yang and Jidong Zhai and Shuhao Zhang and Bingsheng He and Jiazao Lin and Xiao Zhang and Xiaoyong Du},
  doi          = {10.1109/TKDE.2021.3070202},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5896-5909},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Periodic weather-aware LSTM with event mechanism for parking behavior prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the robustness of diffusion in a network under node
attacks. <em>TKDE</em>, <em>34</em>(12), 5884–5895. (<a
href="https://doi.org/10.1109/TKDE.2021.3071081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we assess a network&#39;s ability to maintain its functionality under attacks? Network robustness has been studied extensively in the case of deterministic networks. However, applications such as online information diffusion and the behavior of networked public raise a question of robustness in probabilistic networks. We propose three novel robustness measures for networks hosting a diffusion under the Independent Cascade or Linear Threshold model, susceptible to attacks by an adversarial attacker who disables nodes. The outcome of such a process depends on the selection of its initiators, or seeds, by the seeder , as well as on two factors outside the seeder&#39;s discretion: the attacker&#39;s strategy and the probabilistic diffusion outcome. We consider three levels of seeder awareness regarding these two uncontrolled factors, and evaluate the network&#39;s viability aggregated over all possible extents of an attack. We introduce novel algorithms from building blocks found in previous works to evaluate the proposed measures. A thorough experimental study with synthetic and real, scale-free and homogeneous networks establishes that these algorithms are effective and efficient, while the proposed measures highlight differences among networks in terms of robustness and the surprise they furnish when attacked. Last, we devise a new measure of diffusion entropy, and devise ways to enhance the robustness of probabilistic networks.},
  archive      = {J_TKDE},
  author       = {Alvis Logins and Yuchen Li and Panagiotis Karras},
  doi          = {10.1109/TKDE.2021.3071081},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5884-5895},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {On the robustness of diffusion in a network under node attacks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring diversity in graph learning: A unified framework
for structured multi-view clustering. <em>TKDE</em>, <em>34</em>(12),
5869–5883. (<a href="https://doi.org/10.1109/TKDE.2021.3068461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph learning has emerged as a promising technique for multi-view clustering due to its efficiency of learning a unified graph from multiple views. Previous multi-view graph learning methods mainly try to exploit the multi-view consistency to boost learning performance. However, these methods ignore the prevalent multi-view diversity which may be induced by noise, corruptions, or even view-specific attributes. In this paper, we propose to simultaneously and explicitly leverage the multi-view consistency and the multi-view diversity in a unified framework. The consistent parts are further fused to our target graph with a clear clustering structure, on which the cluster label to each instance can be directly allocated without any postprocessing such as $k$ -means in classical spectral clustering. In addition, our model can automatically assign suitable weight for each view based on its clustering capacity. By leveraging the subtasks of measuring the diversity of graphs, integrating the consistent parts with automatically learned weights, and allocating cluster label to each instance in a joint framework, each subtask can be alternately boosted by utilizing the results of the others towards an overall optimal solution. Extensive experimental results on several benchmark multi-view datasets demonstrate the effectiveness of our model in comparison to several state-of-the-art algorithms.},
  archive      = {J_TKDE},
  author       = {Shudong Huang and Ivor W. Tsang and Zenglin Xu and Jiancheng Lv},
  doi          = {10.1109/TKDE.2021.3068461},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5869-5883},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Measuring diversity in graph learning: A unified framework for structured multi-view clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning from incomplete and inaccurate supervision.
<em>TKDE</em>, <em>34</em>(12), 5854–5868. (<a
href="https://doi.org/10.1109/TKDE.2021.3061215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In plenty of real-life tasks, strongly supervised information is hard to obtain, and thus weakly supervised learning has drawn considerable attention recently. This paper investigates the problem of learning from incomplete and inaccurate supervision, where only a limited subset of training data is labeled but potentially with noise. This setting is challenging and of great importance but rarely studied in the literature. We notice that in many applications, the limited labeled data are with certain structures, which paves us a way to design effective methods. Specifically, we observe that labeled data are usually with one-sided noise such as the bug detection task, where the identified buggy codes are indeed with defects, while codes checked many times or newly fixed may still have other flaws. Furthermore, when there occurs two-sided noise in the labeled data, we exploit the class-prior information of unlabeled data, which is typically available in practical tasks. We propose novel approaches for the incomplete and inaccurate supervision learning tasks and effectively alleviate the negative influence of label noise with the help of a vast number of unlabeled data. Both theoretical analysis and extensive experiments justify and validate the effectiveness of the proposed approaches.},
  archive      = {J_TKDE},
  author       = {Zhen-Yu Zhang and Peng Zhao and Yuan Jiang and Zhi-Hua Zhou},
  doi          = {10.1109/TKDE.2021.3061215},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5854-5868},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning from incomplete and inaccurate supervision},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LDA-reg: Knowledge driven regularization using external
corpora. <em>TKDE</em>, <em>34</em>(12), 5840–5853. (<a
href="https://doi.org/10.1109/TKDE.2021.3069861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While recent developments of neural network (NN) models have led to a series of record-breaking achievements in many applications, the lack of sufficiently good datasets remains a problem for some applications. For such a problem, we can however exploit a large number of unstructured text corpora as an external knowledge to complement the training data, and most prevailing neural network solutions employ word embedding methods for such purposes. In this paper, we propose LDA-Reg, a novel knowledge driven regularization framework based on Latent Dirichlet Allocation (LDA) as an alternative to the word embedding methods to adaptively utilize abundant external knowledge and to interpret the NN model. For the joint learning of the parameters, we propose EM-SGD, an effective update method which incorporates Expectation Maximization (EM) and Stochastic Gradient Descent (SGD) to update parameters iteratively. Moreover, we also devise a lazy update and sparse update method for the high-dimensional inputs and sparse inputs respectively. We validate the effectiveness of our regularization framework through an extensive experimental study over real world and standard benchmark datasets. The results show that our proposed framework not only achieves significant improvement over state-of-the-art word embedding methods but also learns interpretable and significant topics for various tasks.},
  archive      = {J_TKDE},
  author       = {Kai Yang and Zhaojing Luo and Jinyang Gao and Junfeng Zhao and Beng Chin Ooi and Bing Xie},
  doi          = {10.1109/TKDE.2021.3069861},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5840-5853},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LDA-reg: Knowledge driven regularization using external corpora},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge graph embedding by double limit scoring loss.
<em>TKDE</em>, <em>34</em>(12), 5825–5839. (<a
href="https://doi.org/10.1109/TKDE.2021.3060755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding is an effective way to represent knowledge graph, which greatly enhance the performances on knowledge graph completion tasks, e.g., entity or relation prediction. For knowledge graph embedding models, designing a powerful loss framework is crucial to the discrimination between correct and incorrect triplets. Margin-based ranking loss is a commonly used negative sampling framework to make a suitable margin between the scores of positive and negative triples. However, this loss can not ensure ideal low scores for the positive triplets and high scores for the negative triplets, which is not beneficial for knowledge completion tasks. In this paper, we present a double limit scoring loss to separately set upper bound for correct triplets and lower bound for incorrect triplets, which provides more effective and flexible optimization for knowledge graph embedding. Upon the presented loss framework, we present several knowledge graph embedding models including TransE-SS, TransH-SS, TransD-SS, ProjE-SS and ComplEx-SS. The experimental results on link prediction and triplet classification show that our proposed models have the significant improvement compared to state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Xiaofei Zhou and Lingfeng Niu and Qiannan Zhu and Xingquan Zhu and Ping Liu and Jianlong Tan and Li Guo},
  doi          = {10.1109/TKDE.2021.3060755},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5825-5839},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Knowledge graph embedding by double limit scoring loss},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incremental weighted ensemble broad learning system for
imbalanced data. <em>TKDE</em>, <em>34</em>(12), 5809–5824. (<a
href="https://doi.org/10.1109/TKDE.2021.3061428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) is a novel and efficient model, which facilitates representation learning and classification by concatenating feature nodes and enhancement nodes. In spite of the efficient properties, BLS is still suboptimal when facing with imbalance problem. Besides, outliers and noises in imbalanced data remain a challenge for BLS. To address the above issues, in this paper we first propose a weighted BLS, which assigns a weight to each training sample, and adopt a general weighting scheme, which augments the weight of samples from the minority class. To further explore the prior distribution of original data, we design a density based weight generation mechanism to guide the specific weight matrix generation and propose the adaptive weighted broad learning system (AWBLS). This mechanism considers the inter-class and intra-class distance simultaneously in the density calculation. Finally, we propose the incremental weighted ensemble broad learning system (IWEB) by utilizing a progressive mechanism to further improve the stability and robustness of AWBLS. Extensive comparative experiments on 38 real-world data sets verfy that IWEB outperforms most of the imbalance ensemble classification methods.},
  archive      = {J_TKDE},
  author       = {Kaixiang Yang and Zhiwen Yu and C. L. Philip Chen and Wenming Cao and Jane You and Hau-San Wong},
  doi          = {10.1109/TKDE.2021.3061428},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5809-5824},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Incremental weighted ensemble broad learning system for imbalanced data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gas-theft suspect detection among boiler room users: A
data-driven approach. <em>TKDE</em>, <em>34</em>(12), 5796–5808. (<a
href="https://doi.org/10.1109/TKDE.2021.3062707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The natural gas tightly correlates with our everyday life. However, driven by gray incomes, some users are prone to stealing gas by refitting the equipment without permission. Especially for the boiler room users in winter, this phenomenon appears more rampant. Traditional gas-theft detection methods highly rely on the on-site inspection, where exists ineffective and randomness. With the rapidly deployed IoT sensors, we can collect real-time gas consumption data to analyze users’ behavior patterns, where the gas-theft suspects could be discovered early and accurately. In this paper, we propose a data-driven approach, named SVOC, to detect gas-theft suspects among boiler room users. Our approach consists of a scenario-based data quality detection algorithm, a deformation-based normality detection algorithm, and an One-Class Support Vector Machine (OCSVM) based anomaly detection algorithm. Specifically, considering the temporal proximity between the gas consumption and the outdoor temperature, the normality detection algorithm adopts a similarity-based deformation correlation to detect normal boiler room users out of abnormal ones. Then, we employ OCSVM as the anomaly detection algorithm to capture various features across multiple data sources, aiming to distinguish gas-theft suspects from the remaining irregular users. Here, the detected normal and abnormal users are fed into the OCSVM for training and prediction, respectively, which can overcome the label scarcity problem. We conduct extensive experiments on a real-world dataset during one heating season. The results demonstrate distinct advantages of our approach over various baselines. We have developed a real-time system on the cloud, providing daily gas-theft suspects for gas companies.},
  archive      = {J_TKDE},
  author       = {Xiuwen Yi and Xiaodu Yang and Yanyong Huang and Songyu Ke and Junbo Zhang and Tianrui Li and Yu Zheng},
  doi          = {10.1109/TKDE.2021.3062707},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5796-5808},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Gas-theft suspect detection among boiler room users: A data-driven approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Formal analysis and estimation of chance in datasets based
on their properties. <em>TKDE</em>, <em>34</em>(12), 5784–5795. (<a
href="https://doi.org/10.1109/TKDE.2021.3068009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning research, particularly in genomics, is often based on wide shaped datasets, i.e. datasets having a large number of features, but a small number of samples. Such configurations raise the possibility of chance influence (the increase of measured accuracy due to chance correlations) on the learning process and the evaluation results. Prior research underlined the problem of generalization of models obtained based on such data. In this paper, we investigate the influence of chance on prediction and show its significant effects on wide shaped datasets. First, we empirically demonstrate how significant the influence of chance in such datasets is by showing that prediction models trained on thousands of randomly generated datasets can achieve high accuracy. This is the case even when using cross-validation. We then provide a formal analysis of chance influence and design formal chance influence estimators based on the dataset parameters, namely its sample size, the number of features, the number of classes and the class distribution. Finally, we provide an in-depth discussion of the formal analysis including applications of the findings and recommendations on chance influence mitigation.},
  archive      = {J_TKDE},
  author       = {Abdel Aziz Taha and Luca Papariello and Alexandros Bampoulidis and Petr Knoth and Mihai Lupu},
  doi          = {10.1109/TKDE.2021.3068009},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5784-5795},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Formal analysis and estimation of chance in datasets based on their properties},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Faster domain adaptation networks. <em>TKDE</em>,
<em>34</em>(12), 5770–5783. (<a
href="https://doi.org/10.1109/TKDE.2021.3060473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely acknowledged that the success of deep learning is built upon large-scale training data and tremendous computing power. However, the data and computing power are not always available for many real-world applications. In this paper, we address the machine learning problem where it lacks training data and limits computing power. Specifically, we investigate domain adaptation which is able to transfer knowledge from one labeled source domain to an unlabeled target domain, so that we do not need much training data from the target domain. At the same time, we consider the situation that the running environment is confined, e.g., in edge computing the end device has very limited running resources. Technically, we present the Faster Domain Adaptation (FDA) protocol and further report two paradigms of FDA: early stopping and amid skipping. The former accelerates domain adaptation by multiple early exit points. The latter speeds up the adaptation by wisely skip several amid neural network blocks. Extensive experiments on standard benchmarks verify that our method is able to achieve the comparable and even better accuracy but employ much less computing resources. To the best of our knowledge, there are very few works which investigated accelerating knowledge adaptation in the community. This work is expected to inspire the topic for more discussion.},
  archive      = {J_TKDE},
  author       = {Jingjing Li and Mengmeng Jing and Hongzu Su and Ke Lu and Lei Zhu and Heng Tao Shen},
  doi          = {10.1109/TKDE.2021.3060473},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5770-5783},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Faster domain adaptation networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Electroencephalogram signal clustering with convex
cooperative games. <em>TKDE</em>, <em>34</em>(12), 5755–5769. (<a
href="https://doi.org/10.1109/TKDE.2021.3060742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, electroencephalogram (EEG) is mostly analyzed in a supervised way, which requires EEG labels (e.g., EEG classification). With the ever-increasing amount of unlabeled/mislabeled EEG in neuropsychiatric disorder diagnosis, BCI, and rehabilitation, manually labeling of EEG data is a labor intensive and time-consuming process, and few labs have developed algorithms to analyze EEG in an unsupervised manner (i.e., EEG clustering). In this paper, we propose a cooperative game inspired approach to cluster multi-trial EEG data. The idea is to map multi-trial EEG clustering to the coalition formation in a cooperative game, and then identify cluster center (the EEG trial with highest Shapley value) and assign EEG trials into proper clusters based on their cross correlation-transformed Shapley values. We demonstrate the mapped EEG cooperative game is convex, and it leads to an algorithm for multi-trial EEG clustering named CoGEEGc. The CoGEEGc yields high-quality multi-trial EEG clustering with respect to intra-cluster compactness and inter-cluster scatter. We show that CoGEEGc outperforms 15 state-of-the-art EEG or time series clustering approaches through detailed experimentation on real-world multi-trial EEG datasets. Comparison against 15 methods with four theoretical properties of clustering further illustrates the superiority of CoGEEGc, as it satisfies two properties while other approaches only satisfy one.},
  archive      = {J_TKDE},
  author       = {Chenglong Dai and Jia Wu and Dechang Pi and Lin Cui and Blake Johnson and Stefanie I. Becker},
  doi          = {10.1109/TKDE.2021.3060742},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5755-5769},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Electroencephalogram signal clustering with convex cooperative games},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient oblivious query processing for range and kNN
queries. <em>TKDE</em>, <em>34</em>(12), 5741–5754. (<a
href="https://doi.org/10.1109/TKDE.2021.3060757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasingly, individuals and companies adopt a cloud service provider as a primary data and IT infrastructure platform. The remote access of the data inevitably brings the issue of trust. Data encryption is necessary to keep sensitive information secure and private on the cloud. Yet adversaries can still learn valuable information regarding encrypted data by observing data access patterns. To solve such problem, Oblivious RAMs (ORAMs) are proposed to completely hide access patterns. However, most ORAM constructions are expensive and not suitable to deploy in a database for supporting query processing over large data. Furthermore, an ORAM processes queries synchronously , hence, does not provide high throughput for concurrent query processing . In this article, we design a practical oblivious query processing framework to enable efficient query processing over a cloud database. In particular, we focus on processing multiple range and $k$ NN queries asynchronously and concurrently with high throughput . The key idea is to integrate indices into ORAM which leverages a suite of optimization techniques (e.g., oblivious batch processing and caching). The effectiveness and efficiency of our oblivious query processing framework is demonstrated through extensive evaluations over large datasets. Our construction shows an order of magnitude speedup in comparison with other baselines.},
  archive      = {J_TKDE},
  author       = {Zhao Chang and Dong Xie and Feifei Li and Jeff M. Phillips and Rajeev Balasubramonian},
  doi          = {10.1109/TKDE.2021.3060757},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5741-5754},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient oblivious query processing for range and kNN queries},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Distribution prediction for reconfiguring urban dockless
e-scooter sharing systems. <em>TKDE</em>, <em>34</em>(12), 5722–5740.
(<a href="https://doi.org/10.1109/TKDE.2021.3062074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dockless E-scooter Sharing (DES) has become a popular means of last-mile commute for many smart cities. As e-scooters are getting deployed dynamically and flexibly across city regions that expand and/or shrink, accurate prediction of the e-scooter distribution given the reconfigured regions becomes essential for city planning. We present GCScoot , a novel flow distribution prediction approach for reconfiguring urban DES systems. Based on real-world datasets with reconfiguration, we analyze e-scooter distribution features and flow dynamics for the data-driven designs. We propose a novel spatio-temporal graph capsule neural network within GCScoot to predict future dockless e-scooter flows given the reconfigured regions. GCScoot pre-processes historical spatial e-scooter distributions into flow graph structures, where discretized city regions are considered as nodes and inter-region flows as edges. To facilitate initial training, we cluster the regions and generate virtual data for new deployment regions based on their peers in the same cluster. Given above designs, the region-to-region correlations embedded within the temporal flow graphs are captured via the multi-graph capsule convolutional neural network which accurately predicts the DES flows. Extensive studies upon four e-scooter datasets (total $&amp;gt;$ 3.4 million rides) in four populous US cities have corroborated accuracy and effectiveness of GCScoot in predicting the e-scooter distributions.},
  archive      = {J_TKDE},
  author       = {Suining He and Kang G. Shin},
  doi          = {10.1109/TKDE.2021.3062074},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5722-5740},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Distribution prediction for reconfiguring urban dockless E-scooter sharing systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discovering and analyzing contextual behavioral patterns
from event logs. <em>TKDE</em>, <em>34</em>(12), 5708–5721. (<a
href="https://doi.org/10.1109/TKDE.2021.3077653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event logs that are recorded by information systems provide a valuable starting point for the analysis of processes in various domains, reaching from healthcare, through logistics, to e-commerce. Specifically, behavioral patterns discovered from an event log enable operational insights, even in scenarios where process execution is rather unstructured and shows a large degree of variability. While such behavioral patterns capture frequently recurring episodes of a process’ behavior, they are not limited to sequential behavior but include notions of concurrency and exclusive choices. Existing algorithms to discover behavioral patterns are context-agnostic, though. They neglect the context in which patterns are observed, which severely limits the granularity at which behavioral regularities are identified. In this paper, we therefore present an approach to discover contextual behavioral patterns. Contextual patterns may be frequent solely in a certain partition of the event log, which enables fine-granular insights into the aspects that influence the conduct of a process. Moreover, we show how to analyze the discovered contextual behavioral patterns in terms of causal relations between context information and the patterns, as well as correlations between the patterns themselves. A complete analysis methodology leveraging all the tools presented in the paper and supplemented by interpretations guidelines is also provided. Finally, experiments with real-world event logs demonstrate the effectiveness of our techniques in obtaining fine-granular process insights.},
  archive      = {J_TKDE},
  author       = {Mehdi Acheli and Daniela Grigori and Matthias Weidlich},
  doi          = {10.1109/TKDE.2021.3077653},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5708-5721},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Discovering and analyzing contextual behavioral patterns from event logs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepFlowGen: Intention-aware fine grained crowd flow
generation via deep neural networks. <em>TKDE</em>, <em>34</em>(12),
5693–5707. (<a href="https://doi.org/10.1109/TKDE.2021.3061813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining crowd flow distribution with recognized human intention is extremely valuable for a series of applications for metropolitan cities. Previous solutions look at spatial correlation and temporal periodicity based on historical crowd flow information to calculate future crowd flow distribution. However, these mechanisms cannot recognize the intention behind crowd flow. We address this problem by leveraging a key insight – people&#39;s intention behind their movement is highly correlated with the point-of-interest (POI) distribution of the corresponding regions and adjacent regions. Therefore, we propose DeepFlowGen to model the complicated relationship between crowd flow, POI, check-ins, and time to generate intention-aware crowd flow. Specifically, we solve the conflict between dynamic crowd flow and static POI distribution by fusing the information in both time and POI domains. Besides, we employ a sequence of residual blocks in DeepFlowGen to address the challenges of modeling the diverse temporal rhythms and heterogeneous influence of POI. Furthermore, we examine the generated intention-aware crowd flow from two aspects to substantiate the reasonability of DeepFlowGen . Extensive experiments demonstrate that our model outperforms the state-of-the-art solutions by at most 30 percent in terms of NRMSE of total crowd flow. Moreover, the correlation between the generated intention-aware crowd flow and the check-in distribution across different categories of POIs is as high as 0.90 and 0.80 in Beijing and Shanghai. Combined with extensive case studies, we demonstrate the strong ability of our model in generating intention-aware crowd flow.},
  archive      = {J_TKDE},
  author       = {Erzhuo Shao and Huandong Wang and Jie Feng and Tong Xia and Hedong Yang and Lu Geng and Depeng Jin and Yong Li},
  doi          = {10.1109/TKDE.2021.3061813},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5693-5707},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DeepFlowGen: Intention-aware fine grained crowd flow generation via deep neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Competitive relationship prediction for points of interest:
A neural graphlet based approach. <em>TKDE</em>, <em>34</em>(12),
5681–5692. (<a href="https://doi.org/10.1109/TKDE.2021.3063233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competition between Points of Interest (POIs) refers to the situation in which two POIs directly or indirectly provide similar services to secure businesses. A large portion of prior studies on competition analysis focuses on mining textual data, e.g., news articles and social comments. However, the increasing availability of human mobility and mobile query data enables a new paradigm for analyzing the competitive relationships among POIs, which remains largely unexplored. To this end, in this paper, we attempt to mine large-scale online map search query data for better understanding POI competitive relationships. Based on a co-query POI graph built from the map search query data, we develop a novel neural graphlet-based prediction framework to predict the competitive relationships among POIs. A unique perspective of our model is to infer latent POI competitive relationships by integrating multiple distinct factors, e.g., graphlet structure, geographical distance, and regional features, reflected in map search query data and POI data. Finally, we conduct extensive experiments on real-world datasets to demonstrate the effectiveness of the proposed framework, and show that our framework outperforms all baselines with a significant margin in all evaluation metrics.},
  archive      = {J_TKDE},
  author       = {Jingbo Zhou and Tao Huang and Shuangli Li and Renjun Hu and Yanchi Liu and Yanjie Fu and Hui Xiong},
  doi          = {10.1109/TKDE.2021.3063233},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5681-5692},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Competitive relationship prediction for points of interest: A neural graphlet based approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coloring embedder: Towards multi-set membership queries in
web cache sharing. <em>TKDE</em>, <em>34</em>(12), 5664–5680. (<a
href="https://doi.org/10.1109/TKDE.2021.3062182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-set membership queries are fundamental operations in data science. In this paper, we propose a new data structure for multi-set membership queries, named coloring embedder, which is fast, accurate, and memory efficient. The idea of coloring embedder is to first map elements to a high-dimensional space, which nearly eliminates hashing collisions, and then use a dimensional reduction representation, similar to coloring a graph, to save memory. Theoretical proofs and experimental results show that the coloring embedder is effective in solving the problem of multi-set membership queries. We also find that web cache sharing is one of the typical application scenarios of the multi-set membership queries and current methods based on Bloom filters always send redundant queries. We apply coloring embedder to web cache sharing by arranging our data structure on the on-chip and off-chip memory and designing query, insertion and deletion operations for this scenario. The experimental results show that compared with the present method, our method can reduce the queries sent by proxies while reaching equal hit rate with the same size of on-chip memory. The source code of coloring embedder has been released on Github.},
  archive      = {J_TKDE},
  author       = {Zhaodong Kang and Jin Xu and Wenqi Wang and Jie Jiang and Shiqi Jiang and Tong Yang and Bin Cui and Tilman Wolf},
  doi          = {10.1109/TKDE.2021.3062182},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5664-5680},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Coloring embedder: Towards multi-set membership queries in web cache sharing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building graphs at scale via sequence of edges: Model and
generation algorithms. <em>TKDE</em>, <em>34</em>(12), 5649–5663. (<a
href="https://doi.org/10.1109/TKDE.2021.3081624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world graphs exhibit many interesting properties that differentiate them from random graphs, which have been extensively studied for the past decades. For various proposed generative models, a majority of them build the graph by sequentially adding each node and the attached edges. However, the growth of many real-world graphs, such as social networks, is naturally modeled by the sequential insertion of edges. Unfortunately, to the best of our knowledge, no generative model has been proposed to reveal this process. We propose the first sequence-of-edges model, denoted as temporal preferential attachment (TPA) . It relies on preferential attachment (PA) , one of the most influential mechanisms to generate scale-free graphs, and takes time-decay effect and node fitness into consideration. Empirical analysis demonstrates that our model preserves several key properties of the real-world graphs, including both the properties observed from the snapshot graphs (e.g., power-law distribution) and temporal properties observed from the graph generation process (e.g., shrinking diameter). Meanwhile, our model is sufficiently general to accommodate several forms of time decay and fitness distributions. Then, we design two efficient algorithms that generate TPA graphs with billions of edges in several minutes.},
  archive      = {J_TKDE},
  author       = {Yu Liu and Lei Zou and Zhewei Wei},
  doi          = {10.1109/TKDE.2021.3081624},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5649-5663},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Building graphs at scale via sequence of edges: Model and generation algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asynchronous parallel, sparse approximated SVRG for
high-dimensional machine learning. <em>TKDE</em>, <em>34</em>(12),
5636–5648. (<a href="https://doi.org/10.1109/TKDE.2021.3070539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing of the data size and the development of multi-core computers, asynchronous parallel stochastic optimization algorithms such as KroMagnon have gained significant attention. In this paper, we propose a new Sparse approximation and asynchronous parallel Stochastic Variance Reduced Gradient (SSVRG) method for sparse and high-dimensional machine learning problems. Unlike standard SVRG and its asynchronous parallel variant, KroMagnon, the snapshot point of SSVRG is set to the average of all the iterates in the previous epoch, which allows it to take much larger learning rates and also makes it more robust to the choice of learning rates. In particular, we use the sparse approximation of the popular SVRG estimator to perform completely sparse updates at all iterations. Therefore, SSVRG has a much lower per-iteration computational cost than its dense counterpart, SVRG++, and is very friendly to asynchronous parallel implementation. Moreover, we provide the convergence guarantees of SSVRG for both strongly convex and non-strongly convex problems, while existing asynchronous algorithms (e.g., KroMagnon and ASAGA) only have convergence guarantees for strongly convex problems. Finally, we extend SSVRG to non-smooth and asynchronous parallel settings. Numerical experimental results demonstrate that SSVRG converges significantly faster than the state-of-the-art asynchronous parallel methods, e.g., KroMagnon, and is usually more than three orders of magnitude faster than SVRG++.},
  archive      = {J_TKDE},
  author       = {Fanhua Shang and Hua Huang and Jun Fan and Yuanyuan Liu and Hongying Liu and Jianhui Liu},
  doi          = {10.1109/TKDE.2021.3070539},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5636-5648},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Asynchronous parallel, sparse approximated SVRG for high-dimensional machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximately counting butterflies in large bipartite graph
streams. <em>TKDE</em>, <em>34</em>(12), 5621–5635. (<a
href="https://doi.org/10.1109/TKDE.2021.3062987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graphs widely exist in real-world scenarios and model binary relations like host-website, author-paper, and user-product. In bipartite graphs, a butterfly (i.e., $2\times 2$ bi-clique) is the smallest non-trivial cohesive structure and plays an important role in applications such as anomaly detection. Considerable efforts focus on counting butterflies in static bipartite graphs. However, they suffer from high time and space complexity when the bipartite graph of interest is given as a stream of edges. Although there are methods for approximately counting butterflies from bipartite graph streams, they suffer from either low accuracy or high time complexity. Therefore, it is still a challenge to accurately estimate butterfly counts from bipartite graph streams in a short time. To address this issue, we develop novel algorithms by exploiting the bipartite nature, which subtly integrates sampling and sketching techniques. We provide accurate estimators for butterfly counts and derive simple yet exact formulas for bounding their errors. We also conduct extensive experiments on a variety of real-world large bipartite graphs. Experimental results demonstrate that our algorithms are up to 20.0 times more accurate and up to 286.3 times faster than state-of-the-art methods under the same memory usage.},
  archive      = {J_TKDE},
  author       = {Rundong Li and Pinghui Wang and Peng Jia and Xiangliang Zhang and Junzhou Zhao and Jing Tao and Ye Yuan and Xiaohong Guan},
  doi          = {10.1109/TKDE.2021.3062987},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5621-5635},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Approximately counting butterflies in large bipartite graph streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active learning for knowledge graph schema expansion.
<em>TKDE</em>, <em>34</em>(12), 5610–5620. (<a
href="https://doi.org/10.1109/TKDE.2021.3070317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both entity typing and relation extraction from text corpora are widely used to identify the semantic types of an entity and a relation in a knowledge graph (KG). Most existing approaches rely on a pre-defined set of entity types and relation types in a KG. They thus cannot map entity mentions (relation mentions) to unseen entity types (relation types). To fundamentally overcome the limitations, we should add new semantic types of entities and relations to a KG schema. However, schema expansion traditionally requires manual conceptualization through a user’s observation on the text corpus while assuming the existence of suitable target KG schemas. In this work, we propose an A ctive learning framework for K nowledge graph S chema E xpansion ( AKSE ), which can generate a new semantic type for KG schemas, without depending on a set of target schemas and human users’ observation. Specifically, a granularity based active learning algorithm determines whether a KG schema requires new semantic types or not. We also introduce a KG schema attention-based neural method which assigns semantic types to the entities and relationships extracted. To the best of our knowledge, our work is the first study to expand a KG schema with active learning.},
  archive      = {J_TKDE},
  author       = {Seungmin Seo and Byungkook Oh and Eunju Jo and Sanghak Lee and Dongho Lee and Kyong-Ho Lee and Donghoon Shin and Yeonsoo Lee},
  doi          = {10.1109/TKDE.2021.3070317},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5610-5620},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Active learning for knowledge graph schema expansion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on multi-task learning. <em>TKDE</em>,
<em>34</em>(12), 5586–5609. (<a
href="https://doi.org/10.1109/TKDE.2021.3070203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL from the perspective of algorithmic modeling, applications and theoretical analyses. For algorithmic modeling, we give a definition of MTL and then classify different MTL algorithms into five categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach and decomposition approach as well as discussing the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, we review online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works in this paper. Finally, we present theoretical analyses and discuss several future directions for MTL.},
  archive      = {J_TKDE},
  author       = {Yu Zhang and Qiang Yang},
  doi          = {10.1109/TKDE.2021.3070203},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5586-5609},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on multi-task learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A patience-aware recommendation scheme for shared accounts
on mobile devices. <em>TKDE</em>, <em>34</em>(12), 5571–5585. (<a
href="https://doi.org/10.1109/TKDE.2021.3069002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As sharing of accounts is quite common among family members or roommates, the design of efficient recommender schemes for shared accounts has raised much attention recently. Generally speaking, after each login, it is essential for a recommender system to identify the current user behind and leverage this information to make recommendations. One naive approach is first to identify the identity of the current user and then make recommendations. However, this two-stage based approach may not achieve satisfactory performance. The key is that the recommended items favoring identifying users in the first stage may not be interesting to the users, which can deplete the user&#39;s patience quickly and cause early termination of users. To address the problem, we propose a novel recommendation scheme that makes a tradeoff between recommending discriminating items (helpful for identifying the user) and recommending interesting ones to the user (helpful for increasing the number of clicks). Under this scheme, we develop a patience model to capture the user&#39;s dynamic patience level during the recommendation process. Moreover, considering the increasing popularity of mobile devices, we also incorporate mobile sensor data (i.e., angle, accelerometer, gyroscope, etc.) into our approach to further improve the performance of the system. We implemented the above system in an App on mobile devices and carried out extensive experiments. The results demonstrate that our proposed scheme significantly outperforms the existing state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Kaili Mao and Jianwei Niu and Xuefeng Liu and Shaojie Tang and Lizi Liao and Tat-Seng Chua},
  doi          = {10.1109/TKDE.2021.3069002},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5571-5585},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A patience-aware recommendation scheme for shared accounts on mobile devices},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid deep network framework for android malware
detection. <em>TKDE</em>, <em>34</em>(12), 5558–5570. (<a
href="https://doi.org/10.1109/TKDE.2021.3067658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android is a growing target for malicious software (malware) because of its popularity and functionality. Malware poses a serious threat to users’ privacy, money, equipment and file integrity. A series of data-driven malware detection methods were proposed. However, there exist two key challenges for these methods: (1) how to learn effective feature representation from raw data; (2) how to reduce the dependence on the prior knowledge or human labors in feature learning. Inspired by the success of deep learning methods in the feature representation learning community, we propose a malware detection framework which starts with learning rich-features by a novel unsupervised feature learning algorithm Merged Sparse Auto-Encoder (MSAE). In order to extract more compact and discriminative feature from the rich-features to further boost the malware detection capability, a hybrid deep network learning algorithm Stacked Hybrid Learning MSAE and SDAE (SHLMD) is established by further incorporating a classical deep learning method Stacked Denoising Auto-encoders (SDAE). After that, we feed the feature learned by MSAE and SHLMD respectively to classification algorithms, e.g., Support Vector Machine (SVM) or K-NearestNeighbor (KNN), to train a malware detection model. Evaluation results on two real-world datasets demonstrate that SHLMD achieves 94.46 and 90.57 percent accuracy respectively, which outperforms the classical unsupervised feature representation learning Sparse Auto-encoder (SAE). MSAE performs similarly to SAE. SHLMD can further improve the performance of MSAE and the supervised fine-tuned method SDAE. Besides, we compare the performance of our methods with that of state-of-the-art detection approaches, including classical deep-learning-based methods. Extensive experiments show that our proposed methods are effective enough to detect Android malware.},
  archive      = {J_TKDE},
  author       = {Hui-Juan Zhu and Liang-Min Wang and Sheng Zhong and Yang Li and Victor S. Sheng},
  doi          = {10.1109/TKDE.2021.3067658},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {12},
  pages        = {5558-5570},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A hybrid deep network framework for android malware detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparing alternative route planning techniques: A
comparative user study on melbourne, dhaka and copenhagen road networks.
<em>TKDE</em>, <em>34</em>(11), 5552–5557. (<a
href="https://doi.org/10.1109/TKDE.2021.3063717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many modern navigation systems and map-based services do not only provide the fastest route from a source location $s$ to a target location $t$ but also provide a few alternative routes to the users as more options to choose from. Consequently, computing alternative paths has received significant research attention. However, it is unclear which of the existing approaches generates alternative routes of better quality because the quality of these alternatives is mostly subjective. Motivated by this, in this paper, we present a user study conducted on the road networks of Melbourne, Dhaka and Copenhagen that compares the quality (as perceived by the users) of the alternative routes generated by four of the most popular existing approaches including the routes provided by Google Maps. We also present a web-based demo system that can be accessed using any internet-enabled device and allows users to see the alternative routes generated by the four approaches for any pair of selected source and target. We report the average ratings received by the four approaches and our statistical analysis shows that there is no credible evidence that the four approaches receive different ratings on average. We also discuss the limitations of this user study and recommend the readers to interpret these results with caution because certain factors may have affected the participants’ ratings.},
  archive      = {J_TKDE},
  author       = {Lingxiao Li and Muhammad Aamir Cheema and Hua Lu and Mohammed Eunus Ali and Adel N. Toosi},
  doi          = {10.1109/TKDE.2021.3063717},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5552-5557},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Comparing alternative route planning techniques: A comparative user study on melbourne, dhaka and copenhagen road networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transferable feature selection for unsupervised domain
adaptation. <em>TKDE</em>, <em>34</em>(11), 5536–5551. (<a
href="https://doi.org/10.1109/TKDE.2021.3060037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation aims at extracting knowledge from auxiliary source domains to assist the learning task in a target domain. In classification problems, since the distributions of the source and target domains are different, directly using source data to build a classifier for the target domain may hamper the classification performance on the target data. Fortunately, in many tasks, there can be some features that are transferable, i.e., the source and target domains share similar properties. On the other hand, it is common that the source data contain noisy features which may degrade the learning performance in the target domain. This issue, however, is barely studied in existing works. In this paper, we propose to find a feature subset that is transferable across the source and target domains. As a result, the domain discrepancy measured on the selected features can be reduced. Moreover, we seek to find the most discriminative features for classification. To achieve the above goals, we formulate a new sparse learning model that is able to jointly reduce the domain discrepancy and select informative features for classification. We develop two optimization algorithms to address the derived learning problem. Extensive experiments on real-world data sets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Yuguang Yan and Hanrui Wu and Yuzhong Ye and Chaoyang Bi and Min Lu and Dapeng Liu and Qingyao Wu and Michael K. Ng},
  doi          = {10.1109/TKDE.2021.3060037},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5536-5551},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Transferable feature selection for unsupervised domain adaptation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning for dynamic feature extraction using
variational bayesian inference. <em>TKDE</em>, <em>34</em>(11),
5524–5535. (<a href="https://doi.org/10.1109/TKDE.2021.3054671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven methods have been extensively utilized in establishing predictive models from historical data for process monitoring and prediction of quality variables. However, most data-driven approaches assume that training data and testing data come from steady-state operating regions and follow the same distribution, which may not be the case when it comes to complex industrial processes. To avoid these restrictive assumptions and account for practical implementation, a novel online transfer learning technique is proposed to dynamically learn cross-domain features based on the variational Bayesian inference in this work. Stemming from the probabilistic slow feature analysis, a transfer slow feature analysis (TSFA) technique is presented to transfer dynamic models learned from different source processes to enhance prediction performance in the target process. In particular, two weighting functions associated with transition and emission equations are introduced and updated dynamically to quantify the transferability from source domains to the target domain at each time instant. Instead of point estimation, a variational Bayesian inference scheme is designed to learn the parameters under probability distributions accounting for corresponding uncertainties. The effectiveness of the proposed technique with applications to soft sensor modelling is demonstrated by a simulation example, a public dataset and an industrial case study.},
  archive      = {J_TKDE},
  author       = {Junyao Xie and Biao Huang and Stevan Dubljevic},
  doi          = {10.1109/TKDE.2021.3054671},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5524-5535},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Transfer learning for dynamic feature extraction using variational bayesian inference},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pre-training time-aware location embeddings from
spatial-temporal trajectories. <em>TKDE</em>, <em>34</em>(11),
5510–5523. (<a href="https://doi.org/10.1109/TKDE.2021.3057875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing accumulation of spatial-temporal trajectory data, location-based data mining has recently been extensively studied. A fundamental research topic in this field is learning the embedding vectors of locations through self-supervised pre-training. Pre-trained embedding vectors can utilize the highly available unlabeled trajectory data, and benefit downstream tasks in multiple aspects. However, most existing methods ignore the temporal information hidden in the visited time of locations in trajectories. Considering that human activities are highly regulated by specific periods of a day, temporal information can reflect some intrinsic characteristics of locations, so it is necessary to fuse them into location embedding vectors. In this paper, we propose a Time-Aware Location Embedding (TALE) pre-training method based on the CBOW framework, which is able to incorporate temporal information into the learned embedding vectors of locations. A novel temporal tree structure is designed to extract temporal information during the calculation of Hierarchical Softmax. In order to verify the effectiveness of TALE, we apply the learned embedding vectors into three downstream location-based prediction tasks, i.e., location classification, location visitor flow prediction and user next location prediction. Experiments are conducted on four real-world user trajectory datasets, and the experimental results demonstrate that our TALE model can obviously help downstream tasks gain better performance.},
  archive      = {J_TKDE},
  author       = {Huaiyu Wan and Yan Lin and Shengnan Guo and Youfang Lin},
  doi          = {10.1109/TKDE.2021.3057875},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5510-5523},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Pre-training time-aware location embeddings from spatial-temporal trajectories},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of treatment medicines with dual adaptive
sequential networks. <em>TKDE</em>, <em>34</em>(11), 5496–5509. (<a
href="https://doi.org/10.1109/TKDE.2021.3052992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting treatment medicines is a key task in many intelligent healthcare systems. Prediction of treatment medicines can assist doctors in making informed prescription decisions for patients according to their Electronic Health Records (EHRs). However, predicting treatment medicines is a challenging task due to the following reasons: (1) heterogeneous nature of EHR data that typically includes laboratory results, treatment records, disease conditions, and demographic information; (2) complex correlations among EHR sequences, including inter-correlations between sequences and temporal intra-correlations within each sequence; (3) temporal dynamics of these correlations changing with disease progression. In this paper, we predict treatment medicines for patients with dual adaptive sequential networks (DASNet). Specifically, DASNet is designed with three components. First, a decomposed adaptive long short-term memory network (DA-LSTM) is designed to capture the intra- and inter-correlations in multiple heterogeneous temporal sequences. Then, we develop an attentive meta learning network (AT-MetaNet) to learn dynamic weight parameters for DA-LSTM, thus enabling it to model various correlation structures. Finally, we employ an attentive fusion network (AT-FuNet) to incorporate historical information and collectively fuse representation embeddings of heterogeneous data to predict treatment medicines. Our results on the public MIMIC-III dataset covering 11 medical conditions demonstrate that the proposed end-to-end model can achieve the state-of-the-art prediction performance while providing clinically useful insights.},
  archive      = {J_TKDE},
  author       = {Yang An and Liang Zhang and Haoyu Yang and Leilei Sun and Bo Jin and Chuanren Liu and Ruiyun Yu and Xiaopeng Wei},
  doi          = {10.1109/TKDE.2021.3052992},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5496-5509},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Prediction of treatment medicines with dual adaptive sequential networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Point-of-interest recommendation with global and local
context. <em>TKDE</em>, <em>34</em>(11), 5484–5495. (<a
href="https://doi.org/10.1109/TKDE.2021.3059744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of point of interest (POI) recommendation aims to recommend unvisited places to users based on their check-in history. A major challenge in POI recommendation is data sparsity, because a user typically visits only a very small number of POIs among all available POIs. In this paper, we propose AUC-MF to address the POI recommendation problem by maximizing Area Under the ROC curve (AUC). AUC has been widely used for measuring classification performance with imbalanced data distributions. To optimize AUC, we transform the recommendation task to a classification problem, where the visited locations are positive examples and the unvisited are negative ones. We define a new lambda for AUC to utilize the LambdaMF model, which combines the lambda-based method and matrix factorization model in collaborative filtering. Many studies have shown that geographic information plays an important role in POI recommendation. In this study, we focus on two levels geographic information: local similarity and global similarity. We further show that AUC-MF can be easily extended to incorporate geographical contextual information for POI recommendation. Specifically, we propose two novel methods to incorporate geographical information in AUC-MF. Different from most existing models where the contextual information are incorporated into the objective function, the incorporation of contextual information in AUC-MF is a refinement of the model and a sampling strategy. The sampling strategy could speedup convergence and the refining of recommendations is independent of training of the model. This mechanism also enables AUC-MF to be able produce recommendations refined towards different contextual information, with minimum computational cost. Experiments on two datasets show that the proposed AUC-MF outperforms state-of-the-art methods significantly in terms of recommendation accuracy.},
  archive      = {J_TKDE},
  author       = {Peng Han and Shuo Shang and Aixin Sun and Peilin Zhao and Kai Zheng and Xiangliang Zhang},
  doi          = {10.1109/TKDE.2021.3059744},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5484-5495},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Point-of-interest recommendation with global and local context},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Open named entity modeling from embedding distribution.
<em>TKDE</em>, <em>34</em>(11), 5472–5483. (<a
href="https://doi.org/10.1109/TKDE.2021.3049654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we report our discovery on named entity distribution in a general word embedding space, which helps an open definition on multilingual named entity definition rather than previous closed and constraint definition on named entities through a named entity dictionary, which is usually derived from human labor and replies on schedule update. Our initial visualization of monolingual word embeddings indicates named entities tend to gather together despite of named entity types and language difference, which enable us to model all named entities using a specific geometric structure inside embedding space, namely, the named entity hypersphere. For monolingual cases, the proposed named entity model gives an open description of diverse named entity types and different languages. For cross-lingual cases, mapping the proposed named entity model provides a novel way to build a named entity dataset for resource-poor languages. At last, the proposed named entity model may be shown as a handy clue to enhance state-of-the-art named entity recognition systems generally.},
  archive      = {J_TKDE},
  author       = {Ying Luo and Hai Zhao and Zhuosheng Zhang and Bingjie Tang},
  doi          = {10.1109/TKDE.2021.3049654},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5472-5483},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Open named entity modeling from embedding distribution},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MOLER: Incorporate molecule-level reward to enhance deep
generative model for molecule optimization. <em>TKDE</em>,
<em>34</em>(11), 5459–5471. (<a
href="https://doi.org/10.1109/TKDE.2021.3052150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of molecular optimization is to generate molecules similar to a target molecule but with better chemical properties. Deep generative models have shown great success in molecule optimization. However, due to the iterative local generation process of deep generative models, the resulting molecules can significantly deviate from the input in molecular similarity and size, leading to poor chemical properties. The key issue here is that the existing deep generative models restrict their attention on substructure-level generation without considering the entire molecule as a whole. To address this challenge, we propose Mo lecule- Le vel R eward functions ( MOLER ) to encourage (1) the input and the generated molecule to be similar, and to ensure (2) the generated molecule has a similar size to the input. The proposed method can be combined with various deep generative models. Policy gradient technique is introduced to optimize reward-based objectives with small computational overhead. Empirical studies show that MOLER achieves up to 20.2\% relative improvement in success rate over the best baseline method on several properties, including QED, DRD2 and LogP.},
  archive      = {J_TKDE},
  author       = {Tianfan Fu and Cao Xiao and Lucas M. Glass and Jimeng Sun},
  doi          = {10.1109/TKDE.2021.3052150},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5459-5471},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MOLER: Incorporate molecule-level reward to enhance deep generative model for molecule optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling dynamic user preference via dictionary learning for
sequential recommendation. <em>TKDE</em>, <em>34</em>(11), 5446–5458.
(<a href="https://doi.org/10.1109/TKDE.2021.3050407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing the dynamics in user preference is crucial to better predict user future behaviors because user preferences often drift over time. Many existing recommendation algorithms – including both shallow and deep ones – often model such dynamics independently, i.e., user static and dynamic preferences are not modeled under the same latent space, which makes it difficult to fuse them for recommendation. This paper considers the problem of embedding a user&#39;s sequential behavior into the latent space of user preferences, namely translating sequence to preference . To this end, we formulate the sequential recommendation task as a dictionary learning problem, which learns: 1) a shared dictionary matrix , each row of which represents a partial signal of user dynamic preferences shared across users; and 2) a posterior distribution estimator using a deep autoregressive model integrated with Gated Recurrent Unit (GRU), which can select related rows of the dictionary to represent a user&#39;s dynamic preferences conditioned on his/her past behaviors. Qualitative studies on the Netflix dataset demonstrate that the proposed method can capture the user preference drifts over time and quantitative studies on multiple real-world datasets demonstrate that the proposed method can achieve higher accuracy compared with state-of-the-art factorization and neural sequential recommendation methods.},
  archive      = {J_TKDE},
  author       = {Chao Chen and Dongsheng Li and Junchi Yan and Xiaokang Yang},
  doi          = {10.1109/TKDE.2021.3050407},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5446-5458},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Modeling dynamic user preference via dictionary learning for sequential recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to solve task-optimized group search for social
internet of things. <em>TKDE</em>, <em>34</em>(11), 5429–5445. (<a
href="https://doi.org/10.1109/TKDE.2021.3057361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the maturity and popularity of Internet of Things (IoT), the notion of Social Internet of Things (SIoT) has been proposed to support novel applications and networking services for the IoT in more effective and efficient ways. Although there are many works for SIoT, they focus on designing the architectures and protocols for SIoT under the specific schemes. How to efficiently utilize the collaboration capability of SIoT to complete complex tasks remains unexplored. Therefore, we propose a new problem family, namely, Task-Optimized SIoT Selection (TOSS) , to find the best group of IoT objects for a given set of tasks in the task pool. TOSS aims to select the target SIoT group such that the target SIoT group is able to easily communicate with each other while maximizing the accuracy of performing the given tasks. We propose two problem formulations, named Bounded Communication-loss TOSS (BC-TOSS) and Robustness Guaranteed TOSS (RG-TOSS) , for different scenarios and prove that they are both NP-hard and inapproximable. We propose a polynomial-time algorithm with a performance guarantee for BC-TOSS, and an efficient polynomial-time algorithm to obtain good solutions for RG-TOSS. Moreover, as RG-TOSS is NP-hard and inapproximable within any factor, we further propose Structure-Aware Reinforcement Learning (SARL) to leverage the Graph Convolutional Networks (GCN) and Deep Reinforcement Learning (DRL) to effectively solve RG-TOSS. Further, since we use graph models to simulate the problem instance for DRL, which is different from the real ones, we propose Structure-Aware Meta Reinforcement Learning (SAMRL) for fast adapting to new domains. Experimental results on multiple real datasets indicate that our proposed algorithms outperform the other deterministic and learning-based baseline approaches.},
  archive      = {J_TKDE},
  author       = {Chen-Hsu Yang and Hong-Han Shuai and Chih-Ya Shen and Ming-Syan Chen},
  doi          = {10.1109/TKDE.2021.3057361},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5429-5445},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning to solve task-optimized group search for social internet of things},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning dynamics and heterogeneity of spatial-temporal
graph data for traffic forecasting. <em>TKDE</em>, <em>34</em>(11),
5415–5428. (<a href="https://doi.org/10.1109/TKDE.2021.3056502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting is critical in improving safety, stability, and efficiency of intelligent transportation systems. Despite years of studies, accurate traffic prediction still faces the following challenges, including modeling the dynamics of trafﬁc data along both temporal and spatial dimensions, and capturing the periodicity and the spatial heterogeneity of trafﬁc data, and the problem is more difficult for long-term forecast. In this paper, we propose an Attention based Spatial-Temporal Graph Neural Network (ASTGNN) for traffic forecasting. Specifically, in the temporal dimension, we design a novel self-attention mechanism that is capable of utilizing the local context, which is specialized for numerical sequence representation transformation. It enables our prediction model to capture the temporal dynamics of traffic data and to enjoy global receptive ﬁelds that is beneficial for long-term forecast. In the spatial dimension, we develop a dynamic graph convolution module, employing self-attention to capture the spatial correlations in a dynamic manner. Furthermore, we explicitly model the periodicity and capture the spatial heterogeneity through embedding modules. Experiments on five real-world traffic flow datasets demonstrate that ASTGNN outperforms the state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Shengnan Guo and Youfang Lin and Huaiyu Wan and Xiucheng Li and Gao Cong},
  doi          = {10.1109/TKDE.2021.3056502},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5415-5428},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning dynamics and heterogeneity of spatial-temporal graph data for traffic forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intention-aware sequential recommendation with structured
intent transition. <em>TKDE</em>, <em>34</em>(11), 5403–5414. (<a
href="https://doi.org/10.1109/TKDE.2021.3050571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human behaviors in recommendation systems are driven by many high-level, complex, and evolving intentions behind their decision making processes. In order to achieve better performance, it is important for recommendation systems to be aware of user intentions besides considering the historical interaction behaviors. However, user intentions are seldom fully or easily observed in practice, so that the existing works are incapable of fully tracking and modeling user intentions, not to mention using them effectively into recommendation. In this paper, we present the I ntention-Aware S equential Rec ommendation ( ISRec ) method, for capturing the underlying intentions of each user that may lead to her next consumption behavior and improving recommendation performance. Specifically, we first extract the intentions of the target user from sequential contexts, then take complex intent transition into account through the message-passing mechanism on an intention graph, and finally obtain the future intentions of this target user from inference on the intention graph. The sequential recommendation for a user will be made based on the predicted user intentions, offering more transparent and explainable intermediate results for each recommendation. Extensive experiments on various real-world datasets demonstrate the superiority of our method against several state-of-the-art baselines in sequential recommendation in terms of different metrics.},
  archive      = {J_TKDE},
  author       = {Haoyang Li and Xin Wang and Ziwei Zhang and Jianxin Ma and Peng Cui and Wenwu Zhu},
  doi          = {10.1109/TKDE.2021.3050571},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5403-5414},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Intention-aware sequential recommendation with structured intent transition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imitation learning of neural spatio-temporal point
processes. <em>TKDE</em>, <em>34</em>(11), 5391–5402. (<a
href="https://doi.org/10.1109/TKDE.2021.3054787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel Neural Embedding Spatio-Temporal (NEST) point process model for spatio-temporal discrete event data and develop an efficient imitation learning (a type of reinforcement learning) based approach for model fitting. Despite the rapid development of one-dimensional temporal point processes for discrete event data, the study of spatial-temporal aspects of such data is relatively scarce. Our model captures complex spatio-temporal dependence between discrete events by carefully design a mixture of heterogeneous Gaussian diffusion kernels, whose parameters are parameterized by neural networks. This new kernel is the key that our model can capture intricate spatial dependence patterns and yet still lead to interpretable results as we examine maps of Gaussian diffusion kernel parameters. The imitation learning model fitting for the NEST is more robust than the maximum likelihood estimate. It directly measures the divergence between the empirical distributions between the training data and the model-generated data. Moreover, our imitation learning-based approach enjoys computational efficiency due to the explicit characterization of the reward function related to the likelihood function; furthermore, the likelihood function under our model enjoys tractable expression due to Gaussian kernel parameterization. Experiments based on real data show our method’s good performance relative to the state-of-the-art and the good interpretability of NEST’s result.},
  archive      = {J_TKDE},
  author       = {Shixiang Zhu and Shuang Li and Zhigang Peng and Yao Xie},
  doi          = {10.1109/TKDE.2021.3054787},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5391-5402},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Imitation learning of neural spatio-temporal point processes},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GPSC: A grid-based privacy-reserving framework for online
spatial crowdsourcing. <em>TKDE</em>, <em>34</em>(11), 5378–5390. (<a
href="https://doi.org/10.1109/TKDE.2021.3055623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial crowdsourcing (SC) allows requesters to crowdsource tasks to workers based on location proximity. To preserve privacy, the location should not be disclosed to untrustworthy entities (even the SC platform). Previous solutions to preserve workers’ location privacy require an online trusty third party (TTP), which is not practical in reality. In this paper, we design a framework that allows the SC platform to assign tasks to nearest workers in an online manner without knowing their actual locations. We propose an encryption algorithm to encrypt the locations of tasks and workers, and design an indexing method that assigns tasks to workers without losing too much privacy. We prove that there exists a trade-off between efficiency and security theoretically, which can be controlled based on user preference. We verify our method on real-world datasets and experimental results show that our method is efficient, effective and practical.},
  archive      = {J_TKDE},
  author       = {Haoda Li and Qiyang Song and Guoliang Li and Qi Li and Rengui Wang},
  doi          = {10.1109/TKDE.2021.3055623},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5378-5390},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GPSC: A grid-based privacy-reserving framework for online spatial crowdsourcing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast error-bounded distance distribution computation.
<em>TKDE</em>, <em>34</em>(11), 5364–5377. (<a
href="https://doi.org/10.1109/TKDE.2021.3058241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we study the distance distribution computation problem. It has been widely used in many real-world applications, e.g., human genome clustering, cosmological model analysis, and parameter tuning. The straightforward solution for the exact distance distribution computation problem is unacceptably slow due to (i) massive data size, and (ii) expensive distance computation. In this paper, we propose a novel method to compute approximate distance distributions with error bound guarantees. Furthermore, our method is generic to different distance measures. We conduct extensive experimental studies on three widely used distance measures with real-world datasets. The experimental results demonstrate that our proposed method outperforms the sampling-based solution (without error guarantees) by up to three orders of magnitude.},
  archive      = {J_TKDE},
  author       = {Jiahao Zhang and Man Lung Yiu and Bo Tang and Qing Li},
  doi          = {10.1109/TKDE.2021.3058241},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5364-5377},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast error-bounded distance distribution computation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimating the total volume of queries to a search engine.
<em>TKDE</em>, <em>34</em>(11), 5351–5363. (<a
href="https://doi.org/10.1109/TKDE.2021.3054668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of estimating the total number of searches (volume) of queries in a specific domain, which were submitted to a search engine in a given time period. Our statistical model assumes that the distribution of searches follows a Zipf’s law, and that the observed sample volumes are biased accordingly to three possible scenarios. These assumptions are consistent with empirical data, with keyword research practices, and with approximate algorithms used to take counts of query frequencies. A few estimators of the parameters of the distribution are devised and experimented, based on the nature of the empirical/simulated data. For continuous data, we recommend using nonlinear least square regression (NLS) on the top-volume queries, where the bound on the volume is obtained from the well-known Clauset, Shalizi and Newman (CSN) estimation of power-law parameters. For binned data, we propose using a Chi-square minimization approach restricted to the top-volume queries, where the bound is obtained by the binned version of the CSN method. Estimations are then derived for the total number of queries and for the total volume of the population, including statistical error bounds. We apply the methods on the domain of recipes and cooking queries searched in Italian in 2017. The observed volumes of sample queries are collected from Google Trends (continuous data) and SearchVolume (binned data). The estimated total number of queries and total volume are computed for the two cases, and the results are compared and discussed.},
  archive      = {J_TKDE},
  author       = {Fabrizio Lillo and Salvatore Ruggieri},
  doi          = {10.1109/TKDE.2021.3054668},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5351-5363},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Estimating the total volume of queries to a search engine},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Erasable virtual HyperLogLog for approximating cumulative
distribution over data streams. <em>TKDE</em>, <em>34</em>(11),
5336–5350. (<a href="https://doi.org/10.1109/TKDE.2021.3052938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world datasets are given in the stream of entity-identifier pairs, and measuring data distribution on these datasets is fundamental for applications such as privacy protection. In this paper, we study the problem of computing the cumulative distribution for different cardinalities (i.e., the number of distinct entities owning the same identifier). However, previous sketch-based methods cost large memory space especially when there are a large number of identifiers, and sampling-based methods require much time for cardinality estimation. A recent work KHyperLogLog combines both sketch and sampling methods but it is wasteful to separately build a HyperLogLog sketch of large size for identifiers with small cardinalities. To address these challenges, we propose a memory-efficient method EV-HLL, which designs a shared structure to store all sampled identifiers and their entities and utilizes additional sketches to track value updates during the sampling procedure. Meanwhile, EV-HLL provides real-time unbiased estimations according to value changes whenever a new entity-identifier pair arrives. We evaluate the performance of EV-HLL and other state-of-the-arts on real-world available datasets. Experimental results demonstrate that comparing to other methods, EV-HLL effectively reduces their memory usage with the same estimation accuracy and has higher accuracy with the same memory usage.},
  archive      = {J_TKDE},
  author       = {Peng Jia and Pinghui Wang and Junzhou Zhao and Jing Tao and Ye Yuan and Xiaohong Guan},
  doi          = {10.1109/TKDE.2021.3052938},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5336-5350},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Erasable virtual HyperLogLog for approximating cumulative distribution over data streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient sink-reachability analysis via graph reduction.
<em>TKDE</em>, <em>34</em>(11), 5321–5335. (<a
href="https://doi.org/10.1109/TKDE.2021.3052710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reachability problem on directed graphs, asking whether two vertices are connected via a directed path, is an elementary problem that has been well-studied. In this paper, we study a variation of the elementary reachability problem, called the sink-reachability problem, which can be found in many applications such as static program analysis, social network analysis, large scale web graph analysis, XML document link path analysis, and the study of gene regulation relationships. To scale sink-reachablity analysis to large graphs, we develop a highly scalable sink-reachability preserving graph reduction strategy for input sink graphs, by using a composition framework. That is, individual sink-reachability preserving condensation operators, each running in linear time, are pipelined together to produce graph reduction algorithms that result in close to maximum reduction, while keeping the computation efficient. Experiments on large real-world sink graphs demonstrate the efficiency and effectiveness of our compositional approach to sink-reachability preserving graph reduction with a reduction rate of up to 99.74 percent for vertices and a rate of up to 99.46 percent for edges.},
  archive      = {J_TKDE},
  author       = {Jens Dietrich and Lijun Chang and Long Qian and Lyndon M. Henry and Catherine McCartin and Bernhard Scholz},
  doi          = {10.1109/TKDE.2021.3052710},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5321-5335},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient sink-reachability analysis via graph reduction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient and effective multi-modal queries through
heterogeneous network embedding. <em>TKDE</em>, <em>34</em>(11),
5307–5320. (<a href="https://doi.org/10.1109/TKDE.2021.3052871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heterogeneity of today’s Web sources requires information retrieval (IR) systems to handle multi-modal queries. Such queries define a user’s information needs by different data modalities, such as keywords, hashtags, user profiles, and other media. Recent IR systems answer such a multi-modal query by considering it as a set of separate uni-modal queries. However, depending on the chosen operationalisation, such an approach is inefficient or ineffective. It either requires multiple passes over the data or leads to inaccuracies since the relations between data modalities are neglected in the relevance assessment. To mitigate these challenges, we present an IR system that has been designed to answer genuine multi-modal queries. It relies on a heterogeneous network embedding, so that features from diverse modalities can be incorporated when representing both, a query and the data over which it shall be evaluated. By embedding a query and the data in the same vector space, the relations across modalities are made explicit and exploited for more accurate query evaluation. At the same time, multi-modal queries are answered with a single pass over the data. An experimental evaluation using diverse real-world and synthetic datasets illustrates that our approach returns twice the amount of relevant information compared to baseline techniques, while scaling to large multi-modal databases.},
  archive      = {J_TKDE},
  author       = {Chi Thang Duong and Thanh Tam Nguyen and Hongzhi Yin and Matthias Weidlich and Thai Son Mai and Karl Aberer and Quoc Viet Hung Nguyen},
  doi          = {10.1109/TKDE.2021.3052871},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5307-5320},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient and effective multi-modal queries through heterogeneous network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discovering structural errors from business process event
logs. <em>TKDE</em>, <em>34</em>(11), 5293–5306. (<a
href="https://doi.org/10.1109/TKDE.2021.3052927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining aims at discovering behavioral knowledge of business processes from their event logs, which has received an increasing attention in the era of cloud computing and big data. Surprisingly, to date, discovering structural errors (e.g., deadlocks and lack of synchronization) from event logs has not been considered in state-of-the-art process mining techniques. Moreover, existing process discovery approaches cannot be directly applied to event logs of processes with structural errors due to erroneous event occurrences caused by unsynchronized activities. To address this problem, we first preprocess the event log to obtain two separate event logs that are used to discover deadlocks and lack of synchronization, respectively. Erroneous event occurrences caused by unsynchronized activities are discarded in the two processed event logs, from which our error mining algorithms can discover all process fragments involving structural errors, without the need to obtain the overall process first. We implement our approach in a ProM plugin and evaluate it on event logs of real-life business processes, the results of which demonstrate that our approach can effectively and efficiently discover deadlocks and lack of synchronization if event logs contain sufficient event sequences.},
  archive      = {J_TKDE},
  author       = {Wei Song and Zhen Chang and Hans-Arno Jacobsen and Pengcheng Zhang},
  doi          = {10.1109/TKDE.2021.3052927},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5293-5306},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Discovering structural errors from business process event logs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differentially private triangle counting in large graphs.
<em>TKDE</em>, <em>34</em>(11), 5278–5292. (<a
href="https://doi.org/10.1109/TKDE.2021.3052827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triangle count is a critical parameter in mining relationships among people in social networks. However, directly publishing the findings obtained from triangle counts may bring potential privacy concern, which raises great challenges and opportunities for privacy-preserving triangle counting. In this paper, we choose to use differential privacy to protect triangle counting for large scale graphs. To reduce the large sensitivity caused in large graphs, we propose a novel graph projection method that can be used to obtain an upper bound for sensitivity in different distributions. In particular, we publish the triangle counts satisfying the node-differential privacy with two kinds of histograms: the triangle count distribution and the cumulative distribution. Moreover, we extend the research on privacy preserving triangle counting to one of its applications, the local clustering coefficient. Experimental results show that the cumulative distribution can fit the real statistical information better, and our proposed mechanism has achieved better accuracy for triangle counts while maintaining the requirement of differential privacy.},
  archive      = {J_TKDE},
  author       = {Xiaofeng Ding and Shujun Sheng and Huajian Zhou and Xiaodong Zhang and Zhifeng Bao and Pan Zhou and Hai Jin},
  doi          = {10.1109/TKDE.2021.3052827},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5278-5292},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Differentially private triangle counting in large graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Density-based top-k spatial textual clusters retrieval.
<em>TKDE</em>, <em>34</em>(11), 5263–5277. (<a
href="https://doi.org/10.1109/TKDE.2021.3049785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {So-called spatial web queries retrieve web content representing points of interest, such that the points of interest have descriptions that are relevant to query keywords and are located close to a query location. Two broad categories of such queries exist. The first encompasses queries that retrieve single spatial web objects that each satisfy the query arguments. Most proposals belong to this category. The second category, to which this paper&#39;s proposal belongs, encompasses queries that support exploratory user behavior and retrieve sets of objects that represent regions of space that may be of interest to the user. Specifically, the paper proposes a new type of query, the top- $k$ spatial textual cluster retrieval ( $k$ -STC) query that returns the top- $k$ clusters that (i) are located close to a query location, (ii) contain objects that are relevant with regard to given query keywords, and (iii) have an object density that exceeds a given threshold. To compute this query, we propose a DBSCAN-based approach and an OPTICS-based approach that rely on on-line density-based clustering and that exploit early stop conditions. Empirical studies on real data sets offer evidence that the paper&#39;s proposals can find good quality clusters and are capable of excellent performance.},
  archive      = {J_TKDE},
  author       = {Dingming Wu and Ilkcan Keles and Song Wu and Hao Zhou and Simonas Šaltenis and Christian S. Jensen and Kezhong Lu},
  doi          = {10.1109/TKDE.2021.3049785},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5263-5277},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Density-based top-K spatial textual clusters retrieval},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep bayesian active learning for learning to rank: A case
study in answer selection. <em>TKDE</em>, <em>34</em>(11), 5251–5262.
(<a href="https://doi.org/10.1109/TKDE.2021.3056894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a question and a set of candidate answers, answer selection is the task of identifying the best answer, which can be viewed as a kind of learning-to-rank tasks. Learning to rank arises in many information retrieval applications, where deep learning models can achieve inspiring results. Training a deep learning model often requires large scale annotated data that are expensive and time-consuming to obtain. Active learning presents a promising approach to this problem by selecting more informative training data to reduce the amount of labelling efforts required. Because traditional active learning methods cannot be directly used for deep learning, researchers have proposed multiple deep active learning methods. However, none of the previous research efforts on deep active learning algorithms presents a specific framework for learning-to-rank tasks. In this work, we introduce a novel deep active learning framework based on D eep E xpected L oss O ptimization (DELO) for the answer selection task. It adopts a data acquisition function based on model uncertainty with Bayesian deep learning and the expected loss optimization. Moreover, a two-step batch-mode procedure, combining DELO and other data acquisition strategies is proposed to further improve the performance of active learning. Experimental results verify the effectiveness of the proposed framework.},
  archive      = {J_TKDE},
  author       = {Qunbo Wang and Wenjun Wu and Yuxing Qi and Yongchi Zhao},
  doi          = {10.1109/TKDE.2021.3056894},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5251-5262},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep bayesian active learning for learning to rank: A case study in answer selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CPiX: Real-time analytics over out-of-order data streams by
incremental sliding-window aggregation. <em>TKDE</em>, <em>34</em>(11),
5239–5250. (<a href="https://doi.org/10.1109/TKDE.2021.3054898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stream processing is used in various fields. In the field of big data, stream aggregation is a popular processing technique, but it suffers serious setbacks when the order of events (e.g., stream elements) occurring is different from the order of events arriving to the systems. Such data streams are called “non-FIFO steams”. This phenomenon usually occurs in a distributed environment due to many factors, such as network disruptions, delays, etc. Many analyzing scenarios require efficient processing of such non-FIFO streams to meet various data processing requirements. This paper proposes an efficient scalable checkpoint-based bidirectional indexing approach, called $CPiX$ , for faster real-time analysis over non-FIFO streams. CPiX maintains the partial aggregation results in an on-demand manner per checkpoint. CPiX needs less time and space than the state-of-the-art approach. Extensive experiments confirm that CPiX can deal with out-of-order streams very efficiently and is, on average, about 3.8 times faster than the state-of-the-art approach while consuming less memory.},
  archive      = {J_TKDE},
  author       = {Savong Bou and Hiroyuki Kitagawa and Toshiyuki Amagasa},
  doi          = {10.1109/TKDE.2021.3054898},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5239-5250},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CPiX: Real-time analytics over out-of-order data streams by incremental sliding-window aggregation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-aware service recommendation based on knowledge
graph embedding. <em>TKDE</em>, <em>34</em>(11), 5225–5238. (<a
href="https://doi.org/10.1109/TKDE.2021.3059506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over two decades, context awareness has been incorporated into recommender systems in order to provide, not only the top-rated items to consumers but also the ones that are suitable to the user context. As a class of context-aware systems, context-aware service recommendation (CASR) aims to bind high-quality services to users, while taking into account their context requirements, including invocation time, location, social profiles, connectivity, and so on. However, current CASR approaches are not scalable with the huge amount of service data (QoS and context information, users reviews and feedbacks). In addition, they lack a rich representation of contextual information, as they adopt a simple matrix view. Moreover, current CASR approaches adopt the traditional user-service relation and they do not allow for multi-relational interactions between users and services in different contexts. To offer a scalable and context-sensitive service recommendation with great analysis and learning capabilities, we provide a rich and multi-relational representation of the CASR knowledge, based on the concept of knowledge graph. The constructed context-aware service knowledge graph (C-SKG) is, then, transformed into a low-dimensional vector space to facilitate its processing. For this purpose, we adopt Dilated Recurrent Neural Networks to propose a context-aware knowledge graph embedding, based on the principles of first-order and subgraph-aware proximity. Finally, a recommendation algorithm is defined to deliver the top-rated services according to the target user&#39;s context. Experiments have proved the accuracy and scalability of our solution, compared to state-of-the-art CASR approaches.},
  archive      = {J_TKDE},
  author       = {Haithem Mezni and Djamal Benslimane and Ladjel Bellatreche},
  doi          = {10.1109/TKDE.2021.3059506},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5225-5238},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Context-aware service recommendation based on knowledge graph embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auditing network embedding: An edge influence based
approach. <em>TKDE</em>, <em>34</em>(11), 5211–5224. (<a
href="https://doi.org/10.1109/TKDE.2021.3056884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning node representations in a network has a wide range of applications. Most of the existing work focuses on improving the performance of the learned node representations by designing advanced network embedding models. In contrast to these work, this article aims to provide some understanding of the rationale behind the existing network embedding models, e.g., why a given embedding algorithm outputs the specific node representations and how the resulting node representations relate to the structure of the input network. In particular, we propose to discern the edge influence for two widely-studied classes of network embedding models, i.e., skip-gram based models and graph neural networks. We provide algorithms to effectively and efficiently quantify the edge influence on node representations, and further identify high-influential edges by exploiting the linkage between edge influence and network structure. Experimental evaluations are conducted on real datasets showing that: 1) in terms of quantifying edge influence, the proposed method is significantly faster (up to $2,000\times$ ) than straightforward methods with little quality loss, and 2) in terms of identifying high-influential edges, the identified edges by the proposed method have a significant impact in the context of downstream prediction task and adversarial attacking.},
  archive      = {J_TKDE},
  author       = {Yaojing Wang and Yuan Yao and Hanghang Tong and Feng Xu and Jian Lu},
  doi          = {10.1109/TKDE.2021.3056884},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5211-5224},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Auditing network embedding: An edge influence based approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attentive representation learning with adversarial training
for short text clustering. <em>TKDE</em>, <em>34</em>(11), 5196–5210.
(<a href="https://doi.org/10.1109/TKDE.2021.3052244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short text clustering has far-reaching effects on semantic analysis, showing its importance for multiple applications such as corpus summarization and information retrieval. However, it inevitably encounters the severe sparsity of short text representations, making the previous clustering approaches still far from satisfactory. In this paper, we present a novel attentive representation learning model for shot text clustering, wherein cluster-level attention is proposed to capture the correlations between text representations and cluster representations. Relying on this, the representation learning and clustering for short texts are seamlessly integrated into a unified model. To further ensure robust model training for short texts, we apply adversarial training to the unsupervised clustering setting, by injecting perturbations into the cluster representations. The model parameters and perturbations are optimized alternately through a minimax game. Extensive experiments on four real-world short text datasets demonstrate the superiority of the proposed model over several strong competitors, verifying that robust adversarial training yields substantial performance gains.},
  archive      = {J_TKDE},
  author       = {Wei Zhang and Chao Dong and Jianhua Yin and Jianyong Wang},
  doi          = {10.1109/TKDE.2021.3052244},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5196-5210},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Attentive representation learning with adversarial training for short text clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An unsupervised bayesian neural network for truth discovery
in social networks. <em>TKDE</em>, <em>34</em>(11), 5182–5195. (<a
href="https://doi.org/10.1109/TKDE.2021.3054853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of estimating event truths from conflicting agent opinions in a social network is investigated. An autoencoder learns the complex relationships between event truths, agent reliabilities and agent observations. A Bayesian network model is proposed to guide the learning process by modeling the relationship of the autoencoder&#39;s outputs with different variables. At the same time, it also models the social relationships between agents in the network. The proposed approach is unsupervised and is applicable when ground truth labels of events are unavailable. A variational inference method is used to jointly estimate the hidden variables in the Bayesian network and the parameters in the autoencoder. Experiments on three real datasets demonstrate that our proposed approach is competitive with, and in most cases better than, several state-of-the-art benchmark methods.},
  archive      = {J_TKDE},
  author       = {Jielong Yang and Wee Peng Tay},
  doi          = {10.1109/TKDE.2021.3054853},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5182-5195},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An unsupervised bayesian neural network for truth discovery in social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An online offline framework for anomaly scoring and
detecting new traffic in network streams. <em>TKDE</em>,
<em>34</em>(11), 5166–5181. (<a
href="https://doi.org/10.1109/TKDE.2021.3050400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network data constantly evolves with new network applications and protocols. There is a need for robust techniques to detect anomalous behaviour. Offline models trained with static data lose validity when new variants of traffic emerge. They require retraining but the need for ground truth and lengthy training times make this task challenging. Meanwhile, online models which detect outliers in streaming data are susceptible to the curse of dimensionality and natural variability. Today’s anomalies may be tomorrow’s new traffic and existing methods do not provide a way to differentiate between them. We propose a framework that makes the most of both approaches: an offline deep learning model extracts features of normal traffic and provides a bias for an online outlier detection model to select data for training. The online model retains its previously learnt knowledge and retrains itself with new data. Online thresholds are updated in a drifting manner and the Mann-Whitney U test is incorporated to prevent inaccurate updates. We perform analysis on the scores, develop heuristics to detect new traffic and evaluate using three deep learning models and four outlier detection methods on the UNSW-NB15 and CTU-13 datasets. The framework improves upon any individual offline or online models in isolation.},
  archive      = {J_TKDE},
  author       = {Murugaraj Odiathevar and Winston K.G. Seah and Marcus Frean and Alvin Valera},
  doi          = {10.1109/TKDE.2021.3050400},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5166-5181},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An online offline framework for anomaly scoring and detecting new traffic in network streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An integrated multi-task model for fake news detection.
<em>TKDE</em>, <em>34</em>(11), 5154–5165. (<a
href="https://doi.org/10.1109/TKDE.2021.3054993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news detection attracts many researchers’ attention due to the negative impacts on the society. Most existing fake news detection approaches mainly focus on semantic analysis of news’ contents. However, the detection performance will dramatically decrease when the content of news is short. In this paper, we propose a novel fake news detection multi-task learning (FDML) model based on the following observations: 1) some certain topics have higher percentages of fake news; and 2) some certain news authors have higher intentions to publish fake news. FDML model investigates the impact of topic labels for the fake news and introduce contextual information of news at the same time to boost the detection performance on the short fake news. Specifically, the FDML model consists of representation learning and multi-task learning parts to train the fake news detection task and the news topic classification task, simultaneously. As far as we know, this is the first fake news detection work that integrates the above two tasks. The experiment results show that the FDML model outperforms state-of-the-art methods on real-world fake news dataset.},
  archive      = {J_TKDE},
  author       = {Qing Liao and Heyan Chai and Hao Han and Xiang Zhang and Xuan Wang and Wen Xia and Ye Ding},
  doi          = {10.1109/TKDE.2021.3054993},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5154-5165},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An integrated multi-task model for fake news detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Achieving privacy-preserving and lightweight truth discovery
in mobile crowdsensing. <em>TKDE</em>, <em>34</em>(11), 5140–5153. (<a
href="https://doi.org/10.1109/TKDE.2021.3054409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To obtain reliable results from conflicting data in mobile crowdsensing, numerous truth discovery protocols have been proposed in the past decade. However, most of them do not consider the data privacy of entities involved (e.g., workers and servers), and several existing privacy-preserving truth discovery protocols either provide limited privacy protection or have heavy computation and communication overheads due to iterative computation and transmission over large ciphertexts. In this paper, we aim to propose privacy-preserving and lightweight truth discovery protocols to tackle the above problems. Specifically, we carefully design an anonymization protocol named AnonymTD to delink workers from their data, where workers’ data are computed and transmitted without complicated encryption. To further reduce each worker&#39;s overheads in the scenarios where workers are willing to share their weights, we resort to the perturbation technology to propose a more lightweight truth discovery protocol named PerturbTD. Based on workers’ perturbed data, two cloud servers in PerturbTD complete most of the workload of truth discovery together, which avoids the frequent involvement of workers. The theoretical analysis and the comparative experiments in this paper demonstrate that our two protocols can achieve our security goals with low computation and communication overheads.},
  archive      = {J_TKDE},
  author       = {Jianchao Tang and Shaojing Fu and Ximeng Liu and Yuchuan Luo and Ming Xu},
  doi          = {10.1109/TKDE.2021.3054409},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5140-5153},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Achieving privacy-preserving and lightweight truth discovery in mobile crowdsensing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified collaborative representation learning for
neural-network based recommender systems. <em>TKDE</em>,
<em>34</em>(11), 5126–5139. (<a
href="https://doi.org/10.1109/TKDE.2021.3054782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the boosting of neural networks, recommendation methods become significantly improved by their powerful ability of prediction and inference. Existing neural-network based recommender systems (NN-RSs) usually first employ matrix embedding (ME) as a pre-process to learn users’ and items’ representations (latent vectors), then input these representations to a specific modified neural network framework to make accurate Top-k recommendations. Obviously, the performance of ME has a significant effect on RS models. However, most NN-RSs focus on accuracy by building representations from the direct user-item interactions (e.g., user-item rating matrix), while ignoring the underlying relatedness between users and items (e.g., users who rate the same ratings for the same items should be embedded into similar representations), which is an ideological disadvantage. On the other hand, ME models directly employ inner products as a default loss function metric that cannot project users and items into a proper latent space, which is a methodological disadvantage. In this paper, we propose a supervised collaborative representation learning model - Magnetic Metric Learning (MML) - to map users and items into a unified latent vector space, enhancing the representation learning for NN-RSs. First, MML utilizes dual triplets to model not only the observed relationships between users and items, but also the underlying relationships between users as well as items to overcome the ideological disadvantage. Specifically, a modified metric-based dual loss function is proposed in MML to gather similar entities and disperse the dissimilar ones. With MML, we can easily compare all the relationships (user to user, item to item, user to item) according to the weighted metric, which overcomes the methodological disadvantage. We conduct extensive experiments on four real-world datasets with large item space. The results demonstrate that MML can learn a proper unified latent space for representations from the user-item matrix with high accuracy and effectiveness, and lead to a performance gain over the state-of-the-art RS models by an average of 17 percent.},
  archive      = {J_TKDE},
  author       = {Yuanbo Xu and En Wang and Yongjian Yang and Yi Chang},
  doi          = {10.1109/TKDE.2021.3054782},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5126-5139},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A unified collaborative representation learning for neural-network based recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A semantic network encoder for associated fact prediction.
<em>TKDE</em>, <em>34</em>(11), 5114–5125. (<a
href="https://doi.org/10.1109/TKDE.2021.3053389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic network is a network of concepts connected by semantic relations. It contains two forms of binary semantic network and multiplex semantic network . The associated fact prediction is a link prediction task that aims to infer the implicitly connected facts by mining the high-level representation of the network. Previous methods for associated fact prediction put much emphasis on the topological feature of network but not utilize the information of semantic expression. This paper proposes a Sem antic N etwork E ncoder ( SemNE ), which learns a feature mapping function from the binary semantic networks and can be applied to the multiplex semantic networks in a pre-training manner. SemNE is a two-stage framework that contains an embedding encoder and a prediction decoder. It jointly models the semantic information and network topology to enrich the network representation. A word self-organization method based on the factual boundary is proposed to unify the topological feature and the semantic feature representations. Experimental results on binary semantic networks show that SemNE achieves the state-of-the-art results in associated fact prediction and experimental results on multiplex semantic networks show that SemNE is scalable and can effectively improve the performance of existing models.},
  archive      = {J_TKDE},
  author       = {Zhizheng Wang and Yuanyuan Sun and Xuyang Hu and Jiafeng Zhao and Zhihao Yang and Hongfei Lin},
  doi          = {10.1109/TKDE.2021.3053389},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5114-5125},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A semantic network encoder for associated fact prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel probabilistic label enhancement algorithm for
multi-label distribution learning. <em>TKDE</em>, <em>34</em>(11),
5098–5113. (<a href="https://doi.org/10.1109/TKDE.2021.3054465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel probabilistic label enhancement algorithm, called PLEA, to solve challenging label distribution learning (LDL) for multi-label classification problems. We adopt the well-known maximum entropy model based label distribution learner. However, unlike the existing LDL algorithms based on the maximum entropy model, we propose to use manifold learning to enhance the label distribution learner. Specifically, the supervised information in the label manifold is utilized in the feature manifold space construction to improve the accuracy of feature extraction, while dramatically reducing the feature dimension. Then the robust linear regression is employed to estimate the label distributions associated with the extracted reduced-dimension features. Using the enhanced reduced-dimension features and their associated estimated label distributions in the maximum entropy model, the unknown true label distributions can be estimated more accurately, while imposing considerably lower computational complexity. We evaluate the proposed PLEA method on a wide-range artificial and high-dimensional real-world datasets. Experimental results obtained demonstrate that our proposed PLEA method has advantages in LDL accuracy and runtime performance, compared to the latest multi-label LDL approaches. The results also show that our PLEA compares favourably with the state-of-the-arts multi-label learning algorithms for classification tasks.},
  archive      = {J_TKDE},
  author       = {Chao Tan and Sheng Chen and Genlin Ji and Xin Geng},
  doi          = {10.1109/TKDE.2021.3054465},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5098-5113},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A novel probabilistic label enhancement algorithm for multi-label distribution learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new belief-based incomplete pattern unsupervised
classification method. <em>TKDE</em>, <em>34</em>(11), 5084–5097. (<a
href="https://doi.org/10.1109/TKDE.2021.3049511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clustering of incomplete patterns is a very challenging task because the estimations may negatively affect the distribution of real centers and thus cause uncertainty and imprecision in the results. To address this problem, a new belief-based incomplete pattern unsupervised classification method (BPC) is proposed in this paper. First, the complete patterns are grouped into a few clusters by a classical soft method like fuzzy $c$ -means to obtain the corresponding reliable centers and thereby are partitioned into reliable patterns and unreliable ones by an optimization method. Second, a basic classifier trained by reliable patterns is employed to classifies unreliable patterns and the incomplete patterns edited by the neighbors. In this way, most of the edited incomplete patterns can be submitted to specific clusters. Finally, some ambiguous patterns will be carefully repartitioned again by a new distance-based rule depending on the obtained reliable centers and belief functions theory. By doing this, a few patterns that are very difficult to classify between different specific clusters will be reasonably submitted to meta-cluster which can characterize the uncertainty and imprecision of the clusters due to missing values. The simulation results show that the BPC has the potential to deal with real datasets.},
  archive      = {J_TKDE},
  author       = {Zuo-Wei Zhang and Zhe Liu and Zong-Fang Ma and Yiru Zhang and Hao Wang},
  doi          = {10.1109/TKDE.2021.3049511},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5084-5097},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A new belief-based incomplete pattern unsupervised classification method},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A high performance concurrency protocol for smart contracts
of permissioned blockchain. <em>TKDE</em>, <em>34</em>(11), 5070–5083.
(<a href="https://doi.org/10.1109/TKDE.2021.3059959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the emergence of the programmable smart contract makes blockchain systems easily embrace a wide range of industrial services, how to execute smart contracts efficiently becomes a big challenge nowadays. Due to the existence of Byzantine nodes, existing mature concurrency control protocols in database cannot be employed directly, since the mechanism of executing smart contracts varies a lot. Furthermore, even though smart contract execution follows a two-phase style, i.e., the primary node executes a batch of smart contracts in the first phase and the validators replay them in the second phase, existing parallel solutions merely focus on the optimization for the first phase, rather than the second phase. In this paper, we propose a novel two-phase concurrency control protocol to optimize both phases for the first time. First, the primary executes transactions in parallel and generates a transaction dependency graph with high parallelism for validators. Then, a graph partition algorithm is devised to divide the original graph into several sub-graphs to preserve parallelism and reduce communication cost remarkably. Finally, we propose a deterministic replay protocol to re-execute the primary’s parallel schedule concurrently. Moreover, this two-phase protocol is further optimized by integrating with PBFT. Theoretical analysis and extensive experimental results illustrate that the proposed scheme outperforms state-of-art solutions significantly.},
  archive      = {J_TKDE},
  author       = {Cheqing Jin and Shuaifeng Pang and Xiaodong Qi and Zhao Zhang and Aoying Zhou},
  doi          = {10.1109/TKDE.2021.3059959},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5070-5083},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A high performance concurrency protocol for smart contracts of permissioned blockchain},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A general framework for feature selection under orthogonal
regression with global redundancy minimization. <em>TKDE</em>,
<em>34</em>(11), 5056–5069. (<a
href="https://doi.org/10.1109/TKDE.2021.3059523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has attracted a lot of attention in obtaining discriminative and non-redundant features from high-dimension data. Compared with traditional filter and wrapper methods, embedded methods can obtain a more informative feature subset by fully considering the importance of features in the classification tasks. However, the existing embedded methods emphasize the above importance of features and mostly ignore the correlation between the features, which leads to retain the correlated and redundant features with similar scores in the feature subset. To solve the problem, we propose a novel supervised embedded feature selection framework, called feature selection under global redundancy minimization in orthogonal regression (GRMOR). The proposed framework can effectively recognize redundant features from a global view of redundancy among the features. We also incorporate the large margin constraint into GRMOR for robust multi-class classification. Compared with the traditional embedded methods based on least square regression, the proposed framework utilizes orthogonal regression to preserve more discriminative information in the subspace, which can help accurately rank the importance of features in the classification tasks. Experimental results on twelve public datasets demonstrate that the proposed framework can obtain superior classification performance and redundancy removal performance than twelve other feature selection methods.},
  archive      = {J_TKDE},
  author       = {Xueyuan Xu and Xia Wu and Fulin Wei and Wei Zhong and Feiping Nie},
  doi          = {10.1109/TKDE.2021.3059523},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {11},
  pages        = {5056-5069},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A general framework for feature selection under orthogonal regression with global redundancy minimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stable community detection in signed social networks.
<em>TKDE</em>, <em>34</em>(10), 5051–5055. (<a
href="https://doi.org/10.1109/TKDE.2020.3047224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is one of the most fundamental problems in social network analysis, while most existing research focuses on unsigned graphs. In real applications, social networks involve not only positive relationships but also negative ones. It is important to exploit the signed information to identify more stable communities. In this paper, we propose a novel model, named stable $k$ -core, to measure the stability of a community in signed graphs. The stable $k$ -core model not only emphasizes user engagement, but also eliminates unstable structures. We show that the problem of finding the maximum stable $k$ -core is NP-hard. To scale for large graphs, novel pruning strategies and searching methods are proposed. We conduct extensive experiments on 6 real-world signed networks to verify the efficiency and effectiveness of proposed model and techniques.},
  archive      = {J_TKDE},
  author       = {Renjie Sun and Chen Chen and Xiaoyang Wang and Ying Zhang and Xun Wang},
  doi          = {10.1109/TKDE.2020.3047224},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {5051-5055},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Stable community detection in signed social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weighted aggregating stochastic gradient descent for
parallel deep learning. <em>TKDE</em>, <em>34</em>(10), 5037–5050. (<a
href="https://doi.org/10.1109/TKDE.2020.3047894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the stochastic optimization problem focusing on developing scalable parallel algorithms for deep learning tasks. Our solution involves a reformation of the objective function for stochastic optimization in neural network models, along with a novel parallel computing strategy, coined the weighted aggregating stochastic gradient descent ( WASGD ). Following a theoretical analysis on the characteristics of the new objective function, WASGD introduces a decentralized weighted aggregating scheme based on the performance of local workers. Without any center variable, the new method automatically gauges the importance of local workers and accepts them by their contributions. Furthermore, we have developed an enhanced version of the method, WASGD+ , by (1) implementing a designed sample order and (2) upgrading the weight evaluation function. To validate the new method, we benchmark our pipeline against several popular algorithms including the state-of-the-art deep neural network classifier training techniques (e.g., elastic averaging SGD). Comprehensive validation studies have been conducted on four classic datasets: CIFAR-100 , CIFAR-10 , Fashion-MNIST , and MNIST . Subsequent results have firmly validated the superiority of the WASGD scheme in accelerating the training of deep architecture. Better still, the enhanced version, WASGD+ , is shown to be a significant improvement over its prototype.},
  archive      = {J_TKDE},
  author       = {Pengzhan Guo and Zeyang Ye and Keli Xiao and Wei Zhu},
  doi          = {10.1109/TKDE.2020.3047894},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {5037-5050},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Weighted aggregating stochastic gradient descent for parallel deep learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video monitoring queries. <em>TKDE</em>, <em>34</em>(10),
5023–5036. (<a href="https://doi.org/10.1109/TKDE.2020.3048606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in video processing utilizing deep learning primitives achieved breakthroughs in fundamental problems in video analysis such as frame classification and object detection enabling an array of new applications. In this paper we study the problem of interactive declarative query processing on video streams. In particular we introduce a set of approximate filters to speed up queries that involve objects of specific type (e.g., cars, trucks, etc.) on video frames with associated spatial relationships among them (e.g., car left of truck). The resulting filters are able to assess quickly if the query predicates are true to proceed with further analysis of the frame or otherwise not consider the frame further avoiding costly object detection operations. We propose two classes of filters $IC$ and $OD$ , that adapt principles from deep image classification and object detection. The filters utilize extensible deep neural architectures and are easy to deploy and utilize. In addition, we propose statistical query processing techniques to process aggregate queries involving objects with spatial constraints on video streams and demonstrate experimentally the resulting increased accuracy on the resulting aggregate estimation. Finally, we introduce a framework based on extreme value theory to detect unexpected objects on video streams and experimentally demonstrate its utility. Combined these techniques constitute a robust set of video monitoring query processing techniques. We demonstrate that the application of the techniques proposed in conjunction with declarative queries on video streams can dramatically increase the frame processing rate and speed up query processing by at least two orders of magnitude. We present the results of a thorough experimental study utilizing benchmark video data sets at scale demonstrating the performance benefits and the practical relevance of our proposals.},
  archive      = {J_TKDE},
  author       = {Nick Koudas and Raymond Li and Ioannis Xarchakos},
  doi          = {10.1109/TKDE.2020.3048606},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {5023-5036},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Video monitoring queries},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised ensemble classification with sequential and
networked data. <em>TKDE</em>, <em>34</em>(10), 5009–5022. (<a
href="https://doi.org/10.1109/TKDE.2020.3046645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning, the machine learning paradigm where multiple models are combined, has exhibited promising perfomance in a variety of tasks. The present work focuses on unsupervised ensemble classification. The term unsupervised refers to the ensemble combiner who has no knowledge of the ground-truth labels that each classifier has been trained on. While most prior works on unsupervised ensemble classification are designed for independent and identically distributed (i.i.d.) data, the present work introduces an unsupervised scheme for learning from ensembles of classifiers in the presence of data dependencies. Two types of data dependencies are considered: sequential data and networked data whose dependencies are captured by a graph. For both, novel moment matching and Expectation-Maximization algorithms are developed. Performance of these algorithms is evaluated on synthetic and real datasets, which indicate that knowledge of data dependencies in the meta-learner is beneficial for the unsupervised ensemble classification task.},
  archive      = {J_TKDE},
  author       = {Panagiotis A. Traganitis and Georgios B. Giannakis},
  doi          = {10.1109/TKDE.2020.3046645},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {5009-5022},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unsupervised ensemble classification with sequential and networked data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recurrent learning on PM2.5 prediction based on clustered
airbox dataset. <em>TKDE</em>, <em>34</em>(10), 4994–5008. (<a
href="https://doi.org/10.1109/TKDE.2020.3047634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progress of industrial development naturally leads to the demand for more electrical power. Unfortunately, due to the fear of the safety of nuclear power plants, many countries have relied on thermal power plants, which will cause more air pollutants during the process of coal burning. This phenomenon as well as increased vehicle emissions around us, have constituted the primary factors of serious air pollution. Inhaling too much particulate air pollution may lead to respiratory diseases and even death, especially PM $_{2.5}$ . By predicting the air pollutant concentration, people can take precautions to avoid overexposure to air pollutants. Consequently, accurate PM $_{2.5}$ prediction becomes more important. In this study, we propose a PM $_{2.5}$ prediction system, which utilizes the dataset from EdiGreen Airbox and Taiwan EPA. Autoencoder and Linear interpolation are adopted for solving the missing value problem. Spearman’s correlation coefficient is used to identify the most relevant features for PM $_{2.5}$ . Two prediction models (i.e., LSTM and LSTM based on K-means) are implemented which predict PM $_{2.5}$ value for each Airbox device. To assess the performance of the model prediction, the daily average error and the hourly average accuracy for the duration of a week are calculated. The experimental results show that LSTM based on K-means has the best performance among all methods. Therefore, LSTM based on K-means is chosen to provide real-time PM $_{2.5}$ prediction through the Linebot.},
  archive      = {J_TKDE},
  author       = {Chia-Yu Lo and Wen-Hsing Huang and Ming-Feng Ho and Min-Te Sun and Ling-Jyh Chen and Kazuya Sakai and Wei-Shinn Ku},
  doi          = {10.1109/TKDE.2020.3047634},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4994-5008},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Recurrent learning on PM2.5 prediction based on clustered airbox dataset},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preference and constraint factor model for event
recommendation. <em>TKDE</em>, <em>34</em>(10), 4982–4993. (<a
href="https://doi.org/10.1109/TKDE.2020.3046932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Newly emerging Event-based Social Network (EBSN) concentrates on connecting both online social relationships and offline local events. For the growing amount of events published on EBSNs, personalized event recommendation becomes essential to help users choose attractive events. But most of existing event recommendation algorithms fail to distinguish constraint factors of users’ event participation behaviors from preference factors, which reflects the cost of event participation that hinders users from attending interested events. To take full advantage of influences from contextual information on users’ event participation, we differentiate preference and constraint factors which contribute to users’ decision for event participation, and extract the soft spatial and temporal constraints from event venue and start time contexts respectively. Then we propose the Preference and Constraint Factor Model (PCFM) based on factorization machine model, using attentive mechanism to weight feature interactions and incorporate latent factors of users and contextual features for personalized perference modeling and event recommendation. Moreover, learning-to-rank techniques are utilized to train PCFM as a ranking model for the implicit feedback nature of responses from users. Extensive experiments evaluate the performance of our proposed recommendation model on real-world EBSN datasets, and demonstrate the outperformance than state-of-art event recommendation methods on many metrics.},
  archive      = {J_TKDE},
  author       = {Yi’an Lai and Yujie Zhang and Xiangwu Meng and Yulu Du},
  doi          = {10.1109/TKDE.2020.3046932},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4982-4993},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Preference and constraint factor model for event recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of intra-urban human mobility by integrating
regional functions and trip intentions. <em>TKDE</em>, <em>34</em>(10),
4972–4981. (<a href="https://doi.org/10.1109/TKDE.2020.3047406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding intra-urban human mobility patterns and their potential driving forces are vital to city planning and commercial site selection. In this paper, we first investigate the functions of urban regions and how different region types dynamically influence people’s trip decisions. Furthermore, we characterize urban circadian rhythms by time-vary inter-regional transition probabilities between these regions with different functions, and integrate them into intervening opportunity model to predict human mobility. Public transportation card data in Shanghai are used to demonstrate the effectiveness of the model in terms of station passenger flows, travel time and trip flux. By taking regional function into consideration, the proposed model significantly improved the prediction accuracy. Quantitative analysis ulteriorly indicates that trip intentions and regional features are critical elements in trip flux prediction, especially in the afternoon and evening when people have an abundance of opportunities to travel by their own volition. When the function of a certain region changes, our model is able to make reasonable predictions accordingly. The results indicate the importance of considering individual travel motivation and regional function in modeling human mobility. The proposed model could serve as a guide for popularity and trip flux prediction in urban planning and reconstruction.},
  archive      = {J_TKDE},
  author       = {Shuyang Shi and Lin Wang and Shuangdie Xu and Xiaofan Wang},
  doi          = {10.1109/TKDE.2020.3047406},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4972-4981},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Prediction of intra-urban human mobility by integrating regional functions and trip intentions},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pattern classification with corrupted labeling via robust
broad learning system. <em>TKDE</em>, <em>34</em>(10), 4959–4971. (<a
href="https://doi.org/10.1109/TKDE.2021.3049540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing classification systems assume that the data used is high-quality labeled. However, the labeling process in real-world may inevitably introduce corruptions into labels which can confuse the performances of classifiers. In this paper, based on Broad Learning System (BLS), we propose a novel label noise tolerant method to classify the pattern with corrupted labels. The standard BLS has shown promising efficiency and accuracy in general classification, but its learning process is prone to be affected by the noisy labels. Here, by detailed probabilistic analysis, we first give the reason for lacks of robustness in standard BLS. Then a maximum likelihood estimation-based objective function is derived for robust classification. In addition, a manifold regularization term is integrated to preserve the local geometry of data, which makes the model to be more robust and flexible to learn the output weights. Given some basic assumptions on the approximation errors, the obtained model can be transformed to a graph regularized reweighted BLS problem. The negative effects of noisy labels in data can be inhibited adaptively by assigning reasonable weights. Theoretical analysis and extensive experiments are provided to demonstrate the robustness and effectiveness of the proposed robust BLS model, especially for the case of large amounts of noisy labels.},
  archive      = {J_TKDE},
  author       = {Junwei Jin and Yanting Li and C. L. Philip Chen},
  doi          = {10.1109/TKDE.2021.3049540},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4959-4971},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Pattern classification with corrupted labeling via robust broad learning system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiset membership lookup in large datasets. <em>TKDE</em>,
<em>34</em>(10), 4947–4958. (<a
href="https://doi.org/10.1109/TKDE.2021.3049624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a dataset $\mathcal S$ composed of $g$ subsets with each data item belonging to one of them, multiset membership lookup takes an item $e$ as input and outputs a binary answer whether $e\in {\mathcal S}$ and, in case of yes, the ID of the subset to which $e$ belongs. Overlaid upon while more sophisticated than the canonical membership lookup, multiset membership lookup emerges as a pivotal functionality in many computing and networking paradigms. The quest to achieve high-speed, high-accuracy lookup with limited memory cost makes lookup algorithm design a challenging task, particularly when the data items arrive as a stream. In this paper, we devise compact data structures and lookup algorithms that are amendable for hardware implementation, while guaranteeing high lookup accuracy and supporting interactive query processing. We first propose multi-hash color table , a variant of Bloom filter, to encode subset IDs compactly and map the ID of an item to its subset ID. We further construct a more balanced data structure called balanced multi-hash color table to improve the compactness by integrating the state-of-the-art load balancing technique. We complete our work by addressing the case of batch arrivals and design a batched recording algorithm optimizing the memory efficiency. We give both theoretical and empirical analysis to characterize and evaluate the performance of the proposed algorithms in terms of lookup accuracy, memory and access efficiency.},
  archive      = {J_TKDE},
  author       = {Lin Chen and Jihong Yu},
  doi          = {10.1109/TKDE.2021.3049624},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4947-4958},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multiset membership lookup in large datasets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-dimensional randomized response. <em>TKDE</em>,
<em>34</em>(10), 4933–4946. (<a
href="https://doi.org/10.1109/TKDE.2020.3045759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our data world, a host of not necessarily trusted controllers gather data on individual subjects. To preserve her privacy and, more generally, her informational self-determination, the individual has to be empowered by giving her agency on her own data. Maximum agency is afforded by local anonymization, that allows each individual to anonymize her own data before handing them to the data controller. Randomized response (RR) is a local anonymization approach able to yield multi-dimensional full sets of anonymized microdata that are valid for exploratory analysis and machine learning. This is so because an unbiased estimate of the distribution of the true data of individuals can be obtained from their pooled randomized data. Furthermore, RR offers rigorous privacy guarantees. The main weakness of RR is the curse of dimensionality when applied to several attributes: as the number of attributes grows, the accuracy of the estimated true data distribution quickly degrades. We propose several complementary approaches to mitigate the dimensionality problem. First, we present two basic protocols, separate RR on each attribute and joint RR for all attributes, and discuss their limitations. Then we introduce an algorithm to form clusters of attributes so that attributes in different clusters can be viewed as independent and joint RR can be performed within each cluster. After that, we introduce an adjustment algorithm for the randomized data set that repairs some of the accuracy loss due to assuming independence between attributes when using RR separately on each attribute or due to assuming independence between clusters in cluster-wise RR. We also present empirical work to illustrate the proposed methods.},
  archive      = {J_TKDE},
  author       = {Josep Domingo-Ferrer and Jordi Soria-Comas},
  doi          = {10.1109/TKDE.2020.3045759},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4933-4946},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-dimensional randomized response},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Looking back on the past: Active learning with historical
evaluation results. <em>TKDE</em>, <em>34</em>(10), 4921–4932. (<a
href="https://doi.org/10.1109/TKDE.2020.3045816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning is an effective approach for tasks with limited labeled data. It samples a small set of data to annotate actively and is widely applied in various AI tasks. It uses an iterative process, during which we utilize the current trained model to evaluate all unlabeled samples and annotate the best samples based on a specific query strategy to update the underlying model iteratively. Most existing active learning approaches rely on only the evaluation results generated by the current model and ignore the results from previous iterations. In this paper, we propose using more historical evaluation results which can provide additional information to help better select samples. First, we apply two kinds of heuristic features of the historical evaluation results, the weighted sum of historical results and the fluctuation of the historical evaluation sequence, to improve the effectiveness of active learning sampling. Next, to further and more globally use the information contained in the historical results, we design a novel query strategy that learns how to select samples based on the historical sequences automatically. Our proposed idea is general and can be combined with both basic and state-of-the-art query strategies to achieve improvements. We test our approaches on two common NLP tasks including text classification and named entity recognition. Experimental results show that our methods significantly promote existing methods.},
  archive      = {J_TKDE},
  author       = {Jing Yao and Zhicheng Dou and Jian-Yun Nie and Ji-Rong Wen},
  doi          = {10.1109/TKDE.2020.3045816},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4921-4932},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Looking back on the past: Active learning with historical evaluation results},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LF-GDPR: A framework for estimating graph metrics with local
differential privacy. <em>TKDE</em>, <em>34</em>(10), 4905–4920. (<a
href="https://doi.org/10.1109/TKDE.2020.3047124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local differential privacy (LDP) is an emerging technique for privacy-preserving data collection without a trusted collector. Despite its strong privacy guarantee, LDP cannot be easily applied to real-world graph analysis tasks such as community detection and centrality analysis due to its high implementation complexity and low data utility. In this paper, we address these two issues by presenting LF-GDPR, the first LDP-enabled graph metric estimation framework for graph analysis. It collects two atomic graph metrics—the adjacency bit vector and node degree—from each node locally. LF-GDPR simplifies the job of implementing LDP-related steps (e.g., local perturbation, aggregation and calibration) for a graph metric estimation task by providing either a complete or a parameterized algorithm for each step. To address low data utility of LDP, it optimally allocates privacy budget between the two atomic metrics during data collection. To demonstrate the usage of LF-GDPR, we show use cases on two common graph analysis tasks, namely, clustering coefficient estimation and community detection. The privacy and utility achieved by LF-GDPR are verified through theoretical analysis and extensive experimental results.},
  archive      = {J_TKDE},
  author       = {Qingqing Ye and Haibo Hu and Man Ho Au and Xiaofeng Meng and Xiaokui Xiao},
  doi          = {10.1109/TKDE.2020.3047124},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4905-4920},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LF-GDPR: A framework for estimating graph metrics with local differential privacy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to rank for uplift modeling. <em>TKDE</em>,
<em>34</em>(10), 4888–4904. (<a
href="https://doi.org/10.1109/TKDE.2020.3048510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal classification concerns the estimation of the net effect of a treatment on an outcome of interest at the instance level, i.e., of the individual treatment effect (ITE). For binary treatment and outcome variables, causal classification models produce ITE estimates that essentially allow one to rank instances from a large positive effect to a large negative effect. Often, as in uplift modeling (UM), one is merely interested in this ranking, rather than in the ITE estimates themselves. In this regard, we investigate the potential of learning to rank (L2R) techniques to learn a ranking of the instances directly. We propose a unified formalization of different binary causal classification performance measures from the UM literature and explore how these can be integrated into the L2R framework. Additionally, we introduce a new metric for UM with L2R called the promoted cumulative gain (PCG). We employ the L2R technique LambdaMART to optimize the ranking according to PCG and show improved results over the use of standard L2R metrics and equal to improved results when compared with state-of-the-art UM. Finally, we show how L2R techniques can be used to specifically optimize for the top- $k$ fraction of the ranking in a UM context, however, these results do not generalize to the test set.},
  archive      = {J_TKDE},
  author       = {Floris Devriendt and Jente Van Belle and Tias Guns and Wouter Verbeke},
  doi          = {10.1109/TKDE.2020.3048510},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4888-4904},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning to rank for uplift modeling},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving image similarity learning by adding external
memory. <em>TKDE</em>, <em>34</em>(10), 4874–4887. (<a
href="https://doi.org/10.1109/TKDE.2020.3047104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The type of neural networks widely used in artificial intelligence applications mixes its computation and memory modules in neuron weights and activities. The previously learned information are stored in network weights. When dealing with complex data, e.g., those possessing diverse content or containing long-sequences, some information stored in the weights can be altered drastically or wiped as the training goes, but they are not necessarily unimportant. External memory is a recent technique proposed to prevent from forgetting significant previously learned information. In this work, we aim at taking advantage of this recent technique to advance the similarity learning task that is critical in many real-world artificial intelligence applications. We propose suitable external memory design supported by extended attention mechanism. Two different kinds of memory modules are proposed so that the similarity learning process can dynamically shift focus over a wide range of diverse content contained by the training data. Effectiveness of the proposed method is demonstrated through evaluations based on different image retrieval tasks and compared against various state-of-the-art algorithms in the field.},
  archive      = {J_TKDE},
  author       = {Xinjian Gao and Tingting Mu and John Y. Goulermas and Jingkuan Song and Meng Wang},
  doi          = {10.1109/TKDE.2020.3047104},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4874-4887},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Improving image similarity learning by adding external memory},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous network representation learning: A unified
framework with survey and benchmark. <em>TKDE</em>, <em>34</em>(10),
4854–4873. (<a href="https://doi.org/10.1109/TKDE.2020.3045924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since real-world objects and their interactions are often multi-modal and multi-typed, heterogeneous networks have been widely used as a more powerful, realistic, and generic superclass of traditional homogeneous networks (graphs). Meanwhile, representation learning ( a.k.a. embedding) has recently been intensively studied and shown effective for various network mining and analytical tasks. In this work, we aim to provide a unified framework to deeply summarize and evaluate existing research on heterogeneous network embedding (HNE), which includes but goes beyond a normal survey. Since there has already been a broad body of HNE algorithms, as the first contribution of this article, we provide a generic paradigm for the systematic categorization and analysis over the merits of various existing HNE algorithms. Moreover, existing HNE algorithms, though mostly claimed generic, are often evaluated on different datasets. Understandable due to the application favor of HNE, such indirect comparisons largely hinder the proper attribution of improved task performance towards effective data preprocessing and novel technical design, especially considering the various ways possible to construct a heterogeneous network from real-world application data. Therefore, as the second contribution, we create four benchmark datasets with various properties regarding scale, structure, attribute/label availability, and etc . from different sources, towards handy and fair evaluations of HNE algorithms. As the third contribution, we carefully refactor and amend the implementations and create friendly interfaces for 13 popular HNE algorithms, and provide all-around comparisons among them over multiple tasks and experimental settings. By putting all existing HNE algorithms under a unified framework, we aim to provide a universal reference and guideline for the understanding and development of HNE algorithms. Meanwhile, by open-sourcing all data and code, we envision to serve the community with an ready-to-use benchmark platform to test and compare the performance of existing and future HNE algorithms ( https://github.com/yangji9181/HNE ).},
  archive      = {J_TKDE},
  author       = {Carl Yang and Yuxin Xiao and Yu Zhang and Yizhou Sun and Jiawei Han},
  doi          = {10.1109/TKDE.2020.3045924},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4854-4873},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Heterogeneous network representation learning: A unified framework with survey and benchmark},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). <span class="math inline">𝙷𝙰𝙼 </span>HAM: Hybrid
associations models for sequential recommendation. <em>TKDE</em>,
<em>34</em>(10), 4838–4853. (<a
href="https://doi.org/10.1109/TKDE.2021.3049692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims to identify and recommend the next few items for a user that the user is most likely to purchase/review, given the user&#39;s purchase/rating trajectories. It becomes an effective tool to help users select favorite items from a variety of options. In this manuscript, we developed hybrid associations models ( $\mathop {\mathtt {HAM}}\limits$ ) to generate sequential recommendations using three factors: 1) users’ long-term preferences, 2) sequential, high-order and low-order association patterns in the users’ most recent purchases/ratings, and 3) synergies among those items. $\mathop {\mathtt {HAM}}\limits$ uses simplistic pooling to represent a set of items in the associations, and element-wise product to represent item synergies of arbitrary orders. We compared $\mathop {\mathtt {HAM}}\limits$ models with the most recent, state-of-the-art methods on six public benchmark datasets in three different experimental settings. Our experimental results demonstrate that $\mathop {\mathtt {HAM}}\limits$ models significantly outperform the state of the art in all the experimental settings. with an improvement as much as 46.6 percent. In addition, our run-time performance comparison in testing demonstrates that $\mathop {\mathtt {HAM}}\limits$ models are much more efficient than the state-of-the-art methods. and are able to achieve significant speedup as much as 139.7 folds.},
  archive      = {J_TKDE},
  author       = {Bo Peng and Zhiyun Ren and Srinivasan Parthasarathy and Xia Ning},
  doi          = {10.1109/TKDE.2021.3049692},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4838-4853},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {$\mathop {\mathtt {HAM}}$HAM: Hybrid associations models for sequential recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GloDyNE: Global topology preserving dynamic network
embedding. <em>TKDE</em>, <em>34</em>(10), 4826–4837. (<a
href="https://doi.org/10.1109/TKDE.2020.3046511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning low-dimensional topological representation of a network in dynamic environments is attracting much attention due to the time-evolving nature of many real-world networks. The main and common objective of Dynamic Network Embedding (DNE) is to efficiently update node embeddings while preserving network topology at each time step. The idea of most existing DNE methods is to capture the topological changes at or around the most affected nodes (instead of all nodes) and accordingly update node embeddings. Unfortunately, this kind of approximation, although can improve efficiency, cannot effectively preserve the global topology of a dynamic network at each time step, due to not considering the inactive sub-networks that receive accumulated topological changes propagated via the high-order proximity. To tackle this challenge, we propose a novel node selecting strategy to diversely select the representative nodes over a network, which is coordinated with a new incremental learning paradigm of Skip-Gram based embedding approach. The extensive experiments show GloDyNE, with a small fraction of nodes being selected, can already achieve the superior or comparable performance w.r.t. the state-of-the-art DNE methods in three typical downstream tasks. Particularly, GloDyNE significantly outperforms other methods in the graph reconstruction task, which demonstrates its ability of global topology preservation.},
  archive      = {J_TKDE},
  author       = {Chengbin Hou and Han Zhang and Shan He and Ke Tang},
  doi          = {10.1109/TKDE.2020.3046511},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4826-4837},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GloDyNE: Global topology preserving dynamic network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast extended inductive robust principal component analysis
with optimal mean. <em>TKDE</em>, <em>34</em>(10), 4812–4825. (<a
href="https://doi.org/10.1109/TKDE.2020.3047405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the mean calculation of RPCA_OM and inductiveness of IRPCA, we first propose an inductive robust principal component analysis method with removing the optimal mean automatically, which is shorted as IRPCA_OM. Furthermore, IRPCA_OM is extended to Schatten- $p$ norm and a more general framework (i.e., EIRPCA_OM) is presented. The objective function of EIRPCA_OM includes two terms, the first term is a robust reconstruction error term constrained by an $\ell _{2,1}$ -norm and the second term is a regularization term constrained by a Schatten- $p$ norm. The proposed EIRPCA_OM method is robust, inductive and accurate. However, on the high-dimensional data, it would spend a large computation cost in training stage. To this end, a fast version of EIRPCA_OM called as FEIRPCA_OM is proposed, and its basic idea is to eliminate the zero eigenvalues of data matrix. More importantly, an effective theoretical proof is presented to ensure that FEIRPCA_OM has faster processing speed than EIRPCA_OM when processing high-dimensional data, but without any performance loss. Based on it, we also can exchange the less performance loss for the higher computation efficiency by removing the small eigenvalues of data matrix. Experimental results on the public datasets demonstrate that FEIRPCA_OM works efficiently on the high-dimensional data.},
  archive      = {J_TKDE},
  author       = {Shuangyan Yi and Feiping Nie and Yongsheng Liang and Wei Liu and Zhenyu He and Qingmin Liao},
  doi          = {10.1109/TKDE.2020.3047405},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4812-4825},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast extended inductive robust principal component analysis with optimal mean},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event popularity prediction using influential hashtags from
social media. <em>TKDE</em>, <em>34</em>(10), 4797–4811. (<a
href="https://doi.org/10.1109/TKDE.2020.3048428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event popularity prediction over social media is crucial for estimating information propagation scope, decision making, and emergency prevention. However, existing approaches only focus on predicting the occurrences of single attribute such as a message, a hashtag or an image, which are not comprehensive enough for representing complex social event propagation. In this paper, we predict the event popularity, where an event is described as a set of messages containing multiple hashtags. We propose a novel hashtag-influence-based event popularity prediction by mining the impact of an influential hashtag set on the event propagation. Specifically, we first propose a hashtag-influence-based cascade model to select the influential hashtags over an event hashtag graph built by the pairwise hashtag similarity and the topic distribution of event-related hashtags. A novel measurement is proposed to identify the hashtag influence of an event over its content and social impacts. A hashtag correlation-based algorithm is proposed to optimize the seed selection in a greedy manner. Then, we propose an event-fitting boosting model to predict the event popularity by embedding the feature importance over events into the XGBOOST model. Moreover, we propose an event-structure-based method, which incrementally updates the prediction model over social streams. We have conducted extensive experiments to prove the effectiveness and efficiency of the proposed approach.},
  archive      = {J_TKDE},
  author       = {Xi Chen and Xiangmin Zhou and Jeffrey Chan and Lei Chen and Timos Sellis and Yanchun Zhang},
  doi          = {10.1109/TKDE.2020.3048428},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4797-4811},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Event popularity prediction using influential hashtags from social media},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient distributed clustering algorithms on star-schema
heterogeneous graphs. <em>TKDE</em>, <em>34</em>(10), 4781–4796. (<a
href="https://doi.org/10.1109/TKDE.2020.3047631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many datasets including social media data and bibliographic data can be modeled as graphs. Clustering such graphs is able to provide useful insights into the structure of the data. To improve the quality of clustering, node attributes can be taken into account, resulting in attributed graphs. Existing attributed graph clustering methods generally consider attribute similarity and structural similarity separately. In this paper, we represent attributed graphs as star-schema heterogeneous graphs, where attributes are modeled as different types of graph nodes. This enables the use of personalized pagerank (PPR) as a unified distance measure that captures both structural and attribute similarities. We employ DBSCAN for clustering, and we update edge weights iteratively to balance the importance of different attributes. The rapidly growing volume of data nowadays challenges traditional clustering algorithms, and thus, a distributed method is required. Hence, we adopt a popular distributed graph computing system Blogel, based on which, we develop four exact and approximate approaches that enable efficient PPR score computation when edge weights are updated. To improve the effectiveness of the clustering, we propose a simple yet effective edge weight update strategy based on entropy. In addition, we present a game theory based method that enables trading efficiency for result quality. Extensive experiments on real-life datasets offer insights into the effectiveness and efficiency of our proposals.},
  archive      = {J_TKDE},
  author       = {Lu Chen and Yunjun Gao and Xingrui Huang and Christian S. Jensen and Bolong Zheng},
  doi          = {10.1109/TKDE.2020.3047631},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4781-4796},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient distributed clustering algorithms on star-schema heterogeneous graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient similarity-aware influence maximization in
geo-social network. <em>TKDE</em>, <em>34</em>(10), 4767–4780. (<a
href="https://doi.org/10.1109/TKDE.2020.3045783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosion of GPS-enabled smartphones and social media platforms, geo-social networks are increasing as tools for businesses to promote their products or services. Influence maximization, which aims to maximize the expected spread of influence in the networks, has drawn increasing attention. However, most recent work tries to study influence maximization by only considering geographic distance, while ignoring the influence of users’ spatio-temporal behavior on information propagation or location promotion, which can often lead to poor results. To relieve this problem, we propose a Similarity-aware Influence Maximization (SIM) model to efficiently maximize the influence spread by taking the effect of users’ spatio-temporal behavior into account, which is more reasonable to describe the real information propagation. We first calculate the similarity between users according to their historical check-ins, and then we propose a Propagation to Consumption (PTC) model to capture both online and offline behaviors of users. Finally, we propose two greedy algorithms to efficiently maximize the influence spread. The extensive experiments over real datasets demonstrate the efficiency and effectiveness of the proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Xuanhao Chen and Yan Zhao and Guanfeng Liu and Rui Sun and Xiaofang Zhou and Kai Zheng},
  doi          = {10.1109/TKDE.2020.3045783},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4767-4780},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient similarity-aware influence maximization in geo-social network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DiffNet++: A neural influence and interest diffusion network
for social recommendation. <em>TKDE</em>, <em>34</em>(10), 4753–4766.
(<a href="https://doi.org/10.1109/TKDE.2020.3048414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendation has emerged to leverage social connections among users for predicting users’ unknown preferences, which could alleviate the data sparsity issue in collaborative filtering based recommendation. Early approaches relied on utilizing each user’s first-order social neighbors’ interests for better user modeling, and failed to model the social influence diffusion process from the global social network structure. Recently, we propose a preliminary work of a neural influence Diff usion Net work (i.e., DiffNet) for social recommendation L. Wu, P. Sun, Y. Fu, R. Hong, X. Wang, and M. Wang, “A neural influence diffusion model for social recommendation,” in Proc. Int. ACM SIGIR Conf. Res. Develop. Inf. Retrieval , 2019, pp. 235–244.. DiffNet models the recursive social diffusion process for each user, such that the influence diffusion hidden in the higher-order social network is captured in the user embedding process. Despite the superior performance of DiffNet, we argue that, as users play a central role in both user-user social network and user-item interest network, only modeling the influence diffusion process in the social network would neglect the latent collaborative interests of users hidden in the user-item interest network. To this end, in this paper, we propose DiffNet++, an improved algorithm of DiffNet that models the neural influence diffusion and interest diffusion in a unified framework. By reformulating the social recommendation as a heterogeneous graph with social network and interest network as input, DiffNet++ advances DiffNet by injecting both the higher-order user latent interest reflected in the user-item graph and higher-order user influence reflected in the user-user graph for user embedding learning. This is achieved by iteratively aggregating each user’s embedding from three aspects: the user’s previous embedding, the influence aggregation of social neighbors from the social network, and the interest aggregation of item neighbors from the user-item interest network. Furthermore, we design a multi-level attention network that learns how to attentively aggregate user embeddings from these three aspects. Finally, extensive experimental results on four real-world datasets clearly show the effectiveness of our proposed model. We release the source code at https://github.com/PeiJieSun/diffnet .},
  archive      = {J_TKDE},
  author       = {Le Wu and Junwei Li and Peijie Sun and Richang Hong and Yong Ge and Meng Wang},
  doi          = {10.1109/TKDE.2020.3048414},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4753-4766},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DiffNet++: A neural influence and interest diffusion network for social recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepBlue: Bi-layered LSTM for tweet popUlarity estimation.
<em>TKDE</em>, <em>34</em>(10), 4737–4752. (<a
href="https://doi.org/10.1109/TKDE.2021.3049529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social networks, one of the most significant challenges is how to estimate the tweet popularity. Prior studies focus on leveraging different aspects of just a single tweet, while ignoring the impact of historical tweets. In this article, we propose to leverage such historical information and rethink the problem of tweet popularity estimation. From historical information, there are two important factors that can be extracted: (1) user reputation feature, which can represent coarse-grained level of tweet popularity and (2) tweet related features, which can represent fine-grained level of tweet popularity. To incorporate these two factors from historical information, we design a novel deep neural architecture, a Bi-layered LSTM for tweet popUlarity Estimation, called DeepBlue. Specifically, we first propose a user-reputation aware mechanism to combine coarse-grained and fine-grained level estimation into a united LSTM model. We also design a content attention mechanism to consider different impacts of historical tweets in terms of content similarity. We then propose a time aware mechanism to address the time interval irregularity issue. Finally, we apply the Poisson regression model to obtain the overall loss for tweet popularity estimation. Extensive experiments demonstrate the superiority of our proposed approach to other state-of-the-arts in terms of MAE and SRC.},
  archive      = {J_TKDE},
  author       = {Zhongbao Zhang and Zichang Yin and Jian Wen and Li Sun and Sen Su and Philip S. Yu},
  doi          = {10.1109/TKDE.2021.3049529},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4737-4752},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DeepBlue: Bi-layered LSTM for tweet popUlarity estimation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data dependencies extended for variety and veracity: A
family tree. <em>TKDE</em>, <em>34</em>(10), 4717–4736. (<a
href="https://doi.org/10.1109/TKDE.2020.3046443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Besides the conventional schema-oriented tasks, data dependencies are recently revisited for data quality applications, such as violation detection, data repairing and record matching. To address the variety and veracity issues of big data, data dependencies have been extended as data quality rules to adapt to various data types, ranging from (1) categorical data with equality relationships to (2) heterogeneous data with similarity relationships, and (3) numerical data with order relationships. In this survey, we briefly review the recent proposals on data dependencies categorized into the aforesaid types of data. In addition to (a) the concepts of these data dependency notations, we investigate (b) the extension relationships between data dependencies, e.g., conditional functional dependencies (CFDs) extend the conventional functional dependencies (FDs). It forms a family tree of extensions, mostly rooted in FDs, helping us understand the expressive power of various data dependencies. Moreover, we summarize (c) the discovery of dependencies from data, since data dependencies are often unlikely to be manually specified in a traditional way, given the huge volume and high variety of big data. We further outline (d) the applications of the extended data dependencies, in particular in data quality practice. It guides users to select proper data dependencies with sufficient expressive power and reasonable discovery cost. Finally, we conclude with several directions of future studies on the emerging data.},
  archive      = {J_TKDE},
  author       = {Shaoxu Song and Fei Gao and Ruihong Huang and Chaokun Wang},
  doi          = {10.1109/TKDE.2020.3046443},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4717-4736},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Data dependencies extended for variety and veracity: A family tree},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-view locality preserved diversity and consensus
learning for multi-view unsupervised feature selection. <em>TKDE</em>,
<em>34</em>(10), 4705–4716. (<a
href="https://doi.org/10.1109/TKDE.2020.3048678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although demonstrating great success, previous multi-view unsupervised feature selection (MV-UFS) methods often construct a view-specific similarity graph and characterize the local structure of data within each single view. In such a way, the cross-view information could be ignored. In addition, they usually assume that different feature views are projected from a latent feature space while the diversity of different views cannot be fully captured. In this work, we resent a MV-UFS model via cross-view local structure preserved diversity and consensus learning, referred to as CvLP-DCL briefly. In order to exploit both the shared and distinguishing information across different views, we project each view into a label space, which consists of a consensus part and a view-specific part. Therefore, we regularize the fact that different views represent same samples. Meanwhile, a cross-view similarity graph learning term with matrix-induced regularization is embedded to preserve the local structure of data in the label space. By imposing the $l_{2,1}$ -norm on the feature projection matrices for constraining row sparsity, discriminative features can be selected from different views. An efficient algorithm is designed to solve the resultant optimization problem and extensive experiments on six publicly datasets are conducted to validate the effectiveness of the proposed CvLP-DCL.},
  archive      = {J_TKDE},
  author       = {Chang Tang and Xiao Zheng and Xinwang Liu and Wei Zhang and Jing Zhang and Jian Xiong and Lizhe Wang},
  doi          = {10.1109/TKDE.2020.3048678},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4705-4716},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cross-view locality preserved diversity and consensus learning for multi-view unsupervised feature selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuous trajectory similarity search for online outlier
detection. <em>TKDE</em>, <em>34</em>(10), 4690–4704. (<a
href="https://doi.org/10.1109/TKDE.2020.3046670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a new variant of trajectory similarity search from the context of continuous query processing. Given a moving object from $s$ to $d$ , following a reference route $T_r$ , we monitor the trajectory similarity between the reference route and the current partial route at each timestamp for online detour detection. Since existing trajectory distance measures fail to adequately capture the deviation between a partial route and a complete route, we propose a partial trajectory similarity measure to bridge the gap. In particular, we enumerate all the possible routes extended from the partial route to reach the destination $d$ and calculate their minimum distance to $T_r$ . We consider deviation calculation in both euclidean space and road networks. In euclidean space, we can directly infer the optimal future path with the minimum trajectory distance. In road networks, we propose an efficient expansion algorithm with a suite of pruning rules. Furthermore, we propose efficient incremental processing strategies to facilitate continuous query processing for moving objects. Our experiments are conducted on multiple real datasets and the experimental results verify the efficiency of our query processing algorithms.},
  archive      = {J_TKDE},
  author       = {Dongxiang Zhang and Zhihao Chang and Sai Wu and Ye Yuan and Kian-Lee Tan and Gang Chen},
  doi          = {10.1109/TKDE.2020.3046670},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4690-4704},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Continuous trajectory similarity search for online outlier detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Consensus one-step multi-view subspace clustering.
<em>TKDE</em>, <em>34</em>(10), 4676–4689. (<a
href="https://doi.org/10.1109/TKDE.2020.3045770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering has attracted increasing attention in multimedia, machine learning and data mining communities. As one kind of the essential multi-view clustering algorithm, multi-view subspace clustering (MVSC) becomes more and more popular due to its strong ability to reveal the intrinsic low dimensional clustering structure hidden across views. Despite superior clustering performance in various applications, we observe that existing MVSC methods directly fuse multi-view information in the similarity level by merging noisy affinity matrices ; and isolate the processes of affinity learning, multi-view information fusion and clustering . Both factors may cause insufficient utilization of multi-view information, leading to unsatisfying clustering performance. This paper proposes a novel consensus one-step multi-view subspace clustering (COMVSC) method to address these issues. Instead of directly fusing multiple affinity matrices, COMVSC optimally integrates discriminative partition-level information, which is helpful to eliminate noise among data. Moreover, the affinity matrices, consensus representation and final clustering labels matrix are learned simultaneously in a unified framework. By doing so, the three steps can negotiate with each other to best serve the clustering task, leading to improved performance. Accordingly, we propose an iterative algorithm to solve the resulting optimization problem. Extensive experiment results on benchmark datasets demonstrate the superiority of our method against other state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Pei Zhang and Xinwang Liu and Jian Xiong and Sihang Zhou and Wentao Zhao and En Zhu and Zhiping Cai},
  doi          = {10.1109/TKDE.2020.3045770},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4676-4689},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Consensus one-step multi-view subspace clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Challenges in KNN classification. <em>TKDE</em>,
<em>34</em>(10), 4663–4675. (<a
href="https://doi.org/10.1109/TKDE.2021.3049250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The KNN algorithm is one of the most popular data mining algorithms. It has been widely and successfully applied to data analysis applications across a variety of research topics in computer science. This paper illustrates that, despite its success, there remain many challenges in KNN classification, including K computation, nearest neighbor selection, nearest neighbor search and classification rules. Having established these issues, recent approaches to their resolution are examined in more detail, thereby providing a potential roadmap for ongoing KNN-related research, as well as some new classification rules regarding how to tackle the issue of training sample imbalance. To evaluate the proposed approaches, some experiments were conducted with 15 UCI benchmark datasets.},
  archive      = {J_TKDE},
  author       = {Shichao Zhang},
  doi          = {10.1109/TKDE.2021.3049250},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4663-4675},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Challenges in KNN classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CFFNN: Cross feature fusion neural network for collaborative
filtering. <em>TKDE</em>, <em>34</em>(10), 4650–4662. (<a
href="https://doi.org/10.1109/TKDE.2020.3048788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous state-of-the-art recommendation frameworks employ deep neural networks in Collaborative Filtering (CF). In this paper, we propose a cross feature fusion neural network (CFFNN) for the enhancement of CF. Existing studies overlook either user preferences for various item features or the relationship between item features and user features. To solve this problem, we construct a cross feature fusion network to enable the fusion of user features and item features as well as a self-attention network to determine users’ preferences for items. Specifically, we design a feature extraction layer with multiple MLP (Multilayer Perceptrons) modules to extract both user features and item features. Then, we introduce a cross feature fusion mechanism for an accurate determination of the relationship between different user-item interactions. The features of users and items are crossly embedded and then fed into a prediction network. The attention mechanism enables the model to focus on more effective features. The effectiveness of CFFNN model is demonstrated through extensive experiments on four real-world datasets. The experimental results indicate that CFFNN significantly outperforms the existing state-of-the-art models, with a relative improvement of 3.0 to 12.1 percent on hit ratio (HR) and normalized discounted cumulative gain (NDCG) compared with the baselines.},
  archive      = {J_TKDE},
  author       = {Ruiyun Yu and Dezhi Ye and Zhihong Wang and Biyun Zhang and Ann Move Oguti and Jie Li and Bo Jin and Fadi Kurdahi},
  doi          = {10.1109/TKDE.2020.3048788},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4650-4662},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CFFNN: Cross feature fusion neural network for collaborative filtering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Answering why-questions for subgraph queries. <em>TKDE</em>,
<em>34</em>(10), 4636–4649. (<a
href="https://doi.org/10.1109/TKDE.2020.3046436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph queries are routinely used to search for entities in richly attributed graphs e.g., social networks and knowledge graphs. With little knowledge of underlying data, users often need to rewrite queries multiple times to reach desirable answers. Why-questions are studied to clarify missing or unexpected query results. This paper makes a first step to answer Why-questions for entity search in attributed graphs. We consider three common types of Why-questions: Why-not, Why, and Why-rank, which suggest query manipulations that are responsible for user-specified missing, unexpected, and undesirably ranked entities, respectively. (1) We approach a general query rewriting paradigm that suggests to identify desired entities that are specified by Why-questions. We introduce measures that characterize good query rewrites by incorporating both query editing cost and answer closeness. (2) While computing optimal query rewrites is intractable, we develop feasible algorithms, from approximation to fast heuristics, and provide query rewrites with (near) optimality guarantees whenever possible, for Why, Why-not and Why-rank questions. We further show that our results remain intact for Why questions that (1) request a single query rewrite to clarify multiple types of entities, and (2) variants such as Why-empty and Why-so-many, by providing the matching algorithms. Using real-world graphs, we experimentally verify that our algorithms are effective and feasible for large graphs. Our case study also verifies their application in e.g., knowledge exploration.},
  archive      = {J_TKDE},
  author       = {Qi Song and Mohammad Hossein Namaki and Peng Lin and Yinghui Wu},
  doi          = {10.1109/TKDE.2020.3046436},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4636-4649},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Answering why-questions for subgraph queries},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An adaptive social spammer detection model with
semi-supervised broad learning. <em>TKDE</em>, <em>34</em>(10),
4622–4635. (<a href="https://doi.org/10.1109/TKDE.2020.3047857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile social networks include a large number of social members who forward messages cooperatively. However, spammers post links to viruses and advertisements, or follow a large number of users, which produces many misleading messages in mobile social networks. In this paper, we propose an adaptive social spammer detection (ASSD) model. We build a spammer classifier by using a small number of labeled patterns and some unlabeled patterns. The prediction accuracy is high compared with some conventional supervised learning methods. Moreover, the time and energy required to label the identity of social members are reduced by applying ASSD. Because social spammers frequently change their behavior to deceive the spammer detection model, an incremental learning method is designed to update the spammer detection model adaptively, without retraining. We evaluate ASSD by comparing it with other supervised and semi-supervised machine learning methods using the Social Honeypot Dataset. Experimental results show that the proposed model outperforms the baseline methods in terms of recall and precision. Additionally, ASSD maintains a high detection accuracy by adaptively updating the model with newly generated social media data.},
  archive      = {J_TKDE},
  author       = {Tie Qiu and Xize Liu and Xiaobo Zhou and Wenyu Qu and Zhaolong Ning and C. L. Philip Chen},
  doi          = {10.1109/TKDE.2020.3047857},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4622-4635},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An adaptive social spammer detection model with semi-supervised broad learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive local embedding learning for semi-supervised
dimensionality reduction. <em>TKDE</em>, <em>34</em>(10), 4609–4621. (<a
href="https://doi.org/10.1109/TKDE.2021.3049371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning as one of most attractive problems in machine learning research field has aroused broad attentions in recent years. In this paper, we propose a novel locality preserved dimensionality reduction framework, named Semi-supervised Adaptive Local Embedding learning (SALE), which learns a local discriminative embedding by constructing a $k_1$ Nearest Neighbors ( $k_1$ NN) graph on labeled data, so as to explore the intrinsic structure, i.e., sub-manifolds from non-Gaussian labeled data. Then, mapping all samples into learned embedding and constructing another $k_2$ NN graph on all embedded data to explore the global structure of all samples. Therefore, the unlabeled data and their corresponding labeled neighbors can be clustered into same sub-manifold, so as to improve the discriminative power of embedded data. Furthermore, we propose two semi-supervised dimensionality reduction methods with orthogonal and whitening constraints based on proposed SALE framework. An efficient alternatively iterative optimization algorithm is developed to solve the NP-hard problem in our models. Extensive experiments conducted on several synthetic and real-world data sets demonstrate the superiorities of our methods on local structure exploration and classification task.},
  archive      = {J_TKDE},
  author       = {Feiping Nie and Zheng Wang and Rong Wang and Xuelong Li},
  doi          = {10.1109/TKDE.2021.3049371},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4609-4621},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive local embedding learning for semi-supervised dimensionality reduction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on data pricing: From economics to data science.
<em>TKDE</em>, <em>34</em>(10), 4586–4608. (<a
href="https://doi.org/10.1109/TKDE.2020.3045927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data are invaluable. How can we assess the value of data objectively, systematically and quantitatively? Pricing data, or information goods in general, has been studied and practiced in dispersed areas and principles, such as economics, marketing, electronic commerce, data management, data mining and machine learning. In this article, we present a unified, interdisciplinary and comprehensive overview of this important direction. We examine various motivations behind data pricing, understand the economics of data pricing and review the development and evolution of pricing models according to a series of fundamental principles. We discuss both digital products and data products. We also consider a series of challenges and directions for future work.},
  archive      = {J_TKDE},
  author       = {Jian Pei},
  doi          = {10.1109/TKDE.2020.3045927},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4586-4608},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on data pricing: From economics to data science},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel discriminative dictionary pair learning constrained
by ordinal locality for mixed frequency data classification.
<em>TKDE</em>, <em>34</em>(10), 4572–4585. (<a
href="https://doi.org/10.1109/TKDE.2020.3046114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dilemma faced by classification is that the data is not collected at the same frequency in some applications. We investigate the mixed frequency data in a new way and recognize them as a special style of multi-view data, in which each view data is collected at a different sampling frequency. This article proposes a discriminative dictionary pair learning method constrained by ordinal locality for mixed frequency data classification (shorted by DPLOL-MF). This method integrates synthesis dictionary and analysis dictionary into a dictionary pair, which not only improves computational cost caused by the ${\ell _0}$ or ${\ell _1}$ -norm constraint, but also can deal with the sampling frequency inconsistency. The DPLOL-MF utilizes a synthesis dictionary to learn class-specified reconstruction information and employs an analysis dictionary to generate coding coefficients by analyzing samples. Particularly, the ordinal locality preserving term is leveraged to constrain the atoms of dictionaries pair to further facilitate the learned dictionary pair to be more discriminative. Besides, we design a specific classification scheme for the inconsistent sample size of mixed frequency data. This paper illustrates a novel idea to solve the classification task of mixed frequency data and the experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Hong Yu and Qian Yang and Guoyin Wang and Yongfang Xie},
  doi          = {10.1109/TKDE.2020.3046114},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4572-4585},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A novel discriminative dictionary pair learning constrained by ordinal locality for mixed frequency data classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A linear time approach to computing time series similarity
based on deep metric learning. <em>TKDE</em>, <em>34</em>(10),
4554–4571. (<a href="https://doi.org/10.1109/TKDE.2020.3047070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series similarity computation is a fundamental primitive that underpins many time series data analysis tasks. However, many existing time series similarity measures have a high computation cost. While there has been much research effort for reducing the computational cost, such effort is usually specific to one similarity measure. We propose NeuTS ( Neu ral metric learning for T ime S eries) to accelerate time series similarity computation in a generic fashion. NeuTS computes the similarity of a given time series pair in linear time and generic to handle any existing similarity measures. NeuTS samples a number of seed time series from the given database, and then uses their pair-wise similarities as guidance to approximate the similarity function with a neural metric learning framework. NeuTS features two novel modules to achieve accurate approximation of the similarity function: (1) a local attention memory module that augments existing recurrent neural networks for time series encoding; and (2) a distance-weighted ranking loss that effectively transcribes information from the seed-based guidance. With these two modules, NeuTS can yield high accuracies and fast convergence rates even if the training data is small. Our experiments with five real-life datasets and four similarity measures (Fréchet, Hausdorff, ERP and DTW) show that NeuTS outperforms baselines consistently and significantly. Specifically, it achieves over 80 percent accuracies in most settings, while obtaining 50x-1000x speedup over bruteforce methods and 3x-350x speedup over approximate algorithms for top-k similarity search.},
  archive      = {J_TKDE},
  author       = {Di Yao and Gao Cong and Chao Zhang and Xuying Meng and Rongchang Duan and Jingping Bi},
  doi          = {10.1109/TKDE.2020.3047070},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {10},
  pages        = {4554-4571},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A linear time approach to computing time series similarity based on deep metric learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video super-resolution reconstruction based on deep learning
and spatio-temporal feature self-similarity. <em>TKDE</em>,
<em>34</em>(9), 4538–4553. (<a
href="https://doi.org/10.1109/TKDE.2020.3034261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problems in the existing video super-resolution methods, such as noise, over smooth and visual artifacts, which are caused by the reliance on limited external training or mismatch of internal similarity patch instances, this study proposes a novel video super-resolution reconstruction algorithm based on deep learning and spatio-temporal feature similarity (DLSS-VSR). The video super-resolution reconstruction mechanism with the joint internal and external constraints is established utilizing the complementary advantages of both external deep correlation mapping learning and internal spatio-temporal nonlocal self-similarity prior constraint. A deep learning model based on deep convolutional neural network is constructed to learn the nonlinear correlation mapping between low-resolution and high-resolution video frame patches. A novel spatio-temporal feature similarity calculation method is proposed, which considers both internal video spatio-temporal self-similarity and external clean nonlocal similarity. For the internal spatio-temporal feature self-similarity, we improve the accuracy and robustness of similarity matching by proposing a similarity measure strategy based on spatio-temporal moment feature similarity and structural similarity. The external nonlocal similarity prior constraint is learned by the patch group-based Gaussian mixture model. The time efficiency for spatio-temporal similarity matching is further improved based on saliency detection and region correlation judgment strategy, which achieves a better tradeoff between super-resolution accuracy and speed. Experimental results demonstrate that the DLSS-VSR algorithm achieves competitive super-resolution quality compared to other state-of-the-art algorithms in both subjective and objective evaluations.},
  archive      = {J_TKDE},
  author       = {Meiyu Liang and Junping Du and Linghui Li and Zhe Xue and Xiaoxiao Wang and Feifei Kou and Xu Wang},
  doi          = {10.1109/TKDE.2020.3034261},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4538-4553},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Video super-resolution reconstruction based on deep learning and spatio-temporal feature self-similarity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Verifying the correctness of analytic query results.
<em>TKDE</em>, <em>34</em>(9), 4527–4537. (<a
href="https://doi.org/10.1109/TKDE.2020.3037313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data outsourcing is a cost-effective solution for data owners to tackle issues such as large volumes of data, huge number of users, and intensive computation needed for data analysis. They can simply upload their databases to a cloud and let it perform all management works, including query processing. One problem with this service model is how query issuers can verify the query results they receive are indeed correct. This concern is legitimate because, as a third party, clouds may not be fully trustworthy, and as a large data center, clouds are ideal targets for hackers. There has been significant work on query result verification, but most consider only simple queries where query results can be attained by checking the raw data against the query conditions directly. In this paper, we consider the problem of enabling users to verify the correctness of the results of analytic queries. Unlike simple queries, analytic queries involve ranking functions to score a database, which makes it difficult to build data structures for verification purposes. We propose two approaches, namely one-signature and multi-signature , and show that they work well on three representative types of analytic queries, including top-k , range , and KNN queries, through both analysis and experiments.},
  archive      = {J_TKDE},
  author       = {Masoud Nosrati and Ying Cai},
  doi          = {10.1109/TKDE.2020.3037313},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4527-4537},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Verifying the correctness of analytic query results},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TTPNet: A neural network for travel time prediction based on
tensor decomposition and graph embedding. <em>TKDE</em>, <em>34</em>(9),
4514–4526. (<a href="https://doi.org/10.1109/TKDE.2020.3038259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel time prediction of a given trajectory plays an indispensable role in intelligent transportation systems. Although many prior researches have struggled for accurate prediction results, most of them achieve inferior performance due to insufficient feature extraction of travel speed and road network structure from the trajectory data, which confirms the challenges involved in this topic. To overcome those issues, we propose a novel neural Network for Travel Time Prediction based on tensor decomposition and graph embedding, named TTPNet , which can extract travel speed and representation of road network structure effectively from historical trajectories, as well as predict the travel time with better accuracy. Specifically, TTPNet consists of three components: the first module (Travel Speed Features Layer) leverages non-negative tensor decomposition to restore travel speed distributions on different roads in the previous hour, and integrates a CNN-RNN model to extract both long-term and short-term travel speed features of the query trajectory; the second module (Road Network Structure Features Layer) utilizes graph embedding to generate the representation of local and global road network structure; the last module (Deep LSTM Prediction Layer) completes the final predicting task. Empirical results over two real-world large-scale datasets show that our proposed TTPNet model can achieve significantly better performance and remarkable robustness.},
  archive      = {J_TKDE},
  author       = {Yibin Shen and Cheqing Jin and Jiaxun Hua and Dingjiang Huang},
  doi          = {10.1109/TKDE.2020.3038259},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4514-4526},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {TTPNet: A neural network for travel time prediction based on tensor decomposition and graph embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trajectory-based spatiotemporal entity linking.
<em>TKDE</em>, <em>34</em>(9), 4499–4513. (<a
href="https://doi.org/10.1109/TKDE.2020.3036633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory-based spatiotemporal entity linking is to match the same moving object in different datasets based on their movement traces. It is a fundamental step to support spatiotemporal data integration and analysis. In this paper, we study the problem of spatiotemporal entity linking using effective and concise signatures extracted from their trajectories. This linking problem is formalized as a $k$ -nearest neighbor ( $k$ -NN) query on the signatures. Four representation strategies (sequential, temporal, spatial, and spatiotemporal) and two quantitative criteria (commonality and unicity) are investigated for signature construction. A simple yet effective dimension reduction strategy is developed together with a novel indexing structure called the WR-tree to speed up the search. A number of optimization methods are proposed to improve the accuracy and robustness of the linking. Our extensive experiments on real-world datasets verify the superiority of our approach over the state-of-the-art solutions in terms of both accuracy and efficiency.},
  archive      = {J_TKDE},
  author       = {Fengmei Jin and Wen Hua and Thomas Zhou and Jiajie Xu and Matteo Francia and Maria E Orlowska and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.3036633},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4499-4513},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Trajectory-based spatiotemporal entity linking},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards an optimal bus frequency scheduling: When the
waiting time matters. <em>TKDE</em>, <em>34</em>(9), 4484–4498. (<a
href="https://doi.org/10.1109/TKDE.2020.3036573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reorganizing bus frequencies to cater for the actual travel demands can significantly save the cost of the public transport system. Many, if not all, previous studies formulate this as a bus frequency optimization problem that tries to minimize passengers’ average waiting time. On the other hand, many investigations have confirmed that the user satisfaction drops faster as the waiting time increases. Consequently, this paper studies the bus frequency optimization problem considering the user satisfaction. Specifically, for the first time to our best knowledge, we study how to schedule the buses such that the total number of passengers who could receive their bus services within the waiting time threshold can be maximized. We propose two variants of the problem, FAST and FASTCO, to cater for different application needs and prove that both are NP-hard. To solve FAST effectively and efficiently, we first present an index-based $(1-1/e)$ -approximation algorithm. By exploiting the locality property of routes in a bus network, we further propose a partition-based greedy method that achieves a $(1-\rho)(1-1/e)$ approximation ratio. Then we propose a progressive partition-based greedy method to further boost the efficiency while achieving a $(1-\rho)(1-1/e-\varepsilon)$ approximation ratio. For the FASTCO problem, two greedy-based heuristic methods are proposed. Experiments on a real city-wide bus dataset in Singapore have been conducted to verify the efficiency, effectiveness, and scalability of our methods in addressing FAST and FASTCO respectively.},
  archive      = {J_TKDE},
  author       = {Songsong Mo and Zhifeng Bao and Baihua Zheng and Zhiyong Peng},
  doi          = {10.1109/TKDE.2020.3036573},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4484-4498},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards an optimal bus frequency scheduling: When the waiting time matters},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structural and textual information fusion for symptom and
disease representation learning. <em>TKDE</em>, <em>34</em>(9),
4468–4483. (<a href="https://doi.org/10.1109/TKDE.2020.3039469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online medical consult and offline medical check-in have generated a large amount of health-related data in medical forums and patient records. However, exploiting the user-generated content for orienting patients online and assisting medical checkup offline is nontrivial due to the sparsity of symptom-disease associations. The serious sparsity is caused by the informal/chatty expressions of symptoms in the data.},
  archive      = {J_TKDE},
  author       = {Sendong Zhao and Meng Jiang and Bing Qin and Ting Liu and ChengXiang Zhai and Fei Wang},
  doi          = {10.1109/TKDE.2020.3039469},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4468-4483},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Structural and textual information fusion for symptom and disease representation learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Space-efficient subgraph search over streaming graph with
timing order constraint. <em>TKDE</em>, <em>34</em>(9), 4453–4467. (<a
href="https://doi.org/10.1109/TKDE.2020.3035902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing popularity of dynamic applications such as social networks provides a promising way to detect valuable information in real time. These applications create high-speed data that can be easily modeled as streaming graph. Efficient analysis over these data is of great significance. In this paper, we study the subgraph (isomorphism) search over streaming graph data that obeys timing order constraints over the occurrence of edges in the stream. The sliding window model is employed to focus on the most recent data. We propose an efficient solution to answer subgraph search, introduce optimizations to greatly reduce the space cost, and design concurrency management to improve system throughput. Extensive experiments on real network traffic data and synthetic social streaming data shows that our solution outperforms comparative ones by one order of magnitude with less space cost.},
  archive      = {J_TKDE},
  author       = {Youhuan Li and Lei Zou and M. Tamer Özsu and Dongyan Zhao},
  doi          = {10.1109/TKDE.2020.3035902},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4453-4467},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Space-efficient subgraph search over streaming graph with timing order constraint},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smooth compact tensor ring regression. <em>TKDE</em>,
<em>34</em>(9), 4439–4452. (<a
href="https://doi.org/10.1109/TKDE.2020.3037131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In learning tasks with high order correlations, the low-rank approximation of the regression coefficient tensor has become increasingly important. Tensor ring can capture more correlation information among tensor networks. However, its optimal rank is generally unknown and needs to be tuned from multiple combinations. To address the issue, we propose a novel tensor regression framework with a group sparsity constraint on latent factors for tensor ring rank estimation. Specifically, the proposed group sparsity term constrained matrix factorization problem is first shown to be equivalent to a better approximation of matrix rank, namely Schatten- $1/2$ quasi-norm. Extending it into tensor, the tensor ring rank can be inferred during the learning process to balance the prediction error and the model complexity. Besides, a total variation term is introduced to enhance the local consistency of the predicted response, which is useful for reducing the adverse effects of random noise. Experiments on the simulation dataset show that the proposed method can exactly obtain the tensor ring rank, and the effectiveness and robustness of the proposed algorithm is further verified on a real dataset for human motion capture tasks.},
  archive      = {J_TKDE},
  author       = {Jiani Liu and Ce Zhu and Yipeng Liu},
  doi          = {10.1109/TKDE.2020.3037131},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4439-4452},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Smooth compact tensor ring regression},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust variational learning for multiclass kernel models
with stein refinement. <em>TKDE</em>, <em>34</em>(9), 4425–4438. (<a
href="https://doi.org/10.1109/TKDE.2020.3041509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel-based models have a strong generalization ability, but most, including SVM, are vulnerable to the curse of kernelization. Moreover, their predictive performance is sensitive to hyperparameter tuning, which demands high computational resources. These problems render kernel methods problematic when dealing with large-scale datasets. To this end, we first formulate the optimization problem in a kernel-based learning setting as a posterior inference problem, and then develop a rich family of Recurrent Neural Network-based variational inference techniques. Unlike existing literature, which stops at the variational distribution and uses it as the surrogate for the true posterior distribution, here we further leverage Stein Variational Gradient Descent to further bring the variational distribution closer to the true posterior, we refer to this step as Stein Refinement . Putting these altogether, we arrive at a robust and efficient variational learning method for multiclass kernel machines with extremely accurate approximation. Moreover, our formulation enables efficient learning of kernel parameters and hyperparameters which robustifies the proposed method against data uncertainties. The extensive experiments show that without tuning any parameter on modest quantities of data our method obtains comparable accuracy to LIBSVM, a well-known implementation of SVM, and outperforms other baselines, while being able to seamlessly scale with large-scale datasets.},
  archive      = {J_TKDE},
  author       = {Khanh Nguyen and Trung Le and Tu Dinh Nguyen and Geoffrey I. Webb and Dinh Phung},
  doi          = {10.1109/TKDE.2020.3041509},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4425-4438},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust variational learning for multiclass kernel models with stein refinement},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rewarding social recommendation in OSNs: Empirical
evidences, modeling and optimization. <em>TKDE</em>, <em>34</em>(9),
4410–4424. (<a href="https://doi.org/10.1109/TKDE.2020.3038930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, many companies are considering “ social recommendation ” for their businesses, e.g., firms are offering rewards to customers who recommend the firms’ products/services in online social networks (OSNs). However, the pros and cons of such social recommendation scheme are still unclear. Thus, it is difficult for firms to design rewarding schemes, and for OSN platforms to design regulating policies. By analyzing real data from Weixin and Yelp, we first identify key factors that affect the spreading of products/services in OSNs. These findings enable us to develop an accurate (i.e., with a high validation accuracy) mathematical model on social recommendations. Our model captures how users decide whether to recommend an item, which is a key factor but often ignored by previous social recommendation models such as the “ Independent Cascade model ”. We also design algorithms to infer model parameters. Using our model, we uncover conditions when social recommendation improves a firm’s profit and users’ utilities, as well as when it cannot improve the profit or hurts users’ utilities. These conditions help the design of both rewarding schemes and regulating policies. Moreover, we extend our model to a dynamic setting, so that a firm can improve its profit by dynamically optimizing its rewarding schemes.},
  archive      = {J_TKDE},
  author       = {Li Ye and Hong Xie and Yishi Lin and John C. S. Lui},
  doi          = {10.1109/TKDE.2020.3038930},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4410-4424},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Rewarding social recommendation in OSNs: Empirical evidences, modeling and optimization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task learning for influence estimation and
maximization. <em>TKDE</em>, <em>34</em>(9), 4398–4409. (<a
href="https://doi.org/10.1109/TKDE.2020.3040028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of influence maximization when the social network is accompanied by diffusion cascades. In the literature, such information is used to compute influence probabilities, which is utilized by stochastic diffusion models in influence maximization. Motivated by the recent criticism on diffusion models and the galloping advancements in influence learning, we propose IMINFECTOR (Influence Maximization with INFluencer vECTORs), a method that uses representations learned from diffusion cascades to perform model-independent influence maximization. The first part of our methodology is a multi-task neural network that learns embeddings of nodes that initiate cascades (influencer vectors) and embeddings of nodes that participate in them (susceptible vectors). The norm of an influencer vector captures a node’s aptitude to initiate lengthy cascades and is used to reduce the number of candidate seeds. The combination of influencer and susceptible vectors form the diffusion probabilities between nodes. These are used to reformulate the computation of the influence spread and propose a greedy solution to influence maximization that retains the theoretical guarantees. We apply our method in three sizable datasets and evaluate it using cascades from future time steps. IMINFECTOR ’s scalability and accuracy outperform various competitive algorithms and metrics from the diverse landscape of influence maximization.},
  archive      = {J_TKDE},
  author       = {George Panagopoulos and Fragkiskos D. Malliaros and Michalis Vazirgiannis},
  doi          = {10.1109/TKDE.2020.3040028},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4398-4409},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-task learning for influence estimation and maximization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling high-order social relations for item
recommendation. <em>TKDE</em>, <em>34</em>(9), 4385–4397. (<a
href="https://doi.org/10.1109/TKDE.2020.3039463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of online social network makes it compulsory to study how social relations affect user choice. However, most existing methods leverage only first-order social relations, that is, the direct neighbors that are connected to the target user. The high-order social relations, e.g., the friends of friends, which are very informative to reveal user preference, have been largely ignored. In this work, we focus on modeling the indirect influence from the high-order neighbors in social networks to improve the performance of item recommendation. Distinct from mainstream social recommenders that regularize the model learning with social relations, we instead propose to directly factor social relations in the predictive model, aiming at learning better user embeddings to improve recommendation. To address the challenge that high-order neighbors increase dramatically with the order size, we propose to recursively “propagate” embeddings along the social network, effectively injecting the influence of high-order neighbors into user representation. We conduct experiments on two real datasets of Yelp and Douban to verify our High-Order Social Recommender (HOSR) model. Empirical results show that our HOSR significantly outperforms recent graph regularization-based recommenders NSCR and IF-BPR $^+$ , and graph convolutional network-based social influence prediction model DeepInf, achieving new state-of-the-arts of the task.},
  archive      = {J_TKDE},
  author       = {Yang Liu and Liang Chen and Xiangnan He and Jiaying Peng and Zibin Zheng and Jie Tang},
  doi          = {10.1109/TKDE.2020.3039463},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4385-4397},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Modelling high-order social relations for item recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MMCo-clus – an evolutionary co-clustering algorithm for gene
selection. <em>TKDE</em>, <em>34</em>(9), 4371–4384. (<a
href="https://doi.org/10.1109/TKDE.2020.3035695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of Big Data, cluster analysis of high-dimensional data sets often suffers from the Curse of dimensionality . To overcome this problem, the dimensionality reduction through feature selection becomes inevitable. Co-clustering or two-way clustering is considered to be a more sophisticated tool than conventional one-way clustering. Moreover, the advent of multi-view learning shows that the subjects of a data set can be interpreted in many ways. Interestingly, a minimal number of existing feature selection algorithms take advantage of the co-clustering method and are designed to consider multi-view data. Motivated by this, in the current article, we propose a feature (gene) selection method for high dimensional gene expression (GE) data through a m ulti-objective optimization based m ulti-view Co -Clus tering algorithm (named MMCo- Clus ). A popular evolutionary technique – Non-dominated Sorting Genetic Algorithm-II (NSGA-II) has been utilized as the proposed method&#39;s underlying optimization strategy. First, we construct two views of a chosen data set, utilizing knowledge from two different biological data sources. Next, we develop the MMCo- Clus algorithm considering the constructed views to identify a set of “good” co-clustering solutions. Finally, based on a concept of consensus operation on the co-clustering outcome, a small number of most relevant and non-redundant features are extracted from the original feature-space. The reduced dimension formed by new feature-space causes to decrease the computational burden and noise level of original data. For experimental analysis, we have chosen three benchmark GE data sets. Our feature selection method&#39;s effectiveness is evaluated through sample-classification accuracy, accompanied by the cluster profile plot/Eisen plot/t-SNE plot, and biological/statistical significance test. A thorough comparative analysis with existing feature selection algorithms using external and internal evaluation metrics supports our proposed method&#39;s potency.},
  archive      = {J_TKDE},
  author       = {Laizhong Cui and Sudipta Acharya and Sumit Mishra and Yi Pan and Joshua Zhexue Huang},
  doi          = {10.1109/TKDE.2020.3035695},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4371-4384},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MMCo-clus – an evolutionary co-clustering algorithm for gene selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximizing the diversity of exposure in a social network.
<em>TKDE</em>, <em>34</em>(9), 4357–4370. (<a
href="https://doi.org/10.1109/TKDE.2020.3038711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social-media platforms have created new ways for citizens to stay informed and participate in public debates. However, to enable a healthy environment for information sharing, social deliberation, and opinion formation, citizens need to be exposed to sufficiently diverse viewpoints that challenge their assumptions, instead of being trapped inside filter bubbles. In this paper, we take a step in this direction and propose a novel approach to maximize the diversity of exposure in a social network. We formulate the problem in the context of information propagation, as a task of recommending a small number of news articles to selected users. In the proposed setting, we take into account content and user leanings, and the probability of further sharing an article. Our model allows to capture the balance between maximizing the spread of information and ensuring the exposure of users to diverse viewpoints. The resulting problem can be cast as maximizing a monotone and submodular function, subject to a matroid constraint on the allocation of articles to users. It is a challenging generalization of the influence-maximization problem. Yet, we are able to devise scalable approximation algorithms by introducing a novel extension to the notion of random reverse-reachable sets. We experimentally demonstrate the efficiency and scalability of our algorithm on several real-world datasets.},
  archive      = {J_TKDE},
  author       = {Antonis Matakos and Cigdem Aslay and Esther Galbrun and Aristides Gionis},
  doi          = {10.1109/TKDE.2020.3038711},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4357-4370},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Maximizing the diversity of exposure in a social network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LTC: A fast algorithm to accurately find significant items
in data streams. <em>TKDE</em>, <em>34</em>(9), 4342–4356. (<a
href="https://doi.org/10.1109/TKDE.2020.3038911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding top- $k$ frequent items has been a hot issue in databases. Finding top- $k$ persistent items is a new issue, and has attracted increasing attention in recent years. In practice, users often want to know which items are significant, i.e. , not only frequent but also persistent. No prior art can address both of the above two issues at the same time. Also, for high-speed data streams, prior art cannot achieve high accuracy when the memory is tight. In this paper, we define a new issue, named finding significant items, and propose a novel algorithm namely LTC to address this issue. It includes two key techniques, Long-tail Restoring and CLOCK, as well as three optimizations. In addition, LTC is extended to support finding significant items with thresholds. We theoretically derive the correct rate and error bound, and conduct extensive experiments on three real datasets to test the performance of LTC. Our experimental results show that LTC can achieve $10^5$ times higher accuracy in terms of average relative error than other related algorithms. Lastly, LTC is applied to a DDoS detection task and it shows that finding significant items is more powerful than finding frequent items.},
  archive      = {J_TKDE},
  author       = {Shiyu Cheng and Dongsheng Yang and Tong Yang and Haowei Zhang and Bin Cui},
  doi          = {10.1109/TKDE.2020.3038911},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4342-4356},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LTC: A fast algorithm to accurately find significant items in data streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning inter-modal correspondence and phenotypes from
multi-modal electronic health records. <em>TKDE</em>, <em>34</em>(9),
4328–4341. (<a href="https://doi.org/10.1109/TKDE.2020.3038211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative tensor factorization has been shown a practical solution to automatically discover phenotypes from the electronic health records (EHR) with minimal human supervision. Such methods generally require an input tensor describing the inter-modal interactions to be pre-established; however, the correspondence between different modalities (e.g., correspondence between medications and diagnoses) can often be missing in practice. Although heuristic methods can be applied to estimate them, they inevitably introduce errors, and leads to sub-optimal phenotype quality. This is particularly important for patients with complex health conditions (e.g., in critical care) as multiple diagnoses and medications are simultaneously present in the records. To alleviate this problem and discover phenotypes from EHR with unobserved inter-modal correspondence, we propose the collective hidden interaction tensor factorization (cHITF) to infer the correspondence between multiple modalities jointly with the phenotype discovery. We assume that the observed matrix for each modality is marginalization of the unobserved inter-modal correspondence, which are reconstructed by maximizing the likelihood of the observed matrices. Extensive experiments conducted on the real-world MIMIC-III dataset demonstrate that cHITF effectively infers clinically meaningful inter-modal correspondence, discovers phenotypes that are more clinically relevant and diverse, and achieves better predictive performance compared with a number of state-of-the-art computational phenotyping models.},
  archive      = {J_TKDE},
  author       = {Kejing Yin and William K. Cheung and Benjamin C. M. Fung and Jonathan Poon},
  doi          = {10.1109/TKDE.2020.3038211},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4328-4341},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning inter-modal correspondence and phenotypes from multi-modal electronic health records},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Index-based intimate-core community search in large weighted
graphs. <em>TKDE</em>, <em>34</em>(9), 4313–4327. (<a
href="https://doi.org/10.1109/TKDE.2020.3040762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community search that finds query-dependent communities has been studied on various kinds of graphs. As one instance of community search, intimate-core group (community) search over a weighted graph is to find a connected $k$ -core containing all query nodes with the smallest group weight. However, existing state-of-the-art methods start from the maximal $k$ -core to refine an answer, which is practically inefficient for large networks. In this paper, we develop an efficient framework, called l ocal e xploration k -core s earch (LEKS), to find intimate-core groups in graphs. We propose a small-weighted spanning tree to connect query nodes, and then expand the tree level by level to a connected $k$ -core, which is finally refined as an intimate-core group. In addition, to support the intimate group search over large weighted graphs, we develop a weighted-core index (WC-index) and two new WC-index-based algorithms for expansion and refinement phases in LEKS. Specifically, we propose a WC-index-based expansion to efficiently find a candidate graph of intimate-core group, leveraging on a two-level expansion of $k$ -breadth and 1-depth. We propose two graph removal strategies: coarse-grained refinement is designed for large graphs to delete a batch of nodes in a few iterations; fine-grained refinement is designed for small graphs to remove nodes carefully and achieve high-quality answers. Extensive experiments on real-life networks with ground-truth communities validate the effectiveness and efficiency of our proposed methods.},
  archive      = {J_TKDE},
  author       = {Longxu Sun and Xin Huang and Rong-Hua Li and Byron Choi and Jianliang Xu},
  doi          = {10.1109/TKDE.2020.3040762},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4313-4327},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Index-based intimate-core community search in large weighted graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving deep forest by screening. <em>TKDE</em>,
<em>34</em>(9), 4298–4312. (<a
href="https://doi.org/10.1109/TKDE.2020.3038799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most studies about deep learning are based on neural network models, where many layers of parameterized nonlinear differentiable modules are trained by backpropagation. Recently, it has been shown that deep learning can also be realized by non-differentiable modules without backpropagation training called deep forest. We identify that deep forest has high time costs and memory requirements—this has inhibited its use on large-scale datasets. In this paper, we propose a simple and effective approach with three main strategies for efficient learning of deep forest. First, it substantially reduces the number of instances that needs to be processed through redirecting instances having high predictive confidence straight to the final level for prediction, by-passing all the intermediate levels. Second, many non-informative features are screened out, and only the informative ones are used for learning at each level. Third, an unsupervised feature transformation procedure is proposed to replace the supervised multi-grained scanning procedure. Our theoretical analysis supports the proposed approach in varying the model complexity from low to high as the number of levels increases in deep forest. Experiments show that our approach achieves highly competitive predictive performance with reduced time cost and memory requirement by one to two orders of magnitude.},
  archive      = {J_TKDE},
  author       = {Ming Pang and Kai Ming Ting and Peng Zhao and Zhi-Hua Zhou},
  doi          = {10.1109/TKDE.2020.3038799},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4298-4312},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Improving deep forest by screening},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous network crawling: Reaching target nodes by
motif-guided navigation. <em>TKDE</em>, <em>34</em>(9), 4285–4297. (<a
href="https://doi.org/10.1109/TKDE.2020.3038458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With numerous nodes on online heterogeneous networks, how to reach and extract target nodes of our specific interests is a pressing problem. In this paper, we propose a novel heterogeneous network crawler, MCrawl . It addresses the problem via iterative online heterogeneous network crawling by navigating its available APIs, starting from a set of target nodes, i.e., seed nodes. We are facing two challenges towards addressing the problem. First, to navigate within a vast network, how do we start from a small set of target nodes? In other words, which nodes in the “current frontier” and which direction shall we expand, to reach promising target nodes quickly? We propose motif-based crawling to exploit the complex structures and rich semantics of heterogeneous networks. Second, in many scenarios, we do not have a classifier to assess the quality of the harvested nodes and thus the motifs to expand. We develop a probabilistic inference framework to estimate the yield and harvest rates of motifs, achieving principled bootstrapping for crawling. Our experiment on real networks of MCrawl achieves significant margins over baselines.},
  archive      = {J_TKDE},
  author       = {Changyu Wang and Kevin Chen-Chuan Chang and Pinghui Wang and Tao Qin and Xiaohong Guan},
  doi          = {10.1109/TKDE.2020.3038458},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4285-4297},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Heterogeneous network crawling: Reaching target nodes by motif-guided navigation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating knowledge-based attentive user representations
for sparse interaction recommendation. <em>TKDE</em>, <em>34</em>(9),
4270–4284. (<a href="https://doi.org/10.1109/TKDE.2020.3037029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have been widely imported into collaborative-filtering (CF) based recommender systems and yielded remarkable superiority over traditional recommendation models. However, most deep CF-based models perform weakly when observed user-item interactions are sparse since user preferences and item characteristics are inferred mainly based on observed (historical) interactions. To address this problem, we propose a deep knowledge-enhanced recommendation model in this paper. Specifically, to augment user/item representations in the scenario of sparse historical user-item interactions, we first incorporate the knowledge from open knowledge graphs and personal information of users as side information, from which sufficient features of users and items are extracted. Second, to well capture shifted user preferences, we leverage a memory component constituted by recently interacted items rather than all historical ones. Third, attentive user representations are generated by attention mechanism to capture the diversity of user preferences. Furthermore, we build a convolutional neural network to pool the latent features in user representations for better user modeling, which enhances recommendation performance further. Our extensive experiments conducted against two real-world datasets, i.e., Douban movie and NetEase music, demonstrate our model’s remarkable superiority over the state-of-the-art deep recommendation models.},
  archive      = {J_TKDE},
  author       = {Deqing Yang and Chenlu Shen and Baichuan Liu and Lyuxin Xue and Yanghua Xiao},
  doi          = {10.1109/TKDE.2020.3037029},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4270-4284},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Generating knowledge-based attentive user representations for sparse interaction recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GAIN: Graph attention &amp; interaction network for
inductive semi-supervised learning over large-scale graphs.
<em>TKDE</em>, <em>34</em>(9), 4257–4269. (<a
href="https://doi.org/10.1109/TKDE.2020.3036212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have led to state-of-the-art performance on a variety of machine learning tasks such as recommendation, node classification and link prediction. Graph neural network models generate node embeddings by merging nodes features with the aggregated neighboring nodes information. Most existing GNN models exploit a single type of aggregator (e.g., mean-pooling) to aggregate neighboring nodes information, and then add or concatenate the output of aggregator to the current representation vector of the center node. However, using only a single type of aggregator is difficult to capture the different aspects of neighboring information and the simple addition or concatenation update methods limit the expressive capability of GNNs. Not only that, existing supervised or semi-supervised GNN models are trained based on the loss function of the node label, which leads to the neglect of graph structure information. In this paper, we propose a novel graph neural network architecture, Graph Attention &amp; Interaction Network (GAIN), for inductive learning on graphs. Unlike the previous GNN models that only utilize a single type of aggregation method, we use multiple types of aggregators to gather neighboring information in different aspects and integrate the outputs of these aggregators through the aggregator-level attention mechanism. Furthermore, we design a graph regularized loss to better capture the topological relationship of the nodes in the graph. Additionally, we first present the concept of graph feature interaction and propose a vector-wise explicit feature interaction mechanism to update the node embeddings. We conduct comprehensive experiments on two node-classification benchmarks and a real-world financial news dataset. The experiments demonstrate our GAIN model outperforms current state-of-the-art performances on all the tasks.},
  archive      = {J_TKDE},
  author       = {Yunpeng Weng and Xu Chen and Liang Chen and Wei Liu},
  doi          = {10.1109/TKDE.2020.3036212},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4257-4269},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GAIN: Graph attention &amp; interaction network for inductive semi-supervised learning over large-scale graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Few-shot named entity recognition via meta-learning.
<em>TKDE</em>, <em>34</em>(9), 4245–4256. (<a
href="https://doi.org/10.1109/TKDE.2020.3038670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning under the $N$ -way $K$ -shot setting (i.e., $K$ annotated samples for each of $N$ classes) has been widely studied in relation extraction (e.g., FewRel) and image classification (e.g., Mini-ImageNet). Named entity recognition (NER) is typically framed as a sequence labeling problem where the entity classes are inherently entangled together because the entity number and classes in a sentence are not known in advance, leaving the $N$ -way $K$ -shot NER problem so far unexplored. In this paper, we first formally define a more suitable $N$ -way $K$ -shot setting for NER. Then we propose FewNER , a novel meta-learning approach for few-shot NER. FewNER separates the entire network into a task-independent part and a task-specific part. During training in FewNER , the task-independent part is meta-learned across multiple tasks and the task-specific part is learned for each individual task in a low-dimensional space. At test time, FewNER keeps the task-independent part fixed and adapts to a new task via gradient descent by updating only the task-specific part, resulting in it being less prone to overfitting and more computationally efficient. Compared with pre-trained language models (e.g., BERT and ELMo) which obtain the transferability in an implicit manner (i.e., relying on large-scale corpora), FewNER explicitly optimizes the capability of “learning to adapt quickly” through meta-learning. The results demonstrate that FewNER achieves state-of-the-art performance against nine baseline methods by significant margins on three adaptation experiments (i.e., intra-domain cross-type, cross-domain intra-type and cross-domain cross-type).},
  archive      = {J_TKDE},
  author       = {Jing Li and Billy Chiu and Shanshan Feng and Hao Wang},
  doi          = {10.1109/TKDE.2020.3038670},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4245-4256},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Few-shot named entity recognition via meta-learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting reuse for GPU subgraph enumeration.
<em>TKDE</em>, <em>34</em>(9), 4231–4244. (<a
href="https://doi.org/10.1109/TKDE.2020.3035564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph enumeration is important for many applications such as network motif discovery, community detection, and frequent subgraph mining. To accelerate the execution, recent works utilize graphics processing units (GPUs) to parallelize subgraph enumeration. The performances of these parallel schemes are dominated by the set intersection operations which account for up to 95 percent of the total processing time. (Un)surprisingly, a significant portion (as high as 99 percent) of these operations is actually redundant, i.e., the same set of vertices is repeatedly encountered and evaluated. Therefore, in this article, we seek to salvage and recycle the results of such operations to avoid repeated computation. Our solution consists of two phases. In the first phase, we generate a reusable plan that determines the opportunity for reuse. The plan is based on a novel reuse discovery mechanism that can identify available results to prevent redundant computation. In the second phase, the plan is executed to produce the subgraph enumeration results. This processing is based on a newly designed reusable parallel search strategy that can efficiently maintain and retrieve the results of set intersection operations. Our implementation on GPUs shows that our approach can achieve up to 5 times speedups compared with the state-of-the-art GPU solutions.},
  archive      = {J_TKDE},
  author       = {Wentian Guo and Yuchen Li and Kian-Lee Tan},
  doi          = {10.1109/TKDE.2020.3035564},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4231-4244},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Exploiting reuse for GPU subgraph enumeration},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enumerating maximum cliques in massive graphs.
<em>TKDE</em>, <em>34</em>(9), 4215–4230. (<a
href="https://doi.org/10.1109/TKDE.2020.3036013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cliques refer to subgraphs in an undirected graph such that vertices in each subgraph are pairwise adjacent. The maximum clique problem, to find the clique with most vertices in a given graph, has been extensively studied. Besides its theoretical value as an NP-hard problem, the maximum clique problem is known to have direct applications in various fields, such as community search in social networks and social media, team formation in expert networks, gene expression and motif discovery in bioinformatics and anomaly detection in complex networks, revealing the structure and function of networks. However, algorithms designed for the maximum clique problem are expensive to deal with real-world networks. In this paper, we first devise a randomized algorithm for the maximum clique problem. Different from previous algorithms that search from each vertex one after another, our approach RMC , for the randomized maximum clique problem, employs a binary search while maintaining a lower bound $\underline{\omega _c}$ and an upper bound $\overline{\omega _c}$ of $\omega (G)$ . In each iteration, RMC attempts to find a $\omega _t$ -clique where $\omega _t=\lfloor (\underline{\omega _c}+\overline{\omega _c})/2\rfloor$ . As finding $\omega _t$ in each iteration is NP-complete, we extract a seed set $S$ such that the problem of finding a $\omega _t$ -clique in $G$ is equivalent to finding a $\omega _t$ -clique in $S$ with probability guarantees ( $\geq$ $ 1-n^{-c}$ ). We propose a novel iterative algorithm to determine the maximum clique by searching a $k$ -clique in $S$ starting from $k=\underline{\omega _c}+1$ until $S$ becomes $\lbrace \rbrace$ , when more iterations benefit marginally. Due to the potential inconsistency of maximum clique algorithms, we study the problem of maximum clique enumeration and propose an efficient algorithm RMCE to enumerate all maximum cliques in a given graph. As confirmed by the experiments, both RMC and RMCE are much more efficient and robust than previous solutions, RMC can always find the exact maximum clique, and RMCE can always enumerate all maximum cliques in a given graph.},
  archive      = {J_TKDE},
  author       = {Can Lu and Jeffrey Xu Yu and Hao Wei and Yikai Zhang},
  doi          = {10.1109/TKDE.2020.3036013},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4215-4230},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enumerating maximum cliques in massive graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entity alignment for knowledge graphs with multi-order
convolutional networks. <em>TKDE</em>, <em>34</em>(9), 4201–4214. (<a
href="https://doi.org/10.1109/TKDE.2020.3038654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) have become popular structures for unifying real-world entities by modelling the relationships between them and their attributes. To support multilingual applications, a significant number of language-specific KGs have been built by different parties using various data sources. As a result, these monolingual KGs are often disconnected, causing semantic heterogeneity and detracting from the original purpose of KGs. Entity alignment – the task of identifying corresponding entities across different KGs – has attracted a great deal of attention in both academia and industry. However, existing alignment techniques often require large amounts of labelled data, are unable to encode multi-modal data simultaneously, and enforce only a few consistency constraints. In this paper, we propose an end-to-end, unsupervised entity alignment framework for cross-lingual KGs that fuses different types of information in order to fully exploit the richness of KG data. The model captures the relation-based correlation between entities by using a multi-order graph convolutional neural (GCN) model that is designed to satisfy the consistency constraints, while incorporating the attribute-based correlation via a translation machine. We adopt a late-fusion mechanism to combine all the information together, which allows these approaches to complement each other and thus enhances the final alignment result, and makes the model more robust to consistency violations. Empirical results for various scenarios on real-world and synthetic KGs show that our model is up to 22.71 percent more accurate and orders of magnitude faster than existing baselines. We also demonstrate its sensitivity to hyper-parameters, effort saving in terms of labelling, and the robustness against adversarial conditions.},
  archive      = {J_TKDE},
  author       = {Nguyen Thanh Tam and Huynh Thanh Trung and Hongzhi Yin and Tong Van Vinh and Darnbi Sakong and Bolong Zheng and Nguyen Quoc Viet Hung},
  doi          = {10.1109/TKDE.2020.3038654},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4201-4214},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Entity alignment for knowledge graphs with multi-order convolutional networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient radius-bounded community search in geo-social
networks. <em>TKDE</em>, <em>34</em>(9), 4186–4200. (<a
href="https://doi.org/10.1109/TKDE.2020.3040172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by real-life applications in geo-social networks, we study the problem of computing radius-bounded $k$ -cores (RB- $k$ -cores) that aims to find communities satisfying both social and spatial constraints. In particular, the model $k$ -core (i.e., the subgraph where each vertex has at least $k$ neighbors) is used to ensure the social cohesiveness, and a radius-bounded circle is used to restrict the locations of users in an RB- $k$ -core. We explore several algorithmic paradigms to compute RB- $k$ -cores, including a triple-vertex-based paradigm, a binary-vertex-based paradigm, and a paradigm utilizing the concept of rotating circles. The rotating-circle-based paradigm is further enhanced by several pruning techniques to achieve better efficiency. In addition, to find representative RB- $k$ -cores, we study the diversified radius-bounded $k$ -core search problem, which finds $t$ RB- $k$ -cores to cover the most number of vertices. We first propose a baseline algorithm that identifies the distinctive RB- $k$ -cores after finding all the RB- $k$ -cores. Beyond this, we design algorithms that can efficiently maintain the top- $t$ candidate RB- $k$ -cores and also achieve a guaranteed approximation ratio. Experimental studies on both real and synthetic datasets demonstrate that our proposed techniques can efficiently compute (diversified) RB- $k$ -cores. Moreover, our techniques can be used to compute the minimum-circle-bounded $k$ -core and significantly outperform the existing techniques.},
  archive      = {J_TKDE},
  author       = {Kai Wang and Shuting Wang and Xin Cao and Lu Qin},
  doi          = {10.1109/TKDE.2020.3040172},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4186-4200},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient radius-bounded community search in geo-social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective and efficient discovery of top-k meta paths in
heterogeneous information networks. <em>TKDE</em>, <em>34</em>(9),
4172–4185. (<a href="https://doi.org/10.1109/TKDE.2020.3037218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks (HINs) , which are typed graphs with labeled nodes and edges, have attracted tremendous interest from academia and industry. Given two HIN nodes $s$ and $t$ , and a natural number $k$ , we study the discovery of the $k$ most important meta paths in real time, which can be used to support friend search, product recommendation, anomaly detection, and graph clustering. In this work, we argue that the shortest path between $s$ and $t$ may not necessarily be the most important path. As such, we combine several ranking functions, which are based on frequency and rarity , to redefine the unified importance function of the meta paths between $s$ and $t$ . Although this importance function can capture more information, it is very time-consuming to find top- $k$ meta paths using this importance function. Therefore, we integrate this importance function into a multi-step framework, which can efficiently filter some impossible meta paths between $s$ and $t$ . In addition, we combine bidirectional searching algorithm with this framework to further boost the efficiency performance. The experiment on different datasets shows that our proposed method outperforms state-of-the-art algorithms in terms of effectiveness with reasonable response time.},
  archive      = {J_TKDE},
  author       = {Zichen Zhu and Tsz Nam Chan and Reynold Cheng and Loc Do and Zhipeng Huang and Haoci Zhang},
  doi          = {10.1109/TKDE.2020.3037218},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4172-4185},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Effective and efficient discovery of top-k meta paths in heterogeneous information networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Easy-but-effective domain sub-similarity learning for
transfer regression. <em>TKDE</em>, <em>34</em>(9), 4161–4171. (<a
href="https://doi.org/10.1109/TKDE.2020.3039806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer covariance function, which can model domain similarity and adaptively control the knowledge transfer across domains, is widely used in transfer learning. In this paper, we concentrate on Gaussian process ( GP ) models using a transfer covariance function for regression problems in a black-box learning scenario. Precisely, we investigate a family of rather general transfer covariance functions, ${T}_{*}$ , that can model the heterogeneous sub-similarities of domains through multiple kernel learning. A necessary and sufficient condition to obtain valid GP s using ${T}_{*}$ ( $GP_{T_{*}}$ ) for any data is given. This condition becomes specially handy for practical applications as (i) it enables semantic interpretations of the sub-similarities and (ii) it can readily be used for model learning. In particular, we propose a computationally inexpensive model learning rule that can explicitly capture different sub-similarities of domains. We propose two instantiations of $GP_{T_{*}}$ , one with a set of predefined constant base kernels and one with a set of learnable parametric base kernels. Extensive experiments on 36 synthetic transfer tasks and 12 real-world transfer tasks demonstrate the effectiveness of $GP_{T_{*}}$ on the sub-similarity capture and the transfer performance.},
  archive      = {J_TKDE},
  author       = {Pengfei Wei and Ramon Sagarna and Yiping Ke and Yew-Soon Ong},
  doi          = {10.1109/TKDE.2020.3039806},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4161-4171},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Easy-but-effective domain sub-similarity learning for transfer regression},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Developing an unsupervised real-time anomaly detection
scheme for time series with multi-seasonality. <em>TKDE</em>,
<em>34</em>(9), 4147–4160. (<a
href="https://doi.org/10.1109/TKDE.2020.3035685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-line detection of anomalies in time series is a key technique used in various event-sensitive scenarios such as robotic system monitoring, smart sensor networks and data center security. However, the increasing diversity of data sources and the variety of demands make this task more challenging than ever. First, the rapid increase in unlabeled data means supervised learning is becoming less suitable in many cases. Second, a large portion of time series data have complex seasonality features. Third, on-line anomaly detection needs to be fast and reliable. In light of this, we have developed a prediction-driven, unsupervised anomaly detection scheme, which adopts a backbone model combining the decomposition and the inference of time series data. Further, we propose a novel metric, Local Trend Inconsistency (LTI), and an efficient detection algorithm that computes LTI in a real-time manner and scores each data point robustly in terms of its probability of being anomalous. We have conducted extensive experimentation to evaluate our algorithm with several datasets from both public repositories and production environments. The experimental results show that our scheme outperforms existing representative anomaly detection algorithms in terms of the commonly used metric, Area Under Curve (AUC), while achieving the desired efficiency.},
  archive      = {J_TKDE},
  author       = {Wentai Wu and Ligang He and Weiwei Lin and Yi Su and Yuhua Cui and Carsten Maple and Stephen Jarvis},
  doi          = {10.1109/TKDE.2020.3035685},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4147-4160},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Developing an unsupervised real-time anomaly detection scheme for time series with multi-seasonality},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detect professional malicious user with metric learning in
recommender systems. <em>TKDE</em>, <em>34</em>(9), 4133–4146. (<a
href="https://doi.org/10.1109/TKDE.2020.3040618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In e-commerce, online retailers are usually suffering from professional malicious users (PMUs), who utilize negative reviews and low ratings to their consumed products on purpose to threaten the retailers for illegal profits. PMUs are difficult to be detected because they utilize masking strategies to disguise themselves as normal users. Specifically, there are three challenges for PMU detection: 1) professional malicious users do not conduct any abnormal or illegal interactions (they never concurrently leave too many negative reviews and low ratings at the same time), and they conduct masking strategies to disguise themselves. Therefore, conventional outlier detection methods are confused by their masking strategies. 2) the PMU detection model should take both ratings and reviews into consideration, which makes PMU detection a multi-modal problem. 3) there are no datasets with labels for professional malicious users in public, which makes PMU detection an unsupervised learning problem. To this end, we propose an unsupervised multi-modal learning model: MMD, which employs Metric learning for professional Malicious users Detection with both ratings and reviews. MMD first utilizes a modified RNN to project the informational review into a sentiment score, which jointly considers the ratings and reviews. Then professional malicious user profiling (MUP) is proposed to catch the sentiment gap between sentiment scores and ratings. MUP filters the users and builds a candidate PMU set. We apply a metric learning-based clustering to learn a proper metric matrix for PMU detection. Finally, we can utilize this metric and labeled users to detect PMUs. Specifically, we apply the attention mechanism in metric learning to improve the model’s performance. The extensive experiments in four datasets demonstrate that our proposed method can solve this unsupervised detection problem. Moreover, the performance of the state-of-the-art recommender models is enhanced by taking MMD as a preprocessing stage.},
  archive      = {J_TKDE},
  author       = {Yuanbo Xu and Yongjian Yang and En Wang and Fuzhen Zhuang and Hui Xiong},
  doi          = {10.1109/TKDE.2020.3040618},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4133-4146},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Detect professional malicious user with metric learning in recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CuWide: Towards efficient flow-based training for sparse
wide models on GPUs. <em>TKDE</em>, <em>34</em>(9), 4119–4132. (<a
href="https://doi.org/10.1109/TKDE.2020.3038109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wide models such as generalized linear models and factorization-based models have been extensively used in various predictive applications, e.g., recommendation, CTR prediction, and image recognition. Due to the memory bounded property of the models, the performance improvement on CPU is reaching the limitation. GPU is known to have many computation units and high memory bandwidth, and becomes a promising platform for training machine learning models. However, the GPU training for the wide models is far from optimal due to the sparsity and irregularity in wide models. The existing GPU-based wide models are even slower than the ones using CPU. The classical training schema of the wide models does not optimized for the GPU architecture, which suffers from large amount of random memory accesses and redundant read/write of intermediate values. In this paper, we propose an efficient GPU-training framework for the large-scale wide models, named cuWide. To fully benefit from the memory hierarchy of GPU, cuWide applies a new flow-based schema for training, which leverages the spatial and temporal locality of wide models to drastically reduce the amount of communication with GPU global memory. To do so, we adopt a bigraph computation model to efficiently realize the flow-based schema and exploit three flexible interfaces for programming. Further, we use the 2D partition of mini-batch (in sample and feature dimensions) with proposed graph abstraction to optimize GPU memory access for sparse data, and apply several spatial-temporal caching mechanisms (importance-based model caching and cross-stage accumulation caching mechanisms) to achieve a high performance kernel. To efficiently implement cuWide, we also propose several GPU-oriented optimizations, including feature-oriented data layout to enhance the data locality, replication mechanism to reduce update conflicts in shared memory, and multi-stream scheduling to overlap data transferring and kernel computing. We show that cuWide can be up to more than 20× faster than the state-of-the-art GPU solutions and multi-core CPU solutions.},
  archive      = {J_TKDE},
  author       = {Xupeng Miao and Lingxiao Ma and Zhi Yang and Yingxia Shao and Bin Cui and Lele Yu and Jiawei Jiang},
  doi          = {10.1109/TKDE.2020.3038109},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4119-4132},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CuWide: Towards efficient flow-based training for sparse wide models on GPUs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boundary-focused generative adversarial networks for
imbalanced and multimodal time series. <em>TKDE</em>, <em>34</em>(9),
4102–4118. (<a href="https://doi.org/10.1109/TKDE.2022.3182327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance problems have been reported as a major issue in various applications. Classification becomes further complicated when an imbalance occurs in time series data sets. To address time series data, it is necessary to consider their characteristics (i.e., high dimensionality, high correlations, and multimodality). Oversampling is a well-known approach for addressing this problem; however, such an approach does not appropriately consider the characteristics of time series data. This paper addresses these limitations by presenting a model-based oversampling approach, a boundary-focused generative adversarial network (BFGAN). The proposed BFGAN employs a specifically designed additional label for reflecting the importance of a sample&#39;s position in data space. Furthermore, the BFGAN generates artificial samples after taking into consideration a sample&#39;s multimodality and importance by using a suitable modified GAN structure. We present empirical results that reveal a significant improvement in the quality of the generated data when the proposed BFGAN is used as an oversampling algorithm for an imbalanced multimodal time series data set.},
  archive      = {J_TKDE},
  author       = {Han Kyu Lee and Jiyoon Lee and Seoung Bum Kim},
  doi          = {10.1109/TKDE.2022.3182327},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4102-4118},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Boundary-focused generative adversarial networks for imbalanced and multimodal time series},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attributed transition-based domain control knowledge for
domain-independent planning. <em>TKDE</em>, <em>34</em>(9), 4089–4101.
(<a href="https://doi.org/10.1109/TKDE.2020.3037058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-independent planning decouples a planning task specification from planning engines. As the specification is usually describing only the physics of the environment, actions and a goal, the planning engines being generic solvers designed to solve any planning task tend to struggle with tasks that can be easily solved by domain-specific algorithms. Additional control knowledge can, to large extent, bridge such a performance gap. Instead of providing a specific planner supporting a given form of control knowledge, control knowledge can be directly encoded within the planning task specification and thus can be exploited by generic planners. In this paper, we propose Attributed Transition-Based Domain Control Knowledge (ATB-DCK) that is represented by a finite state automaton with attributed states, referring to specific states of objects, connected by transitions imposing constraints on action applicability. ATB-DCK, roughly speaking, represents the “grammar” of solution plans that guides the search. We show that ATB-DCK can be compiled into a classical planning task and thus it complements domain-independent planning techniques. Using several domains from the International Planning Competitions as benchmarks, we demonstrate that this approach often considerably improves efficiency of existing state-of-the-art planning engines.},
  archive      = {J_TKDE},
  author       = {Lukáš Chrpa and Roman Barták and Jindřich Vodrážka and Marta Vomlelová},
  doi          = {10.1109/TKDE.2020.3037058},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4089-4101},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Attributed transition-based domain control knowledge for domain-independent planning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An attribute-aware attentive GCN model for attribute missing
in recommendation. <em>TKDE</em>, <em>34</em>(9), 4077–4088. (<a
href="https://doi.org/10.1109/TKDE.2020.3040772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As important side information, attributes have been widely exploited in the existing recommender system for better performance. However, in the real-world scenarios, it is common that some attributes of items/users are missing (e.g., some movies miss the genre data). Prior studies usually use a default value (i.e., “other”) to represent the missing attribute, resulting in sub-optimal performance. To address this problem, in this paper, we present an attribute-aware attentive graph convolution network (A ${^2}$ -GCN). In particular, we first construct a graph, where users, items, and attributes are three types of nodes and their associations are edges. Thereafter, we leverage the graph convolution network to characterize the complicated interactions among $&amp;lt;$ users, items, attributes $&amp;gt;$ . Furthermore, to learn the node representation, we adopt the message-passing strategy to aggregate the messages passed from the other directly linked types of nodes (e.g., a user or an attribute). Towards this end, we are capable of incorporating associate attributes to strengthen the user and item representation learning, and thus naturally solve the attribute missing problem. Given that for different users, the attributes of an item have different influence on their preference to this item, we design a novel attention mechanism to filter the message passed from an item to a target user by considering the attribute information. Extensive experiments have been conducted on several publicly accessible datasets to justify our model, demonstrating that our model outperforms several state-of-the-art methods and demonstrate the effectiveness of our attention method.},
  archive      = {J_TKDE},
  author       = {Fan Liu and Zhiyong Cheng and Lei Zhu and Chenghao Liu and Liqiang Nie},
  doi          = {10.1109/TKDE.2020.3040772},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4077-4088},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An attribute-aware attentive GCN model for attribute missing in recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A tensor-based markov chain model for heterogeneous
information network collective classification. <em>TKDE</em>,
<em>34</em>(9), 4063–4076. (<a
href="https://doi.org/10.1109/TKDE.2020.3039533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Information Network (HIN) collecitve classification studies the problem of predicting labels for one type of nodes in a HIN which contains multiple types of nodes multiple types of links among them. Previous studies have revealed that exploiting relative importance of links is quite useful to improve node classification performance as connected nodes tend to have similar labels. Most existing approaches exploit the relative importance of links either by directly counting the number of connections among nodes or by learning the weight of each type of link from labeled data only. However, these approaches either neglect the importance of types of links to the class labels or may lead to overfitting problem. We propose a T ensor-based Mark ov chain (T-Mark) approach, which is able to automatically and simultaneously predict the labels for unlabeled nodes and give the relative importance of types of links that actually improve the classification accuracy. Specifically, we build two tensor equations by using the HIN and features of nodes from both labeled and unlabeled data. A Markov chain-based model is proposed and it is solved by an iterative process to obtain the stationary distributions. Theoretical analyses of the existence and uniqueness of such probability distributions are given. Extensive experimental results demonstrate that T-Mark is able to achieve superior performance in the comparison and obtain reasonable relative importance of links.},
  archive      = {J_TKDE},
  author       = {Chao Han and Jian Chen and Mingkui Tan and Michael K. Ng and Qingyao Wu},
  doi          = {10.1109/TKDE.2020.3039533},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4063-4076},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A tensor-based markov chain model for heterogeneous information network collective classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel outlier detection method for multivariate data.
<em>TKDE</em>, <em>34</em>(9), 4052–4062. (<a
href="https://doi.org/10.1109/TKDE.2020.3036524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalous objects from given data has a broad range of real-world applications. Although there is a rich number of outlier detection algorithms, most of them involve hidden assumptions and restrictions. This paper proposes a novel, yet effective outlier learning algorithm that is based on decomposing the full attributes space into different combinations of subspaces, in which the 3D-vectors, representing the data points per 3D-subspace, are rotated about the geometric median, using Rodrigues rotation formula, to construct the overall outlying score. The proposed approach is parameter-free, requires no distribution assumptions and easy to implement. Extensive experimental study and comparison are conducted on both synthetic and real-world datasets with six popular outlier detection algorithms, each from different category. The comparison is evaluated based on the precision @s , average precision, rank power, AUC ROC and time complexity metrics. The results show that the performance of the proposed method is competitive and promising.},
  archive      = {J_TKDE},
  author       = {Yahya Almardeny and Noureddine Boujnah and Frances Cleary},
  doi          = {10.1109/TKDE.2020.3036524},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {9},
  pages        = {4052-4062},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A novel outlier detection method for multivariate data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Truss-based structural diversity search in large graphs.
<em>TKDE</em>, <em>34</em>(8), 4037–4051. (<a
href="https://doi.org/10.1109/TKDE.2020.3027950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social decisions made by individuals are easily influenced by information from their social neighborhoods. A key predictor of social contagion is the multiplicity of social contexts inside the individual’s contact neighborhood, which is termed structural diversity. However, the existing models have limited decomposability for analyzing large-scale networks, and suffer from the inaccurate reflection of social context diversity. In this paper, we propose a truss-based structural diversity model to overcome the weak decomposability. Based on this model, we study a novel problem of truss-based structural diversity search in a graph $G$ , that is, to find the $r$ vertices with the highest truss-based structural diversity and return their social contexts. To tackle this problem, we propose an online structural diversity search algorithm in $O(\rho (m+\mathcal {T}))$ time, where $\rho$ , $m$ , and $\mathcal {T}$ are respectively the arboricity, the number of edges, and the number of triangles in $G$ . To improve the efficiency, we design an elegant and compact index, called TSD-index, which keeps the structural diversity information for all individual vertices. We further optimize the structure of TSD-index into a highly compressed GCT-index. Our GCT-index-based structural diversity search utilizes the global triangle information for fast index construction and finds answers in $O(m)$ time. Extensive experiments demonstrate the effectiveness and efficiency of our proposed model and algorithms, against state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Jinbin Huang and Xin Huang and Jianliang Xu},
  doi          = {10.1109/TKDE.2020.3027950},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {4037-4051},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Truss-based structural diversity search in large graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards query pricing on incomplete data. <em>TKDE</em>,
<em>34</em>(8), 4024–4036. (<a
href="https://doi.org/10.1109/TKDE.2020.3026031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data have significant economic or social value in many application fields including science, business, governance, etc. This naturally leads to the emergence of many data markets such as GBDEx and YoueData. As a result, the data trade through data markets has started to receive attentions from both industry and academia. During the data buying and selling, how to price the data is an indispensable problem. However, pricing incomplete data is more challenging, even though incomplete data exist pervasively in a vast lot of real-life scenarios. In this paper, we attempt to explore the pricing problem for queries over incomplete data . We propose a sophisticated pricing mechanism, termed as ${\sf iDBPricer}$ , which takes a series of essential factors into consideration, including the data contribution/usage , data completeness , and query quality . We present two novel price functions, namely, the usage, and completeness-aware price function ( UCA price for short) and the quality, usage, and completeness-aware price function ( QUCA price for short). Moreover, we develop efficient algorithms for deriving the query prices. Extensive experiments using both real and benchmark datasets demonstrate ${\sf iDBPricer}$ is of excellent performance in terms of effectiveness and scalability, compared with the state-of-the-art price functions.},
  archive      = {J_TKDE},
  author       = {Xiaoye Miao and Yunjun Gao and Lu Chen and Huanhuan Peng and Jianwei Yin and Qing Li},
  doi          = {10.1109/TKDE.2020.3026031},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {4024-4036},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards query pricing on incomplete data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The node-similarity distribution of complex networks and its
applications in link prediction. <em>TKDE</em>, <em>34</em>(8),
4011–4023. (<a href="https://doi.org/10.1109/TKDE.2020.3026311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, quantifying the similarity of nodes has been a hot topic in network science, yet little has been known about the distribution of node-similarity. In this paper, we consider a typical measure of node-similarity called the common neighbor based similarity (CNS). By means of the generating function, we propose a general framework for calculating the CNS distributions of node sets in various networks. Particularly, we show that for the Erdös-Rényi random network, the CNS distribution of node sets of any size obeys the Poisson law. Furthermore, we connect the node-similarity distribution to the link prediction problem, and derive analytical solutions for two key evaluation metrics: i) precision and ii) area under the receiver operating characteristic curve (AUC). We also use the similarity distributions to optimize link prediction by i) deriving the expected prediction accuracy of similarity scores and ii) providing the optimal prediction priority of unconnected node pairs. Simulation results confirm our theoretical findings and also validate the proposed tools in evaluating and optimizing link prediction.},
  archive      = {J_TKDE},
  author       = {Cunlai Pu and Jie Li and Jian Wang and Tony Q. S. Quek},
  doi          = {10.1109/TKDE.2020.3026311},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {4011-4023},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {The node-similarity distribution of complex networks and its applications in link prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SPATM: A social period-aware topic model for personalized
venue recommendation. <em>TKDE</em>, <em>34</em>(8), 3997–4010. (<a
href="https://doi.org/10.1109/TKDE.2020.3029070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized venues recommendation is essential to help people find attractive venue to visit as growth of location-based social networks. Existing approaches never distinguish user individual interests from her social preferences, which leads to a bottleneck of modeling user check-in behaviors accurately. In this paper, we find the differences between user interests and her social preferences clearly and investigate the time law of user check-in behaviors in depth. Consequently, we propose a social-period-aware topic model (SPATM) to learn the influence weights of both user interests and her social preferences on making-decision for each check-in time automatically. Especially, we model latent topic by leveraging smaller size of dynamic activities instead of static categories, which can alleviate the data sparsity problem by using more co-occurrent activities information. Moreover, our approach can automatically judge whether a user’s social preference is periodic or aperiodic and learn the periodicity of periodic one. Furthermore, the Alias Sampling based training approach is introduced to improve sampling efficiency. The results demonstrate our proposed model is effective and outperforms the state-of-the-art approaches in terms of effectiveness and efficiency. Besides, SPATM can learn semantically coherent latent topics and geographically dispersed latent social topics which are useful to explain recommendation.},
  archive      = {J_TKDE},
  author       = {Weiyu Ji and Xiangwu Meng and Yujie Zhang},
  doi          = {10.1109/TKDE.2020.3029070},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3997-4010},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SPATM: A social period-aware topic model for personalized venue recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Semi-supervised city-wide parking availability prediction
via hierarchical recurrent graph neural network. <em>TKDE</em>,
<em>34</em>(8), 3984–3996. (<a
href="https://doi.org/10.1109/TKDE.2020.3034140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to predict city-wide parking availability is crucial for the successful development of Parking Guidance and Information (PGI) systems. The effective prediction of city-wide parking availability can boost parking efficiency, improve urban planning, and ultimately alleviate city congestion. However, it is a non-trivial task for city-wide parking availability prediction because of three major challenges: 1) the non-euclidean spatial autocorrelation among parking lots, 2) the dynamic temporal autocorrelation inside of and between parking lots, and 3) the scarcity of information about real-time parking availability obtained from real-time sensors (e.g., camera, ultrasonic sensor, and bluetooth sensor). To this end, we propose a Semi-supervised Hierarchical Recurrent Graph Neural Network-X ( SHARE-X ) to predict parking availability of each parking lot within a city. Specifically, we first propose a hierarchical graph convolution module to model the non-euclidean spatial autocorrelation among parking lots. Along this line, a contextual graph convolution block and a multi-resolution soft clustering graph convolution block are respectively proposed to capture local and global spatial dependencies between parking lots. Moreover, we devise a hierarchical attentive recurrent network module to incorporate both short and long-term dynamic temporal dependencies of parking lots. Additionally, a parking availability approximation module is introduced to estimate missing real-time parking availabilities from both spatial and temporal domains. Finally, experiments on two real-world datasets demonstrate that SHARE-X outperforms eight state-of-the-art baselines in parking availability prediction.},
  archive      = {J_TKDE},
  author       = {Weijia Zhang and Hao Liu and Yanchi Liu and Jingbo Zhou and Tong Xu and Hui Xiong},
  doi          = {10.1109/TKDE.2020.3034140},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3984-3996},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Semi-supervised city-wide parking availability prediction via hierarchical recurrent graph neural network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement online active learning ensemble for drifting
imbalanced data streams. <em>TKDE</em>, <em>34</em>(8), 3971–3983. (<a
href="https://doi.org/10.1109/TKDE.2020.3026196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications challenged by the joint problem of concept drift and class imbalance are attracting increasing research interest. This paper proposes a novel Reinforcement Online Active Learning Ensemble for Drifting Imbalanced data stream (ROALE-DI). The ensemble classifier has a long-term stable classifier and a dynamic classifier group which applies a reinforcement mechanism to increase the weight of the dynamic classifiers, which perform better on the minority class, and decreases the weight of the opposite. When the data stream is class imbalanced, the classifiers will lack the training samples of the minority class. To supply training samples, when creating a new classifier, the labeled instances buffer is used to provide instances of the minority class. Then, a hybrid labeling strategy that combines the uncertainty strategy and imbalance strategy is proposed to define whether to obtain the real label of an instance. An experimental evaluation compares the classification performance of the proposed method with semi-supervised and supervised algorithms on both real-world and synthetic data streams. The results show that the ROALE-DI achieves higher Area Under the ROC Curve (AUC) and accuracy values with even fewer real labels, and the labeling cost dynamically adjusts according to the concept drift and class imbalance ratio.},
  archive      = {J_TKDE},
  author       = {Hang Zhang and Weike Liu and Qingbao Liu},
  doi          = {10.1109/TKDE.2020.3026196},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3971-3983},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Reinforcement online active learning ensemble for drifting imbalanced data streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Position-transitional particle swarm
optimization-incorporated latent factor analysis. <em>TKDE</em>,
<em>34</em>(8), 3958–3970. (<a
href="https://doi.org/10.1109/TKDE.2020.3033324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional and sparse (HiDS) matrices are frequently found in various industrial applications. A latent factor analysis (LFA) model is commonly adopted to extract useful knowledge from an HiDS matrix, whose parameter training mostly relies on a stochastic gradient descent (SGD) algorithm. However, an SGD-based LFA model&#39;s learning rate is hard to tune in real applications, making it vital to implement its self-adaptation. To address this critical issue, this study firstly investigates the evolution process of a particle swarm optimization algorithm with care, and then proposes to incorporate more dynamic information into it for avoiding accuracy loss caused by premature convergence without extra computation burden, thereby innovatively achieving a novel position-transitional particle swarm optimization (P 2 SO) algorithm. It is subsequently adopted to implement a P 2 SO-based LFA (PLFA) model that builds a learning rate swarm applied to the same group of LFs. Thus, a PLFA model implements highly efficient learning rate adaptation as well as represents an HiDS matrix precisely. Experimental results on four HiDS matrices emerging from real applications demonstrate that compared with an SGD-based LFA model, a PLFA model no longer suffers from a tedious and expensive tuning process of its learning rate, and it can achieve even higher prediction accuracy for missing data of an HiDS matrix. On the other hand, compared with state-of-the-art adaptive LFA models, a PLFA model&#39;s prediction accuracy and computational efficiency are highly competitive. Hence, it has high potential in addressing real industrial issues.},
  archive      = {J_TKDE},
  author       = {Xin Luo and Ye Yuan and Sili Chen and Nianyin Zeng and Zidong Wang},
  doi          = {10.1109/TKDE.2020.3033324},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3958-3970},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Position-transitional particle swarm optimization-incorporated latent factor analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalized graph neural networks with attention mechanism
for session-aware recommendation. <em>TKDE</em>, <em>34</em>(8),
3946–3957. (<a href="https://doi.org/10.1109/TKDE.2020.3031329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of session-aware recommendation aims to predict users’ next click based on their current session and historical sessions. Existing session-aware recommendation methods have defects in capturing complex item transition relationships. Other than that, most of them fail to explicitly distinguish the effects of different historical sessions on the current session. To this end, we propose a novel method, named Personalized Graph Neural Networks with Attention Mechanism (A-PGNN) for brevity. A-PGNN mainly consists of two components: one is Personalized Graph Neural Network (PGNN), which is used to extract the personalized structural information in each user behavior graph, compared with the traditional Graph Neural Network (GNN) model, which considers the role of the user when the node embedding is updated. The other is Dot-Product Attention mechanism, which draws on the Transformer net to explicitly model the effect of historical sessions on the current session. Extensive experiments conducted on two real-world data sets show that A-PGNN evidently outperforms the state-of-the-art personalized session-aware recommendation methods.},
  archive      = {J_TKDE},
  author       = {Mengqi Zhang and Shu Wu and Meng Gao and Xin Jiang and Ke Xu and Liang Wang},
  doi          = {10.1109/TKDE.2020.3031329},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3946-3957},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Personalized graph neural networks with attention mechanism for session-aware recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Periodic communities mining in temporal networks: Concepts
and algorithms. <em>TKDE</em>, <em>34</em>(8), 3927–3945. (<a
href="https://doi.org/10.1109/TKDE.2020.3028025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periodicity is a frequently happening phenomenon for social interactions in temporal networks. Mining periodic communities are essential to understanding periodic group behaviors in temporal networks. Unfortunately, most previous studies for community mining in temporal networks ignore the periodic patterns of communities. In this paper, we study the problem of seeking periodic communities in a temporal network, where each edge is associated with a set of timestamps. We propose novel models, including $\sigma$ -periodic $k$ -core and $\sigma$ -periodic $k$ -clique, that represent periodic communities in temporal networks. Specifically, a $\sigma$ -periodic $k$ -core (or $\sigma$ -periodic $k$ -clique) is a $k$ -core (or clique with size larger than $k$ ) that appears at least $\sigma$ times periodically in the temporal graph. The problem of searching periodic core is efficient but the resulting communities may be not enough cohesive; the problem of enumerating all periodic cliques is not efficient (NP-hard) but the resulting communities are very cohesive. To compute all of them efficiently, we first develop two effective graph reduction techniques to significantly prune the temporal graph. Then, we transform the temporal graph into a static graph and prove that mining the periodic communities in the temporal graph equals mining communities in the transformed graph. Subsequently, we propose a decomposition algorithm to search maximal $\sigma$ -periodic $k$ -core, a Bron-Kerbosch style algorithm to enumerate all maximal $\sigma$ -periodic $k$ -cliques, and a branch-and-bound style algorithm to find the maximum $\sigma$ -periodic clique. The results of extensive experiments on five real-life datasets demonstrate the efficiency, scalability, and effectiveness of our algorithms.},
  archive      = {J_TKDE},
  author       = {Hongchao Qin and Rong-Hua Li and Ye Yuan and Guoren Wang and Weihua Yang and Lu Qin},
  doi          = {10.1109/TKDE.2020.3028025},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3927-3945},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Periodic communities mining in temporal networks: Concepts and algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parallel fractional hot-deck imputation and variance
estimation for big incomplete data curing. <em>TKDE</em>,
<em>34</em>(8), 3912–3926. (<a
href="https://doi.org/10.1109/TKDE.2020.3029146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fractional hot-deck imputation (FHDI) is a general-purpose, assumption-free imputation method for handling multivariate missing data by filling each missing item with multiple observed values without resorting to artificially created values. The corresponding R package FHDI J. Im, I. Cho, and J. K. Kim, “An R package for fractional hot deck imputation,” R J. , vol. 10, no. 1, pp. 140–154, 2018 holds generality and efficiency, but it is not adequate for tackling big incomplete data due to the requirement of excessive memory and long running time. As a first step to tackle big incomplete data by leveraging the FHDI, we developed a new version of a parallel fractional hot-deck imputation (named as P-FHDI) program suitable for curing large incomplete datasets. Results show a favorable speedup when the P-FHDI is applied to big datasets with up to millions of instances or 10,000 of variables. This paper explains the detailed parallel algorithms of the P-FHDI for large instances (big- $n$ ) or high-dimensionality (big- $p$ ) datasets and confirms the favorable scalability. The proposed program inherits all the advantages of the serial FHDI and enables a parallel variance estimation, which will benefit a broad audience in science and engineering.},
  archive      = {J_TKDE},
  author       = {Yicheng Yang and Jae Kwang Kim and In Ho Cho},
  doi          = {10.1109/TKDE.2020.3029146},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3912-3926},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Parallel fractional hot-deck imputation and variance estimation for big incomplete data curing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-query optimization of incrementally evaluated
sliding-window aggregations. <em>TKDE</em>, <em>34</em>(8), 3899–3911.
(<a href="https://doi.org/10.1109/TKDE.2020.3029770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online analytics, in most advanced scientific, business, and social media applications, rely heavily on the efficient execution of large numbers of Aggregate Continuous Queries ( ACQs ). ACQs continuously aggregate streaming data and periodically produce results such as max or average over a given window of the latest data. It has been shown that it is beneficial to use Incremental Evaluation ( IE ) for re-using calculations performed over parts of the ACQ window, and to share them in multi-query ( MQ ) environments among certain sets of ACQs . In this work, we re-examine how the principle of sharing is applied in IE techniques as well as in MQ optimizers. We provide an extensive taxonomy of IE techniques and a new approach of using the state-of-the-art IE techniques as part of MQ optimizers in a way that reduces the execution plan costs by up to 270,000x. We evaluate all of our solutions both theoretically and experimentally using both real and synthetic datasets.},
  archive      = {J_TKDE},
  author       = {Anatoli U. Shein and Panos K. Chrysanthis},
  doi          = {10.1109/TKDE.2020.3029770},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3899-3911},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-query optimization of incrementally evaluated sliding-window aggregations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mining high quality patterns using multi-objective
evolutionary algorithm. <em>TKDE</em>, <em>34</em>(8), 3883–3898. (<a
href="https://doi.org/10.1109/TKDE.2020.3033519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern mining (PM) refers to the process of discovering patterns of interest to users from data. However, most studies have considered only one pattern, such as frequent pattern or high-utility pattern. With the continuous requirement of businesses in various industries, the single-objective PM methods are difficult to meet the increasingly diverse needs of users. In this paper, a multi-objective problem model for high quality pattern mining (HQPM) is proposed, where the objectives are support, occupancy, and utility. In order to solve the proposed three-objective problem efficiently, an improved multi-objective evolutionary algorithm for HQPM (MOEA-PM) is proposed. Two kinds of population initialization strategies are designed, which is used to ensure the population is effectively distributed in the feasible solution space. By taking the properties of the model into consideration, an auxiliary tool is proposed to accelerate the convergence of the algorithm. Experimental results on real-world datasets show that the proposed three-objective problem model with the MOEA-PM algorithm can discover patterns that are both frequently occurring and has a high utility in the transaction datasets, while at the same time being relatively complete. Compared with the state-of-the-art MOEA-based HQPM algorithms, MOEA-PM has better performance in terms of efficiency, quality, and convergence speed.},
  archive      = {J_TKDE},
  author       = {Wei Fang and Qiang Zhang and Jun Sun and Xiaojun Wu},
  doi          = {10.1109/TKDE.2020.3033519},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3883-3898},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Mining high quality patterns using multi-objective evolutionary algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LogStore: A workload-aware, adaptable key-value store on
hybrid storage systems. <em>TKDE</em>, <em>34</em>(8), 3867–3882. (<a
href="https://doi.org/10.1109/TKDE.2020.3027191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to recent explosion of data volume and velocity, a new array of lightweight key-value stores have emerged to serve as alternatives to traditional databases. The majority of these storage engines, however, sacrifice their read performance in order to cope with write throughput by avoiding random disk access when writing a record in favor of fast sequential accesses. But, the boundary between sequential versus random access is becoming blurred with the advent of solid-state drives (SSDs). In this work, we propose our new key-value store, LogStore, optimized for hybrid storage architectures. Additionally, introduce a novel cost-based data staging model based on log-structured storage, in which recent changes are first stored on SSDs, and pushed to HDD as it ages, while minimizing the read/write amplification for merging data from SSDs and HDDs. Furthermore, we take a holistic approach in improving both the read and write performance by dynamically optimizing the data layout, such as deferring and reversing the compaction process, and developing an access strategy to leverage the strengths of each available medium in our storage hierarchy. Lastly, in our extensive evaluation, we demonstrate that LogStore achieves up to 6x improvement in throughput/latency over LevelDB, a state-of-the-art key-value store.},
  archive      = {J_TKDE},
  author       = {Prashanth Menon and Thamir M. Qadah and Tilmann Rabl and Mohammad Sadoghi and Hans-Arno Jacobsen},
  doi          = {10.1109/TKDE.2020.3027191},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3867-3882},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LogStore: A workload-aware, adaptable key-value store on hybrid storage systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning latent multi-criteria ratings from user reviews for
recommendations. <em>TKDE</em>, <em>34</em>(8), 3854–3866. (<a
href="https://doi.org/10.1109/TKDE.2020.3030623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria recommender systems have been increasingly useful for helping consumers identify the most relevant items based on different dimensions of user experiences and highlighting their most valued features. Therefore, researchers have proposed various multi-criteria models to improve recommendation performance. However, most of the existing methods utilize only multi-criteria ratings explicitly provided by the users. Note that explicit multi-criteria ratings are sparse and have the problem of missing values. User reviews, on the other hand, contain richer information of user experiences and reveal multi-dimensional user preferences. Therefore, we propose to use latent multi-criteria ratings generated from user reviews, as opposed to explicit multi-criteria ratings, to provide recommendations and capture latent complex heterogeneous user preferences. Specifically, we propose two novel models for the latent multi-criteria rating generation process: the one-stage model LatentMC-1S that utilizes document hashing method to directly compute latent ratings and the two-stage model LatentMC-2S that uses GRU and Gumbel-Softmax for indirect rating generation. Extensive experiments show that the proposed latent multi-criteria rating approaches outperform explicit ratings across different datasets and performance measures. We also show that latent multi-criteria ratings could be used for imputing missing explicit multi-criteria ratings and thus further improving multi-criteria recommender systems.},
  archive      = {J_TKDE},
  author       = {Pan Li and Alexander Tuzhilin},
  doi          = {10.1109/TKDE.2020.3030623},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3854-3866},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning latent multi-criteria ratings from user reviews for recommendations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). K-core based temporal graph convolutional network for
dynamic graphs. <em>TKDE</em>, <em>34</em>(8), 3841–3853. (<a
href="https://doi.org/10.1109/TKDE.2020.3033829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning is a fundamental task in various applications that strives to learn low-dimensional embeddings for nodes that can preserve graph topology information. However, many existing methods focus on static graphs while ignoring evolving graph patterns. Inspired by the success of graph convolutional networks(GCNs) in static graph embedding, we propose a novel k-core based temporal graph convolutional network, the CTGCN, to learn node representations for dynamic graphs. In contrast to previous dynamic graph embedding methods, CTGCN can preserve both local connective proximity and global structural similarity while simultaneously capturing graph dynamics. In the proposed framework, the traditional graph convolution is generalized into two phases, feature transformation and feature aggregation, which gives the CTGCN more flexibility and enables the CTGCN to learn connective and structural information under the same framework. Experimental results on 7 real-world graphs demonstrate that the CTGCN outperforms existing state-of-the-art graph embedding methods in several tasks, including link prediction and structural role classification. The source code of this work can be obtained from https://github.com/jhljx/CTGCN .},
  archive      = {J_TKDE},
  author       = {Jingxin Liu and Chang Xu and Chang Yin and Weiqiang Wu and You Song},
  doi          = {10.1109/TKDE.2020.3033829},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3841-3853},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {K-core based temporal graph convolutional network for dynamic graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint representation learning and clustering: A framework
for grouping partial multiview data. <em>TKDE</em>, <em>34</em>(8),
3826–3840. (<a href="https://doi.org/10.1109/TKDE.2020.3028422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial multi-view clustering has attracted various attentions from diverse fields. Most existing methods adopt separate steps to obtain unified representations and extract clustering indicators. This separate manner prevents two learning processes to negotiate to achieve optimal performance. In this paper, we propose the Joint Representation Learning and Clustering (JRLC) framework to address this issue. The JRLC framework employs representation matrices to extract view-specific clustering information directly from the presence of partial similarity matrices, and rotates them to learn a common probability label matrix simultaneously, which connects representation learning and clustering seamlessly to achieve better clustering performance. Under the guidance of JRLC framework, several new incomplete multi-view clustering methods can be developed by extending existing single-view graph-based representation learning methods. For illustration, within the framework, we propose two specific methods, JRLC with spectral embedding (JRLC-SE) and JRLC via integrating nonnegative embedding and spectral embedding (JRLC-NS). Two iterative algorithms with guaranteed convergence are designed to solve the resultant optimization problems of JRLC-SE and JRLC-NS. Experimental results on various datasets and news topic clustering application demonstrate the effectiveness of the proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Wenzhang Zhuge and Hong Tao and Tingjin Luo and Ling-Li Zeng and Chenping Hou and Dongyun Yi},
  doi          = {10.1109/TKDE.2020.3028422},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3826-3840},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Joint representation learning and clustering: A framework for grouping partial multiview data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identifying user relationship on WeChat money-gifting
network. <em>TKDE</em>, <em>34</em>(8), 3814–3825. (<a
href="https://doi.org/10.1109/TKDE.2020.3030807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of online social networks, the identification or classification of real-life relationship between users has been very useful for many applications such as financial fraud detection. In real life, usually people with different relationships would present gifts with special meanings to each other on different dates. In many Asian cultures, especially in Chinese culture, the red packet is a traditional form of monetary gift. With the rapid development of the Internet, people gradually began to give electronic red packets instead of paper ones as the means of money gifting on social network platforms. As motivated, in this paper we advocate a novel approach that exploits users’ red packet interactions for users relationship identification on WeChat, one of the largest social platforms in China. Specifically, we analyze the WeChat red packets network, identify the real-life relationship types between users through mining the semantic information of the amount and sending time of each red packet. In order to better capture the red packet gifting behaviors between users for relationship identification, on one hand, we construct an Amount-Date Graph and apply the graph embedding method to learn embeddings of the amount and sending date of each red packet. On the other hand, we propose a novel sequential model, Cross &amp; Attention Sequence Model (CASM), which explicitly learns the interactions between the latent semantic information of each red packet’s amount and sending date in the red packets sequence between two users. To validate our approach, we conduct comprehensive experiments on a real-world WeChat Users Red Packets dataset that involves 8 kinds of real-life relationships. The experiments show that our proposed approach performs significantly better than baselines and achieves 81.70 percent prediction accuracy.},
  archive      = {J_TKDE},
  author       = {Yunpeng Weng and Liang Chen and Xu Chen},
  doi          = {10.1109/TKDE.2020.3030807},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3814-3825},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Identifying user relationship on WeChat money-gifting network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph neural network for fraud detection via
spatial-temporal attention. <em>TKDE</em>, <em>34</em>(8), 3800–3813.
(<a href="https://doi.org/10.1109/TKDE.2020.3025588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Card fraud is an important issue and incurs a considerable cost for both cardholders and issuing banks. Contemporary methods apply machine learning-based approaches to detect fraudulent behavior from transaction records. But manually generating features needs domain knowledge and may lay behind the modus operandi of fraud, which means we need to automatically focus on the most relevant fraudulent behavior patterns in the online detection system. Therefore, in this work, we propose a spatial-temporal attention-based graph network (STAGN) for credit card fraud detection. In particular, we learn the temporal and location-based transaction graph features by a graph neural network first. Afterwards, we employ the spatial-temporal attention on top of learned tensor representations, which are then fed into a 3D convolution network. The attentional weights are jointly learned in an end-to-end manner with 3D convolution and detection networks. After that, we conduct extensive experiments on the real-word card transaction dataset. The result shows that STAGN performs better than other state-of-the-art baselines in both AUC and precision-recall curves. Moreover, we conduct empirical studies with domain experts on the proposed method for fraud detection and knowledge discovery; the result demonstrates its superiority in detecting suspicious transactions, mining spatial and temporal fraud hotspots, and uncover fraud patterns. The effectiveness of the proposed method in other user behavior-based tasks is also demonstrated. Finally, in order to tackle the challenges of big data, we integrate our proposed STAGN into the fraud detection system as the predictive model and present the implementation detail of each module in the system.},
  archive      = {J_TKDE},
  author       = {Dawei Cheng and Xiaoyang Wang and Ying Zhang and Liqing Zhang},
  doi          = {10.1109/TKDE.2020.3025588},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3800-3813},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph neural network for fraud detection via spatial-temporal attention},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Foresee urban sparse traffic accidents: A spatiotemporal
multi-granularity perspective. <em>TKDE</em>, <em>34</em>(8), 3786–3799.
(<a href="https://doi.org/10.1109/TKDE.2020.3034312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accident has become a significant health and development threat with rapid urbanizations. An accurate urban accident forecasting enables higher-quality police force pre-allocation and safe route planning for both traffic administrations and travelers, maximumly reducing injuries and damages. Off-the-shelf short-term accident forecasting methods, which focus on modeling static region-wise correlations with existing neural networks, mostly performed on hour levels and with single step. However, given the dynamic nature of road networks and expanding urban areas, it is challenging when the spatiotemporal granularity of forecasting improves as the rareness of accident records and complexity of long-term future dependencies. To address these challenges, we propose a unified framework RiskSeq, to foresee sparse urban accidents with finer granularities and multiple steps in spatiotemporal perspective. In particular, we design region-wise proximity measurements and temporal feature differential operations, and embed them into a novel Differential Time-varying Graph Convolution Network to dynamically capture traffic variations. Considering the hierarchical spatial dependencies and obvious context influences, a hierarchical sequence learning structure is devised by introducing contextual factors into a step-wise decoder. The multi-scale spatial risks are learned jointly to boost the risk predictions based on risk-gather and risk-assign networks. Extensive experiments demonstrate our RiskSeq can increase 5 to 15 percent performances on two datasets.},
  archive      = {J_TKDE},
  author       = {Zhengyang Zhou and Yang Wang and Xike Xie and Lianliang Chen and Chaochao Zhu},
  doi          = {10.1109/TKDE.2020.3034312},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3786-3799},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Foresee urban sparse traffic accidents: A spatiotemporal multi-granularity perspective},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FastDTW is approximate and generally slower than the
algorithm it approximates. <em>TKDE</em>, <em>34</em>(8), 3779–3785. (<a
href="https://doi.org/10.1109/TKDE.2020.3033752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many time series data mining problems can be solved with repeated use of distance measure. Examples of such tasks include similarity search, clustering, classification, anomaly detection and segmentation. For over two decades it has been known that the Dynamic Time Warping (DTW) distance measure is the best measure to use for most tasks, in most domains. Because the classic DTW algorithm has quadratic time complexity, many ideas have been introduced to reduce its amortized time, or to quickly approximate it. One of the most cited approximate approaches is FastDTW. The FastDTW algorithm has well over a thousand citations and has been explicitly used in several hundred research efforts. In this work, we make a surprising claim. In any realistic data mining application, the approximate FastDTW is much slower than the exact DTW. This fact clearly has implications for the community that uses this algorithm: allowing it to address much larger datasets, get exact results, and do so in less time.},
  archive      = {J_TKDE},
  author       = {Renjie Wu and Eamonn J. Keogh},
  doi          = {10.1109/TKDE.2020.3033752},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3779-3785},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FastDTW is approximate and generally slower than the algorithm it approximates},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extract human mobility patterns powered by city semantic
diagram. <em>TKDE</em>, <em>34</em>(8), 3765–3778. (<a
href="https://doi.org/10.1109/TKDE.2020.3026235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With widespread deployment of GPS devices, massive spatiotemporal trajectories became more accessible. This booming trend paved the solid data ground for researchers to discover the regularities or patterns of human mobility. However, there are still three challenges in semantic pattern extraction including semantic absence, semantic bias and semantic complexity. In this paper, we invent and apply a novel data structure namely City Semantic Diagram to overcome above three challenges. First, our approach resolves semantic absence by exactly identifying semantic behaviours from raw trajectories. Second, the design of semantic purification helps us to detect semantic complexity from human mobility. Third, we avoid semantic bias using objective data source such as ubiquitous GPS trajectories. Comprehensive and massive experiments have been conducted based on real taxi trajectories and points of interest in Shanghai. Compared with existing approaches, City Semantic Diagram is able to discover fine-grained semantic patterns effectively and accurately.},
  archive      = {J_TKDE},
  author       = {Zhangqing Shan and Weiwei Sun and Baihua Zheng},
  doi          = {10.1109/TKDE.2020.3026235},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3765-3778},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Extract human mobility patterns powered by city semantic diagram},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring temporal information for dynamic network
embedding. <em>TKDE</em>, <em>34</em>(8), 3754–3764. (<a
href="https://doi.org/10.1109/TKDE.2020.3034396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing nodes in a network as low-dimensional dense vectors can facilitate the analysis of complex networks, which is a challenging task and has attracted increasing attention. However, in the real world, networks are changing over time, such as cooperation in citation networks and communication in email networks. Most of the recent embedding methods only focus on static networks. Thus they ignore the critical temporal information, which serves as a supplement to structure information and has been proved to improve the quality of node embedding. In this work, we propose an unsupervised deep learning model called DTINE, which explores temporal information for further enhancing the robustness of node representations in dynamic networks. To preserve network topology, we pertinently design a temporal weight and sampling strategy to extract features from the neighborhoods. An attention mechanism will be applied on the recurrent neural network to measure the contributions of historical information and capture the evolution of the networks. Experimental results on four real-world networks demonstrate that the proposed method achieves better performance than state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Maoguo Gong and Shunfei Ji and Yu Xie and Yuan Gao and A. K. Qin},
  doi          = {10.1109/TKDE.2020.3034396},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3754-3764},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Exploring temporal information for dynamic network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing factorization machines with generalized metric
learning. <em>TKDE</em>, <em>34</em>(8), 3740–3753. (<a
href="https://doi.org/10.1109/TKDE.2020.3034613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factorization Machines (FMs) are effective in incorporating side information to overcome the cold-start and data sparsity problems in recommender systems. Traditional FMs adopt the inner product to model the second-order interactions between different attributes, which are represented via feature vectors. The problem is that the inner product violates the triangle inequality property of feature vectors. As a result, it cannot well capture fine-grained attribute interactions, resulting in sub-optimal performance. Recently, the euclidean distance is exploited in FMs to replace the inner product and has delivered better performance. However, previous FM methods including the ones equipped with the euclidean distance all focus on the attribute-level interaction modeling, ignoring the critical intrinsic feature correlations inside attributes. Thereby, they fail to model the complex and rich interactions exhibited in the real-world data. To tackle this problem, in this paper, we propose a FM framework equipped with generalized metric learning techniques to better capture these feature correlations. In particular, based on this framework, we present a Mahalanobis distance and a deep neural network (DNN) methods, which can effectively model the linear and non-linear correlations between features, respectively. Besides, we design an efficient approach for simplifying the model functions. Experiments on several benchmark datasets demonstrate that our proposed framework outperforms several state-of-the-art baselines by a large margin. Moreover, we collect a new large-scale dataset on second-hand trading to justify the effectiveness of our method over cold-start and data sparsity problems in recommender systems.},
  archive      = {J_TKDE},
  author       = {Yangyang Guo and Zhiyong Cheng and Jiazheng Jing and Yanpeng Lin and Liqiang Nie and Meng Wang},
  doi          = {10.1109/TKDE.2020.3034613},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3740-3753},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhancing factorization machines with generalized metric learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing social recommendation with adversarial graph
convolutional networks. <em>TKDE</em>, <em>34</em>(8), 3727–3739. (<a
href="https://doi.org/10.1109/TKDE.2020.3033673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems are expected to improve recommendation quality by incorporating social information when there is little user-item interaction data. However, recent reports from industry show that social recommender systems consistently fail in practice. According to the negative findings, the failure is attributed to: (1) A majority of users only have a very limited number of neighbors in social networks and can hardly benefit from social relations; (2) Social relations are noisy but they are indiscriminately used; (3) Social relations are assumed to be universally applicable to multiple scenarios while they are actually multi-faceted and show heterogeneous strengths in different scenarios. Most existing social recommendation models only consider the homophily in social networks and neglect these drawbacks. In this paper we propose a deep adversarial framework based on graph convolutional networks (GCN) to address these problems. Concretely, for (1) and (2), a GCN-based autoencoder is developed to augment the relation data by encoding high-order and complex connectivity patterns, and meanwhile is optimized subject to the constraint of reconstructing the social profile to guarantee the validity of the identified neighborhood. After obtaining enough purified social relations for each user, a GCN-based attentive social recommendation module is designed to address (3) by capturing the heterogeneous strengths of social relations. Finally, we adopt adversarial training to unify all the components by playing a Minimax game and ensure a coordinated effort to enhance recommendation performance. Extensive experiments on multiple open datasets demonstrate the superiority of our framework and the ablation study confirms the importance and effectiveness of each component.},
  archive      = {J_TKDE},
  author       = {Junliang Yu and Hongzhi Yin and Jundong Li and Min Gao and Zi Huang and Lizhen Cui},
  doi          = {10.1109/TKDE.2020.3033673},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3727-3739},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhancing social recommendation with adversarial graph convolutional networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed density peaks clustering revisited.
<em>TKDE</em>, <em>34</em>(8), 3714–3726. (<a
href="https://doi.org/10.1109/TKDE.2020.3034611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density Peaks (DP) Clustering organizes data into clusters by finding peaks in dense regions. This involves computing density ( $\rho$ ) and distance ( $\delta$ ) of every point. As such, though DP has been very effective in producing high quality clusters, their complexity is O( $N^2$ ) where $N$ is the number of data points. In this paper, we propose a fast distributed density peaks clustering algorithm, FDDP, based on the z-value index. In FDDP, we first employ the z-value index to map multi-dimensional data points into one dimensional space, and then range-partition the data according to the z-value to balance the load across the processing nodes. We ensure minimal overlapping range to handle computations at the boundary points. We also propose FC, an efficient algorithm that employs a forward computing strategy to calculate $\rho$ linearly. Additionally, we propose another algorithm, CB, which uses a caching and efficient searching strategy to compute $\delta$ . Moreover, FDDP is able to reduce the time complexity from $O(N^2)$ to $O(N\cdot log(N))$ . We provide a theoretical analysis of FDDP and evaluated FDDP empirically. Our experimental results show that FDDP outperforms the state-of-the-art algorithms significantly.},
  archive      = {J_TKDE},
  author       = {Jing Lu and Yuhai Zhao and Kian-Lee Tan and Zhengkui Wang},
  doi          = {10.1109/TKDE.2020.3034611},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3714-3726},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Distributed density peaks clustering revisited},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Distributed bayesian matrix decomposition for big data
mining and clustering. <em>TKDE</em>, <em>34</em>(8), 3701–3713. (<a
href="https://doi.org/10.1109/TKDE.2020.3029582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix decomposition is one of the fundamental tools to discover knowledge from big data generated by modern applications. However, it is still inefficient or infeasible to process very big data using such a method in a single machine. Moreover, big data are often distributedly collected and stored on different machines. Thus, such data generally bear strong heterogeneous noise. It is essential and useful to develop distributed matrix decomposition for big data analytics. Such a method should scale up well, model the heterogeneous noise, and address the communication issue in a distributed system. To this end, we propose a distributed Bayesian matrix decomposition model (DBMD) for big data mining and clustering. Specifically, we adopt three strategies to implement the distributed computing including 1) the accelerated gradient descent, 2) the alternating direction method of multipliers (ADMM), and 3) the statistical inference. We investigate the theoretical convergence behaviors of these algorithms. To address the heterogeneity of the noise, we propose an optimal plug-in weighted average that reduces the variance of the estimation. Synthetic experiments validate our theoretical results, and real-world experiments show that our algorithms scale up well to big data and achieves superior or competing performance compared to two typical distributed methods including Scalable-NMF and scalable k-means++.},
  archive      = {J_TKDE},
  author       = {Chihao Zhang and Yang Yang and Wei Zhou and Shihua Zhang},
  doi          = {10.1109/TKDE.2020.3029582},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3701-3713},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Distributed bayesian matrix decomposition for big data mining and clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for spatio-temporal data mining: A survey.
<em>TKDE</em>, <em>34</em>(8), 3681–3700. (<a
href="https://doi.org/10.1109/TKDE.2020.3025580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast development of various positioning techniques such as Global Position System (GPS), mobile devices and remote sensing, spatio-temporal data has become increasingly available nowadays. Mining valuable knowledge from spatio-temporal data is critically important to many real-world applications including human mobility understanding, smart transportation, urban planning, public safety, health care and environmental management. As the number, volume and resolution of spatio-temporal data increase rapidly, traditional data mining methods, especially statistics-based methods for dealing with such data are becoming overwhelmed. Recently deep learning models such as recurrent neural network (RNN) and convolutional neural network (CNN) have achieved remarkable success in many domains due to the powerful ability in automatic feature representation learning, and are also widely applied in various spatio-temporal data mining (STDM) tasks such as predictive learning, anomaly detection and classification. In this paper, we provide a comprehensive review of recent progress in applying deep learning techniques for STDM. We first categorize the spatio-temporal data into five different types, and then briefly introduce the deep learning models that are widely used in STDM. Next, we classify existing literature based on the types of spatio-temporal data, the data mining tasks, and the deep learning models, followed by the applications of deep learning for STDM in different domains including transportation, on-demand service, climate &amp; weather analysis, human mobility, location-based social network, crime analysis, and neuroscience. Finally, we conclude the limitations of current research and point out future research directions.},
  archive      = {J_TKDE},
  author       = {Senzhang Wang and Jiannong Cao and Philip S. Yu},
  doi          = {10.1109/TKDE.2020.3025580},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3681-3700},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep learning for spatio-temporal data mining: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep feature-based text clustering and its explanation.
<em>TKDE</em>, <em>34</em>(8), 3669–3680. (<a
href="https://doi.org/10.1109/TKDE.2020.3028943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text clustering is a critical step in text data analysis and has been extensively studied by the text mining community. Most existing text clustering algorithms are based on the bag-of-words model, which faces the high-dimensional and sparsity problems and ignores text structural and sequence information. Deep learning-based models such as convolutional neural networks and recurrent neural networks regard texts as sequences but lack supervised signals and explainable results. In this paper, we propose a d eep f eature-based t ext c lustering ( DFTC ) framework that incorporates pretrained text encoders into text clustering tasks. This model, which is based on sequence representations, breaks the dependency on supervision. The experimental results show that our model outperforms classic text clustering algorithms and the state-of-the-art pretrained language model, i.e., BERT, on almost all the considered datasets. In addition, the explanation of the clustering results is significant for understanding the principles of the deep learning approach. Our proposed clustering framework includes an explanation module that can help users understand the meaning and quality of the clustering results.},
  archive      = {J_TKDE},
  author       = {Renchu Guan and Hao Zhang and Yanchun Liang and Fausto Giunchiglia and Lan Huang and Xiaoyue Feng},
  doi          = {10.1109/TKDE.2020.3028943},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3669-3680},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep feature-based text clustering and its explanation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). COSINE: Compressive network embedding on large-scale
information networks. <em>TKDE</em>, <em>34</em>(8), 3655–3668. (<a
href="https://doi.org/10.1109/TKDE.2020.3030539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is recently a surge in approaches that learn low-dimensional embeddings of nodes in networks. However, for large-scale real-world networks, it’s inefficient for existing approaches to store amounts of parameters in memory and update them edge by edge. With the knowledge that nodes having similar neighborhoods will be close to each other in the embedding space, we propose COSINE (COmpresSIve Network Embedding) algorithm, which reduces the memory footprint and accelerates the training process by parameter sharing among similar nodes. COSINE applies graph partitioning algorithms to networks and builds parameter sharing dependency of nodes based on the results of partitioning. In this way, COSINE injects prior knowledge about high-order structural information into models, which makes network embedding more efficient and effective. COSINE can be applied to any embedding lookup method and learn high-quality embeddings with limited memory and less training time. We conduct experiments on multi-label classification and link prediction, where baselines and our model have the same memory usage. Experimental results show that COSINE improves baselines by up to 23 percent on classification and 25 percent on link prediction. Moreover, the training time of all representation learning methods using COSINE decreases by 30 to 70 percent.},
  archive      = {J_TKDE},
  author       = {Zhengyan Zhang and Cheng Yang and Zhiyuan Liu and Maosong Sun and Zhichong Fang and Bo Zhang and Leyu Lin},
  doi          = {10.1109/TKDE.2020.3030539},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3655-3668},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {COSINE: Compressive network embedding on large-scale information networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constructing measures of sparsity. <em>TKDE</em>,
<em>34</em>(8), 3643–3654. (<a
href="https://doi.org/10.1109/TKDE.2020.3029851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a rigorous but tractable study of sparsity. We postulate a definition of sparsity that is as broad as possible, so that it generates all the various measures that are useful in practice, but narrow enough that the fundamental properties of generalized sparsity still hold. As we work through the various ways of demonstrating the advantageous properties of sparsity, we illustrate its meaning from geometrical and operational perspectives. Thereafter, we construct specific measures of sparsity which are successfully qualified in complexity analysis and sparse optimization scenarios. Overall, our main objective is to construct measures of sparsity that will facilitate and enhance the design of the next innovative sensing technologies.},
  archive      = {J_TKDE},
  author       = {Giancarlo Pastor and Inmaculada Mora-Jiménez and Riku Jäntti and Antonio J. Caamaño},
  doi          = {10.1109/TKDE.2020.3029851},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3643-3654},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Constructing measures of sparsity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cleaning uncertain data with crowdsourcing - a general model
with diverse accuracy rates. <em>TKDE</em>, <em>34</em>(8), 3629–3642.
(<a href="https://doi.org/10.1109/TKDE.2020.3027545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since inaccuracies commonly exist in many applications, data uncertainty has become an important problem in database systems. To deal with data uncertainty, probabilistic databases can be used to store uncertain data, and querying facilities are provided to yield answers with confidence. However, the results from a query or mining process may not be reliable when the uncertainty propagates in the systems. In this paper, we leverage the power of crowdsourcing by designing a set of Human Intelligence Tasks, or HITs in short, to ask a crowd to improve the quality of uncertain data. In particular, we consider crowds consists of workers with diverse accuracy rates when answering the HITs. We design solutions to maximize the data quality with minimal number of HITs. There are two obstacles for this non-trivial optimization, which lead to very high computational cost for selecting the optimal set of HITs. First, members of a crowd may return incorrect answers with different probabilities. Second, the HITs decomposed from uncertain data are often correlated. We have addressed these challenges in this paper by designing an effective approximation algorithm and an efficient heuristic solution, especially for crowds with diverse individual accuracy rates. To further improve the efficiency, we derive tight lower and upper bounds for effective filtering and estimation. Extensive experiments on both a simulated crowd and a real crowdsourcing platform are conducted to evaluate our solutions.},
  archive      = {J_TKDE},
  author       = {Chen Zhang and Haodi Zhang and Weiteng Xie and Nan Liu and Qifan Li and Di Jiang and Peiguang Lin and Kaishun Wu and Lei Chen},
  doi          = {10.1109/TKDE.2020.3027545},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3629-3642},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cleaning uncertain data with crowdsourcing - a general model with diverse accuracy rates},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BTWalk: Branching tree random walk for multi-order
structured network embedding. <em>TKDE</em>, <em>34</em>(8), 3611–3628.
(<a href="https://doi.org/10.1109/TKDE.2020.3029061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-order proximity is useful for effective network embedding. In contrast to many previous works that only consider order-level weights, this paper proposes to explore a more expressive node-level weighting mechanism to encode the diverse local structure, with a scalable and theoretically justified sampling strategy for its learning. Specifically, we start with a formal definition of multi-order proximity matrix which leads to our new multi-order objective based on Laplacian Eigenmaps and Skip-Gram. Then we instantiate the node-specific multi-order weights in the objective with the help of neighborhood size estimation, which indicates node-specific multi-order information. For objective learning, it is implicitly fulfilled with our proposed branching tree-like random walk strategy termed by BTWalk, which differs from the dominant chain-like walk in existing sampling techniques. BTWalk is designed by a synergetic combination of BFS (breadth-first search) and DFS (depth-first search), which is modulated according to the weights of the considered proximity orders. We theoretically analyze its cost-efficiency, and further propose the so-called Vec4Cross framework that incorporates joint node embedding and network alignment for two partially overlapped networks based on the seed matchings, whereby BTWalk is also adopted for embedding. Promising experimental results are obtained on real-world datasets across popular tasks.},
  archive      = {J_TKDE},
  author       = {Hao Xiong and Junchi Yan},
  doi          = {10.1109/TKDE.2020.3029061},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3611-3628},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {BTWalk: Branching tree random walk for multi-order structured network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attribute graph neural networks for strict cold start
recommendation. <em>TKDE</em>, <em>34</em>(8), 3597–3610. (<a
href="https://doi.org/10.1109/TKDE.2020.3038234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rating prediction is a classic problem underlying recommender systems. It is traditionally tackled with matrix factorization. Recently, deep learning based methods, especially graph neural networks, have made impressive progress on this problem. Despite their effectiveness, existing methods focus on modeling the user-item interaction graph. The inherent drawback of such methods is that their performance is bound to the density of the interactions, which is however usually of high sparsity. More importantly, for a strict cold start user/item that neither appears in the training data nor has any interactions in the test stage, such methods are unable to learn the preference embedding of the user/item since there is no link to this user/item in the graph. In this work, we develop a novel framework Attribute Graph Neural Networks (AGNN) by exploiting the attribute graph rather than the commonly used interaction graph. This leads to the capability of learning embeddings for the strict cold start users/items. Our AGNN can produce the preference embedding for a strict cold user/item by learning on the distribution of attributes with an extended variational auto-encoder (eVAE) structure. Moreover, we propose a new graph neural network variant, i.e., gated-GNN, to effectively aggregate various attributes of different modalities in a neighborhood. Empirical results on three real-world datasets demonstrate that our model yields significant improvements for strict cold start recommendations and outperforms or matches the state-of-the-art performance in the warm start scenario.},
  archive      = {J_TKDE},
  author       = {Tieyun Qian and Yile Liang and Qing Li and Hui Xiong},
  doi          = {10.1109/TKDE.2020.3038234},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3597-3610},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Attribute graph neural networks for strict cold start recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient insertion operator in dynamic ridesharing
services. <em>TKDE</em>, <em>34</em>(8), 3583–3596. (<a
href="https://doi.org/10.1109/TKDE.2020.3027200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic ridesharing refers to services that arrange one-time shared rides on short notice. It underpins various real-world intelligent transportation applications such as car-pooling, food delivery and last-mile logistics. A core operation in dynamic ridesharing is the “ insertion operator ”. Given a worker and a feasible route which contains a sequence of origin-destination pairs from previous requests, the insertion operator inserts a new origin-destination pair from a newly arrived request into the current route such that certain objective is optimized. Common optimization objectives include minimizing the maximum/sum flow time of all requests and minimizing the total travel time of the worker. Despite its frequent usage, the insertion operator has a time complexity of $O(n^3)$ , where $n$ is the number of all requests assigned to the worker. The cubic running time of insertion fundamentally limits the efficiency of urban-scale dynamic ridesharing based applications. In this paper, we propose a novel partition framework and a dynamic programming based insertion with a time complexity of $O(n^2)$ . We further improve the time efficiency of the insertion operator to $O(n)$ harnessing efficient index structures, such as fenwick tree. Evaluations on two real-world large-scale datasets show that our methods can accelerate insertion by 1.5 to 998.1 times.},
  archive      = {J_TKDE},
  author       = {Yi Xu and Yongxin Tong and Yexuan Shi and Qian Tao and Ke Xu and Wei Li},
  doi          = {10.1109/TKDE.2020.3027200},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3583-3596},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An efficient insertion operator in dynamic ridesharing services},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AID*: A spatial index for visual exploration of geo-spatial
data. <em>TKDE</em>, <em>34</em>(8), 3569–3582. (<a
href="https://doi.org/10.1109/TKDE.2020.3026657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual exploration has become an integral part of big spatial data management. With the increase in volume and number of spatial datasets, several specialized mechanisms have been proposed to speed up the exploration of these datasets. However, the existing techniques have major limitations which make them incapable of providing visual exploration for hundreds of thousands of big datasets on a single machine. This paper introduces a new index structure, termed AID*, that facilitates the visual exploration of an arbitrarily large number of big spatial datasets on a single machine. The AID* index defines multi-resolution fixed-size tiles on the input and classifies them as image, data, shallow, or empty tiles, based on their processing cost. Then, it uses this classification to build an index with a minimal index size and construction time, while supporting the desired real-time exploration interface. The index is constructed in parallel, using Hadoop or Spark, and is accessible to end users through a standard web interface similar to Google Maps. The small size of the index allows a single-machine server to host arbitrarily many datasets. Our experiments, on up-to 1 TB of data and 27 billion records, show that the construction of the proposed index is up-to an order of magnitude faster than the baselines without compromising the end-user interactivity.},
  archive      = {J_TKDE},
  author       = {Saheli Ghosh and Ahmed Eldawy},
  doi          = {10.1109/TKDE.2020.3026657},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3569-3582},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {AID*: A spatial index for visual exploration of geo-spatial data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on knowledge graph-based recommender systems.
<em>TKDE</em>, <em>34</em>(8), 3549–3568. (<a
href="https://doi.org/10.1109/TKDE.2020.3028705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the information explosion problem and enhance user experience in various online applications, recommender systems have been developed to model users’ preferences. Although numerous efforts have been made toward more personalized recommendations, recommender systems still suffer from several challenges, such as data sparsity and cold-start problems. In recent years, generating recommendations with the knowledge graph as side information has attracted considerable interest. Such an approach can not only alleviate the above mentioned issues for a more accurate recommendation, but also provide explanations for recommended items. In this paper, we conduct a systematical survey of knowledge graph-based recommender systems. We collect recently published papers in this field, and group them into three categories, i.e., embedding-based methods, connection-based methods, and propagation-based methods. Also, we further subdivide each category according to the characteristics of these approaches. Moreover, we investigate the proposed algorithms by focusing on how the papers utilize the knowledge graph for accurate and explainable recommendation. Finally, we propose several potential research directions in this field.},
  archive      = {J_TKDE},
  author       = {Qingyu Guo and Fuzhen Zhuang and Chuan Qin and Hengshu Zhu and Xing Xie and Hui Xiong and Qing He},
  doi          = {10.1109/TKDE.2020.3028705},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3549-3568},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on knowledge graph-based recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep neural network for crossing-city POI recommendations.
<em>TKDE</em>, <em>34</em>(8), 3536–3548. (<a
href="https://doi.org/10.1109/TKDE.2020.3033841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of location-aware devices (e.g., smart phones), large amounts of location-based social media data such as check-ins are generated. This stimulates plenty of studies for POI recommendations by applying machine learning techniques. However, most of the existing studies focus on POI recommendations in the same city or region, and fail to recommend POIs for users when they travel to a new city. In this paper, we propose a novel deep neural network, named as ST-TransRec, for crossing-city POI recommendations. It integrates the deep neural network, transfer learning technique, and density-based resampling method into a unified framework. In this model, the deep neural network is used to capture users’ preferences for POIs and learn the embeddings of POIs. Besides, the transfer learning technique is employed to bridge the gap between cities that results from the city-dependent features. As the distributions over POIs are imbalanced, we design a density-based spatial resampling model which enables POIs to be well matched across cities. We conduct extensive experiments on two real-world datasets. The experimental results show the advantages of ST-TransRec over the state-of-the-art methods for crossing-city POI recommendations.},
  archive      = {J_TKDE},
  author       = {Dichao Li and Zhiguo Gong},
  doi          = {10.1109/TKDE.2020.3033841},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {8},
  pages        = {3536-3548},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A deep neural network for crossing-city POI recommendations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strict and flexible rule-based graph repairing.
<em>TKDE</em>, <em>34</em>(7), 3521–3535. (<a
href="https://doi.org/10.1109/TKDE.2020.3019817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-life graph datasets extracted from the Web are inevitably full of incompleteness, conflicts, and redundancies, so graph data cleaning shows its necessity. Although rules like data dependencies have been widely studied in relational data repairing, very few works exist to repair graph data. In this article, we introduce a repairing semantics for graphs, called Graph-Repairing Rules ( ${\sf GRR}$ s). This semantics can capture the incompleteness, conflicts, and redundancies in graphs and indicate how to correct these errors. However, this graph repairing semantics can only repair the graphs strictly isomorphic to the rule patterns, which decreases the utility of the rules. To overcome this shortcoming, we further propose a flexible rule-based graph repairing semantics (called $\delta$ -GRR ). We study three fundamental problems associated with both ${\sf GRR}$ s and $\delta$ -GRR s, consistency, implication, and termination, which show whether a given set of rules make sense. Repairing the graph data using ${\sf GRR}$ s or $\delta$ -GRR s involves a problem of finding isomorphic subgraphs of the graph data, which is NP-complete. To efficiently circumvent the complex calculation of subgraph isomorphism, we design a decomposition-and-join strategy to solve this problem. Extensive experiments on real datasets show that our two graph repairing semantics and corresponding repairing algorithms can effectively and efficiently repair real-life graph data.},
  archive      = {J_TKDE},
  author       = {Yurong Cheng and Lei Chen and Ye Yuan and Guoren Wang and Boyang Li and Fusheng Jin},
  doi          = {10.1109/TKDE.2020.3019817},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3521-3535},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Strict and flexible rule-based graph repairing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust network enhancement from flawed networks.
<em>TKDE</em>, <em>34</em>(7), 3507–3520. (<a
href="https://doi.org/10.1109/TKDE.2020.3025147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network data in real-world tends to be error-prone due to incomplete sampling, imperfect measurements, etc.; this in turn results in inaccurate results when performing network analysis or modeling, such as node classification and link prediction, on these flawed networks. In this paper, we aim to reconstruct a reliable network from a flawed, undirected, unweighted network, a process referred to network enhancement. More specifically, network enhancement aims to detect the noisy links that are observed in the network but should not exist in the real world, as well as to predict the missing links that do indeed exist in the real world yet remain unobserved. While some attempts have been made to detect either noisy links or missing links, few of these works have considered unifying these two tasks, even though they are inter-dependent and capable of mutually boosting each others’ performance. In this paper, we therefore propose E-Net, an end-to-end graph neural network model, to leverage the mutual influence of these two tasks in order to achieve both goals more effectively. On one hand, detecting noisy links can benefit the performance of missing link prediction, while on the other hand, predicting missing links can provide indirect supervision for detecting noisy link detection when the labels of these noisy links are unavailable. Moreover, by proposing a subgraph extraction mechanism based on random walk with restart, the model can be scaled up to large networks and is able to preserve the local and global structural characteristics. The experimental results on several types of large networks demonstrate that the proposed model obtains an improvement of 10.7 percent on average in terms of F1 for predicting missing links, along with an average of 3.7 percent improvement in terms of precision for detecting noisy links compared with the state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Jiarong Xu and Yang Yang and Chunping Wang and Zongtao Liu and Jing Zhang and Lei Chen and Jiangang Lu},
  doi          = {10.1109/TKDE.2020.3025147},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3507-3520},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust network enhancement from flawed networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ProbMinHash – a class of locality-sensitive hash algorithms
for the (probability) jaccard similarity. <em>TKDE</em>, <em>34</em>(7),
3491–3506. (<a href="https://doi.org/10.1109/TKDE.2020.3021176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The probability Jaccard similarity was recently proposed as a natural generalization of the Jaccard similarity to measure the proximity of sets whose elements are associated with relative frequencies or probabilities. In combination with a hash algorithm that maps those weighted sets to compact signatures which allow fast estimation of pairwise similarities, it constitutes a valuable method for big data applications such as near-duplicate detection, nearest neighbor search, or clustering. This paper introduces a class of one-pass locality-sensitive hash algorithms that are orders of magnitude faster than the original approach. The performance gain is achieved by calculating signature components not independently, but collectively. Four different algorithms are proposed based on this idea. Two of them are statistically equivalent to the original approach and can be used as drop-in replacements. The other two may even improve the estimation error by introducing statistical dependence between signature components. Moreover, the presented techniques can be specialized for the conventional Jaccard similarity, resulting in highly efficient algorithms that outperform traditional minwise hashing and that are able to compete with the state of the art.},
  archive      = {J_TKDE},
  author       = {Otmar Ertl},
  doi          = {10.1109/TKDE.2020.3021176},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3491-3506},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ProbMinHash – a class of locality-sensitive hash algorithms for the (Probability) jaccard similarity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proactive &amp; time-optimized data synopsis management at
the edge. <em>TKDE</em>, <em>34</em>(7), 3478–3490. (<a
href="https://doi.org/10.1109/TKDE.2020.3021377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things offers the infrastructure for smooth functioning of autonomous context-aware devices being connected towards the Cloud. Edge Computing (EC) relies between the IoT and Cloud providing significant advantages. One advantage is to perform local data processing (limited latency, bandwidth preservation) with real time communication among IoT devices, while multiple nodes become hosts of the collected data (reported by IoT devices). In this work, we provide a mechanism for the exchange of data synopses (summaries of extracted knowledge) among EC nodes that are necessary to give the knowledge on the data present in EC environments. The overarching aim is to intelligently decide on when nodes should exchange data synopses in light of efficient execution of tasks. We enhance such a decision with a stochastic optimization model based on the Theory of Optimal Stopping. We provide the fundamentals of our model and the relevant formulations on the optimal time to disseminate data synopses to network edge nodes. We report a comprehensive experimental evaluation and comparative assessment related to the optimality achieved by our model and the positive effects on EC.},
  archive      = {J_TKDE},
  author       = {Kostas Kolomvatsos and Christos Anagnostopoulos and Maria Koziri and Thanasis Loukopoulos},
  doi          = {10.1109/TKDE.2020.3021377},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3478-3490},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Proactive &amp; time-optimized data synopsis management at the edge},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preference-aware task assignment in spatial crowdsourcing:
From individuals to groups. <em>TKDE</em>, <em>34</em>(7), 3461–3477.
(<a href="https://doi.org/10.1109/TKDE.2020.3021028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ubiquity of smart devices, Spatial Crowdsourcing (SC) has emerged as a new transformative platform that engages mobile users to perform spatio-temporal tasks by physically traveling to specified locations. Thus, various SC techniques have been studied for performance optimization, among which one of the major challenges is how to assign workers the tasks that they are really interested in and willing to perform. In this paper, we propose a novel preference-aware spatial task assignment system based on workers’ temporal preferences, which consists of two components: History-based Context-aware Tensor Decomposition (HCTD) for workers’ temporal preferences modeling and preference-aware task assignment . We model workers’ preferences with a three-dimension tensor (worker-task-time). Supplementing the missing entries of the tensor through HCTD with the assistant of historical data and other two context matrices, we recover workers’ preferences for different categories of tasks in different time slots. Several preference-aware individual task assignment algorithms are then devised, aiming to maximize the total number of task assignments at every time instance, in which we give higher priorities to the workers who are more interested in the tasks. In order to make our proposed framework applicable to more scenarios, we further optimize the original framework by proposing strategies to allow each task to be assigned to a group of workers such that the task can be completed by these workers simultaneously, wherein workers’ tolerable waiting time, consensus, and tasks’ rewards are taken into consideration. We conduct extensive experiments using a real dataset, verifying the practicability of our proposed methods.},
  archive      = {J_TKDE},
  author       = {Yan Zhao and Kai Zheng and Hongzhi Yin and Guanfeng Liu and Junhua Fang and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.3021028},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3461-3477},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Preference-aware task assignment in spatial crowdsourcing: From individuals to groups},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overcoming data sparsity in group recommendation.
<em>TKDE</em>, <em>34</em>(7), 3447–3460. (<a
href="https://doi.org/10.1109/TKDE.2020.3023787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been an important task for recommender systems to suggest satisfying activities to a group of users in people’s daily social life. The major challenge in this task is how to aggregate personal preferences of group members to infer the decision of a group. Conventional group recommendation methods applied a predefined strategy for preference aggregation. However, these static strategies are too simple to model the real and complex process of group decision-making, especially for occasional groups which are formed ad-hoc. Moreover, group members should have non-uniform influences or weights in a group, and the weight of a user can be varied in different groups. Therefore, an ideal group recommender system should be able to accurately learn not only users’ personal preferences but also the preference aggregation strategy from data. In this paper, we propose a novel end-to-end group recommender system named CAGR (short for “ C entrality- A ware G roup R ecommender”), which takes Bipartite Graph Embedding Model (BGEM), the self-attention mechanism and Graph Convolutional Networks (GCNs) as basic building blocks to learn group and user representations in a unified way. Specifically, we first extend BGEM to model group-item interactions, and then in order to overcome the limitation and sparsity of the interaction data generated by occasional groups, we propose a self-attentive mechanism to represent groups based on the group members. In addition, to overcome the sparsity issue of user-item interaction data, we leverage the user social networks to enhance user representation learning, obtaining centrality-aware user representations. To further alleviate the group data sparsity problem, we propose two model optimization approaches to seamlessly integrate the user representations learning process. We create three large-scale benchmark datasets and conduct extensive experiments on them. The experimental results show the superiority of our proposed CAGR by comparing it with state-of-the-art group recommender models.},
  archive      = {J_TKDE},
  author       = {Hongzhi Yin and Qinyong Wang and Kai Zheng and Zhixu Li and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.3023787},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3447-3460},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Overcoming data sparsity in group recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On extracting socially tenuous groups for online social
networks with <span class="math inline"><em>k</em></span>k-triangles.
<em>TKDE</em>, <em>34</em>(7), 3431–3446. (<a
href="https://doi.org/10.1109/TKDE.2020.3025911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research on finding social groups mostly focuses on dense subgraphs in social networks. However, finding socially tenuous groups also has many important applications. In this article, we introduce the notion of $k$k-triangles to measure the tenuity of a group. We then formulate a new research problem, Minimum $k$k-Triangle Disconnected Group with No-Pair Constraint (MkTG) , to find a socially tenuous group from the online social network. We prove that MkTG is NP-hard and inapproximable within any ratio. Two algorithms, namely TERA and TERA-ADV , are designed for solving MkTG effectively and efficiently. Further, we examine the MkTG problem on tree-based social networks, due to their structural resemblance with corporate social networks built upon the supervision relation. Accordingly, we devise an efficient algorithm, namely Tenuity Maximization for Trees (TMT) , to obtain the optimal solution in polynomial time. In addition, we study a more general version of MkTG, named Generalized Minimum $k$k-Triangle Disconnected Group without No-Pair Constraint (MkTG-G) . We formulate MkTG-G, analyze its inapproximability, and propose a randomized approximation algorithm, named Randomized Ranking with Limited Neighborhood Participation (RLNP) . Experimental results on real datasets manifest that the proposed algorithms outperform the baselines in terms of both efficiency and solution quality.},
  archive      = {J_TKDE},
  author       = {Chih-Ya Shen and Hong-Han Shuai and De-Nian Yang and Guang-Siang Lee and Liang-Hao Huang and Wang-Chien Lee and Ming-Syan Chen},
  doi          = {10.1109/TKDE.2020.3025911},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3431-3446},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {On extracting socially tenuous groups for online social networks with $k$k-triangles},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view spectral clustering with high-order optimal
neighborhood laplacian matrix. <em>TKDE</em>, <em>34</em>(7), 3418–3430.
(<a href="https://doi.org/10.1109/TKDE.2020.3025100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view spectral clustering can effectively reveal the intrinsic clustering structure among data by performing clustering on the learned optimal embedding across views. Though demonstrating promising performance in various applications, most of existing methods usually linearly combine a group of pre-specified first-order Laplacian matrices to construct the optimal Laplacian matrix, which may result in limited representation capability and insufficient information exploitation. Also, storing and implementing complex operations on the $n\times n$ Laplacian matrices incur intensive storage and computation complexity. To address these issues, this paper first proposes a multi-view spectral clustering algorithm that learns a high-order optimal neighborhood Laplacian matrix, and then extends it to the late fusion version for accurate and efficient multi-view clustering. Specifically, our proposed algorithm generates the optimal Laplacian matrix by searching the neighborhood of the linear combination of both the first-order and high-order base Laplacian matrices simultaneously. By this way, the representative capacity of the learned optimal Laplacian matrix is enhanced, which is helpful to better utilize the hidden high-order connection information among data, leading to improved clustering performance. We design an efficient algorithm with proved convergence to solve the resultant optimization problem. Extensive experimental results on nine datasets demonstrate the superiority of our algorithm against state-of-the-art methods, which verifies the effectiveness and advantages of the proposed algorithm.},
  archive      = {J_TKDE},
  author       = {Weixuan Liang and Sihang Zhou and Jian Xiong and Xinwang Liu and Siwei Wang and En Zhu and Zhiping Cai and Xin Xu},
  doi          = {10.1109/TKDE.2020.3025100},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3418-3430},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-view spectral clustering with high-order optimal neighborhood laplacian matrix},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view consensus proximity learning for clustering.
<em>TKDE</em>, <em>34</em>(7), 3405–3417. (<a
href="https://doi.org/10.1109/TKDE.2020.3025759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most proximity-based multi-view clustering methods are sensitive to the initial proximity matrix, where the clustering performance is quite unstable when using different initial proximity matrixes. This problem is defined as the initial value sensitivity problem. Since clustering is an unsupervised learning task, it is unrealistic to tune the initial proximity matrix. Thus, how to overcome the initial value sensitivity problem is a significant but unsolved issue in the proximity-based multi-view clustering. To this end, this paper proposes a novel multi-view proximity learning method, named multi-view consensus proximity learning (MCPL). On the one hand, by integrating the information of all views in a self-weighted manner and giving a rank constraint on the Laplacian matrix, the MCPL method learns the consensus proximity matrix to directly reflect the clustering result. On the other hand, different from most multi-view proximity learning methods, in the proposed MCPL method, the data representatives rather than the original data objects are adopted to learn the consensus proximity matrix. The data representatives will be updated in the process of the proximity learning so as to weaken the impact of the initial value on the clustering performance. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Bao-Yu Liu and Ling Huang and Chang-Dong Wang and Jian-Huang Lai and Philip S. Yu},
  doi          = {10.1109/TKDE.2020.3025759},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3405-3417},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-view consensus proximity learning for clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MSHINE: A multiple-meta-paths simultaneous learning
framework for heterogeneous information network embedding.
<em>TKDE</em>, <em>34</em>(7), 3391–3404. (<a
href="https://doi.org/10.1109/TKDE.2020.3025464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks(HINs) become popular in recent years for its strong capability of modelling objects with abundant information using explicit network structure. Network embedding has been proved as an effective method to convert information networks into lower-dimensional space, whereas the core information can be well preserved. However, traditional network embedding algorithms are sub-optimal in capturing rich while potentially incompatible semantics provided by HINs. To address this issue, a novel meta-path-based HIN representation learning framework named mSHINE is designed to simultaneously learn multiple node representations for different meta-paths. More specifically, one representation learning module inspired by the RNN structure is developed and multiple node representations can be learned simultaneously, where each representation is associated with one respective meta-path. By measuring the relevance between nodes with the designed objective function, the learned module can be applied in downstream link prediction tasks. A set of criteria for selecting initial meta-paths is proposed as the other module in mSHINE which is important to reduce the optimal meta-path selection cost when no prior knowledge of suitable meta-paths is available. To corroborate the effectiveness of mSHINE, extensive experimental studies including node classification and link prediction are conducted on five real-world datasets. The results demonstrate that mSHINE outperforms other state-of-the-art HIN embedding methods.},
  archive      = {J_TKDE},
  author       = {Xinyi Zhang and Lihui Chen},
  doi          = {10.1109/TKDE.2020.3025464},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3391-3404},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MSHINE: A multiple-meta-paths simultaneous learning framework for heterogeneous information network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling signed networks as 2-layer growing networks.
<em>TKDE</em>, <em>34</em>(7), 3377–3390. (<a
href="https://doi.org/10.1109/TKDE.2020.3024779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose modeling signed networks by considering two layers in a social network for generation of positive and negative links where both the layers comprise of identical set of nodes. The growth process is modeled based on preferential attachment, formation of links probabilistically asserting structural balance of local groups, and internal growth which happens without addition of new nodes. We prove that the degree distribution of a generated network follows a power-law whose exponent depends on the largest eigenvalue of a matrix which governs the dynamics of growth of degrees of nodes with respect to positive and negative links. A computable formula for average degree and lower-bounds for the number of balanced and unbalanced triads of modelled networks are also obtained. A method for structural reconstruction of real signed networks is formulated through estimation the values of the model parameters to generate the network that can inherit different structural properties of the corresponding real network. Experimental results show that our model which we term as 2L-SNM can replicate properties of several real world signed networks much more robustly than competitive state-of-the-art techniques.},
  archive      = {J_TKDE},
  author       = {Pradumn Kumar Pandey and Bibhas Adhikari and Mainak Mazumdar and Niloy Ganguly},
  doi          = {10.1109/TKDE.2020.3024779},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3377-3390},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Modeling signed networks as 2-layer growing networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LShape partitioning: Parallel skyline query processing using
<span
class="math inline"><em>M</em><em>a</em><em>p</em><em>R</em><em>e</em><em>d</em><em>u</em><em>c</em><em>e</em></span>MapReduce.
<em>TKDE</em>, <em>34</em>(7), 3363–3376. (<a
href="https://doi.org/10.1109/TKDE.2020.3021470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A skyline query searches the data points that are not dominated by others in the dataset. It is widely adopted for many applications which require multi-criteria decision making. However, skyline query processing is considerably time-consuming for a high-dimensional large scale dataset. Parallel computing techniques are therefore needed to address this challenge, among which $MapReduce$ is one of the most popular frameworks to process big data. A great number of efficient $MapReduce$ skyline algorithms have been proposed in the literature and most of their designs focus on partitioning and pruning the given dataset. However, there are still opportunities for further parallelism. In this study, we propose two parallel skyline processing algorithms using a novel $LShape$ partitioning strategy and an effective $Propagation$ $Filtering$ method. These two algorithms are $2Phase$ $LShape$ and $1Phase$ $LShape$ , used for multiple reducers and single reducer, respectively. By extensive experiments, we verify that our algorithms outperformed the state-of-the-art approaches, especially for high-dimensional large scale datasets.},
  archive      = {J_TKDE},
  author       = {Heri Wijayanto and Wenlu Wang and Wei-Shinn Ku and Arbee L.P. Chen},
  doi          = {10.1109/TKDE.2020.3021470},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3363-3376},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LShape partitioning: Parallel skyline query processing using $MapReduce$MapReduce},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning inter- and intra-manifolds for matrix
factorization-based multi-aspect data clustering. <em>TKDE</em>,
<em>34</em>(7), 3349–3362. (<a
href="https://doi.org/10.1109/TKDE.2020.3022072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering on the data with multiple aspects, such as multi-view or multi-type relational data, has become popular in recent years due to their wide applicability. The approach using manifold learning with the Non-negative Matrix Factorization (NMF) framework, that learns the accurate low-rank representation of the multi-dimensional data, has shown effectiveness. We propose to include the inter-manifold in the NMF framework, utilizing the distance information of data points of different data types (or views) to learn the diverse manifold for data clustering. Empirical analysis reveals that the proposed method can find partial representations of various interrelated types and select useful features during clustering. Results on several datasets demonstrate that the proposed method outperforms the state-of-the-art multi-aspect data clustering methods in both accuracy and efficiency.},
  archive      = {J_TKDE},
  author       = {Khanh Luong and Richi Nayak},
  doi          = {10.1109/TKDE.2020.3022072},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3349-3362},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning inter- and intra-manifolds for matrix factorization-based multi-aspect data clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). I/o-efficient algorithms for degeneracy computation on
massive networks. <em>TKDE</em>, <em>34</em>(7), 3335–3348. (<a
href="https://doi.org/10.1109/TKDE.2020.3021484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Degeneracy is an important concept to measure the sparsity of a graph which has been widely used in many network analysis applications. Many network analysis algorithms, such as clique enumeration and truss decomposition, perform very well in graphs having small degeneracies. In this paper, we propose an I/O-efficient algorithm to compute the degeneracy of the massive graph that cannot be fully kept in the main memory. The proposed algorithm only uses $O(n)$ memory, where $n$ denotes the number of nodes of the graph. We also develop an I/O-efficient algorithm to incrementally maintain the degeneracy on dynamic graphs. Extensive experiments show that our algorithms significantly outperform the state-of-the-art degeneracy computation algorithms in terms of both running time and I/O costs. The results also demonstrate high scalability of the proposed algorithms. For example, in a real-world web graph with 930 million nodes and 13.3 billion edges, the proposed algorithm takes only 633 seconds and uses less than 4.5GB memory to compute the degeneracy.},
  archive      = {J_TKDE},
  author       = {Rong-Hua Li and Qiushuo Song and Xiaokui Xiao and Lu Qin and Guoren Wang and Jeffrey Xu Yu and Rui Mao},
  doi          = {10.1109/TKDE.2020.3021484},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3335-3348},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {I/O-efficient algorithms for degeneracy computation on massive networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical latent context representation for context-aware
recommendations. <em>TKDE</em>, <em>34</em>(7), 3322–3334. (<a
href="https://doi.org/10.1109/TKDE.2020.3022102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a hierarchical representation of latent contextual information that captures contextual situations in which users are recommended particular items. We also introduce an algorithm that converts unstructured latent contextual information into structured hierarchical representations. In addition, we present two general context-aware recommendation algorithms that extend collaborative filtering (CF) approaches and utilize structured and unstructured latent contextual information. In particular, the first algorithm utilizes structured latent contexts and the second one combines the structured and the unstructured latent contextual representations. By using latent contextual information in a recommendation model, we capture and represent both the structure of the latent context in the form of a hierarchy and the values of contextual variables in the form of an unstructured vector. We tested the two proposed methods with two CF-based methods on several context-rich datasets under different experimental settings. We show that using hierarchical latent contextual representations leads to significantly better recommendations than the baselines for the datasets having high- and medium-dimensional contexts. Although this is not the case for the low-dimensional contextual data, the hybrid approach, combining structured and unstructured latent contextual information, significantly outperforms other baselines across all the experimental settings and dimensions of contextual data.},
  archive      = {J_TKDE},
  author       = {Moshe Unger and Alexander Tuzhilin},
  doi          = {10.1109/TKDE.2020.3022102},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3322-3334},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical latent context representation for context-aware recommendations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heuristic 3D interactive walks for multilayer network
embedding. <em>TKDE</em>, <em>34</em>(7), 3309–3321. (<a
href="https://doi.org/10.1109/TKDE.2020.3021393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding has been widely used to solve the network analytics problem. Existing methods mainly focus on networks with single-layered homogeneous or heterogeneous networks. However, many real-world complex systems can be naturally represented by multilayer networks, which is another term of heterogeneous networks with multiple edge/relation types. The problem of how to capture and utilize rich interaction information of multi-type relations causes a major challenge of multilayer network embedding. To address this problem, we propose a fast and scalable multilayer network embedding model, called HMNE, to efficiently preserve and learn information of multi-type relations into a unified embedding space. We develop a heuristic 3D interactive walk technique dedicated for multilayer networks, which can leverage rich interactions among distinct layers and effectively capture important information contained in the layered structure. We evaluate our proposed model HMNE on two downstream analytic applications: node classification and link prediction. Experimental results on seven social and biological multilayer network datasets demonstrate that the proposed model outperforms existing competitive baselines with reduced time and memory occupations.},
  archive      = {J_TKDE},
  author       = {Maoguo Gong and Wenfeng Liu and Yu Xie and Zedong Tang and Mingliang Xu},
  doi          = {10.1109/TKDE.2020.3021393},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3309-3321},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Heuristic 3D interactive walks for multilayer network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GraphShield: Dynamic large graphs for secure queries with
forward privacy. <em>TKDE</em>, <em>34</em>(7), 3295–3308. (<a
href="https://doi.org/10.1109/TKDE.2020.3024883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing amount of graph-structured data catalyzes analytics over graph databases using semantic queries. Motivated by the ubiquity of commercial cloud platforms, data owners are willing to store their graph databases remotely. However, data privacy has emerged as a widespread concern since the cloud platforms are not fully trusted. One viable solution is to encrypt sensitive data before outsourcing, which inevitably hinders data retrieval. To enable queries over encrypted data, searchable symmetric encryption (SSE) has been introduced. Yet, the most well-studied class of SSE schemes focuses on retrieving textual files given keywords, which cannot be applied to graph databases directly. This paper extends our preliminary work (FC’17) and proposes GraphShield, a structured encryption scheme for graphs. Beyond shortest distance queries, GraphShield can support other classic graph-based queries (e.g., maximum flow) and more complicated analytics (e.g., PageRank). Technically, we incorporate a suite of (efficient) cryptographic primitives and tailor some extra secure protocols for facilitating graph analytics. Our scheme also allows updates on the encrypted graph with forward privacy guaranteed. We formalize the security model and prove the adaptive security with reasonable leakage. Finally, we implement our scheme on various real-world datasets, and the experiment results demonstrate its practicality and scalability.},
  archive      = {J_TKDE},
  author       = {Minxin Du and Shuangke Wu and Qian Wang and Dian Chen and Peipei Jiang and Aziz Mohaisen},
  doi          = {10.1109/TKDE.2020.3024883},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3295-3308},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GraphShield: Dynamic large graphs for secure queries with forward privacy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph-based identification and authentication: A stochastic
kronecker approach. <em>TKDE</em>, <em>34</em>(7), 3282–3294. (<a
href="https://doi.org/10.1109/TKDE.2020.3025989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large body of research has focused on analyzing large networks and graphs. However, network and graph data is often anonymized for reasons such as protecting data privacy. Under such circumstances, it is difficult to verify the source of network data, which leads to questions such as: Given an anonymized graph, can we identify the network from which it is collected? Or, if one claims the graph is sampled from a certain network, can we verify this claim? The intuitive approach is to check for subgraph isomophism. However, subgraph isomophism is NP-complete; hence, infeasible for most large networks. Inspired by biometrics studies, we address these challenges by formulating two new problems: network identification and network authentication . To tackle these problems, similar to research on human fingerprints, we introduce two versions of a network identity : (1) embedding-based identity and (2) distribution-based identity. We demonstrate the effectiveness of these network identities using extensive experiments on real-world networks. Using these identities, we propose two approaches for network identification. One method uses supervised learning and can achieve an identification accuracy of 84.4 percent, and the other, which is easier to implement, relies on distances between identities and achieves an accuracy rate of 70.8 percent. For network authentication, we propose two methods to build a network authentication system. The first is a supervised learner and yields a low false accept rate and the other method, allows one to control the false reject rate with a reasonable false accept rate across networks. We demonstrate that network authentication can also be used for biometrics, authenticating users based on their touch data on phones and tablets. Our study can help identify or verify the source of network data, validate network-based research, and be used for network-based biometrics.},
  archive      = {J_TKDE},
  author       = {Shengmin Jin and Vir V. Phoha and Reza Zafarani},
  doi          = {10.1109/TKDE.2020.3025989},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3282-3294},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph-based identification and authentication: A stochastic kronecker approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GAN-based enhanced deep subspace clustering networks.
<em>TKDE</em>, <em>34</em>(7), 3267–3281. (<a
href="https://doi.org/10.1109/TKDE.2020.3025301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two GAN-based deep subspace clustering approaches: deep subspace clustering via dual adversarial generative networks (DSC-DAG) and self-supervised deep subspace clustering with adversarial generative networks (S $^2$ DSC-AG). In DSC-DAG, the distributions of both the inputs and corresponding latent representations are learnt via adversarial training simultaneously. Besides, there are two kinds of synthetic representations to facilitate the fine-tuning of the encoder: the combinations of latent representations with random combination coefficients and representations of real-like inputs derived from noise variables. In S $^2$ DSC-AG, a self-supervised information learning module substitutes for adversarial learning in the latent space, since both of them play the same role in learning discriminative latent representations. We analyze connections between these methods and demonstrate their equivalences. We conduct extensive experiments on multiple real-world data sets against state-of-the-art subspace clustering methods in terms of accuracy, normalized mutual information and purity. Experimental results demonstrate the effectiveness and superiority of our proposed methods.},
  archive      = {J_TKDE},
  author       = {Zhiwen Yu and Zhongfan Zhang and Wenming Cao and Cheng Liu and C. L. Philip Chen and Hau-San Wong},
  doi          = {10.1109/TKDE.2020.3025301},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3267-3281},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GAN-based enhanced deep subspace clustering networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully dynamic <span
class="math inline"><em>k</em></span>k-center clustering with improved
memory efficiency. <em>TKDE</em>, <em>34</em>(7), 3255–3266. (<a
href="https://doi.org/10.1109/TKDE.2020.3023020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Static and dynamic clustering algorithms are a fundamental tool in any machine learning library. Most of the efforts in developing dynamic machine learning and data mining algorithms have been focusing on the sliding window model or more simplistic models. However, in many real-world applications one might need to deal with arbitrary deletions and insertions. For example, one might need to remove data items that are not necessarily the oldest ones, because they have been flagged as containing inappropriate content or due to privacy concerns. Clustering trajectory data might also require to deal with more general update operations. We develop a $(2+\epsilon)$ -approximation algorithm for the $k$ -center clustering problem with “small” amortized cost under the fully dynamic adversarial model. In such a model, points can be added or removed arbitrarily, provided that the adversary does not have access to the random choices of our algorithm. The amortized cost of our algorithm is poly-logarithmic when the ratio between the maximum and minimum distance between any two points in input is bounded by a polynomial, while $k$ and $\epsilon$ are constant. Furthermore, we significantly improve the memory requirement of our fully dynamic algorithm, although at the cost of a worse approximation ratio of $4 +\epsilon$ . Our theoretical results are complemented with an extensive experimental evaluation on dynamic data from Twitter, Flickr, as well as trajectory data, demonstrating the effectiveness of our approach.},
  archive      = {J_TKDE},
  author       = {T.-H. Hubert Chan and Arnaud Guerquin and Shuguang Hu and Mauro Sozio},
  doi          = {10.1109/TKDE.2020.3023020},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3255-3266},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fully dynamic $k$k-center clustering with improved memory efficiency},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ESVSSE: Enabling efficient, secure, verifiable searchable
symmetric encryption. <em>TKDE</em>, <em>34</em>(7), 3241–3254. (<a
href="https://doi.org/10.1109/TKDE.2020.3025348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric Searchable Encryption(SSE) is deemed to tackle the privacy issue as well as the operability and confidentiality in data outsourcing. However, most SSE schemes assume that the cloud is honest but curious. This assumption is not always applicable. And even if some schemes supported verification, integrity or freshness checking in a malicious cloud, but the performance and security functionalities are not fully exploited. In this paper, we propose an efficient SSE scheme based on B+-Tree and Counting Bloom Filter (CBF) which supports secure verification, dynamic updating, and multi-user queries. Comparing with the previous state of the arts, we design the new data structure CBF to support dynamic updating and boost verification. We also leverage the timestamp mechanism in the scheme to prevent the malicious cloud from launching a replay attack. The new designed CBF is like a front-engine to save user ${^{\prime }}$ s cost for query and verification. And it can achieve more efficient query and verification with negligible false positive when there is no value matching the queried keyword. The CBF supports efficient dynamic updating by combining Bloom Filter with a one-dimensional array that provides the counting capability. Furthermore, we design the authenticator for CBF. We adopt B+-Tree for it is widely used in many database engines and file systems. We also give a brief security proof of our scheme. Then we provide a detailed performance analysis. Finally, we evaluate our scheme through comprehensive experiments. The results are consistent with our analysis and show that our scheme is secure, and more efficient compared with the previous schemes with the same functionalities. The average performance can be improved by about 20 percent for both the cloud servers and users when the missing rate of the searching keywords is 20 percent. And the higher the missing rate is, the more the performance can be improved.},
  archive      = {J_TKDE},
  author       = {Zhenkui Shi and Xuemei Fu and Xianxian Li and Kai Zhu},
  doi          = {10.1109/TKDE.2020.3025348},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3241-3254},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ESVSSE: Enabling efficient, secure, verifiable searchable symmetric encryption},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Effective similarity search on heterogeneous networks: A
meta-path free approach. <em>TKDE</em>, <em>34</em>(7), 3225–3240. (<a
href="https://doi.org/10.1109/TKDE.2020.3019488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks (HINs) are usually used to model information systems with multi-type objects and relations. In contrast, graphs that have a single type of nodes and edges, are often called homogeneous graphs. Measuring similarities among objects is an important task in data mining applications, such as web search, link prediction, and clustering. Currently, several similarity measures are defined for HINs. Most of these measures are based on meta-paths, which show sequences of node classes and edge types along the paths between two nodes. However, meta-paths, which are often designed by domain experts, are hard to enumerate and choose w.r.t. the quality of similarity scores. This makes using existing similarity measures in real applications difficult. To address this problem, we extend SimRank, a well-known similarity measure on homogeneous graphs, to HINs, by introducing the concept of the decay graph. The newly proposed similarity measure is called HowSim, which has the property of being meta-path free, and capturing the structural and semantic similarity simultaneously. The generality and effectiveness of HowSim, and the efficiency of our proposed algorithms for computing HowSim scores, are demonstrated by extensive experiments.},
  archive      = {J_TKDE},
  author       = {Yue Wang and Zhe Wang and Ziyuan Zhao and Zijian Li and Xun Jian and Hao Xin and Lei Chen and Jianchun Song and Zhenhong Chen and Meng Zhao},
  doi          = {10.1109/TKDE.2020.3019488},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3225-3240},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Effective similarity search on heterogeneous networks: A meta-path free approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain-adversarial network alignment. <em>TKDE</em>,
<em>34</em>(7), 3211–3224. (<a
href="https://doi.org/10.1109/TKDE.2020.3023589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network alignment is a critical task in a wide variety of fields. Many existing works leverage on representation learning to accomplish this task without eliminating domain representation bias induced by domain-dependent features, which yield inferior alignment performance. This paper proposes a unified deep architecture ( DANA ) to obtain a domain-invariant representation for network alignment via an adversarial domain classifier. Specifically, we employ the graph convolutional networks to perform network embedding under the domain adversarial principle, given a small set of observed anchors. Then, the semi-supervised learning framework is optimized by maximizing a posterior probability distribution of observed anchors and the loss of a domain classifier simultaneously. We also develop a few variants of our model, such as, direction-aware network alignment, weight-sharing for directed networks and simplification of parameter space. Experiments on three real-world social network datasets demonstrate that our proposed approaches achieve state-of-the-art alignment results.},
  archive      = {J_TKDE},
  author       = {Huiting Hong and Xin Li and Yuangang Pan and Ivor W. Tsang},
  doi          = {10.1109/TKDE.2020.3023589},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3211-3224},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Domain-adversarial network alignment},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed multimodal path queries. <em>TKDE</em>,
<em>34</em>(7), 3196–3210. (<a
href="https://doi.org/10.1109/TKDE.2020.3020185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal path queries over transportation networks are receiving increasing attention due to their widespread applications. A multimodal path query consists of finding multimodal journeys from source to destination in transportation networks, including unrestricted walking, driving, cycling, and schedule-based public transportation. Transportation networks are generally continent-sized. This characteristic highlights the need for parallel computing to accelerate multimodal path queries. Meanwhile, transportation networks are often fragmented and distributively stored on different machines. This situation calls for exploiting parallel computing power for these distributed systems. Therefore, in this paper, we study distributed multimodal path (DMP) queries over large transportation networks. We develop algorithms to explore parallel computation. When evaluating a DMP query $Q$ on a distributed multimodal graph $Gmult$ , we show that the algorithms possess the following performance guarantees, irrespective of how $Gmult$ is fragmented and distributed: (1) each machine is visited only once; (2) the total network traffic is determined by the size of $Q$ and the fragmentation of $Gmult$ ; (3) the response time is decided by the largest fragment of $Gmult$ ; and (4) the algorithm is parallel scalable. Using real-life and synthetic data, we experimentally verify that the algorithms are scalable on large graphs.},
  archive      = {J_TKDE},
  author       = {Yawen Li and Ye Yuan and Yishu Wang and Xiang Lian and Yuliang Ma and Guoren Wang},
  doi          = {10.1109/TKDE.2020.3020185},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3196-3210},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Distributed multimodal path queries},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed hypergraph processing using intersection graphs.
<em>TKDE</em>, <em>34</em>(7), 3182–3195. (<a
href="https://doi.org/10.1109/TKDE.2020.3022014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of online applications such as social networks has led to an unprecedented scale of data and complex relationships among data. Hypergraphs are introduced to represent complex relationships that may involve more than two entities. A hypergraph is a generalized form of a graph, where edges are generalized to hyperedges. Each hyperedge may consist of any number of vertices. The flexibility of hyperedges also brings challenges in distributed hypergraph processing. In particular, a hypergraph is more difficult to be partitioned and distributed among $k$ workers with balanced partitions. In this paper, we propose to convert a hypergraph into an intersection graph before partitioning by leveraging the inherent shared relationships among hypergraphs. We explore the intersection graph construction method and the corresponding partition strategy which can achieve the goal of evenly distributing vertices and hyperedges across workers, while yielding a significant communication reduction. We also design a distributed processing framework named $Hyraph$ that can directly run hypergraph analysis algorithms on our intersection graphs. Experimental results on real datasets confirm the effectiveness of our techniques and the efficiency of the $Hyraph$ framework.},
  archive      = {J_TKDE},
  author       = {Yu Gu and Kaiqiang Yu and Zhen Song and Jianzhong Qi and Zhigang Wang and Ge Yu and Rui Zhang},
  doi          = {10.1109/TKDE.2020.3022014},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3182-3195},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Distributed hypergraph processing using intersection graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep pairwise hashing for cold-start recommendation.
<em>TKDE</em>, <em>34</em>(7), 3169–3181. (<a
href="https://doi.org/10.1109/TKDE.2020.3024022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation efficiency and data sparsity problems have been regarded as two challenges of improving performance for online recommendation. Most of the previous related work focus on improving recommendation accuracy instead of efficiency. In this paper, we propose a Deep Pairwise Hashing (DPH) to map users and items to binary vectors in Hamming space, where a user&#39;s preference for an item can be efficiently calculated by Hamming distance, which significantly improves the efficiency of online recommendation. To alleviate data sparsity and cold-start problems, the user-item interactive information and item content information are unified to learn effective representations of items and users. Specifically, we first pre-train robust item representation from item content data by a Denoising Auto-encoder instead of other deterministic deep learning frameworks; then we finetune the entire framework by adding a pairwise loss objective with discrete constraints; moreover, DPH aims to minimize a pairwise ranking loss that is consistent with the ultimate goal of recommendation. Finally, we adopt the alternating optimization method to optimize the proposed model with discrete constraints. Extensive experiments on three different datasets show that DPH can significantly advance the state-of-the-art frameworks regarding data sparsity and item cold-start recommendation.},
  archive      = {J_TKDE},
  author       = {Yan Zhang and Ivor W. Tsang and Hongzhi Yin and Guowu Yang and Defu Lian and Jingjing Li},
  doi          = {10.1109/TKDE.2020.3024022},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3169-3181},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep pairwise hashing for cold-start recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-aware path ranking in road networks. <em>TKDE</em>,
<em>34</em>(7), 3153–3168. (<a
href="https://doi.org/10.1109/TKDE.2020.3025024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ranking paths becomes an increasingly important functionality in many transportation services, where multiple paths connecting a source-destination pair are offered to drivers. We study ranking such paths under specific contexts, e.g., at a departure time and for a specific driver. More specifically, we model ranking as a regression problem where we assign a ranking score to each path with the help of historical trajectories. The intuition is that if a driver’s trajectory used path $P$ at time $t$ , we consider this as an evidence that path $P$ is preferred by the driver at time $t$ , thus should have a higher ranking score than other paths connecting the same source and destination. To solve the regression problem, we first propose an effective training data enriching method to obtain a compact and diversified set of training paths using historical trajectories, which provides a data foundation for efficient and effective learning. Next, we propose a multi-task learning framework that considers features representing both candidate paths and contexts. Specifically, a road network embedding is proposed to embed paths into feature vectors by considering both road network topology and spatial properties, such as distances and travel times. By modeling different departure times as a temporal graph, graph embedding is used to embed departure times into feature vectors. The objective function not only considers the discrepancies on ranking scores but also the reconstruction errors of the spatial properties of the paths, which in turn improves the final ranking estimation. Empirical studies on a substantial trajectory data set offer insight into the designed properties of the proposed framework, indicating that it is effective and practical in real world settings.},
  archive      = {J_TKDE},
  author       = {Sean Bin Yang and Chenjuan Guo and Bin Yang},
  doi          = {10.1109/TKDE.2020.3025024},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3153-3168},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Context-aware path ranking in road networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CONNA: Addressing name disambiguation on the fly.
<em>TKDE</em>, <em>34</em>(7), 3139–3152. (<a
href="https://doi.org/10.1109/TKDE.2020.3021256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Name disambiguation is a key and also a very tough problem in many online systems such as social search and academic search. Despite considerable research, a critical issue that has not been systematically studied is disambiguation on the fly — to complete the disambiguation in the real-time. This is very challenging, as the disambiguation algorithm must be accurate, efficient, and error tolerance. In this paper, we propose a novel framework — CONNA — to train a matching component and a decision component jointly via reinforcement learning. The matching component is responsible for finding the top matched candidate for the given paper, and the decision component is responsible for deciding on assigning the top matched person or creating a new person. The two components are intertwined and can be bootstrapped via jointly training. Empirically, we evaluate CONNA on two name disambiguation datasets. Experimental results show that the proposed framework can achieve a 1.21-19.84 percent improvement on F1-score using joint training of the matching and the decision components. The proposed CONNA has been successfully deployed on AMiner — a large online academic search system.},
  archive      = {J_TKDE},
  author       = {Bo Chen and Jing Zhang and Jie Tang and Lingfan Cai and Zhaoyu Wang and Shu Zhao and Hong Chen and Cuiping Li},
  doi          = {10.1109/TKDE.2020.3021256},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3139-3152},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CONNA: Addressing name disambiguation on the fly},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing k-cores in large uncertain graphs: An index-based
optimal approach. <em>TKDE</em>, <em>34</em>(7), 3126–3138. (<a
href="https://doi.org/10.1109/TKDE.2020.3023925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain graph management and analysis have attracted many research attentions. Among them, computing $k$ -cores in uncertain graphs (aka, $(k,\eta)$ -cores) is an important problem and has emerged in many applications such as community detection, protein-protein interaction network analysis and influence maximization. Given an uncertain graph, the $(k,\eta)$ -cores can be derived by iteratively removing the vertex with an $\eta$ -degree of less than $k$ . However, the results heavily depend on the two input parameters $k$ and $\eta$ . The settings for these parameters are unique to the specific graph structure and the user&#39;s subjective requirements. In addition, computing and updating the $\eta$ -degree for each vertex is the most costly component in the algorithm, and the cost is high. To overcome these drawbacks, we propose an index-based solution for computing $(k,\eta)$ -cores. The size of the index is well bounded by $O(m)$ , where $m$ is the number of edges in the graph. Based on the index, queries for any $k$ and $\eta$ can be answered in optimal time. We propose an algorithm for index construction with several different optimizations. We also propose a new algorithm for index construction in external memory. We conduct extensive experiments on eight real-world datasets to practically evaluate the performance of all proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Dong Wen and Bohua Yang and Lu Qin and Ying Zhang and Lijun Chang and Rong-Hua Li},
  doi          = {10.1109/TKDE.2020.3023925},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3126-3138},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Computing K-cores in large uncertain graphs: An index-based optimal approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bipartite graph based multi-view clustering. <em>TKDE</em>,
<em>34</em>(7), 3111–3125. (<a
href="https://doi.org/10.1109/TKDE.2020.3021649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For graph-based multi-view clustering, a critical issue is to capture consensus cluster structures via a two-stage learning scheme. Specifically, first learn similarity graph matrices of multiple views and then fuse them into a unified superior graph matrix. Most current methods learn pairwise similarities between data points for each view independently, which is widely used in single view. However, the consensus information contained in multiple views are ignored, and the involved biases lead to an undesirable unified graph matrix. To this end, we propose a bipartite graph based multi-view clustering (BIGMC) approach. The consensus information can be represented by a small number of representative uniform anchor points for different views. A bipartite graph is constructed between data points and the anchor points. BIGMC constructs the bipartite graph matrices of all views and fuses them to produce a unified bipartite graph matrix. The unified bipartite graph matrix in turn improves the bipartite graph similarity matrix of each view and updates the anchor points. The final unified graph matrix forms the final clusters directly. In BIGMC, an adaptive weight is added for each view to avoid outlier views. A low-rank constraint is imposed on the Laplacian matrix of the unified matrix to construct a multi-component unified bipartite graph, where the component number corresponds to the required cluster number. The objective function is optimized in an alternating optimization fashion. Experimental results on synthetic and real-world data sets demonstrate its effectiveness and superiority compared with the state-of-the-art baselines.},
  archive      = {J_TKDE},
  author       = {Lusi Li and Haibo He},
  doi          = {10.1109/TKDE.2020.3021649},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3111-3125},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Bipartite graph based multi-view clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An innovative risk assessment methodology for medical
information systems. <em>TKDE</em>, <em>34</em>(7), 3095–3110. (<a
href="https://doi.org/10.1109/TKDE.2020.3023553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern Medical Information Systems very often comprise Medical Devices and governed by regulations which require stringent Risk Management activities to be implemented to minimize the occurrence of safety risks. Currently, the reference standard adopted by manufacturers for Risk Management is ISO 14971, which, however, was devised for traditional (mostly hardware) Medical Devices and does not either take into account the peculiarities of modern Medical Information Systems, or define a formal methodology to conduct Risk Assessment. Moreover, the approaches currently implemented by manufacturers typically aims at obtaining qualitative Risk Assessment results. Within the so-delineated application scenario, this paper proposes a methodology for the Dynamic Probabilistic Risk Assessment of Medical Information Systems, by specifically looking at medical devices that are intended as one of the most relevant components in such systems. The methodology complies with ISO 14971 and improves current practices because it allows the analyst to conduct a quantitative analysis, also taking into account the temporal dimension. It relies on a Probabilistic Risk Model, defined as a set of Markov Models, which is model-checked to obtain quantitative information about the risks. The proposed methodology is also adopted to improve definitively the Medical Device post-market surveillance, which is currently implemented as a ”wait for an incident” activity. In other words, currently a manufacturer sets up a service that has to ”react” to an incident by starting an investigation activity. Instead, the methodology proposes the adoption of risk models defined during the development phase also to re-assess periodically the risks related to the product during the post-market surveillance. This may prevent some incidents because risks are assessed using data collected in the field (no longer guesstimated as during the development phase) and taking into account the temporal effects on probability distributions (such as the deterioration of hardware/software components over the time).},
  archive      = {J_TKDE},
  author       = {Antonio Coronato and Alfredo Cuzzocrea},
  doi          = {10.1109/TKDE.2020.3023553},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3095-3110},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An innovative risk assessment methodology for medical information systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A stochastic approach to finding densest temporal subgraphs
in dynamic graphs. <em>TKDE</em>, <em>34</em>(7), 3082–3094. (<a
href="https://doi.org/10.1109/TKDE.2020.3025463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One important problem that is insufficiently studied is finding densest lasting -subgraphs in large dynamic graphs, which considers the time duration of the subgraph pattern. We propose a framework called Expectation-Maximization with Utility functions (EMU), a novel stochastic approach that nontrivially extends the conventional EM approach. EMU has the flexibility of optimizing any user-defined utility functions. We validate our EMU approach by showing that it converges to the optimum—by proving that it is a specification of the general Minorization-Maximization (MM) framework with convergence guarantees. We devise EMU algorithms for the densest lasting subgraph problem, as well as several variants by varying the utility function. Using real-world data, we evaluate the effectiveness and efficiency of our techniques, and compare them with two prior approaches on dense subgraph detection.},
  archive      = {J_TKDE},
  author       = {Xuanming Liu and Tingjian Ge and Yinghui Wu},
  doi          = {10.1109/TKDE.2020.3025463},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3082-3094},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A stochastic approach to finding densest temporal subgraphs in dynamic graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel method for creating an optimized ensemble classifier
by introducing cluster size reduction and diversity. <em>TKDE</em>,
<em>34</em>(7), 3072–3081. (<a
href="https://doi.org/10.1109/TKDE.2020.3025173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new method is proposed for creating an optimized ensemble classifier. The proposed method mitigates the issue of class imbalances by partitioning the input data into its various data classes. The partitions are then clustered incrementally to generate a pool of class pure data clusters. The generated data clusters are then balanced by adding samples from all classes which are closest to the cluster centroid. In this manner all generated data clusters are balanced and classifiers trained on such a data cluster are unbiased as well. This creates a diverse input space for training of base classifiers. The pool of clusters is then utilized to train a set of diverse base classifiers to generate the base classifier pool. The pool of classifiers is then treated as a combinatorial problem of optimization and an evolutionary algorithm is incorporated. The proposed approach generates an optimized ensemble classifier that can not only achieve the highest classification accuracy but also has a lower component size as well. The proposed approach is tested on 31 benchmark datasets from UCI machine learning repository and results are compared with existing state-of-the-art ensemble classifiers as well.},
  archive      = {J_TKDE},
  author       = {Zohaib Jan and Juan Carlos Munos and Asim Ali},
  doi          = {10.1109/TKDE.2020.3025173},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3072-3081},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A novel method for creating an optimized ensemble classifier by introducing cluster size reduction and diversity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-criteria approach for fast and robust representative
selection from manifolds. <em>TKDE</em>, <em>34</em>(7), 3057–3071. (<a
href="https://doi.org/10.1109/TKDE.2020.3024099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of representative selection amounts to sampling few informative exemplars from large datasets. Existing approaches to data selection often fall short of simultaneously handling non-linear data structures, sampling concise and non-redundant subsets, rejecting outliers, and yielding interpretable outcomes. This paper presents a novel representative selection approach, dubbed MOSAIC, for drawing descriptive sketches of arbitrary manifold structures. Resting upon a novel quadratic formulation, MOSAIC advances a multi-criteria selection approach that maximizes the global representation power of the sampled subset, ensures novelty of the samples by minimizing redundancy, and rejects disruptive information by effectively detecting outliers. Theoretical analyses shed light on geometrical characterization of the obtained sketch and reveal that the sampled representatives maximize a well-defined notion of data coverage in a transformed space. In addition, we present a highly scalable randomized implementation of the proposed algorithm shown to bring about substantial speedups. MOSAIC’s superiority in achieving the desired characteristics of a representative subset all at once while exhibiting remarkable robustness to various outlier types is demonstrated via extensive experiments conducted on both real and synthetic data with comparisons to state-of-the-art algorithms.},
  archive      = {J_TKDE},
  author       = {Mahlagha Sedghi and Michael Georgiopoulos and George K. Atia},
  doi          = {10.1109/TKDE.2020.3024099},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3057-3071},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A multi-criteria approach for fast and robust representative selection from manifolds},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A high-performance index for real-time matrix retrieval.
<em>TKDE</em>, <em>34</em>(7), 3044–3056. (<a
href="https://doi.org/10.1109/TKDE.2020.3025925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental technique in machine learning called “embedding” has made significant impact on data representation. Some examples of embedding include word embedding, image embedding and audio embedding. With the embedding techniques, many real-world objects can be represented using matrices. For example, a document can be represented by a matrix, where each row of the matrix represents a word. On the other hand, we have witnessed that many applications continuously generate new data represented by matrices and require real-time query answering on the data. These continuously generated matrices need to be well managed for efficient retrieval. In this paper, we propose a high-performance index for real-time matrix retrieval. Besides fast query response, the index also supports real-time insertion by exploiting the log-structured merge-tree (LSM-tree). Since the index is built for matrices, it consumes much more memory and requires much more time to search than the traditional index for information retrieval. To tackle the challenges, we propose an index with precise and fuzzy inverted lists, and design a series of novel techniques to improve the memory consumption and the search efficiency of the index. The proposed techniques include vector signature, vector residual sorting, hashing based lookup, and dictionary initialization to guarantee the index quality. Comprehensive experimental results show that our proposed index can support real-time search on matrices, and is more time and memory efficient than the state-of-the-art method.},
  archive      = {J_TKDE},
  author       = {Zeyi Wen and Mingyu Liang and Bingsheng He and Zexin Xia},
  doi          = {10.1109/TKDE.2020.3025925},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3044-3056},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A high-performance index for real-time matrix retrieval},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A BP neural network based recommender framework with
attention mechanism. <em>TKDE</em>, <em>34</em>(7), 3029–3043. (<a
href="https://doi.org/10.1109/TKDE.2020.3023976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, some attempts have been made in introducing deep neural networks (DNNs) to recommender systems for generating more accurate prediction due to the nonlinear representation learning capability of DNNs. However, they inevitably result in high computational and storage costs. Worse still, due to the relatively small number of ratings that can be fed into DNNs, they may easily suffer from the overfitting issue. To tackle these issues, we propose a novel recommendation framework based on Back Propagation (BP) neural network with attention mechanism, namely BPAM++. In particular, the BP neural network is utilized to learn the complex relationship between the target user and his/her neighbors and the complex relationship between the target item and its neighbors. Compared with DNNs, the shallow neural network, i.e., BP neural network, can not only reduce the computational and storage costs, but also alleviate the overfitting issues in DNNs caused by a relatively small number of ratings. In addition, an attention mechanism is designed to capture the global impact of the nearest users of the target user on their nearest target user sets. Extensive experiments conducted on eight benchmark datasets confirm the effectiveness of the proposed model.},
  archive      = {J_TKDE},
  author       = {Chang-Dong Wang and Wu-Dong Xi and Ling Huang and Yin-Yu Zheng and Zi-Yuan Hu and Jian-Huang Lai},
  doi          = {10.1109/TKDE.2020.3023976},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {7},
  pages        = {3029-3043},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A BP neural network based recommender framework with attention mechanism},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised spectral feature selection with dynamic
hyper-graph learning. <em>TKDE</em>, <em>34</em>(6), 3016–3028. (<a
href="https://doi.org/10.1109/TKDE.2020.3017250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised spectral feature selection (USFS) methods could output interpretable and discriminative results by embedding a Laplacian regularizer in the framework of sparse feature selection to keep the local similarity of the training samples. To do this, USFS methods usually construct the Laplacian matrix using either a general-graph or a hyper-graph on the original data. Usually, a general-graph could measure the relationship between two samples while a hyper-graph could measure the relationship among no less than two samples. Obviously, the general-graph is a special case of the hyper-graph and the hyper-graph may capture more complex structure of samples than the general graph. However, in previous USFS methods, the construction of the Laplacian matrix is separated from the process of feature selection. Moreover, the original data usually contain noise. Each of them makes difficult to output reliable feature selection models. In this paper, we propose a novel feature selection method by dynamically constructing a hyper-graph based Laplacian matrix in the framework of sparse feature selection. Experimental results on real datasets showed that our proposed method outperformed the state-of-the-art methods in terms of both clustering and segmentation tasks.},
  archive      = {J_TKDE},
  author       = {Xiaofeng Zhu and Shichao Zhang and Yonghua Zhu and Pengfei Zhu and Yue Gao},
  doi          = {10.1109/TKDE.2020.3017250},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {3016-3028},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unsupervised spectral feature selection with dynamic hyper-graph learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised feature learning architecture with
multi-clustering integration RBM. <em>TKDE</em>, <em>34</em>(6),
3002–3015. (<a href="https://doi.org/10.1109/TKDE.2020.3015959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel unsupervised feature learning architecture, which consists of a multi-clustering integration module and a variant of RBM termed multi-clustering integration RBM (MIRBM). In the multi-clustering integration module, we apply three clusterers (K-means, affinity propagation and spectral clustering algorithms) to obtain three different clustering partitions (CPs) without any background knowledge or label. Then, an unanimous voting strategy is used to generate a local clustering partition (LCP). The novel MIRBM model is a core feature encoding part of the proposed unsupervised feature learning architecture. The novelty of it is that the LCP as an unsupervised guidance is integrated into one step contrastive divergence ( ${\mathtt{{CD}}}_{1}$ ) learning to guide the distribution of the hidden layer features. For the instance in the same LCP cluster, the hidden and reconstructed hidden layer features of the MIRBM model in the proposed architecture tend to constrict together in the training process. Meanwhile, each LCP center tends to disperse from each other as much as possible in the hidden and reconstructed hidden layer during training. The experiments demonstrate that the proposed unsupervised feature learning architecture has more powerful feature representation and generalization capability than the state-of-the-art models for clustering tasks in the Microsoft Research Asia Multimedia (MSRA-MM)2.0 dataset.},
  archive      = {J_TKDE},
  author       = {Jielei Chu and Hongjun Wang and Jing Liu and Zhiguo Gong and Tianrui Li},
  doi          = {10.1109/TKDE.2020.3015959},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {3002-3015},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unsupervised feature learning architecture with multi-clustering integration RBM},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). T-PAIR: Temporal node-pair embedding for automatic
biomedical hypothesis generation. <em>TKDE</em>, <em>34</em>(6),
2988–3001. (<a href="https://doi.org/10.1109/TKDE.2020.3017687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study an automatic hypothesis generation (HG) problem, which refers to the discovery of meaningful implicit connections between scientific terms, including but not limited to diseases, chemicals, drugs, and genes extracted from databases of biomedical publications. Most prior studies of this problem focused on the use of static information of terms and largely ignored the temporal dynamics of scientific term relations. Even when the dynamics were considered in a few recent studies, they learned the representations for the scientific terms, rather than focusing on the term-pair relations. Since the HG problem is to predict term-pair connections, it is not enough to know with whom the terms are connected, it is more important to know how the connections have been formed (in a dynamic process). We formulate this HG problem as a future connectivity prediction in a dynamic attributed graph. The key is to capture the temporal evolution of node-pair (term-pair) relations. We propose an inductive edge (node-pair) embedding method named T-PAIR, utilizing both the graphical structure and node attribute to encode the temporal node-pair relationship. We demonstrate the efficiency of the proposed model on three real-world datasets, which are three graphs constructed from Pubmed papers published until 2019 in Neurology , Immunotherapy , and Virology , respectively. Evaluations were conducted on predicting future term-pair relations between millions of seen terms (in the transductive setting), as well as on the relations involving unseen terms (in the inductive setting). Experiment results and case study analyses show the effectiveness of the proposed model.},
  archive      = {J_TKDE},
  author       = {Uchenna Akujuobi and Michael Spranger and Sucheendra K. Palaniappan and Xiangliang Zhang},
  doi          = {10.1109/TKDE.2020.3017687},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2988-3001},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {T-PAIR: Temporal node-pair embedding for automatic biomedical hypothesis generation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward predicting active participants in tweet streams: A
case study on two civil rights events. <em>TKDE</em>, <em>34</em>(6),
2975–2987. (<a href="https://doi.org/10.1109/TKDE.2020.3017635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social media have aroused much research interest in recent years. In contrast to previous work that focused on the detection of emerging topics, this article undertakes the prediction of active users in online social events, which is so far rarely explored. This prediction task is formulated as a binary classification problem that built on real-world tweet streams, taking Ferguson event and New York Chockhold event as examples. Then, a comprehensive user feature system is designed to characterize the events’ online participants, which includes not only basic statistical characteristics and image-pixel-level features, but also some emotional features and personality features. Next, the Weighted Random Forest (Weighted-RF) classifier is adopted to solve the classification problem. Based on the user feature system and the classifier, the experience of a previous event can be archived and applied to the prediction of later similar events. Experimental results show that the Weighted-RF trained by samples of Ferguson event can effectively predict active users in NYC event, with an AUC value around 0.8392. Besides, the image-content based personality model provides a new tool for depicting user portraits, which further contributes to the quantitative analysis of online social events.},
  archive      = {J_TKDE},
  author       = {Xiao-Kun Wu and Tian-Fang Zhao and Wei-Neng Chen and Jun Zhang},
  doi          = {10.1109/TKDE.2020.3017635},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2975-2987},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Toward predicting active participants in tweet streams: A case study on two civil rights events},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The dynamic privacy-preserving mechanisms for online dynamic
social networks. <em>TKDE</em>, <em>34</em>(6), 2962–2974. (<a
href="https://doi.org/10.1109/TKDE.2020.3015835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks that constantly transmit information and change structure are becoming increasingly prevalent. However, traditional privacy models are designed to protect static information, such as records in a database or a person’s profile information, which seldom changes. This conflict between static models and dynamic environments is dramatically hindering the effectiveness and efficiency of privacy preservation in today’s dynamic world. Hence, in this paper, we formally define the concept of dynamic privacy, present two novel perspectives, privacy propagation and accumulation, on the way private information can spread through dynamic cyberspace, and develop associated theories and mechanisms for preserving privacy in advanced complex networks, such as social networking sites where data are constantly being released, shared, and exchanged.},
  archive      = {J_TKDE},
  author       = {Tianqing Zhu and Jin Li and Xiangyu Hu and Ping Xiong and Wanlei Zhou},
  doi          = {10.1109/TKDE.2020.3015835},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2962-2974},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {The dynamic privacy-preserving mechanisms for online dynamic social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tensor canonical correlation analysis networks for
multi-view remote sensing scene recognition. <em>TKDE</em>,
<em>34</em>(6), 2948–2961. (<a
href="https://doi.org/10.1109/TKDE.2020.3016208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural network (CNN) has been proven an effective way to extract high-level features from remote sensing (RS) images automatically. Many variants of the CNN model have been proposed, including principal component analysis network (PCANet), canonical correlation analysis network (CCANet), multiple scale CCANet (MS-CCANet) and multiview CCANet (MCCANet). The PCANet is specialized for single view feature abstraction, while in many real-world practices, the RS data are frequently observed from many more views. Although CCANet, MS-CCANet and MCCANet can be applied to two or more view data, they consider only the pair-wise correlation by calculating a series of two-order covariance matrices. However, the high-order consistence, which can only be explored by collectively and simultaneously examining all views, remains undiscovered. In this paper, we propose the tensor canonical correlation analysis network (TCCANet) to tackle this problem. Particularly, TCCANet learns filter banks by simultaneously maximizing arbitrary number of views with high-order-correlation and solves the optimization problem by decomposing a covariance tensor. After the convolutional stage, we utilize binarization and block-wise histogram strategies to generate the final feature. Furthermore, we also develop a Multiple Scale version of TCCANet, i.e., MS-TCCANet, to extract enriched representation of the RS data by incorporating all previous convolutional layers. Numerical experiment results on RSSCN7 and SAT-6 datasets demonstrate the advantages of TCCANet and MS-TCCANet for RS scene recognition.},
  archive      = {J_TKDE},
  author       = {Xinghao Yang and Weifeng Liu and Wei Liu},
  doi          = {10.1109/TKDE.2020.3016208},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2948-2961},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Tensor canonical correlation analysis networks for multi-view remote sensing scene recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spiral of silence and its application in recommender
systems. <em>TKDE</em>, <em>34</em>(6), 2934–2947. (<a
href="https://doi.org/10.1109/TKDE.2020.3013973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to model missing ratings in recommender systems since user preferences learnt from only observed ratings are biased. One possible explanation for missing ratings is motivated by the spiral of silence theory. When the majority opinion is formed, a spiral process is triggered where users are more and more likely to show their ratings if they perceive that they are supported by the opinion climate. In this paper we first verify the existence of the spiral process in recommender systems by using a variety of different real-life datasets. We then study the characteristics of two key factors in the spiral process: opinion climate and the hardcore users who will give ratings even when they are minority opinion holders. Based on our empirical findings, we develop four variants to model missing ratings. They mimic different components of the spiral of silence based on the spiral process with global opinion climate, local opinion climate, hardcore users, relationships between hardcore users and items, respectively. We experimentally show that, the presented variants all outperform state-of-the-art recommendation models with missing rating components.},
  archive      = {J_TKDE},
  author       = {Chen Lin and Dugang Liu and Hanghang Tong and Yanghua Xiao},
  doi          = {10.1109/TKDE.2020.3013973},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2934-2947},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Spiral of silence and its application in recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social recommendation with characterized regularization.
<em>TKDE</em>, <em>34</em>(6), 2921–2933. (<a
href="https://doi.org/10.1109/TKDE.2020.3017489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendation, which utilizes social relations to enhance recommender systems, has been gaining increasing attention recently with the rapid development of online social networks. Existing social recommendation methods are based on the assumption, so-called social-trust , that users’ preference or decision is influenced by their social-connected friends’ purchase behaviors. However, they assume that the influences of social relationships are always the same, which violates the fact that users are likely to share preference on different products with different friends. More precisely, friends’ behaviors do not necessarily affect a user’s preferences, and the influence is diverse among different items. In this paper, we contribute a new solution, CSR (short for C haracterized S ocial R egularization) model by designing a universal regularization term for modeling variable social influence. This regularization term captures the finely grained similarity of social-connected friends. We further introduce two variants of our model with different optimization manners. Our proposed model can be applied to both explicit and implicit interaction due to its high generality. Extensive experiments on three real-world datasets demonstrate that our CSR can outperform state-of-the-art social recommendation methods. Further experiments show that CSR can improve recommendation performance for those users with sparse social relations or behavioral interactions.},
  archive      = {J_TKDE},
  author       = {Chen Gao and Nian Li and Tzu-Heng Lin and Dongsheng Lin and Jun Zhang and Yong Li and Depeng Jin},
  doi          = {10.1109/TKDE.2020.3017489},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2921-2933},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Social recommendation with characterized regularization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised learning with the EM algorithm: A
comparative study between unstructured and structured prediction.
<em>TKDE</em>, <em>34</em>(6), 2912–2920. (<a
href="https://doi.org/10.1109/TKDE.2020.3019038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning aims to learn prediction models from both labeled and unlabeled samples. There has been extensive research in this area. Among existing work, generative mixture models with Expectation-Maximization (EM) is a popular method due to clear statistical properties. However, existing literature on EM-based semi-supervised learning largely focuses on unstructured prediction, assuming that samples are independent and identically distributed. Studies on EM-based semi-supervised approach in structured prediction is limited. This article aims to fill the gap through a comparative study between unstructured and structured methods in EM-based semi-supervised learning. Specifically, we compare their theoretical properties and find that both methods can be considered as a generalization of self-training with soft class assignment of unlabeled samples, but the structured method additionally considers structural constraint in soft class assignment. We conducted a case study on real-world flood mapping datasets to compare the two methods. Results show that structured EM is more robust to class confusion caused by noise and obstacles in features in the context of the flood mapping application.},
  archive      = {J_TKDE},
  author       = {Wenchong He and Zhe Jiang},
  doi          = {10.1109/TKDE.2020.3019038},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2912-2920},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Semi-supervised learning with the EM algorithm: A comparative study between unstructured and structured prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SCOs: Semi-supervised co-selection by a similarity
preserving approach. <em>TKDE</em>, <em>34</em>(6), 2899–2911. (<a
href="https://doi.org/10.1109/TKDE.2020.3014262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on co-selection of instances and features in the semi-supervised learning scenario. In this context, co-selection becomes a more challenging problem as data contain labeled and unlabeled examples sampled from the same population. To carry out such semi-supervised co-selection, we propose a unified framework, called sCOs, which efficiently integrates labeled and unlabeled parts into the co-selection process. The framework is based on introducing both a sparse regularization term and a similarity preserving approach . It evaluates the usefulness of features and instances in order to select the most relevant ones, simultaneously. We propose two efficient algorithms that work for both convex and nonconvex functions. To the best of our knowledge, this paper offers, for the first time ever, a study utilizing nonconvex penalties for the co-selection of semi-supervised learning tasks. Experimental results on some known benchmark datasets are provided for validating sCOs and comparing it with some representative methods in the state-of-the art.},
  archive      = {J_TKDE},
  author       = {Khalid Benabdeslem and Dou El Kefel Mansouri and Raywat Makkhongkaew},
  doi          = {10.1109/TKDE.2020.3014262},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2899-2911},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SCOs: Semi-supervised co-selection by a similarity preserving approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Representation learning from limited educational data with
crowdsourced labels. <em>TKDE</em>, <em>34</em>(6), 2886–2898. (<a
href="https://doi.org/10.1109/TKDE.2020.3017122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning has been proven to play an important role in the unprecedented success of machine learning models in numerous tasks, such as machine translation, face recognition and recommendation. The majority of existing representation learning approaches often require a large number of consistent and noise-free labels. However, due to various reasons such as budget constraints and privacy concerns, labels are very limited in many real-world scenarios. Directly applying standard representation learning approaches on small labeled data sets will easily run into over-fitting problems and lead to sub-optimal solutions. Even worse, in some domains such as education, the limited labels are usually annotated by multiple workers with diverse expertise, which yields noises and inconsistency in such crowdsourcing settings. In this paper, we propose a novel framework which aims to learn effective representations from limited data with crowdsourced labels. Specifically, we design a grouping based deep neural network to learn embeddings from a limited number of training samples and present a Bayesian confidence estimator to capture the inconsistency among crowdsourced labels. Furthermore, to expedite the training process, we develop a hard example selection procedure to adaptively pick up training examples that are misclassified by the model. Extensive experiments conducted on three real-world data sets demonstrate the superiority of our framework on learning representations from limited data with crowdsourced labels, comparing with various state-of-the-art baselines. In addition, we provide a comprehensive analysis on each of the main components of our proposed framework and also introduce the promising results it achieved in our real production to fully understand the proposed framework. To encourage reproducible results, we make our code available online at https://github.com/tal-ai/RECLE .},
  archive      = {J_TKDE},
  author       = {Wentao Wang and Guowei Xu and Wenbiao Ding and Gale Yan Huang and Guoliang Li and Jiliang Tang and Zitao Liu},
  doi          = {10.1109/TKDE.2020.3017122},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2886-2898},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Representation learning from limited educational data with crowdsourced labels},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal neighborhood multiple kernel clustering with
adaptive local kernels. <em>TKDE</em>, <em>34</em>(6), 2872–2885. (<a
href="https://doi.org/10.1109/TKDE.2020.3014104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple kernel clustering (MKC) algorithm aims to group data into different categories by optimally integrating information from a group of pre-specified kernels. Though demonstrating superiorities in various applications, we observe that existing MKC algorithms usually do not sufficiently consider the local density around individual data samples and excessively limit the representation capacity of the learned optimal kernel , leading to unsatisfying performance. In this paper, we propose an algorithm, called optimal neighborhood MKC with adaptive local kernels (ON-ALK), to address the two issues. In specific, we construct adaptive local kernels to sufficiently consider the local density around individual data samples, where different numbers of neighbors are discriminatingly selected on each sample. Further, the proposed ON-ALK algorithm boosts the representation of the learned optimal kernel via relaxing it into the neighborhood area of weighted combination of the pre-specified kernels. To solve the resultant optimization problem, a three-step iterative algorithm is designed and theoretically proven to be convergent. After that, we also study the generalization bound of the proposed algorithm. Extensive experiments have been conducted to evaluate the clustering performance. As indicated, the algorithm significantly outperforms state-of-the-art methods in recent literatures on six challenging benchmark datasets, verifying its advantages and effectiveness.},
  archive      = {J_TKDE},
  author       = {Jiyuan Liu and Xinwang Liu and Jian Xiong and Qing Liao and Sihang Zhou and Siwei Wang and Yuexiang Yang},
  doi          = {10.1109/TKDE.2020.3014104},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2872-2885},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Optimal neighborhood multiple kernel clustering with adaptive local kernels},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal estimation of low-rank factors via feature level
data fusion of multiplex signal systems. <em>TKDE</em>, <em>34</em>(6),
2860–2871. (<a href="https://doi.org/10.1109/TKDE.2020.3015914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of fusion engines is a subject of great importance in a variety of fields. In this paper, we focus on the problem of linear fusion at the feature level for multiple signal matrices with noises, with the features being extremal eigenvectors. When given multiple similarity matrices, the objective is to find an estimate of the latent signal eigenspace. The concentration result for the inner product of features from different matrix samples is developed, utilizing the random matrix theory. Based on of the theoretical results, we proposed an efficient algorithm, EigFuse , to solve the constrained data-driven optimization problem with different level of noises. Our method is of high efficiency by comparing it with state-of-the-art baseline approaches with multiple noise levels. Comprehensive experiments on several synthetic as well as real-life networks demonstrate our method’s superior performance.},
  archive      = {J_TKDE},
  author       = {Hui-Jia Li and Zhen Wang and Jie Cao and Jian Pei and Yong Shi},
  doi          = {10.1109/TKDE.2020.3015914},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2860-2871},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Optimal estimation of low-rank factors via feature level data fusion of multiplex signal systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neighborhood matters: Influence maximization in social
networks with limited access. <em>TKDE</em>, <em>34</em>(6), 2844–2859.
(<a href="https://doi.org/10.1109/TKDE.2020.3015387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) aims at maximizing the spread of influence by offering discounts to influential users (called seeding). In many applications, due to user’s privacy concern, overwhelming network scale etc., it is hard to target any user in the network as one wishes. Instead, only a small subset of users is initially accessible. Such access limitation would significantly impair the influence spread, since IM often relies on seeding high degree users, which are particularly rare in such a small subset due to the power-law structure of social networks. In this paper, we attempt to solve the limited IM in real-world scenarios by the adaptive approach with seeding and diffusion uncertainty considered. Specifically, we consider fine-grained discounts and assume users accept the discount probabilistically. The diffusion process is depicted by the independent cascade model. To overcome the access limitation, we prove the set-wise friendship paradox (FP) phenomenon that neighbors have higher degree in expectation, and propose a two-stage seeding model with the FP embedded, where neighbors are seeded. On this basis, for comparison we formulate the non-adaptive case and adaptive case, both proven to be NP-hard. In the non-adaptive case, discounts are allocated to users all at once. We show the monotonicity of influence spread w.r.t. discount allocation and design a two-stage coordinate descent framework to decide the discount allocation. In the adaptive case, users are sequentially seeded based on observations of existing seeding and diffusion results. We prove the adaptive submodularity and submodularity of the influence spread function in two stages. Then, a series of adaptive greedy algorithms are proposed with constant approximation ratio. Extensive experiments on real-world datasets show that our adaptive algorithms achieve larger influence spread than non-adaptive and other adaptive algorithms (up to a maximum of 116 percent).},
  archive      = {J_TKDE},
  author       = {Chen Feng and Luoyi Fu and Bo Jiang and Haisong Zhang and Xinbing Wang and Feilong Tang and Guihai Chen},
  doi          = {10.1109/TKDE.2020.3015387},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2844-2859},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Neighborhood matters: Influence maximization in social networks with limited access},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). More than privacy: Applying differential privacy in key
areas of artificial intelligence. <em>TKDE</em>, <em>34</em>(6),
2824–2843. (<a href="https://doi.org/10.1109/TKDE.2020.3014246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has attracted a great deal of attention in recent years. However, alongside all its advancements, problems have also emerged, such as privacy violations, security issues and model fairness. Differential privacy, as a promising mathematical model, has several attractive properties that can help solve these problems, making it quite a valuable tool. For this reason, differential privacy has been broadly applied in AI but to date, no study has documented which differential privacy mechanisms can or have been leveraged to overcome its issues or the properties that make this possible. In this paper, we show that differential privacy can do more than just privacy preservation. It can also be used to improve security, stabilize learning, build fair models, and impose composition in selected areas of AI. With a focus on regular machine learning, distributed machine learning, deep learning, and multi-agent systems, the purpose of this article is to deliver a new view on many possibilities for improving AI performance with differential privacy techniques.},
  archive      = {J_TKDE},
  author       = {Tianqing Zhu and Dayong Ye and Wei Wang and Wanlei Zhou and Philip S. Yu},
  doi          = {10.1109/TKDE.2020.3014246},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2824-2843},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {More than privacy: Applying differential privacy in key areas of artificial intelligence},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Iterative refinement for multi-source visual domain
adaptation. <em>TKDE</em>, <em>34</em>(6), 2810–2823. (<a
href="https://doi.org/10.1109/TKDE.2020.3014697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main challenges in multi-source domain adaptation is how to reduce the domain discrepancy between each source domain and a target domain, and then evaluate the domain relevance to determine how much knowledge should be transferred from different source domains to the target domain. However, most prior approaches barely consider both discrepancies and relevance among domains. In this paper, we propose an algorithm, called Iterative Refinement based on Feature Selection and the Wasserstein distance (IRFSW), to solve semi-supervised domain adaptation with multiple sources. Specifically, IRFSW aims to explore both the discrepancies and relevance among domains in an iterative learning procedure, which gradually refines the learning performance until the algorithm stops. In each iteration, for each source domain and the target domain, we develop a sparse model to select features in which the domain discrepancy and training loss are reduced simultaneously. Then a classifier is constructed with the selected features of the source and labeled target data. After that, we exploit optimal transport over the selected features to calculate the transferred weights. The weight values are taken as the ensemble weights to combine the learned classifiers to control the amount of knowledge transferred from source domains to the target domain. Experimental results validate the effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Hanrui Wu and Yuguang Yan and Guosheng Lin and Min Yang and Michael K. Ng and Qingyao Wu},
  doi          = {10.1109/TKDE.2020.3014697},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2810-2823},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Iterative refinement for multi-source visual domain adaptation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Item recommendation for word-of-mouth scenario in social
e-commerce. <em>TKDE</em>, <em>34</em>(6), 2798–2809. (<a
href="https://doi.org/10.1109/TKDE.2020.3017509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social commerce, which is different from traditional e-commerce where people purchase products via initiative searching or recommendations from the platform, transforms a social community into an inclusive place to do business by enabling people to share products with their friends. A user ( sharer ), can share a link of a product to their social-connected friends ( receiver ). Once a receiver purchases the product, the sharer can earn commission provided by the platform. To promote sales, the platform can also assist sharers by providing product candidates which are more likely to be purchased during the social sharing. We define this task of generating sharing suggestions as item recommendation for word-of-mouth scenario, and to the best of our knowledge, this is a new task that has never been explored. In this article, we propose a TriM (short for Tri ad based word-of- M outh recommendation) model that can capture both the sharer’s influence and the receiver’s interest at the same time, which are two significant factors that determine whether the receiver will buy the product or not. Furthermore, with joint learning on two parts of interaction data to address data sparsity issue, our proposed TriM-Joint further improves the recommendation performance. By conducting experiments, we show that our proposed models achieve the best results compared to state-of-the-art models with significant improvements by at least $7.4\% \sim 14.4\%$ respectively.},
  archive      = {J_TKDE},
  author       = {Chen Gao and Chao Huang and Donghan Yu and Haohao Fu and Tzh-Heng Lin and Depeng Jin and Yong Li},
  doi          = {10.1109/TKDE.2020.3017509},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2798-2809},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Item recommendation for word-of-mouth scenario in social E-commerce},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IncGraph: An improved distributed incremental graph
computing model and framework based on spark GraphX. <em>TKDE</em>,
<em>34</em>(6), 2783–2797. (<a
href="https://doi.org/10.1109/TKDE.2020.3014150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The excavated information will become obsolete when the data changes in dynamic graphs. To compute the up-to-date results, the graph algorithm has to re-compute the entire data from scratch, which will consume huge computation time and resources. To reduce the cost of such calculations, this paper proposes a model called IncGraph to support incremental iterative computation over dynamic graphs. Different from the way of traditional iteration, IncGraph executes the graph algorithm through reusing the results of the previous graph and performs computation on the part of the graph that has changed. IncGraph has two critical components: (1) an incremental iterative computation model that consists of two steps: an incremental step to calculate the results on the changed vertices of the graph, and a merge step to calculate the results on the entire graph by using the results of the previous graph and the incremental step; and (2) an incremental update method to accelerate the iterative process within the iterative graph algorithm. We implement IncGraph model on GraphX and evaluate its performance by using several representative iterative graph algorithms: PageRank, Connected components, and Single Source Shortest Path. The results show that compared with the traditional iteration, when adding the 100k of vertices in different size data sets, the performance optimization ratio of IncGraph is 31.79 percent averagely, and 50.2 percent maximum; and when the percentage of added vertices varied from 0.01 to 10 percent in different data sets, the performance optimization ratio of IncGraph varied from 19.9 to 66.1 percent. Moreover, the result errors of IncGraph is small and can be neglected.},
  archive      = {J_TKDE},
  author       = {Zhuo Tang and Mengsi He and Zhongming Fu and Li Yang},
  doi          = {10.1109/TKDE.2020.3014150},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2783-2797},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {IncGraph: An improved distributed incremental graph computing model and framework based on spark GraphX},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hypergraph partitioning with embeddings. <em>TKDE</em>,
<em>34</em>(6), 2771–2782. (<a
href="https://doi.org/10.1109/TKDE.2020.3017120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problems in scientific computing, such as distributing large sparse matrix operations, have analogous formulations as hypergraph partitioning problems. A hypergraph is a generalization of a traditional graph wherein “hyperedges” may connect any number of nodes. As a result, hypergraph partitioning is an NP-Hard problem to both solve or approximate. State-of-the-art algorithms that solve this problem follow the multilevel paradigm, which begins by iteratively “coarsening” the input hypergraph to smaller problem instances that share key structural features. Once identifying an approximate problem that is small enough to be solved directly, that solution can be interpolated and refined to the original problem. While this strategy represents an excellent trade off between quality and running time, it is sensitive to coarsening strategy. In this work we propose using graph embeddings of the initial hypergraph in order to ensure that coarsened problem instances retrain key structural features. Our approach prioritizes coarsening within self-similar regions within the input graph, and leads to significantly improved solution quality across a range of considered hypergraphs. Reproducibility: All source code, plots and experimental data are available at https://sybrandt.com/2019/partition .},
  archive      = {J_TKDE},
  author       = {Justin Sybrandt and Ruslan Shaydulin and Ilya Safro},
  doi          = {10.1109/TKDE.2020.3017120},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2771-2782},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hypergraph partitioning with embeddings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-grained urban flow inference. <em>TKDE</em>,
<em>34</em>(6), 2755–2770. (<a
href="https://doi.org/10.1109/TKDE.2020.3017104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatially fine-grained urban flow data is critical for smart city efforts. Though fine-grained information is desirable for applications, it demands much more resources for the underlying storage system compared to coarse-grained data. To bridge the gap between storage efficiency and data utility, in this paper, we aim to infer fine-grained flows throughout a city from their coarse-grained counterparts. This task exhibits two challenges: the spatial correlations between coarse- and fine-grained urban flows, and the complexities of external impacts. To tackle these issues, we develop a model entitled UrbanFM which consists of two major parts: 1) an inference network to generate fine-grained flow distributions from coarse-grained inputs that uses a feature extraction module and a novel distributional upsampling module; 2) a general fusion subnet to further boost the performance by considering the influence of different external factors. This structure provides outstanding effectiveness and efficiency for small scale upsampling. However, the single-pass upsampling used by UrbanFM is insufficient at higher upscaling rates. Therefore, we further present UrbanPy, a cascading model for progressive inference of fine-grained urban flows by decomposing the original tasks into multiple subtasks. Compared to UrbanFM, such an enhanced structure demonstrates favorable performance for larger-scale inference tasks.},
  archive      = {J_TKDE},
  author       = {Kun Ouyang and Yuxuan Liang and Ye Liu and Zekun Tong and Sijie Ruan and Yu Zheng and David S. Rosenblum},
  doi          = {10.1109/TKDE.2020.3017104},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2755-2770},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fine-grained urban flow inference},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast streaming <span
class="math inline"><em>k</em></span>k-means clustering with coreset
caching. <em>TKDE</em>, <em>34</em>(6), 2740–2754. (<a
href="https://doi.org/10.1109/TKDE.2020.3018744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new algorithms for $k$ -means clustering on a data stream with a focus on providing fast responses to clustering queries. Compared to the state-of-the-art, our algorithms provide substantial improvements in the query time for cluster-center queries while retaining the desirable properties of provably small approximation error and low space usage. Our proposed clustering algorithms systematically reuse the “coresets” (summaries of data) computed for recent queries in answering the current clustering query, a novel technique which we refer to as coreset caching. We also present an algorithm called OnlineCC that integrates the coreset caching idea with a simple sequential streaming $k$ -means algorithm. In practice, OnlineCC algorithm can provide constant query time. We present both theoretical analysis and detailed experiments demonstrating the correctness, accuracy, and efficiency of all our proposed clustering algorithms.},
  archive      = {J_TKDE},
  author       = {Yu Zhang and Kanat Tangwongsan and Srikanta Tirthapura},
  doi          = {10.1109/TKDE.2020.3018744},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2740-2754},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast streaming $k$k-means clustering with coreset caching},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient algorithms for kernel aggregation queries.
<em>TKDE</em>, <em>34</em>(6), 2726–2739. (<a
href="https://doi.org/10.1109/TKDE.2020.3018376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel functions support a broad range of applications that require tasks like density estimation, classification, regression or outlier detection. For these tasks, a common online operation is to compute the weighted aggregation of kernel function values with respect to a set of points. However, scalable aggregation methods are still unknown for typical kernel functions (e.g., Gaussian kernel, polynomial kernel, sigmoid kernel and additive kernels) and weighting schemes. In this paper, we propose a novel and effective bounding technique, by leveraging index structures, to speed up the computation of kernel aggregation. In addition, we extend our technique to additive kernel functions, including $\chi ^2$ , intersection, JS and Hellinger kernels, which are widely used in different communities, e.g., computer vision, medical science, Geoscience etc. To handle the additive kernel functions, we further develop the novel and effective bound functions to efficiently evaluate the kernel aggregation. Experimental studies on many real datasets reveal that our proposed solution KARL achieves at least one order of magnitude speedup over the state-of-the-art for different types of kernel functions.},
  archive      = {J_TKDE},
  author       = {Tsz Nam Chan and Leong Hou U and Reynold Cheng and Man Lung Yiu and Shivansh Mittal},
  doi          = {10.1109/TKDE.2020.3018376},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2726-2739},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient algorithms for kernel aggregation queries},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting statistically significant communities.
<em>TKDE</em>, <em>34</em>(6), 2711–2725. (<a
href="https://doi.org/10.1109/TKDE.2020.3015667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a key data analysis problem across different fields. During the past decades, numerous algorithms have been proposed to address this issue. However, most work on community detection does not address the issue of statistical significance. Although some research efforts have been made towards mining statistically significant communities, deriving an analytical solution of $p$ -value for one community under the configuration model is still a challenging mission that remains unsolved. The configuration model is a widely used random graph model in community detection, in which the degree of each node is preserved in the generated random networks. To partially fulfill this void, we present a tight upper bound on the $p$ -value of a single community under the configuration model, which can be used for quantifying the statistical significance of each community analytically. Meanwhile, we present a local search method to detect statistically significant communities in an iterative manner. Experimental results demonstrate that our method is comparable with the competing methods on detecting statistically significant communities.},
  archive      = {J_TKDE},
  author       = {Zengyou He and Hao Liang and Zheng Chen and Can Zhao and Yan Liu},
  doi          = {10.1109/TKDE.2020.3015667},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2711-2725},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Detecting statistically significant communities},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting hierarchical and overlapping network communities
based on opinion dynamics. <em>TKDE</em>, <em>34</em>(6), 2696–2710. (<a
href="https://doi.org/10.1109/TKDE.2020.3014329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is common for communities in real-world networks to possess hierarchical and overlapping structures, which make community detection even more challenging. In this paper, by investigating consensus process of the classical DeGroot model in opinion dynamics, we propose a novel method based on the cumulative opinion distance (COD) to discover hierarchical and overlapping communities. It is shown that this method is different from those classical algorithms relying on static fitness metrics that depict the inhomogeneous connectivity across the network. The proposed method is validated from two aspects. First, by estimating the eigenvectors of adjacency matrices, we investigate the detectability limit of our algorithms on random networks, which together with the results concerning the convergence speed of consensus guarantees the performance of our method theoretically. Second, experiments on both large scale real-world networks and artificial benchmarks show that our method is very effective and competitive on hierarchical modular graphs. In particular, it outperforms the state-of-the-art algorithms on overlapping community detection.},
  archive      = {J_TKDE},
  author       = {Ren Ren and Jinliang Shao and Yuhua Cheng and Xiaofan Wang},
  doi          = {10.1109/TKDE.2020.3014329},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2696-2710},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Detecting hierarchical and overlapping network communities based on opinion dynamics},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning for adverse event detection from web search.
<em>TKDE</em>, <em>34</em>(6), 2681–2695. (<a
href="https://doi.org/10.1109/TKDE.2020.3017786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse event detection is critical for many real-world applications including timely identification of product defects, disasters, and major socio-political incidents. In the health context, adverse drug events account for countless hospitalizations and deaths annually. Since users often begin their information seeking and reporting with online searches, examination of search query logs has emerged as an important detection channel. However, search context - including query intent and heterogeneity in user behaviors – is extremely important for extracting information from search queries, and yet the challenge of measuring and analyzing these aspects has precluded their use in prior studies. We propose DeepSAVE, a novel deep learning framework for detecting adverse events based on user search query logs. DeepSAVE uses an enriched variational autoencoder encompassing a novel query embedding and user modeling module that work in concert to address the context challenge associated with search-based detection of adverse events. Evaluation results on three large real-world event datasets show that DeepSAVE outperforms existing detection methods as well as comparison deep learning auto encoders. Ablation analysis reveals that each component of DeepSAVE significantly contributes to its overall performance. Collectively, the results demonstrate the viability of the proposed architecture for detecting adverse events from search query logs.},
  archive      = {J_TKDE},
  author       = {Faizan Ahmad and Ahmed Abbasi and Brent Kitchens and Donald Adjeroh and Daniel Zeng},
  doi          = {10.1109/TKDE.2020.3017786},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2681-2695},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep learning for adverse event detection from web search},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collaborative list-and-pairwise filtering from implicit
feedback. <em>TKDE</em>, <em>34</em>(6), 2667–2680. (<a
href="https://doi.org/10.1109/TKDE.2020.3016732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implicit feedback based collaborative filtering (CF) has attracted much attention in recent years, mainly because users implicitly express their preferences in many real-world scenarios. The current mainstream pairwise methods optimize the Area Under the Curve (AUC) and are empirically proved to be helpful to exploit binary relevance data, but lead to either not address the ranking problem, or not specifically focus on top- $k$ recommendation. Although there exists the listwise method maximizes the Mean Reciprocal Rank (MRR), it has low efficiency and is not particularly adequate for general implicit feedback situations. To that end, in this paper, we propose a new framework, namely Collaborative List-and-Pairwise Filtering (CLAPF) , which aims to introduce pairwise thinking into listwise methods. Specifically, we smooth another well-known rank-biased measure called Mean Average Precision (MAP), and respectively combine two rank-biased metrics (MAP, MRR) with the pairwise objective function to capture the performance of top- $k$ recommendation. Furthermore, the sampling scheme for CLAPF is discussed to accelerate the convergence speed. Our CLAPF framework is a new hybrid model that provides an idea of utilizing rank-biased measures in a pairwise way on implicit feedback. Empirical studies demonstrated CLAPF outperforms state-of-the-art approaches on real-world datasets.},
  archive      = {J_TKDE},
  author       = {Runlong Yu and Qi Liu and Yuyang Ye and Mingyue Cheng and Enhong Chen and Jianhui Ma},
  doi          = {10.1109/TKDE.2020.3016732},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2667-2680},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Collaborative list-and-pairwise filtering from implicit feedback},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AutoHash: Learning higher-order feature interactions for
deep CTR prediction. <em>TKDE</em>, <em>34</em>(6), 2653–2666. (<a
href="https://doi.org/10.1109/TKDE.2020.3016482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature combinations are essential for the success of many web applications, such as personalised recommendation and online advertising. State-of-the-art methods usually model explicit feature interactions to help neural networks reduce the number of parameters and achieve better performance. However, their explicit feature interactions are often restricted to the second-order due to computational complexity. In this work, we propose efficient ways to represent explicit high-order feature combinations as well as prune redundant features in the mean time. To begin with, we make novel use of the Count Sketch algorithm within a DNN classifier such that high-order feature combinations can be compactly represented. After that, to combat the problem of redundant features which degrade the prediction performance, we introduce an adaptive hashing algorithm, AutoHash, which can automatically select meaningful features to interact at high orders according to the specific dataset in question. This is an AutoML approach. Experiments on three well-known public datasets demonstrate that AutoHash is significantly superior to state-of-the-art methods. Meanwhile, due to its efficient scheme of automatically selecting useful high-order feature interactions, AutoHash has less model complexity and can be trained in an end-to-end manner with less training time than state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Niannan Xue and Bin Liu and Huifeng Guo and Ruiming Tang and Fengwei Zhou and Stefanos Zafeiriou and Yuzhou Zhang and Jun Wang and Zhenguo Li},
  doi          = {10.1109/TKDE.2020.3016482},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2653-2666},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {AutoHash: Learning higher-order feature interactions for deep CTR prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate algorithms for data-driven influence limitation.
<em>TKDE</em>, <em>34</em>(6), 2641–2652. (<a
href="https://doi.org/10.1109/TKDE.2020.3016293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become major battlegrounds for political campaigns, viral marketing, and the dissemination of news. As a consequence, “bad actors” are increasingly exploiting these platforms, which is a key challenge for their administrators, businesses and society in general. The spread of fake news is a classical example of the abuse of social networks by these bad actors. While some have advocated for stricter policies to control the spread of misinformation in social networks, this often happens in detriment of their democratic and organic structure. In this paper, we aim to limit the influence of a target group in a social network via the removal of a few users/links. We formulate the influence limitation problem in a data-driven fashion, by taking into account past propagation traces. More specifically, our algorithms find critical edges to be removed in order to decrease the influence of a target group based on past data. The idea is to control the diffusion processes while minimizing the amount of disturbance in the network structure. Moreover, we consider two types of constraints over edge removals, a budget constraint and also a, more general, set of matroid constraints. These problems lead to interesting challenges in terms of algorithm design. For instance, we are able to show that influence limitation is APX-hard and propose deterministic and probabilistic approximation algorithms for the budgeted and the matroid version of the problem, respectively. Experiments show that the proposed approaches outperform several baselines.},
  archive      = {J_TKDE},
  author       = {Sourav Medya and Arlei Silva and Ambuj Singh},
  doi          = {10.1109/TKDE.2020.3016293},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2641-2652},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Approximate algorithms for data-driven influence limitation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection in quasi-periodic time series based on
automatic data segmentation and attentional LSTM-CNN. <em>TKDE</em>,
<em>34</em>(6), 2626–2640. (<a
href="https://doi.org/10.1109/TKDE.2020.3014806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasi-periodic time series (QTS) exists widely in the real world, and it is important to detect the anomalies of QTS. In this paper, we propose an a utomatic Q TS a nomaly d etection f ramework (AQADF) consisting of a two-level clustering-based QTS segmentation algorithm (TCQSA) and a hybrid attentional LSTM-CNN model (HALCM). TCQSA first automatically splits the QTS into quasi-periods which are then classified by HALCM into normal periods or anomalies. Notably, TCQSA integrates a hierarchical clustering and the k-means technique, making itself highly universal and noise-resistant. HALCM hybridizes LSTM and CNN to simultaneously extract the overall variation trends and local features of QTS for modeling its fluctuation pattern. Furthermore, we embed a trend attention gate (TAG) into the LSTM, a feature attention mechanism (FAM) and a location attention mechanism (LAM) into the CNN to finely tune the extracted variation trends and local features according to their true importance to achieve a better representation of the fluctuation pattern of the QTS. On four public datasets, HALCM exceeds four state-of-the-art baselines and obtains at least 97.3 percent accuracy, TCQSA outperforms two cutting-edge QTS segmentation algorithms and can be applied to different types of QTSs. Additionally, the effectiveness of the attention mechanisms is quantitatively and qualitatively demonstrated.},
  archive      = {J_TKDE},
  author       = {Fan Liu and Xingshe Zhou and Jinli Cao and Zhu Wang and Tianben Wang and Hua Wang and Yanchun Zhang},
  doi          = {10.1109/TKDE.2020.3014806},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2626-2640},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Anomaly detection in quasi-periodic time series based on automatic data segmentation and attentional LSTM-CNN},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An experimental study of state-of-the-art entity alignment
approaches. <em>TKDE</em>, <em>34</em>(6), 2610–2625. (<a
href="https://doi.org/10.1109/TKDE.2020.3018741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) finds equivalent entities that are located in different knowledge graphs (KGs), which is an essential step to enhance the quality of KGs, and hence of significance to downstream applications (e.g., question answering and recommendation). Recent years have witnessed a rapid increase of EA approaches, yet the relative performance of them remains unclear, partly due to the incomplete empirical evaluations, as well as the fact that comparisons were carried out under different settings (i.e., datasets, information used as input, etc.). In this paper, we fill in the gap by conducting a comprehensive evaluation and detailed analysis of state-of-the-art EA approaches. We first propose a general EA framework that encompasses all the current methods, and then group existing methods into three major categories. Next, we judiciously evaluate these solutions on a wide range of use cases, based on their effectiveness, efficiency and robustness. Finally, we construct a new EA dataset to mirror the real-life challenges of alignment, which were largely overlooked by existing literature. This study strives to provide a clear picture of the strengths and weaknesses of current EA approaches, so as to inspire quality follow-up research.},
  archive      = {J_TKDE},
  author       = {Xiang Zhao and Weixin Zeng and Jiuyang Tang and Wei Wang and Fabian M. Suchanek},
  doi          = {10.1109/TKDE.2020.3018741},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2610-2625},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An experimental study of state-of-the-art entity alignment approaches},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive lower-level driven compaction to optimize LSM-tree
key-value stores. <em>TKDE</em>, <em>34</em>(6), 2595–2609. (<a
href="https://doi.org/10.1109/TKDE.2020.3019264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Log-structured merge (LSM) tree key-value (KV) stores have been widely deployed in many NoSQL and SQL systems, serving online big data applications such as social networking, graph processing, machine learning, etc. The batch processing of sorted data merging (i.e., compaction) in LSM-tree key-value stores improves the write efficiency, and some lazy compaction methods have been proposed to accumulate more data within a batch. However, these batched writing methods lead to significant tail latency, which is unacceptable for online processing. Aiming to optimize both latency and throughput, we propose a novel Lower-level Driven Compaction (LDC) method which breaks the limitations of the traditional upper-level driven compaction manner and triggers practical compaction actions bottom-up, with the benefits of both decreasing the compaction granularity for smaller latency and reducing write amplification for higher throughput. Furthermore, we extend LDC to Adaptive LDC (ALDC) by adding an adaptive policy to adjust the key compaction threshold to fit the changes of workloads’ features. The experimental results indicate that ALDC reduces the tail latency significantly and meanwhile achieves a much higher and stable throughput compared with existing approaches.},
  archive      = {J_TKDE},
  author       = {Yunpeng Chai and Yanfeng Chai and Xin Wang and Haocheng Wei and Yangyang Wang},
  doi          = {10.1109/TKDE.2020.3019264},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2595-2609},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive lower-level driven compaction to optimize LSM-tree key-value stores},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on large-scale machine learning. <em>TKDE</em>,
<em>34</em>(6), 2574–2594. (<a
href="https://doi.org/10.1109/TKDE.2020.3015777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning can provide deep insights into data, allowing machines to make high-quality predictions and having been widely used in real-world applications, such as text mining, visual classification, and recommender systems. However, most sophisticated machine learning approaches suffer from huge time costs when operating on large-scale data. This issue calls for the need of Large-scale Machine Learning (LML), which aims to learn patterns from big data with comparable performance efficiently. In this paper, we offer a systematic survey on existing LML methods to provide a blueprint for the future developments of this area. We first divide these LML methods according to the ways of improving the scalability: 1) model simplification on computational complexities, 2) optimization approximation on computational efficiency, and 3) computation parallelism on computational capabilities. Then we categorize the methods in each perspective according to their targeted scenarios and introduce representative methods in line with intrinsic strategies. Lastly, we analyze their limitations and discuss potential directions as well as open issues that are promising to address in the future.},
  archive      = {J_TKDE},
  author       = {Meng Wang and Weijie Fu and Xiangnan He and Shijie Hao and Xindong Wu},
  doi          = {10.1109/TKDE.2020.3015777},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2574-2594},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on large-scale machine learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A review for weighted MinHash algorithms. <em>TKDE</em>,
<em>34</em>(6), 2553–2573. (<a
href="https://doi.org/10.1109/TKDE.2020.3021067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data similarity (or distance) computation is a fundamental research topic which underpins many high-level applications based on similarity measures in machine learning and data mining. However, in large-scale real-world scenarios, the exact similarity computation has become daunting due to “3V” nature (volume, velocity and variety) of big data. In this case, the hashing techniques have been verified to efficiently conduct similarity estimation in terms of both theory and practice. Currently, MinHash is a popular technique for efficiently estimating the Jaccard similarity of binary sets and furthermore, weighted MinHash is generalized to estimate the generalized Jaccard similarity of weighted sets. This review focuses on categorizing and discussing the existing works of weighted MinHash algorithms. In this review, we mainly categorize the weighted MinHash algorithms into quantization-based approaches, “active index”-based ones and others, and show the evolution and inherent connection of the weighted MinHash algorithms, from the integer weighted MinHash ones to the real-valued weighted MinHash ones. Also, we have developed a Python toolbox for the algorithms, and released it in our github. We experimentally conduct a comprehensive study of the standard MinHash algorithm and the weighted MinHash ones in the similarity estimation error and the information retrieval task.},
  archive      = {J_TKDE},
  author       = {Wei Wu and Bin Li and Ling Chen and Junbin Gao and Chengqi Zhang},
  doi          = {10.1109/TKDE.2020.3021067},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2553-2573},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A review for weighted MinHash algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A deep multi-view framework for anomaly detection on
attributed networks. <em>TKDE</em>, <em>34</em>(6), 2539–2552. (<a
href="https://doi.org/10.1109/TKDE.2020.3015098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosion of modeling complex systems using attributed networks boosts the research on anomaly detection in such networks, which can be applied in various high-impact domains. Many existing attempts, however, do not seriously tackle the inherent multi-view property in attribute space but concatenate multiple views into a single feature vector, which inevitably ignores the incompatibility between heterogeneous views caused by their own statistical properties. Actually, the distinct but complementary information brought by multi-view data promises the potential for more effective anomaly detection than the efforts only based on single-view data. Furthermore, the abnormal patterns naturally behave diversely in different views, which coincides with people’s desire to discover specific abnormality according to their preferences for views (attributes). Most existing methods cannot adapt to people’s requirements as they fail to consider the idiosyncrasy of user preferences. Therefore, we propose a multi-view framework Alarm to incorporate user preferences into anomaly detection and simultaneously tackle heterogeneous attribute characteristics through multiple graph encoders and a well-designed aggregator that supports self-learning and user-guided learning. Experiments on synthetic and real-world datasets, e.g., Disney, Books, and Enron, corroborate the improvement of Alarm in detection accuracy evaluated by the AUC metric and its effectiveness in supporting user-oriented anomaly detection.},
  archive      = {J_TKDE},
  author       = {Zhen Peng and Minnan Luo and Jundong Li and Luguo Xue and Qinghua Zheng},
  doi          = {10.1109/TKDE.2020.3015098},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2539-2552},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A deep multi-view framework for anomaly detection on attributed networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A data-characteristic-aware latent factor model for web
services QoS prediction. <em>TKDE</em>, <em>34</em>(6), 2525–2538. (<a
href="https://doi.org/10.1109/TKDE.2020.3014302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to accurately predict unknown quality-of-service (QoS) data based on observed ones is a hot yet thorny issue in Web service-related applications. Recently, a latent factor (LF) model has shown its efficiency in addressing this issue owing to its high accuracy and scalability. An LF model can be improved by identifying user and service neighborhoods based on user and service geographical information. However, such information can be difficult to acquire in most applications with the considerations of information security, identity privacy, and commercial interests in a real system. Besides, the existing LF model-based QoS predictors mostly ignore the reliability of given QoS data where noises commonly exist to cause accuracy loss. To address the above issues, this paper proposes a data-characteristic-aware latent factor (DCALF) model to implement highly accurate QoS predictions, where ‘data-characteristic-aware’ indicates that it can appropriately implement QoS prediction according to the characteristics of given QoS data. Its main idea is two-fold: a) it detects the neighborhoods and noises of users and services based on the dense LFs extracted from the original sparse QoS data, b) it incorporates a density peaks-based clustering method into its modeling process for achieving the simultaneous detections of both neighborhoods and noises of QoS data. With such designs, it precisely represents the given QoS data in spite of their sparsity, thereby achieving highly accurate predictions for unknown ones. Experimental results on two QoS datasets generated by real-world Web services demonstrate that the proposed DCALF model outperforms state-of-the-art QoS predictors, making it highly competitive in addressing the issue of Web service selection and recommendation.},
  archive      = {J_TKDE},
  author       = {Di Wu and Xin Luo and Mingsheng Shang and Yi He and Guoyin Wang and Xindong Wu},
  doi          = {10.1109/TKDE.2020.3014302},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {6},
  pages        = {2525-2538},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A data-characteristic-aware latent factor model for web services QoS prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Where to go next: A spatio-temporal gated network for next
POI recommendation. <em>TKDE</em>, <em>34</em>(5), 2512–2524. (<a
href="https://doi.org/10.1109/TKDE.2020.3007194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Point-of-Interest (POI) recommendation which is of great value to both users and POI holders is a challenging task since complex sequential patterns and rich contexts are contained in extremely sparse user check-in data. Recently proposed embedding techniques have shown promising results in alleviating the data sparsity issue by modeling context information, and Recurrent Neural Network (RNN) has been proved effective in the sequential prediction. However, existing next POI recommendation approaches train the embedding and network model separately, which cannot fully leverage rich contexts. In this paper, we propose a novel unified neural network framework, named NeuNext, which leverages POI context prediction to assist next POI recommendation by joint learning. Specifically, the Spatio-Temporal Gated Network (STGN) is proposed to model personalized sequential patterns for users’ long and short term preferences in the next POI recommendation. In the POI context prediction, rich contexts on POI sides are used to construct graph, and enforce the smoothness among neighboring POIs. Finally, we jointly train the POI context prediction and the next POI recommendation to fully leverage labeled and unlabeled data. Extensive experiments on real-world datasets show that our method outperforms other approaches for next POI recommendation in terms of Accuracy and MAP.},
  archive      = {J_TKDE},
  author       = {Pengpeng Zhao and Anjing Luo and Yanchi Liu and Jiajie Xu and Zhixu Li and Fuzhen Zhuang and Victor S. Sheng and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.3007194},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2512-2524},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Where to go next: A spatio-temporal gated network for next POI recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using survival theory in early pattern detection for viral
cascades. <em>TKDE</em>, <em>34</em>(5), 2497–2511. (<a
href="https://doi.org/10.1109/TKDE.2020.3014203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, social networks have developed rapidly and become an indispensable part of people’s everyday life. Many models try to predict whether some reshare cascades are going to be popular or not, but most of their performances are limited due to the lack of cascades’ information in the early stage. In this paper, we propose Early Pattern detection model for Outbreak Cascades (in abbreviation, EPOC) inspired by the survival theory. We use three features to predict cascades’ virality: retweet sequence, follower number sequence, and timestamps of the first tweet which includes both the static and dynamic characteristics of cascades. Utilizing the theory that distributions of both viral and non-viral cascades are Gaussian, we get the boundary between these two kinds of cascades with sufficient proof to testify its rationality. To detect the virality more precisely and earlier, based on hazard functions in the survival theory, we propose two different hazard ceilings to capture the bursting of the cascades. We also provide a series of numerical experiments to analyze impacts of different factors to performance of our model measured by three practical metrics. The results shows that our model could stably outperforms several state-of-art baselines.},
  archive      = {J_TKDE},
  author       = {Xiaofeng Gao and Xiaosong Jia and Chaoqi Yang and Guihai Chen},
  doi          = {10.1109/TKDE.2020.3014203},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2497-2511},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Using survival theory in early pattern detection for viral cascades},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Topic-guided conversational recommender in multiple domains.
<em>TKDE</em>, <em>34</em>(5), 2485–2496. (<a
href="https://doi.org/10.1109/TKDE.2020.3008563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational systems have recently attracted significant attention. Both the research community and industry believe that it will exert huge impact on human-computer interaction, and specifically, the IR/RecSys community has begun to explore Conversational Recommendation. In real-life scenarios, such systems are often urgently needed in helping users accomplishing different tasks under various situations. However, existing works still face several shortcomings: (1) Most efforts are largely confined in single task setting. They fall short of hands in handling tasks across domains. (2) Aside from soliciting user preference from dialogue history, a conversational recommender naturally has access to the back-end data structure which should be fully leveraged to yield good recommendations. In this paper, we thus present a Topic-guided Conversational Recommender ( TCR ) which is specifically designed for the multi-domain setting. It augments the sequence-to-sequence (seq2seq) models with a neural latent topic component to better guide the response generation. To better leverage the dialogue history and the back-end data structure, we adopt a graph convolutional network (GCN) to model the relationships between different recommendation candidates while also capture the match between candidates and the dialogue history. We then seamlessly combine these two parts with the idea of pointer networks. We perform extensive evaluation on a large-scale task-oriented multi-domain dialogue dataset and the results show that our method achieves superior performance as compared to a wide range of baselines.},
  archive      = {J_TKDE},
  author       = {Lizi Liao and Ryuichi Takanobu and Yunshan Ma and Xun Yang and Minlie Huang and Tat-Seng Chua},
  doi          = {10.1109/TKDE.2020.3008563},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2485-2496},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Topic-guided conversational recommender in multiple domains},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time-aware location prediction by convolutional
area-of-interest modeling and memory-augmented attentive LSTM.
<em>TKDE</em>, <em>34</em>(5), 2472–2484. (<a
href="https://doi.org/10.1109/TKDE.2020.3005735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized location prediction is key to many mobile applications and services. In this paper, motivated by both statistical and visualized preliminary analysis on three real datasets, we observe a strong spatiotemporal correlation for user trajectories among the visited area-of-interests (AoIs) and different time periods on both weekly and daily basis, which directly motivates our time-aware location prediction model design called “ $t$ -LocPred”. It models the spatial correlations among AoIs by coarse-grained convolutional processing of the user trajectories in AoIs of different time periods (“ConvAoI”); and predicts his/her fine-grained next visited PoI using a novel memory-augmented attentive LSTM model (“mem-attLSTM”) to capture long-term behavior patterns. Experimental results show that $t$ -LocPred outperforms 8 baselines. We also show the impact of hyperparameters and the benefits ConvAoI can bring to these baselines.},
  archive      = {J_TKDE},
  author       = {Chi Harold Liu and Yu Wang and Chengzhe Piao and Zipeng Dai and Ye Yuan and Guoren Wang and Dapeng Wu},
  doi          = {10.1109/TKDE.2020.3005735},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2472-2484},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Time-aware location prediction by convolutional area-of-interest modeling and memory-augmented attentive LSTM},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Stream processing of shortest path query in dynamic road
networks. <em>TKDE</em>, <em>34</em>(5), 2458–2471. (<a
href="https://doi.org/10.1109/TKDE.2020.3010005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shortest path query in road network is pervasive in various location-based services nowadays. As the business expands, the scalability issue becomes severer and more servers are deployed to cope with it. Moreover, as the traffic condition keeps changing over time, the existing index-based approaches can hardly adapt to the real-life dynamic environment. Therefore, batch shortest path algorithms have been proposed recently to answer a set of queries together using shareable computation. Besides, they can also work in a highly dynamic environment as no index is needed. However, the existing batch algorithms either assume the batch queries are finely decomposed or just process them without differentiation, resulting in poor query efficiency. In this work, we assume the traffic condition is stable over a short period and treat the issued queries within that period as a stream of query sets. Specifically, we first propose three query set decomposition methods to cluster one query set into multiple query subsets: Zigzag that considers the 1-N shared computation; Co-Clustering that considers the source and target&#39;s spatial locality; and Search-Space-Aware that further incorporates search space estimation. After that, we propose two batch algorithms that take advantage of the previously decomposed query sets for efficient query answering: R2R that finds a set of approximate shortest paths from one region to another with bounded error; and Local Cache that improves the existing Global Cache with higher cache hit ratio. Finally, we design three efficient stream processing methods for intra-batch shared computation. The experiments on a large real-world query sets verify the effectiveness and efficiency of our decomposition methods compared with the state-of-the-art batch algorithms.},
  archive      = {J_TKDE},
  author       = {Mengxuan Zhang and Lei Li and Wen Hua and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.3010005},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2458-2471},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Stream processing of shortest path query in dynamic road networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social attentive deep q-networks for recommender systems.
<em>TKDE</em>, <em>34</em>(5), 2443–2457. (<a
href="https://doi.org/10.1109/TKDE.2020.3012346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems aim to accurately and actively provide users with potentially interesting items (products, information or services). Deep reinforcement learning has been successfully applied to recommender systems, but still heavily suffer from data sparsity and cold-start in real-world tasks. In this work, we propose an effective way to address such issues by leveraging the pervasive social networks among users in the estimation of action-values (Q). Specifically, we develop a Social Attentive Deep Q-network (SADQN) to approximate the optimal action-value function based on the preferences of both individual users and social neighbors, by successfully utilizing a social attention layer to model the influence between them. Further, we propose an enhanced variant of SADQN, termed SADQN++, to model the complicated and diverse trade-offs between personal preferences and social influence for all involved users, making the agent more powerful and flexible in learning the optimal policies. The experimental results on real-world datasets demonstrate that the proposed SADQNs remarkably outperform the state-of-the-art deep reinforcement learning agents, with reasonable computation cost.},
  archive      = {J_TKDE},
  author       = {Yu Lei and Zhitao Wang and Wenjie Li and Hongbin Pei and Quanyu Dai},
  doi          = {10.1109/TKDE.2020.3012346},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2443-2457},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Social attentive deep Q-networks for recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised concept learning by concept-cognitive
learning and concept space. <em>TKDE</em>, <em>34</em>(5), 2429–2442.
(<a href="https://doi.org/10.1109/TKDE.2020.3010918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human concept learning, people can naturally combine a handful of labeled data with abundant unlabeled data when they make classification decisions, which is also known as semi-supervised learning (SSL) in machine learning. Especially, human concept learning not only is a static process in human cognition but also can vary gradually with dynamic environments. Nevertheless, the classical SSL algorithms must be redesigned to accommodate newly input data. In this sense, concept-cognitive learning may be a good choice, as it can implement dynamic processes by imitating human cognitive processes. Meanwhile, numerous SSL methods were designed based on the feature vector information of instances, while ignoring concept structural information that is a very important process in human knowledge organization. Based on this idea, a novel SSL method, named semi-supervised concept learning method (S2CL), is proposed for dynamic SSL by employing concept spaces, in which knowledge is represented by hierarchical concept structures. Moreover, to make full use of the global and local conceptual information, we further propose an extended version of S2CL (namely, $\text{S2CL}^{\alpha }$ ) for concept learning. More specifically, to effectively exploit the unlabeled data, this paper first shows some new related theories for S2CL (or $\text{S2CL}^{\alpha }$ ) based on a regular formal decision context; then a novel SSL framework is designed, and its corresponding algorithm is developed. Finally, we conduct some experiments on various datasets to demonstrate the effectiveness of our methods, which include concept classification and incremental learning under a large quantity of unlabeled data.},
  archive      = {J_TKDE},
  author       = {YunLong Mi and Wenqi Liu and Yong Shi and Jinhai Li},
  doi          = {10.1109/TKDE.2020.3010918},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2429-2442},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Semi-supervised concept learning by concept-cognitive learning and concept space},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic interpretation of top-n recommendations.
<em>TKDE</em>, <em>34</em>(5), 2416–2428. (<a
href="https://doi.org/10.1109/TKDE.2020.3010215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, model-based approaches have shown their effectiveness in computing recommendation lists in different domains and settings. By relying on the computation of latent factors, they can recommend items with a very high level of accuracy. Unfortunately, when moving to the latent space, even if the model embeds content-based information, we miss references to the actual semantics of the recommended item. It makes the interpretation of the recommendation process non-trivial. In this paper, we show how to initialize latent factors in Factorization Machines by using semantic features coming from knowledge graphs to train an interpretable model, which is, in turn, able to provide recommendations with a high level of accuracy. In the presented approach, semantic features are injected into the learning process to retain the original informativeness of the items available in the dataset. By relying on the information encoded in the original knowledge graph, we also propose two metrics to evaluate the semantic accuracy and robustness of knowledge-aware interpretability. An extensive experimental evaluation on six different datasets shows the effectiveness of the interpretable model in terms of both accuracy and diversity of recommendation results and interpretability robustness.},
  archive      = {J_TKDE},
  author       = {Vito Walter Anelli and Tommaso Di Noia and Eugenio Di Sciascio and Azzura Ragone and Joseph Trotta},
  doi          = {10.1109/TKDE.2020.3010215},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2416-2428},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Semantic interpretation of top-N recommendations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Role-based graph embeddings. <em>TKDE</em>, <em>34</em>(5),
2401–2415. (<a href="https://doi.org/10.1109/TKDE.2020.3006475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random walks are at the heart of many existing node embedding and network representation learning methods. However, such methods have many limitations that arise from the use of traditional random walks, e.g., the embeddings resulting from these methods capture proximity (communities) among the vertices as opposed to structural similarity (roles). Furthermore, the embeddings are unable to transfer to new nodes and graphs as they are tied to node identity. To overcome these limitations, we introduce the Role2Vec framework based on the proposed notion of attributed random walks to learn structural role-based embeddings. Notably, the framework serves as a basis for generalizing any walk-based method. The Role2Vec framework enables these methods to be more widely applicable by learning inductive functions that capture the structural roles in the graph. Furthermore, the original methods are recovered as a special case of the framework when each vertex is mapped to its own function that uniquely identifies it. Finally, the Role2Vec framework is shown to be effective with an average AUC improvement of 17.8 percent for link prediction while requiring on average 853x less space than existing methods on a variety of graphs from different domains.},
  archive      = {J_TKDE},
  author       = {Nesreen K. Ahmed and Ryan A. Rossi and John Boaz Lee and Theodore L. Willke and Rong Zhou and Xiangnan Kong and Hoda Eldardiry},
  doi          = {10.1109/TKDE.2020.3006475},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2401-2415},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Role-based graph embeddings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Representation learning with multi-level attention for
activity trajectory similarity computation. <em>TKDE</em>,
<em>34</em>(5), 2387–2400. (<a
href="https://doi.org/10.1109/TKDE.2020.3010022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive trajectory data stem from the prevalence of equipment-supporting GPS and wireless communication technology. Especially, activity trajectory from Location-based Social Network (LBSN) endows traditional trajectory data with additional user semantic activities, e.g., visiting work/home/entertainment places. Measuring the similarity between activity trajectories is to compare their proximity in multiple dimensions such as time, location, and semantics. In this way, we can mine implicit user preference and apply it to route planning, POI recommendation or any other online tasks. The key challenge of comparing activity trajectories (i.e., computing their similarity) lies in two aspects. One is the uneven sampling rate in both time and space. The other is the discrepancy of individual activities. Previous effort alleviates the issue of uneven sampling rate via trajectory complements, which is limited to spatial-temporal information. In this paper, we propose to learn a representation for one activity trajectory by jointly considering the spatio-temporal characteristics and the activity semantics. The similarity of two trajectories is computed by weighting individual trajectory points and contextual features with multi-level attention mechanisms. In specific, we propose a point-level and feature-level attention mechanism to adaptively select critical elements and contextual factors for learning trajectory representation. Our proposed approach, called At2vec, demonstrates better performance than existing baselines in extensive experimental evaluation on real trajectory databases.},
  archive      = {J_TKDE},
  author       = {An Liu and Yifan Zhang and Xiangliang Zhang and Guanfeng Liu and Yanan Zhang and Zhixu Li and Lei Zhao and Qing Li and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.3010022},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2387-2400},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Representation learning with multi-level attention for activity trajectory similarity computation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rapid detection of local communities in graph streams.
<em>TKDE</em>, <em>34</em>(5), 2375–2386. (<a
href="https://doi.org/10.1109/TKDE.2020.3012608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the problem of uncovering communities in complex real-world networks whose elements and their respective associations manifest as streams of data. Community detection is applied in emerging computational environments and concerns critical applications in diverse areas including social computing, web analysis, IoT and biology. Despite the already expended related research efforts, the task of revealing the community structure of massive and rapidly-evolving networks remains very challenging. More specifically, there is an emerging need for online approaches that ingest graph data as a stream. In this paper, we propose a streaming-graph community-detection algorithm that expands seed-sets of nodes to communities. We consider an online setting and process a stream of edges while aiming to form communities on-the-fly using partial knowledge of the graph structure. We use space-efficient structures to maintain very limited information regarding the nodes of the graph and the sought communities, so as to effectively process large scale networks. In addition to our novel streaming approach, we develop a technique that increases the accuracy of our algorithm considerably and additionally propose a new clustering algorithm that allows for automatically deriving the size of the communities we seek to detect. Using ground-truth communities for a wide range of large real-word and synthetic networks, our experimental evaluation shows that our approach does achieve accuracy comparable, and oftentimes better, to the state-of-the-art non-streaming community detection algorithms. More importantly, we attain significant improvements in both execution time and memory requirements.},
  archive      = {J_TKDE},
  author       = {Panagiotis Liakos and Katia Papakonstantinopoulou and Alexandros Ntoulas and Alex Delis},
  doi          = {10.1109/TKDE.2020.3012608},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2375-2386},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Rapid detection of local communities in graph streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting human mobility with semantic motivation via
multi-task attentional recurrent networks. <em>TKDE</em>,
<em>34</em>(5), 2360–2374. (<a
href="https://doi.org/10.1109/TKDE.2020.3006048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human mobility prediction is of great importance for a wide spectrum of location-based applications. However, predicting mobility is not trivial because of four challenges: 1) the complex sequential transition regularities exhibited with time-dependent and high-order nature; 2) the multi-level periodicity of human mobility; 3) the heterogeneity and sparsity of the collected trajectory data; and 4) the complicated semantic motivation behind the mobility. In this paper, we propose DeepMove, an attentional recurrent network for mobility prediction from lengthy and sparse trajectories. In DeepMove, we first design a multi-modal embedding recurrent neural network to capture the complicated sequential transitions by jointly embedding the multiple factors that govern human mobility. Then, we propose a historical attention model with two mechanisms to capture the multi-level periodicity in a principle way, which effectively utilizes the periodicity nature to augment the recurrent neural network for mobility prediction. Furthermore, we design a context adaptor to capture the semantic effects of Point-Of-Interest (POI)-based activity and temporal factor (e.g., dwell time). Finally, we use the multi-task framework to encourage the model to learn comprehensive motivations with mobility by introducing the task of the next activity type prediction and the next check-in time prediction. We perform experiments on four representative real-life mobility datasets, and extensive evaluation results demonstrate that our model outperforms the state-of-the-art models by more than 10 percent. Moreover, compared with the state-of-the-art neural network models, DeepMove provides intuitive explanations into the prediction and sheds light on interpretable mobility prediction.},
  archive      = {J_TKDE},
  author       = {Jie Feng and Yong Li and Zeyu Yang and Qiang Qiu and Depeng Jin},
  doi          = {10.1109/TKDE.2020.3006048},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2360-2374},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Predicting human mobility with semantic motivation via multi-task attentional recurrent networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting citywide crowd flows in irregular regions using
multi-view graph convolutional networks. <em>TKDE</em>, <em>34</em>(5),
2348–2359. (<a href="https://doi.org/10.1109/TKDE.2020.3008774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being able to predict the crowd flows in each and every part of a city, especially in irregular regions , is strategically important for traffic control, risk assessment, and public safety. However, it is very challenging because of interactions and spatial correlations between different regions. In addition, it is affected by many factors: i) multiple temporal correlations among different time intervals: closeness, period, trend; ii) complex external influential factors: weather, events; iii) meta features: time of the day, day of the week, and so on. In this paper, we formulate crowd flow forecasting in irregular regions as a spatio-temporal graph (STG) prediction problem in which each node represents a region with time-varying flows. By extending graph convolution to handle the spatial information, we propose using spatial graph convolution to build a multi-view graph convolutional network (MVGCN) for the crowd flow forecasting problem, where different views can capture different factors as mentioned above. We evaluate MVGCN using four real-world datasets (taxicabs and bikes) and extensive experimental results show that our approach outperforms the adaptations of state-of-the-art methods. And we have developed a crowd flow forecasting system for irregular regions that can now be used internally.},
  archive      = {J_TKDE},
  author       = {Junkai Sun and Junbo Zhang and Qiaofei Li and Xiuwen Yi and Yuxuan Liang and Yu Zheng},
  doi          = {10.1109/TKDE.2020.3008774},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2348-2359},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Predicting citywide crowd flows in irregular regions using multi-view graph convolutional networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Multi-scale dynamic convolutional network for knowledge
graph embedding. <em>TKDE</em>, <em>34</em>(5), 2335–2347. (<a
href="https://doi.org/10.1109/TKDE.2020.3005952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs are large graph-structured knowledge bases with incomplete or partial information. Numerous studies have focused on knowledge graph embedding to identify the embedded representation of entities and relations, thereby predicting missing relations between entities. Previous embedding models primarily regard (subject entity, relation, and object entity) triplet as translational distance or semantic matching in vector space. However, these models only learn a few expressive features and hard to handle complex relations, i.e., 1-to-N, N-to-1, and N-to-N, in knowledge graphs. To overcome these issues, we introduce a multi-scale dynamic convolutional network (M-DCN) model for knowledge graph embedding. This model features topnotch performance and an ability to generate richer and more expressive feature embeddings than its counterparts. The subject entity and relation embeddings in M-DCN are composed in an alternating pattern in the input layer, which helps extract additional feature interactions and increase the expressiveness. Multi-scale filters are generated in the convolution layer to learn different characteristics among input embeddings. Specifically, the weights of these filters are dynamically related to each relation to model complex relations. The performance of M-DCN on the five benchmark datasets is tested via experiments. Results show that the model can effectively handle complex relations and achieve state-of-the-art link prediction results on most evaluation metrics.},
  archive      = {J_TKDE},
  author       = {Zhaoli Zhang and Zhifei Li and Hai Liu and Neal N. Xiong},
  doi          = {10.1109/TKDE.2020.3005952},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2335-2347},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-scale dynamic convolutional network for knowledge graph embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Minority sub-region estimation-based oversampling for
imbalance learning. <em>TKDE</em>, <em>34</em>(5), 2324–2334. (<a
href="https://doi.org/10.1109/TKDE.2020.3010013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance problem that characterized with the skew distribution towards the majority arises as one challenge in recent years. Many oversampling techniques have been proposed to cope with this problem and some of them combine the oversampling procedure with the clustering algorithm which guaranteeing new synthetic samples being generated in clusters. However far-away samples but with the same minority sub-region are generally clustered into different groups owing to the characteristic of clustering algorithm itself. Therefore, the following oversampling procedure is mostly carried in incomplete minority sub-regions that synthetic samples not well cover the integral minority region. And to our best knowledge, none of existing algorithm is designed to directly estimate minority sub-regions for class imbalance problem. Thus, one new grouping algorithm, named Direction Distribution-based Minority Sub-region Estimation (DDMSE), is first proposed. The new algorithm exploits the intuitive observation, that the minority with the same sub-region almost distribute within the same direction when compared to other majority, to estimate minority sub-regions that tactfully ignoring negative impacts brought by the distance factor like in clustering algorithms. Finally, new synthetic samples are generated in those minority sub-regions. And experimental results on real-world datasets show the comparable performance with other state-of-the-art oversampling methods.},
  archive      = {J_TKDE},
  author       = {Yi Sun and Lijun Cai and Bo Liao and Wen Zhu},
  doi          = {10.1109/TKDE.2020.3010013},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2324-2334},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Minority sub-region estimation-based oversampling for imbalance learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAS-encryption and its applications in privacy-preserving
classifiers. <em>TKDE</em>, <em>34</em>(5), 2306–2323. (<a
href="https://doi.org/10.1109/TKDE.2020.3009221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homomorphic encryption (HE) schemes, such as fully homomorphic encryption (FHE), support a number of useful computations on ciphertext in a broad range of applications, such as e-voting, private information retrieval, cloud security, and privacy protection. While FHE schemes do not require any interaction during computation, the key limitations are large ciphertext expansion and inefficiency. Thus, to overcome these limitations, we develop a novel cryptographic tool, MAS-Encryption (MASE), to support real-value input and secure computation on the multiply-add structure. The multiply-add structures exist in many important protocols, such as classifiers and outsourced protocols, and we will explain how MASE can be used to protect the privacy of these protocols, using two case study examples. Specifically, the first case study example is the privacy-preserving Naive Bayes classifier that can achieve minimal Bayes risk, and the other example is the privacy-preserving support vector machine. We prove that the constructed classifiers are secure and evaluate their performance using real-world datasets. Experiments show that our proposed MASE scheme and MASE based classifiers are efficient, in the sense that we achieve an optimal tradeoff between computation efficiency and communication interactions. Thus, we avoid the inefficiency of FHE based paradigm.},
  archive      = {J_TKDE},
  author       = {Chong-zhi Gao and Jin Li and Shibing Xia and Kim-Kwang Raymond Choo and Wenjing Lou and Changyu Dong},
  doi          = {10.1109/TKDE.2020.3009221},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2306-2323},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MAS-encryption and its applications in privacy-preserving classifiers},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Many-class few-shot learning on multi-granularity class
hierarchy. <em>TKDE</em>, <em>34</em>(5), 2293–2305. (<a
href="https://doi.org/10.1109/TKDE.2020.3004939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study many-class few-shot (MCFS) problem in both supervised learning and meta-learning settings. Compared to the well-studied many-class many-shot and few-class few-shot problems, the MCFS problem commonly occurs in practical applications but has been rarely studied in previous literature. It brings new challenges of distinguishing between many classes given only a few training samples per class. In this article, we leverage the class hierarchy as a prior knowledge to train a coarse-to-fine classifier that can produce accurate predictions for MCFS problem in both settings. The propose model, “memory-augmented hierarchical-classification network (MahiNet)”, performs coarse-to-fine classification where each coarse class can cover multiple fine classes. Since it is challenging to directly distinguish a variety of fine classes given few-shot data per class, MahiNet starts from learning a classifier over coarse-classes with more training data whose labels are much cheaper to obtain. The coarse classifier reduces the searching range over the fine classes and thus alleviates the challenges from “many classes”. On architecture, MahiNet first deploys a convolutional neural network (CNN) to extract features. It then integrates a memory-augmented attention module and a multi-layer perceptron (MLP) together to produce the probabilities over coarse and fine classes. While the MLP extends the linear classifier, the attention module extends the KNN classifier, both together targeting the “few-shot” problem. We design several training strategies of MahiNet for supervised learning and meta-learning. In addition, we propose two novel benchmark datasets “ mcfs ImageNet” (as a subset of ImageNet) and “ mcfs Omniglot” (re-splitted Omniglot) specially designed for MCFS problem. In experiments, we show that MahiNet outperforms several state-of-the-art models (e.g., prototypical networks and relation networks) on MCFS problems in both supervised learning and meta-learning.},
  archive      = {J_TKDE},
  author       = {Lu Liu and Tianyi Zhou and Guodong Long and Jing Jiang and Chengqi Zhang},
  doi          = {10.1109/TKDE.2020.3004939},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2293-2305},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Many-class few-shot learning on multi-granularity class hierarchy},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to delay in ride-sourcing systems: A multi-agent
deep reinforcement learning framework. <em>TKDE</em>, <em>34</em>(5),
2280–2292. (<a href="https://doi.org/10.1109/TKDE.2020.3006084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ride-sourcing services are now reshaping the way people travel by effectively connecting drivers and passengers through mobile internets. Online matching between idle drivers and waiting passengers is one of the most key components in a ride-sourcing system. The average pickup distance or time is an important measurement of system efficiency since it affects both passengers’ waiting time and drivers’ utilization rate. It is naturally expected that a more effective bipartite matching (with smaller average pickup time) can be implemented if the platform accumulates more idle drivers and waiting passengers in the matching pool. A specific passenger request can also benefit from a delayed matching since he/she may be matched with closer idle drivers after waiting for a few seconds. Motivated by the potential benefits of delayed matching, this paper establishes a two-stage framework which incorporates a combinatorial optimization and multi-agent deep reinforcement learning methods. The multi-agent reinforcement learning methods are used to dynamically determine the delayed time for each passenger request (or the time at which each request enters the matching pool), while the combinatorial optimization conducts an optimal bipartite matching between idle drivers and waiting passengers in the matching pool. Four tailored reinforcement learning methods, delayed multi-agent deep Q learning (Delayed-M-DQN), delayed multi-agent actor-critic (Delayed-M-A2C), delayed multi-agent Proximal Policy Optimization (Delayed-M-PPO), and delayed multi-agent actor-critic with experience replay (Delayed-M-ACER), are developed. Through extensive empirical experiments with a well-designed simulator, we show that the proposed framework is able to remarkably improve system performances, by well balancing the trade-off among pick-up time, matching time, successful matching rate.},
  archive      = {J_TKDE},
  author       = {Jintao Ke and Feng Xiao and Hai Yang and Jieping Ye},
  doi          = {10.1109/TKDE.2020.3006084},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2280-2292},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning to delay in ride-sourcing systems: A multi-agent deep reinforcement learning framework},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning deep graph representations via convolutional neural
networks. <em>TKDE</em>, <em>34</em>(5), 2268–2279. (<a
href="https://doi.org/10.1109/TKDE.2020.3014089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-structured data arise in many scenarios. A fundamental problem is to quantify the similarities of graphs for tasks such as classification. R-convolution graph kernels are positive-semidefinite functions that decompose graphs into substructures and compare them. One problem in the effective implementation of this idea is that the substructures are not independent, which leads to high-dimensional feature space. In addition, graph kernels cannot capture the high-order complex interactions between vertices. To mitigate these two problems, we propose a framework called DeepMap to learn deep representations for graph feature maps. The learned deep representation for a graph is a dense and low-dimensional vector that captures complex high-order interactions in a vertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to arbitrary graphs by generating aligned vertex sequences and building the receptive field for each vertex. We empirically validate DeepMap on various graph classification benchmarks and demonstrate that it achieves state-of-the-art performance.},
  archive      = {J_TKDE},
  author       = {Wei Ye and Omid Askarisichani and Alex Jones and Ambuj Singh},
  doi          = {10.1109/TKDE.2020.3014089},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2268-2279},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning deep graph representations via convolutional neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KGGen: A generative approach for incipient knowledge graph
population. <em>TKDE</em>, <em>34</em>(5), 2254–2267. (<a
href="https://doi.org/10.1109/TKDE.2020.3014166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph is becoming an indispensable resource that offers structured information for numerous AI applications. However, the knowledge graph often suffers from its incompleteness. Building a complete, high-quality knowledge graph is time-consuming and requires significant human annotation efforts. In this paper, we study the Knowledge Graph Population task, which aims at extending the scale of structured knowledge, with a special focus on reducing data preparation and annotation efforts. Previous works mainly based on discriminative methods build classifiers and verify candidate triplets that are extracted from texts, which heavily rely on the quality of data collection and co-occurrance of entities in the text. However, such methods fail to generalize on entity pairs that are not highly co-occurred, and fail to discover entity pairs that are not co-occurred at all in the given text corpus. We introduce a generative perspective to approach this task and define each relationship by learning the data distribution that embodies the core common properties for relational reasoning. A generative model KGGen is proposed, which samples from the learned data distribution for each relation and can generate triplets regardless of entity pair co-occurrence in the text corpus. To further improve the generation quality while alleviate human annotation efforts, adversarial learning is adopted to not only encourage generating high quality triplets, but also give model the ability to automatically assess the generation quality. Quantitative and qualitative experimental results conducted on two real-world generic knowledge graphs show that the proposed model KGGen generates novel and meaningful triplets with improved efficiency and less human annotation comparing with the state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Hao Chen and Chenwei Zhang and Jun Li and Philip S. Yu and Ning Jing},
  doi          = {10.1109/TKDE.2020.3014166},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2254-2267},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {KGGen: A generative approach for incipient knowledge graph population},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Karst: Transactional data ingestion without blocking on a
scalable architecture. <em>TKDE</em>, <em>34</em>(5), 2241–2253. (<a
href="https://doi.org/10.1109/TKDE.2020.3011510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although real-time analytics on the up-to-date dataset has become an emerging demand, many big data systems are still designed for offline analytics. Particularly, for critical applications like Fintech, transactional data ingestion ensures a timely, always-correct, and scalable dataset. To carry out append-only ingestion, existing OLTP/HTAP systems are based on strict transactions with imperfect scalability, while NoSQL-like systems support scalable but relaxed transactions. How to ensure essential transactional guarantees without harming scalability seems to be a non-trivial issue. This paper proposes Karst to bring transactional data ingestion for existing offline analytics. We notice that blocking two-phase commit (2PC) to resolve transactional data ingestion is a performance killer for the partitioned analytical systems. Karst introduces a scalable protocol called metadata-oriented commit (MOC) that converts each distributed transaction into multiple partial transactions to avoid 2PC. Moreover, to ingest massive data into plenty of partitions, Karst also employs lazy persistence, lightweight logging, and optimized data traffic. In experiments, Karst could achieve up to about 2x $\sim$ 10x performance over relevant systems and also shows remarkable scalability.},
  archive      = {J_TKDE},
  author       = {Zhifang Li and Beicheng Peng and Qiuli Huang and Chuliang Weng},
  doi          = {10.1109/TKDE.2020.3011510},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2241-2253},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Karst: Transactional data ingestion without blocking on a scalable architecture},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretation of structural preservation in low-dimensional
embeddings. <em>TKDE</em>, <em>34</em>(5), 2227–2240. (<a
href="https://doi.org/10.1109/TKDE.2020.3005878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite being commonly used in big-data analytics; the outcome of dimensionality reduction remains a black-box to most of its users. Understanding the quality of a low-dimensional embedding is important as not only it enables trust in the transformed data, but it can also help to select the most appropriate dimensionality reduction algorithm in a given scenario. As existing research primarily focuses on the visual exploration of embeddings, there is still a need for enhancing interpretability of such algorithms. To bridge this gap, we propose two novel interactive explanation techniques for low-dimensional embeddings obtained from any dimensionality reduction algorithm. The first technique LAPS produces a local approximation of the neighborhood structure to generate interpretable explanations on the preserved locality for a single instance. The second method GAPS explains the retained global structure of a high-dimensional dataset in its embedding, by combining non-redundant local-approximations from a coarse discretization of the projection space. We demonstrate the applicability of the proposed techniques using 16 real-life tabular, text, image, and audio datasets. Our extensive experimental evaluation shows the utility of the proposed techniques in interpreting the quality of low-dimensional embeddings, as well as with selecting the most suitable dimensionality reduction algorithm for any given dataset.},
  archive      = {J_TKDE},
  author       = {Aindrila Ghosh and Mona Nashaat and James Miller and Shaikh Quader},
  doi          = {10.1109/TKDE.2020.3005878},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2227-2240},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Interpretation of structural preservation in low-dimensional embeddings},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Index-based solutions for efficient density peak clustering.
<em>TKDE</em>, <em>34</em>(5), 2212–2226. (<a
href="https://doi.org/10.1109/TKDE.2020.3004221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density Peak Clustering (DPC), a popular density-based clustering approach, has received considerable attention from the research community primarily due to its simplicity and fewer-parameter requirement. However, the resultant clusters obtained using DPC are influenced by the sensitive parameter $d_c$ , which depends on data distribution and requirements of different users. Besides, the original DPC algorithm requires visiting a large number of objects, making it slow. To this end, this paper investigates index-based solutions for DPC. Specifically, we propose two list-based index methods viz. (i) a simple List Index, and (ii) an advanced Cumulative Histogram Index. Efficient query algorithms are proposed for these indices which significantly avoids irrelevant comparisons at the cost of space. For memory-constrained systems, we further introduce an approximate solution to the above indices which allows substantial reduction in the space cost, provided that slight inaccuracies are admissible. Furthermore, owing to considerably lower memory requirements of existing tree-based index structures, we also present effective pruning techniques and efficient query algorithms to support DPC using the popular Quadtree Index and R-tree Index. Finally, we practically evaluate all the above indices and present the findings and results, obtained from a set of extensive experiments on six synthetic and real datasets. The experimental insights obtained can help to guide in selecting a befitting index.},
  archive      = {J_TKDE},
  author       = {Zafaryab Rasool and Rui Zhou and Lu Chen and Chengfei Liu and Jiajie Xu},
  doi          = {10.1109/TKDE.2020.3004221},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2212-2226},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Index-based solutions for efficient density peak clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph matching via the lens of supermodularity.
<em>TKDE</em>, <em>34</em>(5), 2200–2211. (<a
href="https://doi.org/10.1109/TKDE.2020.3008128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph matching, the problem of aligning a pair of graphs so as to minimize their edge disagreements, has received widespread attention owing to its broad spectrum of applications in data science. As the problem is NP–hard in the worst-case, a variety of approximation algorithms have been proposed for obtaining high quality, suboptimal solutions. In this article, we approach the task of designing an efficient polynomial-time approximation algorithm for graph matching from a previously unconsidered perspective. Our key result is that graph matching can be formulated as maximizing a monotone, supermodular set function subject to matroid intersection constraints. We leverage this fact to apply a discrete optimization variant of the minorization-maximization algorithm which exploits supermodularity of the objective function to iteratively construct and maximize a sequence of global lower bounds on the objective. At each step, we solve a maximum weight matching problem in a bipartite graph. Differing from prior approaches, the algorithm exploits the combinatorial structure inherent in the problem to generate a sequence of iterates featuring monotonically non-decreasing objective value while always adhering to the combinatorial matching constraints. Experiments on real-world data demonstrate the empirical effectiveness of the algorithm relative to the prevailing state-of-the-art.},
  archive      = {J_TKDE},
  author       = {Aritra Konar and Nicholas D. Sidiropoulos},
  doi          = {10.1109/TKDE.2020.3008128},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2200-2211},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph matching via the lens of supermodularity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature and nuclear norm minimization for matrix completion.
<em>TKDE</em>, <em>34</em>(5), 2190–2199. (<a
href="https://doi.org/10.1109/TKDE.2020.3005978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix completion, whose goal is to recover a matrix from a few entries observed, is a fundamental model behind many applications. Our study shows that, in many applications, the to-be-complete matrix can be represented as the sum of a low-rank matrix and a sparse matrix associating with side information matrices. The low-rank matrix depicts the global patterns while the sparse matrix characterizes the local patterns, which are often described by the side information. Accordingly, to achieve high-quality matrix completion, we propose a Feature and Nuclear Norm Minimization (FNNM) model. The rationale of FNNM is to employ transductive completion to generalize the global pattern and inductive completion to recover the local pattern. Alternative minimization algorithm based on fixed-point iteration is developed to numerically solve the FNNM model. FNNM has demonstrated promising results on a variety of applications, including movie recommendation, drug-target interaction prediction, and multi-label learning, consistently outperforming the state-of-the-art matrix completion algorithms.},
  archive      = {J_TKDE},
  author       = {Mengyun Yang and Yaohang Li and Jianxin Wang},
  doi          = {10.1109/TKDE.2020.3005978},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2190-2199},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Feature and nuclear norm minimization for matrix completion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting data skew for improved query performance.
<em>TKDE</em>, <em>34</em>(5), 2176–2189. (<a
href="https://doi.org/10.1109/TKDE.2020.3006446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analytic queries enable sophisticated large-scale data analysis within many commercial, scientific and medical domains today. Data skew is a ubiquitous feature of these real-world domains. In a retail database, some products are typically much more popular than others. In a text database, word frequencies follow a Zipf distribution with a small number of very common words, and a long tail of infrequent words. In a geographic database, some regions have much higher populations (and therefore data measurements) than others. Current systems do not make the most of caches for exploiting skew. In particular, a whole cache line may remain cache resident even though only a small part of the cache line corresponds to a popular data item. In this article, we propose a novel index structure for repositioning data items to concentrate popular items into the same cache lines. The net result is better spatial locality, and better utilization of limited cache resources. We develop a theoretical model for analyzing the cache utilization, and implement database operators that are efficient in the presence of skew. Our experimental evaluation on real and synthetic data shows that exploiting skew can significantly improve in-memory query performance. In some cases, our techniques can speed up queries by over an order of magnitude.},
  archive      = {J_TKDE},
  author       = {Wangda Zhang and Kenneth A. Ross},
  doi          = {10.1109/TKDE.2020.3006446},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2176-2189},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Exploiting data skew for improved query performance},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entropy-based subjective choice models. <em>TKDE</em>,
<em>34</em>(5), 2164–2175. (<a
href="https://doi.org/10.1109/TKDE.2020.3012061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method to mimic a decision-maker’s (DM’s) relativistic evaluation of subjective utility for an attribute value is presented. Based on such utility values, probabilistic models that can yield a DM’s choice probabilities for different alternatives to be chosen are developed. The proposed choice models are further extended to consider the DM’s attitudinal character. An illustrative case-study is included.},
  archive      = {J_TKDE},
  author       = {Manish Aggarwal},
  doi          = {10.1109/TKDE.2020.3012061},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2164-2175},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Entropy-based subjective choice models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Embedded transaction support inside SSD with small-capacity
non-volatile disk cache. <em>TKDE</em>, <em>34</em>(5), 2148–2163. (<a
href="https://doi.org/10.1109/TKDE.2020.3004518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flash-based Solid State Drives (SSDs) have proved to be ideal devices that support embedded transaction protocols inside SSDs. Existing embedded transaction protocols in SSDs effectively improve transaction throughput, but still incur high transaction overhead and long recovery time. While it is reasonable to provide a small-capacity non-volatile (NVM-based) disk cache in the SSDs, in this paper, we propose a new embedded transaction protocol called Non-volatile Cache Transaction (NVCTX). NVCTX reduces transaction overhead and provides fast recovery by leveraging the small-capacity NVM-based disk cache from two aspects. First, we store transactional metadata, which is of small amount but is frequently accessed, in the NVM-based disk cache rather than in the flash memory. Second, we introduce two techniques, i.e., a dynamic allocation algorithm and a hybrid storing method, to improve the performance when the capacity of the NVM-based disk cache is very limited. We have implemented NVCTX on a real hardware board called Cosmos+ FPGA platform, and modified ext4 file system and NVMe (Non-Volatile Memory express) driver to be compatible with the transactional interfaces provided by NVCTX. For comparison, we also implement SCC, BPCC, WAL, and X-FTL protocols in the firmware of Cosmos+ FPGA platform. Evaluations using DBMS (Database Management System) and file system workloads show that, compared to four typical transaction protocols (SCC, BPCC, WAL, and X-FTL), NVCTX improves transaction throughput by up to 136.5, 9.4, 131.6 and 29.9 percent, reduces write traffic to flash memory by up to 42.8, 4.1, 62.4, 31.2 percent, lowers garbage collection overhead by up to 93.2, 63, 66.5, 22.1 percent, and shortens recovery time to 1/2574, 1/2559, 1/95 and 1/2 respectively compared with SCC, BPCC, WAL, and X-FTL.},
  archive      = {J_TKDE},
  author       = {Yanjie Tan and Huailiang Tan and Peng Zhu and Youyou Lu and Zaihong He},
  doi          = {10.1109/TKDE.2020.3004518},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2148-2163},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Embedded transaction support inside SSD with small-capacity non-volatile disk cache},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient processing of group planning queries over
spatial-social networks. <em>TKDE</em>, <em>34</em>(5), 2135–2147. (<a
href="https://doi.org/10.1109/TKDE.2020.3004153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, location-based social networks, that involve both social and spatial information, have received much attention in many real-world applications such as location-based services (LBS), map utilities, business planning, and so on. In this paper, we seamlessly integrate both social networks and spatial road networks, resulting in a so-called spatial-social network , and study an important and novel query type, named group planning query over spatial-social networks (GP-SSN), which is very useful for applications such as trip recommendations. In particular, a GP-SSN query retrieves a group of friends with common interests on social networks and a number of spatially close points of interest (POIs) on spatial road networks that best match group’s preferences and have the smallest traveling distances to the group. In order to tackle the GP-SSN problem, we design effective pruning methods, matching score pruning, user pruning, and distance pruning, to rule out false alarms of GP-SSN query answers and reduce the problem search space. We also propose effective indexing mechanisms to facilitate the GP-SSN query processing, and develop efficient GP-SSN query answering algorithms via index traversals. Extensive experiments have been conducted to evaluate the efficiency and effectiveness of our proposed GP-SSN query processing approaches.},
  archive      = {J_TKDE},
  author       = {Ahmed Al-Baghdadi and Gokarna Sharma and Xiang Lian},
  doi          = {10.1109/TKDE.2020.3004153},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2135-2147},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient processing of group planning queries over spatial-social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-driven variable decomposition for treatment effect
estimation. <em>TKDE</em>, <em>34</em>(5), 2120–2134. (<a
href="https://doi.org/10.1109/TKDE.2020.3006898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal Inference plays an important role in decision making in many fields, such as social marketing, healthcare, and public policy. One fundamental problem in causal inference is the treatment effect estimation in observational studies when variables are confounded. Controlling for confounding effects is generally handled by propensity score. But it treats all observed variables as confounders and ignores the adjustment variables, which have no influence on treatment but are predictive of the outcome. Recently, it has been demonstrated that the adjustment variables are effective in reducing the variance of the estimated treatment effect. However, how to automatically separate the confounders and adjustment variables in observational studies is still an open problem, especially in the scenarios of high dimensional variables, which are common in the big data era. In this paper, we first propose a Data-Driven Variable Decomposition (D $^2$ VD) algorithm, which can 1) automatically separate confounders and adjustment variables with a data-driven approach, and 2) simultaneously estimate treatment effect in observational studies with high dimensional variables. Under standard assumptions, we theoretically prove that our D $^2$ VD algorithm can unbiased estimate treatment effect and achieve lower variance than traditional propensity score based methods. Moreover, to address the challenges from high-dimensional variables and nonlinear, we extend our D $^2$ VD to a non-linear version, namely Nonlinear-D $^2$ VD (N-D $^2$ VD) algorithm. To validate the effectiveness of our proposed algorithms, we conduct extensive experiments on both synthetic and real-world datasets. The experimental results demonstrate that our D $^2$ VD and N-D $^2$ VD algorithms can automatically separate the variables precisely, and estimate treatment effect more accurately and with tighter confidence intervals than the state-of-the-art methods. We also demonstrated that the top-ranked features by our algorithm have the best prediction performance on an online advertising dataset.},
  archive      = {J_TKDE},
  author       = {Kun Kuang and Peng Cui and Hao Zou and Bo Li and Jianrong Tao and Fei Wu and Shiqiang Yang},
  doi          = {10.1109/TKDE.2020.3006898},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2120-2134},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Data-driven variable decomposition for treatment effect estimation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data representation by joint hypergraph embedding and sparse
coding. <em>TKDE</em>, <em>34</em>(5), 2106–2119. (<a
href="https://doi.org/10.1109/TKDE.2020.3009488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF), a popular unsupervised learning technique for data representation, has been widely applied in data mining and machine learning. According to different application scenarios, one can impose different constraints on the factorization to find the desired basis, which captures high-level semantics for the given data, and learns the compact representation corresponding to the basis. We note that almost all previous work on MF in data mining has ignored to find such a basis, which can carry high-order semantics in the data. In this article, we propose a novel MF framework called Joint Hypergraph Embedding and Sparse Coding (JHESC), in which the obtained basis captures high-order semantic information in data. Specifically, we first propose a new hypergraph learning model to obtain a more discriminative basis by hypergraph-based Laplacian Eigenmap, then sparse coding is conducted on the learned basis such that the new representation has stronger identification capability. In addition, we extend the proposed method to the reproducing kernel Hilbert space for dealing with nonlinear data more effectively. Extensive experimental results on data clustering demonstrate that the proposed method consistently outperforms the other state-of-the-art matrix factorization methods.},
  archive      = {J_TKDE},
  author       = {Guo Zhong and Chi-Man Pun},
  doi          = {10.1109/TKDE.2020.3009488},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2106-2119},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Data representation by joint hypergraph embedding and sparse coding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CMAL: Cost-effective multi-label active learning by querying
subexamples. <em>TKDE</em>, <em>34</em>(5), 2091–2105. (<a
href="https://doi.org/10.1109/TKDE.2020.3003899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label active learning (MAL) aims to learn an accurate multi-label classifier by selecting which examples (or example-label pairs) will be annotated and reducing query effort. MAL is a more complicated and expensive process than single-label active learning, due to one example can be associated with a set of non-exclusive labels and the annotator has to scrutinize the whole example and label space to provide correct annotations. Instead of scrutinizing the whole example for annotation, we may just examine some of its subexamples with respect to a label for annotation. In this way, we can not only save the annotation cost but also speedup the annotation process. Given this observation, we introduce CMAL, a two-stage Cost-effective MAL strategy (CMAL) by querying subexamples. CMAL first selects the most informative example-label pairs by leveraging uncertainty, label correlation and label space sparsity. Specifically, the uncertainty of a label to an example can be reduced if its correlated labels already annotated to the example, and its uncertainty can be reduced also if more examples annotated to this label. Next, CMAL greedily queries the most probable positive subexample-label pairs of the selected example-label pair. In addition, we propose rCMAL to account for the representative of examples to more reliably select example-label pairs in the first stage. Extensive experiments on multi-label datasets from diverse domains show that our proposed CMAL and rCMAL can better save the query cost than state-of-the-art MAL methods. The contribution of leveraging label correlation, label sparsity, and representative for saving cost is also confirmed.},
  archive      = {J_TKDE},
  author       = {Guoxian Yu and Xia Chen and Carlotta Domeniconi and Jun Wang and Zhao Li and Zili Zhang and Xiangliang Zhang},
  doi          = {10.1109/TKDE.2020.3003899},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2091-2105},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CMAL: Cost-effective multi-label active learning by querying subexamples},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive hierarchical attention-enhanced gated network
integrating reviews for item recommendation. <em>TKDE</em>,
<em>34</em>(5), 2076–2090. (<a
href="https://doi.org/10.1109/TKDE.2020.3010949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies focusing on integrating reviews with ratings to improve recommendation performance have been quite successful. However, these works still face several shortcomings: (1) The importance of dynamically integrating review and interaction data features is typically ignored, yet treating these fusion features equally may lead to an incomplete understanding of user preferences. (2) Some forms of soft attention methods are adopted to model the local semantic information of words. As features thus captured may contain irrelevant information, the generated attention map is neither discriminatory nor detailed. In this paper, we propose a novel A daptive H ierarchical A ttention-enhanced G ated network integrating reviews for item recommendation , named AHAG. AHAG is a unified framework to capture the hidden intentions of users by adaptively incorporating reviews. Specifically, we design a gated network to dynamically fuse the extracted features and select the features that are most relevant to user preferences. To capture distinguishing fine-grained features, we introduce a hierarchical attention mechanism to learn important semantic information features and the dynamic interaction of these features. Besides, the high-order non-linear interaction of neural factorization machines is utilized to derive the rating prediction. Experiments on seven real-world datasets show that the proposed AHAG significantly outperforms state-of-the-art methods. Furthermore, the attention mechanism can highlight the relevant information in reviews to increase the interpretability of the recommendation task. Source codes are available in https://github.com/luojia527/AHAG .},
  archive      = {J_TKDE},
  author       = {Donghua Liu and Jia Wu and Jing Li and Bo Du and Jun Chang and Xuefei Li},
  doi          = {10.1109/TKDE.2020.3010949},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2076-2090},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive hierarchical attention-enhanced gated network integrating reviews for item recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A method for geodesic distance on subdivision of trees with
arbitrary orders and their applications. <em>TKDE</em>, <em>34</em>(5),
2063–2075. (<a href="https://doi.org/10.1109/TKDE.2020.3014191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geodesic distance, sometimes called shortest path length, has proven useful in a great variety of applications, such as information retrieval on networks including treelike networked models. Here, our goal is to analytically determine the exact solutions to geodesic distances on two different families of growth trees which are recursively created upon an arbitrary tree $\mathcal {T}$ using two types of well-known operations, first-order subdivision and ( $1,m$ )-star-fractal operation. Different from commonly-used methods, for instance, spectral techniques, for addressing such a problem on growth trees using a single edge as seed in the literature, we propose a novel method for deriving closed-form solutions on the presented trees completely. Meanwhile, our technique is more general and convenient to implement compared to those previous methods mainly because there are not complicated calculations needed. In addition, the closed-form expression of mean first-passage time ( $MFPT$ ) for random walk on each member in tree families is also readily obtained according to connection of our obtained results to effective resistance of corresponding electric networks. The results suggest that the two topological operations above are sharply different from each other due to $MFPT$ for random walks, and, however, have likely to show the similar performance, at least, on geodesic distance.},
  archive      = {J_TKDE},
  author       = {Fei Ma and Ping Wang and Xudong Luo},
  doi          = {10.1109/TKDE.2020.3014191},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2063-2075},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A method for geodesic distance on subdivision of trees with arbitrary orders and their applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid data cleaning framework using markov logic
networks. <em>TKDE</em>, <em>34</em>(5), 2048–2062. (<a
href="https://doi.org/10.1109/TKDE.2020.3012472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of dirty data, data cleaning turns into a crux of data analysis. The accuracy limitation of the existing integrity constraints-based cleaning approaches results from insufficient rules. In this paper, we present a novel hybrid data cleaning framework on top of Markov logic networks (MLNs), termed as ${\sf MLNClean}$ , which is capable of learning instantiated rules to supplement the insufficient integrity constraints. ${\sf MLNClean}$ consists of two steps, i.e., pre-processing and two-stage data cleaning . In the pre-processing step, ${\sf MLNClean}$ first infers a set of probable instantiated rules according to MLNs and then builds a two-layer MLN index structure to generate multiple data versions and facilitate the cleaning process. In the two-stage data cleaning step, ${\sf MLNClean}$ first presents a concept of reliability score to clean errors within each data version separately, and afterward eliminates the conflict values among different data version using a novel concept of fusion score . Considerable experimental results on both real and synthetic scenarios demonstrate the effectiveness of ${\sf MLNClean}$ in practice.},
  archive      = {J_TKDE},
  author       = {Congcong Ge and Yunjun Gao and Xiaoye Miao and Bin Yao and Haobo Wang},
  doi          = {10.1109/TKDE.2020.3012472},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2048-2062},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A hybrid data cleaning framework using markov logic networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A graph neural network framework for social recommendations.
<em>TKDE</em>, <em>34</em>(5), 2033–2047. (<a
href="https://doi.org/10.1109/TKDE.2020.3008732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data in many real-world applications such as social networks, users shopping behaviors, and inter-item relationships can be represented as graphs. Graph Neural Networks (GNNs) have shown great success in learning meaningful representations for graphs by inherently integrating node information and topological structure. Data in social recommendations can also be denotes as graph data in the form of user-user social graphs and user-item graphs. In addition, the relationships between items can be denoted as item-item graphs. GNNs provide an unprecedented opportunity to advance social recommendations. However, there are tremendous challenges in building GNNs-based social recommendations where (1) users (items) are simultaneously involved in the user-item graph and user-user social graph (item-item graph); (2) user-item graphs not only contain user-item interactions but also include users’ opinions on items; and (3) the nature of social relations are heterogeneous among users. In this paper, we propose a novel graph neural network framework ( GraphRec+ ) for social recommendations, which is able to coherently model graph data in order to learn better user and item representations. Specifically, we introduce a principled approach for jointly capturing interactions and opinions in the user-item graph and also propose an attention mechanism to differentiate the heterogeneous strengths of social relations. Comprehensive experiments on three real-world datasets show the effectiveness of the proposed framework.},
  archive      = {J_TKDE},
  author       = {Wenqi Fan and Yao Ma and Qing Li and Jianping Wang and Guoyong Cai and Jiliang Tang and Dawei Yin},
  doi          = {10.1109/TKDE.2020.3008732},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2033-2047},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A graph neural network framework for social recommendations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A collective approach to scholar name disambiguation.
<em>TKDE</em>, <em>34</em>(5), 2020–2032. (<a
href="https://doi.org/10.1109/TKDE.2020.3011674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scholar name disambiguation remains a hard and unsolved problem, which brings various troubles for bibliography data analytics. Most existing methods handle name disambiguation separately that tackles one name at a time, and neglect the fact that disambiguation of one name affects the others. Further, it is typically common that only limited information is available for bibliography data, e.g., only basic paper and citation information is available in DBLP. In this study, we propose a collective approach to name disambiguation, which takes the connection of different ambiguous names into consideration. We reformulate bibliography data as a heterogeneous multipartite network, which initially treats each author reference as a unique author entity, and disambiguation results of one name propagate to the others of the network. To further deal with the sparsity problem caused by limited available information, we also introduce word-word and venue-venue similarities, and we finally measure author similarities by assembling similarities from four perspectives. Using real-life data, we experimentally demonstrate that our approach is both effective and efficient.},
  archive      = {J_TKDE},
  author       = {Dongsheng Luo and Shuai Ma and Yaowei Yan and Chunming Hu and Xiang Zhang and Jinpeng Huai},
  doi          = {10.1109/TKDE.2020.3011674},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {5},
  pages        = {2020-2032},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A collective approach to scholar name disambiguation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised large graph embedding based on balanced and
hierarchical k-means. <em>TKDE</em>, <em>34</em>(4), 2008–2019. (<a
href="https://doi.org/10.1109/TKDE.2020.3000226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many successful spectral based unsupervised dimensionality reduction methods, including Laplacian Eigenmap (LE), Locality Preserving Projection (LPP), Spectral Regression (SR), etc. We find that LPP and SR are equivalent if the symmetric similarity matrix is doubly stochastic, Positive Semi-Definite (PSD) and with rank $p$ , where $p$ is the reduced dimension. Since solving SR is believed faster than solving LPP based on some related literature, the discovery promotes us to seek to construct such specific similarity matrix to speed up LPP solving procedures. We then propose an unsupervised linear method called Unsupervised Large Graph Embedding (ULGE). ULGE starts with a similar idea as LPP but adopts an efficient approach to construct anchor-based similarity matrix and then performs spectral analysis on it. Moreover, since conventional anchor generation strategies suffer kinds of problems, we propose an efficient and effective anchor generation strategy, called Balanced $K$ -means based Hierarchical $K$ -means (BHKH). The computational complexity of ULGE can reduce to $O(ndm)$ , which is a significant improvement compared to conventional methods need $O(n^2d)$ at least, where $n$ , $d$ and $m$ are the number of samples, dimensions, and anchors, respectively. Extensive experiments on several publicly available datasets demonstrate the efficiency and effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Feiping Nie and Wei Zhu and Xuelong Li},
  doi          = {10.1109/TKDE.2020.3000226},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {2008-2019},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unsupervised large graph embedding based on balanced and hierarchical K-means},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Target-aware holistic influence maximization in spatial
social networks. <em>TKDE</em>, <em>34</em>(4), 1993–2007. (<a
href="https://doi.org/10.1109/TKDE.2020.3003047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization has recently received significant attention for scheduling online campaigns or advertisements on social network platforms. However, most studies only focus on user influence via cyber interactions while ignoring their physical interactions which are also essential to gauge influence propagation. Additionally, targeted campaigns or advertisements have not received sufficient attention. To address these issues, we first devise a novel holistic influence diffusion model that takes into account both cyber and physical user interactions in an effective and practical way. Based on the new diffusion model, we formulate a new problem of holistic influence maximization , denoted as HIM query, for targeted advertisements in a spatial social network. The HIM query problem aims to find a minimum set of users whose holistic influence can cover all target users in the network, which belongs to a set covering problem. Since the HIM query problem is NP-hard, we develop a greedy baseline algorithm and then improve on this algorithm to reduce the computational cost. To deal with large networks, we also design a spatial-social index to maintain the social, spatial and textual information of users, as well as developing an index-based efficient solution. Finally, we conduct extensive experiments using one synthetic and three real-world datasets to validate the efficiency and effectiveness of the proposed holistic influence diffusion model and our developed algorithms.},
  archive      = {J_TKDE},
  author       = {Taotao Cai and Jianxin Li and Ajmal Mian and Rong-Hua Li and Timos Sellis and Jeffrey Xu Yu},
  doi          = {10.1109/TKDE.2020.3003047},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1993-2007},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Target-aware holistic influence maximization in spatial social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SCHAIN-IRAM: An efficient and effective semi-supervised
clustering algorithm for attributed heterogeneous information networks.
<em>TKDE</em>, <em>34</em>(4), 1980–1992. (<a
href="https://doi.org/10.1109/TKDE.2020.2997938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A heterogeneous information network (HIN) is one whose nodes model objects of different types and whose links model objects’ relationships. To enrich its information, objects in an HIN are typically associated with additional attributes. We call such an HIN an Attributed HIN or AHIN. We study the problem of clustering objects in an AHIN, taking into account objects’ similarities with respect to both object attribute values and their structural connectedness in the network. We show how supervision signal, expressed in the form of a must-link set and a cannot-link set , can be leveraged to improve clustering results. We put forward the SCHAIN algorithm to solve the clustering problem, and two highly efficient variants, SCHAIN-PI and SCHAIN-IRAM, which employ the power iteration based method and the implicitly restarted Arnoldi method respectively to compute eigenvectors of a matrix. We conduct extensive experiments comparing SCHAIN-based algorithms with other state-of-the-art clustering algorithms. Our results show that SCHAIN-IRAM outperforms other competitors in terms of clustering effectiveness and is highly efficient.},
  archive      = {J_TKDE},
  author       = {Xiang Li and Yao Wu and Martin Ester and Ben Kao and Xin Wang and Yudian Zheng},
  doi          = {10.1109/TKDE.2020.2997938},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1980-1992},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SCHAIN-IRAM: An efficient and effective semi-supervised clustering algorithm for attributed heterogeneous information networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Privacy-preserving feature extraction via adversarial
training. <em>TKDE</em>, <em>34</em>(4), 1967–1979. (<a
href="https://doi.org/10.1109/TKDE.2020.2997604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is increasingly popular, partly due to its widespread application potential, such as in civilian, government and military domains. Given the exacting computational requirements, cloud computing has been utilized to host user data and model. However, such an approach has potential privacy implications. Therefore, in this paper, we propose a method to protect user’s privacy in the inference phase of deep learning workflow. Specifically, we use an intermediate layer to separate the entire neural network into two parts, which are respectively deployed on the user device and the cloud server. The encoder , deployed on the user device, is used for raw data transformation, which removes the need for users to upload raw data to the cloud directly. However, we also demonstrate there exists potential for privacy leakage in the intermediate features of the neural network through two concrete experiments. In other words, the encoder on its own does not provide adequate privacy protection. Therefore, we also propose an approach to achieve Privacy-preserving Feature Extraction based on Adversarial Training (P-FEAT) , where the goal of privacy attacking tasks and the goal of target tasks are adversarial in terms of sensitive attributes. By imposing privacy constraints during the feature extraction, we can reduce the contribution of the extracted features to the privacy leakage. In this way, privacy protection capability of the encoder can be further strengthened. We then demonstrate the effectiveness of P-FEAT using a large number of experiments, whose findings show that P-FEAT can significantly reduce the threats of privacy attacking tasks while maintaining high accuracy of the target tasks.},
  archive      = {J_TKDE},
  author       = {Xiaofeng Ding and Hongbiao Fang and Zhilin Zhang and Kim-Kwang Raymond Choo and Hai Jin},
  doi          = {10.1109/TKDE.2020.2997604},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1967-1979},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Privacy-preserving feature extraction via adversarial training},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PPD: A scalable and efficient parallel primal-dual
coordinate descent algorithm. <em>TKDE</em>, <em>34</em>(4), 1958–1966.
(<a href="https://doi.org/10.1109/TKDE.2020.3000905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dual Coordinate Descent (DCD) is one of the most popular optimization methods. The parallelization of DCD is difficult, as DCD is sequential in nature. As such, simultaneously running multiple DCD threads on batches of data elements causes result inaccuracy and slow convergence, due to the concurrent updates of multiple coordinates. Some parallelization methods adopt separable approximate functions that depend on the degree of parallelism. Such dependencies result in both poor scalability and slow-convergence. To address these challenges, in this paper we present a new parallel primal-dual algorithm for DCD, called PPD. In PPD, the block data distribution is utilized to obtain a new approximate function that is independent from the parallelism. Moreover, PPD is designed with a novel primal-dual acceleration scheme to approach the optimal solution closely and quickly. We demonstrate the advantages of PPD in terms of scalability and efficiency through experiments.},
  archive      = {J_TKDE},
  author       = {Hejun Wu and Xinchuan Huang and Qiong Luo and Zhongheng Yang},
  doi          = {10.1109/TKDE.2020.3000905},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1958-1966},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PPD: A scalable and efficient parallel primal-dual coordinate descent algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalized long- and short-term preference learning for
next POI recommendation. <em>TKDE</em>, <em>34</em>(4), 1944–1957. (<a
href="https://doi.org/10.1109/TKDE.2020.3002531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next POI recommendation has been studied extensively in recent years. The goal is to recommend next POI for users at specific time given users’ historical check-in data. Therefore, it is crucial to model both users’ general taste and recent sequential behaviors. Moreover, different users show different dependencies on the two parts. However, most existing methods learn the same dependencies for different users. Besides, the locations and categories of POIs contain different information about users’ preference. However, current researchers always treat them as the same factors or believe that categories determine where to go. To this end, we propose a novel method named Personalized Long- and Short-term Preference Learning (PLSPL) to learn the specific preference for each user. Specially, we combine the long- and short-term preference via user-based linear combination unit to learn the personalized weights on different parts for different users. Besides, the context information such as the category and check-in time is also essential to capture users’ preference. Therefore, in long-term module, we consider the contextual features of POIs in users’ history records and leverage attention mechanism to capture users’ preference. In the short-term module, to better learn the different influences of locations and categories of POIs, we train two LSTM models for location- and category-based sequence, respectively. Then we evaluate the proposed model on two real-world datasets. The experiment results demonstrate that our method outperforms the state-of-art approaches for next POI recommendation.},
  archive      = {J_TKDE},
  author       = {Yuxia Wu and Ke Li and Guoshuai Zhao and Xueming Qian},
  doi          = {10.1109/TKDE.2020.3002531},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1944-1957},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Personalized long- and short-term preference learning for next POI recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online pricing with reserve price constraint for personal
data markets. <em>TKDE</em>, <em>34</em>(4), 1928–1943. (<a
href="https://doi.org/10.1109/TKDE.2020.3000262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The society’s insatiable appetites for personal data are driving the emergence of data markets, allowing data consumers to launch customized queries over the datasets collected by a data broker from data owners. In this paper, we study how the data broker can maximize its cumulative revenue by posting reasonable prices for sequential queries. We thus propose a contextual dynamic pricing mechanism with the reserve price constraint, which features the properties of ellipsoid for efficient online optimization and can support linear and non-linear market value models with uncertainty. In particular, under low uncertainty, the proposed pricing mechanism attains a worst-case cumulative regret logarithmic in the number of queries. We further extend our approach to support other similar application scenarios, including hospitality service and online advertising, and extensively evaluate all three use cases over MovieLens 20M dataset, Airbnb listings in U.S. major cities, and Avazu mobile ad click dataset, respectively. The analysis and evaluation results reveal that: (1) our pricing mechanism incurs low practical regret, while the latency and memory overhead incurred is low enough for online applications; and (2) the existence of reserve price can mitigate the cold-start problem in a posted price mechanism, thereby reducing the cumulative regret.},
  archive      = {J_TKDE},
  author       = {Chaoyue Niu and Zhenzhe Zheng and Fan Wu and Shaojie Tang and Guihai Chen},
  doi          = {10.1109/TKDE.2020.3000262},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1928-1943},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Online pricing with reserve price constraint for personal data markets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi task mutual learning for joint sentiment
classification and topic detection. <em>TKDE</em>, <em>34</em>(4),
1915–1927. (<a href="https://doi.org/10.1109/TKDE.2020.2999489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, advances in neural network approaches have achieved many successes in both sentiment classification and probabilistic topic modeling. On the one hand, latent topics derived from the global context of documents could be helpful in capturing more accurate word semantics and hence could potentially improve the sentiment classification accuracy. On the other hand, the word-level attention vectors obtained during the learning of sentiment classifiers could carry word-level polarity information and can be used to guide the discovery of topics in topic modeling. This paper proposes a multi-task learning framework which jointly learns a sentiment classifier and a topic model by making the word-level latent topic distributions in the topic model to be similar to the word-level attention vectors in sentiment classifiers through mutual learning. Experimental results on the Yelp and IMDB datasets verify the superior performance of the proposed framework over strong baselines on both sentiment classification and topic modeling. The proposed framework also extracts more interpretable topics compared to other conventional topic models and neural topic models.},
  archive      = {J_TKDE},
  author       = {Lin Gui and Jia Leng and Jiyun Zhou and Ruifeng Xu and Yulan He},
  doi          = {10.1109/TKDE.2020.2999489},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1915-1927},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi task mutual learning for joint sentiment classification and topic detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling spatial trajectories with attribute representation
learning. <em>TKDE</em>, <em>34</em>(4), 1902–1914. (<a
href="https://doi.org/10.1109/TKDE.2020.3001025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of positioning devices has given rise to many trajectories, with each having three explicit attributes: user ID , location ID , and time-stamp and an implicit attribute: activity type (akin to “topic” in text mining). To model these trajectories, existing works learn different attribute representations by either introducing latent activity types based on topic models or transforming the location and time context into a low-dimensional space via embedding techniques. In this paper, we propose a holistic approach named Human Mobility Representation Model (HMRM) to simultaneously produce the vector representations of all four (explicit and implicit) attributes. The merits of HMRM lie in that: (1) it models the latent activity types and learns trajectory attribute embeddings in an integrated manner, and (2) it connects the activity-related distributions and these attributes embeddings by adding a newly designed collaborative learning component, and makes them mutually exchanged to take the best of both worlds. We apply HMRM to both unsupervised and supervised tasks including two activity evaluation tasks and two embedding evaluation tasks, on two real check-in datasets collected from Foursquare. Experimental results show that HMRM could not only improve the performance of capturing latent activity types, but also learn better trajectory embeddings.},
  archive      = {J_TKDE},
  author       = {Meng Chen and Yan Zhao and Yang Liu and Xiaohui Yu and Kai Zheng},
  doi          = {10.1109/TKDE.2020.3001025},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1902-1914},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Modeling spatial trajectories with attribute representation learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Missing value imputation via clusterwise linear regression.
<em>TKDE</em>, <em>34</em>(4), 1889–1901. (<a
href="https://doi.org/10.1109/TKDE.2020.3001694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a new method of preprocessing incomplete data is introduced. The method is based on clusterwise linear regression and it combines two well-known approaches for missing value imputation: linear regression and clustering. The idea is to approximate missing values using only those data points that are somewhat similar to the incomplete data point. A similar idea is used also in clustering based imputation methods. Nevertheless, here the linear regression approach is used within each cluster to accurately predict the missing values, and this is done simultaneously to clustering. The proposed method is tested using some synthetic and real-world data sets and compared with other algorithms for missing value imputations. Numerical results demonstrate that this method produces the most accurate imputations in MCAR and MAR data sets with a clear structure and the percentages of missing data no more than 25 percent.},
  archive      = {J_TKDE},
  author       = {Napsu Karmitsa and Sona Taheri and Adil Bagirov and Pauliina Mäkinen},
  doi          = {10.1109/TKDE.2020.3001694},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1889-1901},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Missing value imputation via clusterwise linear regression},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring fitness and precision of automatically discovered
process models: A principled and scalable approach. <em>TKDE</em>,
<em>34</em>(4), 1870–1888. (<a
href="https://doi.org/10.1109/TKDE.2020.3003258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated process discovery techniques allow us to generate a process model from an event log consisting of a collection of business process execution traces. The quality of process models generated by these techniques can be assessed with respect to several criteria, including fitness , which captures the degree to which the generated process model is able to recognize the traces in the event log, and precision , which captures the extent to which the behavior allowed by the process model is observed in the event log. A range of fitness and precision measures have been proposed in the literature. However, existing measures in this field do not fulfil basic monotonicity properties and/or they suffer from scalability issues when applied to models discovered from real-life event logs. This article presents a family of fitness and precision measures based on the idea of comparing the $k$ th order Markovian abstraction of a process model against that of an event log. The article shows that this family of measures fulfils the aforementioned properties for suitably chosen values of $k$ . An empirical evaluation shows that representative exemplars of this family of measures yield intuitive results on a synthetic dataset of model-log pairs, while outperforming existing measures of fitness and precision in terms of execution times on real-life event logs.},
  archive      = {J_TKDE},
  author       = {Adriano Augusto and Abel Armas-Cervantes and Raffaele Conforti and Marlon Dumas and Marcello La Rosa},
  doi          = {10.1109/TKDE.2020.3003258},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1870-1888},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Measuring fitness and precision of automatically discovered process models: A principled and scalable approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Magnitude bounded matrix factorisation for recommender
systems. <em>TKDE</em>, <em>34</em>(4), 1856–1869. (<a
href="https://doi.org/10.1109/TKDE.2020.2998218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low rank matrix factorisation is often used in recommender systems as a way of extracting latent features. When dealing with large and sparse datasets, traditional recommendation algorithms face the problem of acquiring large, unrestrained, fluctuating values over predictions. Imposing bounding constraints has been proven an effective solution. However, existing bounding algorithms can only deal with one pair of fixed bounds, and are very time-consuming when applied on large-scale datasets. In this paper, we propose a novel algorithm named Magnitude Bounded Matrix Factorisation (MBMF), which allows different bounds for individual users/items and performs very quickly on large scale datasets. The key idea of our algorithm is to construct a model by constraining the magnitudes of each individual user/item feature vector. By converting coordinate system with radii set as the corresponding magnitudes, MBMF allows the above constrained optimisation problem to become an unconstrained one, which can be solved by unconstrained optimisation algorithms such as the stochastic gradient descent. We also explore an acceleration approach and the choice of magnitudes are given in detail as well. Experiments on synthetic and real datasets demonstrate that in most cases the proposed MBMF is superior over all existing algorithms in terms of accuracy and time complexity.},
  archive      = {J_TKDE},
  author       = {Shuai Jiang and Kan Li and Richard Yi Da Xu},
  doi          = {10.1109/TKDE.2020.2998218},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1856-1869},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Magnitude bounded matrix factorisation for recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LBSN2Vec++: Heterogeneous hypergraph embedding for
location-based social networks. <em>TKDE</em>, <em>34</em>(4),
1843–1855. (<a href="https://doi.org/10.1109/TKDE.2020.2997869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-Based Social Networks (LBSNs) have been widely used as a primary data source for studying the impact of mobility and social relationships on each other. Traditional approaches manually define features to characterize users’ mobility homophily and social proximity, and show that mobility and social features can help friendship and location prediction tasks, respectively. However, these hand-crafted features not only require tedious human efforts, but also are difficult to generalize. Against this background, we propose in this paper LBSN2Vec++, a heterogeneous hypergraph embedding approach designed specifically for LBSN data for automatic feature learning. Specifically, LBSN data intrinsically forms a heterogeneous hypergraph including both user-user homogeneous edges (friendships) and user-time-POI-semantic heterogeneous hyperedges (check-ins). Based on this hypergraph, we first propose a random-walk-with-stay scheme to jointly sample user check-ins and social relationships, and then learn node embeddings from the sampled (hyper)edges by not only preserving the $n$ -wise node proximity captured by the hyperedges, but also considering embedding space transformation between node domains to fully grasp the complex structural characteristics of the LBSN heterogeneous hypergraph. Using real-world LBSN datasets collected in six cities all over the world, our extensive evaluation shows that LBSN2Vec++ significantly and consistently outperforms both state-of-the-art graph embedding techniques by up to 68 percent and the best-performing hand-crafted features in the literature by up to 70.14 percent on friendship and location prediction tasks.},
  archive      = {J_TKDE},
  author       = {Dingqi Yang and Bingqing Qu and Jie Yang and Philippe Cudré-Mauroux},
  doi          = {10.1109/TKDE.2020.2997869},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1843-1855},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LBSN2Vec++: Heterogeneous hypergraph embedding for location-based social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large scale network embedding: A separable approach.
<em>TKDE</em>, <em>34</em>(4), 1829–1842. (<a
href="https://doi.org/10.1109/TKDE.2020.3002700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many successful methods have been proposed for learning low-dimensional representations on large-scale networks, while almost all existing methods are designed in inseparable processes, learning embeddings for entire networks even when only a small proportion of nodes are of interest. This leads to great inconvenience, especially on large-scale or dynamic networks, where these methods become almost impossible to implement. In this paper, we formalize the problem of separated matrix factorization, based on which we elaborate a novel objective function that preserves both local and global information. We compare our SMF framework with approximate SVD algorithms and demonstrate SMF can capture more information when factorizing a given matrix. We further propose SepNE, a simple and flexible network embedding algorithm which independently learns representations for different subsets of nodes in separated processes. By implementing separability, our algorithm reduces the redundant efforts to embed irrelevant nodes, yielding scalability to large networks. To further incorporate complex information into SepNE, we discuss several methods that can be used to leverage high-order proximities in large networks. We demonstrate the effectiveness of SepNE on several real-world networks with different scales and subjects. With comparable accuracy, our approach significantly outperforms state-of-the-art baselines in running times on large networks.},
  archive      = {J_TKDE},
  author       = {Guojie Song and Liang Zhang and Ziyao Li and Yi Li},
  doi          = {10.1109/TKDE.2020.3002700},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1829-1842},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Large scale network embedding: A separable approach},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving i/o complexity of triangle enumeration.
<em>TKDE</em>, <em>34</em>(4), 1815–1828. (<a
href="https://doi.org/10.1109/TKDE.2020.3003259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, many graph algorithms are now required to operate in external memory and deliver performance that does not significantly degrade with the scale of the problem. One particular area that frequently deals with graphs larger than RAM is triangle listing , where the algorithms must carefully piece together edges from multiple partitions to detect cycles. In recent literature, two competing proposals (i.e., Pagh and PCF) have emerged; however, neither one is universally better than the other. Since little is known about the I/O cost of PCF or how these methods compare to each other, we undertake an investigation into the properties of these algorithms, model their I/O cost, understand their shortcomings, and shed light on the conditions under which each method defeats the other. This insight leads us to develop a novel framework we call Trigon that surpasses the I/O performance of both previous techniques in all graphs and under all RAM conditions.},
  archive      = {J_TKDE},
  author       = {Yi Cui and Di Xiao and Daren B. H. Cline and Dmitri Loguinov},
  doi          = {10.1109/TKDE.2020.3003259},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1815-1828},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Improving I/O complexity of triangle enumeration},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gradual machine learning for entity resolution.
<em>TKDE</em>, <em>34</em>(4), 1803–1814. (<a
href="https://doi.org/10.1109/TKDE.2020.3006142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Usually considered as a classification problem, entity resolution (ER) can be very challenging on real data due to the prevalence of dirty values. The state-of-the-art solutions for ER were built on a variety of learning models (most notably deep neural networks), which require lots of accurately labeled training data. Unfortunately, high-quality labeled data usually require expensive manual work, and are therefore not readily available in many real scenarios. In this paper, we propose a novel learning paradigm for ER, called gradual machine learning , which aims to enable effective machine labeling without the requirement for manual labeling effort. It begins with some easy instances in a task, which can be automatically labeled by the machine with high accuracy, and then gradually labels more challenging instances by iterative factor graph inference. In gradual machine learning, the hard instances in a task are gradually labeled in small stages based on the estimated evidential certainty provided by the labeled easier instances. Our extensive experiments on real data have shown that the performance of the proposed approach is considerably better than its unsupervised alternatives, and highly competitive compared to the state-of-the-art supervised techniques. Using ER as a test case, we demonstrate that gradual machine learning is a promising paradigm potentially applicable to other challenging classification tasks requiring extensive labeling effort.},
  archive      = {J_TKDE},
  author       = {Boyi Hou and Qun Chen and Yanyan Wang and Youcef Nafa and Zhanhuai Li},
  doi          = {10.1109/TKDE.2020.3006142},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1803-1814},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Gradual machine learning for entity resolution},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GFocus: User focus-based graph query autocompletion.
<em>TKDE</em>, <em>34</em>(4), 1788–1802. (<a
href="https://doi.org/10.1109/TKDE.2020.3002934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph query autocompletion ( gQAC ) generates a small list of ranked query suggestions during the graph query formulation process in a visual environment. The current state-of-the-art of gQAC provides suggestions that are formed by adding subgraph increments to arbitrary places of an existing (partial) user query. However, according to the research results on human-computer interaction (HCI), humans can only interact with a small number of recent software artifacts in hand. Hence, many of such suggestions could be irrelevant. In this paper, we present the GFocus framework that exploits a novel notion of user focus of graph query formulation (or simply focus ). Intuitively, the focus is the subgraph that a user is working on. We formulate locality principles inspired by the HCI research to automatically identify and maintain the focus. We propose novel monotone submodular ranking functions for generating popular and comprehensive query suggestions only at the focus. In particular, the query suggestions of GFocus have high result counts (when they are used as queries) and maximally cover the possible suggestions at the focus. We propose efficient algorithms and an index for ranking the suggestions. Our results show that GFocus saves 12-32 percent more mouse clicks and is 35× more efficient than the state-of-the-art competitor.},
  archive      = {J_TKDE},
  author       = {Peipei Yi and Byron Choi and Zhiwei Zhang and Sourav S Bhowmick and Jianliang Xu},
  doi          = {10.1109/TKDE.2020.3002934},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1788-1802},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GFocus: User focus-based graph query autocompletion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). From anticipation to action: Data reveal mobile shopping
patterns during a yearly mega sale event in china. <em>TKDE</em>,
<em>34</em>(4), 1775–1787. (<a
href="https://doi.org/10.1109/TKDE.2020.3001558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online retail market shows a sharp increase in traffic during holiday sales. The ability to distinguish customers who will likely purchase is critical for provisioning traffic and for providing cost-effective promotions. This paper uniquely studies the browsing and purchasing behaviors of online shoppers during a yearly sale event in China, the world’s largest online marketplace. Based on 31 million action logs gathered from wide residential areas, we characterize the steps leading to purchases and determine their precursors. We investigate the effect of time (e.g., date, time of date), environment (e.g., platform, viewed category), and action (e.g., session time, clicks, sequence) on purchases. Action cues from shopping behaviors can be used for early detection. While most shoppers start with strong intentions to purchase, yet the moment of ordering comes rather impulsively within 30 seconds to several minutes of browsing. The predictive accuracy reaches as a high AUC of 0.924. The findings in this paper provide an understanding of traffic during mega sale events that can help online shops plan and provide a better user experience for upcoming shopping festivals.},
  archive      = {J_TKDE},
  author       = {Muzhi Guan and Meeyoung Cha and Yue Wang and Yong Li and Jingbo Sun},
  doi          = {10.1109/TKDE.2020.3001558},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1775-1787},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {From anticipation to action: Data reveal mobile shopping patterns during a yearly mega sale event in china},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fairness in semi-supervised learning: Unlabeled data help to
reduce discrimination. <em>TKDE</em>, <em>34</em>(4), 1763–1774. (<a
href="https://doi.org/10.1109/TKDE.2020.3002567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing specter in the rise of machine learning is whether the decisions made by machine learning models are fair. While research is already underway to formalize a machine-learning concept of fairness and to design frameworks for building fair models with sacrifice in accuracy, most are geared toward either supervised or unsupervised learning. Yet two observations inspired us to wonder whether semi-supervised learning might be useful to solve discrimination problems. First, previous study showed that increasing the size of the training set may lead to a better trade-off between fairness and accuracy. Second, the most powerful models today require an enormous of data to train which, in practical terms, is likely possible from a combination of labeled and unlabeled data. Hence, in this paper, we present a framework of fair semi-supervised learning in the pre-processing phase, including pseudo labeling to predict labels for unlabeled data, a re-sampling method to obtain multiple fair datasets and lastly, ensemble learning to improve accuracy and decrease discrimination. A theoretical decomposition analysis of bias, variance and noise highlights the different sources of discrimination and the impact they have on fairness in semi-supervised learning. A set of experiments on real-world and synthetic datasets show that our method is able to use unlabeled data to achieve a better trade-off between accuracy and discrimination.},
  archive      = {J_TKDE},
  author       = {Tao Zhang and Tianqing Zhu and Jing Li and Mengde Han and Wanlei Zhou and Philip S. Yu},
  doi          = {10.1109/TKDE.2020.3002567},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1763-1774},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fairness in semi-supervised learning: Unlabeled data help to reduce discrimination},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling time-centric computation for efficient temporal
graph traversals from multiple sources. <em>TKDE</em>, <em>34</em>(4),
1751–1762. (<a href="https://doi.org/10.1109/TKDE.2020.3005672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal graph traversal is an approach for analyzing how information spreads throughout a network over time. A system has been recently proposed as an initial effort for efficient analyses against higher time complexity and infinitely evolving data unlike static graph. However, with the system, the response time for traversals from multiple sources is proportional to the number of sources; thus, application domains of the system can be limited. To resolve this problem, the state-of-the-art vertex-centric paradigm can be considered; however, we have found that the paradigm is not fitted into this computation. The paper proposes a novel time-centric computation approach for efficient all-pairs temporal graph traversals. One benefit of this approach is that users only need to focus on designing a repetitive task for graph elements that are valid at each sliding time, which simplifies the program logic and alleviates the burden of writing codes. Another benefit is that the approach is expected to enhance the performance by facilitating the reuse of intermediate results of multiple sources. The proposed approach is evaluated with a prototyped system, the recipes for existing algorithms, and the experiments with open temporal datasets. In addition, we also discuss how to handle ever-evolving real-world temporal networks.},
  archive      = {J_TKDE},
  author       = {Jaewook Byun},
  doi          = {10.1109/TKDE.2020.3005672},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1751-1762},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enabling time-centric computation for efficient temporal graph traversals from multiple sources},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient match-based candidate network generation for
keyword queries over relational databases. <em>TKDE</em>,
<em>34</em>(4), 1735–1750. (<a
href="https://doi.org/10.1109/TKDE.2020.2998046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several systems proposed for processing keyword queries over relational databases rely on the generation and evaluation of Candidate Networks (CNs), i.e., networks of joined database relations that when processed as SQL queries, provide a relevant answer to the input keyword query. Although the evaluation of CNs has been extensively addressed in the literature, the problem of generating CNs efficiently and effectively has received much less attention. This challenging problem consists of automatically locating relations in the database that may contain relevant pieces of information, given a handful of keywords, and determining suitable ways of joining these relations to satisfy the implicit information needs expressed by a user while formulating his/her query. In this paper, we propose a novel approach for generating CNs, wherein the possible matches for the query in the database are efficiently enumerated at first. These query matches are then used to guide the CN generation process, avoiding the exhaustive search procedure used by the current state-of-art approaches. We show that our approach allows the generation of a compact set of CNs that leads to superior quality answers, and demands less resources in terms of processing time and memory. These claims are supported by a comprehensive set of experiments that we carried out using several query sets and datasets used in previous related works and whose results we report and analyze here.},
  archive      = {J_TKDE},
  author       = {Péricles Silva de Oliveira and Altigran da Silva and Edleno de Moura and Rosiane de Freitas},
  doi          = {10.1109/TKDE.2020.2998046},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1735-1750},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient match-based candidate network generation for keyword queries over relational databases},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DRprofiling: Deep reinforcement user profiling for
recommendations in heterogenous information networks. <em>TKDE</em>,
<em>34</em>(4), 1723–1734. (<a
href="https://doi.org/10.1109/TKDE.2020.2998695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are popular for personalization in online communities. Users, items, and other affiliated information such as tags, item genres, and user friends of an online community form a heterogenous information network. User profiling is the foundation of personalized recommender systems. It provides the basis to discover knowledge about an individual user’s interests to items. Typically, users are profiled with their direct explicit or implicit ratings, which ignored the inter-connections among users, items, and other entity nodes of the information network. This paper proposes a deep reinforcement user profiling approach for recommender systems. The user profiling process is framed as a sequential decision making problem which can be solved with a Reinforcement Learning (RL) agent. The RL agent interacts with the external heterogenous information network environment and learns a decision making policy network to decide whether there is an interest or preference path between a user and an unobserved item. To effectively train the RL agent, this paper proposes a multi-iteration training process to combine both expert and data-specific knowledge to profile users, generate meta-paths, and make recommendations. The effectiveness of the proposed approaches is demonstrated in experiments conducted on three datasets.},
  archive      = {J_TKDE},
  author       = {Huizhi Liang},
  doi          = {10.1109/TKDE.2020.2998695},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1723-1734},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DRprofiling: Deep reinforcement user profiling for recommendations in heterogenous information networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discretization using combination of heuristics for high
accuracy with huge noise reduction. <em>TKDE</em>, <em>34</em>(4),
1710–1722. (<a href="https://doi.org/10.1109/TKDE.2020.2997719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, several algorithms for discretization have been devised, but the problem of efficient, accurate discretization still remains an open problem. This paper proposes a novel discretization algorithm, called SPID5, based on combination of two heuristics, one being local and the other global, both being supervised and their combination resulting in a significant synergy. The local heuristic is the well-known information gain of the continuous attributes, and the global heuristic is a novel concept of iterative reduction of noise in the data set. The reduction of noise is achieved by reducing successively pseudo deletion count of the data set to be discretized. The performance of SPID5 algorithm is compared with that of three well-known and time-tested discretization algorithms, using six state-of-the-art classifiers and 35 real-world data sets from the standard UCI data repository. Performance of SPID5 compares favorably with that of all the three existing discretization algorithms it is compared with, not only in terms of classification accuracy but also in terms of noise reduction in the data sets.},
  archive      = {J_TKDE},
  author       = {Somnath Pal and Saptarshi Ghosh and Himika Biswas and Mitesh Patwari},
  doi          = {10.1109/TKDE.2020.2997719},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1710-1722},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Discretization using combination of heuristics for high accuracy with huge noise reduction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Dimensionality reduction based on multilocal linear pattern
preservation. <em>TKDE</em>, <em>34</em>(4), 1696–1709. (<a
href="https://doi.org/10.1109/TKDE.2020.2999504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manifold learning-based methods, such as LLE, capture the geometry of the data based on the assumption that the local structure of a manifold is linear. However, these methods may extract an inaccurate local structure when the nonlinearity of the data is obvious. In this paper, we propose a novel dimensionality reduction method with the ability to characterize the locally nonlinear geometry of the data by multilocal linearity. Specifically, we first construct a local area for each data point. And based on the overlapping of local areas, each data point will belong to and be linearly reconstructed from several local areas. Next, the set of linear coefficients used to reconstruct the data point constitutes the multilocal linear pattern (MLLP) which is used to characterize the local geometry of the data. Geometrically, the MLLP of a data point represents the hyperplanes in different directions passing through the current point. And the locally nonlinear surface where the data point is located is approximated by these hyperplanes, which is more accurate to reflect the geometry of the data. Then, MLLP is preserved to the embedding data space, and the dimension-reduced data can be obtained by minimizing the reconstruction errors. Finally, experiment results on various datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_TKDE},
  author       = {Shujie Zhang and Zhengming Ma and Guokai Zhang and Weichao Gan},
  doi          = {10.1109/TKDE.2020.2999504},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1696-1709},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dimensionality reduction based on multilocal linear pattern preservation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deterministic inference of topic models via maximal latent
state replication. <em>TKDE</em>, <em>34</em>(4), 1684–1695. (<a
href="https://doi.org/10.1109/TKDE.2020.3000559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic topic models, such as latent dirichlet allocation (LDA), are often used to discover hidden semantic structure of a collection of documents. In recent years, various inference algorithms have been developed to cope with learning of topic models, among which Gibbs sampling methods remain a popular choice. In this paper, we aim to improve the inference of topic models based on the Gibbs sampling framework. We extend a state augmentation based Gibbs sampling method by maximizing the replications of latent states, and propose a new generic deterministic inference method, named maximal latent state replication (MAX), for learning of a family of probabilistic topic models. One key benefit of the proposed method lies in the deterministic nature for inference, which may help to improve its running efficiency as well as predictive perplexity. We have conducted extensive experiments on real-life publicly available datasets, and the results have validated that our proposed method MAX significantly outperforms state-of-the-art baselines for inference of existing well-known topic models.},
  archive      = {J_TKDE},
  author       = {Daniel Rugeles and Zhen Hai and Manoranjan Dash and Gao Cong},
  doi          = {10.1109/TKDE.2020.3000559},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1684-1695},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deterministic inference of topic models via maximal latent state replication},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuous monitoring of maximum clique over dynamic graphs.
<em>TKDE</em>, <em>34</em>(4), 1667–1683. (<a
href="https://doi.org/10.1109/TKDE.2020.3003701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum clique problem ( MCP ) has various applications to reveal the structure and function of graphs. Graphs are constantly updated in the real life. However, no algorithm is specifically designed for dynamic graph. Although MCP in dynamic graphs can be solved by simply invoking a state-of-the-art static approach, such as PMC , when the graph is updated, such an approach of simply re-calculating from scratch is inefficient. The key issue with MCP algorithm is to find a large clique, namely a seed , as fast as possible. Thus, search space can be pruned based on the seed. Size of the seed greedily found by PMC cannot be guaranteed, as it fluctuates considerably. Moreover, the time required to find a seed under PMC is up to $O(| E| \cdot \Delta (G))$ , where $\Delta (G)$ is the highest degree in G . In this article, we intend to find a sizable seed by updating the previous maximum clique with the incident vertices of the inserted/deleted edge. Size of the seed now is guaranteed to be no less than $\omega (G^{\prime})\; - \;1$ , where $\omega (G^{\prime})$ is the size of the maximum clique on the updated graph. Moreover, the seed can be found in a time complexity of $O(\Delta (G)^{2})$ . Two other crucial issues related to the MCP in dynamic graphs are refreshing rate and refreshing overhead. After a tight upper bound is imposed on $\omega (G^{\prime})$ , the necessity of refreshing is evaluated by comparing the seed with its largest challenger, then unnecessary refreshing is wiped out effectively. The size of the largest challenger is judiciously estimated using a lazy growth strategy. Subsequently, the search space in refreshing is confined on a much smaller subgraph using a local refreshing strategy. Extensive experiments indicate that the proposed approach outperforms the baseline algorithm by approximately one order of magnitude.},
  archive      = {J_TKDE},
  author       = {Shengli Sun and Weiping Li and Yimo Wang and Weilong Liao and Philip S. Yu},
  doi          = {10.1109/TKDE.2020.3003701},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1667-1683},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Continuous monitoring of maximum clique over dynamic graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ChOracle: A unified statistical framework for churn
prediction. <em>TKDE</em>, <em>34</em>(4), 1656–1666. (<a
href="https://doi.org/10.1109/TKDE.2020.3000456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User churn is an important issue in online services that threatens the health and profitability of services. Most of the previous works on churn prediction convert the problem into a binary classification task where the users are labeled as churned and non-churned. More recently, some works have tried to convert the user churn prediction problem into the prediction of user return time. In this approach which is more realistic in real world online services, at each time-step the model predicts the user return time instead of predicting a churn label. However, the previous works in this category suffer from lack of generality and require high computational complexity. In this paper, we introduce ChOracle , an oracle that predicts the user churn by modeling the user return times to service by utilizing a combination of Temporal Point Processes and Recurrent Neural Networks. Moreover, we incorporate latent variables into the proposed recurrent neural network to model the latent user loyalty to the system. We also develop an efficient approximate variational inference algorithm for learning parameters of the proposed RNN by using back propagation through time. Finally, we demonstrate the superior performance of ChOracle on a wide variety of real world datasets.},
  archive      = {J_TKDE},
  author       = {Ali Khodadadi and Seyed Abbas Hosseini and Ehsan Pajouheshgar and Farnam Mansouri and Hamid R. Rabiee},
  doi          = {10.1109/TKDE.2020.3000456},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1656-1666},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ChOracle: A unified statistical framework for churn prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Answer again: Improving VQA with cascaded-answering model.
<em>TKDE</em>, <em>34</em>(4), 1644–1655. (<a
href="https://doi.org/10.1109/TKDE.2020.2998805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) is a very challenging task, which requires to understand visual images and natural language questions simultaneously. In the open-ended VQA task, most previous solutions focus on understanding the question and image contents, as well as their correlations. However, they mostly reason the answers in a one-stage way, which results in that the generated answers are significantly ignored. In this paper, we propose a novel approach, termed Cascaded-Answering Model (CAM), which extends the conventional one-stage VQA model to a two-stage model. Hence, the proposed model can fully explore the semantics embedded in the predicted answers. Specifically, CAM is composed of two cascaded answering modules: Candidate Answer Generation (CAG) module and Final Answer Prediction (FAP) module. In CAG module, we select multiple relevant candidates from the generated answers using a typical VQA approach with Co-Attention. While in FAP module, we integrate the information of question and image, together with the semantics explored from the selected candidate answers to predict the final answer. Experimental results demonstrate that the proposed model produces high-quality candidate answers and achieves the state-of-the-art performance on five large benchmark datasets, VQA-1.0, VQA-2.0, VQA-CP v2, TDIUC and COCO-QA.},
  archive      = {J_TKDE},
  author       = {Liang Peng and Yang Yang and Xiaopeng Zhang and Yanli Ji and Huimin Lu and Heng Tao Shen},
  doi          = {10.1109/TKDE.2020.2998805},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1644-1655},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Answer again: Improving VQA with cascaded-answering model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing in-memory NoSQL landscape. <em>TKDE</em>,
<em>34</em>(4), 1628–1643. (<a
href="https://doi.org/10.1109/TKDE.2020.3002908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-memory key-value stores have quickly become a key enabling technology to build high-performance applications that must cope with massively distributed workloads. In-memory key-value stores (also referred to as NoSQL) primarly aim to offer low-latency and high-throughput data access which motivates the rapid adoption of modern network cards such as Remote Direct Memory Access (RDMA). In this paper, we present the fundamental design principles for exploiting RDMAs in modern NoSQL systems. Moreover, we describe a break-down analysis of the state-of-the-art of the RDMA-based in-memory NoSQL systems regarding the indexing, data consistency, and the communication protocol. In addition, we compare traditional in-memory NoSQL with their RDMA-enabled counterparts. Finally, we present a comprehensive analysis and evaluation of the existing systems based on a wide range of configurations such as the number of clients, real-world request distributions, and workload read-write ratios.},
  archive      = {J_TKDE},
  author       = {Masoud Hemmatpour and Bartolomeo Montrucchio and Maurizio Rebaudengo and Mohammad Sadoghi},
  doi          = {10.1109/TKDE.2020.3002908},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1628-1643},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Analyzing in-memory NoSQL landscape},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient split-merge re-start for the <span
class="math inline"><em>K</em></span>k-means algorithm. <em>TKDE</em>,
<em>34</em>(4), 1618–1627. (<a
href="https://doi.org/10.1109/TKDE.2020.3002926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The $K$ -means algorithm is one of the most popular clustering methods. However, it is a well-known fact that its performance, in terms of quality of the obtained solution and computational load, highly depends upon its initialization phase. For this reason, different initialization techniques have been developed throughout the years to enable its fast convergence to competitive solutions. In this sense, it is common practice to re-start the $K$ -means algorithm several times via one of these techniques and keep the solution with the lowest error. Unfortunately, such a choice is still likely to be a poor approximation of the optimal set of centroids. In this article, we introduce a cheap Split-Merge step that can be used to re-start the $K$ -means algorithm after reaching a fixed point. Under some settings, one can show that this approach reduces the error of the given fixed point without requiring any further iteration of the $K$ -means algorithm. Moreover, experimental results show that this strategy is able to generate approximations with an associated error that is hard to reach for different multi-start methods, such as multi-start Forgy $K$ -means, $K$ -means++ and Hartigan $K$ -means, while also computing a lower amount of distances than the previous algorithms.},
  archive      = {J_TKDE},
  author       = {Marco Capó and Aritz Pérez and Jose A. Lozano},
  doi          = {10.1109/TKDE.2020.3002926},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1618-1627},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An efficient split-merge re-start for the $K$K-means algorithm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial deep embedded clustering: On a better trade-off
between feature randomness and feature drift. <em>TKDE</em>,
<em>34</em>(4), 1603–1617. (<a
href="https://doi.org/10.1109/TKDE.2020.2997772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the absence of concrete supervisory signals, deep clustering models construct their own labels based on self-supervision and pseudo-supervision. However, applying these techniques can cause Feature Randomness and Feature Drift. In this paper, we formally characterize these two new concepts. On one hand, Feature Randomness takes place when a considerable portion of the pseudo-labels is deemed to be random. In this regard, the trained model can learn non-representative features. On the other hand, Feature Drift takes place when the pseudo-supervised and the reconstruction losses are jointly minimized. While penalizing the reconstruction loss aims to preserve all the inherent data information, optimizing the embedded-clustering objective drops the latent between-cluster variances. Due to this compromise, the clustering-friendly representations can be easily drifted. In this context, we propose ADEC (Adversarial Deep Embedded Clustering) a novel autoencoder-based clustering model, which relies on a discriminator network to reduce random features while avoiding the drifting effect. Our new metrics $\Delta _{FR}$ and $\Delta _{FD}$ allows to, respectively, assess the level of Feature Randomness and Feature Drift. We empirically demonstrate the suitability of our model on handling these problems using benchmark real datasets. Experimental results validate that our model outperforms state-of-the-art autoencoder-based clustering methods.},
  archive      = {J_TKDE},
  author       = {Nairouz Mrabah and Mohamed Bouguessa and Riadh Ksantini},
  doi          = {10.1109/TKDE.2020.2997772},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1603-1617},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adversarial deep embedded clustering: On a better trade-off between feature randomness and feature drift},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptively secure and fast processing of conjunctive queries
over encrypted data. <em>TKDE</em>, <em>34</em>(4), 1588–1602. (<a
href="https://doi.org/10.1109/TKDE.2020.2997688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the fundamental problem of processing conjunctive queries that contain both keyword and range conditions on public clouds in a privacy preserving manner. No prior Searchable Symmetric Encryption (SSE) based privacy preserving conjunctive query processing scheme satisfies the three requirements of adaptive security, efficient query processing, and scalable index size. In this paper, we propose the first privacy preserving conjunctive query processing scheme that satisfies all the above three requirements. To achieve adaptive security, we propose an Indistinguishable Bloom Filter (IBF) data structure for indexing. To achieve efficient query processing and structural indistinguishability, we propose a highly balanced binary tree data structure called Indistinguishable Binary Tree (IBtree). To achieve scalable and compact index size, we propose an IBtree space compression algorithm to remove redundant information in IBFs. To optimize search efficiency, we propose a traversal minimization algorithm. To make our scheme dynamic, we propose update algorithms. We prove that our scheme is adaptive secure under the IND-CKA secure model. The key contribution of this paper is on achieving conjunctive query processing with both strong privacy guarantee and practical efficiency in terms of both speed and space. We implemented our scheme in C++, evaluated and compared its performance with the prior KRB scheme for keyword queries and the prior PBtree scheme for range queries on two real-world data sets. Experimental results show that our scheme is both fast and scalable. For example, processing a query only takes a few milliseconds for millions of records.},
  archive      = {J_TKDE},
  author       = {Rui Li and Alex X. Liu},
  doi          = {10.1109/TKDE.2020.2997688},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1588-1602},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptively secure and fast processing of conjunctive queries over encrypted data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive temporal-frequency network for time-series
forecasting. <em>TKDE</em>, <em>34</em>(4), 1576–1587. (<a
href="https://doi.org/10.1109/TKDE.2020.3003420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel adaptive temporal-frequency network (ATFN), which is an end-to-end hybrid model incorporating deep learning networks and frequency patterns, is proposed for mid- and long-term time series forecasting. Within the framework of the ATFN, an augmented sequence to sequence model is used to learn the trend feature of complicated nonstationary time series, a frequency-domain block is used to capture dynamic and complicated periodic patterns of time series data, and a fully connected neural network is used to combine the trend and periodic features for producing a final forecast. An adaptive frequency mechanism consisting of phase adaption, frequency adaption, and amplitude adaption is designed for mapping the frequency spectrum of the current sliding window to that of the forecasting interval. The multilayer neural networks conduct a transformation similar to the inverse discrete Fourier transform for generating a periodic feature forecast. Synthetic data and real-world data with different periodic characteristics are used to evaluate the effectiveness of the proposed model. The experimental results indicate that the ATFN has promising performance and strong adaptability for long-term time-series forecasting.},
  archive      = {J_TKDE},
  author       = {Zhangjing Yang and Weiwu Yan and Xiaolin Huang and Lin Mei},
  doi          = {10.1109/TKDE.2020.3003420},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1576-1587},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Adaptive temporal-frequency network for time-series forecasting},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework for user identification across online
and offline data. <em>TKDE</em>, <em>34</em>(4), 1562–1575. (<a
href="https://doi.org/10.1109/TKDE.2020.3000287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User identification across multiple datasets has a wide range of applications and there has been an increasing set of research works on this topic during recent years. However, most of existing works focus on user identification with a single input data type, e.g., (I) identifying a user across multiple social networks with online data and (II) detecting a single user from heterogeneous trajectory datasets with offline data. Different from previous works, in this paper, we propose a framework on user identification between online and offline datasets. We build connections between these two types of data by a mapping from IP addresses to physical locations. To solve this problem, we propose a novel framework consisting of three steps. First, we use a clustering method based on locations of IP addresses to map IP addresses into specific physical location distributions. Second, we propose a novel pairwise index to reduce space cost and running time for computing the co-occurrence. Lastly, we apply a learning-to-rank method to merge the effect of multiple features we get in the first two steps. Based on our framework, we design experiments to demonstrate the efficiency (in time and space) of our framework, together with the precision and recall of our approach compared to other methods.},
  archive      = {J_TKDE},
  author       = {Tianyi Hao and Jingbo Zhou and Yunsheng Cheng and Longbo Huang and Haishan Wu},
  doi          = {10.1109/TKDE.2020.3000287},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1562-1575},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A unified framework for user identification across online and offline data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on modern deep neural network for traffic
prediction: Trends, methods and challenges. <em>TKDE</em>,
<em>34</em>(4), 1544–1561. (<a
href="https://doi.org/10.1109/TKDE.2020.3001195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this modern era, traffic congestion has become a major source of severe negative economic and environmental impact for urban areas worldwide. One of the most efficient ways to mitigate traffic congestion is through future traffic prediction. The research field of traffic prediction has evolved greatly ever since its inception in the late 70s. Earlier studies mainly use classical statistical models such as ARIMA and its variants. Recently, researchers have started to focus on machine learning models because of their power and flexibility. As theoretical and technological advances emerge, we enter the era of deep neural network, which gained popularity due to its sheer prediction power which can be attributed to the complex and deep structure. Despite the popularity of deep neural network models in the field of traffic prediction, literature surveys of such methods are rare. In this work, we present an up-to-date survey of deep neural network for traffic prediction. We will provide a detailed explanation of popular deep neural network architectures commonly used in the traffic flow prediction literatures, categorize and describe the literatures themselves, present an overview of the commonalities and differences among different works, and finally provide a discussion regarding the challenges and future directions for this field.},
  archive      = {J_TKDE},
  author       = {David Alexander Tedjopurnomo and Zhifeng Bao and Baihua Zheng and Farhana Murtaza Choudhury and A. K. Qin},
  doi          = {10.1109/TKDE.2020.3001195},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1544-1561},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on modern deep neural network for traffic prediction: Trends, methods and challenges},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hidden markov contour tree model for spatial structured
prediction. <em>TKDE</em>, <em>34</em>(4), 1530–1543. (<a
href="https://doi.org/10.1109/TKDE.2020.3002887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial structured models are predictive models that capture dependency structure between samples based on their locations in the space. Learning such models plays an important role in many geoscience applications such as water surface mapping, but it also poses significant challenges due to implicit dependency structure in continuous space and high computational costs. Existing models often assume that the dependency structure is based on either spatial proximity or network topology, and thus cannot incorporate complex dependency structure such as contour and flow direction on a 3D potential surface. To fill the gap, we recently proposed a novel spatial structured model called hidden Markov contour tree (HMCT), which generalizes the traditional hidden Markov model from a total order sequence to a partial order polytree. HMCT also advances existing work on hidden Markov trees through capturing complex contour structures on a 3D surface. We proposed efficient model construction and learning algorithms. This paper extends our initial HMCT model into a post-processor that can refine the classified results from other existing models. We analyzed the theoretical properties of the extended model. Evaluations on real-world flood mapping datasets show that HMCT outperforms multiple baseline methods in classification performance and the HMCT can also effectively enhance the results of other baseline methods. Computational experiments also show that HMCT is scalable to large data sizes (e.g., classifying millions of samples in seconds).},
  archive      = {J_TKDE},
  author       = {Arpan Man Sainju and Wenchong He and Zhe Jiang},
  doi          = {10.1109/TKDE.2020.3002887},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1530-1543},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A hidden markov contour tree model for spatial structured prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A general approach for supporting time series matching using
multiple-warped distances. <em>TKDE</em>, <em>34</em>(4), 1516–1529. (<a
href="https://doi.org/10.1109/TKDE.2020.2998002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series are generated at an unprecedented rate in domains ranging from finance, medicine to education. Collections composed of heterogeneous, variable-length and misaligned times series are best explored using a plethora of dynamic time warping distances. However, the computational costs of using such elastic distances result in unacceptable response times. We thus design the first practical solution for the efficient GEN eral EX ploration of time series leveraging multiple warped distances. GENEX pre-processes time series data in metric point-wise distance spaces, while providing bounds for the accuracy of corresponding analytics derived in non-metric warped distance spaces. Our empirical evaluation on 66 benchmark datasets provides a comparative study of the accuracy and response times of diverse warped distances. We show that GENEX is a versatile yet highly efficient solution for processing expensive-to-compute warped distances over large datasets, with response times 3 to 5 orders of magnitude faster than state-of-art systems.},
  archive      = {J_TKDE},
  author       = {Rodica Neamtu and Ramoza Ahsan and Cuong Nguyen and Charles Lovering and Elke A. Rundensteiner and Gabor Sarkozy},
  doi          = {10.1109/TKDE.2020.2998002},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {4},
  pages        = {1516-1529},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A general approach for supporting time series matching using multiple-warped distances},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised entity resolution with blocking and graph
algorithms. <em>TKDE</em>, <em>34</em>(3), 1501–1515. (<a
href="https://doi.org/10.1109/TKDE.2020.2991063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity resolution identifies all records in a database that refer to the same entity. In this paper, we propose an unsupervised framework for entity resolution using blocking and graph algorithms. The records are partitioned into blocks with no redundancy for efficiency improvement. For intra-block data processing, we propose a graph-theoretic fusion framework with two components, namely ITER and CliqueRank. Specifically, ITER constructs a weighted bipartite graph between terms and record-record pairs and iteratively propagates the node salience until convergence. Subsequently, CliqueRank constructs a record graph to estimate the likelihood of two records resident in the same clique. The derived likelihood from CliqueRank is fed back to ITER to rectify the edge weight until a joint optimum can be reached. Experimental evaluation was conducted with 4 real datasets. Results show that our unsupervised framework is comparable or even superior to state-of-the-art deep learning approaches.},
  archive      = {J_TKDE},
  author       = {Dongxiang Zhang and Dongsheng Li and Long Guo and Kian-Lee Tan},
  doi          = {10.1109/TKDE.2020.2991063},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1501-1515},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unsupervised entity resolution with blocking and graph algorithms},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The use of fuzzy logic as augmentation to quantitative
analysis to unleash knowledge of participants’ uncertainty when filling
a survey: Case of cloud computing. <em>TKDE</em>, <em>34</em>(3),
1489–1500. (<a href="https://doi.org/10.1109/TKDE.2020.2993326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative analysis is a solid, well established mathematical technique that can be used to analyze the result of survey(s) in a specific field. Survey analysis is usually based on the study of the effect of independent variables on a dependent variable. Although quantitative analysis can use an R-Squared value as a method to measure the strength of the relationship between the independent and dependent variables, it does not capture the effect of participants’ ambiguity when answering questionnaires. The source of such ambiguity stems from the process of completing the survey, whereby the respondent may have answered most of the independent questions with ease, but has difficulty in responding to the overall dependent question (or vice versa). The objective of this paper is to demonstrate the use of fuzzy logic as a mechanism to measure the uncertainty faced by participants when filling a questionnaire. Based on the participants’ responses to the independent variables, the proposed technique uses fuzzy logic inference to measure the subjectivity (qualitative aspect) of the participants’ response to the dependent variable. Beyond quantitative analysis, augmentation with such a fuzzy module can provide clearer picture to analysts when analyzing the survey results. In this paper, Cloud acceptance survey will be used as a vehicle to provide step-by-step explanation of the proposed augmentation technique to unleash the hidden knowledge in similar cases to cloud computing long survey questionnaire where participants may change their mind at the end of the survey causing uncertainty represented in discrepancy of the collected data. The proposed technique would only be valid for long surveys like the presented Cloud computing acceptability where uncertainty in the data is inevitable.},
  archive      = {J_TKDE},
  author       = {I. Kouatli},
  doi          = {10.1109/TKDE.2020.2993326},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1489-1500},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {The use of fuzzy logic as augmentation to quantitative analysis to unleash knowledge of participants’ uncertainty when filling a survey: Case of cloud computing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stat-DSM: Statistically discriminative sub-trajectory mining
with multiple testing correction. <em>TKDE</em>, <em>34</em>(3),
1477–1488. (<a href="https://doi.org/10.1109/TKDE.2020.2994344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel statistical approach to evaluate the statistical significance (reliability) of the results from discriminative sub-trajectory mining, which we call Statistically Discriminative Sub-trajectory Mining (Stat-DSM) . Given two groups of trajectories, the goal of Stat-DSM is to extract moving patterns in the form of sub-trajectories that occur statistically significantly more often in one group than in the other. An advantage of the proposed method is that the statistical significance of the extracted sub-trajectories are properly controlled in the sense that the probability of finding a falsely discriminative sub-trajectory is smaller than a specified significance threshold $\alpha$ (e.g., 0.05), which is crucial when the method is used in scientific or social science studies under noisy environments. Finding such statistically discriminative sub-trajectories from a massive trajectory dataset is both computationally and statistically challenging. In the Stat-DSM method, we address these difficulties by introducing a tree representation of sub-trajectories, and applying an efficient permutation-based statistical inference method to the tree. To the best of our knowledge, Stat-DSM is the first method that provides a statistical approach to quantify the reliability of discriminative sub-trajectory mining results. We illustrate the effectiveness and scalability of the Stat-DSM method by applying it to a real-world dataset containing 1,000,000 trajectories.},
  archive      = {J_TKDE},
  author       = {Vo Nguyen Le Duy and Takuto Sakuma and Taiju Ishiyama and Hiroki Toda and Kazuya Arai and Masayuki Karasuyama and Yuta Okubo and Masayuki Sunaga and Hiroyuki Hanada and Yasuo Tabei and Ichiro Takeuchi},
  doi          = {10.1109/TKDE.2020.2994344},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1477-1488},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Stat-DSM: Statistically discriminative sub-trajectory mining with multiple testing correction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatio-temporal meta learning for urban traffic prediction.
<em>TKDE</em>, <em>34</em>(3), 1462–1476. (<a
href="https://doi.org/10.1109/TKDE.2020.2995855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting urban traffic is of great importance to intelligent transportation systems and public safety, yet is very challenging in three aspects: 1) complex spatio-temporal correlations of urban traffic, including spatial correlations between locations along with temporal correlations among timestamps; 2) spatial diversity of such spatio-temporal correlations, which varies from location to location and depends on the surrounding geographical information, e.g., points of interests and road networks; and 3) temporal diversity of such spatio-temporal correlations, which is highly influenced by dynamic traffic states. To tackle these challenges, we proposed a deep meta learning based model, entitled ST-MetaNet $^+$ , to collectively predict traffic in all locations at the same time. ST-MetaNet $^+$ employs a sequence-to-sequence architecture, consisting of an encoder to learn historical information and a decoder to make predictions step by step. Specifically, the encoder and decoder have the same network structure, consisting of meta graph attention networks and meta recurrent neural networks, to capture diverse spatial and temporal correlations, respectively. Furthermore, the weights (parameters) of meta graph attention networks and meta recurrent neural networks are generated from the embeddings of geo-graph attributes and the traffic context learned from dynamic traffic states. Extensive experiments were conducted based on three real-world datasets to illustrate the effectiveness of ST-MetaNet $^+$ beyond several state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Zheyi Pan and Wentao Zhang and Yuxuan Liang and Weinan Zhang and Yong Yu and Junbo Zhang and Yu Zheng},
  doi          = {10.1109/TKDE.2020.2995855},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1462-1476},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Spatio-temporal meta learning for urban traffic prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Spatio-temporal capsule-based reinforcement learning for
mobility-on-demand coordination. <em>TKDE</em>, <em>34</em>(3),
1446–1461. (<a href="https://doi.org/10.1109/TKDE.2020.2992565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an alternative means of convenient and smart transportation, mobility-on-demand (MOD), typified by online ride-sharing and connected taxicabs, has been rapidly growing and spreading worldwide. The large volume of complex traffic and the uncertainty of market supplies/demands have made it essential for many MOD service providers to proactively dispatch vehicles towards ride-seekers. To meet this need effectively, we propose STRide , an MOD coordination learning mechanism reinforced spatio-temporally with capsules. We formalize the adaptive coordination of vehicles into a reinforcement learning framework. STRide incorporates spatial and temporal distributions of supplies (vehicles) and demands (ride requests), customers’ preferences and other external factors. A novel spatio-temporal capsule neural network is designed to predict the provider’s rewards based on MOD network states, vehicles and their dispatch actions. This way, the MOD platform adapts itself to the supply-demand dynamics with the best potential rewards. We have conducted extensive data analytics and experimental evaluation with five large-scale datasets ( $\sim$ 27 million rides from Uber, NYC/Chicago Taxis, Didi and Car2Go). STRide is shown to outperform state-of-the-arts, substantially reducing request-rejection rate and passenger waiting time, and also increasing the service provider’s profits.},
  archive      = {J_TKDE},
  author       = {Suining He and Kang G. Shin},
  doi          = {10.1109/TKDE.2020.2992565},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1446-1461},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Spatio-temporal capsule-based reinforcement learning for mobility-on-demand coordination},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Short text topic modeling techniques, applications, and
performance: A survey. <em>TKDE</em>, <em>34</em>(3), 1427–1445. (<a
href="https://doi.org/10.1109/TKDE.2020.2992485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing short texts infers discriminative and coherent latent topics that is a critical and fundamental task since many real-world applications require semantic understanding of short texts. Traditional long text topic modeling algorithms (e.g., PLSA and LDA) based on word co-occurrences cannot solve this problem very well since only very limited word co-occurrence information is available in short texts. Therefore, short text topic modeling has already attracted much attention from the machine learning research community in recent years, which aims at overcoming the problem of sparseness in short texts. In this survey, we conduct a comprehensive review of various short text topic modeling techniques proposed in the literature. We present three categories of methods based on Dirichlet multinomial mixture, global word co-occurrences, and self-aggregation, with example of representative approaches in each category and analysis of their performance on various tasks. We develop the first comprehensive open-source library, called STTM, for use in Java that integrates all surveyed algorithms within a unified interface, benchmark datasets, to facilitate the expansion of new methods in this research field. Finally, we evaluate these state-of-the-art methods on many real-world datasets and compare their performance against one another and versus long text topic modeling algorithm.},
  archive      = {J_TKDE},
  author       = {Jipeng Qiang and Zhenyu Qian and Yun Li and Yunhao Yuan and Xindong Wu},
  doi          = {10.1109/TKDE.2020.2992485},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1427-1445},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Short text topic modeling techniques, applications, and performance: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SACCOS: A semi-supervised framework for emerging class
detection and concept drift adaption over data streams. <em>TKDE</em>,
<em>34</em>(3), 1416–1426. (<a
href="https://doi.org/10.1109/TKDE.2020.2993193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address challenges of detecting instances from emerging classes over a non-stationary data stream during data classification. In particular, data instances from an entirely unknown class may appear in a data stream over time. Existing classification techniques utilize unsupervised clustering to identify emergence of such data instances. Unfortunately, they make strong assumptions which are typically invalid in practice; (i) Most instances associated with a class are closer to each other in feature space than instances associated with different classes, (ii) Covariates of data are normalized through an oracle to overcome the effect of a few data instances having large feature values, and (iii) Labels of instances from emerging classes are readily available soon after detection. To address the challenges that occur in practice when the above assumptions are weak, i.e., instances of each class are scattered and the true labels of novel class instances are sparsely available, we propose a practical semi-supervised emerging class detection framework. Particularly, we aim to identify similar data instances within local regions in feature space by incorporating a mutual graph clustering mechanism. We also perform online normalization along the data stream instead of assuming an oracle, and propose a classification technique that uses only a small amount of true labels for training and emerging class detection. Our empirical evaluation of this framework on real-world datasets demonstrates its superiority of classification performance compared to existing methods, while using significantly fewer labeled instances.},
  archive      = {J_TKDE},
  author       = {Yang Gao and Swarup Chandra and Yifan Li and Latifur Khan and Thuraisingham Bhavani},
  doi          = {10.1109/TKDE.2020.2993193},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1416-1426},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SACCOS: A semi-supervised framework for emerging class detection and concept drift adaption over data streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust subspace clustering with low-rank structure
constraint. <em>TKDE</em>, <em>34</em>(3), 1404–1415. (<a
href="https://doi.org/10.1109/TKDE.2020.2995896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel low-rank structural model is proposed for segmenting data drawn from a high-dimensional space. Our method is based on the fact that all groups clustered from a high-dimensional dataset are distributed in multiple low-rank subspaces. In general, it’s a very difficult task to find the low-rank structures hidden in data. Different from the classical sparse subspace clustering (SSC) and low-rank representation (LRR) which all take two steps including building the affinity matrix and spectral clustering, we introduce a new rank constraint into our model. This constraint allows our model to learn a subspace indicator which can capture different clusters directly from the data without any postprocessing. To further approximate the rank constraint, a piecewise function is utilized as the relaxing item for the proposed model. Besides, under the subspace indicator constraints, the integer programming problem is avoided, which makes our algorithm more efficient and scalable. In addition, we prove the convergence of the proposed algorithm in theory and further discuss the general case in which subspaces don’t pass through the origin. Experiment results on both synthetic and real-world datasets demonstrate that our algorithm significantly outperforms the state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Feiping Nie and Wei Chang and Zhanxuan Hu and Xuelong Li},
  doi          = {10.1109/TKDE.2020.2995896},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1404-1415},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust subspace clustering with low-rank structure constraint},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predicting hot events in the early period through bayesian
model for social networks. <em>TKDE</em>, <em>34</em>(3), 1390–1403. (<a
href="https://doi.org/10.1109/TKDE.2020.2994946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting emerging hot events in an early stage is essential for various applications, including information dissemination mining, ads recommendation and etc. Existing techniques either require a long-term observation over the event or features that are expensive to extract. However, given limited data at the early stage of an emerging event, the temporal features of hot events and non-hot events are not distinctive enough yet. In this work, we introduce BEEP, a Bayesian perspective Early stage Event Prediction model, that tackles this dilemma. We formulate the hot event prediction problem by two Semi-Naive Bayes Classifiers, where we consider both the temporal features and structural features and perform distribution test for the selected features. Theoretical analysis and extensive empirical evaluations on two real datasets demonstrate the effectiveness of our methods.},
  archive      = {J_TKDE},
  author       = {Zuowu Zheng and Xiaofeng Gao and Xiao Ma and Guihai Chen},
  doi          = {10.1109/TKDE.2020.2994946},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1390-1403},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Predicting hot events in the early period through bayesian model for social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Persistence of RDF data into NoSQL: A survey and a reference
architecture. <em>TKDE</em>, <em>34</em>(3), 1370–1389. (<a
href="https://doi.org/10.1109/TKDE.2020.2994521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RDF is being increasingly considered in a broad range of information management scenarios. Governments, large corporations, startups, and other organizations around the world are using RDF as a data model to represent and share knowledge. However, there is still a long evolutionary track with multiple challenges for RDF reaching the scale of the most recent Big Data intensive applications (e.g., Smart Cities, Sensor Networks, eHealth, Internet of Things). In this survey, we review the usage of NoSQL databases to the storage of large RDF graphs by rehearsing the latest surveys and expanding their findings by updating proposals and bringing light to aspects such as model mapping between RDF and NoSQL, triple indexing and partitioning, graph fragmentation and data caching. Moreover, we explain how the surveyed works extended the RDF capabilities so the datasets can benefit of the characteristics of scalability, schemaless data, and better overall performance of NoSQL databases. The survey summarizes the current state of art, discusses open problems, and proposes a Reference Architecture (RA). For the best of our knowledge, this is the first survey where the focus is solely on papers that use one or more NoSQL systems for the RDF persistence.},
  archive      = {J_TKDE},
  author       = {Luiz Henrique Zambom Santana and Ronaldo dos Santos Mello},
  doi          = {10.1109/TKDE.2020.2994521},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1370-1389},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Persistence of RDF data into NoSQL: A survey and a reference architecture},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Noise removal in embedded image with bit approximation.
<em>TKDE</em>, <em>34</em>(3), 1359–1369. (<a
href="https://doi.org/10.1109/TKDE.2020.2992572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stego-images are often contaminated by interchannel noise or active noise attack when communicating on the Web. And it is challenging to restore embedded image from corrupted stego-image. This paper studies a k NN-bit approximation algorithm to remove noises in embedded image. The proposed algorithm distinguishes reliable bits from extracted bits, and estimates pixel values by keeping reliable bits unchanged and correcting unreliable bits. Specifically, the 8th (highest) unreliable bit of a pixel can be approximated with its nearest neighbor pixels. And then, if an unreliable bit locates at any one of the $5^{th}\sim 7^{th}$ bits of a pixel, it is adjusted with two nearest neighbors of the pixel, where the pixel is in-between these two nearest neighbors. Finally, for other unreliable bits, each one is approximated by the maximum and minimum possible values of nearest neighbors of its pixel. We conduct experiments for illustrating the efficiency, and demonstrate that the proposed algorithm can recover the embedded images with good visual quality from corrupted stego-images.},
  archive      = {J_TKDE},
  author       = {Xianquan Zhang and Xuelong Li and Zhenjun Tang and Shichao Zhang and Shaomin Xie},
  doi          = {10.1109/TKDE.2020.2992572},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1359-1369},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Noise removal in embedded image with bit approximation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-source spatial entity linkage. <em>TKDE</em>,
<em>34</em>(3), 1344–1358. (<a
href="https://doi.org/10.1109/TKDE.2020.2990491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Besides the traditional cartographic data sources, spatial information can also be derived from location-based sources. However, even though different location-based sources refer to the same physical world, each one has only partial coverage of the spatial entities, describe them with different attributes, and sometimes provide contradicting information. Hence, we introduce the spatial entity linkage problem, which finds which pairs of spatial entities belong to the same physical spatial entity. Our proposed solution ( QuadSky ) starts with a time-efficient spatial blocking technique ( QuadFlex ), compares pairwise the spatial entities in the same block, ranks the pairs using Pareto optimality with the SkyRank algorithm, and finally, classifies the pairs with our novel SkyEx-* family of algorithms that yield 0.85 precision and 0.85 recall for a manually labeled dataset of 1,500 pairs and 0.87 precision and 0.6 recall for a semi-manually labeled dataset of 777,452 pairs. Moreover, we provide a theoretical guarantee and formalize the SkyEx-FES algorithm that explores only 27 percent of the skylines without any loss in F-measure . Furthermore, our fully unsupervised algorithm SkyEx-D approximates the optimal result with an F-measure loss of just 0.01. Finally, QuadSky provides the best trade-off between precision and recall , and the best F-measure compared to the existing baselines and clustering techniques, and approximates the results of supervised learning solutions.},
  archive      = {J_TKDE},
  author       = {Suela Isaj and Torben Bach Pedersen and Esteban Zimányi},
  doi          = {10.1109/TKDE.2020.2990491},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1344-1358},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-source spatial entity linkage},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling product’s visual and functional characteristics for
recommender systems. <em>TKDE</em>, <em>34</em>(3), 1330–1343. (<a
href="https://doi.org/10.1109/TKDE.2020.2991793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An effective recommender system can significantly help customers to find desired products and assist business owners to earn more income. Nevertheless, the decision-making process of users is highly complex, not only dependent on the personality and preference of a user, but also complicated by the characteristics of a specific product. For example, for products of different domains (e.g., clothing versus office products), the product aspects that affect a user’s decision are very different. As such, traditional collaborative filtering methods that model only user-item interaction data would deliver unsatisfactory recommendation results. In this work, we focus on fine-grained modeling of product characteristics to improve recommendation quality. Specifically, we first divide a product’s characteristics into visual and functional aspects—i.e., the visual appearance and functionality of the product. One insight is that, the visual characteristic is very important for products of visually-aware domain (e.g., clothing), while the functional characteristic plays a more crucial role for visually non-aware domain (e.g., office products). We then contribute a novel probabilistic model, named Visual and Functional Probabilistic Matrix Factorization (VFPMF), to unify the two factors to estimate user preferences on products. Nevertheless, such an expressive model poses efficiency challenge in parameter learning from implicit feedback. To address the technical challenge, we devise a computationally efficient learning algorithm based on alternating least squares. Furthermore, we provide an online updating procedure of the algorithm, shedding some light on how to adapt our method to real-world recommendation scenario where data continuously streams in. Extensive experiments on four real-word datasets demonstrate the effectiveness of our method with both offline and online protocols.},
  archive      = {J_TKDE},
  author       = {Bin Wu and Xiangnan He and Yun Chen and Liqiang Nie and Kai Zheng and Yangdong Ye},
  doi          = {10.1109/TKDE.2020.2991793},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1330-1343},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Modeling product’s visual and functional characteristics for recommender systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mg2vec: Learning relationship-preserving heterogeneous graph
representations via metagraph embedding. <em>TKDE</em>, <em>34</em>(3),
1317–1329. (<a href="https://doi.org/10.1109/TKDE.2020.2992500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given that heterogeneous information networks (HIN) encompass nodes and edges belonging to different semantic types, they can model complex data in real-world scenarios. Thus, HIN embedding has received increasing attention, which aims to learn node representations in a low-dimensional space, in order to preserve the structural and semantic information on the HIN. In this regard, metagraphs, which model common and recurring patterns on HINs, emerge as a powerful tool to capture semantic-rich and often latent relationships on HINs. Although metagraphs have been employed to address several specific data mining tasks, they have not been thoroughly explored for the more general HIN embedding. In this paper, we leverage metagraphs to learn relationship-preserving HIN embedding in a self-supervised setting, to support various relationship mining tasks. In particular, we observe that most of the current approaches often under-utilize metagraphs, which are only applied in a pre-processing step and do not actively guide representation learning afterwards. Thus, we propose the novel framework of mg2vec, which learns the embeddings for metagraphs and nodes jointly. That is, metagraphs actively participates in the learning process by mapping themselves to the same embedding space as the nodes do. Moreover, metagraphs guide the learning through both first- and second-order constraints on node embeddings, to model not only latent relationships between a pair of nodes, but also individual preferences of each node. Finally, we conduct extensive experiments on three public datasets. Results show that mg2vec significantly outperforms a suite of state-of-the-art baselines in relationship mining tasks including relationship prediction, search and visualization.},
  archive      = {J_TKDE},
  author       = {Wentao Zhang and Yuan Fang and Zemin Liu and Min Wu and Xinming Zhang},
  doi          = {10.1109/TKDE.2020.2992500},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1317-1329},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Mg2vec: Learning relationship-preserving heterogeneous graph representations via metagraph embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MAB-based reinforced worker selection framework for budgeted
spatial crowdsensing. <em>TKDE</em>, <em>34</em>(3), 1303–1316. (<a
href="https://doi.org/10.1109/TKDE.2020.2992531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial crowdsensing is a special kind of crowdsourcing which allocates tasks to workers in some special places where workers can sense data for them. Due to the lack of priori information about the quality of workers and the ground truth, selecting the most suitable workers, which can guarantee the quality of the sensing tasks, remains a great challenge. In this paper, we propose a novel framework which can choose the most reliable workers among available workers under constraint budget. We model the quality of workers through two factors, bias and variance, which describe the continuous feature of sensing tasks. Our framework first allocate some calibration tasks to calibrate the bias and then iteratively estimate the workers variance more and more accurately. To choose more reliable workers, we face the exploration and exploitation dilemma. Therefore, we design a novel Multi-Armed Bandit (MAB) algorithm which based on Upper Confidence Bounds (UCB) scheme and combined with a weighted data aggregation scheme to estimate a more accurate ground truth of a sensing task. Futhermore, a dynamic budget allocation algorithm is designed to achieve global optimization. Then, we prove the expected sensing error can be bounded according to the regret bound of the MAB. In simulation experiments, we compare our algorithm with several baselines with real-world data set and it shows the effectiveness in inferring the ground truth with limited budget.},
  archive      = {J_TKDE},
  author       = {Xiaofeng Gao and Shenwei Chen and Guihai Chen},
  doi          = {10.1109/TKDE.2020.2992531},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1303-1316},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MAB-based reinforced worker selection framework for budgeted spatial crowdsensing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging currency for repairing inconsistent and
incomplete data. <em>TKDE</em>, <em>34</em>(3), 1288–1302. (<a
href="https://doi.org/10.1109/TKDE.2020.2992456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data quality plays a key role in big data management today. With the explosive growth of data from a variety of sources, the quality of data is faced with multiple problems. Motivated by this, we study the multiple data cleaning on incompleteness and inconsistency with currency reasoning and determination in this paper. We introduce a 4-step framework, named ${\sf Imp3C}$ , for errors detection and quality improvement in incomplete and inconsistent data without timestamps. We achieve an integrated currency determining method to compute the currency orders among tuples, according to currency constraints. Thus, the inconsistent data and missing values are repaired effectively considering the temporal impact. For both effectiveness and efficiency consideration, we carry out inconsistency repair ahead of incompleteness repair. A currency-related consistency distance metric is defined to measure the similarity between dirty tuples and clean ones more accurately. In addition, currency orders are treated as an important feature in the missing imputation training process. The solution algorithms are introduced in detail with case studies. A thorough experiment on three real-life datasets verifies our method ${\sf Imp3C}$ improves the performance of data repairing with multiple quality problems. ${\sf Imp3C}$ outperforms the existing advanced methods, especially in the datasets with complex currency orders.},
  archive      = {J_TKDE},
  author       = {Xiaoou Ding and Hongzhi Wang and Jiaxuan Su and Muxian Wang and Jianzhong Li and Hong Gao},
  doi          = {10.1109/TKDE.2020.2992456},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1288-1302},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Leveraging currency for repairing inconsistent and incomplete data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint learning of user representation with diffusion
sequence and network structure. <em>TKDE</em>, <em>34</em>(3),
1275–1287. (<a href="https://doi.org/10.1109/TKDE.2020.2995075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information sharing behavior and social link building behavior have shown strong correlation on social media. The aim of this article is to explore this correlation for simultaneously modeling and predicting sharing behavior in information diffusion sequences and linking behavior in social network, which correspond to information diffusion prediction and social link prediction problems. To achieve this goal, we propose a joint user representation learning model to characterize the two correlated behaviors in a shared latent space. The proposed model learns user representations via two maximum likelihood estimation objectives defined on observed information diffusion sequences and social network structure respectively and incorporates them in a unified framework. A multi-task learning algorithm is designed for efficient model optimization. Based on the learned representations, the model can be directly applied to predicting diffusion processes and inferring unobserved social links at the same time. We evaluate the proposed model on two real social media datasets with extensive experiments. The model consistently achieves significant improvements over the state-of-the-art approaches on diffusion prediction and link prediction tasks. The better robustness of our model in further ablation studies demonstrates that capturing the behavior correlation in the shared representation space is beneficial.},
  archive      = {J_TKDE},
  author       = {Zhitao Wang and Chengyao Chen and Wenjie Li},
  doi          = {10.1109/TKDE.2020.2995075},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1275-1287},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Joint learning of user representation with diffusion sequence and network structure},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Item concept network: Towards concept-based item
representation learning. <em>TKDE</em>, <em>34</em>(3), 1258–1274. (<a
href="https://doi.org/10.1109/TKDE.2020.2995859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Item concept modeling is commonly achieved by leveraging textual information. However, many existing models do not leverage the inferential property of concepts to capture word meanings, which therefore ignores the relatedness between correlated concepts, a phenomenon which we term conceptual “correlation sparsity.” In this paper, we distinguish between word modeling and concept modeling and propose an item concept modeling framework centering around the item concept network (ICN). ICN models and further enriches item concepts by leveraging the inferential property of concepts and thus addresses the correlation sparsity issue. Specifically, there are two stages in the proposed framework: ICN construction and embedding learning. In the first stage, we propose a generalized network construction method to build ICN, a structured network which infers expanded concepts for items via matrix operations. The second stage leverages neighborhood proximity to learn item and concept embeddings. With the proposed ICN, the resulting embedding facilitates both homogeneous and heterogeneous tasks, such as item-to-item and concept-to-item retrieval, and delivers related results which are more diverse than traditional keyword-matching-based approaches. As our experiments on two real-world datasets show, the framework encodes useful conceptual information and thus outperforms traditional methods in various item classification and retrieval tasks.},
  archive      = {J_TKDE},
  author       = {Ting-Hsiang Wang and Hsiu-Wei Yang and Chih-Ming Chen and Ming-Feng Tsai and Chuan-Ju Wang},
  doi          = {10.1109/TKDE.2020.2995859},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1258-1274},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Item concept network: Towards concept-based item representation learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). G-PICS: A framework for GPU-based spatial indexing and query
processing. <em>TKDE</em>, <em>34</em>(3), 1243–1257. (<a
href="https://doi.org/10.1109/TKDE.2020.2992440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support for efficient spatial data storage and retrieval has become a vital component in almost all spatial database systems. While GPUs have become a mainstream platform for high-throughput data processing in recent years, exploiting the massively parallel processing power of GPUs is non-trivial. Current approaches that parallelize one query at a time have low work efficiency and cannot make good use of GPU resources. On the other hand, many spatial database systems could receive a large number of queries simultaneously. In this paper, we present a comprehensive framework named G-PICS for parallel processing of concurrent spatial queries on GPUs. G-PICS encapsulates efficient parallel algorithms for constructing a variety of spatial trees with different space partitioning methods. G-PICS also provides highly optimized programs for processing major spatial query types, and such programs can be accessed via an API that could be further extended to implement user-defined algorithms. While support for dynamic data inputs is missing in existing work, G-PICS implements efficient parallel algorithms for bulk updates of data. Furthermore, G-PICS is designed to work in a Multi-GPU environment to support datasets beyond the size of a single GPU’s global memory. Empirical evaluation of G-PICS shows significant performance improvement over the state-of-the-art GPU and parallel CPU-based spatial query processing systems. In particular, G-PICS achieves double-digit speedup over such systems in tree construction (up to 53X) and query processing (up to 80X).},
  archive      = {J_TKDE},
  author       = {Zhila-Nouri Lewis and Yi-Cheng Tu},
  doi          = {10.1109/TKDE.2020.2992440},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1243-1257},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {G-PICS: A framework for GPU-based spatial indexing and query processing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GBNRS: A novel rough set algorithm for fast adaptive
attribute reduction in classification. <em>TKDE</em>, <em>34</em>(3),
1231–1242. (<a href="https://doi.org/10.1109/TKDE.2020.2997039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature reduction is an important aspect of Big Data analytics on today’s ever-larger datasets. Rough sets are a classical method widely applied in attribute reduction. Most rough set algorithms use the priori domain knowledge of a dataset to process continuous attributes through using a membership function. Neighborhood rough sets (NRS) replace the membership function with the concept of neighborhoods, allowing NRS to handle scenarios where no a priori knowledge is available. However, the neighborhood radius of each object in NRS is fixed, and the optimization of the radius depends on grid searching. This diminishes both the efficiency and effectiveness, leading to a time complexity of not lower than $O(N^2)$ . To resolve these limitations, granular ball neighborhood rough sets (GBNRS), a novel NRS method with time complexity $O(N)$ , is proposed. GBNRS adaptively generates a different neighborhood for each object, resulting in greater generality and flexibility in comparison to standard NRS methods. GBNRS is compared with the current state-of-the-art NRS method, FARNeMF, and find that GBNRS obtains both higher performance and higher classification accuracy on public benchmark datasets. All code has been released in the open source GBNRS library at http://www.cquptshuyinxia.com/GBNRS.html .},
  archive      = {J_TKDE},
  author       = {Shuyin Xia and Hao Zhang and Wenhua Li and Guoyin Wang and Elisabeth Giem and Zizhong Chen},
  doi          = {10.1109/TKDE.2020.2997039},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1231-1242},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GBNRS: A novel rough set algorithm for fast adaptive attribute reduction in classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fuzzy k-means clustering with discriminative embedding.
<em>TKDE</em>, <em>34</em>(3), 1221–1230. (<a
href="https://doi.org/10.1109/TKDE.2020.2995748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy K-Means (FKM) clustering is of great importance for analyzing unlabeled data. FKM algorithms assign each data point to multiple clusters with some degree of certainty measured by the membership function. In these methods, the fuzzy membership degree matrix is obtained based on the calculation of the distance between data points in the original space. However, this operation may lead to suboptimal results because of the influence of noises and redundant features. Besides, some FKM clustering methods ignore the importance of the weighting exponent. In this paper, we propose a novel FKM method called Fuzzy K-Means Clustering With Discriminative Embedding. Within this method, we simultaneously conduct dimensionality reduction along with fuzzy membership degree learning. To retain most information in the embedding subspace and improve the robustness of this method, principal component analysis is incorporated into our framework. An iterative optimization algorithm is proposed to solve the model. To validate the efficacy of the proposed method, we perform comprehensive analyses, including convergence behavior, parameter determination and computational complexity. Moreover, we also match a appropriate weighting exponent for each data set. Experimental results on benchmark data sets show that the proposed method is more discriminative and effective for clustering tasks.},
  archive      = {J_TKDE},
  author       = {Feiping Nie and Xiaowei Zhao and Rong Wang and Xuelong Li and Zhihui Li},
  doi          = {10.1109/TKDE.2020.2995748},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1221-1230},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fuzzy K-means clustering with discriminative embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Evolutionary markov dynamics for network community
detection. <em>TKDE</em>, <em>34</em>(3), 1206–1220. (<a
href="https://doi.org/10.1109/TKDE.2020.2997043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community structure division is a crucial problem in the field of network data analysis. Algorithms based on Markov chains are easy to use and provide promising solutions for community detection. In a Markov chain-based algorithm (i.e., MCL), a flow distribution matrix and a transition matrix are used to describe stochastic flows and transition probabilities, respectively, on a network. The dynamic interaction process between stochastic flows and transition probabilities in MCLs is manifested through an iterative process of updating the abovementioned two matrices. As one of the key mechanisms of MCLs, such a dynamic process for increasing the inhomogeneity directly affects the accuracy and computational cost of MCL-based methods. Inspired by a kind of positive feedback interaction of a dendritic network of tube-like amoeba cell pseudopodia (named the Physarum foraging network), a Physarum -inspired relationship among vertices is proposed to enhance the transition probability in the dynamic process of MCL-based community detection algorithms. Specifically, the proposed hybrid community detection algorithm can adaptively search for a better combination of parameters based on a genetic algorithm. Some experiments are carried out on both static and dynamic networks. The results show that the unique Physarum inspired algorithm achieved better computational efficiency and detection performance than other algorithms.},
  archive      = {J_TKDE},
  author       = {Zhen Wang and Chunyu Wang and Xianghua Li and Chao Gao and Xuelong Li and Junyou Zhu},
  doi          = {10.1109/TKDE.2020.2997043},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1206-1220},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Evolutionary markov dynamics for network community detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluating public anxiety for topic-based communities in
social networks. <em>TKDE</em>, <em>34</em>(3), 1191–1205. (<a
href="https://doi.org/10.1109/TKDE.2020.2989759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although individual anxiety evaluation has been well studied, there is still not much work on evaluating public anxiety of groups, especially in the form of communities on social networks, which can be leveraged to detect mental healthness of a society. However, we cannot simply average individual anxiety scores to evaluate a community&#39;s public anxiety, because following factors should be considered: (1) impacts from interpersonal relations on each individual group member&#39;s anxiety levels (the ${\tt Structural}$ component); (2) topic-based discussions which reflect a community&#39;s anxiety status (the ${\tt Topical}$ component). In this paper, we initiate the study of evaluating public anxiety of Topic-based Social Network Communities ( $\textsc {TSNC}$ ). We propose an evaluation framework to project the anxiety level of a $\textsc {TSNC}$ into a score in the [0,1] range. We devise a cascading model to dynamically compute the individual anxiety scores using the ${\tt Structural}$ influence. We design a probabilistic model to measure anxiety score of social network messages using a generalized user, and compose a tree structure ( ${\tt MC}$ - ${\tt Tree}$ ) to effectively compute the anxiety score of a $\textsc {TSNC}$ from the ${\tt Topical}$ aspect. For large communities, to avoid expensive real-time computing, we use a small sample to compute the public anxiety within given confidence interval. The effectiveness of our model are verified by precision and recall in an empirical study on real-world Weibo and Twitter data sets.},
  archive      = {J_TKDE},
  author       = {Na Ta and Kaiyu Li and Yi Yang and Fang Jiao and Zheng Tang and Guoliang Li},
  doi          = {10.1109/TKDE.2020.2989759},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1191-1205},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Evaluating public anxiety for topic-based communities in social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhanced discrete multi-modal hashing: More constraints yet
less time to learn. <em>TKDE</em>, <em>34</em>(3), 1177–1190. (<a
href="https://doi.org/10.1109/TKDE.2020.2995195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the exponential growth of multimedia data, multi-modal hashing as a promising technique to make cross-view retrieval scalable is attracting more and more attention. However, most of the existing multi-modal hashing methods either divide the learning process unnaturally into two separate stages or treat the discrete optimization problem simplistically as a continuous one, which leads to suboptimal results. Recently, a few discrete multi-modal hashing methods that try to address such issues have emerged, but they still ignore several important discrete constraints (such as the balance and decorrelation of hash bits). In this paper, we overcome those limitations by proposing a novel method named “Enhanced Discrete Multi-modal Hashing (EDMH)” which learns binary codes and hashing functions simultaneously from the pairwise similarity matrix of data, under the aforementioned discrete constraints. Although the model of EDMH looks a lot more complex than the other models for multi-modal hashing, we are actually able to develop a fast iterative learning algorithm for it, since the subproblems of its optimization all have closed-form solutions after introducing a couple of auxiliary variables. Our experimental results on three real-world datasets have revealed the usefulness of those previously ignored discrete constraints and demonstrated that EDMH not only performs much better than state-of-the-art competitors according to several retrieval metrics but also runs much faster than most of them.},
  archive      = {J_TKDE},
  author       = {Yong Chen and Hui Zhang and Zhibao Tian and Jun Wang and Dell Zhang and Xuelong Li},
  doi          = {10.1109/TKDE.2020.2995195},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1177-1190},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Enhanced discrete multi-modal hashing: More constraints yet less time to learn},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Encoding high-cardinality string categorical variables.
<em>TKDE</em>, <em>34</em>(3), 1164–1176. (<a
href="https://doi.org/10.1109/TKDE.2020.2992529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical models usually require vector representations of categorical variables, using for instance one-hot encoding . This strategy breaks down when the number of categories grows, as it creates high-dimensional feature vectors. Additionally, for string entries, one-hot encoding does not capture morphological information in their representation. Here, we seek low-dimensional encoding of high-cardinality string categorical variables. Ideally, these should be: scalable to many categories; interpretable to end users; and facilitate statistical analysis. We introduce two encoding approaches for string categories: a Gamma-Poisson matrix factorization on substring counts, and a min-hash encoder , for fast approximation of string similarities. We show that min-hash turns set inclusions into inequality relations that are easier to learn. Both approaches are scalable and streamable. Experiments on real and simulated data show that these methods improve supervised learning with high-cardinality categorical variables. We recommend the following: if scalability is central, the min-hash encoder is the best option as it does not require any data fit; if interpretability is important, the Gamma-Poisson factorization is the best alternative, as it can be interpreted as one-hot encoding on inferred categories with informative feature names. Both models enable autoML on string entries as they remove the need for feature engineering or data cleaning.},
  archive      = {J_TKDE},
  author       = {Patricio Cerda and Gaël Varoquaux},
  doi          = {10.1109/TKDE.2020.2992529},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1164-1176},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Encoding high-cardinality string categorical variables},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient shapelet discovery for time series classification.
<em>TKDE</em>, <em>34</em>(3), 1149–1163. (<a
href="https://doi.org/10.1109/TKDE.2020.2995870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series shapelets are discriminative subsequences, recently found effective for time series classification ( tsc ). It is evident that the quality of shapelets is crucial to the accuracy of tsc . However, major research has focused on building accurate models from some shapelet candidates. To determine such candidates, existing studies are surprisingly simple, e.g., enumerating subsequences of some fixed lengths, or randomly selecting some subsequences as shapelet candidates. The major bulk of computation is then on building the model from the candidates. In this paper, we propose a novel efficient shapelet discovery method, called bspcover , to discover a set of high-quality shapelet candidates for model building. Specifically, bspcover generates abundant candidates via Symbolic Aggregate approXimation with sliding window, then prunes identical and highly similar candidates via Bloom filters , and similarity matching , respectively. We next propose a $p$p-Cover algorithm to efficiently determine discriminative shapelet candidates that maximally represent each time-series class. Finally, any existing shapelet learning method can be adopted to build a classification model. We have conducted extensive experiments with well-known time-series datasets and representative state-of-the-art methods. Results show that bspcover speeds up the state-of-the-art methods by more than 70 times, and the accuracy is often comparable to or higher than existing works.},
  archive      = {J_TKDE},
  author       = {Guozhong Li and Byron Choi and Jianliang Xu and Sourav S Bhowmick and Kwok-Pan Chun and Grace Lai-Hung Wong},
  doi          = {10.1109/TKDE.2020.2995870},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1149-1163},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient shapelet discovery for time series classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient regular expression matching based on positional
inverted index. <em>TKDE</em>, <em>34</em>(3), 1133–1148. (<a
href="https://doi.org/10.1109/TKDE.2020.2992295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the efficient regular expression (regex) matching problem. Existing algorithms are the scanning-based algorithms which typically use an equivalent automaton compiled from the regex query to verify a document. Although some works propose various strategies to quickly jump to candidate locations in a document where a query result may appear, they still need to utilize the scanning-based method to verify these candidate locations. These methods become inefficient when there are still many candidate locations needed to be verified. In this article, we propose a novel approach to efficiently compute all matching positions for a regex query purely based on a positional $q$ -gram inverted index. We propose a gram-driven NFA to represent the language of a regex and show all regex matching locations can be obtained by finding positions on $q$ -grams of GNFA that satisfy certain positional constraints. Then we propose several GNFA-based query plans to answer the query using the positional inverted index. In order to improve the query efficiency, we design the algorithm to build a tree-based query plan by carefully choosing a checking order for positional constraints. Experimental results on real-world datasets show that our method outperforms state-of-the-art methods by up to an order of magnitude in query efficiency.},
  archive      = {J_TKDE},
  author       = {Tao Qiu and Xiaochun Yang and Bin Wang and Wei Wang},
  doi          = {10.1109/TKDE.2020.2992295},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1133-1148},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Efficient regular expression matching based on positional inverted index},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic heterogeneous information network embedding with
meta-path based proximity. <em>TKDE</em>, <em>34</em>(3), 1117–1132. (<a
href="https://doi.org/10.1109/TKDE.2020.2993870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information network (HIN) embedding aims at learning the low-dimensional representation of nodes while preserving structure and semantics in a HIN. Existing methods mainly focus on static networks, while a real HIN usually evolves over time with the addition (deletion) of multiple types of nodes and edges. Because even a tiny change can influence the whole structure and semantics, the conventional HIN embedding methods need to be retrained to get the updated embeddings, which is time-consuming and unrealistic. In this paper, we investigate the problem of dynamic HIN embedding and propose a novel Dynamic HIN Embedding model (DyHNE) with meta-path based proximity. Specifically, we introduce the meta-path based first- and second-order proximities to preserve structure and semantics in HINs. As the HIN evolves over time, we naturally capture changes with the perturbation of meta-path augmented adjacency matrices. Thereafter, we learn the node embeddings by solving generalized eigenvalue problem effectively and employ eigenvalue perturbation to derive the updated embeddings efficiently without retraining. Experiments show that DyHNE outperforms the state-of-the-arts in terms of effectiveness and efficiency.},
  archive      = {J_TKDE},
  author       = {Xiao Wang and Yuanfu Lu and Chuan Shi and Ruijia Wang and Peng Cui and Shuai Mou},
  doi          = {10.1109/TKDE.2020.2993870},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1117-1132},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Dynamic heterogeneous information network embedding with meta-path based proximity},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Database meets artificial intelligence: A survey.
<em>TKDE</em>, <em>34</em>(3), 1096–1116. (<a
href="https://doi.org/10.1109/TKDE.2020.2994641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Database and Artificial Intelligence (AI) can benefit from each other. On one hand, AI can make database more intelligent (AI4DB). For example, traditional empirical database optimization techniques (e.g., cost estimation, join order selection, knob tuning, index and view selection) cannot meet the high-performance requirement for large-scale database instances, various applications and diversified users, especially on the cloud. Fortunately, learning-based techniques can alleviate this problem. On the other hand, database techniques can optimize AI models (DB4AI). For example, AI is hard to deploy in real applications, because it requires developers to write complex codes and train complicated models. Database techniques can be used to reduce the complexity of using AI models, accelerate AI algorithms and provide AI capability inside databases. Thus both DB4AI and AI4DB have been extensively studied recently. In this article, we review existing studies on AI4DB and DB4AI. For AI4DB, we review the techniques on learning-based configuration tuning, optimizer, index/view advisor, and security. For DB4AI, we review AI-oriented declarative language, AI-oriented data governance, training acceleration, and inference acceleration. Finally, we provide research challenges and future directions.},
  archive      = {J_TKDE},
  author       = {Xuanhe Zhou and Chengliang Chai and Guoliang Li and Ji Sun},
  doi          = {10.1109/TKDE.2020.2994641},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1096-1116},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Database meets artificial intelligence: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-network skip-gram embedding for joint network
alignment and link prediction. <em>TKDE</em>, <em>34</em>(3), 1080–1095.
(<a href="https://doi.org/10.1109/TKDE.2020.2997861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction and network alignment are two fundamental and interleaved tasks in network analysis. In this paper, we propose a novel cross-network embedding model under the Skip-gram framework, which alternately performs link prediction and network alignment by joint optimization. Vertex sequences, obtained via a biased random walk based on empirical mixture distributions, are used to train a Skip-gram based node embedding model. On one hand, based on the similarity in embedding space, network alignment can be effectively performed either with the initial ground truth alignments as seeds or from scratch. On the other hand, the proposed link prediction model involves training a supervised classifier by sampling a set of positive and negative edges. We also modify and incorporate the Collective Link Fusion (CLF) method under a Skip-gram framework and show that the new method can achieve better results in both tasks. Extensive experimental results show the state-of-the-art performance of our methods.},
  archive      = {J_TKDE},
  author       = {Xingbo Du and Junchi Yan and Rui Zhang and Hongyuan Zha},
  doi          = {10.1109/TKDE.2020.2997861},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1080-1095},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cross-network skip-gram embedding for joint network alignment and link prediction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Capri: Consensus accelerated proximal reweighted iteration
for a class of nonconvex minimizations. <em>TKDE</em>, <em>34</em>(3),
1066–1079. (<a href="https://doi.org/10.1109/TKDE.2020.2989393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of nonconvex regularized optimization problems, which appear frequently in machine learning and data processing. Due to the structure of the problems, the iteratively reweighted algorithm was developed and applied to the consensus optimization. In this paper, we propose the acceleration of this scheme by adding an inertial term in each iteration. The proposed algorithms inherit the advantages of classical decentralized algorithms: they can be implemented over a connected network, in which the agents communicate with their neighbors and perform local computations. We also employ the diminishing stepsizes technique for the iteratively reweighted algorithm and consider its acceleration. In specific cases, our algorithms reduce to existing decentralized schemes and also indicate novel ones. Mathematically, we prove the convergence for both algorithms with several assumptions on the objective functions. With Kurdyka-Łojasiewicz property, convergence rates can be derived for constant stepsize case. Numerical results demonstrate the efficiency of the algorithms.},
  archive      = {J_TKDE},
  author       = {Tao Sun and Dongsheng Li},
  doi          = {10.1109/TKDE.2020.2989393},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1066-1079},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Capri: Consensus accelerated proximal reweighted iteration for a class of nonconvex minimizations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BrePartition: Optimized high-dimensional kNN search with
bregman distances. <em>TKDE</em>, <em>34</em>(3), 1053–1065. (<a
href="https://doi.org/10.1109/TKDE.2020.2992594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bregman distances (also known as Bregman divergences) are widely used in machine learning, speech recognition and signal processing, and k NN searches with Bregman distances have become increasingly important with the rapid advances of multimedia applications. Data in multimedia applications such as images and videos are commonly transformed into space of hundreds of dimensions. Such high-dimensional space has posed significant challenges for existing k NN search algorithms with Bregman distances, which could only handle data of medium dimensionality (typically less than 100). This paper addresses the urgent problem of high-dimensional k NN search with Bregman distances. We propose a novel partition-filter-refinement framework. Specifically, we propose an optimized dimensionality partitioning scheme to solve several non-trivial issues. First, an effective bound from each partitioned subspace to obtain exact k NN results is derived. Second, we conduct an in-depth analysis of the optimized number of partitions and devise an effective strategy for partitioning. Third, we design an efficient integrated index structure for all the subspaces together to accelerate the search processing. Moreover, we extend our exact solution to an approximate version by a trade-off between the accuracy and efficiency. Experimental results on four real-world datasets and two synthetic datasets show the clear advantage of our method in comparison to state-of-the-art algorithms.},
  archive      = {J_TKDE},
  author       = {Yang Song and Yu Gu and Rui Zhang and Ge Yu},
  doi          = {10.1109/TKDE.2020.2992594},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1053-1065},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {BrePartition: Optimized high-dimensional kNN search with bregman distances},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An effective imbalanced JPEG steganalysis scheme based on
adaptive cost-sensitive feature learning. <em>TKDE</em>, <em>34</em>(3),
1038–1052. (<a href="https://doi.org/10.1109/TKDE.2020.2995070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steganalysis in real-world application often exhibit skewed sample distribution which poses a massive challenge for steganography detection. Conventional steganalysis algorithms are not effective when the training data distribution is imbalanced, and may fail in the scenario of imbalanced data distribution. To address imbalanced data distribution issue in steganalysis, a novel framework termed adaptive cost-sensitive feature learning via F-measure maximization is proposed, which is inspired by the fact that F-measure is a more suitable performance metric compared to accuracy for imbalanced data. We investigate the adaptive cost-sensitive strategy by generating and assigning different weight to each instance with misclassification occurrence. This scheme adaptively determines the weights according to the intra-class and inter-class costs from the imbalanced distribution. Features corresponding to the largest F-measure can be obtained by solving a series of adaptive cost-sensitive feature learning problems with optimization theory. In this way, the learned features are the most representative features between the cover and stego images so that imbalanced steganalysis can significantly alleviate. Extensive experiments on various imbalanced steganalysis tasks show the superiority of the proposed method over the state-of-the-art methods, and it can recognize more minority samples and has excellent classification performance.},
  archive      = {J_TKDE},
  author       = {Ju Jia and Liming Zhai and Weixiang Ren and Lina Wang and Yanzhen Ren},
  doi          = {10.1109/TKDE.2020.2995070},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1038-1052},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An effective imbalanced JPEG steganalysis scheme based on adaptive cost-sensitive feature learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A self-play and sentiment-emphasized comment integration
framework based on deep q-learning in a crowdsourcing scenario.
<em>TKDE</em>, <em>34</em>(3), 1021–1037. (<a
href="https://doi.org/10.1109/TKDE.2020.2993272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing is a hotspot research field which can facilitate machine learning by collecting labels to train models. Consequently, the state-of-the-art research efforts in crowdsourcing focus on truth inference or label integration, to remove inconsistent labels or to alleviate biased labeling. In turn, the integrated labels will be used to fine-tune machine learning models. Particularly, in this paper, we change the target of truth inference in crowdsourcing from discrete labels to multiple comments given by online participants, that is, the integration of the crowdsourced comments. For such a goal, we propose a S elf-play and S entiment- E mphasized C omment I ntegration F ramework (SSECIF), based on deep Q -learning, with three unique features. First, our framework SSECIF can generate the comment integration in a totally self-play way, without relying on the ground truth generated by human effort. Second, the integrated comment generated by SSECIF can include salient content with low redundancy. Third, the proposed framework SSECIF has emphasized, with a higher intensity, the sentiment in the integrated comment, in order to reflect the attitude or opinion more obviously. Extensive evaluation on real-world datasets demonstrates that SSECIF has achieved the best overall performance in terms of both effectiveness and efficiency, compared with the state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Huan Rong and Victor S. Sheng and Tinghuai Ma and Yang Zhou and Mznah Al-Rodhaan},
  doi          = {10.1109/TKDE.2020.2993272},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1021-1037},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A self-play and sentiment-emphasized comment integration framework based on deep Q-learning in a crowdsourcing scenario},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A new linguistic petri net for complex knowledge
representation and reasoning. <em>TKDE</em>, <em>34</em>(3), 1011–1020.
(<a href="https://doi.org/10.1109/TKDE.2020.2997175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Petri nets (FPNs) are a useful instrument for modelling expert systems to conduct knowledge representation and reasoning. Many studies have been carried out for improving the performance of FPNs in terms of their accurate representation of knowledge and power of approximate reasoning. Nevertheless, the current representation methods with FPNs are unable to handle the uncertain linguistic knowledge given by domain experts and the reliability of their judgments. In addition, the existing reasoning algorithms have no way to capture the interrelationship of the propositions with the same output transition. Therefore, we present a new type of FPNs, called 2-dimensional uncertain linguistic Petri nets (2DULPNs). The 2-dimensional uncertain linguistic variables (2DULVs) and Choquet integral are combined for knowledge representation and reasoning for the first time. The truth degrees of propositions, thresholds and certainty values of linguistic production rules are denoted as 2DULVs. Some new aggregated operators based on Choquet integral are proposed and used in the approximate reasoning to capture the interactions among antecedent propositions. Finally, an equipment fault diagnosis example is provided to illustrate the correctness and effectiveness of the proposed 2DULPN model.},
  archive      = {J_TKDE},
  author       = {Hu-Chen Liu and Xue Luan and MengChu Zhou and Yun Xiong},
  doi          = {10.1109/TKDE.2020.2997175},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {3},
  pages        = {1011-1020},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A new linguistic petri net for complex knowledge representation and reasoning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VERTICOX: Vertically distributed cox proportional hazards
model using the alternating direction method of multipliers.
<em>TKDE</em>, <em>34</em>(2), 996–1010. (<a
href="https://doi.org/10.1109/TKDE.2020.2989301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cox proportional hazards model is a popular semi-parametric model for survival analysis. In this paper, we aim at developing a federated algorithm for the Cox proportional hazards model over vertically partitioned data (i.e., data from the same patient are stored at different institutions). We propose a novel algorithm, namely VERTICOX, to obtain the global model parameters in a distributed fashion based on the Alternating Direction Method of Multipliers (ADMM) framework. The proposed model computes intermediary statistics and exchanges them to calculate the global model without collecting individual patient-level data. We demonstrate that our algorithm achieves equivalent accuracy for the estimation of model parameters and statistics to that of its centralized realization. The proposed algorithm converges linearly under the ADMM framework. Its computational complexity and communication costs are polynomially and linearly associated with the number of subjects, respectively. Experimental results show that VERTICOX can achieve accurate model parameter estimation to support federated survival analysis over vertically distributed data by saving bandwidth and avoiding exchange of information about individual patients. The source code for VERTICOX is available at: https://github.com/daiwenrui/VERTICOX .},
  archive      = {J_TKDE},
  author       = {Wenrui Dai and Xiaoqian Jiang and Luca Bonomi and Yong Li and Hongkai Xiong and Lucila Ohno-Machado},
  doi          = {10.1109/TKDE.2020.2989301},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {996-1010},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {VERTICOX: Vertically distributed cox proportional hazards model using the alternating direction method of multipliers},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variable-length subsequence clustering in time series.
<em>TKDE</em>, <em>34</em>(2), 983–995. (<a
href="https://doi.org/10.1109/TKDE.2020.2986965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsequence clustering is an important issue in time series data mining. Observing that most time series consist of various patterns with different unknown lengths, we propose an optimization framework to adaptively estimate the lengths and representations for different patterns. Our framework minimizes the inner subsequence cluster errors with respect to subsequence clusters and segmentation under time series cover constraint where the subsequence cluster lengths can be variable. To optimize our framework, we first generate abundant initial subsequence clusters with different lengths. Then, three cluster operations, i.e., cluster splitting, combination and removing, are used to iteratively refine the cluster lengths and representations by respectively splitting clusters consisting of different patterns, joining neighboring clusters belonging to the same pattern and removing clusters to the predefined cluster number. During each cluster refinement, we employ an efficient algorithm to alternatively optimize subsequence clusters and segmentation based on dynamic programming. Our method can automatically and efficiently extract the unknown variable-length subsequence clusters in the time series. Comparative results with the state-of-the-art are conducted on various synthetic and real time series, and quantitative and qualitative performances demonstrate the effectiveness of our method.},
  archive      = {J_TKDE},
  author       = {Jiangyong Duan and Lili Guo},
  doi          = {10.1109/TKDE.2020.2986965},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {983-995},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Variable-length subsequence clustering in time series},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using randomness to improve robustness of tree-based models
against evasion attacks. <em>TKDE</em>, <em>34</em>(2), 969–982. (<a
href="https://doi.org/10.1109/TKDE.2020.2987299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models have been widely used in security applications. However, it is well-known that adversaries can adapt their attacks to evade detection. There has been some work on making machine learning models more robust to such attacks. However, one simple but promising approach called randomization is under-explored. In addition, most existing works focus on models with differentiable error functions while tree-based models do not have such error functions but are quite popular because they are easy to interpret. This paper proposes a novel randomization-based approach to improve robustness of tree-based models against evasion attacks. The proposed approach incorporates randomization into both model training time and model application time (meaning when the model is used to detect attacks). We also apply this approach to random forest, an existing ML method which already has incorporated randomness at training time but still often fails to generate robust models. We proposed a novel weighted-random-forest method to generate more robust models and a clustering method to add randomness at model application time. We also proposed a theoretical framework to provide a lower bound for adversaries’ effort. Experiments on intrusion detection and spam filtering data show that our approach further improves robustness of random-forest method.},
  archive      = {J_TKDE},
  author       = {Fan Yang and Zhiyuan Chen and Aryya Gangopadhyay},
  doi          = {10.1109/TKDE.2020.2987299},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {969-982},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Using randomness to improve robustness of tree-based models against evasion attacks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User identity linkage via co-attentive neural network from
heterogeneous mobility data. <em>TKDE</em>, <em>34</em>(2), 954–968. (<a
href="https://doi.org/10.1109/TKDE.2020.2989732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online services are playing critical roles in almost all aspects of users’ life. Users usually have multiple online identities (IDs) in different online services. In order to fuse the separated user data in multiple services for better business intelligence, it is critical for service providers to link online IDs belonging to the same user. On the other hand, the popularity of mobile networks and GPS-equipped smart devices have provided a generic way to link IDs, i.e., utilizing the mobility traces of IDs. However, linking IDs based on their mobility traces has been a challenging problem due to the highly heterogeneous, incomplete and noisy mobility data across services. In this paper, we propose DPLink , an end-to-end deep learning based framework, to complete the user identity linkage task for heterogeneous mobility data collected from different services with different properties. DPLink is made up by a feature extractor including a location encoder and a trajectory encoder to extract representative features from trajectory and a comparator to compare and decide whether to link two trajectories as the same user. Particularly, we propose a pre-training strategy with a simple task to train the DPLink model to overcome the training difficulties introduced by the highly heterogeneous nature of different source mobility data. Besides, we introduce a multi-modal embedding network and a co-attention mechanism in DPLink to deal with the low-quality problem of mobility data. By conducting extensive experiments on two real-life ground-truth mobility datasets with eight baselines, we demonstrate that DPLink outperforms the state-of-the-art solutions by more than 15 percent in terms of hit-precision. Moreover, it is expandable to add external geographical context data and works stably with heterogeneous noisy mobility traces.},
  archive      = {J_TKDE},
  author       = {Jie Feng and Yong Li and Zeyu Yang and Mingyang Zhang and Huandong Wang and Han Cao and Depeng Jin},
  doi          = {10.1109/TKDE.2020.2989732},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {954-968},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {User identity linkage via co-attentive neural network from heterogeneous mobility data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised discriminative projection for feature
selection. <em>TKDE</em>, <em>34</em>(2), 942–953. (<a
href="https://doi.org/10.1109/TKDE.2020.2983396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the most important techniques to deal with the high-dimensional data for a variety of machine learning and data mining tasks, such clustering, classification, and retrieval, etc. Fuzziness is a widespread nature of data in nature human society. However, most existing feature selection methods ignore the existence of fuzziness in the data, resulting in sub-optimal feature subsets. To address the problem, we propose a novel unsupervised feature selection method, called Unsupervised Discriminative Projection for Feature Selection (UDPFS) to select discriminative features by conducting fuzziness learning and sparse learning, simultaneously. Specifically, we use projection matrix transform data as its low-dimensional representation, which are partitioned into clusters by using membership matrix with sparse constraint. In addition, $\ell _{2, 1}$ -norm regularization is applied to the projection matrix. Then, a discriminative projection matrix with row sparse is obtained by perform fuzziness learning and sparse learning, simultaneously. An effective alternative optimization algorithm is proposed to solve the objective function. Evaluate experimental results on several real-world datasets show the effectiveness and superiority of the proposed unsupervised feature selection method.},
  archive      = {J_TKDE},
  author       = {Rong Wang and Jintang Bian and Feiping Nie and Xuelong Li},
  doi          = {10.1109/TKDE.2020.2983396},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {942-953},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Unsupervised discriminative projection for feature selection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards understanding the instability of network embedding.
<em>TKDE</em>, <em>34</em>(2), 927–941. (<a
href="https://doi.org/10.1109/TKDE.2020.2989512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding algorithms learn a mapping from the discrete representation of nodes to continuous vector spaces that preserve the proximities of nodes. The techniques have a wide range of applications in various downstream tasks such as node classification, link prediction, and network alignment. Despite recent efforts to the design of novel models, little attention has been paid to understanding the instability of network embedding. In this paper, we fill this gap by investigating several state-of-the-art network embedding methods. Node embeddings form a geometric shape in the latent space. Characterizing the geometry is critical to figure out the variance of network embedding. Hence, we define two metrics to characterize the geometric properties and find that node embeddings tremble in different instantiations of an embedding space. Then, we formally define the stability of node embeddings as the invariance of the nearest neighbors of nodes. Experimental results show that existing embedding approaches have significant amounts of instability. We explore the influence factors that affect the stability of different methods and find that both network structure and algorithm models affect the stability of node embeddings significantly. Finally, we examine the implications of embedding instability for downstream tasks and find remarkable impacts on the performance.},
  archive      = {J_TKDE},
  author       = {Chenxu Wang and Wei Rao and Wenna Guo and Pinghui Wang and Jun Liu and Xiaohong Guan},
  doi          = {10.1109/TKDE.2020.2989512},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {927-941},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Towards understanding the instability of network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Social boosted recommendation with folded bipartite network
embedding. <em>TKDE</em>, <em>34</em>(2), 914–926. (<a
href="https://doi.org/10.1109/TKDE.2020.2982878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence of online social platforms, social recommendation has emerged as a promising direction that leverages the social network among users to enhance recommendation performance. However, the available social relations among users are usually extremely sparse and noisy, which may lead to inferior recommendation performance. To alleviate this problem, this paper novelly exploits the implicit higher-order social influence and dependencies among users to enhance social recommendation. In this paper, we propose a novel embedding method for general bipartite graphs, which defines inter-class message passing between explicit relations and intra-class message passing between implicit higher-order relations via a novel sequential modelling paradigm. Inspired by recent advances in self-attention-based sequential modelling, the proposed model features a self-attentive representation learning mechanism for implicit user-user relations. Moreover, this paper also explores the inductive embedding learning for social recommendation problems to improve the recommendation performance in cold-start settings. The proposed inductive learning paradigm for social recommendation enables embedding inference for those cold-start users and items (unseen during training) as long as they are linked to existing nodes in the original network. Extensive experiments on real-world datasets demonstrate the superiority of our method and suggest that higher-order implicit relationship among users is beneficial to improving social recommendation.},
  archive      = {J_TKDE},
  author       = {Hongxu Chen and Hongzhi Yin and Tong Chen and Weiqing Wang and Xue Li and Xia Hu},
  doi          = {10.1109/TKDE.2020.2982878},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {914-926},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Social boosted recommendation with folded bipartite network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reliability maximization in uncertain graphs. <em>TKDE</em>,
<em>34</em>(2), 894–913. (<a
href="https://doi.org/10.1109/TKDE.2020.2987570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network reliability measures the probability that a target node is reachable from a source node in an uncertain graph, i.e., a graph where every edge is associated with a probability of existence. In this paper, we investigate the novel and fundamental problem of adding a small number of edges in the uncertain network for maximizing the reliability between a given pair of nodes. We study the $\mathbf {NP}$ -hardness and the approximation hardness of our problem, and design effective, scalable solutions. Furthermore, we consider extended versions of our problem (e.g., multiple source and target nodes can be provided as input) to support and demonstrate a wider family of queries and applications, including sensor network reliability maximization and social influence maximization. Experimental results validate the effectiveness and efficiency of the proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Xiangyu Ke and Arijit Khan and Mohammad Al Hasan and Rojin Rezvansangsari},
  doi          = {10.1109/TKDE.2020.2987570},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {894-913},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Reliability maximization in uncertain graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PGeoTopic: A distributed solution for mining geographical
topic models. <em>TKDE</em>, <em>34</em>(2), 881–893. (<a
href="https://doi.org/10.1109/TKDE.2020.2989142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geographical topic models have been used to mine geo-tagged documents for topical region and geographical topics, and also have applications in recommendations, user mobility modeling, event detection, etc. Existing studies focus on learning effective geographical topic models while ignoring the efficiency issue. However, it is very expensive to train geographical topic models — it may take days to train a geographical topic model of a small scale on a collection of documents with millions of word tokens. In this paper, we propose the first distributed solution, called ${\sf PGeoTopic}$ , for training geographical topic models. The proposed solution comprises several novel technical components to increase parallelism, reduce memory requirement, and reduce communication cost. Experiments show that our approach for mining geographical topic models is scalable with both model size and data size on distributed systems.},
  archive      = {J_TKDE},
  author       = {Kaiqi Zhao and Gao Cong and Xiucheng Li},
  doi          = {10.1109/TKDE.2020.2989142},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {881-893},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {PGeoTopic: A distributed solution for mining geographical topic models},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online spatio-temporal crowd flow distribution prediction
for complex metro system. <em>TKDE</em>, <em>34</em>(2), 865–880. (<a
href="https://doi.org/10.1109/TKDE.2020.2985952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key mission of the modern traffic management, crowd flow prediction (CFP) benefits in many tasks of intelligent transportation services. However, most existing techniques focus solely on forecasting entrance and exit flows of metro stations that do not provide enough useful knowledge for traffic management. In practical applications, managers desperately want to solve the problem of getting the potential passenger distributions to help authorities improve transport services, termed as crowd flow distribution (CFD) forecasts. Therefore, to improve the quality of transportation services, we proposed three spatiotemporal models to effectively address the network-wide CFD prediction problem based on the online latent space (OLS) strategy. Our models take into account the various trending patterns and climate influences, as well as the inherent similarities among different stations that are able to predict both CFD and entrance and exit flows precisely. In our online systems, a sequence of CFD snapshots is used as the training data. The latent attribute evolutions of different metro stations can be learned from the previous trend and do the next prediction based on the transition patterns. All the empirical results demonstrate that the three developed models outperform all the other state-of-the-art approaches on three large-scale real-world datasets.},
  archive      = {J_TKDE},
  author       = {Yongshun Gong and Zhibin Li and Jian Zhang and Wei Liu and Yu Zheng},
  doi          = {10.1109/TKDE.2020.2985952},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {865-880},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Online spatio-temporal crowd flow distribution prediction for complex metro system},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Obscure: Information-theoretically secure, oblivious, and
verifiable aggregation queries on secret-shared outsourced data.
<em>TKDE</em>, <em>34</em>(2), 843–864. (<a
href="https://doi.org/10.1109/TKDE.2020.2983932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite exciting progress on cryptography, secure and efficient query processing over outsourced data remains an open challenge. We develop a communication-efficient and information-theoretically secure system, entitled Obscure for aggregation queries with conjunctive or disjunctive predicates, using secret-sharing. Obscure is strongly secure (i.e., secure regardless of the computational-capabilities of an adversary) and prevents the network, as well as, the (adversarial) servers to learn the user’s queries, results, or the database. In addition, Obscure provides additional security features, such as hiding access-patterns (i.e., hiding the identity of the tuple satisfying a query) and hiding query-patterns (i.e., hiding which two queries are identical). Also, Obscure does not require any communication between any two servers that store the secret-shared data before/during/after the query execution. Moreover, our techniques deal with the secret-shared data that is outsourced by a single or multiple database owners, as well as, allows a user, which may not be the database owner, to execute the query over secret-shared data. We further develop (non-mandatory) privacy-preserving result verification algorithms that detect malicious behaviors, and experimentally validate the efficiency of Obscure on large datasets, the size of which prior approaches of secret-sharing or multi-party computation systems have not scaled to.},
  archive      = {J_TKDE},
  author       = {Peeyush Gupta and Yin Li and Sharad Mehrotra and Nisha Panwar and Shantanu Sharma and Sumaya Almanee},
  doi          = {10.1109/TKDE.2020.2983932},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {843-864},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Obscure: Information-theoretically secure, oblivious, and verifiable aggregation queries on secret-shared outsourced data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural text segmentation and its application to sentiment
analysis. <em>TKDE</em>, <em>34</em>(2), 828–842. (<a
href="https://doi.org/10.1109/TKDE.2020.2983360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text segmentation is a fundamental task in natural language processing. Depending on the levels of granularity, the task can be defined as segmenting a document into topical segments, or segmenting a sentence into elementary discourse units (EDUs). Traditional solutions to the two tasks heavily rely on carefully designed features. The recently proposed neural models do not need manual feature engineering, but they either suffer from sparse boundary tags or cannot efficiently handle the issue of variable size output vocabulary. In light of such limitations, we propose a generic end-to-end segmentation model, namely ${\mathrm{S}\scriptstyle{\mathrm{EG}}}{\mathrm{B}\scriptstyle{\mathrm{OT}}}$ , which first uses a bidirectional recurrent neural network to encode an input text sequence. ${\mathrm{S}\scriptstyle{\mathrm{EG}}}{\mathrm{B}\scriptstyle{\mathrm{OT}}}$ then uses another recurrent neural networks, together with a pointer network, to select text boundaries in the input sequence. In this way, ${\mathrm{S}\scriptstyle{\mathrm{EG}}}{\mathrm{B}\scriptstyle{\mathrm{OT}}}$ does not require any hand-crafted features. More importantly, ${\mathrm{S}\scriptstyle{\mathrm{EG}}}{\mathrm{B}\scriptstyle{\mathrm{OT}}}$ inherently handles the issue of variable size output vocabulary and the issue of sparse boundary tags. In our experiments, ${\mathrm{S}\scriptstyle{\mathrm{EG}}}{\mathrm{B}\scriptstyle{\mathrm{OT}}}$ outperforms state-of-the-art models on two tasks: document-level topic segmentation and sentence-level EDU segmentation. As a downstream application, we further propose a hierarchical attention model for sentence-level sentiment analysis based on the outcomes of ${\mathrm{S}\scriptstyle{\mathrm{EG}}}{\mathrm{B}\scriptstyle{\mathrm{OT}}}$ . The hierarchical model can make full use of both word-level and EDU-level information simultaneously for sentence-level sentiment analysis. In particular, it can effectively exploit EDU-level information, such as the inner properties of EDUs, which cannot be fully encoded in word-level features. Experimental results show that our hierarchical model achieves new state-of-the-art results on the Movie Review and Stanford Sentiment Treebank benchmarks.},
  archive      = {J_TKDE},
  author       = {Jing Li and Billy Chiu and Shuo Shang and Ling Shao},
  doi          = {10.1109/TKDE.2020.2983360},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {828-842},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Neural text segmentation and its application to sentiment analysis},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view k-means clustering with adaptive sparse
memberships and weight allocation. <em>TKDE</em>, <em>34</em>(2),
816–827. (<a href="https://doi.org/10.1109/TKDE.2020.2986201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many real-world applications exploit multi-view data, which is collected from diverse domains or obtained from various feature extractors and reflect different properties or distributions of the data. In this work, a novel unsupervised multi-view framework is proposed to cluster such data. The proposed method, called Multi-View clustering with Adaptive Sparse Memberships and Weight Allocation (MVASM), pays more attention to constructing a common membership matrix with proper sparseness over different views and learns the centroid matrix and its corresponding weight of each view. Concretely, MVASM method attempts to learn a common and flexible sparse membership matrix to indicate the clustering, which explores the underlying consensus information of multiple views, and solves the multiple centroid matrices and weights to utilize the view-specific information and further modifies the above-mentioned membership matrix. In addition, the theoretical analysis, including the determination of the power exponent parameter, convergence analysis, and complexity analysis are also presented. Compared to the state-of-the-art methods, the proposed method improves the performance of clustering on different public datasets and demonstrates its reasonability and superiority.},
  archive      = {J_TKDE},
  author       = {Junwei Han and Jinglin Xu and Feiping Nie and Xuelong Li},
  doi          = {10.1109/TKDE.2020.2986201},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {816-827},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-view K-means clustering with adaptive sparse memberships and weight allocation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view clustering with the cooperation of visible and
hidden views. <em>TKDE</em>, <em>34</em>(2), 803–815. (<a
href="https://doi.org/10.1109/TKDE.2020.2983366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data are becoming common in real-world applications and many multi-view clustering algorithms have thus been proposed. The existing algorithms usually focus on the cooperation of different visible views in the original space but neglect the influence of the hidden information among these visible views, or they only consider the hidden information among the views. The algorithms are therefore not efficient since the available information is not fully exploited, particularly the otherness information in different views and the consistency information among them. In practice, the otherness and consistency information in multi-view data are both very useful for effective clustering analyses. In this study, a Multi-View clustering algorithm with the Cooperation of Visible and Hidden views, i.e., MV-Co-VH, is proposed. The MV-Co-VH algorithm first projects the multiple views from different visible spaces to the common hidden space by using non-negative matrix factorization to obtain the common hidden view data. Collaborative learning is then implemented in the clustering procedure based on the visible views and the shared hidden view. The experimental results of extensive experiments on UCI multi-view datasets and real-world image multi-view datasets show that the clustering performance of the proposed algorithm is competitive with or even better than that of the existing algorithms.},
  archive      = {J_TKDE},
  author       = {Zhaohong Deng and Ruixiu Liu and Peng Xu and Kup-Sze Choi and Wei Zhang and Xiaobin Tian and Te Zhang and Ling Liang and Bin Qin and Shitong Wang},
  doi          = {10.1109/TKDE.2020.2983366},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {803-815},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-view clustering with the cooperation of visible and hidden views},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task learning for recommendation over heterogeneous
information network. <em>TKDE</em>, <em>34</em>(2), 789–802. (<a
href="https://doi.org/10.1109/TKDE.2020.2983409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommender systems (RS) only consider homogeneous data and cannot fully model heterogeneous information of complex objects and relations. Recent advances in the study of Heterogeneous Information Network (HIN) have shed some light on how to leverage heterogeneous information in RS. However, existing HIN-based recommendation models assume HIN is invariable and merely use HIN as a data source for assisting recommendation, which limits their performance. In this paper, we propose a multi-task learning framework, called MTRec, for recommendation over HIN. MTRec relies on self-attention mechanism to learn the semantics of meta-paths in HIN and jointly optimizes the tasks of both recommendation and link prediction. Using a Bayesian task weight learner, MTRec is able to achieve the balance of two tasks during optimization automatically. Moreover, MTRec provides good interpretabilities of recommendation through a “translation” mechanism which is used to model the three-way interactions among users, items and the meta-paths connecting them. Experimental results demonstrate the superiority of MTRec over state-of-the-art HIN-based recommendation models, and the case studies we provide illustrate that MTRec enhances the explainability of RS.},
  archive      = {J_TKDE},
  author       = {Hui Li and Yanlin Wang and Ziyu Lyu and Jieming Shi},
  doi          = {10.1109/TKDE.2020.2983409},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {789-802},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-task learning for recommendation over heterogeneous information network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maximizing the utility in location-based mobile advertising.
<em>TKDE</em>, <em>34</em>(2), 776–788. (<a
href="https://doi.org/10.1109/TKDE.2020.2986198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile technology, nowadays, people spend a large amount of time on mobile devices. The locations and contexts of users are easily accessed by mobile advertising brokers, and the brokers can send customers related location-based advertisements. In this paper, we consider an important location-based advertising problem, namely maximum utility advertisement assignment (MUAA) problem, with the estimation of the interests of customers and the contexts of the vendors, we want to maximize the overall utility of ads by determining the ads sent to each customer subject to the constraints of the capacities of customers, the distance ranges and the budgets of vendors. We prove that the MUAA problem is NP-hard and intractable. Thus, we propose one offline approach, namely the ${\sf reconciliation\ approach}$ , which has an approximation ratio of $(1-\epsilon)\cdot \theta$ . In addition, we also address the online scenario, in which customers arrive in a streaming fashion, with one novel online algorithm, namely the ${\sf online\ adaptive\ factor-aware\ approach}$ , which has a competitive ratio (compared to the optimal solution of the offline scenario) of $\frac{\ln (g)+1}{\theta }$ , $g&amp;gt;e$ , where $e$ is the base of the natural logarithm. Through extensive experiments, we demonstrate the efficiency and effectiveness of our proposed approaches over both real and synthetic datasets.},
  archive      = {J_TKDE},
  author       = {Peng Cheng and Xiang Lian and Lei Chen and Siyuan Liu},
  doi          = {10.1109/TKDE.2020.2986198},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {776-788},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Maximizing the utility in location-based mobile advertising},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LookCom: Learning optimal network for community detection.
<em>TKDE</em>, <em>34</em>(2), 764–775. (<a
href="https://doi.org/10.1109/TKDE.2020.2987784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is one of the fundamental tasks in graph mining, which aims to identify group assignment of nodes in a complex network. Recently, network embedding techniques have demonstrated their strong power in advancing the community detection task and achieve better performance than various traditional methods. Despite their empirical success, most of the existing algorithms directly leverage the observed coarse network structure for community detection. Therefore, they often lead to suboptimal performance as the observed connections fail to capture the essential tie strength information among nodes precisely and account for the impact of noisy links. In this paper, an optimal network structure for community detection is introduced to characterize the fine-grained tie strength information between connected nodes and alleviate the adverse effects of noisy links. To obtain an expressive node representation for community detection, we learn the optimal network structure and network embeddings in a joint framework, instead of using a two-stage approach to derive the node embeddings from the coarse network topology. In particular, we formulate the joint framework as an optimization problem and an alternating optimization algorithm is exploited to solve the proposed optimization problem. Additionally, theoretical analyses regarding the computational complexity and the convergence of the optimization algorithm are also provided. Extensive experiments on both synthetic and real-world networks demonstrate the effectiveness and superiority of the proposed framework.},
  archive      = {J_TKDE},
  author       = {Yixiang Dong and Minnan Luo and Jundong Li and Deng Cai and Qinghua Zheng},
  doi          = {10.1109/TKDE.2020.2987784},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {764-775},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LookCom: Learning optimal network for community detection},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear approximation of f-measure for the performance
evaluation of classification algorithms on imbalanced data sets.
<em>TKDE</em>, <em>34</em>(2), 753–763. (<a
href="https://doi.org/10.1109/TKDE.2020.2986749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accuracy is a popular measure for evaluating the performance of classification algorithms tested on ordinary data sets. When a data set is imbalanced, F -measure will be a better choice than accuracy for this purpose. Since F -measure is calculated as the harmonic mean of recall and precision, it is difficult to find the sampling distribution of F -measure for evaluating classification algorithms. Since the values of recall and precision are dependent, their joint distribution is assumed to follow a bivariate normal distribution in this study. When the evaluation method is k -fold cross validation, a linear approximation approach is proposed to derive the sampling distribution of F -measure. This approach is used to design methods for comparing the performance of two classification algorithms tested on single or multiple imbalanced data sets. The methods are tested on ten imbalanced data sets to demonstrate their effectiveness. The weight of recall provided by this linear approximation approach can help us to analyze the characteristics of classification algorithms.},
  archive      = {J_TKDE},
  author       = {Tzu-Tsung Wong},
  doi          = {10.1109/TKDE.2020.2986749},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {753-763},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Linear approximation of F-measure for the performance evaluation of classification algorithms on imbalanced data sets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Information fusion for (re)configuring bike station
networks with crowdsourcing. <em>TKDE</em>, <em>34</em>(2), 736–752. (<a
href="https://doi.org/10.1109/TKDE.2020.2991000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike sharing service (BSS) networks have been proliferating all over the globe thanks to their success as the first/last-mile connectivity inside a smart city. Their (re)configuration — i.e., station (re)placement and dock resizing — has thus become increasingly important for BSS providers and smart city planners. Instead of using conventional labor-intensive manual surveys, we propose a novel information fusion framework called CBikes that (re)configures the BSS network by jointly fusing crowdsourced station suggestions from online websites and the usage history of bike stations. Using comprehensive real data analyses, we identify and exploit important global trip patterns to (re)configure the BSS network while mitigating the local biases of individual feedbacks. Specifically, crowdsourced feedbacks, station usage, cost and other constraints are fused into a joint optimization of BSS network configuration. We also model the spatial distributions of station usage to account for and estimate the unexplored regions without historical usage information. We further design a semidefinite programming transformation to solve the bike station (re)placement problem efficiently and effectively. Our extensive data analytics and evaluation have shown CBikes ’ effectiveness and accuracy in (re)placing stations and resizing docks based on three large BSS systems (with $&amp;gt;$ 900 stations) in Chicago, Twin Cities (Minneapolis–Saint Paul), and Los Angeles.},
  archive      = {J_TKDE},
  author       = {Suining He and Kang G. Shin},
  doi          = {10.1109/TKDE.2020.2991000},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {736-752},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Information fusion for (Re)Configuring bike station networks with crowdsourcing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incorporating multi-source urban data for personalized and
context-aware multi-modal transportation recommendation. <em>TKDE</em>,
<em>34</em>(2), 723–735. (<a
href="https://doi.org/10.1109/TKDE.2020.2985954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation recommendation is one important map service in navigation applications. Previous transportation recommendation solutions fail to deliver satisfactory user experience because their recommendations only consider routes in one transportation mode (uni-modal, e.g., taxi, bus, cycle) and largely overlook situational context. In this work, we propose $\mathsf {Hydra}$ , a multi-task deep learning based recommendation system that offers multi-modal transportation planning and is adaptive to various situational context (e.g., nearby point-of-interest (POI) distribution and weather). We leverage the availability of existing routing engines and big urban data, and design a novel two-level framework that integrates uni-modal and multi-modal (e.g., taxi-bus, bus-cycle) routes as well as heterogeneous urban data for intelligent multi-modal transportation recommendation. In addition to urban context features constructed from multi-source urban data, we learn the latent representations of users, origin-destination (OD) pairs and transportation modes based on user implicit feedbacks, which captures the collaborative transportation mode preferences of users and OD pairs. Moreover, we propose two models to recommend the proper route among various uni-modal and multi-modal transportation routes: (1) a light-weight gradient boosting decision tree (GBDT) based recommendation model; and (2) a multi-task wide and deep learning (MTWDL) based recommendation model. We also optimize the framework to support real-time, large-scale route query and recommendation. We deploy $\mathsf {Hydra}$ on Baidu Maps, 1 1.https://maps.baidu.com/. one of the world&#39;s largest map services. Real-world urban-scale experiments demonstrate the effectiveness and efficiency of our proposed system. Since its deployment in August 2018, $\mathsf {Hydra}$ has answered over a hundred million route recommendation queries made by over ten million distinct users. The GBDT based model and MTWDL based model achieve 82.8 and 96.6 percent relative improvement of user click ratio, respectively.},
  archive      = {J_TKDE},
  author       = {Hao Liu and Yongxin Tong and Jindong Han and Panpan Zhang and Xinjiang Lu and Hui Xiong},
  doi          = {10.1109/TKDE.2020.2985954},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {723-735},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Incorporating multi-source urban data for personalized and context-aware multi-modal transportation recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HinCTI: A cyber threat intelligence modeling and
identification system based on heterogeneous information network.
<em>TKDE</em>, <em>34</em>(2), 708–722. (<a
href="https://doi.org/10.1109/TKDE.2020.2987019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber attacks have become increasingly complicated, persistent, organized, and weaponized. Faces with this situation, drives a rising number of organizations across the world are showing a growing willingness to leverage the open exchange of cyber threat intelligence (CTI) for obtaining a full picture of the fast-evolving cyber threat situation and protecting themselves against cyber-attacks. However, modeling CTI is challenging due to the explicit and implicit relationships among CTI and the heterogeneity of cyber-threat infrastructure nodes involved in CTI. Owing to the limited labels of cyber threat infrastructure nodes involved in CTI, automatically identifying the threat type of infrastructure nodes for early warning is also challenging. To tackle these challenges, a practical system called HinCTI is developed for modeling cyber threat intelligence and identifying threat types. We first design a threat intelligence meta-schema to depict the semantic relatedness of infrastructure nodes. We then model cyber threat intelligence on heterogeneous information network (HIN), which can integrate various types of infrastructure nodes and rich relations among them. Following, we define a meta-path and meta-graph instances-based threat Infrastructure similarity (MIIS) measure between threat infrastructure nodes and present a MIIS measure-based heterogeneous graph convolutional network (GCN) approach to identify the threat types of infrastructure nodes involved in CTI. Moreover, through the hierarchical regularization strategy, our model can alleviate the problem of overfitting and achieve good results in the threat type identification of infrastructure nodes. To the best of our knowledge, this work is the first to model CTI on HIN for threat identification and propose a heterogeneous GCN-based approach for threat type identification of infrastructure nodes. With HinCTI , comprehensive experiments are conducted on real-world datasets, and experimental results demonstrate that our proposed approach can significantly improve the performance of threat type identification compared to the existing state-of-the-art baseline methods. Our work is beneficial to greatly relieve security analysts from heavy analysis work and efficiently protect organizations against cyber-attacks.},
  archive      = {J_TKDE},
  author       = {Yali Gao and Xiaoyong Li and Hao Peng and Binxing Fang and Philip S. Yu},
  doi          = {10.1109/TKDE.2020.2987019},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {708-722},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {HinCTI: A cyber threat intelligence modeling and identification system based on heterogeneous information network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hihooi: A database replication middleware for scaling
transactional databases consistently. <em>TKDE</em>, <em>34</em>(2),
691–707. (<a href="https://doi.org/10.1109/TKDE.2020.2987560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the Internet and Internet-connected devices, modern business applications can experience rapid increases as well as variability in transactional workloads. Database replication has been employed to scale performance and improve availability of relational databases but past approaches have suffered from various issues including limited scalability, performance versus consistency tradeoffs, and requirements for database or application modifications. This paper presents Hihooi, a replication-based middleware system that is able to achieve workload scalability, strong consistency guarantees, and elasticity for existing transactional databases at a low cost. A novel replication algorithm enables Hihooi to propagate database modifications asynchronously to all replicas at high speeds, while ensuring that all replicas are consistent. At the same time, a fine-grained routing algorithm is used to load balance incoming transactions to available replicas in a consistent way. Our thorough experimental evaluation with several well-established benchmarks shows how Hihooi is able to achieve almost linear workload scalability for transactional databases.},
  archive      = {J_TKDE},
  author       = {Michael A. Georgiou and Aristodemos Paphitis and Michael Sirivianos and Herodotos Herodotou},
  doi          = {10.1109/TKDE.2020.2987560},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {691-707},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hihooi: A database replication middleware for scaling transactional databases consistently},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). G-inspector: Recurrent attention model on graph.
<em>TKDE</em>, <em>34</em>(2), 680–690. (<a
href="https://doi.org/10.1109/TKDE.2020.2983689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph classification problem is becoming one of research hotspots in the realm of graph mining, which has been widely used in cheminformatics, bioinformatics and social network analytics. Existing approaches, such as graph kernel methods and graph Convolutional Neural Network, are facing the challenges of non-interpretability and high dimensionality. To address the problems, we propose a novel recurrent attention model, called g-Inspector, which applies the attention mechanism to investigate the significance of each region to make the results interpretable. It also takes a shift operation to guide the inspector agent to discover the next relevant region, so that the model sequentially loads small regions instead of the entire large graph, to solve the high dimensionality problem. The experiments conducted on standard graph datasets show the effectiveness of our g-Inspector in graph classification problems.},
  archive      = {J_TKDE},
  author       = {Zhiling Luo and Yinghua Cui and Sha Zhao and Jianwei Yin},
  doi          = {10.1109/TKDE.2020.2983689},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {680-690},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {G-inspector: Recurrent attention model on graph},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gaussian distribution based oversampling for imbalanced data
classification. <em>TKDE</em>, <em>34</em>(2), 667–679. (<a
href="https://doi.org/10.1109/TKDE.2020.2985965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalanced data classification problem widely exists in many real-world applications. Data resampling is a promising technique to deal with imbalanced data through either oversampling or undersampling. However, the traditional data resampling approaches simply take into account the local neighbor information to generate new instances in linear ways, leading to the generation of incorrect and unnecessary instances. In this study, we propose a new data resampling technique, namely, Gaussian Distribution based Oversampling (GDO), to handle the imbalanced data for classification. In GDO, anchor instances are selected from the minority class instances in a probabilistic way by taking into account the density and distance information carried by the minority instances. Then new minority instances are generated following a Gaussian distribution model. The proposed method is validated in experimental study by comparing with seven imbalanced learning approaches on 40 data sets from the KEEL repository and 10 large data sets from the UCI repository. Experimental results show that our method outperforms the other compared methods in terms of AUC, G-mean and memory usage with an increase in running time. We also apply GDO to deal with two real imbalanced data classification problems: Internet video traffic identification and metastasis detection of esophageal cancer. The experimental results once again validate the effectiveness of our approach.},
  archive      = {J_TKDE},
  author       = {Yuxi Xie and Min Qiu and Haibo Zhang and Lizhi Peng and Zhenxiang Chen},
  doi          = {10.1109/TKDE.2020.2985965},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {667-679},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Gaussian distribution based oversampling for imbalanced data classification},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and secure distributed nonnegative matrix
factorization. <em>TKDE</em>, <em>34</em>(2), 653–666. (<a
href="https://doi.org/10.1109/TKDE.2020.2985964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) has been successfully applied in several data mining tasks. Recently, there is an increasing interest in the acceleration of NMF, due to its high cost on large matrices. On the other hand, the privacy issue of NMF over federated data is worthy of attention, since NMF is prevalently applied in image and text analysis which may involve leveraging privacy data (e.g, medical image and record) across several parties (e.g., hospitals). In this paper, we study the acceleration and security problems of distributed NMF. First, we propose a distributed sketched alternating nonnegative least squares (DSANLS) framework for NMF, which utilizes a matrix sketching technique to reduce the size of nonnegative least squares subproblems with a convergence guarantee. For the second problem, we show that DSANLS with modification can be adapted to the security setting, but only for one or limited iterations . Consequently, we propose four efficient distributed NMF methods in both synchronous and asynchronous settings with a security guarantee. We conduct extensive experiments on several real datasets to show the superiority of our proposed methods. The implementation of our methods is available at https://github.com/qianyuqiu79/DSANLS .},
  archive      = {J_TKDE},
  author       = {Yuqiu Qian and Conghui Tan and Danhao Ding and Hui Li and Nikos Mamoulis},
  doi          = {10.1109/TKDE.2020.2985964},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {653-666},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast and secure distributed nonnegative matrix factorization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting interpretable patterns for flow prediction in
dockless bike sharing systems. <em>TKDE</em>, <em>34</em>(2), 640–652.
(<a href="https://doi.org/10.1109/TKDE.2020.2988008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike the traditional dock-based systems, dockless bike-sharing systems are more convenient for users in terms of flexibility. However, the flexibility of these dockless systems comes at the cost of management and operation complexity. Indeed, the imbalanced and dynamic use of bikes leads to mandatory rebalancing operations, which impose a critical need for effective bike traffic flow prediction. While efforts have been made in developing traffic flow prediction models, existing approaches lack interpretability, and thus have limited value in practical deployment. To this end, we propose an Interpretable Bike Flow Prediction (IBFP) framework, which can provide effective bike flow prediction with interpretable traffic patterns. Specifically, by dividing the urban area into regions according to flow density, we first model the spatio-temporal bike flows between regions with graph regularized sparse representation, where graph Laplacian is used as a smooth operator to preserve the commonalities of the periodic data structure. Then, we extract traffic patterns from bike flows using subspace clustering with sparse representation to construct interpretable base matrices. Moreover, the bike flows can be predicted with the interpretable base matrices and learned parameters. Finally, experimental results on real-world data show the advantages of the IBFP method for flow prediction in dockless bike sharing systems. In addition, the interpretability of our flow pattern exploitation is further illustrated through a case study where IBFP provides valuable insights into bike flow analysis.},
  archive      = {J_TKDE},
  author       = {Jingjing Gu and Qiang Zhou and Jingyuan Yang and Yanchi Liu and Fuzhen Zhuang and Yanchao Zhao and Hui Xiong},
  doi          = {10.1109/TKDE.2020.2988008},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {640-652},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Exploiting interpretable patterns for flow prediction in dockless bike sharing systems},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evidence integration for multi-hop reading comprehension
with graph neural networks. <em>TKDE</em>, <em>34</em>(2), 631–639. (<a
href="https://doi.org/10.1109/TKDE.2020.2982894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop reading comprehension focuses on one type of factoid question, where a system needs to properly integrate multiple pieces of evidence to correctly answer a question. Previous work approximates global evidence with local coreference information, encoding coreference chains with DAG-styled GRU layers within a gated-attention reader. However, coreference is limited in providing information for rich inference. We introduce a new method for better connecting global evidence, which forms more complex graphs compared to DAGs. To perform evidence integration on our graphs, we investigate two recent graph neural networks, namely graph convolutional network (GCN) and graph recurrent network (GRN). Experiments on two standard datasets show that richer global information leads to better answers. Our approach shows highly competitive performances on these datasets without deep language models (such as ELMo).},
  archive      = {J_TKDE},
  author       = {Linfeng Song and Zhiguo Wang and Mo Yu and Yue Zhang and Radu Florian and Daniel Gildea},
  doi          = {10.1109/TKDE.2020.2982894},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {631-639},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Evidence integration for multi-hop reading comprehension with graph neural networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ESA-stream: Efficient self-adaptive online data stream
clustering. <em>TKDE</em>, <em>34</em>(2), 617–630. (<a
href="https://doi.org/10.1109/TKDE.2020.2990196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many big data applications produce a massive amount of high-dimensional, real-time, and evolving streaming data. Clustering such data streams with both effectiveness and efficiency are critical for these applications. Although there are well-known data stream clustering algorithms that are based on the popular online-offline framework, these algorithms still face some major challenges. Several critical questions are still not answer satisfactorily: How to perform dimensionality reduction effectively and efficiently in the online dynamic environment? How to enable the clustering algorithm to achieve complete real-time online processing? How to make algorithm parameters learn in a self-supervised or self-adaptive manner to cope with high-speed evolving streams? In this paper, we focus on tackling these challenges by proposing a fully online data stream clustering algorithm (called ESA-Stream) that can learn parameters online dynamically in a self-adaptive manner, speedup dimensionality reduction, and cluster data streams effectively and efficiently in an online and dynamic environment. Experiments on a wide range of synthetic and real-world data streams show that ESA-Stream outperforms state-of-the-art baselines considerably in both effectiveness and efficiency.},
  archive      = {J_TKDE},
  author       = {Yanni Li and Hui Li and Zhi Wang and Bing Liu and Jiangtao Cui and Hang Fei},
  doi          = {10.1109/TKDE.2020.2990196},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {617-630},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ESA-stream: Efficient self-adaptive online data stream clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective keyword search over weighted graphs.
<em>TKDE</em>, <em>34</em>(2), 601–616. (<a
href="https://doi.org/10.1109/TKDE.2020.2985376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real graphs often contain edge and node weights, representing, for instance, penalty, distance or uncertainty. We study the problem of keyword search over weighted node-labeled graphs, in which a query consists of a set of keywords and an answer is a subgraph whose nodes contain the keywords. We evaluate answers using three ranking strategies: optimizing edge weights, optimizing node weights, and a bi-objective combination of both node and edge weights. We prove that optimizing node weights and the bi-objective function are NP-hard. We propose an algorithm that optimizes edge weights and has an approximation ratio of two for the unique node enumeration paradigm. To optimize node weights and the bi-objective function, we propose transformations that distribute node weights onto the edges. We then prove that our transformations allow our algorithm to also optimize node weights and the bi-objective function with the same approximation ratio of two. Notably, the proposed transformations are compatible with existing algorithms that only optimize edge weights. We empirically show that in many natural examples, incorporating node weights (both keyword holders and middle nodes) produces more relevant answers than ranking methods based only on edge weights. Extensive experiments over real-life datasets verify the effectiveness and efficiency of our solution.},
  archive      = {J_TKDE},
  author       = {Mehdi Kargar and Lukasz Golab and Divesh Srivastava and Jaroslaw Szlichta and Morteza Zihayat},
  doi          = {10.1109/TKDE.2020.2985376},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {601-616},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Effective keyword search over weighted graphs},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adaptation on graphs by learning aligned graph bases.
<em>TKDE</em>, <em>34</em>(2), 587–600. (<a
href="https://doi.org/10.1109/TKDE.2020.2984212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common assumption in semi-supervised learning is that the class label function has a slow variation on the data graph, while in many problems, the label function may vary abruptly in certain graph regions, resulting in high-frequency components. Although semi-supervised learning is an ill-posed problem, it is often possible to find a source graph on which the label function has similar frequency content to the target graph where the actual classification problem is defined. In this paper, we propose a method for domain adaptation on graphs based on learning the spectrum of the label function in a source graph with many labels, and transferring the spectrum information to the target graph. When transferring the frequency content, it is not easy to share graph Fourier coefficients directly between the two independently constructed graphs, since no match exists between their Fourier bases. We solve this by learning a transformation between the Fourier bases of the two graphs that flexibly “aligns” them. The unknown class label function on the target graph is then reconstructed from the learnt spectrum while retaining consistency with the available labels. Comparative experiments suggest that the proposed algorithm often outperforms recent domain adaptation methods in various data classification applications.},
  archive      = {J_TKDE},
  author       = {Mehmet Pilancı and Elif Vural},
  doi          = {10.1109/TKDE.2020.2984212},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {587-600},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Domain adaptation on graphs by learning aligned graph bases},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Discovering temporal patterns for event sequence clustering
via policy mixture model. <em>TKDE</em>, <em>34</em>(2), 573–586. (<a
href="https://doi.org/10.1109/TKDE.2020.2986206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal point process (TPP) is an expressive tool for modeling the temporal pattern of event sequences. However, discovering temporal patterns for event sequences clustering is rarely studied in TPP modeling. To solve this problem, we take a reinforcement learning view whereby the observed sequences are assumed to be generated from a mixture of latent policies. The purpose is to cluster the sequences with different temporal patterns into the underlying policies while learning each of the policy model. The flexibility of our model lies in: i) all the components are networks including the policy network for modeling the temporal point process; ii) to handle varying-length event sequences, we resort to inverse reinforcement learning by decomposing the observed sequence into states (RNN hidden embedding of history) and actions (time interval to next event) in order to learn a reward function, it helps to achieve better performance or increasing efficiency compared to existing methods using rewards over the entire sequence such as log-likelihood or Wasserstein distance. We adopt an Expectation-Maximization algorithm, in E-step estimating the cluster labels for each sequence, in M-step aiming to learn the respective policy. Extensive experiments on synthetic and real-world datasets show the efficacy of our method against the state-of-the-arts.},
  archive      = {J_TKDE},
  author       = {Weichang Wu and Junchi Yan and Xiaokang Yang and Hongyuan Zha},
  doi          = {10.1109/TKDE.2020.2986206},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {573-586},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Discovering temporal patterns for event sequence clustering via policy mixture model},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep cross-modal hashing with hashing functions and unified
hash codes jointly learning. <em>TKDE</em>, <em>34</em>(2), 560–572. (<a
href="https://doi.org/10.1109/TKDE.2020.2987312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their high retrieval efficiency and low storage cost, cross-modal hashing methods have attracted considerable attention. Generally, compared with shallow cross-modal hashing methods, deep cross-modal hashing methods can achieve a more satisfactory performance by integrating feature learning and hash codes optimizing into a same framework. However, most existing deep cross-modal hashing methods either cannot learn a unified hash code for the two correlated data-points of different modalities in a database instance or cannot guide the learning of unified hash codes by the feedback of hashing function learning procedure, to enhance the retrieval accuracy. To address the issues above, in this paper, we propose a novel end-to-end Deep Cross-Modal Hashing with Hashing Functions and Unified Hash Codes Jointly Learning (DCHUC). Specifically, by an iterative optimization algorithm, DCHUC jointly learns unified hash codes for image-text pairs in a database and a pair of hash functions for unseen query image-text pairs. With the iterative optimization algorithm, the learned unified hash codes can be used to guide the hashing function learning procedure; Meanwhile, the learned hashing functions can feedback to guide the unified hash codes optimizing procedure. Extensive experiments on three public datasets demonstrate that the proposed method outperforms the state-of-the-art cross-modal hashing methods.},
  archive      = {J_TKDE},
  author       = {Rong-Cheng Tu and Xian-Ling Mao and Bing Ma and Yong Hu and Tan Yan and Wei Wei and Heyan Huang},
  doi          = {10.1109/TKDE.2020.2987312},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {560-572},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep cross-modal hashing with hashing functions and unified hash codes jointly learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-database micro-expression recognition: A benchmark.
<em>TKDE</em>, <em>34</em>(2), 544–559. (<a
href="https://doi.org/10.1109/TKDE.2020.2985365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-database micro-expression recognition (CDMER) is one of recently emerging and interesting problem in micro-expression analysis. CDMER is more challenging than the conventional micro-expression recognition (MER), because the training and testing samples in CDMER come from different micro-expression databases, resulting in inconsistency of the feature distributions between the training and testing sets. In this paper, we contribute to this topic from three aspects. First, we establish a CDMER experimental evaluation protocol aiming to allow the researchers to conveniently work on this topic and evaluate their proposed methods under the same standard. Second, we conduct benchmark experiments by using NINE state-of-the-art domain adaptation (DA) methods and SIX popular spatiotemporal descriptors for investigating CDMER problem from two different perspectives. Third, we propose a novel DA method called region selective transfer regression (RSTR) to deal with the CDMER task. The overall superior performance of RSTR over the state-of-the-art DA methods demonstrates that taking into consideration the facial local region information used in RSTR contributes to developing effective DA methods for dealing with CDMER problem.},
  archive      = {J_TKDE},
  author       = {Tong Zhang and Yuan Zong and Wenming Zheng and C. L. Philip Chen and Xiaopeng Hong and Chuangao Tang and Zhen Cui and Guoying Zhao},
  doi          = {10.1109/TKDE.2020.2985365},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {544-559},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cross-database micro-expression recognition: A benchmark},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CHEER: Rich model helps poor model via knowledge infusion.
<em>TKDE</em>, <em>34</em>(2), 531–543. (<a
href="https://doi.org/10.1109/TKDE.2020.2989405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in applying deep learning (DL) to healthcare, driven by the availability of data with multiple feature channels in rich-data environments (e.g., intensive care units). However, in many other practical situations, we can only access data with much fewer feature channels in a poor-data environments (e.g., at home), which often results in predictive models with poor performance. How can we boost the performance of models learned from such poor-data environment by leveraging knowledge extracted from existing models trained using rich data in a related environment? To address this question, we develop a knowledge infusion framework named CHEER that can succinctly summarize such rich model into transferable representations, which can be incorporated into the poor model to improve its performance. The infused model is analyzed theoretically and evaluated empirically on several datasets. Our empirical results showed that CHEER outperformed baselines by 5.60 to 46.80 percent in terms of the macro-F1 score on multiple physiological datasets.},
  archive      = {J_TKDE},
  author       = {Cao Xiao and Trong Nghia Hoang and Shenda Hong and Tengfei Ma and Jimeng Sun},
  doi          = {10.1109/TKDE.2020.2989405},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {531-543},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {CHEER: Rich model helps poor model via knowledge infusion},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel enriched version of truncated nuclear norm
regularization for matrix completion of inexact observed data.
<em>TKDE</em>, <em>34</em>(2), 519–530. (<a
href="https://doi.org/10.1109/TKDE.2020.2983708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, matrix completion has become one of the main concepts in data science. Truncated nuclear norm regularization (TNNR) approximation of the rank function is an example of the favorite approaches in matrix completion that performs better than other approximations like the nuclear norm. In all TNNR based methods, the observed data is considered to be exact, so they do not give an appropriate solution for inexact observed data. But, in real applications, in addition to missing data, observed data may be inaccurate. In this paper, we proposed a novel method based on TNNR that can deal with missing data and inexact observed data by adding some terms in the objective and constraint of the matrix completion problem. Experimental results confirm the quality of our proposed method in comparison with the other state of the art matrix completion and low-rank approximation techniques.},
  archive      = {J_TKDE},
  author       = {Tayyebeh Saeedi and Mansoor Rezghi},
  doi          = {10.1109/TKDE.2020.2983708},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {519-530},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A novel enriched version of truncated nuclear norm regularization for matrix completion of inexact observed data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A biclustering method for heterogeneous and temporal medical
data. <em>TKDE</em>, <em>34</em>(2), 506–518. (<a
href="https://doi.org/10.1109/TKDE.2020.2983692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of biclustering on heterogeneous data, that is, data of various types (binary, numeric, symbolic, temporal). We propose a new method, HBC-t (Heterogeneous BiClustering for temporal data), designed to extract biclusters from heterogeneous, temporal, large-scale, sparse data matrices. HBC-t is based on HBC, using similar mechanisms but adding support for temporal data. The goal of this method is to handle Electronic Health Records (EHR) data gathered by hospitals on patients, stays, acts, diagnoses, prescriptions, etc.; and to provide valuable insights on this data. Temporal data accounts for a majority of the data available for this study, and in EHR in general where medical events are timestamped. Therefore, it is crucial to have an algorithm that supports this type of data. The proposed algorithm takes advantage of the data sparsity and uses a constructive greedy heuristic to build a large number of possibly overlapping biclusters. HBC-t is successfully compared with several other biclustering algorithms on numeric and temporal data. Experiments on full-scale real-life data sets further assert its scalability and efficiency.},
  archive      = {J_TKDE},
  author       = {Maxence Vandromme and Julie Jacques and Julien Taillard and Laetitia Jourdan and Clarisse Dhaenens},
  doi          = {10.1109/TKDE.2020.2983692},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {2},
  pages        = {506-518},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A biclustering method for heterogeneous and temporal medical data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subgraph matching with effective matching order and
indexing. <em>TKDE</em>, <em>34</em>(1), 491–505. (<a
href="https://doi.org/10.1109/TKDE.2020.2980257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph matching finds all embeddings from a data graph that are identical to a query graph. Recent algorithms work by generating a tree-structured index on the data graph based on the query graph, ordering the vertices path-by-path in the tree, and enumerating the embeddings following the matching order. However, we find such path-based ordering and tree-structured index based enumeration inherently limit the performance due to the lack of consideration on the edges among the vertices across tree paths. To address this problem, we propose an approach that generates the matching order based on a cost model considering both the edges among query vertices and the number of candidates. Furthermore, we create a bigraph index for candidate vertices and their selected neighbors in the data graph, and use this index to perform enumeration along the matching order. Our experiments on both real-world and synthetic datasets show that our method outperforms the state of the art by orders of magnitude.},
  archive      = {J_TKDE},
  author       = {Shixuan Sun and Qiong Luo},
  doi          = {10.1109/TKDE.2020.2980257},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {491-505},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Subgraph matching with effective matching order and indexing},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Steerable self-driving data visualization. <em>TKDE</em>,
<em>34</em>(1), 475–490. (<a
href="https://doi.org/10.1109/TKDE.2020.2981464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a self-driving data visualization system, called DeepEye , that automatically generates and recommends visualizations based on the idea of visualization by examples. We propose effective visualization recognition techniques to decide which visualizations are meaningful and visualization ranking techniques to rank the good visualizations. Furthermore, a main challenge of automatic visualization system is that the users may be misled by blindly suggesting visualizations without knowing the user&#39;s intent. To this end, we extend DeepEye to be easily steerable by allowing the user to use keyword search and providing click-based faceted navigation . Empirical results, using real-life data and use cases, verify the power of our proposed system.},
  archive      = {J_TKDE},
  author       = {Yuyu Luo and Xuedi Qin and Chengliang Chai and Nan Tang and Guoliang Li and Wenbo Li},
  doi          = {10.1109/TKDE.2020.2981464},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {475-490},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Steerable self-driving data visualization},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatiotemporal activity modeling via hierarchical
cross-modal embedding. <em>TKDE</em>, <em>34</em>(1), 462–474. (<a
href="https://doi.org/10.1109/TKDE.2020.2983892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-increasing urbanization process, modeling people&#39;s spatiotemporal activities from their online traces has become a crucial task. State-of-the-art methods for this task rely on cross-modal embedding, which maps items from different modalities (e.g., location, time, text) into the same latent space. Despite their inspiring results, existing cross-modal embedding methods merely capture co-occurrences between items without modeling their high-order interactions. In this paper, we first construct two graphs from raw data records to represent the user interaction graph layer and activity graph layer and propose a hierarchical cross-modal embedding method that takes the high-order relationships into consideration. The key notion behind our method is a novel hierarchical embedding framework with meta-graphs connecting different layers. We introduce both inter-record and intra-record meta-graph structures, which enable learning distributed representations that preserve high-order proximities across graphs from different layers. Our empirical experiments on three real-world datasets demonstrate that our method not only outperforms state-of-the-art methods for spatiotemporal activity prediction, but also captures cross-modal proximity at a finer granularity.},
  archive      = {J_TKDE},
  author       = {Yang Liu and Xiang Ao and Linfeng Dong and Chao Zhang and Jin Wang and Qing He},
  doi          = {10.1109/TKDE.2020.2983892},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {462-474},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Spatiotemporal activity modeling via hierarchical cross-modal embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SoulMate: Short-text author linking through multi-aspect
temporal-textual embedding. <em>TKDE</em>, <em>34</em>(1), 448–461. (<a
href="https://doi.org/10.1109/TKDE.2020.2982148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linking authors of short-text contents has important usages in many applications, including Named Entity Recognition (NER) and human community detection. However, certain challenges lie ahead. First, the input short-text contents are noisy, ambiguous, and do not follow the grammatical rules. Second, traditional text mining methods fail to effectively extract concepts through words and phrases. Third, the textual contents are temporally skewed, which can affect the semantic understanding by multiple time facets. Finally, using knowledge-bases can make the results biased to the content of the external database and deviate the meaning from the input short text corpus. To overcome these challenges, we devise a neural network-based temporal-textual framework that generates the subgraphs with highly correlated authors from short-text contents. Our approach, on the one hand, computes the relevance score (edge weight) between the authors through considering a portmanteau of contents and concepts, and on the other hand, employs a stack-wise graph cutting algorithm to extract the communities of the related authors. Experimental results show that compared to other knowledge-centered competitors, our multi-aspect vector space model can achieve a higher performance in linking short-text authors. In addition, given the author linking task, the more comprehensive the dataset is, the higher the significance of the extracted concepts will be.},
  archive      = {J_TKDE},
  author       = {Saeed Najafipour and Saeid Hosseini and Wen Hua and Mohammad Reza Kangavari and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.2982148},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {448-461},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {SoulMate: Short-text author linking through multi-aspect temporal-textual embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RHINE: Relation structure-aware heterogeneous information
network embedding. <em>TKDE</em>, <em>34</em>(1), 433–447. (<a
href="https://doi.org/10.1109/TKDE.2020.2982898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information network (HIN) embedding aims to learn the low-dimensional representations of nodes while preserving structures and semantics in HINs. Although most existing methods consider heterogeneous relations and achieve promising performance, they usually employ one single model for all relations without distinction, which inevitably restricts the capability of HIN embedding. In this paper, we argue that heterogeneous relations have different structural characteristics, and propose a novel Relation structure-aware HIN Embedding model, called RHINE. By exploring four real-world networks with thorough analysis, we present two structure-related measures which consistently distinguish heterogeneous relations into two categories: Affiliation Relations (ARs) and Interaction Relations (IRs). To respect the distinctive structural characteristics of relations, in RHINE, we propose different models specifically tailored to handle ARs and IRs, which can better capture the structures in HINs. Finally, we combine and optimize these models in a unified manner. Furthermore, considering that nodes connected via heterogeneous relations may have multi-aspect semantics and each relation focuses on one aspect, we introduce relation-specific projection matrices to learn node and relation embeddings in separate spaces rather than a common space, which can better preserve the semantics in HINs, referring to a new model RHINE-M. Experiments on four real-world datasets demonstrate that our models significantly outperform the state-of-the-art methods in four tasks.},
  archive      = {J_TKDE},
  author       = {Chuan Shi and Yuanfu Lu and Linmei Hu and Zhiyuan Liu and Huadong Ma},
  doi          = {10.1109/TKDE.2020.2982898},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {433-447},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RHINE: Relation structure-aware heterogeneous information network embedding},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RDMN: A relative density measure based on MST neighborhood
for clustering multi-scale datasets. <em>TKDE</em>, <em>34</em>(1),
419–432. (<a href="https://doi.org/10.1109/TKDE.2020.2982400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density based clustering techniques discover the intrinsic clusters by separating the regions present in the dataset as high- and low-density regions based on their neighborhood information. They are popular and effective because they identify the clusters of arbitrary shapes and automatically detect the number of clusters. However, the distribution patterns of clusters are natural and complex in the datasets generated by different applications. Most of the existing density based clustering algorithms are not suitable to identify the clusters of complex pattern with large variation in density because they use fixed global parameters to compute the density of data points. Minimum spanning tree (MST) of a complete graph easily captures the intrinsic neighborhood information of different characteristic datasets without any user defined parameters. We propose a new Relative Density measure based on MST Neighborhood graph (RDMN) to compute the density of data points. Based on this new density measure, we propose a clustering technique to identify the clusters of complex patterns with varying density. The MST neighborhood graph is partitioned into dense regions based on the density level of data points to retain the shape of clusters. Finally, these regions are merged into actual clusters using MST based clustering technique. To the best of our knowledge, the proposed RDMN is the first MST based density measure for capturing the intrinsic neighborhood without any user defined parameter. Experimental results on synthetic and real datasets demonstrate that the proposed algorithm outperforms other popular clustering techniques in terms of cluster quality, accuracy, and robustness against noise and detecting the outliers.},
  archive      = {J_TKDE},
  author       = {Gaurav Mishra and Sraban Kumar Mohanty},
  doi          = {10.1109/TKDE.2020.2982400},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {419-432},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RDMN: A relative density measure based on MST neighborhood for clustering multi-scale datasets},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling dynamic missingness of implicit feedback for
sequential recommendation. <em>TKDE</em>, <em>34</em>(1), 405–418. (<a
href="https://doi.org/10.1109/TKDE.2020.2980517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit feedback is widely used in collaborative filtering methods for sequential recommendation. It is well known that implicit feedback contains a large number of values that are missing not at random (MNAR); and the missing data is a mixture of negative and unknown feedback, making it difficult to learn users’ negative preferences. Recent studies modeled exposure , a latent missingness variable which indicates whether an item is exposed to a user, to give each missing entry a confidence of being negative feedback. However, these studies use static models and ignore the information in temporal dependencies among items, which seems to be an essential underlying factor to subsequent missingness. To model and exploit the dynamics of missingness, we propose a latent variable named “ user intent ” to govern the temporal changes of item missingness, and a hidden Markov model to represent such a process. The resulting framework captures the dynamic item missingness and incorporates it into matrix factorization (MF) for recommendation. We further extend the proposed framework to capture the dynamic preference of users, which results in a unified framework that is able to model different evolution patterns of user intent and user preference. We also explore two types of constraints to achieve a more compact and interpretable representation of user intents . Experiments on real-world datasets demonstrate the superiority of our method against state-of-the-art recommender systems.},
  archive      = {J_TKDE},
  author       = {Xiaolin Zheng and Menghan Wang and Renjun Xu and Jianmeng Li and Yan Wang},
  doi          = {10.1109/TKDE.2020.2980517},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {405-418},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Modeling dynamic missingness of implicit feedback for sequential recommendation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Matrix completion via schatten capped <span
class="math inline"><em>p</em></span>p norm. <em>TKDE</em>,
<em>34</em>(1), 394–404. (<a
href="https://doi.org/10.1109/TKDE.2020.2978465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-rank matrix completion problem is fundamental in both machine learning and computer vision fields with many important applications, such as recommendation system, motion capture, face recognition, and image inpainting. In order to avoid solving the rank minimization problem which is NP-hard, several surrogate functions of the rank have been proposed in the literature. However, the matrix restored from the optimization problem based on the existing surrogate functions seriously deviates from the original one. In this paper, we first design a new non-convex Schatten capped $p$ norm which generalizes several existing non-convex matrix norms and balances between the rank and the nuclear norm of the matrix. Then, a matrix completion method based on the Schatten capped $p$ norm is proposed by exploiting the framework of the alternating direction method of multipliers. Meanwhile, the Schatten capped $p$ norm regularized least squares subproblem is analyzed in detail and is solved explicitly. Finally, we evaluate the performance of the proposed matrix completion method based on extensive experiments in the field of image inpainting. All the experimental results demonstrate that the proposed method can indeed improve the accuracy of matrix completion compared with the existing methods.},
  archive      = {J_TKDE},
  author       = {Guorui Li and Guang Guo and Sancheng Peng and Cong Wang and Shui Yu and Jianwei Niu and Jianli Mo},
  doi          = {10.1109/TKDE.2020.2978465},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {394-404},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Matrix completion via schatten capped $p$p norm},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning vertex representations for bipartite networks.
<em>TKDE</em>, <em>34</em>(1), 379–393. (<a
href="https://doi.org/10.1109/TKDE.2020.2979980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a widespread increase of interest in network representation learning (NRL). By far most research efforts have focused on NRL for homogeneous networks like social networks where vertices are of the same type, or heterogeneous networks like knowledge graphs where vertices (and/or edges) are of different types. There has been relatively little research dedicated to NRL for bipartite networks. Arguably, generic network embedding methods like node2vec and LINE can also be applied to learn vertex embeddings for bipartite networks by ignoring the vertex type information. However, these methods are suboptimal in doing so, since real-world bipartite networks concern the relationship between two types of entities, which usually exhibit different properties and patterns from other types of network data. For example, E-Commerce recommender systems need to capture the collaborative filtering patterns between customers and products, and search engines need to consider the matching signals between queries and webpages. This work addresses the research gap of learning vertex representations for bipartite networks. We present a new solution BiNE, short for Bi partite N etwork E mbedding , which accounts for two special properties of bipartite networks: long-tail distribution of vertex degrees and implicit connectivity relations between vertices of the same type. Technically speaking, we make three contributions: (1) We design a biased random walk generator to generate vertex sequences that preserve the long-tail distribution of vertices; (2) We propose a new optimization framework by simultaneously modeling the explicit relations (i.e., observed links) and implicit relations (i.e., unobserved but transitive links); (3) We explore the theoretical foundations of BiNE to shed light on how it works, proving that BiNE can be interpreted as factorizing multiple matrices. We perform extensive experiments on five real datasets covering the tasks of link prediction (classification) and recommendation (ranking), empirically verifying the effectiveness and rationality of BiNE. Our experiment codes are available at: https://github.com/clhchtcjj/BiNE .},
  archive      = {J_TKDE},
  author       = {Ming Gao and Xiangnan He and Leihui Chen and Tingting Liu and Jinglin Zhang and Aoying Zhou},
  doi          = {10.1109/TKDE.2020.2979980},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {379-393},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Learning vertex representations for bipartite networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large scale tensor factorization via parallel sketches.
<em>TKDE</em>, <em>34</em>(1), 365–378. (<a
href="https://doi.org/10.1109/TKDE.2020.2982144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor factorization methods have recently gained increased popularity. A key feature that renders tensors attractive is the ability to directly model multi-relational data. In this work, we propose ParaSketch, a parallel tensor factorization algorithm that enables massive parallelism, to deal with large tensors. The idea is to compress the large tensor into multiple small tensors, decompose each small tensor in parallel, and combine the results to reconstruct the desired latent factors. Prior art in this direction entails potentially very high complexity in the (Gaussian) compression and final combining stages. Adopting sketching matrices for compression, the proposed method enjoys a dramatic reduction in compression complexity, and features a much lighter combining step. Moreover, theoretical analysis shows that the compressed tensors inherit latent identifiability under mild conditions, hence establishing correctness of the overall approach. Numerical experiments corroborate the theory and demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_TKDE},
  author       = {Bo Yang and Ahmed S. Zamzam and Nicholas D. Sidiropoulos},
  doi          = {10.1109/TKDE.2020.2982144},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {365-378},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Large scale tensor factorization via parallel sketches},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lamps: Location-aware moving top-k pub/sub. <em>TKDE</em>,
<em>34</em>(1), 352–364. (<a
href="https://doi.org/10.1109/TKDE.2020.2979176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Huge amounts of spatio-textual objects, such as geo-tagged tweets, are being generated at an unprecedented scale, leading to a variety of applications such as location-based recommendation and sponsored search. Many of these applications need to support moving top-k spatio-textual subscriptions. For example, while walking, a tourist issues a moving subscription and looks for top-k advertisements published by nearby shops. Unfortunately, existing methods that monitor the results of spatio-textual subscriptions support only static top-k subscriptions or moving boolean subscriptions. In this article, we propose a novel system, called Lamps (Location-Aware Moving Top-k Pub/Sub), which continuously monitors the top-k most relevant spatio-textual objects for a large number of moving top-k spatio-textual subscriptions simultaneously. To the best of our knowledge, this is the first study of a location-aware moving top-k pub/sub system. As with existing works on continuous moving top-k subscription processing, Lamps employs the concept of a safe region to monitor top-k results. However, unlike with existing works that assume static objects, top-k result updates may be triggered by newly generated objects. To continuously monitor the top-k results for massive moving subscriptions efficiently, we propose SQ-tree, a novel index based on safe regions, to filter subscriptions whose top-k results do not change. Moreover, to reduce the expensive cost of safe region re-evaluation, we develop a novel approximation technique for safe region construction. Our experimental results on real datasets show that Lamps achieves higher performance than baseline approaches.},
  archive      = {J_TKDE},
  author       = {Shunya Nishio and Daichi Amagata and Takahiro Hara},
  doi          = {10.1109/TKDE.2020.2979176},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {352-364},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Lamps: Location-aware moving top-k Pub/Sub},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Label propagated nonnegative matrix factorization for
clustering. <em>TKDE</em>, <em>34</em>(1), 340–351. (<a
href="https://doi.org/10.1109/TKDE.2020.2982387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) that utilizes plenty of unlabeled examples to boost the performance of learning from limited labeled examples is a powerful learning paradigm with widely real-world applications such as information retrieval and document clustering. Label propagation (LP) is a popular SSL method which propagates labels through the dataset along high density areas defined by unlabeled examples, but it is fragile to bridge examples. Semi-supervised K-Means uses labeled examples to initialize clustering centers to separate different examples, however, semi-supervised K-Means fails in the situation of imbalanced issues, that is, the example size of each class varies significantly. This paper proposes a novel label propagated nonnegative matrix factorization method (LPNMF) to handle clean labeled but biased data and its extension LPNMF-E to handle noisy labeled data based on the framework of NMF. LPNMF decomposes the whole dataset into the product of a basis matrix and a coefficient matrix. To propagate labels to unlabeled examples, LPNMF regards the class indicators of labeled examples as their coefficients and iteratively updates both basis matrix and coefficients of unlabeled examples. LPNMF absorbs the merits from both semi-supervised K-Means and label propagation to handle their respective shortages. Specifically, on the one hand, LPNMF learns representative clustering centers based on the distribution of the dataset, similar to semi-supervised K-means, and thus is robust to the bridge examples. On the other hand, LPNMF pushes labels according to the affinity between examples, similar to label propagation, and thus relieves the biased problem. Moreover, we introduce a LPNMF extension to handle the noisy label case. LPNMF-E relaxes the constraint of labeled examples. Since the label of each labeled example also obtains label information from the global distribution of the whole dataset and local manifold of its neighbors, LPNMF-E outputs reliable class indicators even if a portion of examples are incorrectly labeled. Theoretical analyses for the generalization ability of our proposed models are also provided. Experimental results on both clean and noisy labeled datasets confirm the effectiveness of LPNMF and LPNMF-E compared with both LP and the representative semi-supervised K-Means algorithms.},
  archive      = {J_TKDE},
  author       = {Long Lan and Tongliang Liu and Xiang Zhang and Chuanfu Xu and Zhigang Luo},
  doi          = {10.1109/TKDE.2020.2982387},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {340-351},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Label propagated nonnegative matrix factorization for clustering},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HyperMinHash: MinHash in LogLog space. <em>TKDE</em>,
<em>34</em>(1), 328–339. (<a
href="https://doi.org/10.1109/TKDE.2020.2981311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this extended abstract, we describe and analyze a lossy compression of MinHash from buckets of size $O(\log n)$ to buckets of size $O(\log \log n)$ by encoding using floating-point notation. This new compressed sketch, which we call HyperMinHash, as we build off a HyperLogLog scaffold, can be used as a drop-in replacement of MinHash. Unlike comparable Jaccard index fingerprinting algorithms in sub-logarithmic space (such as b-bit MinHash), HyperMinHash retains MinHash&#39;s features of streaming updates, unions, and cardinality estimation. For a additive approximation error $\epsilon$ on a Jaccard index $ t$ , given a random oracle, HyperMinHash needs $O\left(\epsilon ^{-2} \left(\log \log n + \log \frac{1}{ \epsilon } \right)\right)$ space. HyperMinHash allows estimating Jaccard indices of 0.01 for set cardinalities on the order of $10^{19}$ with relative error of around 10 percent using 2MiB of memory; MinHash can only estimate Jaccard indices for cardinalities of $10^{10}$ with the same memory consumption.},
  archive      = {J_TKDE},
  author       = {Yun William Yu and Griffin M. Weber},
  doi          = {10.1109/TKDE.2020.2981311},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {328-339},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {HyperMinHash: MinHash in LogLog space},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical prediction and adversarial learning for
conditional response generation. <em>TKDE</em>, <em>34</em>(1), 314–327.
(<a href="https://doi.org/10.1109/TKDE.2020.2977637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are a variety of underlying factors influencing what and how people communicate in their daily life. The ability to capture and utilize these factors enables the conversational systems to generate favorable responses and set up amicable connections with users. In this work, we investigate two major factors in response generation, i.e., emotion and intention. To explore the dependency between them, we develop a hierarchical variational model that predicts in sequence the emotion and intention to be conveyed in a response. The response can then be generated word-by-word based on the predictions. We also apply a novel adversarial-augmented inference network to facilitate model training. The experimental results demonstrate the effectiveness of the proposed model as well as the novel adversarial objective. The hypothesis that emotion shapes human communication behavior is also validated.},
  archive      = {J_TKDE},
  author       = {Yanran Li and Ruixiang Zhang and Wenjie Li and Ziqiang Cao},
  doi          = {10.1109/TKDE.2020.2977637},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {314-327},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical prediction and adversarial learning for conditional response generation},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fastest path query answering using time-dependent
hop-labeling in road network. <em>TKDE</em>, <em>34</em>(1), 300–313.
(<a href="https://doi.org/10.1109/TKDE.2020.2981062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the fastest path in the time-dependent road network is time consuming because its problem complexity is $\Omega (T(|V|\log |V|+|E|))$ , where $T$ is the size of the result&#39;s time-dependent function, $|V|$ and $|E|$ are the number of vertices and edges. There are three kinds of fastest path problems: SSFP (Single-Staring Time Fastest Path) that has a fixed departure time, ISFP (Interval-Staring Time Fastest Path) that selects the best departure time from an interval, and FPP (Fastest Path Profile) that returns the travel time of the entire time domain. In this paper, we aim to answer these three queries in time-dependent road network faster by extending the 2-hop labeling approach, which is fast in answering shortest distance query in the static graph. However, it is hard to construct index for SSFP and ISFP because there are $|\mathcal {T}|$ and $|\mathcal {T}|^2$ possible time points and intervals, where $\mathcal {T}$ is the time domain. Therefore, we first propose the time-dependent hop-labeling for FPP , then provide the specific optimizations for SSFP and ISFP query answering. Moreover, it is both time and space consuming to build an index in a large time-dependent graph, so we partition road network into smaller sub-graphs and build indexes within and between the partitions. Furthermore, we propose an online approximation technique AT-Dijkstra and a bottom-up compression method to further reduce the label size, save construction time and speedup query answering. Experiments on real world road network show that our approach outperforms the state-of-art fastest path index approaches and can speed up the query answering by hundreds of times.},
  archive      = {J_TKDE},
  author       = {Lei Li and Sibo Wang and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.2981062},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {300-313},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fastest path query answering using time-dependent hop-labeling in road network},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast multi-view semi-supervised learning with learned graph.
<em>TKDE</em>, <em>34</em>(1), 286–299. (<a
href="https://doi.org/10.1109/TKDE.2020.2978844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view semi-supervised learning (SSL) has attracted great attention due to its effectiveness in information utilization of multiple views and labeled and unlabeled data to solve practical problems. However, most existing methods exhibit high computational complexity. Effective integration of the information on different views to achieve enhanced performance remains a challenging task. In this study, we combine an anchor-based approach with multi-view semi-supervised learning to address these problems. A novel multi-view SSL method called fast multi-view SSL (FMSSL) based on learned graph is proposed. Starting from the affinity graphs constructed by using an anchor-based strategy, FMSSL learns an optimal multi-view consensus graph by using feature and label information. The learned graph can jointly consider the relation of multiple views to approximate the manifold structure. The learned graph is then introduced into the SSL model as the weight matrix of a bipartite graph to simultaneously perform separate classification on the original samples and anchors. Accordingly, multi-view SSL can be efficiently performed, and the computational complexity can be significantly reduced. We propose an effective algorithm to optimize the objective function. Extensive experimental results on different real-world datasets demonstrate the effectiveness and efficiency of the proposed algorithm.},
  archive      = {J_TKDE},
  author       = {Bin Zhang and Qianyao Qiang and Fei Wang and Feiping Nie},
  doi          = {10.1109/TKDE.2020.2978844},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {286-299},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fast multi-view semi-supervised learning with learned graph},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DGDFS: Dependence guided discriminative feature selection
for predicting adverse drug-drug interaction. <em>TKDE</em>,
<em>34</em>(1), 271–285. (<a
href="https://doi.org/10.1109/TKDE.2020.2978055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse drug-drug interaction (ADDI) is referred to as a situation where the unpleasant or adverse effects caused by the co-administration of two drugs, which becomes a significant problem for public health. With the increasing availability of healthcare data, many methods are proposed for ADDI prediction. However, these methods usually work in a “nondiscriminatory” manner, i.e., they treat each feature without discrimination and equally incorporate all features into the predictive models. In practice, only a few features are essentially discriminative and relevant to ADDIs. In this paper, we propose a Dependence Guided Discriminative Feature Selection (DGDFS) model for ADDI prediction. In DGDFS, two drug attributes, molecular structure and side effect are adopted to model the adverse interaction among drugs and $l_{2,0}$ -norm equality constraints are introduced to select discriminative molecular substructures and side effects for ADDI prediction. Besides, three dependence guided terms, i.e., the dependence between molecular structure and ADDI, the dependence between side effect and ADDI, and the dependence between molecular structure and side effect, are designed to guide feature selection. An iterative algorithm based on the alternating direction method of multipliers is developed for optimization. Experimental results indicate the effectiveness of DGDFS compared with fourteen baselines and its three variants.},
  archive      = {J_TKDE},
  author       = {Jiajing Zhu and Yongguo Liu and Chuanbiao Wen and Xindong Wu},
  doi          = {10.1109/TKDE.2020.2978055},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {271-285},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {DGDFS: Dependence guided discriminative feature selection for predicting adverse drug-drug interaction},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning on graphs: A survey. <em>TKDE</em>,
<em>34</em>(1), 249–270. (<a
href="https://doi.org/10.1109/TKDE.2020.2981333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been shown to be successful in a number of domains, ranging from acoustics, images, to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs. Recently, substantial research efforts have been devoted to applying deep learning methods to graphs, resulting in beneficial advances in graph analysis techniques. In this survey, we comprehensively review the different types of deep learning methods on graphs. We divide the existing methods into five categories based on their model architectures and training strategies: graph recurrent neural networks, graph convolutional networks, graph autoencoders, graph reinforcement learning, and graph adversarial methods. We then provide a comprehensive overview of these methods in a systematic manner mainly by following their development history. We also analyze the differences and compositions of different methods. Finally, we briefly outline the applications in which they have been used and discuss potential future research directions.},
  archive      = {J_TKDE},
  author       = {Ziwei Zhang and Peng Cui and Wenwu Zhu},
  doi          = {10.1109/TKDE.2020.2981333},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {249-270},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Deep learning on graphs: A survey},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost-sensitive portfolio selection via deep reinforcement
learning. <em>TKDE</em>, <em>34</em>(1), 236–248. (<a
href="https://doi.org/10.1109/TKDE.2020.2979700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio Selection is an important real-world financial task and has attracted extensive attention in artificial intelligence communities. This task, however, has two main difficulties: (i) the non-stationary price series and complex asset correlations make the learning of feature representation very hard; (ii) the practicality principle in financial markets requires controlling both transaction and risk costs. Most existing methods adopt handcraft features and/or consider no constraints for the costs, which may make them perform unsatisfactorily and fail to control both costs in practice. In this paper, we propose a cost-sensitive portfolio selection method with deep reinforcement learning. Specifically, a novel two-stream portfolio policy network is devised to extract both price series patterns and asset correlations, while a new cost-sensitive reward function is developed to maximize the accumulated return and constrain both costs via reinforcement learning. We theoretically analyze the near-optimality of the proposed reward, which shows that the growth rate of the policy regarding this reward function can approach the theoretical optimum. We also empirically evaluate the proposed method on real-world datasets. Promising results demonstrate the effectiveness and superiority of the proposed method in terms of profitability, cost-sensitivity and representation abilities.},
  archive      = {J_TKDE},
  author       = {Yifan Zhang and Peilin Zhao and Qingyao Wu and Bin Li and Junzhou Huang and Mingkui Tan},
  doi          = {10.1109/TKDE.2020.2979700},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {236-248},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cost-sensitive portfolio selection via deep reinforcement learning},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Copula guided parallel gibbs sampling for nonparametric and
coherent topic discovery. <em>TKDE</em>, <em>34</em>(1), 219–235. (<a
href="https://doi.org/10.1109/TKDE.2020.2976945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Dirichlet Process (HDP) has attracted much attention in the research community of natural language processing. Given a corpus, HDP is able to determine the number of topics automatically, possessing an important feature dubbed nonparametric that overcomes the challenging issue of manually specifying a suitable topic number in parametric topic models, such as Latent Dirichlet Allocation (LDA). Nevertheless, HDP requires a much higher computational cost than LDA for parameter estimation. By taking the advantage of multi-threading, a parallel Gibbs sampling algorithm is proposed to estimate parameters for HDP based on the equivalence between HDP and Gamma-Gamma Poisson Process (G2PP) in terms of the generative process. Unfortunately, the above parallel Gibbs sampling algorithm requires to apply the finite approximation on the number of topics manually (i.e., predefine the topic number), thus can not retain the nonparametric feature of HDP. Another drawback of the above models is the lack of capturing the semantic dependencies between words, because the topic assignment of words is independent with each other. Although some works have been done in phrase-based topic modelling, these existing methods are still limited by either enforcing the entire phrase to share a common topic or requiring much complex and time-consuming phrase mining methods. In this paper, we aim to develop a copula guided parallel Gibbs sampling algorithm for HDP which can adjust the number of topics dynamically and capture the latent semantic dependencies between words that compose a coherent segment. Extensive experiments on real-world datasets indicate that our method achieves low perplexities and high topic coherence scores with a small time cost. In addition, we validate the effectiveness of our method on the modelling of word semantic dependencies by comparing the extracted topical phrases with those learned by state-of-the-art phrase-based baselines.},
  archive      = {J_TKDE},
  author       = {Lihui Lin and Yanghui Rao and Haoran Xie and Raymond Y. K. Lau and Jian Yin and Fu Lee Wang and Qing Li},
  doi          = {10.1109/TKDE.2020.2976945},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {219-235},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Copula guided parallel gibbs sampling for nonparametric and coherent topic discovery},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constrained truth discovery. <em>TKDE</em>, <em>34</em>(1),
205–218. (<a href="https://doi.org/10.1109/TKDE.2020.2982393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To aggregate useful information among diversified sources, a hotspot research topic called truth discovery has emerged in recent years. Existing truth discovery methods attempt to infer the true attribute values for the entities by identifying and trusting reliable data sources. That is, the values provided by reliable sources are more likely to be the true values. However, all these methods neglect the relations among different entities, which play important roles in truth discovery task. When reliable data sources cannot provide sufficient information of entities, the true attribute values of these entities can still be inferred by propagating trustworthy information from related entities. Motivated by this, in this paper, we introduce the constrained truth discovery problem. We incorporate denial constraints, a universally quantified first-order logic formalism which can express a large number of effective and widely existing relations among entities, into the process of truth discovery. We formulate it as a constrained optimization problem and analyze its hardness. To address the problem, we propose algorithms to partition the entities into disjoint groups, and generate arithmetic constraints for each disjoint group separately. Then, the true attribute values of the entities in each disjoint group are derived by minimizing the objective function under the corresponding arithmetic constraints. Experimental results on both real-world and synthetic datasets demonstrate that the proposed approach achieves good performance even with very few constraints and reliable sources.},
  archive      = {J_TKDE},
  author       = {Chen Ye and Hongzhi Wang and Kangjie Zheng and Youkang Kong and Rong Zhu and Jing Gao and Jianzhong Li},
  doi          = {10.1109/TKDE.2020.2982393},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {205-218},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Constrained truth discovery},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collective decision for open set recognition. <em>TKDE</em>,
<em>34</em>(1), 192–204. (<a
href="https://doi.org/10.1109/TKDE.2020.2978199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In open set recognition (OSR), almost all existing methods are designed specially for recognizing individual instances, even these instances are collectively coming in batch. Recognizers in decision either reject or categorize them to some known class using empirically-set threshold. Thus the decision threshold plays a key role. However, the selection for it usually depends on the knowledge of known classes, inevitably incurring risks due to lacking available information from unknown classes. On the other hand, a more realistic OSR system should NOT just rest on a reject decision but should go further, especially for discovering the hidden unknown classes among the reject instances, whereas existing OSR methods do not pay special attention. In this paper, we introduce a novel collective/batch decision strategy with an aim to extend existing OSR for new class discovery while considering correlations among the testing instances. Specifically, a collective decision-based OSR framework (CD-OSR) is proposed by slightly modifying the Hierarchical Dirichlet process (HDP). Thanks to HDP, our CD-OSR does not need to define the decision threshold and can implement the open set recognition and new class discovery simultaneously. Finally, extensive experiments on benchmark datasets indicate the validity of CD-OSR.},
  archive      = {J_TKDE},
  author       = {Chuanxing Geng and Songcan Chen},
  doi          = {10.1109/TKDE.2020.2978199},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {192-204},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Collective decision for open set recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cohesive subgraph search using keywords in large networks.
<em>TKDE</em>, <em>34</em>(1), 178–191. (<a
href="https://doi.org/10.1109/TKDE.2020.2975793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyword search has been widely studied to retrieve relevant substructures from graphs for a given set of keywords. However, existing well-studied approaches aim at finding compact trees/subgraphs containing the keywords, and ignore a critical measure, density, to represent how strongly and stably the keyword nodes are connected in the substructure. In this paper, given a set of keywords $Q = \lbrace w_1, w_2, \ldots, w_l\rbrace$ , we study the problem of finding a cohesive subgraph containing $Q$ with high density and compactness from a graph $G$ . We model the cohesive subgraph based on a carefully chosen $k$ -truss model, and formulate the problem of finding cohesive subgraphs for keyword queries as minimal dense truss search problem, i.e., finding minimal subgraph that maximizes the trussness covering $Q$ . However, unlike $k$ -truss based community search that can be efficiently done based on the local search from a given set of nodes, minimal dense truss search for keyword queries is a nontrivial task as the subset of keyword nodes to be included in the retrieved substructure is previously unknown. To tackle this problem, we first design a novel hybrid KT-Index to keep the keyword and truss information compacly, and then propose an efficient algorithm that carries the search on KT-Index directly to find the dense truss with the maximum trussness $G_{den}$ without repeated accesses to the original graph. Then, we develop a novel refinement approach to extract minimal dense truss from the dense truss $G_{den}$ , by checking each node at most once based on the anti-monotonicity property derived from $k$ -truss, together with several optimization strategies including batch based deletion, early-stop based deletion, and local exploration. Moreover, we also extend the proposed method to deal with the top- $r$ search. Extensive experimental studies on real-world networks validated the effectiveness and efficiency of our approaches.},
  archive      = {J_TKDE},
  author       = {Yuanyuan Zhu and Qian Zhang and Lu Qin and Lijun Chang and Jeffrey Xu Yu},
  doi          = {10.1109/TKDE.2020.2975793},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {178-191},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Cohesive subgraph search using keywords in large networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An optimal online semi-connected PLA algorithm with maximum
error bound. <em>TKDE</em>, <em>34</em>(1), 164–177. (<a
href="https://doi.org/10.1109/TKDE.2020.2981319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Piecewise Linear Approximation (PLA) is one of the most widely used approaches for representing a time series with a set of approximated line segments. With this compressed form of representation, many large complicated time series can be efficiently stored, transmitted and analyzed. In this article, with the introduced concept of “semi-connection” that allowing two representation lines to be connected at a point between two consecutive time stamps, we propose a new optimal linear-time PLA algorithm SemiOptConnAlg for generating the least number of semi-connected line segments with guaranteed maximum error bound. With extended experimental tests, we demonstrate that the proposed algorithm is very efficient in execution time and achieves better performances than the state-of-art solutions.},
  archive      = {J_TKDE},
  author       = {Huanyu Zhao and Chaoyi Pang and Ramamohanarao Kotagiri and Christopher K. Pang and Ke Deng and Jian Yang and Tongliang Li},
  doi          = {10.1109/TKDE.2020.2981319},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {164-177},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An optimal online semi-connected PLA algorithm with maximum error bound},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An online robust support vector regression for data streams.
<em>TKDE</em>, <em>34</em>(1), 150–163. (<a
href="https://doi.org/10.1109/TKDE.2020.2979967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since support vector regression (SVR) is a flexible regression algorithm, its computational complexity does not depend on the dimensionality of the input space, and it has excellent generalization capability. However, a central assumption with SVRs is that all the required data is available at the time of construction, which means these algorithms cannot be used with data streams. Incremental SVR has been offered as a potential solution, but its accuracy suffers with noise and learning speeds are slow. To overcome these two limitations, we propose a novel incremental regression algorithm, called online robust support vector regression (ORSVR). ORSVR solves nonparallel bound functions simultaneously. Hence, the large quadratic programming problem (QPP) in classical v-SVR are decomposed into two smaller QPPs. An incremental learning algorithm then solves each QPP step-by-step. The results of a series of comparative experiments demonstrate that the ORSVR algorithm efficiently solves regression problems in data streams, with or without noise, and speeds up the learning process.},
  archive      = {J_TKDE},
  author       = {Hang Yu and Jie Lu and Guangquan Zhang},
  doi          = {10.1109/TKDE.2020.2979967},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {150-163},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {An online robust support vector regression for data streams},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aligning points to lines: Provable approximations.
<em>TKDE</em>, <em>34</em>(1), 138–149. (<a
href="https://doi.org/10.1109/TKDE.2020.2980836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We suggest a new optimization technique for minimizing the sum $\sum _{i=1}^n g_i(x)$ of $n$ non-convex real functions that satisfy a property that we call piecewise log-Lipschitz. This is by forging links between techniques in computational geometry, combinatorics and convex optimization. As an example application, we provide the first constant-factor approximation algorithms whose running-times are polynomial in $n$ for the fundamental problem of Points-to-Lines alignment : Given $n$ points $p_1,\ldots,p_n$ and $n$ lines $\ell _1,\ldots,\ell _n$ on the plane and $z&amp;gt;0$ , compute the matching $\pi :[n]\to [n]$ and alignment (rotation matrix $R$ and translation vector $t$ ) that minimize the sum of euclidean distances $\sum _{i=1}^n \mathrm{dist}(Rp_i-t,\ell _{\pi (i)})^z$ between each point to its corresponding line. This problem is non-trivial even if $z=1$ and the matching $\pi$ is given. If $\pi$ is given, our algorithms run in $O(n^3)$ time, and even near-linear in $n$ using core-sets that support: streaming, dynamic, and distributed parallel computations in poly-logarithmic update time. Generalizations for handling e.g., outliers or pseudo-distances such as $M$ -estimators for the problem are also provided. Experimental results and open source code show that our algorithms improve existing heuristics also in practice. A companion demonstration video in the context of Augmented Reality shows how such algorithms may be used in real-time systems.},
  archive      = {J_TKDE},
  author       = {Ibrahim Jubran and Dan Feldman},
  doi          = {10.1109/TKDE.2020.2980836},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {138-149},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Aligning points to lines: Provable approximations},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Activity organization for friend-making optimization in
online social networks. <em>TKDE</em>, <em>34</em>(1), 122–137. (<a
href="https://doi.org/10.1109/TKDE.2020.2980516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The social presence theory in social psychology suggests that computer-mediated online interactions are inferior to face-to-face, in-person interactions. Thus, it&#39;s important to organize social activities for online social network users to meet in person. In this paper, we consider the scenarios of organizing in person friend-making social activities via online social networks (OSNs) and formulate a new research problem, namely, Hop-bounded Maximum Group Friending (HMGF) , that takes into consideration both existing friendships and the likelihood of new friend making in organization of the targeted in person friend-making social activities. To find a set of attendees for such social activities, HMGF is unique and challenging due to the interplay of the group size, the constraint on existing friendships, and the objective of maximizing the likelihood of friend making. We prove that HMGF is NP-Hard, and there exists no approximation algorithm for it unless $P=NP$ . We also provide an Integer Linear Programming (ILP) formulation for the HMGF problem. The ILP formulation, which can be solved efficiently by a commercial solver to obtain the optimal solution for small HMGF instances, acts as a baseline approach for comparison in the evaluation of the proposed algorithm. We further propose an error-bounded approximation algorithm, MaxGF , to efficiently obtain the solutions very close to the optimal solutions. To boost the performance, we devise two graph-theoretical pruning strategies, namely Neighbor Pruning and Core Pruning , which can effectively avoid redundant graph explorations to improve the performance of HMGF. We also study HMGF on a class of special graphs, threshold graphs , which have properties very similar to many online social networks. We prove that MaxGF can obtain the optimal solution to HMGF on threshold graphs in polynomial time. We conduct a user study to validate our problem formulation and perform extensive experiments on real datasets to demonstrate the efficiency and effectiveness of our proposed algorithm. The experimental results manifest that our proposed algorithms outperform the baselines, including the ILP formulation.},
  archive      = {J_TKDE},
  author       = {Chih-Ya Shen and De-Nian Yang and Wang-Chien Lee and Ming-Syan Chen},
  doi          = {10.1109/TKDE.2020.2980516},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {122-137},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Activity organization for friend-making optimization in online social networks},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Achieving secure and dynamic range queries over encrypted
cloud data. <em>TKDE</em>, <em>34</em>(1), 107–121. (<a
href="https://doi.org/10.1109/TKDE.2020.2983030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is motivating data owners to outsource their databases to the cloud. However, for privacy concerns, the sensitive data has to be encrypted before outsourcing, which inevitably posts a challenging task for effective data utilization. Existing work either focuses on keyword searches, or suffers from inadequate security guarantees or inefficiency. In this paper, we concentrate on multi-dimensional range queries over dynamic encrypted cloud data. We first propose a tree-based private range query scheme over dynamic encrypted cloud data (TRQED), which supports faster-than-linear range queries and protects single-dimensional privacy. Then, we discuss the defects of TRQED in terms of privacy-preservation. We modify the framework of the system by adopting a two-server model and put forward a safer range query scheme, called TRQED $^{+}$ . By newly designed secure node query (SNQ) and secure point query (SPQ), we propose the perturbation-based oblivious R-tree traversal (ORT) operation to preserve both path pattern and stronger single-dimensional privacy. Finally, we conduct comprehensive experiments on real-world datasets and perform comparisons with existing works to evaluate the performance of the proposed schemes. Experimental results show that our TRQED and TRQED $^+$ surpass the state-of-the-art methods in privacy-preservation level and efficiency.},
  archive      = {J_TKDE},
  author       = {Wei Yang and Yangyang Geng and Lu Li and Xike Xie and Liusheng Huang},
  doi          = {10.1109/TKDE.2020.2983030},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {107-121},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Achieving secure and dynamic range queries over encrypted cloud data},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accurately estimating user cardinalities and detecting super
spreaders over time. <em>TKDE</em>, <em>34</em>(1), 92–106. (<a
href="https://doi.org/10.1109/TKDE.2020.2975625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online monitoring user cardinalities in graph streams is fundamental for many applications such as anomaly detection. These graph streams may contain edge duplicates and have a large number of user-item pairs, which makes it infeasible to exactly compute user cardinalities due to limited computational and memory resources. Existing methods are designed to approximately estimate user cardinalities, but their accuracy highly depends on complex parameters and they cannot provide anytime-available estimation. To address these problems, we develop novel bit/register sharing algorithms, which use a bit/register array to build a compact sketch of all users’ connected items. Our algorithms exploit the dynamic properties of the bit/register arrays (e.g., the fraction of zero bits in the bit array) to significantly improve the estimation accuracy, and have low time complexity $O(1)$ to update the estimations for a new user-item pair. In addition, our algorithms are simple and easy to use, without requirements to tune any parameter. Furthermore, we extend our methods to detect super spreaders with large cardinalities in real-time. We evaluate the performance of our methods on real-world datasets. The experimental results demonstrate that our methods are several times more accurate and faster than state-of-the-art methods using the same amount of memory.},
  archive      = {J_TKDE},
  author       = {Peng Jia and Pinghui Wang and Yuchao Zhang and Xiangliang Zhang and Jing Tao and Jianwei Ding and Xiaohong Guan and Don Towsley},
  doi          = {10.1109/TKDE.2020.2975625},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {92-106},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Accurately estimating user cardinalities and detecting super spreaders over time},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on spark ecosystem: Big data processing
infrastructure, machine learning, and applications. <em>TKDE</em>,
<em>34</em>(1), 71–91. (<a
href="https://doi.org/10.1109/TKDE.2020.2975652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive increase of big data in industry and academic fields, it is important to apply large-scale data processing systems to analyze Big Data. Arguably, Spark is the state-of-the-art in large-scale data computing systems nowadays, due to its good properties including generality, fault tolerance, high performance of in-memory data processing, and scalability. Spark adopts a flexible Resident Distributed Dataset (RDD) programming model with a set of provided transformation and action operators whose operating functions can be customized by users according to their applications. It is originally positioned as a fast and general data processing system. A large body of research efforts have been made to make it more efficient (faster) and general by considering various circumstances since its introduction. In this survey, we aim to have a thorough review of various kinds of optimization techniques on the generality and performance improvement of Spark. We introduce Spark programming model and computing system, discuss the pros and cons of Spark, and have an investigation and classification of various solving techniques in the literature. Moreover, we also introduce various data management and processing systems, machine learning algorithms and applications supported by Spark. Finally, we make a discussion on the open issues and challenges for large-scale in-memory data processing with Spark.},
  archive      = {J_TKDE},
  author       = {Shanjiang Tang and Bingsheng He and Ce Yu and Yusen Li and Kun Li},
  doi          = {10.1109/TKDE.2020.2975652},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {71-91},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on spark ecosystem: Big data processing infrastructure, machine learning, and applications},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on deep learning for named entity recognition.
<em>TKDE</em>, <em>34</em>(1), 50–70. (<a
href="https://doi.org/10.1109/TKDE.2020.2981314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.},
  archive      = {J_TKDE},
  author       = {Jing Li and Aixin Sun and Jianglei Han and Chenliang Li},
  doi          = {10.1109/TKDE.2020.2981314},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {50-70},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey on deep learning for named entity recognition},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of data-driven and knowledge-aware eXplainable AI.
<em>TKDE</em>, <em>34</em>(1), 29–49. (<a
href="https://doi.org/10.1109/TKDE.2020.2983930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are witnessing a fast development of Artificial Intelligence (AI), but it becomes dramatically challenging to explain AI models in the past decade. “Explanation” has a flexible philosophical concept of “satisfying the subjective curiosity for causal information”, driving a wide spectrum of methods being invented and/or adapted from many aspects and communities, including machine learning, visual analytics, human-computer interaction and so on. Nevertheless, from the view-point of data and knowledge engineering (DKE), a best explaining practice that is cost-effective in terms of extra intelligence acquisition should exploit the causal information and explaining scenarios which is hidden richly in the data itself. In the past several years, there are plenty of works contributing in this line but there is a lack of a clear taxonomy and systematic review of the current effort. To this end, we propose this survey, reviewing and taxonomizing existing efforts from the view-point of DKE, summarizing their contribution, technical essence and comparative characteristics. Specifically, we categorize methods into data-driven methods where explanation comes from the task-related data, and knowledge-aware methods where extraneous knowledge is incorporated. Furthermore, in the light of practice, we provide survey of state-of-art evaluation metrics and deployed explanation applications in industrial practice.},
  archive      = {J_TKDE},
  author       = {Xiao-Hui Li and Caleb Chen Cao and Yuhan Shi and Wei Bai and Han Gao and Luyu Qiu and Cong Wang and Yuanyuan Gao and Shenjia Zhang and Xun Xue and Lei Chen},
  doi          = {10.1109/TKDE.2020.2983930},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {29-49},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey of data-driven and knowledge-aware eXplainable AI},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey and quantitative study on map inference algorithms
from GPS trajectories. <em>TKDE</em>, <em>34</em>(1), 15–28. (<a
href="https://doi.org/10.1109/TKDE.2020.2977034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Map inference algorithm aims to construct a digital map from other data sources automatically. Due to the labour intensity of traditional map creation and the frequent road change nowadays, map inference is deemed to be a promising solution to automatic map construction and update. However, existing map inference from GPS trajectories suffers from low GPS data quality, which makes the quality of the constructed map unsatisfactory. In this paper, we study the existing map inference algorithms using GPS trajectories. Different from previous surveys, we (1) include the most recent solutions and propose a new categorisation of method; (2) study how different types of GPS errors affect the quality of inference results; (3) evaluate the existing map inference quality measures regarding their ability to identify map quality issues. To achieve these goals, we conduct a comprehensive experimental study on several representative algorithms using both real-world datasets and synthetic datasets, which are generated from our proposed synthetic trajectory generator and artificial map generator. Overall, our study provides insightful observations regarding (1) which inference method performs better in each working scenario, (2) the general data quality requirements for map inference, (3) the direction of future works for quantitative map quality measures.},
  archive      = {J_TKDE},
  author       = {Pingfu Chao and Wen Hua and Rui Mao and Jiajie Xu and Xiaofang Zhou},
  doi          = {10.1109/TKDE.2020.2977034},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {15-28},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey and quantitative study on map inference algorithms from GPS trajectories},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for anomaly detection in time-driven and
event-driven processes using kernel traces. <em>TKDE</em>,
<em>34</em>(1), 1–14. (<a
href="https://doi.org/10.1109/TKDE.2020.2978469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-checking and verification using Kripke structures and computational tree logic* (CTL*) use abstractions from the model/process/application to create the state-transition graphs that verify the model behavior. This scheme of profiling the performance of a process imports that the depth of the process operation correlates with the level abstraction. However, because of state explosion problems, these abstractions tend to restrict the scope to create manageable execution states. Therefore, for context modeling, this procedure does not generate a fine-grained behavioral model as generated states limit the ability of the abstraction to capture the execution time interactions amongst the processes, the hardware, and the kernel. Hence, in this paper, we present an end-to-end framework that comprises auto-encoders and probabilistic models to understand the behavior of system processes and detect deviant behaviors. We test this framework with a publicly available dataset generated from an autonomous aerial vehicle (UAV) application and the results show that by creating a fine-grained model that exploits previously unharnessed properties of the system calls, we can create a dynamic anomaly detection framework that evolves as the threats change.},
  archive      = {J_TKDE},
  author       = {Okwudili M. Ezeme and Qusay H. Mahmoud and Akramul Azim},
  doi          = {10.1109/TKDE.2020.2978469},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  number       = {1},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A framework for anomaly detection in time-driven and event-driven processes using kernel traces},
  volume       = {34},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
