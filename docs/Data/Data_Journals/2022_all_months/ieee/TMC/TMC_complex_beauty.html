<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmc---319">TMC - 319</h2>
<ul>
<li><details>
<summary>
(2022). Vehicular traffic simulation in the city of turin from raw
data. <em>TMC</em>, <em>21</em>(12), 4656–4666. (<a
href="https://doi.org/10.1109/TMC.2021.3075985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The testing of vehicular communication technologies, the study of urban mobility patterns, the evaluation of new traffic policies cannot dispense from vehicle mobility simulation. As is often the case, the larger the dataset, the better. Indeed, in recent years, many projects in the fields of mobility or vehicular communication have sought new traffic simulators with extended areas of investigation, possibly covering a whole city and its suburbs. In this spirit, we have modeled an urban traffic simulation in a 600-Km 2 area in and around the Municipality of Turin, leveraging the SUMO tool. This paper aims at reporting in detail the methodology we followed in the creation of this dataset. Our results demonstrate that a complete modeling of such a wide area is possible at the expense of minor simplifications, reaching a very good level of approximation.},
  archive      = {J_TMC},
  author       = {Marco Rapelli and Claudio Casetti and Giandomenico Gagliardi},
  doi          = {10.1109/TMC.2021.3075985},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4656-4666},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Vehicular traffic simulation in the city of turin from raw data},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Truthful incentive mechanism for budget-constrained online
user selection in mobile crowdsensing. <em>TMC</em>, <em>21</em>(12),
4642–4655. (<a href="https://doi.org/10.1109/TMC.2021.3083920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) has attained much attention for gathering distributed mobile users to complete large-scale sensing tasks. To ensure the task completion, enough users should be motivated to participate in sensing tasks. Thus, much research in MCS focuses on proposing incentive mechanism, and these works usually focus on the offline scenario, where the information of all users is available to the platform. However, we argue that the actual MCS is usually an online scenario, where the platform does not know the user&#39;s information until they establish connections with the platform. Meanwhile, mobile users connect to the platform randomly and will cut off the connection at any time. Hence, when accessed by a user, the platform needs to make an irrevocable decision instantly about whether to select the user or not, and decides a remuneration for the user without knowing future information. In this paper, we first propose a reverse-auction framework to model the interaction between the platform and mobile users. Then, we present an online truthful incentive mechanism (OTIM) to motivate users, including online winner selection and remuneration determination strategies. Finally, massive simulations are conducted based on three real traces, and the simulation results illustrate that OTIM achieves truthfulness, individual rationality, computational efficiency and an approximately full budget utilization.},
  archive      = {J_TMC},
  author       = {En Wang and Hengzhi Wang and Yongjian Yang and Wenbin Liu},
  doi          = {10.1109/TMC.2021.3083920},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4642-4655},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Truthful incentive mechanism for budget-constrained online user selection in mobile crowdsensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structure-free broadcast scheduling for duty-cycled multihop
wireless sensor networks. <em>TMC</em>, <em>21</em>(12), 4624–4641. (<a
href="https://doi.org/10.1109/TMC.2021.3084145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broadcasting is an essential operation in wireless networks for disseminating the message from the source node to all other nodes. Unfortunately, the problem of Minimum Latency Broadcast Scheduling (MLBS) in duty-cycled wireless sensor networks is not well studied. In existing works, the construction of broadcast tree and the scheduling of transmissions are conducted separately, where a tree-based structure is used as the input of the scheduling algorithm. Relying on a pre-determined tree may result in a much large latency even using the optimal scheduling method. Thus, the MLBS problem in duty-cycled WSNs without the above limitation is investigated in this paper. First, to avoid relying on a pre-determined structure, a two-step scheduling algorithm is proposed to construct the broadcast tree and compute a collision-free schedule simultaneously. To the best of our knowledge, this is the first work that can integrate these two kinds of operations together. Second, a novel transmission mode, i.e., concurrent broadcasting, is first introduced for wireless networks and several techniques are designed to further improve the broadcast latency. Third, the multiple messages broadcasting and all-to-all broadcasting algorithms, which can generate a series of broadcast schedules independently without a pre-determined tree, are also proposed by taking care of the collisions in both the current and the previous broadcast schedules. Finally, the theoretical analysis and experimental results demonstrate the efficiency of the proposed algorithms in terms of latency.},
  archive      = {J_TMC},
  author       = {Quan Chen and Zhipeng Cai and Lianglun Cheng and Hong Gao and Jianzhong Li},
  doi          = {10.1109/TMC.2021.3084145},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4624-4641},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Structure-free broadcast scheduling for duty-cycled multihop wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single-anchor ultra-wideband localization system using
wrapped PDoA. <em>TMC</em>, <em>21</em>(12), 4609–4623. (<a
href="https://doi.org/10.1109/TMC.2021.3083613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultra-wideband (UWB) technology has been widely used in high-accuracy localization systems benefiting from its superior time-resolution and stability. In recent years, the single-anchor localization (SAL) scheme has attracted intense interests with its high accuracy, low system complexity, and low deployment costs compared to traditional UWB localization schemes. In this paper, we develop a SAL system which achieves 3D high-accuracy localization using time and wrapped phase measurements of UWB signals. We expand the array aperture to improve the localization accuracy and address the phase wrapping problem using information fusion. Statistical characterization of ambiguous position estimates is encapsulated by soft positional information (SPI), which is approximated by Gaussian mixture model (GMM) to accelerate the filtering process. The parameters of GMM are estimated by an efficient parallel algorithm and two filtering methods are proposed to track the agent in different scenarios using approximate SPI. Finally, we implement the system on a low-cost platform and experimental results show that the proposed SAL system can achieve decimeter-level 3D localization accuracy in outdoor and indoor environments.},
  archive      = {J_TMC},
  author       = {Feng Ge and Yuan Shen},
  doi          = {10.1109/TMC.2021.3083613},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4609-4623},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Single-anchor ultra-wideband localization system using wrapped PDoA},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Securing IoT devices by exploiting backscatter propagation
signatures. <em>TMC</em>, <em>21</em>(12), 4595–4608. (<a
href="https://doi.org/10.1109/TMC.2021.3084754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-power radio technologies open up many opportunities to facilitate Internet-of-Things (IoT) into our daily life, while their minimalist design also makes IoT devices vulnerable to many active attacks. Recent advances use an antenna array to extract fine-grained physical-layer signatures to identify the attackers, which adds burdens in terms of energy and hardware cost to IoT devices. In this paper, we present ShieldScatter, a lightweight system that attaches low-cost tags to single-antenna devices to shield the system from active attacks. The key insight of ShieldScatter is to intentionally create multi-path propagation signatures with the careful deployment of tags. These signatures can be used to construct a sensitive profile to identify the location of the signals’ arrival, and thus detect the threat. In addition, we also design a tag-random scheme and a multiple receivers combination approach to detect a powerful attacker who has the strong priori knowledge of the legitimate user. We prototype ShieldScatter with USRPs and tags to evaluate our system in various environments. The results show that even when the powerful attacker is close to the legitimate device, ShieldScatter can mitigate 95 percent of attack attempts while triggering false alarms on just 7 percent of legitimate traffic.},
  archive      = {J_TMC},
  author       = {Zhiqing Luo and Wei Wang and Qianyi Huang and Tao Jiang and Qian Zhang},
  doi          = {10.1109/TMC.2021.3084754},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4595-4608},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Securing IoT devices by exploiting backscatter propagation signatures},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Robust online prediction of spectrum map with incomplete
and corrupted observations. <em>TMC</em>, <em>21</em>(12), 4583–4594.
(<a href="https://doi.org/10.1109/TMC.2021.3081715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum map is an essential tool for a range of emerging applications of 5G and 6G networks. Despite the great efforts that have been put on the construction of spectrum maps, access to accurate and valid spectrum data in dynamically changing environments emphasizes the need for more advanced solutions tailored to such rapidly varying scenarios. To this end, the idea of spectrum map prediction is introduced. In this paper, we address the problem of spectrum map prediction from historical spectrum observations in the dynamically changing environments. The problem is particularly challenging when the available historical spectrum observations are incomplete and corrupted by anomalies. We propose three techniques to solve the problem. First, we combine the spectrum map with prediction functionalities so as to offer a huge potential for efficient resource management and flexible sharing of resources in dynamically changing environments. Second, by fully exploiting the hidden spatial-temporal-spectral structures of the spectrum data and the sparsity of anomalies and missing data, we model the spectrum map as a 3rd-order spectrum tensor and formulate the spectrum map prediction problem as a low-rank tensor completion problem. Third, we design a robust online spectrum map prediction (ROSMP) algorithm based on the alternating direction minimization method, which derives the tensor decomposition factors for a new timeslot based on the update of existing ones rather than re-computing from the scratch. By gradually learning the hidden spatial-temporal-spectral structures of the spectrum data, ROSMP is able to predict and obtain the complete spectrum map with high accuracy. Finally, extensive numerical evaluations using a real spectrum measurement dataset confirm the efficacy and efficiency of ROSMP and show the superiority of ROSMP over the baselines.},
  archive      = {J_TMC},
  author       = {Xi Li and Xin Wang and Tiecheng Song and Jing Hu},
  doi          = {10.1109/TMC.2021.3081715},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4583-4594},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust online prediction of spectrum map with incomplete and corrupted observations},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust channel estimation in multiuser downlink 5G systems
under channel uncertainties. <em>TMC</em>, <em>21</em>(12), 4569–4582.
(<a href="https://doi.org/10.1109/TMC.2021.3084398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless communication, the performance of the network highly relies on the accuracy of channel state information (CSI). On the other hand, the channel statistics are usually unknown, and the measurement information is lost due to the fading phenomenon. Therefore, we propose a channel estimation approach for downlink communication under channel uncertainty. We apply the Tobit Kalman filter (TKF) method to estimate the hidden state vectors of wireless channels. To minimize the maximum estimation error, a robust minimax minimum estimation error (MSE) estimation approach is developed while the QoS requirements of wireless users is taken into account. We then formulate the minimax problem as a non-cooperative game to find an optimal filter and adjust the best behavior for the worst-case channel uncertainty. We also investigate a scenario in which the actual operating point is not exactly known under model uncertainty. Finally, we investigate the existence and characterization of a saddle point as the solution of the game. Theoretical analysis verifies that our work is robust against the uncertainty of the channel statistics and able to track the true values of the channel states. Additionally, simulation results demonstrate the superiority of the model in terms of MSE value over related techniques.},
  archive      = {J_TMC},
  author       = {Azadeh Pourkabirian and Mohammad Hossein Anisi},
  doi          = {10.1109/TMC.2021.3084398},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4569-4582},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust channel estimation in multiuser downlink 5G systems under channel uncertainties},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RL-recruiter+: Mobility-predictability-aware participant
selection learning for from-scratch mobile crowdsensing. <em>TMC</em>,
<em>21</em>(12), 4555–4568. (<a
href="https://doi.org/10.1109/TMC.2021.3077636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Participant selection is a fundamental research issue in Mobile Crowdsensing (MCS). Previous approaches commonly assume that adequately long periods of candidate participants’ historical mobility trajectories are available to model their patterns before the selection process, which is not realistic for some new MCS applications or platforms. The sparsity or even absence of mobility traces will incur inaccurate location prediction, thus undermining the deployment of new MCS applications. To this end, this paper investigates a novel problem called “From-Scratch MCS” (FS-MCS for short), in which we study how to intelligently select participants to minimize such a “cold-start” effect. Specifically, we propose a novel framework based on reinforcement learning, named RL-Recruiter+. With the gradual accumulation of mobility trajectories over time, RL-Recruiter+ is able to make a good sequence of participant selection decisions for each sensing slot. Compared to its previous version, RL-Recruiter, Re-Recruiter+ jointly considers both the previous coverage and current mobility predictability when training the participant selection decision model. We evaluate our approach experimentally based on two real-world mobility datasets. The results demonstrate that RL-Recruiter+ outperforms the baseline approaches, including RL-Recruiter under various settings.},
  archive      = {J_TMC},
  author       = {Yunfan Hu and Jiangtao Wang and Bo Wu and Sumi Helal},
  doi          = {10.1109/TMC.2021.3077636},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4555-4568},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RL-recruiter+: Mobility-predictability-aware participant selection learning for from-scratch mobile crowdsensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Request reliability augmentation with service function chain
requirements in mobile edge computing. <em>TMC</em>, <em>21</em>(12),
4541–4554. (<a href="https://doi.org/10.1109/TMC.2021.3081681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provisioning reliable network services for mobile users in edge computing environments is the top priority of network service providers, as unreliable services will result in tremendous losses of revenues and customers. In this paper, we study a novel service reliability augmentation problem in a mobile edge computing (MEC) network, where mobile users request network services with service function chain (SFC) and reliability expectation requirements. To enhance the service reliability of user requests, it is a common practice to make use of redundant virtualized network function (VNF) instance placement in case the primary VNF instance fails. We aim to augment the service reliability of each admitted request to its specified reliability expectation, subject to computing capacity on each cloudlet. To this end, we first formulate a novel service reliability augmentation problem for each request with an SFC and a reliability expectation requirement, by augmenting its reliability through redundant VNF instance deployment. We then show that the problem is NP-hard, and provide an admission framework of user requests by placing primary VNF instances of network functions in the SFC to different cloudlets. We then deal with the service reliability augmentation problem of an admitted request under the assumption that all secondary VNF instances of each primary VNF instance must be placed into the cloudlets no more than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$l$&lt;/tex-math&gt;&lt;/inline-formula&gt; hops from the cloudlet of its primary VNF instance for a fixed &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$l$&lt;/tex-math&gt;&lt;/inline-formula&gt; with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1\leq l \leq n-1$&lt;/tex-math&gt;&lt;/inline-formula&gt; , where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the number of cloudlets in the network, for which we formulate an integer linear program solution, and develop a randomized algorithm with a good approximation ratio and high probability, at the expense of moderate resource constraint violations. We also devise a deterministic heuristic for the problem without any resource violation. We third study the service reliability augmentation problem for a set of admitted requests by extending the proposed algorithm for the service reliability augmentation problem for a single request admission. We finally evaluate the performance of the proposed algorithms through experimental simulations. Experimental results demonstrate that the proposed algorithms are promising, and their empirical results are superior to their analytical counterparts.},
  archive      = {J_TMC},
  author       = {Weifa Liang and Yu Ma and Wenzheng Xu and Zichuan Xu and Xiaohua Jia and Wanlei Zhou},
  doi          = {10.1109/TMC.2021.3081681},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4541-4554},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Request reliability augmentation with service function chain requirements in mobile edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning-based mobile AR/VR multipath
transmission with streaming power spectrum density analysis.
<em>TMC</em>, <em>21</em>(12), 4529–4540. (<a
href="https://doi.org/10.1109/TMC.2021.3082912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-path transmission control protocol (MPTCP) is an extension of TCP that enables the concurrent transmission of information through different network interfaces (e.g., Cellular, Wi-Fi, 802.11p, and so on) available at terminal side. It is well known that MPTCP can provide significant advantages in bandwidth aggregation and transmission stability. Unfortunately, path diversity can limit bandwidth aggregation efficiency and incur higher delays. These issues become critical when in presence of emerging mobile AR and VR applications, which are bandwidth hungry, time-sensitive and exhibit abrupt variations of the bitrate. To address these issues, we propose the R einforcement L earning-based mobile AR/VR multipath transmission with streaming P ower S pectrum D ensity analysis (RL-PSD). RL-PSD analyses the Power Spectrum Density (PSD) of the AR/VR input stream to extract its features. Then, both the input stream and network features are considered to model the MPTCP congestion control as an reinforcement learning process. Finally, a two-stage reinforcement algorithm is proposed to optimize transmission performance. RL-PSD has been tested in both single-terminal and multi-terminal scenarios: results show that it outperforms the other advanced solutions conceived to support the multipath transmission of AR/VR streams.},
  archive      = {J_TMC},
  author       = {Changqiao Xu and Jiuren Qin and Ping Zhang and Kai Gao and Luigi Alfredo Grieco},
  doi          = {10.1109/TMC.2021.3082912},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4529-4540},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reinforcement learning-based mobile AR/VR multipath transmission with streaming power spectrum density analysis},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preventing sensitive information leakage from mobile sensor
signals via integrative transformation. <em>TMC</em>, <em>21</em>(12),
4517–4528. (<a href="https://doi.org/10.1109/TMC.2021.3078086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ubiquitous mobile sensors on human activity recognition pose the threat of leaking personal information that is implicitly contained within the time-series sensor signals and can be extracted by attackers. Existing protective methods only support specific sensitive attributes and require massive relevant sensitive ground truth for training, which is unfavourable to users. To fill this gap, we propose a novel data transformation framework for prohibiting the leakage of sensitive information from sensor data. The proposed framework transforms raw sensor data into a new format, where the sensitive information is hidden and the desired information (e.g., human activities) is retained. Training can be conducted without using any personal information as ground truth. Meanwhile, multiple attributes of sensitive information (e.g., age, gender) can be collectively hidden through a one-time transformation. The experimental results on two multimodal sensor-based human activity datasets manifest the feasibility of the presented framework in hiding users’ sensitive information (inference MAE increases &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 2 times and inference accuracy degrades &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 50%) without degrading the usability of the data for activity recognition (only &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 2% accuracy degradation).},
  archive      = {J_TMC},
  author       = {Dalin Zhang and Lina Yao and Kaixuan Chen and Zheng Yang and Xin Gao and Yunhao Liu},
  doi          = {10.1109/TMC.2021.3078086},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4517-4528},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Preventing sensitive information leakage from mobile sensor signals via integrative transformation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial synchronization to accelerate federated learning
over relay-assisted edge networks. <em>TMC</em>, <em>21</em>(12),
4502–4516. (<a href="https://doi.org/10.1109/TMC.2021.3083154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a promising machine learning paradigm to cooperatively train a global model with highly distributed data located on mobile devices. Aiming to optimize the communication efficiency for gradient aggregation and model synchronization among large-scale devices, we propose a relay-assisted FL framework. By breaking the traditional transmission-order constraint and exploiting the broadcast characteristic of relay nodes, we design a novel synchronization scheme named Partial Synchronization Parallel (PSP), in which models and gradients are transmitted simultaneously and aggregated at relay nodes, resulting in traffic reduction. We prove that PSP has the same convergence rate as the sequential synchronization approaches via rigorous analysis. To further accelerate the training process, we integrate PSP with any unbiased and error-bounded compression technologies and prove that the convergence properties of the resulting scheme still hold. Extensive experiments are conducted in a distributed cluster environment with real-world datasets and the results demonstrate that our proposed approach reduces the training time up to 37 percent compared to state-of-the-art methods.},
  archive      = {J_TMC},
  author       = {Zhihao Qu and Song Guo and Haozhao Wang and Baoliu Ye and Yi Wang and Albert Y. Zomaya and Bin Tang},
  doi          = {10.1109/TMC.2021.3083154},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4502-4516},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Partial synchronization to accelerate federated learning over relay-assisted edge networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overlay-based android malware detection at market scales:
Systematically adapting to the new technological landscape.
<em>TMC</em>, <em>21</em>(12), 4488–4501. (<a
href="https://doi.org/10.1109/TMC.2021.3079433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Android overlay enables one app to draw over other apps by creating an extra View layer atop the host View , which nevertheless can be exploited by malicious apps (malware) to attack users. To combat this threat, prior countermeasures concentrate on restricting the capabilities of overlays at the OS level while sacrificing overlays’ usability; recently, the overlay mechanism has been substantially updated to prevent a variety of attacks, which however can still be evaded by considerable adversaries. To address these shortcomings, a more pragmatic approach is to enable early detection of overlay-based malware during the app market review process, so that all the capabilities of overlays can stay unchanged. For this purpose, in this paper we first conduct a large-scale comparative study of overlay characteristics in benign and malicious apps, and then implement the OverlayChecker system to automatically detect overlay-based malware for one of the world’s largest Android app stores. In particular, we have made systematic efforts in feature engineering, UI exploration, emulation architecture, and run-time environment, thus maintaining high detection accuracy (97 percent precision and 97 percent recall) and short per-app scan time ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 1.7 minutes) with only two commodity servers, under an intensive workload of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;/inline-formula&gt; 10K newly submitted apps per day.},
  archive      = {J_TMC},
  author       = {Liangyi Gong and Zhenhua Li and Hongyi Wang and Hao Lin and Xiaobo Ma and Yunhao Liu},
  doi          = {10.1109/TMC.2021.3079433},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4488-4501},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Overlay-based android malware detection at market scales: Systematically adapting to the new technological landscape},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing bulk transfer size and scheduling for efficient
buffer management in mobile opportunistic networks. <em>TMC</em>,
<em>21</em>(12), 4471–4487. (<a
href="https://doi.org/10.1109/TMC.2021.3075993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Opportunistic Networks (MONs) are characterized by intermittent connectivity with long isolation period, and nodes following redundant transmissions for reliable message delivery. This often leads to unnecessary buffer occupancy, preventing new messages from getting replicated due to small contact duration and low bandwidth, or leading to packet drop under constrained buffer. Although attempts have been made to mitigate buffer congestion, the existing schemes are localized, are slow to react, or are specific to a routing scheme. Moreover, they rely on message exchanges to obtain buffer state/occupancy, thereby incurring additional overhead. In this paper, we first develop a generalized probabilistic forwarding model where the forwarding probability denotes the likelihood of a message to get forwarded to the encountered node. Based on the forwarding probability, we develop a congestion indicator and predict the point of congestion using the Kalman filter. Using this, a node can decide the optimal number and the exact set of messages to replicate, which leads to an optimal performance with minimal packet drop and overhead. Simulation results using a synthetic mobility model and a real-life mobility trace show that the proposed scheme outperforms the existing schemes.},
  archive      = {J_TMC},
  author       = {Gourish Goudar and Suvadip Batabyal},
  doi          = {10.1109/TMC.2021.3075993},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4471-4487},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing bulk transfer size and scheduling for efficient buffer management in mobile opportunistic networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mobile data traffic prediction by exploiting time-evolving
user mobility patterns. <em>TMC</em>, <em>21</em>(12), 4456–4470. (<a
href="https://doi.org/10.1109/TMC.2021.3079117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding mobile data traffic and forecasting future traffic trend is beneficial to wireless carriers and service providers who need to perform resource allocation and energy saving management. However, predicting wireless traffic accurately at large-scale and fine-granularity is particularly challenging due to the following two factors: the spatial correlations between the network units (i.e., a cell tower or an access point) introduced by user arbitrary movements, and the time-evolving nature of user movements which frequently changes with time. In this paper, we use a time-evolving graph to formulate the time-evolving nature of user movements, and propose a model Graph-based Temporal Convolutional Network (GTCN) to predict the future traffic of each network unit in a wireless network. GTCN can bring significant benefits to two aspects. (1) GTCN can effectively learn intra- and inter-time spatial correlations between network units in a time-evolving graph through a node aggregation method. (2) GTCN can efficiently model the temporal dynamics of the mobile traffic trend from different network units through a temporal convolutional layer. Experimental results on two real-world datasets demonstrate the efficiency and efficacy of our method. Compared with state-of-the-art methods, the improvement of the prediction performance of our GTCN is 3.2 to 10.2 percent for different prediction horizons. GTCN also achieves 8.4× faster on prediction time.},
  archive      = {J_TMC},
  author       = {Feiyang Sun and Pinghui Wang and Junzhou Zhao and Nuo Xu and Juxiang Zeng and Jing Tao and Kaikai Song and Chao Deng and John C.S. Lui and Xiaohong Guan},
  doi          = {10.1109/TMC.2021.3079117},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4456-4470},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobile data traffic prediction by exploiting time-evolving user mobility patterns},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). : Multi-dimensional spatial reuse enhancement for
directional millimeter-wave wireless networks. <em>TMC</em>,
<em>21</em>(12), 4439–4455. (<a
href="https://doi.org/10.1109/TMC.2021.3082209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millimeter wave (mmWave) wireless networks are envisioned to bring a very high degree of spatial reuse, i.e., multiple links can operate simultaneously without interference. The vision, however, is becoming doubtful, as recent studies found that non-negligible interference exists due to imperfect beam patterns. In this paper, we extensively measure the spatial reuse issue in a dense 60 GHz mmWave network consisting of multiple access points (AP) and users. Our measurement quantifies the impact of interference on network performance and finds that the existing prediction based on interference-resolving approaches are insufficient. Motivated by the findings, we propose MDSR , which enhances the spatial reuse in 60 GHz mmWave networks. Instead of relying on interference prediction, MDSR takes a new measurement principle of building a conflict graph that implicitly takes into account the impact of both beam imperfection and reflections. Using the conflict graph, MDSR improves the spatial reuse from three dimensions: AP association, user scheduling, and beam selection, which can determine the optimal AP-user-beam combination and minimize interference in each scheduling cycle. We prototype and evaluate MDSR on the testbed using commodity mmWave radios. The evaluation results demonstrate that MDSR improves network throughput by multi-folds compared with the state-of-the-art one.},
  archive      = {J_TMC},
  author       = {Yi Yang and Anfu Zhou and Dongzhu Xu and Kun Liang and Huadong Ma and Teng Wei and Jianhua Liu},
  doi          = {10.1109/TMC.2021.3082209},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4439-4455},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {: Multi-dimensional spatial reuse enhancement for directional millimeter-wave wireless networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Make smart decisions faster: Deciding D2D resource
allocation via stackelberg game guided multi-agent deep reinforcement
learning. <em>TMC</em>, <em>21</em>(12), 4426–4438. (<a
href="https://doi.org/10.1109/TMC.2021.3085206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device-to-Device (D2D) communication enabling direct data transmission between two mobile users has emerged as a vital component for 5G cellular networks to improve spectrum utilization and enhance system capacity. A critical issue for realizing these benefits in D2D-enabled networks is to properly allocate radio resources while coordinating the co-channel interference in a time-varying communication environment. In this paper, we propose a Stackelberg game (SG) guided multi-agent deep reinforcement learning (MADRL) approach, which allows D2D users to make smart power control and channel allocation decisions in a distributed manner. In particular, we define a crucial Stackelberg Q-value (ST-Q) to guide the learning direction, which can be calculated based on the equilibrium achieved in the Stackelberg game. With the guidance of the Stackelberg equilibrium, our approach converges faster with fewer iterations than the general MADRL method and thereby exhibits better performance in handling the network dynamics. After the initial training, each agent can infer timely D2D resource allocation strategies with distributed execution. Extensive simulations are conducted to validate the efficacy of our proposed scheme in developing timely resource allocation strategies. The results also show that our method outperforms the general MADRL based approach in terms of the average utility, channel capacity, and training time.},
  archive      = {J_TMC},
  author       = {Dian Shi and Liang Li and Tomoaki Ohtsuki and Miao Pan and Zhu Han and H. Vincent Poor},
  doi          = {10.1109/TMC.2021.3085206},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4426-4438},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Make smart decisions faster: Deciding D2D resource allocation via stackelberg game guided multi-agent deep reinforcement learning},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Location privacy-preserving task recommendation with
geometric range query in mobile crowdsensing. <em>TMC</em>,
<em>21</em>(12), 4410–4425. (<a
href="https://doi.org/10.1109/TMC.2021.3080714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile crowdsensing, location-based task recommendation requires each data requester to submit a task-related geometric range to crowdsensing service providers such that they can match suitable workers within this range. Generally, a trusted server (i.e., database owner) should be deployed to protect location privacy during the process, which is not desirable in practice. In this paper, we propose the location privacy-preserving task recommendation (PPTR) schemes with geometric range query in mobile crowdsensing without the trusted database owner. Specifically, we first propose a PPTR scheme with linear search complexity, named PPTR-L, based on a two-server model. By leveraging techniques of polynomial fitting and randomizable matrix multiplication, PPTR-L enables the service provider to find the workers located in the data requester’s arbitrary geometric query range without disclosing the sensitive location privacy. To further improve query efficiency, we design a novel data structure for task recommendation and propose PPTR-F to achieve faster-than-linear search complexity. Through security analysis, it is shown that our schemes can protect the confidentiality of workers’ locations and data requesters’ queries. Extensive experiments are performed to demonstrate that our schemes can achieve high computational efficiency in terms of geometric range query.},
  archive      = {J_TMC},
  author       = {Chuan Zhang and Liehuang Zhu and Chang Xu and Jianbing Ni and Cheng Huang and Xuemin Shen},
  doi          = {10.1109/TMC.2021.3080714},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4410-4425},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Location privacy-preserving task recommendation with geometric range query in mobile crowdsensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lightweight public key authenticated encryption with keyword
search against adaptively-chosen-targets adversaries for mobile devices.
<em>TMC</em>, <em>21</em>(12), 4397–4409. (<a
href="https://doi.org/10.1109/TMC.2021.3077508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage services have grown extensively in recent years. For security and privacy purposes, sensitive data need to be outsourced to clouds in encrypted form. Searchable public key encryption (SPKE) enables data ciphertexts to be retrieved by keyword(s) without decryption. Unfortunately, most of the existing SPKE schemes cannot withstand the keyword guessing attack. To combat such attack, public key authenticated encryption with keyword search (PAEKS) was presented. However, the existing PAEKS schemes were proven secure under a designated-targets security model, in which an adversary only can attack a sender and a recipient designated by the challenger. Our cryptanalysis indicates that such a scheme may be insecure against the practical attacks where the adversaries choose their targets by themselves. To fight against adaptively-chosen-targets adversaries, we refine the adversary model for PAEKS by permitting the adversaries to choose their targets adaptively, and then formalize the security definitions under the improved security model. After that, we devise a lightweight PAEKS scheme that avoids the time-consuming bilinear pairing operations and give the security proofs. The comparisons show that it outperforms the existing bilinear pairing-based PAEKS schemes in both the computation and communication performance, and therefore is more suitable for the resource-constrained mobile devices.},
  archive      = {J_TMC},
  author       = {Yang Lu and Jiguo Li},
  doi          = {10.1109/TMC.2021.3077508},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4397-4409},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Lightweight public key authenticated encryption with keyword search against adaptively-chosen-targets adversaries for mobile devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint observation and transmission scheduling in agile
satellite networks. <em>TMC</em>, <em>21</em>(12), 4381–4396. (<a
href="https://doi.org/10.1109/TMC.2021.3076088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with traditional observation satellites, agile earth observation satellites are capable of prolonging observation time windows (OTWs) for targets, which significantly alleviates observation conflicts, thereby facilitating imaging data collection. However, it also leads to more uncertainties in determining the start time to image targets within these longer OTWs for an agile satellite network (ASN) to collect imaging data. Furthermore, these collected data are offloaded only within short transmission time windows between data collectors and data sinks, thus resulting in a transmission scheduling problem. Toward this end, this paper investigates joint observation and transmission scheduling in ASNs, aiming at accommodating more imaging data to be collected and offloaded successfully. Specifically, we formulate the studied problem as integer linear programming (ILP) to maximize the weighted sum of scheduled imaging tasks. Then, we explore the hidden structure of this ILP and transform it into a special framework, which can be solved efficiently through semidefinite relaxation (SDR). To reduce computation complexity, we further propose a fast yet efficient algorithm by combining the advantages of the devised SDR method and a genetic algorithm with special population initialization. Finally, simulation results demonstrate that the proposed algorithm can significantly increase the weighted sum of scheduled tasks.},
  archive      = {J_TMC},
  author       = {Lijun He and Ben Liang and Jiandong Li and Min Sheng},
  doi          = {10.1109/TMC.2021.3076088},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4381-4396},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint observation and transmission scheduling in agile satellite networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HIRO-NET: Heterogeneous intelligent robotic network for
internet sharing in disaster scenarios. <em>TMC</em>, <em>21</em>(12),
4367–4380. (<a href="https://doi.org/10.1109/TMC.2021.3078050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes HIRO-NET, an Heterogeneous Intelligent Robotic Network. HIRO-NET is an emergency infrastructure-less network that aims to address the problem of providing connectivity in the immediate aftermath of a natural disaster, where no cellular or wide area network is operational and no Internet access is available. HIRO-NET establishes a two-tier wireless mesh network where the Lower Tier connects nearby survivors in a self-organized mesh via Bluetooth Low Energy (BLE) and the Upper Tier creates long-range VHF links between autonomous robots exploring the disaster-stricken area. HIRO-NET&#39;s main goal is to enable users in the disaster area to exchange text messages to share critical information and request help from first responders. The mesh network discovery problem is analyzed and a network protocol specifically designed to facilitate the exploration process is presented. We show how HIRO-NET robots successfully discover, bridge and interconnect local mesh networks. Results show that the Lower Tier always reaches network convergence and the Upper Tier can virtually extend HIRO-NET functionalities to the range of a small metropolitan area. In the event of an Internet connection still being available to some user, HIRO-NET is able to opportunistically share and provide access to low data-rate services (e.g., Twitter, Gmail) to the whole network. Results suggest that a temporary emergency network to cover a metropolitan area can be created in tens of minutes.},
  archive      = {J_TMC},
  author       = {Ludovico Ferranti and Salvatore D’Oro and Leonardo Bonati and Francesca Cuomo and Tommaso Melodia},
  doi          = {10.1109/TMC.2021.3078050},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4367-4380},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HIRO-NET: Heterogeneous intelligent robotic network for internet sharing in disaster scenarios},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FD-JCAS techniques for mmWave HetNets: Ginibre point process
modeling and analysis. <em>TMC</em>, <em>21</em>(12), 4352–4366. (<a
href="https://doi.org/10.1109/TMC.2021.3076856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the co-design of full-duplex (FD) radio with joint communication and radar sensing (JCAS) techniques in millimeter-wave (mmWave) heterogeneous networks (HetNets). Spectral co-existence of radar and communication systems causes mutual interference between the two systems, compromising both the data exchange and sensing capabilities. Focusing on the detection performance, we propose a cooperative detection technique, which exploits the sensing information from multiple base stations (BSs), aiming at enhancing the probability of successfully detecting an object. Three combining rules are considered, namely the OR , the Majority and the AND rule. In real-world network scenarios, the locations of the BSs are spatially correlated, exhibiting a repulsive behavior. Therefore, we model the spatial distribution of the BSs as a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\beta$&lt;/tex-math&gt;&lt;/inline-formula&gt; -Ginibre point process ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\beta$&lt;/tex-math&gt;&lt;/inline-formula&gt; -GPP), which can characterize the repulsion among the BSs. By using stochastic geometry tools, analytical expressions for the detection performance of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\beta$&lt;/tex-math&gt;&lt;/inline-formula&gt; -GPP-based FD-JCAS systems are expressed for each of the considered combining rule. Furthermore, by considering temporal interference correlation, we evaluate the probability of successfully detecting an object over two different time slots. Our results demonstrate that our proposed technique can significantly improve the detection performance when compared to the conventional non-cooperative technique.},
  archive      = {J_TMC},
  author       = {Christodoulos Skouroumounis and Constantinos Psomas and Ioannis Krikidis},
  doi          = {10.1109/TMC.2021.3076856},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4352-4366},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FD-JCAS techniques for mmWave HetNets: Ginibre point process modeling and analysis},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting channel polarization for reliable wide-area
backscatter networks. <em>TMC</em>, <em>21</em>(12), 4338–4351. (<a
href="https://doi.org/10.1109/TMC.2021.3075549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-standing vision of backscatter networks is to provide long-range connectivity and high-speed transmissions for batteryless Internet-of-Things (IoT). Recent years have seen major innovations in designing backscatter networks toward this goal. Yet, they either operate at a very short range, or experience extremely low throughput. This paper takes one step further towards breaking this stalemate, by presenting PolarScatter that exploits channel polarization in long-range backscatter networks. We transform backscatter channels into nearly noiseless virtual channels through channel polarization, and convey bits with extremely low error probability. Specifically, we propose a new polar code scheme that automatically adapts itself to different channel quality, and design a low-cost encoder to accommodate polar codes on resource-constrained backscatter tags. Furthermore, we devise a new metric to calculate log-likelihood ratio for accurate decoding, and present a stopping criterion of iterations to reduce decoding latency. We build a prototype PCB tag, and our experiments show that it achieves up to 11.5× throughput improvement over the state-of-the-art long-range backscatter solution. We also simulate an IC design in TSMC 65 nm LP CMOS process. Compared with traditional encoders, our encoder reduces storage overhead by three orders of magnitude, and lowers the power consumption to tens of microwatts.},
  archive      = {J_TMC},
  author       = {Guochao Song and Wei Wang and Hang Yang and Dongchen Zhang and Peng Gao and Tao Jiang},
  doi          = {10.1109/TMC.2021.3075549},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4338-4351},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Exploiting channel polarization for reliable wide-area backscatter networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Energy-efficient trajectory optimization for UAV-assisted
IoT networks. <em>TMC</em>, <em>21</em>(12), 4323–4337. (<a
href="https://doi.org/10.1109/TMC.2021.3075083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and study an energy-efficient trajectory optimization scheme for unmanned aerial vehicle (UAV) assisted Internet of Things (IoT) networks. In such networks, a single UAV is powered by both solar energy and charging stations (CSs), resulting in sustainable communication services, while avoiding energy outage. In particular, we optimize the trajectory design of UAV by jointly considering the average data rate, the total energy consumption, and the fairness of coverage for the IoT terminals. A dynamic spatial-temporal configuration scheme is operated for terminals working in the discontinuous reception (DRX) mode. The module-free, action-confined on-policy and off-policy reinforcement learning (RL) approaches are proposed and jointly applied to solve the formulated optimization problem in this paper. We evaluate the effectiveness of the proposed strategy by comparing it with other dynamic benchmark algorithms. The extensive simulation results provided in this paper reveal that the proposed scheme outperforms the benchmarks in terms of data transmission, energy efficiency and adaptivity of avoiding battery depletion. By deploying the proposed trajectory scheme, the UAV is able to adapt itself according to the temporal and dynamic conditions of communication networks.},
  archive      = {J_TMC},
  author       = {Liang Zhang and Abdulkadir Celik and Shuping Dang and Basem Shihada},
  doi          = {10.1109/TMC.2021.3075083},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4323-4337},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient trajectory optimization for UAV-assisted IoT networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Energy-efficient non-orthogonal multiple access for
downlink communication in mobile edge computing systems. <em>TMC</em>,
<em>21</em>(12), 4310–4322. (<a
href="https://doi.org/10.1109/TMC.2021.3083660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Downlink mobile edge computing (MEC) networks are requiblack to serve increasing large number of Internet of Things (IoT) devices with limited battery capacity. In order to serve massive user equipments with low power consumption requirements, in this paper, we propose an energy-efficient multi-carrier non-orthogonal multiple access (MC-NOMA) design which allows more than two IoT devices to multiplex and access the same subcarrier band. With the aim to minimize the total transmit energy while meeting the demands of each IoT device such as the low latency, in our design, we first derive the optimal successive interference cancellation (SIC) policy and minimum power allocated to every IoT device. Then we propose an optimal greedy algorithm to allocate the frequency blocks, and formulate the optimization of the computational resource allocation as a min-max problem. Subsequently, we characterize the MC-NOMA network with the potential game model, and present a scheduling scheme to manage massive IoT devices. Simulation results demonstrate that our proposed scheme can consume 3-10 dB less energy in a MEC network deployed with 256 IoT devices compablack with the conventional orthogonal multiple access (OMA) scheme and non-orthogonal multiple access (NOMA) scheme.},
  archive      = {J_TMC},
  author       = {Lin Zhang and Furong Fang and Guixun Huang and Yawen Chen and Haibo Zhang and Yuan Jiang and Weibin Ma},
  doi          = {10.1109/TMC.2021.3083660},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4310-4322},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Energy-efficient non-orthogonal multiple access for downlink communication in mobile edge computing systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DPoS: Decentralized, privacy-preserving, and low-complexity
online slicing for multi-tenant networks. <em>TMC</em>, <em>21</em>(12),
4296–4309. (<a href="https://doi.org/10.1109/TMC.2021.3074934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing is the key to enable virtualized resource sharing among vertical industries in the era of 5G communication. Efficient resource allocation is of vital importance to realize network slicing in real-world business scenarios. To deal with the high algorithm complexity, privacy leakage, and unrealistic offline setting of current network slicing algorithms, in this paper we propose a fully decentralized and low-complexity online algorithm, DPoS, for multi-resource slicing. We first formulate the problem as a global social welfare maximization problem. Next, we design the online algorithm DPoS based on the primal-dual approach and posted price mechanism. In DPoS, each tenant is incentivized to make its own decision based on its true preferences without disclosing any private information to the mobile virtual network operator and other tenants. We provide a rigorous theoretical analysis to show that DPoS has the optimal competitive ratio when the cost function of each resource is linear. Extensive simulation experiments are conducted to evaluate the performance of DPoS. The results show that DPoS can not only achieve close-to-offline-optimal performance, but also have low algorithmic overheads.},
  archive      = {J_TMC},
  author       = {Hailiang Zhao and Shuiguang Deng and Zijie Liu and Zhengzhe Xiang and Jianwei Yin and Schahram Dustdar and Albert Y. Zomaya},
  doi          = {10.1109/TMC.2021.3074934},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4296-4309},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DPoS: Decentralized, privacy-preserving, and low-complexity online slicing for multi-tenant networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DFPS: A distributed mobile system for free parking
assignment. <em>TMC</em>, <em>21</em>(12), 4279–4295. (<a
href="https://doi.org/10.1109/TMC.2021.3080222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cruising for vacant curbside parking spaces causes waste of time, frustration, waste of fuel, and pollution. This problem has been addressed by centralized solutions that perform parking assignments and communicate them to drivers’ smart phones. These solutions suffer, however, from two intrinsic problems: scalability, as the server has to perform intensive computation and communication with the drivers; and privacy, as the drivers have to disclose their destinations to the server. This article proposes DFPS, a distributed mobile system for free parking assignment. DFPS solves the scalability problem by using the drivers’ smart phones to cooperatively compute the parking assignments, and a centralized dispatcher to receive and distribute parking requests to the network of smart phones. The phones of the parked drivers in DFPS are structured in a K-D tree to serve parking requests in a distributed fashion. DFPS removes the computation from the dispatcher and substantially reduces its communication load. DFPS solves the privacy problem through an entropy-based cloaking technique that runs on drivers’ smart phones and conceals drivers’ destinations from the dispatcher. The evaluation demonstrates that DFPS is scalable and obtains better travel time than a centralized system, while protecting the privacy of drivers’ destinations.},
  archive      = {J_TMC},
  author       = {Abeer Hakeem and Reza Curtmola and Xiaoning Ding and Cristian Borcea},
  doi          = {10.1109/TMC.2021.3080222},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4279-4295},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DFPS: A distributed mobile system for free parking assignment},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost-effective user allocation in 5G NOMA-based mobile edge
computing systems. <em>TMC</em>, <em>21</em>(12), 4263–4278. (<a
href="https://doi.org/10.1109/TMC.2021.3077470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) allows edge servers to be placed at cellular base stations. App vendors like Uber and YouTube can rent computing resources and deploy latency-sensitive applications on edge servers for their users to access. Non-orthogonal multiple access (NOMA) is an emerging technique that facilitates the massive connectivity of 5G networks, further enhancing the capability of MEC. The edge user allocation (EUA) problem faces new challenges in 5G NOMA-based MEC systems. In this study, we investigate the EUA problem in a multi-cell multi-channel downlink power-domain NOMA-based MEC system. The main objective is to help mobile app vendors maximize their benefit by allocating maximum users to edge servers in a specific area at the lowest computing resource and transmit power costs. To this end, we introduce a decentralized game-theoretic approach to effectively select a channel and edge server for each user while fulfilling their resource and data rate requirements. We theoretically and experimentally evaluate our solution, which significantly outperforms various state-of-the-art and baseline approaches.},
  archive      = {J_TMC},
  author       = {Phu Lai and Qiang He and Guangming Cui and Feifei Chen and John Grundy and Mohamed Abdelrazek and John Hosking and Yun Yang},
  doi          = {10.1109/TMC.2021.3077470},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4263-4278},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cost-effective user allocation in 5G NOMA-based mobile edge computing systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-adaptive sub-nyquist sampling for low-power wearable
sensing systems. <em>TMC</em>, <em>21</em>(12), 4249–4262. (<a
href="https://doi.org/10.1109/TMC.2021.3077731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a context-adaptive sample acquisition strategy at sub-Nyquist sampling rate for wearable embedded sensor devices. Our approach can be applied to compressive sensing frameworks to minimise sampling and transmission costs. We consider a context estimate to represent the local signal structure and a feed-forward response model to continuously tune signal acquisition of an online sampling and transmission system. To evaluate our approach, we analysed the performance in different pattern recognition scenarios. We report three case studies here: (1) eating monitoring based on electromyography measurements in smart eyeglasses, (2) human activity recognition based on waist-worn inertial sensor data, and (3) heartbeat detection and arrhythmia classification based on single-lead electrocardiogram readings. Compared to conventional sub-Nyquist sampling, our context-adaptive approach saves between 13 to 22 percent of energy, while achieving similar pattern recognition performance and reconstruction error.},
  archive      = {J_TMC},
  author       = {Giovanni Schiboni and Celia Martin Vicario and Juan Carlos Suarez and Federico Cruciani and Oliver Amft},
  doi          = {10.1109/TMC.2021.3077731},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4249-4262},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Context-adaptive sub-nyquist sampling for low-power wearable sensing systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computation offloading in heterogeneous vehicular edge
networks: On-line and off-policy bandit solutions. <em>TMC</em>,
<em>21</em>(12), 4233–4248. (<a
href="https://doi.org/10.1109/TMC.2021.3082927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of intelligent transportation systems (ITS) and vehicular communications, vehicular edge computing (VEC) is emerging as a promising technology to support low-latency ITS applications and services. In this paper, we consider the computation offloading problem from mobile vehicles/users in a heterogeneous VEC scenario, and focus on the network- and base station selection problems, where different networks have different traffic loads. In a fast-varying vehicular environment, computation offloading experience of users is strongly affected by the latency due to the congestion at the edge computing servers co-located with the base stations. However, as a result of the non-stationary property of such an environment and also information shortage, predicting this congestion is an involved task. To address this challenge, we propose an on-line learning algorithm and an off-policy learning algorithm based on multi-armed bandit theory. To dynamically select the least congested network in a piece-wise stationary environment, these algorithms predict the latency that the offloaded tasks experience using the offloading history. In addition, to minimize the task loss due to the mobility of the vehicles, we develop a method for base station selection. Moreover, we propose a relaying mechanism for the selected network, which operates based on the sojourn time of the vehicles. Through intensive numerical analysis, we demonstrate that the proposed learning-based solutions adapt to the traffic changes of the network by selecting the least congested network, thereby reducing the latency of offloaded tasks. Moreover, we demonstrate that the proposed joint base station selection and the relaying mechanism minimize the task loss in a vehicular environment.},
  archive      = {J_TMC},
  author       = {Arash Bozorgchenani and Setareh Maghsudi and Daniele Tarchi and Ekram Hossain},
  doi          = {10.1109/TMC.2021.3082927},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4233-4248},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Computation offloading in heterogeneous vehicular edge networks: On-line and off-policy bandit solutions},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Collective de-anonymization of social networks with optional
seeds. <em>TMC</em>, <em>21</em>(12), 4218–4232. (<a
href="https://doi.org/10.1109/TMC.2021.3077520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Internet users interacting with their different friends in different social networks, the de-anonymization problem has been raising improving concern. Since the assailants may de-anonymize a social network by matching it with a correlated sanitized network and identifying anonymized user identities, multifarious arts study on the theoretical conditions or practical algorithms for correctly de-anonymizing a social network. Except for the structural information of these social networks, there has also been bounteous works taking advantage of some pre-identified seed nodes for reference in the anonymized network. In this paper, we systematically probe the theoretical conditions and algorithmic approaches for correctly matching two different-sized social networks by leveraging the multi-hop neighborhood relationships. A limited number of seeds are also taken into consideration as auxiliary information. To this end, we introduce the de-anonymization problem with the aid of the collectiveness and the collective adjacency disagreements, which are the collection of disagreements of different multi-hop adjacency matrices. We theoretically demonstrate that minimizing the collective adjacency disagreements can help match two social networks even in a very sparse circumstance, as it significantly enlarges the difference between the mismatched node pairs and the correctly matched pairs. Besides, the seeds is proved to bring positive influence in improving the de-anonymization accuracy. Algorithmically, we relax the domain of the matching function to continuum and adopt the conditional gradient descending method on the collective-form objective, to efficiently minimize the collective adjacency disagreements of two networks. We conduct tremendous experiments on different networks with or without seeds, the results of which return desirable de-anonymization accuracies and reveal the advantages of the collectiveness: the collectiveness manifests rich structural information, thereby most nodes can be correctly matched with their correspondences even in some sparse networks, where merely utilizing the 1-hop adjacency relationships might fail to work.},
  archive      = {J_TMC},
  author       = {Jiapeng Zhang and Luoyi Fu and Huan Long and Gui&#39;e Meng and Feilong Tang and Xinbing Wang and Guihai Chen},
  doi          = {10.1109/TMC.2021.3077520},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4218-4232},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Collective de-anonymization of social networks with optional seeds},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Blockchain-enabled intelligent transportation systems: A
distributed crowdsensing framework. <em>TMC</em>, <em>21</em>(12),
4201–4217. (<a href="https://doi.org/10.1109/TMC.2021.3079984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation System (ITS) is critical to cope with traffic events, e.g., traffic jams and accidents, and provide services for personal traveling. However, existing researches have not jointly considered the user data safety, utility and system latency comprehensively, to the best of our knowledge. Since both safe and efficient transmissions are significant for ITS, we construct a blockchain-enabled crowdsensing framework for distributed traffic management. First, we illustrate the system model and formulate a multi-objective optimization problem. Due to its complexity, we decompose it into two subproblems, and propose the corresponding schemes, i.e., a Deep Reinforcement Learning (DRL)-based algorithm and a DIstributed Alternating Direction mEthod of Multipliers (DIADEM) algorithm. Extensive experiments are carried out to evaluate the performance of our solutions, and experimental results demonstrate that the DRL-based algorithm can legitimately select active miners and transactions to make a satisfied trade-off between the blockchain safety and latency, and the DIADEM algorithm can effectively select task computation modes for vehicles in a distributed way to maximize their social welfare.},
  archive      = {J_TMC},
  author       = {Zhaolong Ning and Shouming Sun and Xiaojie Wang and Lei Guo and Song Guo and Xiping Hu and Bin Hu and Ricky Y. K. Kwok},
  doi          = {10.1109/TMC.2021.3079984},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4201-4217},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Blockchain-enabled intelligent transportation systems: A distributed crowdsensing framework},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AdaptiveFog: A modelling and optimization framework for fog
computing in intelligent transportation systems. <em>TMC</em>,
<em>21</em>(12), 4187–4200. (<a
href="https://doi.org/10.1109/TMC.2021.3080397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing has been advocated as an enabling technology for computationally intensive services in smart connected vehicles. Most existing works focus on analyzing the queueing and workload processing latencies associated with fog computing, ignoring the fact that wireless access latency can sometimes dominate the overall latency. This motivates the work in this paper, where we report on a five-month measurement study of the wireless access latency between connected vehicles and a fog/cloud computing system supported by commercially available LTE networks. We propose AdaptiveFog , a novel framework for autonomous and dynamic switching between different LTE networks that implement a fog/cloud infrastructure. AdaptiveFog&#39;s main objective is to maximize the service confidence level , defined as the probability that the latency of a given service type is below some threshold. To quantify the performance gap between different LTE networks, we introduce a novel statistical distance metric, called weighted Kantorovich-Rubinstein (K-R) distance. Two scenarios based on finite- and infinite-horizon optimization of short-term and long-term confidence are investigated. For each scenario, a simple threshold policy based on weighted K-R distance is proposed and proved to maximize the latency confidence for smart vehicles. Extensive analysis and simulations are performed based on our latency measurements. Our results show that AdaptiveFog achieves around 30 to 50 percent improvement in the confidence levels of fog and cloud latencies, respectively.},
  archive      = {J_TMC},
  author       = {Yong Xiao and Marwan Krunz},
  doi          = {10.1109/TMC.2021.3080397},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {12},
  number       = {12},
  pages        = {4187-4200},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AdaptiveFog: A modelling and optimization framework for fog computing in intelligent transportation systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WUR-TS: Semi-passive wake-up radio receiver based time
synchronization method for energy harvesting wireless networks.
<em>TMC</em>, <em>21</em>(11), 4172–4186. (<a
href="https://doi.org/10.1109/TMC.2021.3064374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a semi-passive wake-up radio receiver based time synchronization (WUR-TS) method is developed for energy harvesting wireless networks. In WUR-TS, energy harvesting nodes (EHNs) do not exchange any timing information, but only receive the wake-up signal broadcast periodically by the central node to synchronize time throughout the network. Based on the experimental data, a model is developed to accurately estimate the arrival time of each wake-up signal. By using this model, the EHN can calculate its clock drift in complex radio environments. We have implemented WUR-TS with a minimum number of commercial components. According to the experimental results, WUR-TS can achieve a synchronization accuracy of 3 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; s when the power supply voltage is 2.8 V and the received wake-up signal strength is higher than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$-$&lt;/tex-math&gt;&lt;/inline-formula&gt; 33 dBm. WUR-TS is an ultra-low-power synchronization method. If no wake-up signal is detected, the power consumption of each EHN is 3.2 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; W. If the wake-up signal is detected, the EHN consumes only 3.6 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mu$&lt;/tex-math&gt;&lt;/inline-formula&gt; J of energy to complete time synchronization.},
  archive      = {J_TMC},
  author       = {Yu Luo and Lina Pu},
  doi          = {10.1109/TMC.2021.3064374},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4172-4186},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WUR-TS: Semi-passive wake-up radio receiver based time synchronization method for energy harvesting wireless networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding WiFi signal frequency features for
position-independent gesture sensing. <em>TMC</em>, <em>21</em>(11),
4156–4171. (<a href="https://doi.org/10.1109/TMC.2021.3063135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed rapid development in the research area of WiFi sensing, which senses human activities in a contactless and non-intrusive manner. One major issue that hinders real-world deployment of these systems is position dependence, i.e., once the human target changes location and orientation, the sensing performance degrades significantly. Existing machine learning based methods aim to solve this problem by either generating high-dimensional features or transfer learning the environment knowledge. However, these methods require significant training effort and yet acquire limited improvement. In this paper, we start by understanding and analyzing the Doppler frequency shift in WiFi sensing. We then develop a WiFi frequency model to quantify the relationship between signal frequency and target position, motion direction and speed for human activities. Based on this theoretical model, we prove that the commonly-used movement speed and motion direction features are position dependent, and further identify movement fragments and relative motion direction changes as two position-independent features. Building upon the frequency model and the position-independent features, we design a suite of position-independent gestures and develop the gesture recognition system accordingly. Evaluation results show that under various conditions (i.e., different locations, orientations, environments, and persons), our system achieves more than 96 percent recognition accuracy without any training, significantly outperforming state-of-the-art machine learning based solutions.},
  archive      = {J_TMC},
  author       = {Kai Niu and Fusang Zhang and Xuanzhi Wang and Qin Lv and Haitong Luo and Daqing Zhang},
  doi          = {10.1109/TMC.2021.3063135},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4156-4171},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Understanding WiFi signal frequency features for position-independent gesture sensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time-efficient tag identification in blocker-assisted RFID
systems. <em>TMC</em>, <em>21</em>(11), 4139–4155. (<a
href="https://doi.org/10.1109/TMC.2021.3065366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In RFID systems, the privacy problem has attracted increasing attention as the tags have extremely limited on-chip resources and may blindly respond to unauthorized readers. To protect the privacy, one widely used solution is to deploy one or more blocker tags to collide the RF signal sent from protected tags all the time. In this paper, we investigate the problem of tag identification in privacy-sensitive RFID systems when we have the authorized reader(s). Due to the presence of blocker tags, the tag identification becomes more challenging since the protected tags and blocker tags will always respond concurrently, leading to unreconciled collisions. To overcome this challenge, we in this paper propose three efficient tag identification protocols IIP, SIP, and SUIP, which meet three application requirements: privacy, accuracy, and efficiency. IIP iteratively deactivates blocking tags as well as labeling genuine tags, and finally identifies tags by avoiding all the unreconciled collisions. On top of IIP, SIP further avoids the slot waste by carrying out a filter to separate genuine tags from others in advance. Furthermore, SUIP can identify the incremental unknown tags in an efficient way. It separates the incremental unknown tags from others by using a filter with improved performance and puts forward a collision reconciliation technique to accelerate the identification process. Simulation results demonstrate that our protocols are able to guarantee any identification accuracy in a privacy-protected way.},
  archive      = {J_TMC},
  author       = {Yanyan Wang and Jia Liu and Xia Wang and Xingyu Chen and Dong Jiang and Lijun Chen},
  doi          = {10.1109/TMC.2021.3065366},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4139-4155},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Time-efficient tag identification in blocker-assisted RFID systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TCDA: Truthful combinatorial double auctions for mobile edge
computing in industrial internet of things. <em>TMC</em>,
<em>21</em>(11), 4125–4138. (<a
href="https://doi.org/10.1109/TMC.2021.3064314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) emerges as an appealing paradigm to provide time-sensitive computing services for industrial Internet of Things (IIoT) applications. How to guarantee truthfulness and budget-balance under locality constraints is an important issue to the allocation and pricing design of the MEC system. In this paper, we propose a truthful combinatorial double auction mechanism, which integrates the padding concept and the efficient pricing strategy to guarantee desirable properties in constrained MEC environments. This mechanism takes into account the locality characteristics of the MEC systems, where mobile devices (MDs) only offload tasks to edge servers (ESs) in the proximity with various requirements, and ESs only serve their neighboring MDs with limited resources. To be specific, for allocation, a linear programming (LP)-based padding method is used to obtain the near-optimal solution in the polynomial time. For pricing, a critical-value-based pricing strategy and a VCG-based pricing strategy are designed for MDs and ESs to achieve truthfulness and budget-balance. Our theoretical analysis confirms that TCDA is able to hold a set of desirable economic properties, including truthfulness, individual rationality, and budget-balance. Furthermore, simulation results validate the theoretical analysis, and verify the effectiveness and efficiency of TCDA.},
  archive      = {J_TMC},
  author       = {Lianbo Ma and Xueyi Wang and Xingwei Wang and Liang Wang and Ying Shi and Min Huang},
  doi          = {10.1109/TMC.2021.3064314},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4125-4138},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {TCDA: Truthful combinatorial double auctions for mobile edge computing in industrial internet of things},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). &lt;Inline-formula&gt;&lt;tex-math notation=“LaTeX”&gt;<span
class="math inline"><code>S</code><code>Y</code><code>M</code><code>M</code><code>e</code><code>T</code><code>R</code><code>y</code></span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:mi
mathvariant=“monospace”&gt;SYMMeTRy&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“zheleva-ieq1-3065891.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt; :
Exploiting MIMO self-similarity for under-determined modulation
recognition. <em>TMC</em>, <em>21</em>(11), 4111–4124. (<a
href="https://doi.org/10.1109/TMC.2021.3065891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modulation recognition (modrec) seeks to identify the modulation of a transmitter from coresponding spectrum scans. It is an essential functional component of future spectrum sensing with critical applications in dynamic spectrum access and spectrum enforcement. While predominantly studied in single-input single-output (SISO) systems, practical modrec for multiple-input multiple-output (MIMO) communications requires more research attention. Existing MIMO modrec impose stringent requirements of fully- or over-determined sensing front-end, i.e., the number of sensor antennas should exceed that at the transmitter. This poses a prohibitive sensor cost even for simple 2x2 MIMO systems and will severely hamper progress in flexible spectrum access. We design a MIMO modrec framework that enables efficient and cost-effective modulation classification for under-determined settings involving fewer sensor antennas than those used for transmission. Our key idea is to exploit the inherent multi-scale self-similarity of MIMO modulation &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {IQ}$&lt;/tex-math&gt;&lt;/inline-formula&gt; constellations, which persists in under-determined settings. Our framework, called &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {{SYMMeTRy}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ( S elf-similarit Y for M IMO M odula T ion R ecognition), designs domain-aware classification features with high discriminative potential by summarizing regularities of symbol co-location in the MIMO constellation. To this end, we summarize the fractal geometry of observed samples to extract discriminative features for supervised MIMO modrec. We evaluate &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {{SYMMeTRy}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; in a realistic simulation and in a small-scale MIMO testbed. We demonstrate that it maintains high and consistent performance across various noise regimes, channel fading conditions and with increasing MIMO transmitter complexity. Our efforts highlight &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {{SYMMeTRy}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ’s high potential to enable efficient and practical MIMO modrec in spectrum sensing infrastructures with mixed-complexity sensors.},
  archive      = {J_TMC},
  author       = {Wei Xiong and Lin Zhang and Maxwell McNeil and Petko Bogdanov and Mariya Zheleva},
  doi          = {10.1109/TMC.2021.3065891},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4111-4124},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathtt {{SYMMeTRy}}$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi mathvariant=&quot;monospace&quot;&gt;SYMMeTRy&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;zheleva-ieq1-3065891.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt; : exploiting MIMO self-similarity for under-determined modulation recognition},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stable matching based resource allocation for service
provider’s revenue maximization in 5G networks. <em>TMC</em>,
<em>21</em>(11), 4094–4110. (<a
href="https://doi.org/10.1109/TMC.2021.3064047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G technology is foreseen to have a heterogeneous architecture with the various computational capability, and radio-enabled service providers (SPs) and service requesters (SRs), working altogether in a cellular model. However, the coexistence of heterogeneous network model spawns several research challenges such as diverse SRs with uneven service deadlines, interference management, and revenue maximization of non-uniform computational capacities enabled SPs. Thus, we propose a coexistence of heterogeneous SPs and SRs enabled cellular 5G network and formulate the SPs’ revenue maximization via resource allocation, considering different kinds of interference, data rate, and latency altogether as an optimization problem and further propose a distributed many-to-many stable matching based solution. Moreover, we offer an adaptive stable matching based distributed algorithm to solve the formulated problem in a dynamic network model. Through extensive theoretical and simulation analysis, we have shown the effect of different parameters on the resource allocation objectives and achieves 94 percent of optimum network performance.},
  archive      = {J_TMC},
  author       = {Ajay Pratap and Sajal K. Das},
  doi          = {10.1109/TMC.2021.3064047},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4094-4110},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Stable matching based resource allocation for service provider&#39;s revenue maximization in 5G networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Radio frequency fingerprinting on the edge. <em>TMC</em>,
<em>21</em>(11), 4078–4093. (<a
href="https://doi.org/10.1109/TMC.2021.3064466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have been very successful at radio frequency fingerprinting tasks, predicting the identity of transmitting devices with high accuracy. We study radio frequency fingerprinting deployments at resource-constrained edge devices. We use structured pruning to jointly train and sparsify neural networks tailored to edge hardware implementations. We compress convolutional layers by a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$27.2\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; factor while incurring a negligible prediction accuracy decrease (less than 1 percent). We demonstrate the efficacy of our approach over multiple edge hardware platforms, including a Samsung Gallaxy S10 phone and a Xilinx-ZCU104 FPGA. Our method yields significant inference speedups, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$11.5\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; on the FPGA and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; on the smartphone, as well as high efficiency: the FPGA processing time is &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$17\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; smaller than in a V100 GPU. To the best of our knowledge, we are the first to explore the possibility of compressing networks for radio frequency fingerprinting; as such, our experiments can be seen as a means of characterizing the informational capacity associated with this specific learning task.},
  archive      = {J_TMC},
  author       = {Tong Jian and Yifan Gong and Zheng Zhan and Runbin Shi and Nasim Soltani and Zifeng Wang and Jennifer Dy and Kaushik Chowdhury and Yanzhi Wang and Stratis Ioannidis},
  doi          = {10.1109/TMC.2021.3064466},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4078-4093},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Radio frequency fingerprinting on the edge},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On self-configuring IoT with dual radios: A cross-layer
approach. <em>TMC</em>, <em>21</em>(11), 4064–4077. (<a
href="https://doi.org/10.1109/TMC.2021.3066441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing interest in emerging IoT applications provides a strong drive to release a plethora of communication radios from different standards, which are largely classified into short-range (IEEE 802.15.4) and long-range radios (IEEE 802.15.4g). In this paper, we propose a joint, self-configuring MAC and routing protocol, SEDA-Net, which aims at adaptively choosing the best configuration for communication coordination and data delivery, depending on different deployed topologies and external conditions. SEDA-Net is a combination of SEDA-MAC, SEDA-Routing, and Cross-Opt. SEDA-MAC and SEDA-Routing adaptively determine the best radio configuration for communication coordination under duty-cycling and each node&#39;s next-hop over which radio and Cross-Opt jointly optimizes inter-coupled MAC and routing in an iterative manner. SEDA-Net differs from prior approaches which are designed with static configurations of radios and/or mainly with the goal of throughput maximization for dual Wi-Fi or Wi-Fi/LTE setups. We implement SEDA-Net on Contiki OS and perform extensive simulations and experiments using a testbed in an office building. This testbed consists of 45 nodes equipped with a commercial platform, Firefly, having 2.4 GHz short-range and 920 MHz long-range radios. We demonstrate that energy efficiency quantified by the network lifetime increases by up to 2.1 times, compared to that of existing approaches.},
  archive      = {J_TMC},
  author       = {Jinhwan Jung and Joonki Hong and Yung Yi},
  doi          = {10.1109/TMC.2021.3066441},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4064-4077},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On self-configuring IoT with dual radios: A cross-layer approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-block ascending auctions for effective 5G licensed
shared access. <em>TMC</em>, <em>21</em>(11), 4051–4063. (<a
href="https://doi.org/10.1109/TMC.2021.3063990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Licensed Shared Access (LSA) is a new concept proposed by the radio spectrum policy group in order to optimize spectrum usage: a Mobile Network Operator (MNO) can access temporarily to other incumbent&#39;s spectrum after obtaining a license. The licensing process is made via an auction mechanism. The mechanisms proposed in the literature for the LSA context are one-shot auction mechanisms which allocate all the available spectrum as a unique block. In this paper, we first show how to increase the performance of those auctions (in terms of revenue, efficiency and fairness of the allocation) while preserving truthful bidding, by splitting spectrum and converting single block auctions into multi-block auctions. Simulation results illustrate how appropriately choosing the number of blocks allows to increase the aforementioned metrics. Second, we show how to convert one-shot mechanisms to equivalent ascending mechanisms (in terms of allocations and payments) so that we add transparency and privacy to the auction.},
  archive      = {J_TMC},
  author       = {Ayman Chouayakh and Aurélien Bechler and Isabel Amigo and Loutfi Nuaymi and Patrick Maillé},
  doi          = {10.1109/TMC.2021.3063990},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4051-4063},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-block ascending auctions for effective 5G licensed shared access},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). LoRa backscatter assisted state estimator for micro aerial
vehicles with online initialization. <em>TMC</em>, <em>21</em>(11),
4038–4050. (<a href="https://doi.org/10.1109/TMC.2021.3063850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advances in agile micro aerial vehicles (MAVs) have shown great potential in replacing humans for labor-intensive or dangerous indoor investigation, such as warehouse management and fire rescue. However, the design of a state estimation system that enables autonomous flight poses fundamental challenges in such dim or smoky environments. Current dominated computer-vision based solutions only work in well-lighted texture-rich environments. This paper addresses the challenge by proposing Marvel, an RF backscatter-based state estimation system with online initialization and calibration. Marvel is nonintrusive to commercial MAVs by attaching backscatter tags to their landing gears without internal hardware modifications, and works in a plug-and-play fashion with an automatic initialization module. Marvel is enabled by three new designs, a backscatter-based pose sensing module, an online initialization and calibration module, and a backscatter-inertial super-accuracy state estimation algorithm. We demonstrate our design by programming a commercial MAV to autonomously fly in different trajectories. The results show that Marvel supports navigation within a range of 50 m or through three concrete walls, with an accuracy of 34 cm for localization and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$4.99^{\circ }$&lt;/tex-math&gt;&lt;/inline-formula&gt; for orientation estimation. We further demonstrate our online initialization and calibration by comparing to the perfect initial parameter measurements from burdensome manual operations.},
  archive      = {J_TMC},
  author       = {Shengkai Zhang and Wei Wang and Ning Zhang and Tao Jiang},
  doi          = {10.1109/TMC.2021.3063850},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4038-4050},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LoRa backscatter assisted state estimator for micro aerial vehicles with online initialization},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Location selection for air quality monitoring with
consideration of limited budget and estimation error. <em>TMC</em>,
<em>21</em>(11), 4025–4037. (<a
href="https://doi.org/10.1109/TMC.2021.3065656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate acquisition of air quality is important for improving human well-being. However, directly monitoring air quality at all locations is costly. The challenge is how we can select a small number of locations to monitor the air quality such that the estimation error of air quality at other locations can be minimized. In this paper, a general location selection strategy is proposed based on active learning, which involves iterations of a selector and an estimator. We implement four instances of this general strategy to embody it: KAL (Active Learning based on Kriging), TAL (Active Learning based on Regression Tree), KMAL (Active Learning based on Kriging and MPGR) and TMAL (Active Learning based on Regression Tree and MPGR). The estimator of KAL or TAL can estimate the air quality at remaining locations from air quality samples at monitoring locations, leveraging spatial or cross-domain correlation of air quality. The selecting indicators of their selectors are designed to measure the uncertainty of unlabeled samples according to their estimators. KMAL and TMAL are upgrades of the former two, respectively, by introducing MPGR (Manifold Preserving Graph Reduction) to also take the representativeness of unlabeled samples into account. The experimental results show that the proposed strategy can achieve a low estimation error with few monitoring locations. Particularly, given the same budget (i.e., the number of monitoring locations), the estimation error is reduced from about 20 percent of baselines to 15 percent by KAL and to 5 percent by KMAL; and TAML likewise.},
  archive      = {J_TMC},
  author       = {Zhiyong Yu and Huijuan Chang and Zhiwen Yu and Bin Guo and Rongye Shi},
  doi          = {10.1109/TMC.2021.3065656},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4025-4037},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Location selection for air quality monitoring with consideration of limited budget and estimation error},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Invariant feature learning for sensor-based human activity
recognition. <em>TMC</em>, <em>21</em>(11), 4013–4024. (<a
href="https://doi.org/10.1109/TMC.2021.3064252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable sensor-based human activity recognition (HAR) has been a research focus in the field of ubiquitous and mobile computing for years. In recent years, many deep models have been applied to HAR problems. However, deep learning methods typically require a large amount of data for models to generalize well. Significant variances caused by different participants or diverse sensor devices limit the direct application of a pre-trained model to a subject or device that has not been seen before. To address these problems, we present an invariant feature learning framework (IFLF) that extracts common information shared across subjects and devices. IFLF incorporates two learning paradigms: 1) meta-learning to capture robust features across seen domains and adapt to an unseen one with similarity-based data selection; 2) multi-task learning to deal with data shortage and enhance overall performance via knowledge sharing among different subjects. Experiments demonstrated that IFLF is effective in handling both subject and device diversion across popular open datasets and an in-house dataset. It outperforms a baseline model of up to 40 percent in test accuracy.},
  archive      = {J_TMC},
  author       = {Yujiao Hao and Rong Zheng and Boyu Wang},
  doi          = {10.1109/TMC.2021.3064252},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4013-4024},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Invariant feature learning for sensor-based human activity recognition},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interference-aware game-theoretic device allocation for
mobile edge computing. <em>TMC</em>, <em>21</em>(11), 4001–4012. (<a
href="https://doi.org/10.1109/TMC.2021.3064063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC), as an emerging and prospective mobile computing paradigm, allows a content provider to serve its users by allocating their mobile devices to nearby edge servers to lower the latency in the delivery of its content to those mobile services. From the content provider&#39;s perspective, a cost-effective mobile device allocation (MDA) aims to allocate maximum mobile devices to minimum edge servers. However, the allocation of excessive mobile devices to an edge server may result in severe communication interference and consequently, impact mobile devices’ data rates. Sometimes, not all the mobile devices can be allocated to edge servers and thus have to retrieve content from the remote cloud through base stations with high latency. The connection between these mobile devices and base stations also incur communication interference. In this paper, we formally model this Interference-aware mobile edge device allocation (I-MEDA) problem, and propose a game-theoretic based approach named I-MEDAGame to formulate the I-MEDA problem as an I-MEDA game. In the I-MEDA game, allocation decisions are made for individual mobile devices in parallel to alleviate the need for centralized optimization. Our theoretical analysis of I-MEDAGame shows that it admits at least one Nash equilibrium. To solve the I-MEDA problem, I-MEDAGame employs a novel decentralized algorithm to find the Nash equilibrium of the IMEDA game. The performance of I-MEDAGame is theoretically analyzed and experimentally evaluated. The results show that I-MEDAGame can solve the I-MEDA problem effectively and efficiently, outperforming four representative approaches significantly.},
  archive      = {J_TMC},
  author       = {Guangming Cui and Qiang He and Feifei Chen and Yiwen Zhang and Hai Jin and Yun Yang},
  doi          = {10.1109/TMC.2021.3064063},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {4001-4012},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Interference-aware game-theoretic device allocation for mobile edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). G-ADRR: Network-wide slicing of wi-fi networks with variable
loads in space and time. <em>TMC</em>, <em>21</em>(11), 3986–4000. (<a
href="https://doi.org/10.1109/TMC.2021.3066875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As part of 3GPP releases 15 and 16 Wi-Fi networks have been integrated with the 5G Core, which is a key feature in private network scenarios. Another important feature for private networks is multi-tenancy, whereby an infrastructure provider shares a common radio access network among several tenants subject to service level agreements (SLAs). 3GPP has defined network slicing on the radio access segment supporting multi-tenancy for 5GNR, but a similar feature is lacking in Wi-Fi networks. In this paper we present G-ADRR, which, to be best of our knowledge, is the first global slicing policy for Wi-Fi that delivers per-tenant radio level SLAs over a given geographical area. We extensively evaluate the performance of G-ADRR by means of an experimental prototype and packet level simulations, and demonstrate its advantages as compared to two alternative global scheduling strategies and a static slice configuration policy commonly used in the state-of-the-art.},
  archive      = {J_TMC},
  author       = {August Betzler and Daniel Camps-Mur and Miguel Catalan},
  doi          = {10.1109/TMC.2021.3066875},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3986-4000},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {G-ADRR: Network-wide slicing of wi-fi networks with variable loads in space and time},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-grained vibration based sensing using a smartphone.
<em>TMC</em>, <em>21</em>(11), 3971–3985. (<a
href="https://doi.org/10.1109/TMC.2021.3067679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing surfaces based on their vibration signatures is useful as it can enable tagging of different locations without requiring any additional hardware, such as near field communication (NFC) tags. However, previous vibration based surface recognition schemes either use custom hardware for creating and sensing vibration, which makes them difficult to adopt, or use intertial (IMU) sensors in commercial off-the-shelf (COTS) smartphones to sense movements produced due to vibrations, which makes them coarse-grained because of the low sampling rates of IMU sensors. The mainstream COTS smartphones based schemes are also susceptible to inherent hardware based irregularities in vibration mechanism of the smartphones. Moreover, the existing schemes that use microphones to sense vibration are prone to short-term and constant background noises (e.g., intermittent talking, exhaust fan, etc.) because microphones not only capture the sounds created by vibration but also other interfering sounds present in the environment. In this paper, we propose VibroTag, a robust and practical vibration based sensing scheme that works with smartphones with different hardware, can extract fine-grained vibration signatures of different surfaces, and is robust to environmental noise and hardware based irregularities. We implemented VibroTag on two different Android phones and evaluated in multiple different environments where we collected data from four individuals for 5 to 20 consecutive days. Our results show that VibroTag achieves an average accuracy of 86.55 percent while recognizing 24 different locations/surfaces, even when some of those surfaces were made of similar material. VibroTag’s accuracy is 37 percent higher than the average accuracy of 49.25 percent achieved by one of the state-of-the-art IMUs based schemes, which we implemented for comparison with VibroTag.},
  archive      = {J_TMC},
  author       = {Kamran Ali and Alex X. Liu},
  doi          = {10.1109/TMC.2021.3067679},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3971-3985},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fine-grained vibration based sensing using a smartphone},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and high-resolution NLoS beam switching over commercial
off-the-shelf mmWave devices. <em>TMC</em>, <em>21</em>(11), 3956–3970.
(<a href="https://doi.org/10.1109/TMC.2021.3064809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high directionality of mmWave communication makes its line-of-sight (LoS) path susceptible to blockage when the user is moving. Most existing solutions have very stringent requirements on the antennas of the transmitter and the receiver, which are hardly met by today’s consumer-level commercial off-the-shelf (COTS) mmWave products. In reality, a COTS device uses low-resolution wide-beam antennas, and hence cannot support the aforementioned methods for NLoS beam switching in response to the LoS blockage. In this paper, we develop a new method to support high-resolution mmWave multi-path channel resolving based on coarse-grained wide-beam phased array antennas. We design a novel real-time beam-switching algorithm that allows COTS devices to estimate the location and reflection coefficient of the dominant reflectors. Whenever the current LoS is blocked, our algorithm can compute in real-time the best alternative beam direction based on estimated reflectors to establish a strong NLoS link. We implemented the proposed algorithm on a COTS mmWave device and evaluated the system’s performance on the physical and transport layer. Our experiments demonstrate the effectiveness of our algorithm on estimating dominant reflectors and calculating strong alternative beam directions, and its efficacy in providing robust connections for COTS mmWave devices.},
  archive      = {J_TMC},
  author       = {Xueyang Hu and Tian Liu and Tao Shu},
  doi          = {10.1109/TMC.2021.3064809},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3956-3970},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fast and high-resolution NLoS beam switching over commercial off-the-shelf mmWave devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling global cooperation for heterogeneous networks via
reliable concurrent cross technology communications. <em>TMC</em>,
<em>21</em>(11), 3941–3955. (<a
href="https://doi.org/10.1109/TMC.2021.3066568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial scientific medical (ISM) band has become more and more crowded due to the ever-growing size of many mainstream technologies, e.g., Wi-Fi, ZigBee and Bluetooth. Though the coexistence issue has led to severe Cross Technology Interference (CTI), it provides great opportunities to better utilize the scarce bandwidth resources. A fundamental question is how to ensure harmonious and effective operations for different networks? To exploit it, a novel global cooperation framework is proposed. In particular, our work enables reliable concurrent Cross Technology Communication (CTC) from Wi-Fi to Wi-Fi, ZigBee and Bluetooth commodity devices. Compared to existing CTC approaches, our scheme improves the communication efficiency significantly, and hence is the foundation for effective global cooperation. Based on the proposed CTC scheme, a unified Media Access Control (MAC) approach is introduced to cooperate CTC message transmission and reception for heterogeneous networks with different MACs. Three proof-of-concepts applications, e.g., global synchronization, global CTI coordination and global Location Based Service (LBS) broadcasting are discussed to fully leverage the benefits of global cooperation. Extensive evaluations show that compared with existing schemes, the proposed framework achieves 8.1 times lower synchronization error, 9 times lower packet delivery delay, and 2.7 times lower energy consumption for acquiring LBS message.},
  archive      = {J_TMC},
  author       = {Weiwei Chen and Zhimeng Yin and Tian He},
  doi          = {10.1109/TMC.2021.3066568},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3941-3955},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling global cooperation for heterogeneous networks via reliable concurrent cross technology communications},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-technology communication for heterogeneous wireless
devices through symbol-level energy modulation. <em>TMC</em>,
<em>21</em>(11), 3926–3940. (<a
href="https://doi.org/10.1109/TMC.2021.3065998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coexistence of heterogeneous devices in wireless networks brings a new topic on cross-technology communication (CTC) to improve the coexistence efficiency and boost collaboration among these devices. Current advances on CTC mainly fall into two categories, physical-layer CTC and packet-level energy modulation (PLEM). The physical-layer CTC achieves a high CTC data rate, but with channel incompatible to commercial devices, making it hard to be deployed in current wireless networks. PLEM is channel and physical layer compatible, but with two main drawbacks of the low CTC data rate and MAC incompatibility, which will induce severe interference to the other devices’ normal data transmissions. In this paper, we propose symbol-level energy modulation (SLEM), the first CTC method that is fully compatible with current devices in both channel and the physical/MAC layer processes, having the ability to be deployed in commercial wireless networks smoothly. SLEM inserts extra bits to WiFi data bits to generate the transmitting bits, so as to adjust the energy levels of WiFi symbols to deliver CTC information. We make theoretical analysis to figure out the performance of both CTC and WiFi transmissions. We also conduct experiments to demonstrate the feasibility of SLEM and its performance under different network situations.},
  archive      = {J_TMC},
  author       = {Junmei Yao and Xiaolong Zheng and Ruitao Xie and Kaishun Wu},
  doi          = {10.1109/TMC.2021.3065998},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3926-3940},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cross-technology communication for heterogeneous wireless devices through symbol-level energy modulation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterizing embedded web browsing in mobile apps.
<em>TMC</em>, <em>21</em>(11), 3912–3925. (<a
href="https://doi.org/10.1109/TMC.2021.3065945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern mobile operating systems support displaying Web pages in native mobile applications. When an app user navigates to a specific location containing a Web page, the Web page will be loaded and rendered from within the app. Such kind of Web browsing, as we call embedded Web browsing , is different from traditional Web browsing, which involves typing a URL on a browser and loading the Web page. However, little has been known about the prevalence or performance of such embedded Web pages. In this paper, we conduct, to the best of our knowledge, the first measurement study on embedded Web browsing on Android. Our study on 22,521 popular Android apps shows that 57.9 and 73.8 percent of apps embed Web pages on two popular app markets, that is, Google Play and Wandoujia, respectively. We design and implement EWProfiler, a tool that can automatically search for embedded Web pages inside apps, trigger page loads, and retrieve performance metrics to analyze the embedded Web browsing performance at scale. Based on 445 embedded Web pages obtained by EWProfiler in 99 popular apps from the two app markets, we investigate the characteristics and performance of embedded Web pages, and find that embedded Web pages significantly impede the app user experience. We investigate the effectiveness of three techniques, i.e., separating the browser kernel to a different process, loading pages from the local storage, and pre-rendering, to optimize the performance of embedded Web browsing. We believe that our findings could draw the attention of Web developers, browser vendors, app developers, and mobile OS vendors together toward a better performance of embedded Web browsing.},
  archive      = {J_TMC},
  author       = {Deyu Tian and Yun Ma and Aruna Balasubramanian and Yunxin Liu and Gang Huang and Xuanzhe Liu},
  doi          = {10.1109/TMC.2021.3065945},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3912-3925},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Characterizing embedded web browsing in mobile apps},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Budgeted unknown worker recruitment for heterogeneous
crowdsensing using CMAB. <em>TMC</em>, <em>21</em>(11), 3895–3911. (<a
href="https://doi.org/10.1109/TMC.2021.3064324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing, through which a requester can coordinate a crowd of workers to complete some sensing tasks, has attracted significant attention recently. In this paper, we focus on the unknown worker recruitment problem in mobile crowdsensing, where workers’ sensing qualities are unknown a priori. We consider the scenario of recruiting workers to complete some continuous sensing tasks. The whole process is divided into multiple rounds. In each round, every task may be covered by more than one recruited workers, but its completion quality only depends on these workers’ maximum sensing quality. Each recruited worker will incur a cost and each task is attached a weight to indicate its importance. Our objective is to determine a recruiting strategy to maximize the total weighted completion quality under a limited budget. We model such unknown worker recruitment process as a novel combinatorial multi-armed bandit (CMAB) problem, and propose an unknown worker recruitment algorithm based on the modified upper confidence bound (UCB). Moreover, we extend the problem to the case where the workers’ costs are also unknown and design the corresponding algorithm. We analyze the regret bounds of the two proposed algorithms through rigorous proofs. In addition, we also study the unknown worker recruitment problem with fairness constraints. Here, the term “fairness” means that the platform must guarantee a minimum selection fraction for each registered worker, so that the platform can avoid the scenario where some workers are over-recruited but some others might be under-recruited. For this problem, we devise a fairness-aware unknown worker recruitment algorithm. Finally, we demonstrate the performance of the proposed algorithms through extensive simulations on real-world traces},
  archive      = {J_TMC},
  author       = {Guoju Gao and He Huang and Mingjun Xiao and Jie Wu and Yu-E Sun and Yang Du},
  doi          = {10.1109/TMC.2021.3064324},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3895-3911},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Budgeted unknown worker recruitment for heterogeneous crowdsensing using CMAB},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BlockRoam: Blockchain-based roaming management system for
future mobile networks. <em>TMC</em>, <em>21</em>(11), 3880–3894. (<a
href="https://doi.org/10.1109/TMC.2021.3065672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile service providers (MSPs) are particularly vulnerable to roaming frauds, especially ones that exploit the long delay in the data exchange process of the contemporary roaming management systems, causing multi-billion dollars loss each year. In this paper, we introduce BlockRoam, a novel blockchain-based roaming management system that provides an efficient data exchange platform among MSPs and mobile subscribers. Utilizing the Proof-of-Stake (PoS) consensus mechanism and smart contracts, BlockRoam can significantly shorten the information exchanging delay, thereby addressing the roaming fraud problems. Through intensive analysis, we show that the security and performance of such PoS-based blockchain network can be further enhanced by incentivizing more users (e.g., subscribers) to participate in the network. Moreover, users in such networks often join stake pools (e.g., formed by MSPs) to increase their profits. Therefore, we develop an economic model based on Stackelberg game to jointly maximize the profits of the network users and the stake pool, thereby encouraging user participation. We also propose an effective method to guarantee the uniqueness of this game’s equilibrium. The performance evaluations show that the proposed economic model helps the MSPs to earn additional profits, attracts more investment to the blockchain network, and enhances the network’s security and performance.},
  archive      = {J_TMC},
  author       = {Cong T. Nguyen and Diep N. Nguyen and Dinh Thai Hoang and Hoang-Anh Pham and Nguyen Huynh Tuong and Yong Xiao and Eryk Dutkiewicz},
  doi          = {10.1109/TMC.2021.3065672},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3880-3894},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BlockRoam: Blockchain-based roaming management system for future mobile networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Beyond RSS: A PRR and SNR aided localization system for
transceiver-free target in sparse wireless networks. <em>TMC</em>,
<em>21</em>(11), 3866–3879. (<a
href="https://doi.org/10.1109/TMC.2021.3063629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays transceiver-free (also referred to as device-free) localization using Received Signal Strength (RSS) is a hot topic for researchers due to its widespread applicability. However, RSS is easily affected by the indoor environment, resulting in a dense deployment of reference nodes. Some hybrid systems have already been proposed to help RSS localization, but most of them require additional hardware support. In order to solve this problem, in this paper, we propose two algorithms, which leverage the Packet Received Rate (PRR) to help RSS localization without additional hardware support. Moreover, we take the environment noise information into consideration by utilizing the Signal-to-Noise Ratio (SNR) which is based on the RSS and Noise Floor (NF) information instead of pure RSS. Thus, we can alleviate the noise effect in the environment and make our system more sensitive to the target. Specifically, when reference nodes are sparsely deployed and RSS is very weak, PRR and SNR can help in performing localization more accurately. Our BEYOND RSS system is based on sparse wireless sensor networks, wherein the experimental results show that the average localization error of our approach outperforms the pure RSS based approach by about 15.19%.},
  archive      = {J_TMC},
  author       = {Dian Zhang and Wen Xie and Zexiong Liao and Wenzhan Zhu and Landu Jiang and Yongpan Zou},
  doi          = {10.1109/TMC.2021.3063629},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3866-3879},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Beyond RSS: A PRR and SNR aided localization system for transceiver-free target in sparse wireless networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BEHAVE: Behavior-aware, intelligent and fair resource
management for heterogeneous edge-IoT systems. <em>TMC</em>,
<em>21</em>(11), 3852–3865. (<a
href="https://doi.org/10.1109/TMC.2021.3068632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is an emerging solution to support the future Internet of Things (IoT) applications that are delay-sensitive, processing-intensive or that require closer intelligence. Machine intelligence and data-driven approaches are envisioned to build future Edge-IoT systems that satisfy IoT devices’ demands for edge resources. However, significant challenges and technical barriers exist which complicate the resource management for such Edge-IoT systems. IoT devices running various applications can demonstrate a wide range of behaviors in the devices’ resource demand that are extremely difficult to manage. In addition, the management of multidimensional resources fairly and efficiently by the edge in such a setting is a challenging task. In this paper, we develop a novel data-driven resource management framework named BEHAVE that intelligently and fairly allocates edge resources to heterogeneous IoT devices with consideration of their behavior of resource demand (BRD). BEHAVE aims to holistically address the management technical barriers by: 1) building an efficient scheme for modeling and assessment of the BRD of IoT devices based on their resource requests and resource usage; 2) expanding a new Rational, Fair, and Truthful Resource Allocation (RFTA) model that binds the devices’ BRD and resource allocation to achieve fair allocation and encourage truthfulness in resource demand; and 3) developing an enhanced deep reinforcement learning (EDRL) scheme to achieve the RFTA goals. The evaluation results demonstrate BEHAVE &#39;s capability to analyze the IoT devices’ BRD and adjust its resource management policy accordingly.},
  archive      = {J_TMC},
  author       = {Ismail AlQerm and Jianyu Wang and Jianli Pan and Yuanni Liu},
  doi          = {10.1109/TMC.2021.3068632},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3852-3865},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {BEHAVE: Behavior-aware, intelligent and fair resource management for heterogeneous edge-IoT systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An online framework for joint network selection and service
placement in mobile edge computing. <em>TMC</em>, <em>21</em>(11),
3836–3851. (<a href="https://doi.org/10.1109/TMC.2021.3064847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and deployment of 5G wireless technology, mobile edge computing (MEC) has emerged as a new computing paradigm to facilitate a large variety of infrastructures at the network edge to reduce user-perceived communication delay. One of the fundamental problems in this new paradigm is to preserve satisfactory quality-of-service (QoS) for mobile users in light of densely dispersed wireless communication environment and often capacity-constrained MEC nodes. Such user-perceived QoS, typically in terms of the end-to-end delay, is highly vulnerable to both access network bottleneck and communication delay. Previous works have primarily focused on optimizing the communication delay through dynamic service placement, while ignoring the critical effect of access network selection on the access delay. In this work, we study the problem of jointly optimizing the access network selection and service placement for MEC, with the objective of improving the QoS in a cost-efficient manner by judiciously balancing the access delay, communication delay, and service switching cost. Specifically, we propose an efficient online framework to decompose a long-term time-varying optimization problem into a series of one-shot subproblems. To address the NP-hardness of the one-shot problem, we design a computationally-efficient two-phase algorithm based on matching and game theory, which achieves a near-optimal solution. Both rigorous theoretical analysis on the optimality gap and extensive trace-driven simulations are conducted to validate the efficacy of our proposed solution.},
  archive      = {J_TMC},
  author       = {Bin Gao and Zhi Zhou and Fangming Liu and Fei Xu and Bo Li},
  doi          = {10.1109/TMC.2021.3064847},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3836-3851},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An online framework for joint network selection and service placement in mobile edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive data transmission control for spatio-temporal data
retention over crowds of vehicles. <em>TMC</em>, <em>21</em>(11),
3822–3835. (<a href="https://doi.org/10.1109/TMC.2021.3066438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some specific services for Internet of Things, such as real-time map and providing local weather information, depend strongly on geographical time and location. We refer to the data for such service as spatio-temporal data (STD). When STD is used in a query response system similar to conventional Internet services, users not only need to acquire data actively as required, they must also have functions for retrieving data available STD. Therefore, we propose an STD retention system that uses vehicles as information hubs (InfoHubs) for disseminating and retaining the data in a specific area. In our system, InfoHubs diffuse, maintain, and advertise STD over places and times where the STD are strongly dependent, thereby allowing users to receive such data passively within the specific area. Additionally, because STD are associated with a particular space, the system can reduce search costs. We also propose an adaptive transmission control method that each vehicle effectively operates its wireless resources autonomously and STD are retained and distributed efficiently. Finally, we evaluated our proposed method using simulations and clarified that our proposed system is capable of achieving a coverage rate of nearly 100 percent for STD while reducing the number of data transmissions compared to existing systems.},
  archive      = {J_TMC},
  author       = {Daiki Nobayashi and Ichiro Goto and Hiroki Teshiba and Kazuya Tsukamoto and Takeshi Ikenaga and Mario Gerla},
  doi          = {10.1109/TMC.2021.3066438},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3822-3835},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive data transmission control for spatio-temporal data retention over crowds of vehicles},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A low cost decentralized future contacts prediction model
using wi-fi traces. <em>TMC</em>, <em>21</em>(11), 3807–3821. (<a
href="https://doi.org/10.1109/TMC.2021.3065026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to accurately predict human encounters can inspire a variety of promising applications, ranging from epidemiology to data forwarding in opportunistic networks. This work aims at designing a low cost, highly accurate human encounter prediction model based on Wi-Fi datasets. By leveraging the temporal dependency of human mobility, we propose the distributed human encounter prediction (DHEP) model, which uses the Wi-Fi access history and inferred contact information of only the person of interest to estimate future encounters of that person. We implement the proposed DHEP model using a recurrent neural network and a feed-forward neural network. An embedding model that learns the low-dimensional representation of a person&#39;s location is proposed to reduce the number of training parameters. The experimental results on two large Wi-Fi datasets show the proposed RNN-based DHEP model outperforms existing models, and achieves 87 to 91 percent accuracy based on University at Buffalo (UB) traces. We also compare DHEP with the centralized human encounter prediction (CHEP) model, which gathers the contact history of all people for predicting future encounters. Despite a slightly lower performance than CHEP, DHEP has a low overhead and can protect data privacy.},
  archive      = {J_TMC},
  author       = {Thi-Nga Dao and Tan-Quan Ngo and Cong-Binh Nguyen and Seokhoon Yoon and Jangyoung Kim and Chunming Qiao},
  doi          = {10.1109/TMC.2021.3065026},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {11},
  number       = {11},
  pages        = {3807-3821},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A low cost decentralized future contacts prediction model using wi-fi traces},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ULPT: A user-centric location privacy trading framework for
mobile crowd sensing. <em>TMC</em>, <em>21</em>(10), 3789–3806. (<a
href="https://doi.org/10.1109/TMC.2021.3058181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowd sensing (MCS) arises as a promising data collection paradigm that leverages the power of ubiquitous mobile devices to acquire rich information regarding their surrounding environment. In many location-based sensing tasks, workers are required to associate their sensing reports with corresponding geographic coordinates. Such information leaves a trail of worker&#39;s historical location record which thus poses a severe threat to their location privacy. On the other hand, individual workers may perceive location privacy differently. Instead of following conventional solutions that aim to perfectly hide user privacy, this paper adopts a novel alternative approach. A u ser-centric l ocation p rivacy t rading framework, called ULPT, is constructed to facilitate location privacy trading between workers and the platform. Each worker can decide how much location privacy to disclose to the platform in an MCS task based on its own location privacy leakage budget &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\xi$&lt;/tex-math&gt;&lt;/inline-formula&gt; . The higher &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\xi$&lt;/tex-math&gt;&lt;/inline-formula&gt; is, the more privacy its reported location discloses. Accordingly, it receives higher payment from the platform as compensation. Besides, ULPT enables the platform to select a suitable set of winning workers to achieve desirable MCS service accuracy while taking into account of its budget limit and worker privacy requirements. For this purpose, a heuristic algorithm is devised with a bounded optimality gap. As formally proved in this manuscript, ULPT guarantees a series of nice properties, including &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\xi$&lt;/tex-math&gt;&lt;/inline-formula&gt; - privacy , &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(\alpha, \beta)$&lt;/tex-math&gt;&lt;/inline-formula&gt; - accuracy , budget feasibility . Moreover, both rigorous theoretical analysis and extensive simulations are conducted to evaluate tradeoffs among these three.},
  archive      = {J_TMC},
  author       = {Wenqiang Jin and Mingyan Xiao and Linke Guo and Lei Yang and Ming Li},
  doi          = {10.1109/TMC.2021.3058181},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3789-3806},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ULPT: A user-centric location privacy trading framework for mobile crowd sensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Storage capacity of opportunistic information dissemination
systems. <em>TMC</em>, <em>21</em>(10), 3773–3788. (<a
href="https://doi.org/10.1109/TMC.2021.3057259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Floating Content (FC) is a paradigm for localized infrastructure-less content dissemination, that aims at sharing information among nodes within a restricted geographical area by relying only on opportunistic content exchanges. FC provides the basis for the probabilistic spatial storage of shared information in a completely decentralized fashion, usually without support from dedicated infrastructure. One of the key open issues in FC is the characterization of its performance limits as functions of the system parameters, accounting for its reliance on volatile wireless exchanges and on limited user resources. This paper takes a first step towards tackling this issue, by elaborating a model for the storage capacity of FC, i.e., for the maximum amount of information that can be stored through the FC paradigm. The storage capacity of FC, and of similar probabilistic content dissemination systems, is evaluated with a powerful information theoretical approach, based on a mean field model of opportunistic information exchange. In addition, an extremely simple explicit approximate expression for storage capacity is derived. The numerical results generated by our analytical models are compared to the predictions of realistic simulations under different setups, proving the accuracy of our analytical approaches, and characterizing the properties of the FC storage capacity.},
  archive      = {J_TMC},
  author       = {Gianluca Rizzo and Noelia Pérez Palma and Marco Ajmone Marsan and Vincenzo Mancuso},
  doi          = {10.1109/TMC.2021.3057259},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3773-3788},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Storage capacity of opportunistic information dissemination systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Privacy-preserving streaming truth discovery in
crowdsourcing with differential privacy. <em>TMC</em>, <em>21</em>(10),
3757–3772. (<a href="https://doi.org/10.1109/TMC.2021.3062775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP) has gained popularity in truth discovery recently due to its strong privacy guarantee. However, existing DP mechanisms for streaming data publication are not suitable for truth discovery as they fail to consider the different reliabilities of individuals, while the DP-based approaches for truth discovery are not suitable for streaming data because they ignore the correlations between truths over time. Directly applying these existing methods to streaming crowdsourced data would lead to low accuracy of the discovered truth. To solve this problem, in this paper, we propose an edge computing based privacy-preserving truth discovery mechanism, named PrivSTD, for streaming crowdsourced data to realize high accuracy of discovered truth while protecting the privacy of workers. Specifically, edge servers are introduced between the untrusted cloud server and workers to securely calculate the local truths and workers’ reliabilities. A truth-dependent budget recycle mechanism is proposed for each edge server to adaptively determine the perturbed timestamp and allocate the privacy budget according to the changing pattern of local truths. Besides, a reliability-based perturbation mechanism is proposed to reduce the perturbation magnitude on the basis of worker&#39;s reliability. We theoretical analyze the data utility and computation cost of PrivSTD, and prove that PrivSTD can satisfy &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$w$&lt;/tex-math&gt;&lt;/inline-formula&gt; -event ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\epsilon,\delta$&lt;/tex-math&gt;&lt;/inline-formula&gt; )-differential privacy. Extensive experimental results on synthetic and real-world datasets demonstrate that PrivSTD achieves better utility than the state-of-the-art approaches.},
  archive      = {J_TMC},
  author       = {Dan Wang and Ju Ren and Zhibo Wang and Xiaoyi Pang and Yaoxue Zhang and Xuemin Shen},
  doi          = {10.1109/TMC.2021.3062775},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3757-3772},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy-preserving streaming truth discovery in crowdsourcing with differential privacy},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing energy consumption of mobile games. <em>TMC</em>,
<em>21</em>(10), 3744–3756. (<a
href="https://doi.org/10.1109/TMC.2021.3058381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Games are energy-intensive applications on mobile devices. Optimizing the energy efficiency of games is hence critical for battery-limited mobile devices. Although the advent of energy-aware scheduling (EAS) integrated in recent devices has provided opportunities for improved energy management, the framework is not specifically tuned for game applications. In this paper, we aim to improve the energy efficiency of game applications running on EAS-enabled mobile devices. To this end, we first analyze the functional characteristics of games, and investigate the source of the energy inefficiency. We then propose a scheme, called System-level Energy-optimization for Game Applications (SEGA), to improve the energy efficiency of games. SEGA governs CPU and GPU power consumption in a tightly coupled manner by employing three key techniques: (1) Lsync-aware GPU DVFS governor, (2) adaptive capacity clamping, and (3) on-demand touch boosting. We implemented SEGA on the latest Android-based smartphones. The evaluation results for 23 popular games showed that SEGA reduced the energy consumption of the Google Pixel 2 XL and Samsung Galaxy S9 Plus smartphones, at the device level, by 6.1–22.3 and 4.0–11.7 percent, respectively, with a quality of service (QoS) degradation of 1.1 and 0.5 percent, on average.},
  archive      = {J_TMC},
  author       = {Yonghun Choi and Seonghoon Park and Seunghyeok Jeon and Rhan Ha and Hojung Cha},
  doi          = {10.1109/TMC.2021.3058381},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3744-3756},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing energy consumption of mobile games},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-line-of-sight localization of passive UHF RFID tags in
smart storage systems. <em>TMC</em>, <em>21</em>(10), 3731–3743. (<a
href="https://doi.org/10.1109/TMC.2021.3058952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The UHF radio-frequency identification (RFID) has gained growing attention for tagged object localization in smart storage systems. Due to Non-Line-Of-Sight (NLOS) condition, it is challenging to accurately locate the position of tags inside closed spaces. In this paper, we propose a precise and cost-effective solution for tagged object localization in closed spaces, using only received signal strength (RSS) information. We establish a RSS profile for each tag and discover some important features of RSS profiles including uniqueness, time-variation, column-dependence and waveform-similarity. Based on these features, we propose a reference-free RSS-profile (RFRP) localization scheme. The advantage of our propose scheme is to accurately localize multiple tags in closed spaces by overcoming the challenges including the lack of pre-deployed reference tags, NLOS propagation, multi-path propagation and coupling effect. The RFRP scheme first roughly estimates tags’ coordinates based on Peak Asymmetry Factor, then acquires reference-tag substitutes through the similarity of RSS sequences. Subsequently, our scheme refines the relative positions of all tags by these substitutes. Finally all tags’ absolute positions are estimated through a RSS-ranging model. Extensive experiment results demonstrate that our approach can achieve high ordering accuracy and localization accuracy for the tags inside closed spaces.},
  archive      = {J_TMC},
  author       = {Linqing Gui and Shuwen Xu and Fu Xiao and Feng Shu and Shui Yu},
  doi          = {10.1109/TMC.2021.3058952},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3731-3743},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Non-line-of-sight localization of passive UHF RFID tags in smart storage systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent deep reinforcement learning multiple access for
heterogeneous wireless networks with imperfect channels. <em>TMC</em>,
<em>21</em>(10), 3718–3730. (<a
href="https://doi.org/10.1109/TMC.2021.3057826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a futuristic spectrum sharing paradigm for heterogeneous wireless networks with imperfect channels. In the heterogeneous networks, multiple wireless networks adopt different medium access control (MAC) protocols to share a common wireless spectrum and each network is unaware of the MACs of others. This paper aims to design a distributed deep reinforcement learning (DRL) based MAC protocol for a particular network, and the objective of this network is to achieve a global &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\alpha$&lt;/tex-math&gt;&lt;/inline-formula&gt; -fairness objective. In the conventional DRL framework, feedback/reward given to the agent is always correctly received, so that the agent can optimize its strategy based on the received reward. In our wireless application where the channels are noisy, the feedback/reward (i.e., the ACK packet) may be lost due to channel noise and interference. Without correct feedback, the agent (i.e., the network user) may fail to find a good solution. Moreover, in the distributed protocol, each agent makes decisions on its own. It is a challenge to guarantee that the multiple agents will make coherent decisions and work together to achieve the same objective, particularly in the face of imperfect feedback channels. To tackle the challenge, we put forth (i) a feedback recovery mechanism to recover missing feedback information, and (ii) a two-stage action selection mechanism to aid coherent decision making to reduce transmission collisions among the agents. Extensive simulation results demonstrate the effectiveness of these two mechanisms. Last but not least, we believe that the feedback recovery mechanism and the two-stage action selection mechanism can also be used in general distributed multi-agent reinforcement learning problems in which feedback information on rewards can be corrupted.},
  archive      = {J_TMC},
  author       = {Yiding Yu and Soung Chang Liew and Taotao Wang},
  doi          = {10.1109/TMC.2021.3057826},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3718-3730},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-agent deep reinforcement learning multiple access for heterogeneous wireless networks with imperfect channels},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent coordinated close-in jamming for disabling a
rogue drone. <em>TMC</em>, <em>21</em>(10), 3700–3717. (<a
href="https://doi.org/10.1109/TMC.2021.3062225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones, including remotely piloted aircraft or unmanned aerial vehicles, have become extremely appealing over the recent years, with a multitude of applications and usages. However, they can potentially present major threats for security and public safety, especially when they fly across critical infrastructures and public spaces. This work investigates a novel counter-drone solution by proposing a multi-agent framework in which a team of pursuer drones cooperate in order to track and jam a rogue drone. Within the proposed framework, a joint mobility and power control solution is developed to optimize the respective decisions of each cooperating agent in order to best track and intercept the moving rogue drone. Both centralized and distributed variants of the joint optimization problem are developed and extensive simulations are conducted to evaluate the performance of the problem variants and to demonstrate the effectiveness of the proposed solution.},
  archive      = {J_TMC},
  author       = {Panayiota Valianti and Savvas Papaioannou and Panayiotis Kolios and Georgios Ellinas},
  doi          = {10.1109/TMC.2021.3062225},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3700-3717},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-agent coordinated close-in jamming for disabling a rogue drone},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring roaming in europe: Infrastructure and implications
on users’ QoE. <em>TMC</em>, <em>21</em>(10), 3687–3699. (<a
href="https://doi.org/10.1109/TMC.2021.3058787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Roam like Home” is the initiative of the European Commission (EC) to end the levy of extra charges when roaming within the European region. As a result, people can use data services more freely across Europe. However, the implications of roaming solutions on network performance have not been carefully examined yet. This paper provides an in-depth characterization of the implications of international data roaming within Europe. We build a unique roaming measurement platform using 16 different mobile networks deployed in six countries across Europe. Using this platform, we measure different aspects of international roaming in 4G networks in Europe, including mobile network configuration, performance characteristics, and quality of experience. We find that operators adopt a common approach to implement roaming called Home-routed roaming (HR). This results in additional latency penalties of 60 ms or more, depending on geographical distance. This leads to worse browsing performance, with an increase in the metrics related to Quality of Experience (QoE) of users (Page Load time and Speed Index) in the order of 15-20 percent. We further analyze in isolation the impact of latency on QoE metrics and find that the penalty imposed by HR leads to a degradation on QoE metrics up to 150 percent in case of intercontinental roaming.},
  archive      = {J_TMC},
  author       = {Anna Maria Mandalari and Andra Lutu and Ana Custura and Ali Safari Khatouni and Özgü Alay and Marcelo Bagnulo and Vaibhav Bajpai and Anna Brunstrom and Jörg Ott and Martino Trevisan and Marco Mellia and Gorry Fairhurst},
  doi          = {10.1109/TMC.2021.3058787},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3687-3699},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Measuring roaming in europe: Infrastructure and implications on users’ QoE},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MDLdroidLite: A release-and-inhibit control approach to
resource-efficient deep neural networks on mobile devices. <em>TMC</em>,
<em>21</em>(10), 3670–3686. (<a
href="https://doi.org/10.1109/TMC.2021.3062575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile deep learning (MDL) has emerged as a privacy-preserving learning paradigm for mobile devices. This paradigm offers unique features such as privacy preservation, continual learning and low-latency inference to the building of personal mobile sensing applications. However, squeezing Deep Learning to mobile devices is extremely challenging due to resource constraint. Traditional Deep Neural Networks (DNNs) are usually over-parametered, hence incurring huge resource overhead for on-device learning. In this paper, we present a novel on-device deep learning framework named MDLdroidLite that transforms traditional DNNs into resource-efficient model structures for on-device learning. To minimize resource overhead, we propose a novel release-and-inhibit control (RIC) approach based on Model Predictive Control theory to efficiently grow DNNs from tiny to backbone. We also design a gate-based fast adaptation mechanism for channel-level knowledge transformation to quickly adapt new-born neurons with existing neurons, enabling safe parameter adaptation and fast convergence for on-device training. Our evaluations show that MDLdroidLite boosts on-device training on various PMS datasets with 28× to 50× less model parameters, 4× to 10× less floating number operations than the state-of-the-art model structures while keeping the same accuracy level.},
  archive      = {J_TMC},
  author       = {Yu Zhang and Tao Gu and Xi Zhang},
  doi          = {10.1109/TMC.2021.3062575},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3670-3686},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MDLdroidLite: A release-and-inhibit control approach to resource-efficient deep neural networks on mobile devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint resource dimensioning and placement for dependable
virtualized services in mobile edge clouds. <em>TMC</em>,
<em>21</em>(10), 3656–3669. (<a
href="https://doi.org/10.1109/TMC.2021.3060118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is an emerging architecture for accommodating latency sensitive virtualized services (VSs). Many of these VSs are expected to be safety critical, and will have some form of reliability requirements. In order to support provisioning reliability to such VSs in MEC in an efficient and confidentiality preserving manner, in this paper we consider the joint resource dimensioning and placement problem for VSs with diverse reliability requirements, with the objective of minimizing the energy consumption. We formulate the problem as an integer programming problem, and prove that it is NP-hard. We propose a two-step approximation algorithm with bounded approximation ratio based on Lagrangian relaxation. We benchmark our algorithm against two greedy algorithms in realistic scenarios. The results show that the proposed solution is computationally efficient, scalable and can provide up to 30 percent reduction in energy consumption compared to greedy algorithms.},
  archive      = {J_TMC},
  author       = {Peiyue Zhao and György Dán},
  doi          = {10.1109/TMC.2021.3060118},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3656-3669},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint resource dimensioning and placement for dependable virtualized services in mobile edge clouds},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IMag+: An accurate and rapidly deployable inertial
magneto-inductive SLAM system. <em>TMC</em>, <em>21</em>(10), 3644–3655.
(<a href="https://doi.org/10.1109/TMC.2021.3062813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localisation is an important part of many applications. Our motivating scenarios are short-term construction work and emergency rescue. These scenarios also require rapid setup and robustness to environmental conditions additional to localisation accuracy. These requirements preclude the use of many traditional high-performance methods, e.g., vision-based, laser-based, Ultra-wide band (UWB) and Global Positioning System (GPS)-based localisation systems. To overcome these challenges, we introduce iMag+ , an accurate and rapidly deployable inertial magneto-inductive (MI) mapping and localisation system, which only requires monitored workers to carry a single MI transmitter and an inertial measurement unit in order to localise themselves with minimal setup effort. However, one major challenge is to use distorted and ambiguous MI location estimates for localisation. To solve this challenge, we propose a novel method to use MI devices for sensing environmental distortions for accurate closing inertial loops. We also suggest a robust and efficient first quadrant estimator to sanitise the ambiguous MI estimates. By applying robust simultaneous localisation and mapping (SLAM), our proposed localisation method achieves excellent tracking accuracy and can improve performance significantly compared with only using a Magneto-inductive device or inertial measurement unit (IMU) for localisation.},
  archive      = {J_TMC},
  author       = {Bo Wei and Niki Trigoni and Andrew Markham},
  doi          = {10.1109/TMC.2021.3062813},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3644-3655},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {IMag+: An accurate and rapidly deployable inertial magneto-inductive SLAM system},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fingerprinting movements of industrial robots for replay
attack detection. <em>TMC</em>, <em>21</em>(10), 3629–3643. (<a
href="https://doi.org/10.1109/TMC.2021.3059796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial robots are prototypical cyber-physical systems widely deployed in (smart) manufacturing, which operate according to the operation code uploaded by the human operator and are monitored in real-time based on their movement data. However, industrial robots suffer from replay attacks, via which attackers can manipulate the robot operation without being observed by the monitoring system. To mitigate this vulnerability, we design a novel intrusion detection system for industrial robots using their power fingerprint, called PIDS ( P ower-based I ntrusion D etection S ystem), and deliver PIDS as a bump-in-the-wire module installed at the powerline of commodity robots. The foundation of PIDS is the physically-induced dependency between the robot movement and the concomitant power consumption, which PIDS captures via joint physical analysis and (cyber) data-driven modeling. PIDS then fingerprints the robot movements observed by the monitoring system using their expected power consumption, and cross-validates the fingerprints with empirically collected power information — a mismatch thereof flags anomalies of the observed movements (i.e., evidence of replay attack). We have evaluated PIDS using three models of robots from different vendors — i.e., ABB IRB120, KUKA KR6 R700, and Universal Robots UR5 robots — with over 2,000 operation cycles. Experimental results show that PIDS detects replay attacks at an average rate of 96.5 percent (up to 99.9 percent) and a 0.1s latency.},
  archive      = {J_TMC},
  author       = {Hongyi Pu and Liang He and Chengcheng Zhao and David K. Y. Yau and Peng Cheng and Jiming Chen},
  doi          = {10.1109/TMC.2021.3059796},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3629-3643},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fingerprinting movements of industrial robots for replay attack detection},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FedPacket: A federated learning approach to mobile packet
classification. <em>TMC</em>, <em>21</em>(10), 3609–3628. (<a
href="https://doi.org/10.1109/TMC.2021.3058627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve mobile data transparency, various approaches have been proposed to inspect network traffic generated by mobile devices and detect exposure of personally identifiable information (PII), ad requests, etc. State-of-the-art approaches use features extracted from HTTP packets and train classifiers in a centralized way: users collect and label network packets on their mobile devices, then upload data to a central server; the server uses the data contributed by all users to train a packet classifier. However, training datasets from network traffic collected on user devices may contain sensitive information that users may not want to upload. In this article, we propose a federated learning approach to mobile packet classification, which enables devices to collaboratively train a global model, without uploading the training data collected on devices. We apply our framework to two packet classification tasks (i.e., to predict PII exposure or ad requests in individual packets) and we demonstrate its effectiveness in terms of classification performance, communication and computation cost, using three real-world datasets. Methodological challenges we address in the process include model and feature selection, as well as tuning the federated learning parameters specifically for our packet classification tasks. We also discuss privacy limitations and mitigation approaches.},
  archive      = {J_TMC},
  author       = {Evita Bakopoulou and Bálint Tillman and Athina Markopoulou},
  doi          = {10.1109/TMC.2021.3058627},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3609-3628},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FedPacket: A federated learning approach to mobile packet classification},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation of congestion from cellular walled gardens using
passive measurements. <em>TMC</em>, <em>21</em>(10), 3595–3608. (<a
href="https://doi.org/10.1109/TMC.2021.3060006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite widespread LTE deployment, coverage does not necessarily translate to usable service. Even in well-provisioned urban networks, unusually high usage (such as during a public event or after a natural disaster) can lead to congestion that makes the LTE service difficult, if not impossible, to use, even if the user is solidly within the coverage area. A typical approach to detect and quantify congestion on LTE networks is to secure the cooperation of the network provider for access to internal metrics. An alternative approach is to deploy multiple mobile devices with active subscriptions to each network operator. Both approaches are resource and time intensive. In this work, we propose a novel method to estimate congestion from overloaded LTE networks using only passive measurements, and without requiring provider cooperation. We analyze packet-level traces for four commercial LTE service providers, from several locations during both typical levels of usage and during public events that yield large, dense crowds. This study presents the first look at congestion detection through overload estimation by examining unencrypted broadcast messages. We show that an upsurge in broadcast reject and cell barring messages, leading to overload, can accurately detect an increase in network congestion.},
  archive      = {J_TMC},
  author       = {Vivek Adarsh and Michael Nekrasov and Udit Paul and Elizabeth Belding},
  doi          = {10.1109/TMC.2021.3060006},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3595-3608},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Estimation of congestion from cellular walled gardens using passive measurements},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling secret key distribution over screen-to-camera
channel leveraging color shift property. <em>TMC</em>, <em>21</em>(10),
3581–3594. (<a href="https://doi.org/10.1109/TMC.2021.3059349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years witnessed the emergence of visible light communication (VLC) over screen-to-camera channel, such as barcode and unobtrusive optical pattern, due to the widely adoption of screen and camera in plenty of electronic devices. The prevalence of wide viewing angle screen and high standard cameras also imposes great threat for visible light communication, and the information leakage over screen-to-camera channel has been rarely explored. In this paper, we propose a secret key distribution system leveraging the unique color shift property over screen-to-camera channel. To facilitate such design, two practical secret key distribution methods, key matching-based and nearest next hop-based, are developed to map the secret key into a unique optical pattern on screen, which can only be correctly decoded by the legitimate user situated at an accessible region. We also provide theoretical analysis on the security of both methods. The performance of the proposed system is implemented with off-the-shelf devices and validated under various experimental scenarios. The results demonstrate that our system can achieve high bit-decoding accuracy for the legitimate users while maintaining low recovery accuracy for the attackers.},
  archive      = {J_TMC},
  author       = {Hongbo Liu and Cong Shi and Yingying Chen},
  doi          = {10.1109/TMC.2021.3059349},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3581-3594},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling secret key distribution over screen-to-camera channel leveraging color shift property},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling finger-touch-based mobile user authentication via
physical vibrations on IoT devices. <em>TMC</em>, <em>21</em>(10),
3565–3580. (<a href="https://doi.org/10.1109/TMC.2021.3057083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work enables mobile user authentication via finger inputs on ubiquitous surfaces leveraging low-cost physical vibration. The system we proposed extends finger-input authentication beyond touch screens to any solid surface for IoT devices (e.g., smart access systems and IoT appliances). Unlike passcode or biometrics-based solutions, it integrates passcode, behavioral and physiological characteristics, and surface dependency together to provide a low-cost, tangible and enhanced security solution. The proposed system builds upon a touch sensing technique with vibration signals that can operate on surfaces constructed from a broad range of materials. New algorithms are developed to discriminate fine-grained finger inputs and supports three independent passcode secrets including PIN number, lock pattern, and simple gestures by extracting unique features in the frequency domain to capture both behavioral and physiological characteristics including contacting area, touching force, and etc. The system is implemented using a single pair of low-cost portable vibration motor and receiver that can be easily attached to any surface (e.g., a door panel, a stovetop or an appliance). Extensive experiments demonstrate that our system can authenticate users with high accuracy (e.g., more than 97 percent within two trials), low false positive rate (e.g., less 2 percent) and is robust to various types of attacks.},
  archive      = {J_TMC},
  author       = {Xin Yang and Song Yang and Jian Liu and Chen Wang and Yingying Chen and Nitesh Saxena},
  doi          = {10.1109/TMC.2021.3057083},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3565-3580},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling finger-touch-based mobile user authentication via physical vibrations on IoT devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Eliciting information from heterogeneous mobile crowdsourced
workers without verification. <em>TMC</em>, <em>21</em>(10), 3551–3564.
(<a href="https://doi.org/10.1109/TMC.2021.3062425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile crowdsourcing, platforms seek to incentivize heterogeneous workers to complete tasks (e.g., road traffic sensing) and truthfully report their solutions. When platforms cannot verify the quality of the workers’ solutions, the crowdsourcing problem is known as information elicitation without verification (IEWV). In an IEWV problem, a platform needs to provide incentives to motivate high-quality solutions and truthful reporting of the solutions from the workers. A common approach to solve the IEWV problem is majority voting, where each worker is rewarded according to whether his solution matches the majority’s solution. However, previous work has not considered workers with heterogeneous solution accuracy. This is unrealistic in many domains, where one would expect workers to differ in judgment, expertise, and reliability. Moreover, prior work has not considered how this heterogeneity affects a platform’s tradeoff between the quality of the workers’ solutions and the platform’s cost of achieving this. We address these gaps by studying the interactions between the mobile crowdsourcing platform and workers as a two-stage Stackelberg game. In Stage I, the platform chooses the reward level for majority voting. In Stage II, the workers decide their effort levels and reporting strategies. We show that as a worker’s solution accuracy increases, he is more likely, in equilibrium, to exert effort and truthfully report his solution. However, given a fixed total worker population, surprisingly, the platform’s payoff may decrease in the number of high-accuracy workers. We further characterize the value of knowing the workers’ solution accuracy in terms of improving the platform’s optimal reward design and maximizing its payoff. Knowing such information enables a more effective aggregation of the workers’ solutions. We further design a discriminatory reward policy to incentivize heterogeneous workers. Surprisingly, such a discriminatory policy can improve both the platform’s and the workers’ payoffs, and hence improve the social welfare.},
  archive      = {J_TMC},
  author       = {Chao Huang and Haoran Yu and Jianwei Huang and Randall A. Berry},
  doi          = {10.1109/TMC.2021.3062425},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3551-3564},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Eliciting information from heterogeneous mobile crowdsourced workers without verification},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning based dynamic trajectory control
for UAV-assisted mobile edge computing. <em>TMC</em>, <em>21</em>(10),
3536–3550. (<a href="https://doi.org/10.1109/TMC.2021.3059691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a platform of flying mobile edge computing (F-MEC), where unmanned aerial vehicles (UAVs) serve as equipment providing computation resource, and they enable task offloading from user equipment (UE). We aim to minimize energy consumption of all UEs via optimizing user association, resource allocation and the trajectory of UAVs. To this end, we first propose a Convex optimizAtion based Trajectory control algorithm (CAT), which solves the problem in an iterative way by using block coordinate descent (BCD) method. Then, to make the real-time decision while taking into account the dynamics of the environment (i.e., UAV may take off from different locations), we propose a deep Reinforcement leArning based trajectory control algorithm (RAT). In RAT, we apply the Prioritized Experience Replay (PER) to improve the convergence of the training procedure. Different from the convex optimization based algorithm which may be susceptible to the initial points and requires iterations, RAT can be adapted to any taking off points of the UAVs and can obtain the solution more rapidly than CAT once training process has been completed. Simulation results show that the proposed CAT and RAT achieve the considerable performance and both outperform traditional algorithms.},
  archive      = {J_TMC},
  author       = {Liang Wang and Kezhi Wang and Cunhua Pan and Wei Xu and Nauman Aslam and Arumugam Nallanathan},
  doi          = {10.1109/TMC.2021.3059691},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3536-3550},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deep reinforcement learning based dynamic trajectory control for UAV-assisted mobile edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cooperative service placement and scheduling in edge clouds:
A deadline-driven approach. <em>TMC</em>, <em>21</em>(10), 3519–3535.
(<a href="https://doi.org/10.1109/TMC.2021.3061602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing enables resource-limited edge clouds (ECs) in federation to help each other with resource-hungry yet delay-sensitive service requests. Contrary to common practice, we acknowledge that mobile services are heterogeneous and the limited storage resources of ECs allow only a subset of services to be placed at the same time. This paper presents a jointly optimized design of cooperative placement and scheduling framework, named JCPS, that pursues social cost minimization over time while ensuring diverse user demands. Our main contribution is a novel perspective on cost reduction by exploiting the spatial-temporal diversities in workload and resource cost among federated ECs. To build a practical edge cloud federation system, we have to consider two major challenges: user deadline preference and ECs’ strategic behaviors . We first formulate and solve the problem of spatially strategic optimization without deadline awareness, which is proved &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {NP}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -hard. By leveraging user deadline tolerance, we develop a Lyapunov-based deadline-driven joint cooperative mechanism under the scenario where the workload and resource information of ECs are known for one-shot global cost minimization. The service priority imposed by deadline urgency drives time-critical placement and scheduling, which, combined with cooperative control, enables workloads migrated across different times and ECs. Given selfishness of individual ECs, we further design an auction-based cooperative mechanism to elicit truthful bids on workload and resource cost. Rigorous theoretical analysis and extensive simulations are performed, validating the efficiency of JCPS in realizing cost reduction and user satisfaction.},
  archive      = {J_TMC},
  author       = {Yuqing Li and Wenkuan Dai and Xiaoying Gan and Haiming Jin and Luoyi Fu and Huadong Ma and Xinbing Wang},
  doi          = {10.1109/TMC.2021.3061602},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3519-3535},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cooperative service placement and scheduling in edge clouds: A deadline-driven approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CMAB-based reverse auction for unknown worker recruitment in
mobile crowdsensing. <em>TMC</em>, <em>21</em>(10), 3502–3518. (<a
href="https://doi.org/10.1109/TMC.2021.3059346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile CrowdSensing (MCS), through which a requester can coordinate a crowd of workers to accomplish some data collection tasks, has been recognized as a promising paradigm for large-scale data acquisition in recent years. Many researches focus on the worker recruitment problem in MCS, but most of them either have the assumption that workers’ qualities are known ahead of time or cannot ensure that workers report costs honestly. In this paper, we propose an incentive mechanism based on Combinatorial Multi-Armed Bandit and reverse Auction, called CMABA, to solve the multiple unknown workers recruitment problem in MCS. Our objective is to determine a recruiting strategy to maximize the total sensing quality under a limited budget, while ensuring truthfulness and individual rationality of sensing workers. We theoretically prove that our CMABA mechanism achieves truthfulness and individual rationality, and then analyze the regret of the mechanism. Based on CMABA, we ulteriorly propose an adaptive incentive mechanism, called ACMABA, to recruit workers via the alternative worker recruitment and quality update, which can achieve a higher total sensing quality and lower regret. Additionally, we also demonstrate significant performances of the CMABA and ACMABA mechanisms through extensive simulations on real-world data traces.},
  archive      = {J_TMC},
  author       = {Mingjun Xiao and Baoyi An and Jing Wang and Guoju Gao and Sheng Zhang and Jie Wu},
  doi          = {10.1109/TMC.2021.3059346},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3502-3518},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CMAB-based reverse auction for unknown worker recruitment in mobile crowdsensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An agile and distributed mechanism for inter-domain network
slicing in next generation mobile networks. <em>TMC</em>,
<em>21</em>(10), 3486–3501. (<a
href="https://doi.org/10.1109/TMC.2021.3061613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing is emerging as a promising method to provide sought after versatility and flexibility to cope with ever-increasing demands. To realize such potential advantages and to meet the challenging requirements of various network slices in an on-demand fashion, we need to develop an agile and distributed mechanism for resource provisioning to different network slices in a heterogeneous multi-resource multi-domain mobile network environment. We formulate inter-domain resource provisioning to network slices in such an environment as an optimization problem which maximizes social welfare among network slice tenants (so that maximizing tenants’ satisfaction), while minimizing operational expenditures for infrastructure service providers at the same time. To solve the envisioned problem, we implement an iterative auction game among network slice tenants, on one hand, and a plurality of price-taking subnet service providers, on the other hand. We show that the proposed solution method results in a distributed privacy-saving mechanism which converges to the optimal solution of the described optimization problem. In addition to providing analytical results to characterize the performance of the proposed mechanism, we also employ numerical evaluations to validate the results, demonstrate convergence of the presented algorithm, and show the enhanced performance of the proposed approach (in terms of resource utilization, fairness and operational costs) against the existing solutions.},
  archive      = {J_TMC},
  author       = {Jalal Khamse-Ashari and Gamini Senarath and Irem Bor-Yaliniz and Halim Yanikomeroglu},
  doi          = {10.1109/TMC.2021.3061613},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3486-3501},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An agile and distributed mechanism for inter-domain network slicing in next generation mobile networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adapting to unknown conditions in learning-based mobile
sensing. <em>TMC</em>, <em>21</em>(10), 3470–3485. (<a
href="https://doi.org/10.1109/TMC.2021.3061130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many applications utilize sensors on mobile devices and apply deep learning for diverse applications. However, they have rarely enjoyed mainstream adoption due to many different individual conditions users encounter. Individual conditions are characterized by users’ unique behaviors and different devices they carry, which collectively make sensor inputs different. It is impractical to train countless individual conditions beforehand and we thus argue meta-learning is a great approach in solving this problem. We present MetaSense that leverages “seen” conditions in training data to adapt to an “unseen” condition (i.e., the target user). Specifically, we design a meta-learning framework that learns “how to adapt” to the target via iterative training sessions of adaptation. MetaSense requires very few training examples from the target (e.g., one or two) and thus requires minimal user effort. In addition, we propose a similar condition detector (SCD) that identifies when the unseen condition has similar characteristics to seen conditions and leverages this hint to further improve the accuracy. Our evaluation with 10 different datasets shows that MetaSense improves the accuracy of state-of-the-art transfer learning and meta learning methods by 15 and 11 percent, respectively. Furthermore, our SCD achieves additional accuracy improvement (e.g., 15 percent for human activity recognition).},
  archive      = {J_TMC},
  author       = {Taesik Gong and Yeonsu Kim and Ryuhaerang Choi and Jinwoo Shin and Sung-Ju Lee},
  doi          = {10.1109/TMC.2021.3061130},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3470-3485},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adapting to unknown conditions in learning-based mobile sensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A truthful auction for graph job allocation in vehicular
cloud-assisted networks. <em>TMC</em>, <em>21</em>(10), 3455–3469. (<a
href="https://doi.org/10.1109/TMC.2021.3059803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular cloud computing has been emerged as a promising solution to fulfill users’ demands on processing computation-intensive applications in modern driving environments. Such applications are commonly represented by graphs consisting of components and edges. However, encouraging vehicles to share resources poses significant challenges owing to users’ selfishness. In this paper, an auction-based graph job allocation problem is studied in vehicular cloud-assisted networks considering resource reutilization. Our goal is to map each buyer (component) to a feasible seller (virtual machine) while maximizing the buyers’ utility-of-service, which concerns the execution time and commission cost. First, we formulate the auction-based graph job allocation as a 0-1 integer programming (0-1 IP) problem. Then, a Vickrey-Clarke-Groves based payment rule is proposed which satisfies the desired economical properties, truthfulness and individual rationality. We face two challenges: 1) the abovementioned 0-1 IP problem is NP-hard; 2) one constraint associated with the IP problem poses addressing the subgraph isomorphism problem. Thus, obtaining the optimal solution is practically infeasible in large-scale networks. Motivated by which, we develop a structure-preserved matching algorithm by maximizing the utility-of-service-gain, and the corresponding payment rule which offers economical properties and low computation complexity. Extensive simulations demonstrate that the proposed algorithm outperforms the contrast methods considering various problem sizes.},
  archive      = {J_TMC},
  author       = {Zhibin Gao and Minghui Liwang and Seyyedali Hosseinalipour and Huaiyu Dai and Xianbin Wang},
  doi          = {10.1109/TMC.2021.3059803},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3455-3469},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A truthful auction for graph job allocation in vehicular cloud-assisted networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A one-page text entry method optimized for rectangle
smartwatches. <em>TMC</em>, <em>21</em>(10), 3443–3454. (<a
href="https://doi.org/10.1109/TMC.2021.3057226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide the design and implementation of UOIT, a text entry method optimized for smartwatches. UOIT uses only one page where a user can see and tap directly for entry without any additional actions, such as zoom-in/zoom-out and swipes, which are required in the existing entry methods. To fully utilize the constrained screen space and to address the “fat finger” problem, we use a technique called “drawing-like typing”, which reduces the 26 small alphabetic keys into 13 large keys with a dual input property. To evaluate the performance of UOIT, we conducted two user studies while varying the learning period. In the short-term experiments (i.e., two days), we observed a fast learning curve of users when using the UOIT keyboard. Moreover, with the long-term experiments (i.e., a month), we show that users can type as fast as QWERTY keyboard but with much less errors. Moreover, UOIT outperforms the state-of-the-art keyboard in both speed and error rate.},
  archive      = {J_TMC},
  author       = {Rhongho Jang and Changhun Jung and David Mohaisen and Kyunghee Lee and DaeHun Nyang},
  doi          = {10.1109/TMC.2021.3057226},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3443-3454},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A one-page text entry method optimized for rectangle smartwatches},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A hybrid control scheme for 360-degree dynamic adaptive
video streaming over mobile devices. <em>TMC</em>, <em>21</em>(10),
3428–3442. (<a href="https://doi.org/10.1109/TMC.2021.3058099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A 360-degree streaming system can provide immersive, interactive, and autonomous experiences surrounding the user by means of viewpoint changes to see different angles of a 360-degree video. However, due to the limited capacity and highly dynamic conditions of cellular networks, high-resolution 360-degree video playback over mobile devices often suffers from playback freezing, and bandwidth waste is inevitably incurred in delivering out-of-view video data. In this paper, a hybrid control scheme is presented for segment-level continuous bitrate selection and tile-level bitrate allocation for 360-degree streaming over mobile devices to increase users’ quality of experience. First, a deep reinforcement learning (RL) method is proposed to predict the segment bitrate and avoid playback freezing. Second, a viewpoint-prediction-map-based cooperative bargaining game theory is proposed for bitrate allocation optimization to choose a suitable bitrate for each tile to reduce unreasonable bandwidth waste. The proposed scheme is compared with state-of-the-art approaches under a wide variety of mobile network conditions with multiple viewpoint traces and 360-degree video contents. The experimental results indicate that the proposed method outperforms the compared state-of-the-art approaches in terms of various experimental objectives on mobile devices.},
  archive      = {J_TMC},
  author       = {Xuekai Wei and Mingliang Zhou and Sam Kwong and Hui Yuan and Weijia Jia},
  doi          = {10.1109/TMC.2021.3058099},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {10},
  number       = {10},
  pages        = {3428-3442},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A hybrid control scheme for 360-degree dynamic adaptive video streaming over mobile devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Wi-PIGR: Path independent gait recognition with commodity
wi-fi. <em>TMC</em>, <em>21</em>(9), 3414–3427. (<a
href="https://doi.org/10.1109/TMC.2021.3052314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi based gait recognition has many potential applications. However, the gait information derived from Wi-Fi changes with the walking path. This makes the human identification through gait really challenging, the existing Wi-Fi based gait recognition systems require the subject walking along a predetermined path. This path dependence restriction impedes Wi-Fi based gait recognition from being widely used. In this paper, a path independent gait recognition system for a single subject, Wi-PIGR, is proposed. In Wi-PIGR, the subject is identified through the gait regardless of the walking path. Specifically, an extra receiver is introduced to get CSI data in orthogonal directions. A series of signal processing techniques are proposed to eliminate the differences among signals introduced by walking along the arbitrary paths and generate a high quality path independent signal spectrogram. Furthermore, a deep learning approach is integrated into the feature extraction. The experiment results in typical indoor environment demonstrate the superior performance of Wi-PIGR, with the average recognition accuracy of 77.15 percent, when the number of subjects is 50.},
  archive      = {J_TMC},
  author       = {Lei Zhang and Cong Wang and Daqing Zhang},
  doi          = {10.1109/TMC.2021.3052314},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3414-3427},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Wi-PIGR: Path independent gait recognition with commodity wi-fi},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UW-SEEDEX: A pseudorandom-based MAC protocol for underwater
acoustic networks. <em>TMC</em>, <em>21</em>(9), 3402–3413. (<a
href="https://doi.org/10.1109/TMC.2021.3052754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater wireless acoustic networks (UWANs) take advantage of acoustic communication to enable many distinct applications. The peculiar features of underwater acoustic channels, such as long propagation delay, high bit error rates, and severely limited bandwidth, make the use of medium access control (MAC) solutions designed for terrestrial radio networks inefficient in UWANs. This paper proposes UW-SEEDEX, a MAC protocol for UWANs that employs random time slot schedules, created from seeds, to avoid collisions. After exchanging seeds, nodes can know other’s entire schedules, allowing them to then better plan their transmissions. Simulations evaluate how each of UW-SEEDEX’s parameter affects its performance in metrics such as end-to-end delay, energy consumption, transmissions per data reception, and reception rate using different test scenarios. Simulations also show that UW-SEEDEX can perform better than other MAC solutions, delivering more messages than protocols such as UW-Aloha and Slotted FAMA and reduced, on average, up to three times the number of transmissions required for each message reception in networks with grid topologies. UW-SEEDEX presented reception rates close to 100 percent, low energy cost, and fewer transmissions per data reception. Our code is available at https://gitlab.com/epmcj/ns-3-dev/-/tree/new-uan-mac-protocols .},
  archive      = {J_TMC},
  author       = {Eduardo P. M. Câmara Júnior and Luiz F. M. Vieira and Marcos A. M. Vieira},
  doi          = {10.1109/TMC.2021.3052754},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3402-3413},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {UW-SEEDEX: A pseudorandom-based MAC protocol for underwater acoustic networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User-level privacy-preserving federated learning: Analysis
and performance optimization. <em>TMC</em>, <em>21</em>(9), 3388–3401.
(<a href="https://doi.org/10.1109/TMC.2021.3056991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), as a type of collaborative machine learning framework, is capable of preserving private data from mobile terminals (MTs) while training the data into useful models. Nevertheless, from a viewpoint of information theory, it is still possible for a curious server to infer private information from the shared models uploaded by MTs. To address this problem, we first make use of the concept of local differential privacy (LDP), and propose a user-level differential privacy (UDP) algorithm by adding artificial noise to the shared models before uploading them to servers. According to our analysis, the UDP framework can realize &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(\epsilon _{i}, \delta _{i})$&lt;/tex-math&gt;&lt;/inline-formula&gt; -LDP for the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$i$&lt;/tex-math&gt;&lt;/inline-formula&gt; th MT with adjustable privacy protection levels by varying the variances of the artificial noise processes. We then derive a theoretical convergence upper-bound for the UDP algorithm. It reveals that there exists an optimal number of communication rounds to achieve the best learning performance. More importantly, we propose a communication rounds discounting (CRD) method. Compared with the heuristic search method, the proposed CRD method can achieve a much better trade-off between the computational complexity of searching and the convergence performance. Extensive experiments indicate that our UDP algorithm using the proposed CRD method can effectively improve both the training efficiency and model quality for the given privacy protection levels.},
  archive      = {J_TMC},
  author       = {Kang Wei and Jun Li and Ming Ding and Chuan Ma and Hang Su and Bo Zhang and H. Vincent Poor},
  doi          = {10.1109/TMC.2021.3056991},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3388-3401},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {User-level privacy-preserving federated learning: Analysis and performance optimization},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Timeliness-aware incentive mechanism for vehicular
crowdsourcing in smart cities. <em>TMC</em>, <em>21</em>(9), 3373–3387.
(<a href="https://doi.org/10.1109/TMC.2021.3052963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular crowdsourcing is a promising paradigm that takes advantage of powerful onboard capabilities of vehicles to perform various tasks in smart cities. To fulfill this vision, a well-designed incentive mechanism is essential to stimulate the participation of vehicles. In this paper, we propose a timeliness-aware incentive mechanism for vehicular crowdsourcing by taking vehicle’s uncertain travel time into account. In view of the stochastic nature of traffic conditions, we derive a tractable expression for the probability distribution of task delay based on a discrete-time traffic model. By leveraging reverse auction framework, we model the utility of a service requester as a function in terms of uncertain task delay and incurred payment. To maximize the requester’s utility under a budget constraint, we cast the mechanism design as a non-monotone submodular maximization problem over a knapsack constraint. Based on this formulation, we develop a t ruthful b udgeted u tility m aximization a uction (TBUMA), which is truthful, budget feasible, profitable, individually rational and computationally efficient. Through extensive trace-based simulations, we demonstrate the effectiveness of our proposed incentive mechanism.},
  archive      = {J_TMC},
  author       = {Xianhao Chen and Lan Zhang and Yawei Pang and Bin Lin and Yuguang Fang},
  doi          = {10.1109/TMC.2021.3052963},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3373-3387},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Timeliness-aware incentive mechanism for vehicular crowdsourcing in smart cities},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Theoretical broadcast rate optimization for V2V
communications at intersection. <em>TMC</em>, <em>21</em>(9), 3360–3372.
(<a href="https://doi.org/10.1109/TMC.2021.3051956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative vehicle safety (CVS) systems have been receiving significant attention as key enablers of important intelligent transportation system (ITS) applications, such as cooperative collision warning, emergency braking, and auto driving. In CVS systems, vehicles periodically broadcast short packets that include various types of vehicular information, e.g., position and speed. In this paper, we propose an optimization method for the broadcast rate in vehicle-to-vehicle (V2V) broadcast communications at an intersection based on theoretical analysis. We consider a model in which the locations of vehicles are modeled separately as queuing , and running segments and derive key performance metrics of V2V broadcast communications through a stochastic geometry approach. We develop closed-form approximate formulas for the theoretical expressions because they are mathematically intractable. Based on approximate analysis, we optimize the broadcast rate such that the interference at an intersection is mitigated and the overall performance of V2V communications is maximized. Because of the closed-form approximation, the optimal rate can be used as a guideline for a real-time control-method, which cannot be achieved through time-consuming simulations. We evaluate our method through numerical examples and demonstrate its effectiveness.},
  archive      = {J_TMC},
  author       = {Tatsuaki Kimura and Hiroshi Saito},
  doi          = {10.1109/TMC.2021.3051956},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3360-3372},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Theoretical broadcast rate optimization for V2V communications at intersection},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Structure-free general data aggregation scheduling for
multihop battery-free wireless networks. <em>TMC</em>, <em>21</em>(9),
3342–3359. (<a href="https://doi.org/10.1109/TMC.2021.3053557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advances in wireless power transfer techniques, battery-free wireless sensor networks (BF-WSNs) which can support long-term applications, has been attracting increasing interests in recent years. Unfortunately, the problem of minimum latency aggregation scheduling (MLAS) is not well studied in BF-WSNs. Existing works always have a rigid assumption that there is only one single query which is targeted at the whole network. Aiming at making the work more practical and general, we investigate the general MLAS problem in BF-WSNs, which is targeted at any subset of nodes in the network and aimed for an arbitrary number of aggregation queries. First, the general MLAS problem when there is one single query is studied. To control the number of nodes participating in the aggregation process, a node selection algorithm is proposed to cover and connect the whole target nodes. Then, a latency and energy aware scheduling algorithm is proposed to integrate the construction of aggregation tree with the chosen nodes, and the computation of a conflict-free schedule simultaneously, relying on non-predetermined structures. Second, the general MLAS problem when there is a group of aggregation queries is studied. Through designing some special structures to avoid collisions between both current and existing aggregation schedules, an algorithm without any waiting time is proposed. Additionally, the algorithm under physical interference model and dynamic energy arrival model are also presented. The theoretical analysis and simulation results verify that the proposed algorithms have high performance in terms of latency and energy efficiency.},
  archive      = {J_TMC},
  author       = {Quan Chen and Zhipeng Cai and Lianglun Cheng and Hong Gao},
  doi          = {10.1109/TMC.2021.3053557},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3342-3359},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Structure-free general data aggregation scheduling for multihop battery-free wireless networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sensory data aggregation in internet of things:
Period-driven pipeline scheduling approach. <em>TMC</em>,
<em>21</em>(9), 3326–3341. (<a
href="https://doi.org/10.1109/TMC.2021.3052803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Smart City contexts and the adoption of Industry 4.0 are being upgraded with the latest technologies throughout all systems. New data are continuously collected in huge amounts; therefore, an efficient data aggregation scheduling scheme is highly demanded. This paper addresses the minimum time aggregation scheduling problem in duty-cycled sensor networks. Existing solutions schedule the sensory data through predefined routing structures, which limit the utilization of diverse active time slots of sensors. We propose a period-driven pipeline scheduling approach, namely PDA, that simultaneously grows the aggregation tree and assigns a transmission schedule for each node being added to the tree. Particularly, this process is performed in a top-down manner. In each iteration, corresponding to a time slot, PDA uses a multi-level ranking strategy to schedule several &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\langle sender, receiver \rangle$&lt;/tex-math&gt;&lt;/inline-formula&gt; pairs, so that in a working period ahead, the possibility to pipeline as many transmissions as possible is high. Intensive simulation results show that the proposed scheme notably works better than the best known recent algorithms by having up to 35 percent shorter aggregation time, as well as having a significantly improved network throughput and time utilization.},
  archive      = {J_TMC},
  author       = {Tien-Dung Nguyen and Duc-Tai Le and Hyunseung Choo},
  doi          = {10.1109/TMC.2021.3052803},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3326-3341},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sensory data aggregation in internet of things: Period-driven pipeline scheduling approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SARDO: An automated search-and-rescue drone-based solution
for victims localization. <em>TMC</em>, <em>21</em>(9), 3312–3325. (<a
href="https://doi.org/10.1109/TMC.2021.3051273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural disasters affect millions of people every year. Finding missing persons in the shortest possible time is of crucial importance to reduce the death toll. This task is especially challenging when victims are sparsely distributed in large and/or difficult-to-reach areas and cellular networks are down. In this paper we present SARDO, a drone-based search and rescue solution that leverages the high penetration rate of mobile phones in the society to localize missing people. SARDO is an autonomous, all-in-one drone-based mobile network solution that does not require infrastructure support or mobile phones modifications. It builds on novel concepts such as pseudo-trilateration combined with machine-learning techniques to efficiently locate mobile phones in a given area. Our results, with a prototype implementation in a field-[1], show that SARDO rapidly determines the location of mobile phones ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim \!3$&lt;/tex-math&gt;&lt;/inline-formula&gt; min/UE) in a given area with an accuracy of few tens of meters and at a low battery consumption cost ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim \!5\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; ). State-of-the-art localization solutions for disaster scenarios rely either on mobile infrastructure support or exploit onboard cameras for human/computer vision, IR, thermal-based localization. To the best of our knowledge, SARDO is the first drone-based cellular search-and-rescue solution able to accurately localize missing victims through mobile phones.},
  archive      = {J_TMC},
  author       = {Antonio Albanese and Vincenzo Sciancalepore and Xavier Costa-Pérez},
  doi          = {10.1109/TMC.2021.3051273},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3312-3325},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SARDO: An automated search-and-rescue drone-based solution for victims localization},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource allocation and consensus of blockchains in
pervasive edge computing environments. <em>TMC</em>, <em>21</em>(9),
3298–3311. (<a href="https://doi.org/10.1109/TMC.2021.3053230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge devices with sensing, storage, and communication resources are penetrating our daily lives. These resources make it possible for edge devices to conduct data transactions (e.g., micro-payments, micro-access control). The blockchain technology can be used to ensure transaction unmodifiable and undeniable. In this paper, we propose a blockchain system that adapts to the limitations of edge devices. The new blockchain system can fairly and efficiently allocate storage resources on edge devices, which makes it scalable. We find the optimal peer nodes for transaction data storage and propose a recent block storage allocation scheme for quick retrieval of missing blocks. We develop data migration algorithms to dynamically reallocate data and block storage to adapt topology changes in the network. The proposed blockchain system can also reach consensus with low energy consumption in edge devices with a new Proof of Stake mechanism. Extensive simulations show that our proposed blockchain system works efficiently in edge environments. On average, the new system uses 18.4 percent less time and consumes 87 percent less battery power when compared with traditional blockchain systems.},
  archive      = {J_TMC},
  author       = {Yaodong Huang and Jiarui Zhang and Jun Duan and Bin Xiao and Fan Ye and Yuanyuan Yang},
  doi          = {10.1109/TMC.2021.3053230},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3298-3311},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Resource allocation and consensus of blockchains in pervasive edge computing environments},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proven secure tree-based authenticated key agreement for
securing V2V and V2I communications in VANETs. <em>TMC</em>,
<em>21</em>(9), 3280–3297. (<a
href="https://doi.org/10.1109/TMC.2021.3056712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular ad hoc networks (VANETs) are vulnerable to many kinds of security attacks, so it is necessary to design an authenticated key agreement (AKA) scheme for securing communication channels in VANETs. Existing AKA schemes in VANETs have not provided an efficient and secure method to secure V2V and V2I communications simultaneously while meeting the necessary security and privacy requirements. Further, few key updating mechanisms, which are secure, conditional privacy-preserving, practical, and lightweight, exist in current VANETs AKA schemes. In this paper, we propose a proven secure AKA scheme for securing V2V and V2I communications in VANETs, which can be divided into two parts. The first part is a three-party authentication process in which vehicles, road side unit (RSU), and trust authority (TA) authenticate each other. The second part is the key agreement process, which is used in the key generation and updating processes. For this phase, we design a tree-based key agreement algorithm that considers two scenarios, i.e., the joining of an authenticated vehicle and the leaving of the vehicle. The formal security proof and the security analysis show that our proposed scheme satisfies session key security and the necessary security requirements in VANETs, respectively. The performance analysis demonstrates that our proposed scheme has an advantage over several representative AKA schemes in VANETs.},
  archive      = {J_TMC},
  author       = {Lu Wei and Jie Cui and Hong Zhong and Yan Xu and Lu Liu},
  doi          = {10.1109/TMC.2021.3056712},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3280-3297},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Proven secure tree-based authenticated key agreement for securing V2V and V2I communications in VANETs},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PrivacyEye: A privacy-preserving and computationally
efficient deep learning-based mobile video analytics system.
<em>TMC</em>, <em>21</em>(9), 3263–3279. (<a
href="https://doi.org/10.1109/TMC.2021.3050458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large volumes of video data recorded by the increasing mobile devices and embedded sensors can be leveraged to answer queries of our lives, physical world and our evolving society. Especially, the rapid development of convolutional neural networks (CNNs) in the past few years offers the great advantage for multiple tasks in video analysis. However, adopting running CNNs directly on mobile devices and embedded sensors for video analytics brings heavy burden due to their limited capacity, especially for learning a large volume of data. A promising approach is to outsource the computation-intensive part of CNN to cloud. However, the reveal of data to cloud may cause privacy leakage. In addition, the cloud-assisted approach may also bring some communication efficiency challenges for large volume of data. To address both privacy and efficiency issues, we design a privacy-preserving and computationally efficient framework for mobile video analytics. To protect the private information, we split the CNN model into two subnetworks, and first part is used as a feature extractor deployed in the mobile side and the second part is utilized as a classifier deployed in the cloud side. A specific-designed adversarial training process is adopted in order to extract features for normal task classification while hiding the features for sensitive task. In addition, to improve video process efficiency, we design a two-stage framework. The first stage is to extract key frames and necessary intermediate frames, while skipping redundant ones. The second stage is to extract the features of key frames by CNN-based feature extractor but apply optical-flow-based feature propagation algorithm to obtain the features of intermediate frames. Extensive experiments demonstrate our proposed system PrivacyEye can effectively protect private information while keep the accuracy of the normal tasks with less than 2 percent drop, and it saves up to 82.9 percent execution time and 78.8 percent energy consumption.},
  archive      = {J_TMC},
  author       = {Wei Du and Ang Li and Pan Zhou and Ben Niu and Dapeng Wu},
  doi          = {10.1109/TMC.2021.3050458},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3263-3279},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PrivacyEye: A privacy-preserving and computationally efficient deep learning-based mobile video analytics system},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Privacy preserving participant recruitment for coverage
maximization in location aware mobile crowdsensing. <em>TMC</em>,
<em>21</em>(9), 3250–3262. (<a
href="https://doi.org/10.1109/TMC.2021.3050147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing has emerged as a promising paradigm where location-based sensing tasks are outsourced to mobile participants carrying sensor-equipped devices. A critical issue of crowdsensing is to guarantee the sensing coverage by appropriately recruiting participants, which requires participants’ precise locations and thus raises privacy concerns. In this paper, we are motivated to develop a privacy preserving participant recruitment scheme for mobile crowdsensing, which maximizes the spatial coverage of the sensing range while protecting participants’ location privacy against an untrusted crowdsensing platform. Briefly, we propose a utility-assured location obfuscation mechanism operated in a hexagonal grid system, which the participants can follow to locally perturb their locations with personalized privacy demands. Given the obfuscated locations, we efficiently solve a coverage-maximized participant recruitment problem with the budget constraint by using a deterministic rounding algorithm. Considering the existence of biased sensing data incurred by location obfuscation, we further develop a fault-aware crowdsensing framework to improve the robustness of the recruitment strategy, where a constant-approximation algorithm is applied to select participants against any number of unqualified sensing results. Extensive simulations on real-world location datasets and Uber’s geospatial indexing system validate the efficacy of our location obfuscation mechanism and participant recruitment schemes in mobile crowdsensing systems.},
  archive      = {J_TMC},
  author       = {Liang Li and Dian Shi and Xinyue Zhang and Ronghui Hou and Hao Yue and Hui Li and Miao Pan},
  doi          = {10.1109/TMC.2021.3050147},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3250-3262},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy preserving participant recruitment for coverage maximization in location aware mobile crowdsensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predictive boundary tracking based on motion behavior
learning for continuous objects in industrial wireless sensor networks.
<em>TMC</em>, <em>21</em>(9), 3239–3249. (<a
href="https://doi.org/10.1109/TMC.2021.3049220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diffusion of toxic gas, biochemical material, and radio-active contamination – known as continuous objects – endangers the safe production of the petrochemical and nuclear industries. To mitigate these well known hazards, the new paradigm of industrial wireless sensor networks (IWSNs) shows great potential in monitoring evolving hazardous phenomena in unfriendly industrial fields. In order to prolong the lifetime of these networks, existing research focuses on energy-efficient boundary nodes selection. However, sensor state cannot be scheduled proactively, due to the difficulty in predicting the spatiotemporal evolution of diffusive hazards. In this article, we propose a motion behavior learning predictive tracking (MBLPT) algorithm for continuous objects in IWSNs. Considering the relatively unpredictable patterns exhibited by continuous objects, the MBLPT uses a data-driven approach for motion state recognition, and then utilizes Bayesian model averaging (BMA) for future boundary prediction. The prediction of the MBLPT provides the knowledge for establishing a wake-up zone, in which standby nodes are activated in advance to participate in tracking the upcoming boundary. Simulation results demonstrate that the MBLPB achieves superior energy efficiency while keeping effective tracking accuracy.},
  archive      = {J_TMC},
  author       = {Li Liu and Guangjie Han and Zhengwei Xu and Lei Shu and Miguel Martínez-García and Bao Peng},
  doi          = {10.1109/TMC.2021.3049220},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3239-3249},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Predictive boundary tracking based on motion behavior learning for continuous objects in industrial wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Minimizing the age-of-critical-information: An imitation
learning-based scheduling approach under partial observations.
<em>TMC</em>, <em>21</em>(9), 3225–3238. (<a
href="https://doi.org/10.1109/TMC.2021.3053136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age of Information (AoI) has become an important metric to evaluate the freshness of information, and studies of minimizing AoI in wireless networks have drawn extensive attention. In mobile edge networks, changes in critical levels for distinct information is important for users’ decision making, especially when merely partial observations are available. However, existing research has not yet addressed this issue, which is the subject of this paper. To address this issue, we first establish a system model, in which the information freshness is quantified by changes in its critical levels. We formulate Age-of-Critical-Information (AoCI) minimization as an optimization problem, with the purpose of minimizing the average relative AoCI of mobile clients to help them make timely decisions. Then, we propose an information-aware heuristic algorithm that can reach optimal performance with full obsevations in an offline manner. For online scheduling, an imitation learning-based scheduling approach is designed to choose update preferences for mobile clients under partial observations, where policies obtained by the above heuristic algorithm are utilized for expert policies. Finally, we demonstrate the superiority of our designed algorithm from both theoretical and experimental perspectives.},
  archive      = {J_TMC},
  author       = {Xiaojie Wang and Zhaolong Ning and Song Guo and Miaowen Wen and H. Vincent Poor},
  doi          = {10.1109/TMC.2021.3053136},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3225-3238},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Minimizing the age-of-critical-information: An imitation learning-based scheduling approach under partial observations},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ISHU: Interference reduction scheme for D2D mobile groups
using uplink NOMA. <em>TMC</em>, <em>21</em>(9), 3208–3224. (<a
href="https://doi.org/10.1109/TMC.2021.3051670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, Interference Reduction Scheme for Device-to-Device (D2D) Mobile Groups Using Uplink NOMA (ISHU) is proposed to maximize the throughput of the network. To achieve this goal, we integrated uplink non-orthogonal multiple access (NOMA) in the D2D mobile groups (DMGs). DMGs improve the spectral efficiency by sharing the resources with cellular mobile users (CMUs) whereas, uplink NOMA in DMGs associate the large number of D2D mobile users (DMUs) with the D2D transmitter (DDT). ISHU jointly optimizes the user group association and resource allocation in the uplink NOMA-enabled DMGs. The problem of joint user association and resource allocation is formulated as a mixed integer non-linear programming. To address this problem, we divided the problem of interference mitigation in two sub-problems and solved it independently. First, for joint user group association and sub-carrier assignment, a 3-D matching game is designed between the DMUs, DDT, and sub-carriers, respectively. Second, to optimize the power of DMUs across each sub-carriers, the branch and bound (BB) technique is used. Also, to reduce the complexity of ISHU scheme, the successive convex approximation low complexity (SCALE) technique is used across each sub-carrier. Simulated results demonstrated that ISHU provides 3.846 and 26.92 percent superior throughout as compared to the existing uplink conventional NOMA and OFDMA schemes.},
  archive      = {J_TMC},
  author       = {Ishan Budhiraja and Neeraj Kumar and Sudhanshu Tyagi},
  doi          = {10.1109/TMC.2021.3051670},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3208-3224},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ISHU: Interference reduction scheme for D2D mobile groups using uplink NOMA},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). (In)secure acoustic mobile authentication. <em>TMC</em>,
<em>21</em>(9), 3193–3207. (<a
href="https://doi.org/10.1109/TMC.2021.3053282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic fingerprinting aims to identify a mobile device based on its internal microphone(s) and speaker(s) which are unique due to manufacturing imperfection. This paper seeks a thorough understanding of the (in)security of exploring acoustic fingerprints for achieving distributed mobile authentication. Our contributions are threefold. First, we present a new acoustic fingerprint-emulation attack and demonstrate that it is a common vulnerability of acoustic mobile authentication systems. Second, we propose a dynamic challenge-response defense to secure acoustic mobile authentication systems against the acoustic fingerprint-emulation attack. Finally, we thoroughly investigate existing acoustic fingerprinting schemes and identify the best option for accurate, secure, and deployable acoustic mobile authentication systems.},
  archive      = {J_TMC},
  author       = {Dianqi Han and Ang Li and Tao Li and Lili Zhang and Yan Zhang and Jiawei Li and Rui Zhang and Yanchao Zhang},
  doi          = {10.1109/TMC.2021.3053282},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3193-3207},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {(In)secure acoustic mobile authentication},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving discovery process toward user engagement based on
advertising extensions in bluetooth low energy networks. <em>TMC</em>,
<em>21</em>(9), 3176–3192. (<a
href="https://doi.org/10.1109/TMC.2021.3054931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Bluetooth Low Energy (BLE) beacons enhanced further for connectionless services such as location-specific information and navigation. With BLE 5.0, the way beacons deliver more information can move away from the current model of app-paired-to-device to a connectionless IoT. When users pass areas with installed BLE beacons, their mobile devices can receive specials, promotional contents, and discount coupons. However, the beacons are only broadcasting. This means that beacons are not able to collect information from the users with mobile devices. In this paper, we propose responsive advertising with the wait-slot scheme (RAWS) based on advertising extensions to improve the performance of the discovery process before further communications in BLE networks. Besides, we consider the energy consumption and investigate the latency-energy tradeoff with our proposed scheme. The theoretical lower bounds for both latency and energy of the discovery process as well as their tradeoff are presented. In addition, we formulate the state transition diagram for analyzing the performance of our proposed scheme. Simulation results validated by analysis results show that RAWS indeed improves the latency and the energy consumption of the discovery process in BLE networks.},
  archive      = {J_TMC},
  author       = {Ting-Ting Yang and Hsueh-Wen Tseng},
  doi          = {10.1109/TMC.2021.3054931},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3176-3192},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Improving discovery process toward user engagement based on advertising extensions in bluetooth low energy networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ECHO: Efficient zero-control-packet broadcasting for mobile
ad hoc networks. <em>TMC</em>, <em>21</em>(9), 3163–3175. (<a
href="https://doi.org/10.1109/TMC.2021.3055819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications such as collaborative mapping motivate a need for network-wide broadcasting in Mobile Ad Hoc Networks (MANET) with low-rate long-range links. Existing MANET protocols are inadequate in such low-capacity regimes due to their high use of control packets. We present a novel protocol called ECHO that constructs and maintains a broadcast backbone without using any control packets. Instead, using a field in the data packet header, a node transmits and listens for an “echo” of the specific packet to determine its membership in the backbone. ECHO is deterministic, source-independent, fully distributed, accommodates mobility, and balances battery consumption across nodes. We prove ECHO’s correctness and show that its communication complexity is lower than that of Multi-Point Relay (MPR) and Flooding, and comparable to that of Opportunistic Announcement (OA). Simulations over random mobile low-capacity networks show that ECHO provides at least a 30 percent better delivery ratio than Flooding, MPR, and OA for 50-node networks and dramatically reduces the communication load. Experiments on a 12-node testbed of goTenna mobile mesh networking devices show that ECHO reduces transmissions by about 3x and increases battery life by more than 50 percent over Flooding. ECHO’s performance advantages are crucial for scalable broadcast in low-power, low-capacity wireless networks.},
  archive      = {J_TMC},
  author       = {Ayush Dusia and Ram Ramanathan and Warren Ramanathan and Christophe Servaes and Adarshpal S. Sethi},
  doi          = {10.1109/TMC.2021.3055819},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3163-3175},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ECHO: Efficient zero-control-packet broadcasting for mobile ad hoc networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Delay and reliability-constrained VNF placement on mobile
and volatile 5G infrastructure. <em>TMC</em>, <em>21</em>(9), 3150–3162.
(<a href="https://doi.org/10.1109/TMC.2021.3055426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ongoing research and industrial exploitation of SDN and NFV technologies promise higher flexibility on network automation and infrastructure optimization. Choosing the location of Virtual Network Functions is a central problem in the automation and optimization of the software-defined, virtualization-based next generation of networks such as 5G and beyond. Network services provided for autonomous vehicles, factory automation, e-health and cloud robotics often require strict delay bounds and reliability constraints influenced by the location of its composing Virtual Network Functions. Robots, vehicles and other end-devices provide significant capabilities such as actuators, sensors and local computation which are essential for some services. Moreover, these devices are continuously on the move and might lose network connection or run out of battery, which further challenge service delivery in this dynamic environment. This work tackles the mobility, and battery restrictions; as well as the temporal aspects and conflicting traits of reliable, low latency service deployment over a volatile network, where mobile compute nodes act as an extension of the cloud and edge computing infrastructure. The problem is formulated as a cost-minimizing Virtual Network Function placement optimization and an efficient heuristic is proposed. The algorithms are extensively evaluated from various aspects by simulation on detailed real-world scenarios.},
  archive      = {J_TMC},
  author       = {Balázs Németh and Nuria Molner and Jorge Martín-Pérez and Carlos J. Bernardos and Antonio de la Oliva and Balázs Sonkoly},
  doi          = {10.1109/TMC.2021.3055426},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3150-3162},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Delay and reliability-constrained VNF placement on mobile and volatile 5G infrastructure},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CR-LBT: Listen-before-talk with collision resolution for 5G
NR-u networks. <em>TMC</em>, <em>21</em>(9), 3138–3149. (<a
href="https://doi.org/10.1109/TMC.2021.3055028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve higher throughputs in cellular networks, 3GPP proposes to use unlicensed frequency bands and develops technologies — the latest one is NR-U — allowing a cellular base station to transmit in unlicensed bands, which are already occupied by Wi-Fi networks. To enable fair channel sharing between two technologies, the base station uses a sort of CSMA/CA with binary exponential backoff similar to Wi-Fi. However, the base station can start data transmission only at strictly periodic time moments. Many papers propose sending a reservation signal between the end of the backoff procedure and such a moment to prevent nearby devices from accessing the channel. However, this approach significantly reduces Wi-Fi performance. The paper proposes a novel method CR-LBT of transmitting a reservation signal that greatly decreases channel resource waste caused by collisions and improves channel resource sharing fairness. With developed analytical models and simulations, it is shown that CR-LBT may simultaneously increase the throughput of both NR-U and Wi-Fi networks. The effect is more noticeable for the Wi-Fi network, the throughput of which may rise three times compared with the traditional method of sending the reservation signal. Finally, the influence of various factors on CR-LBT performance is studied.},
  archive      = {J_TMC},
  author       = {Vyacheslav Loginov and Evgeny Khorov and Andrey Lyakhov and Ian F. Akyildiz},
  doi          = {10.1109/TMC.2021.3055028},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3138-3149},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CR-LBT: Listen-before-talk with collision resolution for 5G NR-U networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compressed sensing based low-power multi-view video coding
and transmission in wireless multi-path multi-hop networks.
<em>TMC</em>, <em>21</em>(9), 3122–3137. (<a
href="https://doi.org/10.1109/TMC.2021.3049797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Multimedia Sensor Network (WMSN) is increasingly being deployed for surveillance, monitoring and Internet-of-Things (IoT) sensing applications where a set of cameras capture and compress local images and then transmit the data to a remote controller. Such captured local images may also be compressed in a multi-view fashion to reduce the redundancy among overlapping views. In this paper, we present a novel paradigm for compressed-sensing-enabled multi-view coding and streaming in WMSN. We first propose a new encoding and decoding architecture for multi-view video systems based on Compressed Sensing (CS) principles, composed of cooperative sparsity-aware block-level rate-adaptive encoders, feedback channels and independent decoders. The proposed architecture leverages the properties of CS to overcome many limitations of traditional encoding techniques, specifically massive storage requirements and high computational complexity. Then, we present a modeling framework that exploits the aforementioned coding architecture. The proposed mathematical problem minimizes the power consumption by jointly determining the encoding rate and multi-path rate allocation subject to distortion and energy constraints. Extensive performance evaluation results show that the proposed framework is able to transmit multi-view streams with guaranteed video quality at lower power consumption.},
  archive      = {J_TMC},
  author       = {Nan Cen and Zhangyu Guan and Tommaso Melodia},
  doi          = {10.1109/TMC.2021.3049797},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3122-3137},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Compressed sensing based low-power multi-view video coding and transmission in wireless multi-path multi-hop networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boosting chirp signal based aerial acoustic communication
under dynamic channel conditions. <em>TMC</em>, <em>21</em>(9),
3110–3121. (<a href="https://doi.org/10.1109/TMC.2021.3051665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial acoustic communication attracts substantial attention for its simplicity and cost-effectiveness. Unfortunately, the preferred inaudible transmission has to strike a balance between the transmission rate and communication range, when the Bit-Error-Rate (BER) is under a certain threshold. Additionally, the performance of previous proposals can be deteriorated by dynamic channel conditions including near-far problem, device heterogeneity, and multipath fading. To this end, we propose a High-speed, long-range, and Robust Chirp Spread Spectrum (HRCSS) scheme for inaudible aerial acoustic communication under dynamic channels. HRCSS innovates in the definition of a loose orthogonality condition, and it leverages this orthogonality to overlap multiple chirp carriers in a single time duration to form a data symbol representing multiple bits, thereby substantially promoting the data rate. To further enhance system robustness in long communication ranges and dynamic channel conditions, we construct a lightweight rate adaptation algorithm and design a simple yet efficient normalization method. Experiment results reveal that HRCSS achieves a significant improvement in data rate over existing methods: it delivers 500 bps data rate with a BER of 0.24 percent at 10 m, and achieves 125 bps with zero BER at 20 m. Meanwhile, HRCSS can work adaptively under dynamic channel conditions while still retaining a BER below 3 percent.},
  archive      = {J_TMC},
  author       = {Chao Cai and Zhe Chen and Jun Luo and Henglin Pu and Menglan Hu and Rong Zheng},
  doi          = {10.1109/TMC.2021.3051665},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3110-3121},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Boosting chirp signal based aerial acoustic communication under dynamic channel conditions},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A tag-correlation-based approach to fast identification of
group tags. <em>TMC</em>, <em>21</em>(9), 3096–3109. (<a
href="https://doi.org/10.1109/TMC.2021.3052572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tag identification is a critical operation in large-scale RFID applications. Typically, in the RFID-enabled warehouse, the reader needs to execute tag identifications to obtain the inventory information of numerous tagged items. The existing schemes usually divide the time frame into multiple slots and map each tag to one of them for replying its identity. This imposes serious tag collisions because two or more tags may be mapped to the same slot and their responses corrupt with each other. When tag collision happens, all the collided tags cannot be identified by the reader, which significantly increases the identification delay. To overcome the collision problem in the identification process, this paper proposes a Group Tag Identification (GTI) framework to identify grouped tags in both singleton and collision slots. The key novelty of GTI is in leveraging tag-correlation to identify grouped tags in the collision slots without any extra transmission overhead. The main challenge of this work is to overcome the communication and architectural limitations of RFID systems in the context of building ID and slot-correlation between tags. Extensive simulations show that GTI significantly reduces the identification delay by up to 40 percent when compared with the state-of-the-art dynamical frame slotted aloha schemes.},
  archive      = {J_TMC},
  author       = {Xin Xie and Xiulong Liu and Heng Qi and Song Guo and Keqiu Li},
  doi          = {10.1109/TMC.2021.3052572},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3096-3109},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A tag-correlation-based approach to fast identification of group tags},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). A misreport- and collusion-proof crowdsourcing mechanism
without quality verification. <em>TMC</em>, <em>21</em>(9), 3084–3095.
(<a href="https://doi.org/10.1109/TMC.2021.3052873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality control plays a critical role in crowdsourcing. The state-of-the-art work is not suitable for crowdsourcing applications that require extensive validation of the tasks quality, since it is a long haul for the requestor to verify task quality or select professional workers in a one-by-one mode. In this paper, we propose a misreport- and collusion-proof crowdsourcing mechanism, guiding workers to truthfully report the quality of submitted tasks without collusion by designing a mechanism, so that workers have to act the way the requestor would like. In detail, the mechanism proposed by the requester makes no room for the workers to obtain profit through quality misreport and collusion, and thus, the quality can be controlled without any verification. Extensive simulation results verify the effectiveness of the proposed mechanism. Finally, the importance and originality of our work lie in that it reveals some interesting and even counterintuitive findings: 1) a high-quality worker may pretend to be a low-quality one; 2) the rise of task quality from high-quality workers may not result in the increased utility of the requestor; 3) the utility of the requestor may not get improved with the increasing number of workers. These findings can boost forward looking and strategic planning solutions for crowdsourcing.},
  archive      = {J_TMC},
  author       = {Kun Li and Shengling Wang and Xiuzhen Cheng and Qin Hu},
  doi          = {10.1109/TMC.2021.3052873},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3084-3095},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A misreport- and collusion-proof crowdsourcing mechanism without quality verification},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for personalized location privacy. <em>TMC</em>,
<em>21</em>(9), 3071–3083. (<a
href="https://doi.org/10.1109/TMC.2021.3055865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location privacy has been one of the most important research areas over recent years, and many location Privacy Preserving Mechanisms (PPMs) have been proposed. Each PPM typically achieves certain tradeoffs between privacy protection and resource consumption, and no PPM performs perfectly in all cases. Instead of designing one PPM that works for all cases, this paper studies how to make the best use of multiple single PPMs for location privacy protection in different scenarios. In particular, we propose a general framework called SmartGuard, which dynamically selects the best privacy preservation strategy for a user based on her preferences and the current status of her mobile device. SmartGuard quantifies user privacy under various scenarios, models the effects of different PPMs on several key factors such as the remaining battery level and network bandwidth, and then recommends the best privacy strategy for the user. To illustrate how our SmartGuard works, we apply it to a specific scenario of LBSs and implement it on Android based phones. Evaluation results show that our solution outperforms existing PPMs under various scenarios.},
  archive      = {J_TMC},
  author       = {Ben Niu and Qinghua Li and Hanyi Wang and Guohong Cao and Fenghua Li and Hui Li},
  doi          = {10.1109/TMC.2021.3055865},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3071-3083},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A framework for personalized location privacy},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 5G network planning under service and EMF constraints:
Formulation and solutions. <em>TMC</em>, <em>21</em>(9), 3053–3070. (<a
href="https://doi.org/10.1109/TMC.2021.3054482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We target the planning of a 5G cellular network under 5G service and ElectroMagnetic Fields (EMFs) constraints. We initially model the problem with a mixed integer linear programming (MILP) formulation. The pursued objective is a weighed function of next-generation Node-B (gNB) installation costs and 5G service coverage level from a massive multiple input multiple output (MIMO) system. In addition, we precisely model restrictive EMF constraints and we integrate scaling parameters to estimate the power radiated by 5G gNBs. Since the considered planning problem is NP-Hard, and therefore very challenging to be solved even for small problem instances, we design an efficient heuristic, called PLATEA , to practically solve it. Results, obtained over a realistic scenario that includes EMF exposure from pre-5G technologies (e.g., 2G, 3G, 4G), prove that the cellular planning selected by PLATEA ensures 5G service and restrictive EMF constraints. However, we demonstrate that the results are strongly affected by: i) the relative weight between gNB installation costs and 5G service coverage level; ii) the scaling parameters to estimate the exposure generated by 5G gNBs; iii) the amount of exposure from pre-5G technologies; and iv) the adopted frequency reuse scheme.},
  archive      = {J_TMC},
  author       = {Luca Chiaraviglio and Cristian Di Paolo and Nicola Blefari-Melazzi},
  doi          = {10.1109/TMC.2021.3054482},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {9},
  number       = {9},
  pages        = {3053-3070},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {5G network planning under service and EMF constraints: Formulation and solutions},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video aficionado: We know what you are watching.
<em>TMC</em>, <em>21</em>(8), 3041–3052. (<a
href="https://doi.org/10.1109/TMC.2020.3045730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Users enjoy the convenience of watching videos on smart devices. However, video watching records can be exposed without users’ knowledge and be exploited to infer private information. In this paper, we design and implement a new side-channel attack system, named video aficionado , which can identify video watching information without violating any access control policies on Android. Our system only needs to collect power consumption data of a video playing app, which does not require explicit user permission. The collected data is sent to a remote server, where noise is cleaned and identified by a multi-layer perceptron (MLP) trained classifier. We evaluate our proposed system through a set of carefully designed experiments. Experimental results demonstrate that our system can make an identification with 74.5 percent accuracy on average for each 20-second power measurement segment out of 3918 segments collected from 20 videos. To the best of our knowledge, video aficionado is the first real-time power consumption-based video identification system on smart devices.},
  archive      = {J_TMC},
  author       = {Jialing He and Zijian Zhang and Jian Mao and Liran Ma and Bakh Khoussainov and Rui Jin and Liehuang Zhu},
  doi          = {10.1109/TMC.2020.3045730},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {3041-3052},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Video aficionado: We know what you are watching},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scanning the voice of your fingerprint with everyday
surfaces. <em>TMC</em>, <em>21</em>(8), 3024–3040. (<a
href="https://doi.org/10.1109/TMC.2021.3049217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the premise of uniqueness and acceptance, fingerprint has been the most adopted biometric technologies in high-impact applications (e.g., smartphone security, monetary transactions and international-border verification). Although there are an array of commercial fingerprint scanners across different sensing modalities including optical, capacitive, thermal and ultrasonic, existing fingerprint technologies are vulnerable to spoofing attacks via fake-finger in Kang et al. , 2003. In this paper, we investigate a new dimension of fingerprint sensing based on the friction-excited sonic wave (in simpler words, ”voice of fingerprint”) from a user swiping his fingertip on everyday surfaces. Specifically, we develop SonicPrint to leverage the intrinsic fingerprint ridge information in sonic wave for user identification. First, the complex ambient noise is isolated from the sonic wave using background isolation and adaptive segmentation models. Afterward, a series of multi-level friction descriptors that highlight the target fingerprint information is extracted. These descriptors are fed to a specially designed ensemble classifier for user identification. SonicPrint is practical as it leverages in-built microphones in smart devices, requiring no hardware modifications. As the first exploratory study, our experimental results with 31 participants over three different swipe actions on 12 different types of materials show up to a 98 percent identification accuracy.},
  archive      = {J_TMC},
  author       = {Aditya Singh Rathore and Chenhan Xu and Weijin Zhu and Afee Daiyan and Kun Wang and Feng Lin and Kui Ren and Wenyao Xu},
  doi          = {10.1109/TMC.2021.3049217},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {3024-3040},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Scanning the voice of your fingerprint with everyday surfaces},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust human face authentication leveraging acoustic sensing
on smartphones. <em>TMC</em>, <em>21</em>(8), 3009–3023. (<a
href="https://doi.org/10.1109/TMC.2020.3048659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User authentication on smartphones is the key to many applications, which must satisfy both security and convenience. We propose a novel user authentication system EchoPrint , which leverages acoustics and vision for secure and convenient user authentication, without requiring any special hardware. EchoPrint actively emits almost inaudible acoustic signals from the earpiece speaker to “illuminate” the user&#39;s face and authenticates the user by the unique features extracted from the echoes bouncing off the 3D facial contour. To combat changes in phone-holding poses thus echoes, a convolutional neural network (CNN) is trained to extract reliable acoustic features, which are further combined with visual facial features extracted from state-of-the-art face recognition deep models to feed a binary support vector machine (SVM) classifier for final authentication. Because the echo features depend on 3D facial geometries, EchoPrint is not easily spoofed by images or videos like 2D visual face recognition systems. It needs only commodity hardware, thus avoiding the extra costs of special sensors in solutions like FaceID. Experiments with 62 volunteers and non-human objects such as images, photos, and sculptures show that EchoPrint achieves 93.75 percent balanced accuracy and 93.50 percent F-score, while the average precision is 98.05 percent using acoustic features and basic facial landmarks. The precision is further improved to 99.96 percent with sophisticated visual features.},
  archive      = {J_TMC},
  author       = {Bing Zhou and Zongxing Xie and Yinuo Zhang and Jay Lohokare and Ruipeng Gao and Fan Ye},
  doi          = {10.1109/TMC.2020.3048659},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {3009-3023},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust human face authentication leveraging acoustic sensing on smartphones},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reducing the service function chain backup cost over the
edge and cloud by a self-adapting scheme. <em>TMC</em>, <em>21</em>(8),
2994–3008. (<a href="https://doi.org/10.1109/TMC.2020.3048885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging virtual network functions (VNFs) bring new opportunities to network services on the edge within customers’ premises. Network services are realized by chained up VNFs, which are called service function chains (SFCs). These services are deployed on commercial edge servers for higher flexibility and scalability. Despite such promises, it is still unclear how to provide highly available and cost-effective SFCs under edge resource limitations and time-varying VNF failures. In this paper, we propose a novel Reliability-aware Adaptive Deployment scheme named RAD to efficiently place and back up SFCs over both the edge and the cloud. Specifically, RAD first deploys SFCs to fully utilize edge resources. It then uses both static backups and dynamic ones created on the fly to guarantee the availability under the resource limitation of edge networks. RAD does not assume failure rates of VNFs but instead strives to find the sweet spot between the desired availability of SFCs and the backup cost. Theoretical performance bounds, extensive simulations, and small-scale experiments highlight that RAD provides significantly higher availability with lower backup costs compared with existing baselines.},
  archive      = {J_TMC},
  author       = {Xiaojun Shang and Yaodong Huang and Zhenhua Liu and Yuanyuan Yang},
  doi          = {10.1109/TMC.2020.3048885},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2994-3008},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reducing the service function chain backup cost over the edge and cloud by a self-adapting scheme},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QoS and resource-aware security orchestration and life cycle
management. <em>TMC</em>, <em>21</em>(8), 2978–2993. (<a
href="https://doi.org/10.1109/TMC.2020.3046968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-touch network and service management (ZSM) exploits network function virtualization (NFV) and software-defined networking (SDN) to efficiently and dynamically orchestrate different service function chaining (SFC), whereby reducing capital expenditure and operation expenses. The SFC is an optimization problem that shall consider different constraints, such as Quality of Service (QoS), and actual resources, to achieve cost-efficient scheduling and allocation of the service functions. However, the large-scale, complexity and security issues brought by virtualized IoT networks, which embrace different network segments, e.g., Fog, Edge, Core, Cloud, that can also exploit proximity (computation offloading of virtualized IoT functions to the Edge), imposes new challenges for ZSM orchestrators intended to optimize the SFC, thereby achieving seamless user-experience, minimal end-to-end delay at a minimal cost. To cope with these challenges, this paper proposes a cost-efficient optimized orchestration system that addresses the whole life-cycle management of different SFCs, that considers QoS (including end-to-end delay, bandwidth, jitters), actual capacities of Virtual Network Functions (VNFs), potentially deployed across multiple Clouds-Edges, in terms of resources (CPU, RAM, storage) and current network security levels to ensure trusted deployments. The proposed orchestration system has been implemented and evaluated in the scope of H2020 Anastacia EU project, 1 showing its feasibility and performance to efficiently manage SFC, optimizing deployment costs, reducing overall end-to-end delay and optimizing VNF instances distribution.},
  archive      = {J_TMC},
  author       = {Miloud Bagaa and Tarik Taleb and Jorge Bernal Bernabe and Antonio Skarmeta},
  doi          = {10.1109/TMC.2020.3046968},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2978-2993},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {QoS and resource-aware security orchestration and life cycle management},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Private cell-ID trajectory prediction using multi-graph
embedding and encoder-decoder network. <em>TMC</em>, <em>21</em>(8),
2967–2977. (<a href="https://doi.org/10.1109/TMC.2020.3047735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction for mobile phone users is a cornerstone component to support many higher-level applications in LBSs (Location-Based Services). Most existing methods are designed based on the assumption that the explicit location information of the trajectories is available (e.g., GPS trajectories). However, collecting such kind of trajectories lays a heavy burden on the mobile phones and incurs privacy concerns. In this paper, we study the problem of trajectory prediction based on cell-id trajectories without explicit location information and propose a deep learning framework (called DeepCTP) to solve this problem. Specifically, we use a multi-graph embedding method to learn the latent spatial correlations between cell towers by exploiting handoff patterns. Then, we design a novel spatial-aware loss function for the encoder-decoder network to generate cell-id trajectory predictions. We conducted extensive experiments on real datasets. The experiment results show that DeepCTP outperforms the state-of-the-art cell-id trajectory prediction methods in terms of prediction error.},
  archive      = {J_TMC},
  author       = {Mingqi Lv and Dajian Zeng and Ling Chen and Tieming Chen and Tiantian Zhu and Shouling Ji},
  doi          = {10.1109/TMC.2020.3047735},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2967-2977},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Private cell-ID trajectory prediction using multi-graph embedding and encoder-decoder network},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Principle of computation power optimization in millimeter
wave massive MIMO systems. <em>TMC</em>, <em>21</em>(8), 2955–2966. (<a
href="https://doi.org/10.1109/TMC.2020.3048718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation power of baseband units (BBUs) is a major source of power consumption in millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems with a large number of users due to complex signal processing. The effective reduction of computation power is critical for improving system energy efficiency. In this paper, the principle of reducing the computation power of BBUs is first investigated in mmWave massive MIMO systems with a hybrid precoding structure. A recursive constraint in decomposing the baseband precoding matrix is derived for reducing the computation power of hybrid precoding systems. Furthermore, the optimal number of sub-matrices minimizing the maximum error in decomposing the baseband precoding matrix is obtained. Based on the proposed principle, consisting of the recursive constraint and the optimal number of sub-matrices, a fast Monte Carlo baseband precoding (FMCBP) algorithm is developed to reduce the computation power of BBUs and improve system energy efficiency. Simulation results show that the total transmission rate and energy efficiency of mmWave systems are coupled with the computation power of BBUs, based on the FMCBP algorithm. Moreover, the FMCBP algorithm maximally improves the energy efficiency of multi-user mmWave massive MIMO communication systems by 124 percent, compared with the conventional equivalent zero-forcing algorithm.},
  archive      = {J_TMC},
  author       = {Jing Yang and Xiaohu Ge and Yonghui Li},
  doi          = {10.1109/TMC.2020.3048718},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2955-2966},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Principle of computation power optimization in millimeter wave massive MIMO systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal scheduling of age-centric caching: Tractability and
computation. <em>TMC</em>, <em>21</em>(8), 2939–2954. (<a
href="https://doi.org/10.1109/TMC.2020.3045104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of age of information (AoI) has become an important performance metric in network and control systems. Information freshness, represented by AoI, naturally arises in the context of caching. We address optimal scheduling of cache updates for a time-slotted system where the contents vary in size. There is limited capacity for the cache for making updates. Each content is associated with a utility function that depends on the AoI and the time duration of absence from the cache. For this combinatorial optimization problem, we present the following contributions. First, we provide theoretical results of problem tractability. Whereas the problem is NP-hard, we prove solution tractability in polynomial time for a special case where all contents have the same size, by a reformulation using network flows. Second, we derive an integer linear formulation for the problem, of which the optimal solution can be obtained for small-scale scenarios. Next, via a mathematical reformulation, we derive a scalable optimization algorithm using repeated column generation. In addition, the algorithm computes a bound of global optimum, that can be used to assess the performance of any scheduling solution. Performance evaluation of large-scale scenarios demonstrates the strengths of the algorithm in comparison to a greedy schedule. Finally, we extend the applicability of our work to cyclic scheduling.},
  archive      = {J_TMC},
  author       = {Ghafour Ahani and Di Yuan and Sumei Sun},
  doi          = {10.1109/TMC.2020.3045104},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2939-2954},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimal scheduling of age-centric caching: Tractability and computation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the computation of virtual backbones with fault tolerance
in heterogeneous wireless sensor networks. <em>TMC</em>, <em>21</em>(8),
2922–2938. (<a href="https://doi.org/10.1109/TMC.2020.3048960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of wireless sensor networks (WSNs), the problem of virtual backbones (VBs) for undertaking routing tasks to alleviate broadcast storms has been extensively studied. In practical applications, different nodes in a WSN may have different transmission ranges because of differences in power control or functionality, among other reasons. In such a situation, a disk graph (DG) can be used as a mathematical model of the WSN, and a strongly connected dominating and absorbent set (SCDAS) in the DG can be treated as a VB in the corresponding WSN. In a WSN with faulty nodes, a fault-tolerant VB is superior to a traditional one. Thus, it is desirable to construct a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -strongly connected &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ m$&lt;/tex-math&gt;&lt;/inline-formula&gt; -dominating and absorbent set ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ (k,m)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -SCDAS) in the DG to serve as a fault-tolerant VB in the corresponding WSN. In this article, to enable the construction of a high-quality &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ (k,m)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -SCDAS in a DG, a constant approximation algorithm with a performance ratio of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(2k(5^{k-1}-1)+1)(R+m+4(\frac{R}{m}+1))$&lt;/tex-math&gt;&lt;/inline-formula&gt; is proposed, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ k$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ m$&lt;/tex-math&gt;&lt;/inline-formula&gt; are constants ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ 2 \;\leqslant\; k \;\leqslant\; m$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$ R$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the maximum number of independent nodes within the transmission range of a node in the DG. A theoretical analysis and simulation results show that our work is superior to previous approaches.},
  archive      = {J_TMC},
  author       = {Weiguang Zhang and Jiarong Liang and Xinyu Liang},
  doi          = {10.1109/TMC.2020.3048960},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2922-2938},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the computation of virtual backbones with fault tolerance in heterogeneous wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mobile proxy caching for multi-view 3D videos with adaptive
view selection. <em>TMC</em>, <em>21</em>(8), 2909–2921. (<a
href="https://doi.org/10.1109/TMC.2020.3047714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the emergence of mobile 3D devices, multi-view 3D videos are expected to play increasingly important roles in providing immersively interactive experiences to users. Compared with traditional single-view videos, it is envisaged that a multi-view 3D video requires a larger storage space and bandwidth consumption. Nevertheless, efficient caching for multi-view 3D videos in a mobile proxy has not been explored in the literature. In this paper, therefore, we first observe that the storage space can be effectively reduced by leveraging Depth Image Based Rendering (DIBR) in multi-view 3D videos. We then formulate a new cache management problem, named Adaptive View Selection and Cache Operation (AVSCO), and find the optimal policy based on Markov Decision Process (MDP). Afterward, we propose an online algorithm with a guaranteed competitive ratio to support human visual continuity in AVSCO. Then, we devise an approximate MDP to accelerate the computation of MDP by aggregating similar states to reduce the state space. Simulation and prototype implementation results manifest that the proposed algorithms can significantly improve the cache hit rate and reduce the bandwidth consumption for the remote access compared with the existing cache replacement algorithms.},
  archive      = {J_TMC},
  author       = {Mengsi Yeh and Chih-Hang Wang and De-Nian Yang and Ji-Tang Lee and Wanjiun Liao},
  doi          = {10.1109/TMC.2020.3047714},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2909-2921},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobile proxy caching for multi-view 3D videos with adaptive view selection},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MetaRadar: Indoor localization by reconfigurable
metamaterials. <em>TMC</em>, <em>21</em>(8), 2895–2908. (<a
href="https://doi.org/10.1109/TMC.2020.3044603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor localization has drawn much attention owing to its potential for supporting location based services. Among various indoor localization techniques, the received signal strength (RSS) based technique is widely researched. However, in conventional RSS based systems where the radio environment is unconfigurable, adjacent locations may have similar RSS values, which limits the localization precision. In this paper, we present MetaRadar, which explores reconfigurable radio reflection with a surface/plane made of metamaterial units for multi-user localization. By changing the reflectivity of metamaterial, MetaRadar modifies the radio channels at different locations, and improves localization accuracy by making RSS values at adjacent locations have significant differences. However, in MetaRadar, it is challenging to build radio maps for all the radio environments generated by metamaterial units and select suitable maps from all the possible maps to realize a high accuracy localization. To tackle this challenge, we propose a compressive construction technique which can predict all the possible radio maps, and propose a configuration optimization algorithm to select favorable metamaterial reflectivities and the corresponding radio maps. The experimental results show a significant improvement from a decimeter-level localization error in the traditional RSS-based systems to a centimeter-level one in MetaRadar.},
  archive      = {J_TMC},
  author       = {Haobo Zhang and Jingzhi Hu and Hongliang Zhang and Boya Di and Kaigui Bian and Zhu Han and Lingyang Song},
  doi          = {10.1109/TMC.2020.3044603},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2895-2908},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MetaRadar: Indoor localization by reconfigurable metamaterials},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint data collection and resource allocation for
distributed machine learning at the edge. <em>TMC</em>, <em>21</em>(8),
2876–2894. (<a href="https://doi.org/10.1109/TMC.2020.3045436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the paradigm of edge computing, the enormous data generated at the network edge can be processed locally. To make full utilization of these widely distributed data, we focus on an edge computing system that conducts distributed machine learning using gradient-descent based approaches. To ensure the system’s performance, there are two major challenges: how to collect data from multiple data source nodes for training jobs and how to allocate the limited resources on each edge server among these jobs. In this paper, we jointly consider the two challenges for distributed training (without service requirement), aiming to maximize the system throughput while ensuring the system’s quality of service (QoS). Specifically, we formulate the joint problem as a mixed-integer non-linear program, which is NP-hard, and propose an efficient approximation algorithm. Furthermore, we take service placement into consideration for diverse training jobs and propose an approximation algorithm. We also analyze that our proposed algorithm can achieve the constant bipartite approximation under many practical situations. We build a test-bed to evaluate the effectiveness of our proposed algorithm in a practical scenario. Extensive simulation results and testing results show that the proposed algorithms can improve the system throughput 56-69 percent compared with the conventional algorithms.},
  archive      = {J_TMC},
  author       = {Min Chen and Haichuan Wang and Zeyu Meng and Hongli Xu and Yang Xu and Jianchun Liu and He Huang},
  doi          = {10.1109/TMC.2020.3045436},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2876-2894},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint data collection and resource allocation for distributed machine learning at the edge},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint channel and link selection in formation-keeping UAV
networks: A two-way consensus game. <em>TMC</em>, <em>21</em>(8),
2861–2875. (<a href="https://doi.org/10.1109/TMC.2020.3048480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is the first to investigate both communication and control in traffic channel (TCH) and control channel (CCH) respectively when considering leader-follower formation keeping in UAV communication networks. In this paper, we analyze the relationship between the mutual interference and information exchange cost, and then formulate the joint channel and link selection problem as a two-way consensus game between CCH and TCH. To characterize the two-way choice of link selection, we creatively propose the generalized two-way consensus equilibrium (GTCE) to capture the stable state. Then, we prove that the formulated game has at least one pure-strategy GTCE which can maximize the UAV communication network utility. A distributed better reply based joint channel and link selection (BRJCLS) algorithm as well as two-dimensional minimum spanning tree (MST) based initialization (TMSTI) algorithm is proposed to achieve the GTCE. Simulation results are presented to show the convergence and effectiveness of the formulated two-way consensus game and proposed algorithms.},
  archive      = {J_TMC},
  author       = {Jiaxin Chen and Ping Chen and Yuhua Xu and Nan Qi and Tao Fang and Chao Dong and Qihui Wu},
  doi          = {10.1109/TMC.2020.3048480},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2861-2875},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint channel and link selection in formation-keeping UAV networks: A two-way consensus game},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HearSmoking: Smoking detection in driving environment via
acoustic sensing on smartphones. <em>TMC</em>, <em>21</em>(8),
2847–2860. (<a href="https://doi.org/10.1109/TMC.2020.3048785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving safety has drawn much public attention in recent years due to the fast-growing number of cars. Smoking is one of the threats to driving safety but is often ignored by drivers. Existing works on smoking detection either work in contact manner or need additional devices. This motivates us to explore the practicability of using smartphones to detect smoking events in driving environment. In this paper, we propose a cigarette smoking detection system, named HearSmoking, which only uses acoustic sensors on smartphones to improve driving safety. After investigating typical smoking habits of drivers, including hand movement and chest fluctuation, we design an acoustic signal to be emitted by the speaker and received by the microphone. We calculate Relative Correlation Coefficient of received signals to obtain movement patterns of hands and chest. The processed data is sent into a trained Convolutional Neural Network for classification of hand movement. We also design a method to detect respiration at the same time. To improve system performance, we further analyse the periodicity of the composite smoking motion. Through extensive experiments in real driving environments, HearSmoking detects smoking events with an average total accuracy of 93.44 percent in real-time.},
  archive      = {J_TMC},
  author       = {Yadong Xie and Fan Li and Yue Wu and Song Yang and Yu Wang},
  doi          = {10.1109/TMC.2020.3048785},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2847-2860},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HearSmoking: Smoking detection in driving environment via acoustic sensing on smartphones},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HDSpeed: Hybrid detection of vehicle speed via acoustic
sensing on smartphones. <em>TMC</em>, <em>21</em>(8), 2833–2846. (<a
href="https://doi.org/10.1109/TMC.2020.3048380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speeding is one of the biggest threatens to road safety. However, facilities like radar detector and speed camera are not deployed everywhere, as roads in some areas like campus and residential areas often lack these facilities. Several solutions either depend on pre-deployed infrastructures, or require additional devices, which motivate us to explore the practicability of using smartphones’ acoustic sensors to detect vehicle speed. In this paper, we propose a Hybrid Detection system for vehicle Speed (HDSpeed). We first investigate the relationship between acoustic pattern and vehicle speed. According to our findings on typical patterns of both electric vehicles (EVs) and gasoline vehicles (GVs), we separately extract different features from the acoustic signals of EVs and GVs. A CNN and an LSTMN are designed for training EV and GV models, respectively. Considering that applying neural networks obtains coarse-grained information like a speed section, we propose a detection method based on active acoustic sensing, in which method HDSpeed calculates the fine-grained speed by detecting the distance change between the smartphone and the passing vehicle. In addition, the previously detected speed section can eliminate interferences of surrounding moving objects. Through extensive experiments in real driving environments, HDSpeed achieves an average error of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$2.17km/h$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Yue Wu and Fan Li and Yadong Xie and Song Yang and Yu Wang},
  doi          = {10.1109/TMC.2020.3048380},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2833-2846},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {HDSpeed: Hybrid detection of vehicle speed via acoustic sensing on smartphones},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FedHome: Cloud-edge based personalized federated learning
for in-home health monitoring. <em>TMC</em>, <em>21</em>(8), 2818–2832.
(<a href="https://doi.org/10.1109/TMC.2020.3045266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-home health monitoring has attracted great attention for the ageing population worldwide. With the abundant user health data accessed by Internet of Things (IoT) devices and recent development in machine learning, smart healthcare has seen many successful stories. However, existing approaches for in-home health monitoring do not pay sufficient attention to user data privacy and thus are far from being ready for large-scale practical deployment. In this paper, we propose FedHome, a novel cloud-edge based federated learning framework for in-home health monitoring, which learns a shared global model in the cloud from multiple homes at the network edges and achieves data privacy protection by keeping user data locally. To cope with the imbalanced and non-IID distribution inherent in user’s monitoring data, we design a generative convolutional autoencoder (GCAE), which aims to achieve accurate and personalized health monitoring by refining the model with a generated class-balanced dataset from user’s personal data. Besides, GCAE is lightweight to transfer between the cloud and edges, which is useful to reduce the communication cost of federated learning in FedHome. Extensive experiments based on realistic human activity recognition data traces corroborate that FedHome significantly outperforms existing widely-adopted methods.},
  archive      = {J_TMC},
  author       = {Qiong Wu and Xu Chen and Zhi Zhou and Junshan Zhang},
  doi          = {10.1109/TMC.2020.3045266},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2818-2832},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {FedHome: Cloud-edge based personalized federated learning for in-home health monitoring},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated learning meets contract theory:
Economic-efficiency framework for electric vehicle networks.
<em>TMC</em>, <em>21</em>(8), 2803–2817. (<a
href="https://doi.org/10.1109/TMC.2020.3045987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel economic-efficiency framework for an electric vehicle (EV) network to maximize the profits (i.e., the amount of money that can be earned) for charging stations (CSs). To that end, we first introduce an energy demand prediction method for CSs leveraging federated learning approaches, in which each CS can train its own energy transactions locally and exchange its learned model with other CSs to improve the learning quality while protecting the CS&#39;s information privacy. Based on the predicted energy demands, each CS can reserve energy from the smart grid provider (SGP) in advance to optimize its profit. Nonetheless, due to the competition among the CSs as well as unknown information from the SGP, i.e., the willingness to transfer energy, we develop a multi-principal one-agent (MPOA) contract-based method to address these issues. In particular, we formulate the CSs’ profit maximization as a non-collaborative energy contract problem under the SGP&#39;s unknown information and common constraints as well as other CSs’ contracts. To solve this problem, we transform it into an equivalent low-complexity optimization problem and develop an iterative algorithm to find the optimal contracts for the CSs. Through simulation results using a real CS dataset, we demonstrate that our proposed framework can enhance energy demand prediction accuracy up to 24.63 percent compared with other machine learning algorithms. Furthermore, our proposed framework can outperform other economic models by 48 and 36 percent in terms of the CSs’ utilities and social welfare (i.e., the total profits of all participating entities) of the network, respectively.},
  archive      = {J_TMC},
  author       = {Yuris Mulya Saputra and Diep N. Nguyen and Dinh Thai Hoang and Thang X. Vu and Eryk Dutkiewicz and Symeon Chatzinotas},
  doi          = {10.1109/TMC.2020.3045987},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2803-2817},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Federated learning meets contract theory: Economic-efficiency framework for electric vehicle networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling fine-grained finger gesture recognition on
commodity WiFi devices. <em>TMC</em>, <em>21</em>(8), 2789–2802. (<a
href="https://doi.org/10.1109/TMC.2020.3045635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture recognition has become increasingly important in human-computer interaction and can support different applications such as smart home, VR, and gaming. Traditional approaches usually rely on dedicated sensors that are worn by the user or cameras that require line of sight. In this paper, we present a fine-grained finger gesture recognition system by using commodity WiFi without requiring user to wear any sensors. Our system takes advantages of the fine-grained Channel State Information available from commodity WiFi devices and the prevalence of WiFi network infrastructures. It senses and identifies subtle movements of finger gestures by examining the unique patterns exhibited in the detailed CSI. We devise environmental noise removal mechanism to mitigate the effect of signal dynamic due to the environment changes. Moreover, we propose to capture the intrinsic gesture behavior to deal with individual diversity and gesture inconsistency. Lastly, we utilize multiple WiFi links and larger bandwidth at 5GHz to achieve finger gesture recognition under multi-user scenario. Our experimental evaluation in different environments demonstrates that our system can achieve over 90 percent recognition accuracy and is robust to both environment changes and individual diversity. Results also show that our system can provide accurate gesture recognition under different scenarios.},
  archive      = {J_TMC},
  author       = {Sheng Tan and Jie Yang and Yingying Chen},
  doi          = {10.1109/TMC.2020.3045635},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2789-2802},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling fine-grained finger gesture recognition on commodity WiFi devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting submerged objects using active acoustics and deep
neural networks: A test case for pelagic fish. <em>TMC</em>,
<em>21</em>(8), 2776–2788. (<a
href="https://doi.org/10.1109/TMC.2020.3044397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate detection and quantification of submerged targets has been recognized as a key challenge in marine exploration, one that traditional census approaches cannot handle efficiently. Here we present a deep learning approach to detect the pattern of a moving fish from the reflections of an active acoustic emitter. To allow for real-time detection, we use a convolutional neural network, which provides the simultaneous labeling of a large buffer of signal samples. This allows to capture the structure of the reflecting signal from the moving target and to separate it from clutter reflections. We evaluate system performance both on synthetic (simulated) data, as well as on real data recorded over 50 sea experiments in a variety of sea conditions. When tested on real signals, the network trained on simulated patterns showed non-trivial detection capabilities, suggesting that transfer learning can be a viable approach in these scenarios, where tagged data is often lacking. However, training the network directly on the real reflections with data augmentation techniques allowed to reach a more favorable precision-recall trade-off, approaching an ideal detection bound. We also evaluate an alternative model based on recurrent neural networks which, despite exhibiting slightly inferior performance, could be applied in scenarios requiring on-line processing of the reflection sequence.},
  archive      = {J_TMC},
  author       = {Alberto Testolin and Dror Kipnis and Roee Diamant},
  doi          = {10.1109/TMC.2020.3044397},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2776-2788},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Detecting submerged objects using active acoustics and deep neural networks: A test case for pelagic fish},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cratus: A lightweight and robust approach for mobile live
streaming. <em>TMC</em>, <em>21</em>(8), 2761–2775. (<a
href="https://doi.org/10.1109/TMC.2020.3048826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Live video applications are getting popular, and content providers widely use adaptive bitrate (ABR) streaming to improve QoE while maintaining low latency. However, users’ increasing preference to watch videos on mobile devices poses great challenges for ABR algorithm due to the dramatically varying cellular network. Existing learn-based ABR algorithms face difficulties to generalize to various network conditions because of their reliance on training traces, and model/rule-based ABR schemes suffer from rebuffering under low latency constraint since they cannot robustly control the buffer occupancy within a small range. To address it, this work proposes Cratus, a lightweight and robust ABR algorithm for mobile live streaming, which achieves high QoE and low latency by accurately regulating the buffer at a small level. To enhance the control ability, Cratus controls the buffer dynamic behavior rather than the buffer occupancy. By using sliding mode control approach, Cratus robustly controls the buffer dynamic and ensures that the buffer occupancy is bounded around the target level regardless of network uncertainties. Trace-driven experiments show that Cratus outperforms existing ABRs: average QoE is increased by 12.3 to 28.6 percent, and rebuffering time is limited within 0.8 &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$s$&lt;/tex-math&gt;&lt;/inline-formula&gt; on average, which is reduced by 53.5 to 92.3 percent.},
  archive      = {J_TMC},
  author       = {Bo Wang and Mingwei Xu and Fengyuan Ren and Chao Zhou and Jianping Wu},
  doi          = {10.1109/TMC.2020.3048826},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2761-2775},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cratus: A lightweight and robust approach for mobile live streaming},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coverage and energy analysis of mobile sensor nodes in
obstructed noisy indoor environment: A voronoi-approach. <em>TMC</em>,
<em>21</em>(8), 2745–2760. (<a
href="https://doi.org/10.1109/TMC.2020.3046184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When deploying a wireless sensor network (WSN) identifying optimal locations for the nodes is challenging, especially so if the environment is either (i) unknown or (ii) obstacle-rich. We proposes BISON (Bio-Inspired Self-Organizing Network), a variant of the Voronoi algorithm to address this challenge. Among the features of the approach are the restrictions placed upon the abilities of the nodes: (i) all information is sensed locally as well as (ii) subject to communication noise. Performance is measured as (i) the percentage of area covered, (ii) the total distance traveled by the nodes, (iii) the cumulative energy consumption and (iv) the uniformity of nodes’ distribution. Obstacle constellations and noise levels are studied systematically and a collision-free recovery strategy for failing nodes is proposed. Results obtained from extensive simulations show the algorithm outperforming previously reported approaches in both, convergence speed, as well as deployment cost.},
  archive      = {J_TMC},
  author       = {Khouloud Eledlebi and Dymitr Ruta and Hanno Hildmann and Fabrice Saffre and Yousof Al Hammadi and A. F. Isakovic},
  doi          = {10.1109/TMC.2020.3046184},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2745-2760},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Coverage and energy analysis of mobile sensor nodes in obstructed noisy indoor environment: A voronoi-approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continuous maneuver control and data capture scheduling of
autonomous drone in wireless sensor networks. <em>TMC</em>,
<em>21</em>(8), 2732–2744. (<a
href="https://doi.org/10.1109/TMC.2021.3049178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to flexible deployment and excellent maneuverability, autonomous drones are regarded as an effective means to enable aerial data capture in large-scale wireless sensor networks with limited to no cellular infrastructure, e.g., smart farming in a remote area. A key challenge in drone-assisted sensor networks is that the autonomous drone’s maneuvering can give rise to buffer overflows at the ground sensors and unsuccessful data collection due to lossy airborne channels. In this paper, we propose a new deep deterministic policy gradient based maneuver control (DDPG-MC) scheme which minimizes the overall data packet loss through online training instantaneous headings and patrol velocities of the drone, and the selection of the ground sensors for data collection in a continuous action space. Moreover, the maneuver control of the drone and communication schedule is formulated as an absorbing Markov chain, where network states consist of battery energy levels, data queue backlogs, timestamps of the data collection, and channel conditions between the ground sensors and the drone. An experience replay memory is utilized onboard at the drone to store the training experiences of the maneuver control and communication schedule at each time step. Numerical results demonstrate that the proposed DDPG-MC achieves 15.2 and 47.6 percent lower packet loss rate than deep Q-learning-based flight control and non-learning scheduling policies, respectively.},
  archive      = {J_TMC},
  author       = {Kai Li and Wei Ni and Falko Dressler},
  doi          = {10.1109/TMC.2021.3049178},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2732-2744},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Continuous maneuver control and data capture scheduling of autonomous drone in wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anonymous authenticated key agreement and group proof
protocol for wearable computing. <em>TMC</em>, <em>21</em>(8),
2718–2731. (<a href="https://doi.org/10.1109/TMC.2020.3048703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable computing has been used in a wide range of applications. But wearable computing often suffers from various security and privacy issues. To solve these issues, many effective authentication schemes have been proposed. However, most of the existing schemes are vulnerable to various known attacks (such as desynchronization attack, privileged-insider attack, and anonymity attack), or require high computation and communication costs, and are not suitable for resource-constrained wearable devices, or simultaneous verification of multiple wearable devices is not supported. Therefore, in this paper, we propose a new anonymous authentication and group proof protocol for wearable computing, which achieves mutual authentication between the wearable device and user and between user and cloud server, and generates a group proof for multiple wearable devices. Further, we extend the Real-Or-Random (ROR) model to support anonymity and group proof, and formally prove that the proposed scheme is provably secure under the extended security model. In addition, the informal security analysis is demonstrated that the proposed scheme is more resilient against known attacks. Finally, compared with some existing schemes, the proposed scheme offers more functionality features and requires less communication and computation costs.},
  archive      = {J_TMC},
  author       = {Yimin Guo and Zhenfeng Zhang and Yajun Guo},
  doi          = {10.1109/TMC.2020.3048703},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2718-2731},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Anonymous authenticated key agreement and group proof protocol for wearable computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AIRTIME: End-to-end virtualization layer for
RAN-as-a-service in future multi-service mobile networks. <em>TMC</em>,
<em>21</em>(8), 2701–2717. (<a
href="https://doi.org/10.1109/TMC.2020.3046535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future mobile networks are envisioned to become multi-service systems, enabling the dynamic deployment of services with vastly different performance requirements, accommodating the needs of diverse service providers. Virtualizing the mobile network infrastructure is of fundamental importance for realizing this vision in a cost-effective manner. While there have been extensive research efforts in virtualization for the mobile core network, virtualization in the radio access network (RAN) is still at an early stage. In this article, we present AIRTIME, a new RAN slicing system that enables the dynamic on-the-fly virtualization of RANs, with the programmability required by service providers to customize any aspect of their virtual RAN to meet their service needs. We present a prototype implementation of AIRTIME and evaluate the: ( i ) capacity to create virtual RANs on-the-fly, ( ii ) performance experienced by slice owners, ( iii ) isolation among multiple virtual RANs sharing the same physical infrastructure, and ( iv ) scalability to accommodate a large number of virtual RANs.},
  archive      = {J_TMC},
  author       = {Maicon Kist and João F. Santos and Diarmuid Collins and Juergen Rochol and Luiz A. DaSilva and Cristiano Bonato Both},
  doi          = {10.1109/TMC.2020.3046535},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2701-2717},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {AIRTIME: End-to-end virtualization layer for RAN-as-a-service in future multi-service mobile networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A near-optimal approach for online task offloading and
resource allocation in edge-cloud orchestrated computing. <em>TMC</em>,
<em>21</em>(8), 2687–2700. (<a
href="https://doi.org/10.1109/TMC.2020.3045471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the explosion of mobile devices and the evolution of wireless communication technologies, novel applications with intensive computation demands and low-latency requirements have arisen. Edge computing has been proposed as an extension of cloud computing, which moves computation workloads from remote cloud to network edge. Cooperating edge computing and cloud computing can significantly reduce the latency of computation tasks. However, considering the heterogeneity and stochastic arrivals of tasks and the limited computation and communication resources on the edge, task offloading and resource allocation are two joint crucial problems in an edge-cloud orchestrated computing system. In this paper, we propose an online task offloading and resource allocation approach for edge-cloud orchestrated computing, with the aim to minimize the average latency of tasks over time. We first build system models to analyze the latency and energy consumption incurred under different computing modes and formally formulate the joint problem as a mixed-integer optimal decision problem. Then, we employ Lyapunov optimization and duality theory to decompose the problem into a set of subproblems, which can be solved in a semi-decentralized way. We also formally analyze that our approach can achieve near-optimal performance. Extensive simulations are conducted to verify the superiority of our approach.},
  archive      = {J_TMC},
  author       = {Tong Liu and Lu Fang and Yanmin Zhu and Weiqin Tong and Yuanyuan Yang},
  doi          = {10.1109/TMC.2020.3045471},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2687-2700},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A near-optimal approach for online task offloading and resource allocation in edge-cloud orchestrated computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A flexible enhanced throughput and reduced overhead (FETRO)
MAC protocol for ETSI SmartBAN. <em>TMC</em>, <em>21</em>(8), 2671–2686.
(<a href="https://doi.org/10.1109/TMC.2020.3047596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart body area networks (SmartBAN) is an emerging wireless body area networks (WBAN) standard proposed by the European Telecommunications Standards Institute (ETSI). This paper first examines the potential of SmartBAN medium access control (MAC) layer with scheduled access to support a myriad of WBAN applications, having diverse data rate requirements. Extra scheduled access slots can be allocated to high date rate sensor nodes for managing their data rate requirements. High data rate sensor nodes can also be re-assigned to use the available time slots of low data rate sensor nodes in Inter-Beacon Interval (IBI) by the central hub. But these two schemes incorporate different physical (PHY) and MAC layer overheads related to frame transmission, frame acknowledgement and slot re-assignment. This redundant overhead transmission results in high overhead energy consumption and reduced effective throughput. Therefore, an innovative and flexible enhanced throughput and reduced overhead (FETRO) MAC protocol for scheduled access is proposed in this article. In the proposed scheme, the sensor node data rate requirements are considered while assigning the scheduled access slot duration by allowing minimal changes in the base-line standard implementation. This infers the provision of scheduled access slots with variable slot durations within an IBI. We also evaluate the existing techniques of extra slot allocation and slot re-assignment in SmartBAN as well as the proposed FETRO MAC protocol with variable slot length. The proposed FETRO MAC scheme results in optimizing both the overall throughput and normalized overhead energy consumption per kilo bits per second (Kbps). Additionally, the impact of various WBAN channel models over these throughput management approaches is also investigated. The proposed FETRO MAC protocol with variable slot duration gives an average reduction of 65.5 and 59.16 percent, respectively, in the hub and nodes normalized overhead energy consumption per Kbps outcomes, as compared to the de-facto SmartBAN MAC scheduling strategies.},
  archive      = {J_TMC},
  author       = {Rida Khan and Muhammad Mahtab Alam and Mohsen Guizani},
  doi          = {10.1109/TMC.2020.3047596},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {8},
  number       = {8},
  pages        = {2671-2686},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A flexible enhanced throughput and reduced overhead (FETRO) MAC protocol for ETSI SmartBAN},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VrAIn: Deep learning based orchestration for computing and
radio resources in vRANs. <em>TMC</em>, <em>21</em>(7), 2652–2670. (<a
href="https://doi.org/10.1109/TMC.2020.3043100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The virtualization of radio access networks (vRAN) is the last milestone in the NFV revolution. However, the complex relationship between computing and radio dynamics make vRAN resource control particularly daunting. We present vrAIn , a resource orchestrator for vRANs based on deep reinforcement learning. First, we use an autoencoder to project high-dimensional context data (traffic and channel quality patterns) into a latent representation. Then, we use a deep deterministic policy gradient (DDPG) algorithm based on an actor-critic neural network structure and a classifier to map contexts into resource control decisions. We have evaluated vrAIn experimentally, using an open-source LTE stack over different platforms, and via simulations over a production RAN. Our results show that: ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathrm{i}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) vrAIn provides savings in computing capacity of up to 30 percent over CPU-agnostic methods; ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathrm{ii}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) it improves the probability of meeting QoS targets by 25 percent over static policies; ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathrm{iii}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) upon computing capacity under-provisioning, vrAIn improves throughput by 25 percent over state-of-the-art schemes; and ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathrm{iv}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) it performs close to an optimal offline oracle. To our knowledge, this is the first work that thoroughly studies the computational behavior of vRANs and the first approach to a model-free solution that does not need to assume any particular platform or context.},
  archive      = {J_TMC},
  author       = {Jose A. Ayala-Romero and Andres Garcia-Saavedra and Marco Gramaglia and Xavier Costa-Pérez and Albert Banchs and Juan J. Alcaraz},
  doi          = {10.1109/TMC.2020.3043100},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2652-2670},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {VrAIn: Deep learning based orchestration for computing and radio resources in vRANs},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VeMo: Enable transparent vehicular mobility modeling at
individual levels with full penetration. <em>TMC</em>, <em>21</em>(7),
2637–2651. (<a href="https://doi.org/10.1109/TMC.2020.3044244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and predicting real-time vehicle mobility patterns on highways are essential to address traffic congestion and respond to the emergency. However, almost all existing works (e.g., based on cellphones, onboard devices, or traffic cameras) suffer from high costs, low penetration rates, or only aggregate results. To address these drawbacks, we utilize Electric Toll Collection systems (ETC) as a large-scale sensor network and design a system called VeMo to transparently model and predict vehicle mobility at the individual level with a full penetration rate. Our novelty is how we address uncertainty issues (i.e., unknown routes and speeds) due to sparse implicit ETC data based on a key data-driven insight, i.e., individual driving behaviors are strongly correlated with crowds of drivers under certain spatiotemporal contexts and can be predicted by combining both personal habits and context information. We evaluate VeMo with (i) a large-scale ETC system with tracking devices at 773 highway entrances and exits capturing more than 2 million vehicles every day; (ii) a fleet consisting of 114 thousand vehicles with GPS data as ground truth. Compared with state-of-the-art benchmark mobility models, the experimental results show that VeMo outperforms them by 10 percent on average.},
  archive      = {J_TMC},
  author       = {Yu Yang and Xiaoyang Xie and Zhihan Fang and Fan Zhang and Yang Wang and Desheng Zhang},
  doi          = {10.1109/TMC.2020.3044244},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2637-2651},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {VeMo: Enable transparent vehicular mobility modeling at individual levels with full penetration},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UltraGesture: Fine-grained gesture sensing and recognition.
<em>TMC</em>, <em>21</em>(7), 2620–2636. (<a
href="https://doi.org/10.1109/TMC.2020.3037241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rising of AR/VR technology and miniaturization of mobile devices, gesture recognition is becoming increasingly popular in the research area of human-computer interaction. Some pioneer ultrasound-based gesture recognition systems have been proposed. However, they mostly rely on low-resolution Doppler Effect, with the focus on whole hand motion and fail to deal with minor finger motions. This paper is to present UltraGesture, an ultrasonic finger motion perception and recognition system based on Channel Impulse Response (CIR). CIR measurements can provide with 7 mm resolution, which is sufficient for minor finger motion recognition. UltraGesture encapsulates CIR measurements into image, and builds a Convolutional Neural Network model to classify these images into different categories corresponding to distinct gestures. Furthermore, we use a sliding-window based method to improve accuracy and reduce response latency. UltraGesture can run on the already existed commercial speakers and microphones on most mobile devices without any hardware modification. Our results demonstrate that UltraGesture can achieve an average accuracy ofgreater than 99 percent for 12 gestures including finger click and rotation.},
  archive      = {J_TMC},
  author       = {Kang Ling and Haipeng Dai and Yuntang Liu and Alex X. Liu and Wei Wang and Qing Gu},
  doi          = {10.1109/TMC.2020.3037241},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2620-2636},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {UltraGesture: Fine-grained gesture sensing and recognition},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The case for FPGA-based edge computing. <em>TMC</em>,
<em>21</em>(7), 2610–2619. (<a
href="https://doi.org/10.1109/TMC.2020.3041781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge Computing has emerged as a new computing paradigm dedicated for mobile performance enhancement and energy efficiency purposes. Specifically, it benefits today’s interactive applications on power-constrained devices by offloading compute-intensive tasks to the edge nodes in close proximity. Meanwhile, FPGA is well known for its excellence in accelerating (domain-specific) compute-intensive tasks such as deep learning algorithms in a high performance and energy-efficient manner due to its hardware-customizable nature. In this paper, we make the first attempt to leverage and combine the advantages of these two, and proposed a new network-assisted computing model, namely FPGA-based edge computing. As a case study, we choose three computer vision (CV)-based mobile interactive applications, and implement their back-end computation engines on FPGA. By deploying such application-customized accelerator modules for computation offloading at the network edge, we experimentally demonstrate that this approach can effectively reduce response time for the applications and energy consumption for the entire system in comparison with traditional CPU-based edge/cloud offloading approach.},
  archive      = {J_TMC},
  author       = {Chenren Xu and Shuang Jiang and Guojie Luo and Guangyu Sun and Ning An and Gang Huang and Xuanzhe Liu},
  doi          = {10.1109/TMC.2020.3041781},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2610-2619},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {The case for FPGA-based edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sum-rate maximization of uplink rate splitting multiple
access (RSMA) communication. <em>TMC</em>, <em>21</em>(7), 2596–2609.
(<a href="https://doi.org/10.1109/TMC.2020.3037374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of maximizing the wireless users’ sum-rate for uplink rate splitting multiple access (RSMA) communications is studied. In the considered model, the message intended for a single user is split into two sub-messages with separate transmit power and the base station (BS) uses a successive decoding technique to decode the received messages. To maximize each user’s transmission rate, the users must adjust their transmit power and the BS must determine the decoding order of the messages transmitted from the users to the BS. This problem is formulated as a sum-rate maximization problem with proportional rate constraints by adjusting the users’ transmit power and the BS’s decoding order. However, since the decoding order variable in the optimization problem is discrete, the original maximization problem with transmit power and decoding order variables can be transformed into a problem with only the rate splitting variable. Then, the optimal rate splitting of each user is determined. Given the optimal rate splitting of each user and a decoding order, the optimal transmit power of each user is calculated. Next, the optimal decoding order is determined by an exhaustive search method. To further reduce the complexity of the optimization algorithm used for sum-rate maximization in RSMA, a user pairing based algorithm is introduced, which enables two users to use RSMA in each pair and also enables the users in different pairs to be allocated with orthogonal frequency. For comparisons, the optimal sum-rate maximizing solutions with proportional rate constraints are obtained for non-orthogonal multiple access (NOMA), frequency division multiple access (FDMA), and time division multiple access (TDMA). Simulation results show that RSMA can achieve up to 10.0, 22.2, and 81.2 percent gains in terms of sum-rate compared to NOMA, FDMA, and TDMA.},
  archive      = {J_TMC},
  author       = {Zhaohui Yang and Mingzhe Chen and Walid Saad and Wei Xu and Mohammad Shikh-Bahaei},
  doi          = {10.1109/TMC.2020.3037374},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2596-2609},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Sum-rate maximization of uplink rate splitting multiple access (RSMA) communication},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust offloading scheduling for mobile edge computing.
<em>TMC</em>, <em>21</em>(7), 2581–2595. (<a
href="https://doi.org/10.1109/TMC.2020.3043000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of R obust offloading sch E duling for mob I le edge computi N g (REIN), i.e., in the presence of uncertain offloading failures, how to determine an offloading schedule to minimize the overall latency of all computation-intensive tasks. We mathematically formulate the problem in the form of min-max robust optimization, based on the twice equivalent transformations of the scheduling problem that originally does not consider robustness. REIN is challenging to solve because the min-max robust objective is computationally intractable with existing approaches, and the monotonicity of the objective function is uncertain, even if we transform the objective into the popular max-min form by introducing an appropriate constant upper bound. To solve the above challenges, we first construct a constant upper bound and a monotone modular function to approximate the transformed max-min objective function, and then propose a computationally feasible solution with provable performance bound. Moreover, given the fact of the weak computation ability of users in practical, we construct a tighter constant upper bound and a monotone submodular approximation function, and propose a feasible solution with possibly improved performance bound. Extensive results show that, given a maximum number of offloading failures, our proposed algorithms outperform three benchmark algorithms, and approach the optimum at small time costs.},
  archive      = {J_TMC},
  author       = {Yuben Qu and Haipeng Dai and Fan Wu and Dongyu Lu and Chao Dong and Shaojie Tang and Guihai Chen},
  doi          = {10.1109/TMC.2020.3043000},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2581-2595},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust offloading scheduling for mobile edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RFEye in the sky. <em>TMC</em>, <em>21</em>(7), 2566–2580.
(<a href="https://doi.org/10.1109/TMC.2020.3038886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce RFEye , a generalized technique to locate signals independent of the waveform, using a single Unmanned Aerial Vehicle (UAV) equipped with only one omnidirectional antenna. This is achieved by acquiring signals from uncoordinated positions within a sphere of 1-meter radius at two nearby locations and formulating an asynchronous, distributed receiver beamforming at the UAV to compute the Direction of Arrival (DoA) from the unknown transmitter. The proposed method includes four steps: 1) Blind detection and extraction of unique signature in the signal to be localized, 2) Asynchronous signal acquisition and conditioning, 3) DoA calculation by creating a virtual distributed antenna array at UAV and 4) Obtaining position fix of emitter using DoA from two locations. These steps are analyzed for various sources of error, computational complexity and compared with widely used signal subspace-based DoA estimation algorithms. RFEye is implemented using an Intel-Aero UAV, equipped with a USRP B205 software-defined radio to acquire signals from a ground emitter. Practical outdoor experiments show that RFEye achieves a median accuracy of 1.03m in 2D and 2.5m in 3D for Wi-Fi, and 1.15m in 2D and 2.7m in 3D for LoRa (Long Range) waveforms, and is robust to external factors like wind and UAV position errors.},
  archive      = {J_TMC},
  author       = {Maqsood Ahamed Abdul Careem and Jorge Gomez and Dola Saha and Aveek Dutta},
  doi          = {10.1109/TMC.2020.3038886},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2566-2580},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RFEye in the sky},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reducing the cost of consistency: Performance improvements
in next generation cellular networks with optimal resource reallocation.
<em>TMC</em>, <em>21</em>(7), 2546–2565. (<a
href="https://doi.org/10.1109/TMC.2020.3039757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consistent rate provisioning is one of the most prominent features envisioned for the next generation of cellular networks (5G), as a pivotal condition to an improved user experience, especially for services like live video streaming, online gaming, etc. However, prior research has shown that providing a consistent rate, while very beneficial to the QoS of mobile users, can result in a severe underutilization of the available resources, leading to a very inefficient operation of cellular networks. One of the ways of increasing resource allocation efficiency is by reallocating the unused resources to the same users. To this end, in this paper we quantify the benefits offered by different reallocation policies both for the mobile operator and users. We then determine, based on theoretical analysis, the optimal policies to follow for different optimization objectives. First, we focus on increasing the efficiency (total throughput) of the cellular network operator in a cell and then on providing proportional and max-min fairness to mobile users. The analysis captures the correlation of the user&#39;s channel quality in contiguous frames by using Markov chains. The outcomes of the analysis hold both for users that are always active in a given cell, and for users whose activity is intermittent. We also analyze the case with two classes of consistent users: premium and regular . The theoretical analysis is validated by extensive synthetic simulations and simulations run on real-life traces. We also compare the performance of different reallocation policies with that of a benchmark and show that the optimal reallocation policy for a given objective improves the performance by at least 35 percent.},
  archive      = {J_TMC},
  author       = {Fidan Mehmeti and Thomas F. La Porta},
  doi          = {10.1109/TMC.2020.3039757},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2546-2565},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reducing the cost of consistency: Performance improvements in next generation cellular networks with optimal resource reallocation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ReCARL: Resource allocation in cloud RANs with deep
reinforcement learning. <em>TMC</em>, <em>21</em>(7), 2533–2545. (<a
href="https://doi.org/10.1109/TMC.2020.3044282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud radio access networks (CRANs) have become a key enabling technique for the next generation wireless communications. Resource allocation in CRANs still needs to be further improved to reach the objective of minimizing power consumption and meeting demands of wireless users over a long period. Inspired by the success of Deep Reinforcement Learning (DRL) on solving complicated control problems, we present a novel framework, ReCARL , for power-efficient resource allocation in CRANs with deep reinforcement learning. Specifically, we define the state space, action space and reward function for the DRL agent, apply a deep neural network (DNN) to approximating the action-value function, and formally formulate the resource allocation problem (in each decision epoch) as a convex optimization problem. Under ReCARL, we propose two different DRL agents: one has a regular DNN structure trained with the basic deep Q-learning method ( ReCARL-Basic ); while the other has a context-aware DNN structure trained with a hybrid deep Q-learning method ( ReCARL-Hybrid ). We evaluated the performance of ReCARL along with the two DRL agents by comparing them with two widely-used baselines via extensive simulation. The simulation results show that ReCARL achieves significant power savings while meeting user demands, and it can well handle highly dynamic cases.},
  archive      = {J_TMC},
  author       = {Zhiyuan Xu and Jian Tang and Chengxiang Yin and Yanzhi Wang and Guoliang Xue and Jing Wang and M. Cenk Gursoy},
  doi          = {10.1109/TMC.2020.3044282},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2533-2545},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ReCARL: Resource allocation in cloud RANs with deep reinforcement learning},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Privacy-preserving incentive mechanisms for truthful data
quality in data crowdsourcing. <em>TMC</em>, <em>21</em>(7), 2518–2532.
(<a href="https://doi.org/10.1109/TMC.2020.3040138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data crowdsourcing is a promising paradigm that leverages the “wisdom” of a potentially large crowd of “workers” in many application domains. Quality-aware crowdsourcing is beneficial as it makes use of workers’ data quality to perform task allocation and data aggregation. However, a worker’s quality and data can be her private information that she may have incentive to misreport to the crowdsourcing requester. Moreover, a worker’s quality and data can depend on her sensitive information (e.g., location), which can be inferred from the outcomes of task allocation and data aggregation by an adversary. In this paper, we devise Privacy-preserving crowdsourcing mechanisms for truthful Data Quality Elicitation (PDQE). In these mechanisms, we design differentially private task allocation and data aggregation algorithms to prevent the inference of a worker’s quality and data from the outcomes of these algorithms. In the meantime, the mechanisms also incentivize workers to truthfully report their quality and data and make desired efforts. We first focus on the mechanisms for a single task (S-PDQE) and then extend it to the case of multiple tasks (M-PDQE). We further show that both the mechanisms achieve a bounded performance gap compared to the optimal strategy. We evaluate the proposed mechanisms using simulations based on real-world data, which corroborate their highly-desired properties on truthful data quality elicitation, data accuracy and privacy protection.},
  archive      = {J_TMC},
  author       = {Yuxi Zhao and Xiaowen Gong and Xu Chen},
  doi          = {10.1109/TMC.2020.3040138},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2518-2532},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Privacy-preserving incentive mechanisms for truthful data quality in data crowdsourcing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Online bitrate selection for viewport adaptive 360-degree
video streaming. <em>TMC</em>, <em>21</em>(7), 2506–2517. (<a
href="https://doi.org/10.1109/TMC.2020.3038710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {360-degree video streaming provides users with immersive experience by letting users determine their field-of-views (FoVs) in real time. To efficiently utilize the limited bandwidth resources, recent works have proposed a viewport adaptive 360-degree video streaming model by exploiting the bitrate adaptation in spatial and temporal domains. In this paper, under this video streaming model, we propose an online bitrate selection algorithm to enhance the user’s quality of experience (QoE). This is achieved by characterizing the user’s personalized FoV and real-time downloading capacity in an online fashion. We address the unknown user-specific FoV by introducing the reference FoV and design an online bitrate selection algorithm to learn the difference between the user’s actual FoV and the reference FoV. We prove that as the number of video segments increases, the performance of the proposed online algorithm approaches the optimal performance asymptotically, with a bounded error. We perform trace-driven simulations with real-world datasets. Simulation results show that under the scenario where the available video bitrates are relatively high, our proposed algorithm can improve the user’s viewing quality level between &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$4.2\!-\!29.4$&lt;/tex-math&gt;&lt;/inline-formula&gt; percent and reduce the average intra-segment quality switch by at least 12.4 percent when compared with several existing methods.},
  archive      = {J_TMC},
  author       = {Ming Tang and Vincent W.S. Wong},
  doi          = {10.1109/TMC.2020.3038710},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2506-2517},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online bitrate selection for viewport adaptive 360-degree video streaming},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online altitude control and scheduling policy for minimizing
AoI in UAV-assisted IoT wireless networks. <em>TMC</em>, <em>21</em>(7),
2493–2505. (<a href="https://doi.org/10.1109/TMC.2020.3042925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers unmanned aerial vehicle (UAV) assisted Internet of Things (IoT) networks, where low resource IoT devices periodically sample a stochastic process and need to upload more recent information to a Base Station (BS). Among the myriad of applications, there is a need for timely delivery of data (for example, status-updates) before the data becomes outdated and loses its value. Since transmission capabilities of IoT devices are limited, it may not always be feasible to transmit over one hop transmission to the BS. To address this challenge, UAVs with virtual queues are deployed as middle layer between IoT devices and the BS to relay recent information over unreliable channels. In the absence of channel conditions, the optimal online scheduling policy is investigated as well as dynamic UAV altitude control that maintains a fresh status of information at the BS. The objective of this paper is to minimize the Expected Weighted Sum Age of Information (EWSA) for IoT devices. First, the problem is formulated as an optimization problem that is however generally hard to solve. Second, an online model free Deep Reinforcement Learning (DRL) is proposed, where the deployed UAV obtains instantaneous channel state information (CSI) in real time along with any adjustment to its deployment altitude. Third, we formulate the online problem as a Markov Decision Process (MDP) and Proximal Policy Optimization (PPO) algorithm, which is a highly stable state-of-the-art DRL algorithm, is leveraged to solve the formulated problem. Finally, extensive simulations are conducted to verify findings and comprehensive comparisons with other baseline approaches are provided to demonstrate the effectiveness of the proposed design.},
  archive      = {J_TMC},
  author       = {Moataz Samir and Chadi Assi and Sanaa Sharafeddine and Ali Ghrayeb},
  doi          = {10.1109/TMC.2020.3042925},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2493-2505},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online altitude control and scheduling policy for minimizing AoI in UAV-assisted IoT wireless networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the accuracy and efficiency of sensing and localization
for robotics. <em>TMC</em>, <em>21</em>(7), 2480–2492. (<a
href="https://doi.org/10.1109/TMC.2020.3038146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent robotic applications, a critical need is to simultaneously detect communication (emission state) and estimate its trajectory. Whilst wireless sensor observations are useful, they are often uncertain due to the stochastic communication bursts and robot mobility. Over-sampling the information environment can incur excessive radio interference and energy usage. Therefore, one challenge is how to improve the efficiency of sensing under sparse and dynamic information, and make accurate inference on the robot&#39;s location. Here, we design a novel mixed detection and estimation (MDE) scheme to enhance both the accuracy and the efficiency by exploiting the mobility pattern correlations. Relying on a Markov state-space model, dynamic behaviors of robot&#39;s communication state and movement are formulated. A two-stage sequential Bayesian scheme, premised on random finite set (RFS), is developed to detect and estimate the involved unknown states. Specifically, in order to counteract the probability likelihood disappearance (caused by no information emission) and improve robustness to ambient noise, a sequential pre-filtering technique is designed, which can refine local observations and thereby significantly improve the accuracy of the system. We validate the proposed MDE scheme via both theoretical analysis and numerical simulations, demonstrating it would improve both the detection and estimation accuracy and efficiency.},
  archive      = {J_TMC},
  author       = {Zhuangkun Wei and Bin Li and Weisi Guo and Wenxiu Hu and Chenglin Zhao},
  doi          = {10.1109/TMC.2020.3038146},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2480-2492},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On the accuracy and efficiency of sensing and localization for robotics},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network-aware recommendations in the wild: Methodology,
realistic evaluations, experiments. <em>TMC</em>, <em>21</em>(7),
2466–2479. (<a href="https://doi.org/10.1109/TMC.2020.3042606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint caching and recommendation has been recently proposed as a new paradigm for increasing the efficiency of mobile edge caching. Early findings demonstrate significant gains for the network performance. However, previous works evaluated the proposed schemes exclusively on simulation environments. Hence, it still remains uncertain whether the claimed benefits would change in real settings. In this paper, we propose a methodology that enables to evaluate joint network and recommendation schemes in real content services by only using publicly available information. We apply our methodology to the YouTube service, and conduct extensive measurements to investigate the potential performance gains. Our results show that significant gains can be achieved in practice; e.g., 8 to 10 times increase in the cache hit ratio from cache-aware recommendations. Finally, we build an experimental testbed and conduct experiments with real users; we make available our code and datasets to facilitate further research. To our best knowledge, this is the first realistic evaluation (over a real service, with real measurements and user experiments) of the joint caching and recommendations paradigm. Our findings provide experimental evidence for the feasibility and benefits of this paradigm, validate assumptions of previous works, and provide insights that can drive future research.},
  archive      = {J_TMC},
  author       = {Savvas Kastanakis and Pavlos Sermpezis and Vasileios Kotronis and Daniel Menasché and Thrasyvoulos Spyropoulos},
  doi          = {10.1109/TMC.2020.3042606},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2466-2479},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Network-aware recommendations in the wild: Methodology, realistic evaluations, experiments},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Minimizing the longest tour time among a fleet of UAVs for
disaster area surveillance. <em>TMC</em>, <em>21</em>(7), 2451–2465. (<a
href="https://doi.org/10.1109/TMC.2020.3038156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the employment of multiple Unmanned Aerial Vehicles (UAVs) to monitor Points of Interests (PoIs) in a disaster area, e.g., collapsed buildings after an earthquake, where the UAVs can take photos and videos for the people trapped at PoIs, because such valuable information is imperative to make rescue decisions. Unlike most existing studies that ignored the monitoring time of PoIs and simply minimized the longest flying distance among the UAVs, we observe that it takes time to monitor the PoIs. Then, it is possible that the flying distance of a UAV in its flying tour may not be too long, the tour however contains many densely-located PoIs. Therefore, it will take a very long time for the UAV to monitor the PoIs in its tour. In this paper, we first formulate a problem of finding flying tours for &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$K$&lt;/tex-math&gt;&lt;/inline-formula&gt; given UAVs to collaboratively monitor PoIs in a disaster area, such that the maximum spent time of the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$K$&lt;/tex-math&gt;&lt;/inline-formula&gt; UAVs among their tours is minimized, where the spent time of a UAV in its tour consists of the flying time and the PoI monitoring time. We then propose a novel &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$5\frac{1}{3}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation algorithm for the problem, improving the best approximation ratio 6 so far for the problem of minimizing the longest flying distance among the UAVs. In addition, we extend the proposed algorithm to the case that each UAV may not be able to monitor all PoIs assigned to it, due to its limited maximum flying time (e.g., 30 minutes), and the UAV must return to its depot to replace its battery. We finally evaluate the performance of the proposed algorithms via simulation environments, and experimental results show that the proposed algorithms are very promising. Especially, the maximum spent times of the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$K$&lt;/tex-math&gt;&lt;/inline-formula&gt; UAVs in their tours by the proposed algorithms are up to 30 percent shorter than those by existing algorithms. In addition, the empirical approximation ratios of the proposed algorithms are no more than 2.4, which are much smaller than their theoretical approximation ratios that are at least &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$5\frac{1}{3}$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Qing Guo and Jian Peng and Wenzheng Xu and Weifa Liang and Xiaohua Jia and Zichuan Xu and Yanbin Yang and Minghui Wang},
  doi          = {10.1109/TMC.2020.3038156},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2451-2465},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Minimizing the longest tour time among a fleet of UAVs for disaster area surveillance},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Location privacy protection in vehicle-based spatial
crowdsourcing via geo-indistinguishability. <em>TMC</em>,
<em>21</em>(7), 2436–2450. (<a
href="https://doi.org/10.1109/TMC.2020.3037911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, vehicles have been increasingly adopted in many spatial crowdsourcing (SC) applications. Similar to other SC applications, location privacy is of great concern to vehicle workers as they are required to disclose their own location to servers to facilitate the service utilities. Traditional location privacy protection mechanisms cannot be applied to vehicle-based SC since they assume workers’ mobility on a 2-dimensional plane without considering the network-constrained mobility features of vehicles. Accordingly, in this paper, we aim at addressing issues related to Vehicle-based spatial crowdsourcing Location Privacy (VLP) over road networks. Our objective is to design a location obfuscation strategy to minimize the quality loss due to obfuscation with geo-indistinguishability satisfied. Considering the computational complexity of VLP, by resorting to discretization, we first approximate VLP to a linear programming problem that can be solved by well-developed approaches. To further improve the time-efficiency, we conduct constraint reduction for VLP by exploiting key features of geo-indistinguishability in road networks and problem decomposition based on VLP’s constraint structure. Finally, we carry out both trace-driven simulation and real-world experiments, where our experimental results demonstrate the superiority of our approach over a known state-of-the-art location obfuscation strategy in terms of both quality-of-service and privacy.},
  archive      = {J_TMC},
  author       = {Chenxi Qiu and Anna Squicciarini and Ce Pang and Ning Wang and Ben Wu},
  doi          = {10.1109/TMC.2020.3037911},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2436-2450},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Location privacy protection in vehicle-based spatial crowdsourcing via geo-indistinguishability},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint server selection, cooperative offloading and handover
in multi-access edge computing wireless network: A deep reinforcement
learning approach. <em>TMC</em>, <em>21</em>(7), 2421–2435. (<a
href="https://doi.org/10.1109/TMC.2020.3043736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-access edge computing (MEC) is the key enabling technology that supports compute-intensive applications in 5G networks. By deploying powerful servers at the edge of wireless networks, MEC can extend the computational capacity of the mobile devices by migrating compute-intensive tasks to the MEC servers. In this paper, we consider a multi-user MEC wireless network in which multiple mobile devices can associate and perform computation offloading via wireless channels to MEC servers attached to the base stations (BSs). The decision whether the computation task is executed locally at the user device or to be offloaded for MEC server execution should be adaptive to the time-varying network dynamics. Taking into account the dynamic of the environment, we propose a deep reinforcement learning (DRL) based approach to solve the formulated nonconvex problem of minimizing computation cost in terms of total delay. However, real-world networks tend to have a large number of users and MEC servers involving large numbers of different actions (continuous and discrete), where evaluating the combination of every possible action becomes impractical. Therefore, conventional DRL methods may be difficult or even impossible to directly apply to the proposed model. Based on the recursive decomposition of the action space available to each state, we propose a DRL-based algorithm for joint server selection, cooperative offloading, and handover in a multi-access edge wireless network. Numerical results show that the proposed DRL based algorithm significantly outperforms the traditional Q-learning method and local computation in terms of task success rate and total delay.},
  archive      = {J_TMC},
  author       = {Tai Manh Ho and Kim-Khoa Nguyen},
  doi          = {10.1109/TMC.2020.3043736},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2421-2435},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint server selection, cooperative offloading and handover in multi-access edge computing wireless network: A deep reinforcement learning approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Human activity recognition across scenes and categories
based on CSI. <em>TMC</em>, <em>21</em>(7), 2411–2420. (<a
href="https://doi.org/10.1109/TMC.2020.3041756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activity recognition based on channel state information (CSI) plays an increasingly important role in human computer interaction. However most CSI activity recognition systems need to re-collect a large amount of samples and retrain model when they are used in new environments or recognize new types of activities, which greatly reduces the practicality of CSI activity recognition. To address this problem we design an adaptable CSI activity recognition system based on meta-learning, which only needs to fine-tune model with very little train effort when it is used in new environments or recognize new types of activities. Specifically, we first use meta-learning algorithm to get the pre-trained model that adapts to task distribution, when the environment or activity category changes, our system doesn&#39;t need to retrain the model and has maximal performance after updates the pre-trained model through one or more gradient steps computed with a small amount of samples from new activities. To prevent the loss of CSI time information after feature extraction with multi-layer CNN, we add time encoding on CSI data as the input of CNN neural network. Considering that CSI data may be labeled incorrectly during labeling process, we improve categorical cross entropy loss(CCE) to enhance the system&#39;s robustness to these mislabeled data. We test our system on the gesture dataset and the body activity dataset, and the experimental results show that our system achieves average accuracy of 72 percent with one sample of each new activity and 89.6 percent with five samples of each new activity.},
  archive      = {J_TMC},
  author       = {Yong Zhang and Xinyuan Wang and Yujie Wang and Hongxin Chen},
  doi          = {10.1109/TMC.2020.3041756},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2411-2420},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Human activity recognition across scenes and categories based on CSI},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hear sign language: A real-time end-to-end sign language
recognition system. <em>TMC</em>, <em>21</em>(7), 2398–2410. (<a
href="https://doi.org/10.1109/TMC.2020.3038303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language recognition (SLR) bridges the communication gap between the hearing-impaired and the ordinary people. However, existing SLR systems either cannot provide continuous recognition or suffer from low recognition accuracy due to the difficulty of sign segmentation and the insufficiency of capturing both finger and arm motions. The latest system, SignSpeaker, has a significant limit in recognizing two-handed signs with only one smartwatch. To address these problems, this paper designs a novel real-time end-to-end SLR system, called DeepSLR, to translate sign language into voices to help people “hear” sign language. Specifically, two armbands embedded with an IMU sensor and multi-channel sEMG sensors are attached on the forearms to capture both coarse-grained arm movements and fine-grained finger motions. We propose an attention-based encoder-decoder model with a multi-channel convolutional neural network (CNN) to realize accurate, scalable, and end-to-end continuous SLR without sign segmentation. We have implemented DeepSLR on a smartphone and evaluated its effectiveness through extensive evaluations. The average word error rate of continuous sentence recognition is 10.8 percent, and it takes less than 1.1s for detecting signals and recognizing a sentence with 4 sign words, validating the recognition efficiency and real-time ability of DeepSLR in real-world scenarios.},
  archive      = {J_TMC},
  author       = {Zhibo Wang and Tengda Zhao and Jinxin Ma and Hongkai Chen and Kaixin Liu and Huajie Shao and Qian Wang and Ju Ren},
  doi          = {10.1109/TMC.2020.3038303},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2398-2410},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Hear sign language: A real-time end-to-end sign language recognition system},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Economics of mobile data trading market. <em>TMC</em>,
<em>21</em>(7), 2385–2397. (<a
href="https://doi.org/10.1109/TMC.2020.3040388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To exploit users’ heterogeneous data demands, several mobile network operators worldwide have launched the mobile data trading markets, where users can trade mobile data quota with each other. In this paper, we aim to understand the importance of data trading market (DTM) by studying the users’ operator selection and trading decisions, and analyzing the operator’s profit maximizing strategy. We model the interactions between the mobile operator and the users as a three-stage Stackelberg game. In Stage I, the operator chooses the operation fee imposed on sellers to maximize its profit. In Stage II, each user chooses his operator. In Stage III, each DTM user chooses his trading decisions. We derive the closed-form expression of the unique Nash equilibrium (NE) in Stages II and III, where every user proposes the same price such that the total demand matches with the total supply. We further show that the Stage I’s problem is convex and compute the optimal operation fee. Our analysis and numerical results show that an operator with a small initial market share can increase its profit by proposing a DTM, which is in line with the real-world situation in Hong Kong.},
  archive      = {J_TMC},
  author       = {Junlin Yu and Man Hon Cheung and Jianwei Huang},
  doi          = {10.1109/TMC.2020.3040388},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2385-2397},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Economics of mobile data trading market},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepMM: Deep learning based map matching with data
augmentation. <em>TMC</em>, <em>21</em>(7), 2372–2384. (<a
href="https://doi.org/10.1109/TMC.2020.3043500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental component in map service, map matching is of great importance for many trajectory-based applications, e.g., route optimization, traffic scheduling, and fleet management. In practice, Hidden Markov Model and its variants are widely used to provide accurate and efficient map matching service. However, HMM-based methods fail to utilize the knowledge (e.g., the mobility pattern) of enormous trajectory big data, which are useful for intelligent map matching. Furthermore, with many following-up works, they are still easily influenced by the common noisy and sparse records in the reality. In this paper, we revisit the map matching task from the data perspective and propose to utilize the great power of massive data and deep learning to solve these problems. Based on the seq2seq learning framework, we build a trajectory2road model with attention mechanism to map the sparse and noisy trajectory into the accurate road network. Different from previous algorithms, our deep learning based model complete the map matching in the latent space, which provides the high tolerance to the noisy trajectory and also enhances the matching with the knowledge of mobility pattern. Extensive experiments demonstrate that the proposed model outperforms the widely used HMM-based methods by more than 10 percent (absolute accuracy) in various situations especially the noisy and sparse settings.},
  archive      = {J_TMC},
  author       = {Jie Feng and Yong Li and Kai Zhao and Zhao Xu and Tong Xia and Jinglin Zhang and Depeng Jin},
  doi          = {10.1109/TMC.2020.3043500},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2372-2384},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DeepMM: Deep learning based map matching with data augmentation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compact scheduling for task graph oriented mobile
crowdsourcing. <em>TMC</em>, <em>21</em>(7), 2358–2371. (<a
href="https://doi.org/10.1109/TMC.2020.3040007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of increasingly powerful mobile devices and wireless networks, mobile crowdsourcing has emerged as a novel service paradigm. It enables crowd workers to take over outsourced location-dependent tasks, and has attracted much attention from both research communities and industries. In this paper, we consider a mobile crowdsourcing scenario, where a mobile crowdsourcing task is too complex (e.g., post-earthquake recovery, citywide package delivery) but can be divided into a number of easier subtasks, which have interdependency between them. Under this scenario, we investigate an important problem, namely task graph scheduling in mobile crowdsourcing (TGS-MC), which seeks to optimize a compact scheduling, such that the task completion time (i.e., makespan) and overall idle time are simultaneously minimized with the consideration of worker reliability. We analyze the complexity and NP-complete of the TGS-MC problem, and propose two heuristic approaches, including BFS-based dynamic priority scheduling BFSPriD algorithm, and an evolutionary multitasking-based EMTTSch algorithm, to solve our problem from local and global optimization perspective, respectively. We conduct extensive evaluation using two real-world data sets, and demonstrate superiority of our proposed approaches.},
  archive      = {J_TMC},
  author       = {Liang Wang and Zhiwen Yu and Qi Han and Dingqi Yang and Shirui Pan and Yuan Yao and Daqing Zhang},
  doi          = {10.1109/TMC.2020.3040007},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2358-2371},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Compact scheduling for task graph oriented mobile crowdsourcing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Characterising usage patterns and privacy risks of a home
security camera service. <em>TMC</em>, <em>21</em>(7), 2344–2357. (<a
href="https://doi.org/10.1109/TMC.2020.3039787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Home security cameras (HSCs) are becoming increasingly important in protecting people’s household property and caring for family members. As an emerging type of home IoT devices, HSCs are distinct from traditional IoT devices in that they are often installed in intimate places, detecting movements constantly. Such close integration with users’ daily life may result in distinct user behavioral patterns and privacy concerns. To explore this, we perform a detailed measurement study based on a large-scale service log dataset from a major HSC service provider. Our analysis reveals unique usage patterns of HSCs, including significant wasted uploads, asymmetrical upload and download traffic, skewed user engagement, and limited watching locations. We further identify three types of privacy risks in current HSC services using both passive logs and active measurements. These risks can be exploited by attackers, through observing only the traffic rates of HSCs, to infer the working state of cameras and even the daily activity routine in places where the camera is installed. Moreover, we find the premium users who pay an extra fee are especially vulnerable to such privacy inferences. We propose countermeasures from the perspectives of susceptible users and HSC providers to mitigate the risks.},
  archive      = {J_TMC},
  author       = {Jinyang Li and Zhenyu Li and Gareth Tyson and Gaogang Xie},
  doi          = {10.1109/TMC.2020.3039787},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2344-2357},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Characterising usage patterns and privacy risks of a home security camera service},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beaconless geographical routing protocol for a heterogeneous
MSN. <em>TMC</em>, <em>21</em>(7), 2332–2343. (<a
href="https://doi.org/10.1109/TMC.2020.3038628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional beaconless geographical routing (BGR) protocols perform poorly in a heterogeneous environment due to the consideration of location solely with an assumption of homogeneous transmission. Therefore, we propose a novel BGR with consideration of the locations of candidate forwarders and different transmission ranges. Our proposed protocol, namely, the heterogeneity-aware BGR (HA-BGR), is designed for a heterogeneous mobile sensor network (MSN), where the transmission ranges of mobile sensors are different. In HA-BGR, a node takes its distance, transmission range, and progress to the destination into consideration before setting itself to be a candidate next hop and remains active. Examined by analytical and extensive simulation results, HA-BGR not only needs fewer next-hop candidates but also achieves better performance in the end-to-end delivery ratio and latency as compared to the recently proposed convex-lense decision region BGR (CDR-BGR).},
  archive      = {J_TMC},
  author       = {Muhammad Taufiq Nuruzzaman and Huei-Wen Ferng},
  doi          = {10.1109/TMC.2020.3038628},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2332-2343},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Beaconless geographical routing protocol for a heterogeneous MSN},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analysis of spectrum sensing and spectrum access in
cognitive radio networks with heterogeneous traffic and
&lt;inline-formula&gt;&lt;tex-math notation=“LaTeX”&gt;<span
class="math inline"><em>p</em></span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“rakhee-ieq1-3042836.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;-retry
buffering. <em>TMC</em>, <em>21</em>(7), 2318–2331. (<a
href="https://doi.org/10.1109/TMC.2020.3042836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that cognitive radio (CR) techniques have great potential to deal with the problem of radio spectrum scarcity. Spectrum sensing technique plays a critical role in enabling unlicensed secondary users (SUs) to utilize spectrum holes in cognitive radio networks (CRNs). However, a licensed primary user (PU) can be appropriately protected by simultaneously performing spectrum sensing and data transmission i.e., by using full-duplex (FD) mode. In this paper, we have proposed and analyzed a strategy which includes spectrum sensing and spectrum access mechanisms both. We consider heterogeneous traffic of real-time and non real-time SUs based on their different delay tolerance characteristics. We address the issue of false alarm rate (FAR) associated with FD sensing. Spectrum handoff and call buffering strategies with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p$&lt;/tex-math&gt;&lt;/inline-formula&gt; -Retry policy are employed jointly so that SUs that would otherwise be blocked or forcibly dropped could be buffered and possibly served later. To evaluate the performance of the proposed strategy, five-dimensional continuous time Markov chain (CTMC) model is developed and the queueing-theoretic approach is utilized. Numerical results demonstrate the influence of spectrum sensing errors on the performance of such CRNs. Results also reveal that the provision of buffers under retrial policy increases the overall network resource utilization while decreasing blocking and dropping probabilities.},
  archive      = {J_TMC},
  author       = {Shruti and Rakhee Kulshrestha},
  doi          = {10.1109/TMC.2020.3042836},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2318-2331},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Analysis of spectrum sensing and spectrum access in cognitive radio networks with heterogeneous traffic and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$p$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi&gt;p&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;rakhee-ieq1-3042836.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt;-retry buffering},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reinforcement learning framework for efficient informative
sensing. <em>TMC</em>, <em>21</em>(7), 2306–2317. (<a
href="https://doi.org/10.1109/TMC.2020.3040945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale spatial data can be collected using mobile robots with sensing and navigation capabilities. Due to limited battery lifetime and scarcity of charging stations, it is important to plan informative paths so as to maximize the utility of data given a limited travel budget, which is known as the informative path planning (IPP) problem. IPP is NP-hard, and existing solutions suffer from high complexity or low optimality. In this paper, we present a novel IPP solution based on reinforcement learning (RL). The basic idea is to learn the structural characteristics of informative paths, so informative paths can be predicted. As such, when budgets change, we avoid solving the problem from scratch and thus path planning efficiency can be improved dramatically. Among the 20 path planning experiments in two areas, the proposed RL based solution achieves the best path utility in 15 experiments, compared with state-of-the-art algorithms. More importantly, the inference complexity is linear with respect to the budget (equivalently, the maximum number of steps in RL), which is lower than other solutions. Despite the NP-hardness, the path planning process can be finished within a few seconds in our experiments on two graphs of different sizes.},
  archive      = {J_TMC},
  author       = {Yongyong Wei and Rong Zheng},
  doi          = {10.1109/TMC.2020.3040945},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2306-2317},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A reinforcement learning framework for efficient informative sensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A lightweight collaborative deep neural network for the
mobile web in edge cloud. <em>TMC</em>, <em>21</em>(7), 2289–2305. (<a
href="https://doi.org/10.1109/TMC.2020.3043051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enabling deep learning technology on the mobile web can improve the user’s experience for achieving web artificial intelligence in various fields. However, heavy DNN models and limited computing resources of the mobile web are now unable to support executing computationally intensive DNNs when deploying in a cloud computing platform. With the help of promising edge computing, we propose a lightweight collaborative deep neural network for the mobile web, named LcDNN, which contributes to three aspects: (1) We design a composite collaborative DNN that reduces the model size, accelerates inference, and reduces mobile energy cost by executing a lightweight binary neural network (BNN) branch on the mobile web. (2) We provide a jointly training method for LcDNN and implement an energy-efficient inference library for executing the BNN branch on the mobile web. (3) To further promote the resource utilization of the edge cloud, we develop a DRL-based online scheduling scheme to obtain an optimal allocation for LcDNN. The experimental results show that LcDNN outperforms existing approaches for reducing the model size by about 16x to 29x. It also reduces the end-to-end latency and mobile energy cost with acceptable accuracy and improves the throughput and resource utilization of the edge cloud.},
  archive      = {J_TMC},
  author       = {Yakun Huang and Xiuquan Qiao and Pei Ren and Ling Liu and Calton Pu and Schahram Dustdar and Junliang Chen},
  doi          = {10.1109/TMC.2020.3043051},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {7},
  number       = {7},
  pages        = {2289-2305},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A lightweight collaborative deep neural network for the mobile web in edge cloud},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wireless powered mobile edge computing: Dynamic resource
allocation and throughput maximization. <em>TMC</em>, <em>21</em>(6),
2271–2288. (<a href="https://doi.org/10.1109/TMC.2020.3034479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless powered mobile edge computing (WP-MEC) has been widely studied as a promising technology to liberate wireless terminals from the computation-intensive and energy-consuming tasks. This article considers a WP-MEC system consisting of multiple base stations (BSs) and mobile devices (MDs), where the MDs offload tasks to the BSs for computational resources and the BSs charge the MDs using wireless power transfer (WPT). In practice, each BS and MD are equipped with a task buffer with limited size and a battery with limited capacity. First, we develop a time slotted WP-MEC system with task and energy queuing dynamics to study long-term system performance under time-varying fading channels and stochastic task and energy arrivals. Second, we propose a dynamic throughput maximum (DTM) algorithm based on perturbed Lyapunov optimization to maximize the system throughput under task and energy queue stability constraints, by optimizing the allocation of communication, computation, and energy resources. For the DTM algorithm, we characterize a throughput-backlog trade-off of [ &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}(1/V)$&lt;/tex-math&gt;&lt;/inline-formula&gt; , &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}(V)$&lt;/tex-math&gt;&lt;/inline-formula&gt; ] to indicate that the system throughput goes up as the queue backlog increases, where &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$V$&lt;/tex-math&gt;&lt;/inline-formula&gt; is a control parameter between the system throughput and the queue backlog. However, we find that, as &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$V$&lt;/tex-math&gt;&lt;/inline-formula&gt; goes large, the system throughput can be pushed arbitrarily close to the optimum at the cost of linearly increasing queue backlog (i.e., &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}(V)$&lt;/tex-math&gt;&lt;/inline-formula&gt; ). To reduce the cost, we further develop an improved dynamic throughput maximum (IDTM) algorithm, and verify that the IDTM algorithm can achieve a trade-off of [ &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}(1/V)$&lt;/tex-math&gt;&lt;/inline-formula&gt; , &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}((\log (V))^2)$&lt;/tex-math&gt;&lt;/inline-formula&gt; ] between the system throughput and the queue backlog. The simulation results demonstrate that IDTM retains close system throughput to DTM with only &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathcal {O}((\log (V))^2)$&lt;/tex-math&gt;&lt;/inline-formula&gt; queue backlog.},
  archive      = {J_TMC},
  author       = {Xiumei Deng and Jun Li and Long Shi and Zhiqiang Wei and Xiaobo Zhou and Jinhong Yuan},
  doi          = {10.1109/TMC.2020.3034479},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2271-2288},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Wireless powered mobile edge computing: Dynamic resource allocation and throughput maximization},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using truth detection to incentivize workers in mobile
crowdsourcing. <em>TMC</em>, <em>21</em>(6), 2257–2270. (<a
href="https://doi.org/10.1109/TMC.2020.3034590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsourcing platforms often want to incentivize workers to finish tasks with high quality and truthfully report their solutions by providing proper rewards. Most existing incentive mechanisms reward workers based on the comparison among workers’ reported solutions. However, these mechanisms are vulnerable to worker collusion, i.e., workers coordinate to misreport their solutions. We address such an issue by proposing a novel rewarding mechanism based on a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${truth detection}$&lt;/tex-math&gt;&lt;/inline-formula&gt; technology, which relies on the independent verification of the correctness of each worker’s response to some question with an imperfect accuracy. We model the interactions between the platform and workers as a two-stage Stackelberg game. In Stage I, the platform optimizes the reward mechanism parameters associated with truth detection to maximize its payoff. In Stage II, the workers decide their effort levels and reporting strategies to maximize their payoffs (which depend on the output of the truth detector). We analyze the game’s equilibrium and show that our proposed mechanism can effectively mitigate worker collusion. We also propose a novel rule, named filtered majority , for the platform to more effectively aggregate the workers’ solutions. Our proposed aggregation rule utilizes truth detection and outperforms the conventional simple majority rule. We further characterize the impact of the truth detection accuracy on the platform’s decisions. Surprisingly, under the simple majority rule, we show that as the truth detection accuracy improves, the platform should always incentivize more workers to exert effort and truthfully report. However, under our proposed filtered majority rule, we show that as the truth detection accuracy improves, in some cases, the platform should incentivize fewer workers and save costs. We further examine the impact of the workers’ imperfect estimation of the truth detection accuracy on the platform’s decisions.},
  archive      = {J_TMC},
  author       = {Chao Huang and Haoran Yu and Randall A Berry and Jianwei Huang},
  doi          = {10.1109/TMC.2020.3034590},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2257-2270},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Using truth detection to incentivize workers in mobile crowdsourcing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trace-driven optimization on bitrate adaptation for mobile
video streaming. <em>TMC</em>, <em>21</em>(6), 2243–2256. (<a
href="https://doi.org/10.1109/TMC.2020.3036707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile video streaming occupies three-quarters of today&#39;s cellular network traffic. The quality of mobile videos becomes increasingly important for video providers to attract more users. For example, they invest in network bandwidth resources and conduct adaptive bitrate techniques to improve video quality. Prior adaptive bitrate (ABR) algorithms perform well under given throughput traces on broadband and WiFi networks. They may perform poorly for mobile video streaming due to the high network dynamics of cellular networks. To study the properties of throughput traces under cellular networks, we collect 4G network throughput traces for over four months in two large cities, Beijing and Suzhou in China. We derive the environment-specific Markov property of throughputs in the dataset. Accordingly, we propose NEIVA, an environment identification based technique to adaptively predict future throughput for different types of environments. We also implement NEIVA and integrate it with the state-of-the-art ABR algorithm, model predictive control (MPC) approach in our testbed for experiments. By emulating mobile video streaming under throughput traces in our dataset, NEIVA achieves 20 - 25 percent improvement on throughput prediction accuracy comparing to baseline predictors. Meanwhile, NEIVA achieves 11 - 20 percent user QoE improvement over MPC with baseline predictors.},
  archive      = {J_TMC},
  author       = {Chunyu Qiao and Gen Li and Qiang Ma and Jiliang Wang and Yunhao Liu},
  doi          = {10.1109/TMC.2020.3036707},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2243-2256},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Trace-driven optimization on bitrate adaptation for mobile video streaming},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). STMARL: A spatio-temporal multi-agent reinforcement learning
approach for cooperative traffic light control. <em>TMC</em>,
<em>21</em>(6), 2228–2242. (<a
href="https://doi.org/10.1109/TMC.2020.3033782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of intelligent traffic light control systems is essential for smart transportation management. While some efforts have been made to optimize the use of individual traffic lights in an isolated way, related studies have largely ignored the fact that the use of multi-intersection traffic lights is spatially influenced, as well as the temporal dependency of historical traffic status for current traffic light control. To that end, in this article, we propose a novel Spatio-Temporal Multi-Agent Reinforcement Learning (STMARL) framework for effectively capturing the spatio-temporal dependency of multiple related traffic lights and control these traffic lights in a coordinating way. Specifically, we first construct the traffic light adjacency graph based on the spatial structure among traffic lights. Then, historical traffic records will be integrated with current traffic status via Recurrent Neural Network structure. Moreover, based on the temporally-dependent traffic information, we design a Graph Neural Network based model to represent relationships among multiple traffic lights, and the decision for each traffic light will be made in a distributed way by the deep Q-learning method. Finally, the experimental results on both synthetic and real-world data have demonstrated the effectiveness of our STMARL framework, which also provides an insightful understanding of the influence mechanism among multi-intersection traffic lights.},
  archive      = {J_TMC},
  author       = {Yanan Wang and Tong Xu and Xin Niu and Chang Tan and Enhong Chen and Hui Xiong},
  doi          = {10.1109/TMC.2020.3033782},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2228-2242},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {STMARL: A spatio-temporal multi-agent reinforcement learning approach for cooperative traffic light control},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SpeedTalker: Automobile speed estimation via mobile phones.
<em>TMC</em>, <em>21</em>(6), 2210–2227. (<a
href="https://doi.org/10.1109/TMC.2020.3034354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among all the road accidents, speeding is the most deadly factor. To reduce speeding, it is essential to devise efficient schemes for ubiquitous speed monitoring. Traditional approaches either suffers from using special equipment(e.g., radar speed gun) or special deployment(e.g., position-fixed cameras). In this article, we propose SpeedTalker, a mobile phone-based approach to perform speed detection on automobiles. By leveraging the built-in microphones and camera from the mobile phone, SpeedTalker estimates the automobile speed by passively sensing the acoustic and image signals. We propose an integrated solution to effectively estimate the automobile’s speed based on COTS devices, and provide a platform for every pedestrian to help report the speeding event of automobiles. Specifically, we use the time difference of arrivals (TDOA) model based on acoustic signals to figure out the candidate trajectories of automobile, and use the pin-hole model based on image frames to figure out the vertical distance between the user’s position and the automobile’s trajectory, thus to estimate the unique trajectory. Combined with the time stamp of the trajectory, the automobile speed can be estimated. Besides, we propose a method to effectively mitigate the influence of the movement jitters of mobile phone. We implemented a system prototype for SpeedTalker and estimated the automobile speed with high accuracy. Experiment results show that in the scenario of single automobile, SpeedTalker can achieve an average estimation error of 6.1 percent compared to radar speed guns. In the scenario of multiple automobiles, SpeedTalker can achieve an average estimation error of 9.8 percent, which is acceptable for usage.},
  archive      = {J_TMC},
  author       = {Xinran Lu and Lei Xie and Yafeng Yin and Wei Wang and Yanling Bu and Qing Guo and Sanglu Lu},
  doi          = {10.1109/TMC.2020.3034354},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2210-2227},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SpeedTalker: Automobile speed estimation via mobile phones},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simultaneous energy harvesting and gait recognition using
piezoelectric energy harvester. <em>TMC</em>, <em>21</em>(6), 2198–2209.
(<a href="https://doi.org/10.1109/TMC.2020.3035045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Piezoelectric energy harvester (PEH), which generates electricity from stress or vibrations, is attracting tremendous attention as a viable solution to extend battery life of wearable devices. More interestingly, besides the energy harvesting capability, recent research has demonstrated the feasibility of leveraging PEH as an power-free sensor for gait recognition as its stress or vibration patters are significantly influenced by the gait. However, as PEHs are not designed for precise motion sensing, the gait recognition accuracy remains low with conventional classification algorithms. The accuracy deteriorates further when the generated electricity is stored simultaneously. In this work, to achieve high performance gait recognition and efficient energy harvesting at the same time, we make two distinct contributions. First, we propose a preprocessing algorithm to filter out the effect of energy storage on PEH electricity signals. Second, we propose long short-term memory (LSTM) network-based classifiers to accurately capture temporal information in gait-induced electricity generation. We prototype the proposed gait recognition architecture in the form factor of an insole and evaluate its gait recognition as well as energy harvesting performance with 20 subjects. Our results show that the proposed architecture detects human gait with 12 percent higher recall and harvests up to 127 percent more energy while consuming 38 percent less power compared to the state-of-the-art.},
  archive      = {J_TMC},
  author       = {Dong Ma and Guohao Lan and Weitao Xu and Mahbub Hassan and Wen Hu},
  doi          = {10.1109/TMC.2020.3035045},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2198-2209},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Simultaneous energy harvesting and gait recognition using piezoelectric energy harvester},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ROSE: Robustly safe charging for wireless power transfer.
<em>TMC</em>, <em>21</em>(6), 2180–2197. (<a
href="https://doi.org/10.1109/TMC.2020.3032591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One critical issue for wireless power transfer is to avoid human health impairments caused by electromagnetic radiation (EMR) exposure. The existing studies mainly focus on scheduling wireless chargers so that (expected) EMR at any point in the area does not exceed a threshold &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$R_t$&lt;/tex-math&gt;&lt;/inline-formula&gt; . Nevertheless, they overlook the EMR jitter that leads to exceeding of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$R_t$&lt;/tex-math&gt;&lt;/inline-formula&gt; even if the expected EMR is no more than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$R_t$&lt;/tex-math&gt;&lt;/inline-formula&gt; . This paper studies the fundamental problem of RO bustly S af E charging for wireless power transfer (ROSE), that is, scheduling the power of chargers so that the charging utility for all rechargeable devices is maximized while the probability that EMR anywhere does not exceed &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$R_t$&lt;/tex-math&gt;&lt;/inline-formula&gt; is no less than a given confidence. We first build our empirical probabilistic charging model and EMR model. Then, we present EMR approximation and area discretization techniques to formulate ROSE into a Second-Order Cone Program. After that, we propose the first redundant second-order cone constraints reduction algorithm to reduce the computational cost, and therefore obtain a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(1-\epsilon)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation centralized algorithm. Further, we propose a &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$(1-\epsilon)$&lt;/tex-math&gt;&lt;/inline-formula&gt; -approximation fully distributed algorithm scalable with network size for ROSE. We conduct both simulation and field experiments, and the results show that our algorithms can outperform comparison algorithms by 480.19 percent.},
  archive      = {J_TMC},
  author       = {Haipeng Dai and Yun Xu and Guihai Chen and Wanchun Dou and Chen Tian and Xiaobing Wu and Tian He},
  doi          = {10.1109/TMC.2020.3032591},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2180-2197},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ROSE: Robustly safe charging for wireless power transfer},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust low-overhead RF-based localization for realistic
environments. <em>TMC</em>, <em>21</em>(6), 2168–2179. (<a
href="https://doi.org/10.1109/TMC.2020.3034620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the noisy indoor radio propagation channel, radio frequency (RF)-based location determination systems usually require a tedious calibration phase to construct an RF fingerprint of the area of interest. This fingerprint varies with the used mobile device, changes of the transmit power of smart access points (APs), and dynamic changes in the environment; requiring re-calibration of the area of interest; which reduces the technology ease of use. In this paper, we present IncVoronoi : a novel system that can provide low-overhead accurate RF-based indoor localization that works in realistic environments. The basic idea is that the relative relation between the received signal strength from two APs at a certain location reflects the relative distance from this location to the respective APs. Building on this, IncVoronoi incrementally reduces the user ambiguity region based on refining the Voronoi tessellation of the area of interest. IncVoronoi also includes a number of modules to efficiently run in realtime as well as to handle practical deployment issues including the noisy wireless environment, obstacles in the environment, heterogeneous devices hardware, and smart APs. We analyze the complexity of IncVoronoi and further deploy it on different Android phones using the iBeacons and WiFi technologies in a university campus and a commercial building. Evaluation of IncVoronoi with a side-by-side comparison with traditional fingerprinting techniques shows that it can achieve a consistent median accuracy less than 1.9m under different scenarios with a low beacon density of one beacon every 22m &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$^2$&lt;/tex-math&gt;&lt;/inline-formula&gt; . Compared to fingerprinting techniques, whose accuracy degrades by at least 156 percent, this accuracy comes with no training overhead and is robust to the different user devices, different transmit powers, and over temporal changes in the environment. This highlights the promise of IncVoronoi as a next generation indoor localization system.},
  archive      = {J_TMC},
  author       = {Rizanne Elbakly and Moustafa Youssef},
  doi          = {10.1109/TMC.2020.3034620},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2168-2179},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust low-overhead RF-based localization for realistic environments},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Power distribution of device-to-device communications under
nakagami fading channel. <em>TMC</em>, <em>21</em>(6), 2158–2167. (<a
href="https://doi.org/10.1109/TMC.2020.3035543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, device-to-device (D2D) communication was designated to work in cellular networks as a new standard to boost their performances. This kind of communication can occur either underlay to the existing cellular infrastructure, or overlay in the industrial scientific and medical (ISM) unused band. In this paper, we consider the case that D2D transmissions take place concurrently with the usual cellular players in the same spectrum band, and thus, controlling the interference caused by the cellular user equipments (UEs) is of crucial importance. In this work, we consider the uplink transmission of a tier of D2D users. Using network model based on stochastic geometry, we express the general cumulative distribution function (CDF) of the D2D transmit power under Nakagami fading channel. Special cases as CDF of the transmit power for Rayleigh fading and noiseless environment were derived. Besides, an upper bound of the general CDF expression is proposed. To deal with D2D lifetime, first, we express the expectation of the transmit power, then we determine the expectation of the devices lifetime and finally, we give an upper bound of this lifetime expectation. Through simulation, the obtained numerical results confirm the effectiveness of the proposed analytic schemes.},
  archive      = {J_TMC},
  author       = {Adil Boumaalif and Ouadoudi Zytoune},
  doi          = {10.1109/TMC.2020.3035543},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2158-2167},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Power distribution of device-to-device communications under nakagami fading channel},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Power adaptation for enhancing spectral efficiency and
energy efficiency in multi-hop full duplex cognitive wireless relay
networks. <em>TMC</em>, <em>21</em>(6), 2143–2157. (<a
href="https://doi.org/10.1109/TMC.2020.3035529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the energy efficiency (EE) and the spectral efficiency (SE) performance of multi-hop full duplex cognitive relay networks (MH-FDCRNs) operating in the spectrum sharing mode, under the influence of interference from the primary source. We formulate three distinct optimization problems for finding the optimal power allocation (OPA) for the secondary nodes in MH-FDCRN: (i) EE optimization with minimum SE requirement; (ii) SE optimization with minimum EE requirement; and (iii) EE-SE trade-off optimization. The impact of residual self-interference (RSI) arising due to full duplex operation at the relay nodes and the inter relay interference (IRI) arising due to frequency re-use are considered. For the EE/SE optimization problems, we transform the original non-convex optimization problems to their convex forms by expressing the numerator of the objective function as the difference of concave functions, and by using parametric transformation. For the EE-SE trade-off optimization problem, we first transform the original multi objective optimization problem into a single objective form; and then into its convex form by introducing an auxiliary variable. Computationally efficient algorithms are proposed to solve the considered problems. The convergence properties of the proposed algorithms are established through mathematical analysis as well as through computer simulation studies. We prove that the points of convergence of the proposed iterative algorithms are the Karush-Kuhn-Tucker (KKT) points of the initial non-convex problems. With the help of detailed numerical results, the best trade-off among EE and SE can be achieved by proper selection of priority factor, compared to the individual optimization approaches.},
  archive      = {J_TMC},
  author       = {Poornima S. and A. V. Babu},
  doi          = {10.1109/TMC.2020.3035529},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2143-2157},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Power adaptation for enhancing spectral efficiency and energy efficiency in multi-hop full duplex cognitive wireless relay networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimized content caching and user association for edge
computing in densely deployed heterogeneous networks. <em>TMC</em>,
<em>21</em>(6), 2130–2142. (<a
href="https://doi.org/10.1109/TMC.2020.3033563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying small cell base stations (SBS) under the coverage area of a macro base station (MBS), and caching popular contents at the SBSs in advance, are effective means to provide high-speed and low-latency services in next generation mobile communication networks. In this paper, we investigate the problem of content caching (CC) and user association (UA) for edge computing. A joint CC and UA optimization problem is formulated to minimize the content download latency. We prove that the joint CC and UA optimization problem is NP-hard. Then, we propose a CC and UA algorithm (JCC-UA) to reduce the content download latency. JCC-UA includes a smart content caching policy (SCCP) and dynamic user association (DUA). SCCP utilizes the exponential smoothing method to predict content popularity and cache contents according to prediction results. DUA includes a rapid association (RA) method and a delayed association (DA) method. Simulation results demonstrate that the proposed JCC-UA algorithm can effectively reduce the latency of user content downloading and improve the hit rates of contents cached at the BSs as compared to several baseline schemes.},
  archive      = {J_TMC},
  author       = {Yun Li and Hui Ma and Lei Wang and Shiwen Mao and Guoyin Wang},
  doi          = {10.1109/TMC.2020.3033563},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2130-2142},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimized content caching and user association for edge computing in densely deployed heterogeneous networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online user-AP association with predictive scheduling in
wireless caching networks. <em>TMC</em>, <em>21</em>(6), 2116–2129. (<a
href="https://doi.org/10.1109/TMC.2020.3036876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For wireless caching networks, the scheme design for content delivery is non-trivial in the face of the following tradeoff. On one hand, to optimize overall throughput, users can associate their nearby APs with great channel capacities; however, this may lead to unstable queue backlogs on APs and prolong request delays. On the other hand, to ensure queue stability, some users may have to associate APs with inferior channel states, which would incur throughput loss. Moreover, for such systems, how to conduct predictive scheduling to reduce delays and the fundamental limits of its benefits remain unexplored. In this paper, we formulate the problem of online user-AP association and resource allocation for content delivery with predictive scheduling under a fixed content placement as a stochastic network optimization problem. By exploiting its unique structure, we transform the problem into a series of modular maximization sub-problems with matroid constraints. Then we devise PUARA , a Predictive User-AP Association and Resource Allocation scheme which achieves a provably near-optimal throughput with queue stability. Our theoretical analysis and simulation results show that PUARA can not only perform a tunable control between throughput maximization and queue stability, but also incur a notable delay reduction with predicted information.},
  archive      = {J_TMC},
  author       = {Xi Huang and Shuang Zhao and Xin Gao and Ziyu Shao and Hua Qian and Yang Yang},
  doi          = {10.1109/TMC.2020.3036876},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2116-2129},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online user-AP association with predictive scheduling in wireless caching networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online task offloading for 5G small cell networks.
<em>TMC</em>, <em>21</em>(6), 2103–2115. (<a
href="https://doi.org/10.1109/TMC.2020.3036390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small cells are deployed in 5G networks to complement the macro cells for improving coverage and capacity. Small cells and edge computing are natural partners which can improve users’ experience. Small cell nodes (SCNs) equipped with edge servers can support emerging computing services, such as virtual reality which impose low-latency and precise contextual requirements. With the proliferation of wireless devices, there is an increasing demand for offloading tasks to SCNs. Given limited computation and communication resources, the fundamental problem for a small cell network is how to select computing tasks to maximize effective rewards in an uncertain and stochastic environment. To this end, we propose an online learning framework, LFSC, which has the performance guarantee to guide task offloading in a small cell network. LFSC balances between reward and constraint violations, and it consists of three subroutines: i) a randomized algorithm which calculates selection probability of each task based on task weights; ii) a greedy assignment algorithm which cooperatively allocates tasks among different SCNs based on the selection probability; iii) an update algorithm which exploits the multi-armed bandit (MAB) technique to update task weights according to the feedback. Our theoretical analysis shows that both the regret and violations metrics of LFSC have the sub-linear property. Extensive simulation studies based on real world data confirm that LFSC achieves a close-to-optimal reward with low violations, and outperforms many state-of-the-art algorithms.},
  archive      = {J_TMC},
  author       = {Ruiting Zhou and Xueying Zhang and Shixin Qin and John C.S. Lui and Zhi Zhou and Hao Huang and Zongpeng Li},
  doi          = {10.1109/TMC.2020.3036390},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2103-2115},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Online task offloading for 5G small cell networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On designing strategy-proof budget feasible online
mechanisms for mobile crowdsensing with time-discounting values.
<em>TMC</em>, <em>21</em>(6), 2088–2102. (<a
href="https://doi.org/10.1109/TMC.2020.3034499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing has become increasingly popular due to its ability to collect a massive amount of data with the help of many individual smartphone users. A crowdsensing platform can utilize the collected data to extract effective information and provide diverse services. Designing an incentive mechanism to compensate the participants for their resources consumption is critical in attracting more participation. Offline incentive mechanism design has been widely studied in various crowdsensing applications, whereas the online scenario, is much more challenging due to the unavailability of future information when the platform makes user selection decisions. In this paper, we investigate the problem of online crowdsensing by considering a critical property that the values of users’ contributions decrease as time goes by. The time-discounting property is common in inter-temporal choice scenarios but has not been carefully addressed from the perspective of mechanism design. To handle this problem, we propose a new method to select users based on a time-dependent threshold, and present a strategy-proof framework where participants prefer to submit their true types, instead of manipulating the market by misreporting their private information. We consider two cases, one is that the total value is the summation of each participant&#39;s contributing value, the other is more general that the total value function is submodular. We call these two mechanisms TDM and TDMS, respectively. We prove that our two mechanisms can achieve computational efficiency, budget feasibility, strategy-proofness, and a constant competitive ratio, in the context of time-discounting values. By comparing our mechanisms with the state-of-the-art methods, we show that our design achieves better performance in terms of the total value.},
  archive      = {J_TMC},
  author       = {Zhenzhe Zheng and Shuo Yang and Jiapeng Xie and Fan Wu and Xiaofeng Gao and Guihai Chen},
  doi          = {10.1109/TMC.2020.3034499},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2088-2102},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {On designing strategy-proof budget feasible online mechanisms for mobile crowdsensing with time-discounting values},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network localization and navigation with scalable inference
and efficient operation. <em>TMC</em>, <em>21</em>(6), 2072–2087. (<a
href="https://doi.org/10.1109/TMC.2020.3035511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-aware networks enable new services and applications in fields such as autonomous driving, smart cities, and the Internet-of-Things. Network localization and navigation (NLN) is a recently proposed paradigm for accurate ubiquitous localization without the need for extensive infrastructure. In NLN, devices form an interconnected network for the purpose of cooperatively localizing one another. This paper introduces Peregrine, a system that combines real-time distributed NLN algorithms with ultra-wideband (UWB) sensing and communication. The Peregrine software integrates three NLN algorithms to jointly perform 3-D localization and network operation in a technology agnostic manner, leveraging both spatial and temporal cooperation. Peregrine hardware is composed of compact low-cost devices that comprise a microprocessor and a UWB radio. The contribution of each algorithmic component is characterized through indoor network experimentation. Results show that Peregrine is robust, scalable, and capable of sub-meter accuracy in challenging wireless environments.},
  archive      = {J_TMC},
  author       = {Bryan Teague and Zhenyu Liu and Florian Meyer and Andrea Conti and Moe Z. Win},
  doi          = {10.1109/TMC.2020.3035511},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2072-2087},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Network localization and navigation with scalable inference and efficient operation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-leader multi-follower stackelberg game in mobile
blockchain mining. <em>TMC</em>, <em>21</em>(6), 2058–2071. (<a
href="https://doi.org/10.1109/TMC.2020.3035990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of Blockchain-based mobile applications are impeded due to the resource limitations of mobile devices. Computation offloading can be a viable solution. In this paper, we consider a two-layer computation offloading paradigm including an edge computing service provider (ESP) and a cloud computing service provider (CSP). We formulate a multi-leader multi-follower Stackelberg game to address the computing resource management problem in such a network, by jointly maximizing the profits of each service provider (SP) and the payoffs of individual miners. We study two practical scenarios: a fixed-miner-number scenario for permissioned blockchains and a dynamic-miner-number scenario for permissionless blockchains. For the fixed-miner-number scenario, we discuss two different edge operation modes, i.e., the ESP is connected (to the CSP) or standalone , which form different miner subgames based on whether each miner&#39;s strategy set is mutually dependent. The existence and uniqueness of Stackelberg equilibrium (SE) in both modes are analyzed, according to which algorithms are proposed to achieve the corresponding SE(s). For the dynamic-miner-number scenario, we focus on the impact of population uncertainty and find that the uncertainty inflates the aggressiveness in the ESP resource purchasing. Numerical evaluations are presented to verify the proposed models.},
  archive      = {J_TMC},
  author       = {Suhan Jiang and Xinyi Li and Jie Wu},
  doi          = {10.1109/TMC.2020.3035990},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2058-2071},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-leader multi-follower stackelberg game in mobile blockchain mining},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LoRadar: Enabling concurrent radar sensing and LoRa
communication. <em>TMC</em>, <em>21</em>(6), 2045–2057. (<a
href="https://doi.org/10.1109/TMC.2020.3035797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Miniature radar has demonstrated its great potential in smart homes, such as understanding the wellness of the residents and providing ubiquitous interactions. While it has many promising applications, it also results in congested RF (radio frequency) environments as there is an unprecedented amount of traffic in a smart home. To ease the strain on the limited spectrum, we ask the question that, can we reuse the sensing signals for data communication? With such a capability, we can improve the spectrum utilization by sharing the spectrum between sensing and communication systems. However, radar signals are customized for the sensing purpose and are incompatible with legacy communication standards. To address this challenge, we have an observation that, non-linearity effect in RF circuits can convert wideband radar signals into a LoRa signal. Based on this observation, in this paper, we present LoRadar, which enables an FMCW (Frequency-Modulated Continuous Wave) radar to carry LoRa signals in sensing waves. We present both the downlink and uplink design, enabling a LoRadar device to communicate with LoRa nodes in a bi-directional way. We implement LoRadar and evaluation results show that LoRadar can achieve home-level coverage with 3.4kbps data rate while it preserves the sensing resolution of the radar.},
  archive      = {J_TMC},
  author       = {Qianyi Huang and Zhiqing Luo and Jin Zhang and Wei Wang and Qian Zhang},
  doi          = {10.1109/TMC.2020.3035797},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2045-2057},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LoRadar: Enabling concurrent radar sensing and LoRa communication},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint radio resource allocation and cooperative caching in
PD-NOMA-based HetNets. <em>TMC</em>, <em>21</em>(6), 2029–2044. (<a
href="https://doi.org/10.1109/TMC.2020.3034618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel joint resource allocation and cooperative caching scheme for power-domain non-orthogonal multiple access (PD-NOMA)-based heterogeneous networks (HetNets). In our scheme, the requested content is fetched directly from the edge if it is cached in the storage of one of the base stations (BSs), and otherwise is fetched via the backhaul. Our scheme consists of two phases: 1) Caching phase where the contents are saved in the storage of the BSs; and 2) Delivery phase where the requested contents are delivered to users. We formulate a novel optimization problem over radio resources and content placement variables. We aim to minimize the network cost subject to quality-of-service (QoS), caching, subcarrier assignment, and power allocation constraints. By exploiting advanced optimization methods, such as alternative search method (ASM), Hungarian algorithm, successive convex approximation (SCA), we obtain an efficient sub-optimal solution of the optimization problem. Numerical results illustrate that our ergodic caching policy via the proposed resource management algorithm can achieve a considerable reduction on the total cost on average compared to the most popular caching and random caching policy. Moreover, our cooperative NOMA scheme outperforms orthogonal multiple access (OMA) in terms of the delivery cost in general with an acceptable complexity increase.},
  archive      = {J_TMC},
  author       = {Maryam Moghimi and Abolfazl Zakeri and Mohammad Reza Javan and Nader Mokari and Derrick Wing Kwan Ng},
  doi          = {10.1109/TMC.2020.3034618},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2029-2044},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint radio resource allocation and cooperative caching in PD-NOMA-based HetNets},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Game theoretic multihop D2D content sharing: Joint
participants selection, routing, and pricing. <em>TMC</em>,
<em>21</em>(6), 2013–2028. (<a
href="https://doi.org/10.1109/TMC.2020.3033536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device-to-device (D2D) content sharing holds great promise to alleviate the growing strain on cellular networks, as it offloads popular content data onto direct peer-to-peer links. However, it is still unexplored how content sharing could benefit from utilizing multihop rather than the conventional single-hop D2D communications. As a step towards this end, this paper proposes a game theoretic approach to enable D2D content sharing with multihop communication capabilities. Given a subset of participants, a Nash bargaining game is modeled to provide the routing and pricing graphs, where a novel incentive mechanism is adopted to stimulate cooperation. By iteratively evaluating the solution of the Nash bargaining subgame, participants that include content sources and transmission relays are determined, which ensures that all participants make contributions to the content sharing process. An additional procedure termed pricing plan is introduced to make sure that the final pricing graph is practical and feasible in terms of D2D communication. Experimental results are presented to demonstrate that the proposed game theoretic approach could not only jointly deal with the participants selection, routing, and pricing problems in multihop D2D content sharing, but also effectively restrict utilities and transmission resources to only contributive participants.},
  archive      = {J_TMC},
  author       = {Di Zhang and Yujian Fang and Yuezhi Zhou and Junyi He and Yaoxue Zhang},
  doi          = {10.1109/TMC.2020.3033536},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {2013-2028},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Game theoretic multihop D2D content sharing: Joint participants selection, routing, and pricing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploiting big.LITTLE batteries for software defined
management on mobile devices. <em>TMC</em>, <em>21</em>(6), 1998–2012.
(<a href="https://doi.org/10.1109/TMC.2020.3035236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery service time is a critical constraint on the availability and functionality of mobile devices. Equipping larger batteries may mitigate such deficiency yet it raises the challenges on thermal limit and physical size. Changing the battery chemistry is another solution, which however usually benefits the energy efficiency of only part of the applications, depending on their software behaviors. To address the challenges of battery energy efficiency and heat dissipation in limited physical space, we propose CAPMAN, a management framework that jointly optimizes the c ooling and a ctive p ower man agement in a smartphone, a typical mobile device, equipped with a hybrid battery pack. We establish the framework with three components. First, we abstract the correlation among the batteries, devices and software into a finite state machine model, whose state transitions can be triggered by actions like system calls and user activities. Second, we propose a battery scheduling algorithm that determines the more suitable battery for cooling/active power use, with respect to the dynamic software behaviors and their impact on the hardware states, based on a Markov decision process (MDP). Third, we design a facility for joint cooling and active power management by coordinating TECs and batteries. With the three major designs, CAPMAN realizes software defined management that schedules heterogeneous batteries and TEC cooling in a timely manner. In addition, CAPMAN provides an online algorithm with a proved O(1.05)-competitiveness performance. With a pair of big.LITTLE batteries, we prototype CAPMAN on multiple popular smartphones and a PYNQ development board. The evaluation with real-world workloads shows that compared to the current mainstream, CAPMAN can achieve 114 percent longer battery service time under skewed loads; compared to the state-of-the-practice baselines, CAPMAN shows 55 percent performance gain and 53 percent less energy use on average. Those results approve that big.LITTLE batteries with sophisticated software defined management is an effective way to prolong the battery service times on mobile devices.},
  archive      = {J_TMC},
  author       = {Zichen Xu and Jie Zhou and Wenli Zheng and Yuhao Wang and Minyi Guo},
  doi          = {10.1109/TMC.2020.3035236},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {1998-2012},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Exploiting big.LITTLE batteries for software defined management on mobile devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Deep reinforcement learning for task offloading in mobile
edge computing systems. <em>TMC</em>, <em>21</em>(6), 1985–1997. (<a
href="https://doi.org/10.1109/TMC.2020.3036871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile edge computing systems, an edge node may have a high load when a large number of mobile devices offload their tasks to it. Those offloaded tasks may experience large processing delay or even be dropped when their deadlines expire. Due to the uncertain load dynamics at the edge nodes, it is challenging for each device to determine its offloading decision (i.e., whether to offload or not, and which edge node it should offload its task to) in a decentralized manner. In this work, we consider non-divisible and delay-sensitive tasks as well as edge load dynamics, and formulate a task offloading problem to minimize the expected long-term cost. We propose a model-free deep reinforcement learning-based distributed algorithm, where each device can determine its offloading decision without knowing the task models and offloading decision of other devices. To improve the estimation of the long-term cost in the algorithm, we incorporate the long short-term memory (LSTM), dueling deep Q-network (DQN), and double-DQN techniques. Simulation results show that our proposed algorithm can better exploit the processing capacities of the edge nodes and significantly reduce the ratio of dropped tasks and average delay when compared with several existing algorithms.},
  archive      = {J_TMC},
  author       = {Ming Tang and Vincent W.S. Wong},
  doi          = {10.1109/TMC.2020.3036871},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {1985-1997},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deep reinforcement learning for task offloading in mobile edge computing systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data aggregation scheduling in battery-free wireless sensor
networks. <em>TMC</em>, <em>21</em>(6), 1972–1984. (<a
href="https://doi.org/10.1109/TMC.2020.3035671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To break through the limitation of battery-powered wireless sensor networks, a novel kind of network, named battery-free wireless sensor network (BF-WSN), is proposed. Battery-free sensor nodes in BF-WSNs harvest energy from power sources in their ambient environment, such as solar power, wind power and radio frequency (RF) signal power, etc. , instead of batteries. Therefore, the energy consumption of battery-free sensor nodes are not limited by the battery capacity anymore. However, they still have limited energy harvesting rates and energy capacities. Data aggregation is a fundamental operation in sensor networks where the sensory data gathered by the relay nodes can be merged by in-network computation, such as taking the maximum, average, or sum, etc., of them. Due to the energy features of BF-WSNs, the data aggregation scheduling problem in BF-WSNs is more complicated and the previous aggregation scheduling algorithms designed for battery-powered WSNs are no longer applicable. This paper investigates the Minimum-Latency Aggregation Scheduling problem in BF-WSNs, which is proved to be NP-hard. Then, we propose the Data Aggregation Scheduling algorithm to solve the problem. Finally, the theoretical analysis and extensive simulation results are provided to verify the performance of the proposed algorithm.},
  archive      = {J_TMC},
  author       = {Tongxin Zhu and Jianzhong Li and Hong Gao and Yingshu Li},
  doi          = {10.1109/TMC.2020.3035671},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {1972-1984},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Data aggregation scheduling in battery-free wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Covert communications in multi-channel slotted ALOHA
systems. <em>TMC</em>, <em>21</em>(6), 1958–1971. (<a
href="https://doi.org/10.1109/TMC.2020.3036022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fundamental limits of covert communication, where a message is sent from transmitter Alice to intended recipient Bob without detection by an attentive adversary warden Willie, has been considered extensively in recent years at the physical layer. The covert throughput depends critically on the warden&#39;s understanding of the characteristics of the radio environment and the type of receiver that he employs, and, as expected, the throughput increases when the warden has some uncertainty about the environment or some non-idealities in his receiver. In this paper, we consider the covert throughput when the adversary is only able to observe the medium access control (MAC) layer in a wireless communication system. In particular, given that the system has a rate of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\lambda$&lt;/tex-math&gt;&lt;/inline-formula&gt; packets per slot transmitted over &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; channels by allowable system users, we study the allowable rate &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\lambda _a$&lt;/tex-math&gt;&lt;/inline-formula&gt; by covert users while maintaining covertness from an attentive warden observing the channel status in a slotted ALOHA system. We characterize performance for wardens with different abilities to discern the number of packets on a given channel, ranging from simple receivers that detect only whether there was a packet present to complicated receivers that can determine the number of packets involved in any collision, and also consider intended recipients Bob with varying abilities to perform multi-packet reception. In contrast to prior work in covert communications, the application considered motivates the consideration of results for finite (often small) observation vector lengths &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; at the adversary. Numerical results are provided both to illustrate the tightness of our achievability regions for the packet transmission rate of the covert transmitters and to demonstrate the covert throughput of the system as a function of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\lambda$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$n$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Azadeh Sheikholeslami and Majid Ghaderi and Dennis Goeckel},
  doi          = {10.1109/TMC.2020.3036022},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {1958-1971},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Covert communications in multi-channel slotted ALOHA systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beam learning in MmWave/THz-band drone networks under
in-flight mobility uncertainties. <em>TMC</em>, <em>21</em>(6),
1945–1957. (<a href="https://doi.org/10.1109/TMC.2020.3034064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on designing high-data-rate wireless communications for drone networks in the mmWave and terahertz (THz) frequency bands. MmWave/THz-band communications have been envisioned as key technologies to achieve ultra broadband wireless links through beamforming in 5G and beyond networks. However, a main challenge with these frequency bands is that the narrow-beam directional wireless links can be easily disconnected because of the beam misalignment in mobile environments. To address this challenge, in this article we design a new beam control scheme called LeBeam , with the objective of maximizing the expected capacity of the mmWave/THz-band links by determining the optimal beamwidth dynamically under the mobility uncertainties of flying drones. In LeBeam , an Echo State Network (ESN) is adopted to capture the mobility uncertainties of the drones dynamically and predict the optimal beamwidth based on the first- and second-order moments of the drone mobility. The ESN has been trained based on real drone flight traces. To this end, we measure and analyze the mobility uncertainties of flying drones by carrying out a series of field experiments in different weather. It is found that flying drones experience micro-, small- and large-scale mobility uncertainties, and the resulting mobility behavior cannot be characterized with any existing statistical models. The performance of LeBeam is evaluated over UBSim, a newly developed trace-driven Universal Broadband Simulator for integrated aerial and ground wireless networking. Results indicate that the micro-scale mobility has only negligible effects on the link capacity (less than 1 percent), while the wireless links may experience significant capacity degradation (over 50 percent on average) in the presence of small- and large-scale mobility uncertainties.},
  archive      = {J_TMC},
  author       = {Sabarish Krishna Moorthy and Zhangyu Guan},
  doi          = {10.1109/TMC.2020.3034064},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {1945-1957},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Beam learning in MmWave/THz-band drone networks under in-flight mobility uncertainties},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive hybrid model-enabled sensing system (HMSS) for
mobile fine-grained air pollution estimation. <em>TMC</em>,
<em>21</em>(6), 1927–1944. (<a
href="https://doi.org/10.1109/TMC.2020.3034270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained city-scale outdoor air pollution maps provide important environmental information for both city managers and residents. Installing portable sensors on vehicles (e.g., taxis, Ubers) provides a low-cost, easy-maintenance, and high-coverage approach to collecting data for air pollution estimation. However, as non-dedicated platforms, vehicles like taxis usually prefer gathering at busy areas of a city where it is more likely to pick up riders. This leaves many parts of the city unsensed or less-sensed. In addition, due to the natural changes in a city and the movements of the vehicles, the sensed and unsensed areas change over time. Consequently, challenges of air pollution estimation with data collected by non-dedicated mobile platforms are twofold: i. data coverage is sparse; ii. data coverage changes over time. Therefore, the major research question is: how can we derive accurate and robust fine-grained field (e.g., air pollution) estimation given dynamic and sparse data collected from uncontrollable mobile sensing platforms? This paper presents adaptive HMSS , an adaptive h ybrid m odel-enabled s ensing s ystem for fine-grained air pollution estimation with dynamic and sparse data collected from uncontrollable mobile sensing platforms, which is achieved by combining the advantages of a physics guided model and a data driven model . To address the challenge of sparse coverage, the physical understanding of the spatiotemporal correlation for air pollution distribution in the physics guided model is utilized to infer values at unsensed sparse areas. Meanwhile, the data driven model is adopted to estimate the air pollution influential factors (e.g., buildings) not included in the physics guided model . To address the challenge of time-varying coverage, an adaptive model combination algorithm is designed to enable the system bias to either of the two models according to the amount of data collection and uncertainty of the model. To evaluate the system performance, we deployed 47 air pollution sensing devices on taxis and fixed locations in 2 cities for both controlled and uncontrolled experiments for over two weeks. The results show that with a resolution of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$500 \;\mathrm m$&lt;/tex-math&gt;&lt;/inline-formula&gt; by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$500\;\mathrm m$&lt;/tex-math&gt;&lt;/inline-formula&gt; by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1\;\mathrm {hour}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , our system achieves up to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$3.2\times$&lt;/tex-math&gt;&lt;/inline-formula&gt; error reduction when compared to the baseline approaches.},
  archive      = {J_TMC},
  author       = {Xinlei Chen and Susu Xu and Xinyu Liu and Xiangxiang Xu and Hae Young Noh and Lin Zhang and Pei Zhang},
  doi          = {10.1109/TMC.2020.3034270},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {1927-1944},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Adaptive hybrid model-enabled sensing system (HMSS) for mobile fine-grained air pollution estimation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A force-directed approach to seeking route recommendation in
ride-on-demand service using multi-source urban data. <em>TMC</em>,
<em>21</em>(6), 1909–1926. (<a
href="https://doi.org/10.1109/TMC.2020.3033274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapidly-growing business of ride-on-demand (RoD) service such as Uber, Lyft and Didi proves the effectiveness of their new service model – using mobile apps and dynamic pricing to coordinate between drivers, passengers and the service provider, to manipulate the supply and demand, and to improve service responsiveness as well as quality. Despite its success, dynamic pricing creates a new problem for drivers: how to seek for passengers to maximize revenue under dynamic prices. Seeking route recommendation has already been studied extensively in traditional taxi service, but most studies do not consider the effects of taxis and passengers on the seeking taxi simultaneously. Further, in RoD service it is necessary to consider more factors such as dynamic prices, the status of other transportation services, etc. In this paper, we employ a force-directed approach to model, by analogy, the relationship between vacant cars and passengers as that between positive and negative charges in electrostatic field. We extract features from multi-source urban data to describe dynamic prices, the status of RoD, taxi and public transportation services, and incorporate them into our model. The model is then used in route recommendation in every intersection so that a driver in a vacant RoD car knows which road segment to take next. We conduct extensive experiments based on our multi-source urban data, including RoD service operational data, taxi GPS trajectory data and public transportation distribution data, and results not only show that our approach outperforms existing baselines, but also justify the need to incorporate multi-source urban data and dynamic prices.},
  archive      = {J_TMC},
  author       = {Suiming Guo and Chao Chen and Jingyuan Wang and Yan Ding and Yaxiao Liu and Ke Xu and Zhiwen Yu and Daqing Zhang},
  doi          = {10.1109/TMC.2020.3033274},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {6},
  number       = {6},
  pages        = {1909-1926},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A force-directed approach to seeking route recommendation in ride-on-demand service using multi-source urban data},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When attackers meet AI: Learning-empowered attacks in
cooperative spectrum sensing. <em>TMC</em>, <em>21</em>(5), 1892–1908.
(<a href="https://doi.org/10.1109/TMC.2020.3030061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defense strategies have been well studied to combat Byzantine attacks that aim to disrupt cooperative spectrum sensing by sending falsified versions of spectrum sensing data to a fusion center. However, existing studies usually assume network or attackers as passive entities, e.g., assuming the prior knowledge of attacks is known or fixed. In practice, attackers can actively adopt arbitrary behaviors and avoid pre-assumed patterns or assumptions used by defense strategies. In this paper, we revisit this security vulnerability as an adversarial machine learning problem and propose a novel learning-empowered attack framework named Learning-Evaluation-Beating (LEB) to mislead the fusion center. Based on the black-box nature of the fusion center in cooperative spectrum sensing, our new perspective is to make the adversarial use of machine learning to construct a surrogate model of the fusion center&#39;s decision model. We propose a generic algorithm to create malicious sensing data using this surrogate model. Our real-world experiments show that the LEB attack is effective to beat a wide range of existing defense strategies with an up to 82 percent of success ratio. Given the gap between the proposed LEB attack and existing defenses, we introduce a non-invasive method named as influence-limiting defense, which can coexist with existing defenses to defend against LEB attack or other similar attacks. We show that this defense is highly effective and reduces the overall disruption ratio of LEB attack by up to 80 percent.},
  archive      = {J_TMC},
  author       = {Zhengping Luo and Shangqing Zhao and Zhuo Lu and Jie Xu and Yalin E. Sagduyu},
  doi          = {10.1109/TMC.2020.3030061},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1892-1908},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {When attackers meet AI: Learning-empowered attacks in cooperative spectrum sensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Utilizing multi-connectivity to reduce latency and enhance
availability for vehicle to infrastructure communication. <em>TMC</em>,
<em>21</em>(5), 1874–1891. (<a
href="https://doi.org/10.1109/TMC.2020.3028306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative intelligent transport systems (C-ITS) enable information to be shared wirelessly between vehicles and infrastructure in order to improve transport safety and efficiency. Delivering C-ITS services using existing cellular networks offers both financial and technological advantages, not least since these networks already offer many of the features needed by C-ITS, and since many vehicles on our roads are already connected to cellular networks. Still, C-ITS pose stringent requirements in terms of availability and latency on the underlying communication system; requirements that will be hard to meet for currently deployed 3G, LTE, and early-generation 5G systems. Through a series of experiments in the MONROE testbed (a cross-national, mobile broadband testbed), the present study demonstrates how cellular multi-access selection algorithms can provide close to 100 percent availability, and significantly reduce C-ITS transaction times. The study also proposes and evaluates a number of low-complexity, low-overhead single-access selection algorithms, and shows that it is possible to design such solutions so that they offer transaction times and availability levels that rival those of multi-access solutions.},
  archive      = {J_TMC},
  author       = {Alexander Rabitsch and Karl-Johan Grinnemo and Anna Brunstrom and Henrik Abrahamsson and Fehmi Ben Abdesslem and Stefan Alfredsson and Bengt Ahlgren},
  doi          = {10.1109/TMC.2020.3028306},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1874-1891},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Utilizing multi-connectivity to reduce latency and enhance availability for vehicle to infrastructure communication},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Underwater ultrasonic wireless power transfer: A
battery-less platform for the internet of underwater things.
<em>TMC</em>, <em>21</em>(5), 1861–1873. (<a
href="https://doi.org/10.1109/TMC.2020.3029679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Underwater Things (IoUT) will enable new military, scientific, and commercial applications at sea. However, powering of electronic devices in deep water still remains one of the main challenges, since these systems are typically powered by traditional batteries. This article presents the design of the first batteryless underwater sensor node that can be wirelessly recharged through ultrasonic waves from longer distances than allowed by current technologies. First, the architecture of an underwater platform capable of extracting electrical energy from ultrasonic waves is introduced. We then illustrate how to interface this system with an underwater digital communication unit. We discuss the design of a prototype where the storage unit is realized with a batch of supercapacitors. We show through experiments that the harvested energy is sufficient to provide the sensor node with the power necessary to perform a sensing operation and power a modem for ultrasonic communications. In the article, we evaluate the system power transfer efficiency. Given the reduced attenuation of ultrasonic waves in water, we show that our approach can cover longer distances with less transmission power than alternative solutions. Last, we experimentally evaluate the overall operating efficiency of the system.},
  archive      = {J_TMC},
  author       = {Raffaele Guida and Emrecan Demirors and Neil Dave and Tommaso Melodia},
  doi          = {10.1109/TMC.2020.3029679},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1861-1873},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Underwater ultrasonic wireless power transfer: A battery-less platform for the internet of underwater things},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Supremo: Cloud-assisted low-latency super-resolution in
mobile devices. <em>TMC</em>, <em>21</em>(5), 1847–1860. (<a
href="https://doi.org/10.1109/TMC.2020.3025300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf Supremo}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , a cloud-assisted system for low-latency image super-resolution (SR) in mobile devices. As SR is extremely compute-intensive, we first further optimize state-of-the-art DNN to reduce the inference latency. Furthermore, we design a mobile-cloud cooperative execution pipeline composed of specialized data compression algorithms to minimize end-to-end latency with minimal image quality degradation. Finally, we extend &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf Supremo}$&lt;/tex-math&gt;&lt;/inline-formula&gt; to video applications by formulating a dynamic optimal control algorithm to design &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf Supremo-Opt}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , which aims to maximize the impact of SR while satisfying latency and resource constraints under practical network conditions. &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf Supremo}$&lt;/tex-math&gt;&lt;/inline-formula&gt; upscales 360p image to 1080p in 122 ms, which is 43.68× faster than on-device GPU execution. Compared to cloud offloading-based solutions, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf Supremo}$&lt;/tex-math&gt;&lt;/inline-formula&gt; reduces wireless network bandwidth consumption and end-to-end latency by 15.23× and 4.85× compared to baseline approach of sending and receiving whole images, and achieves 2.39 dB higher PSNR compared to using conventional JPEG to achieve similar data size compression. Furthermore, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf Supremo-Opt}$&lt;/tex-math&gt;&lt;/inline-formula&gt; guarantees robust performance in practical scenarios.},
  archive      = {J_TMC},
  author       = {Juheon Yi and Seongwon Kim and Joongheon Kim and Sunghyun Choi},
  doi          = {10.1109/TMC.2020.3025300},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1847-1860},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Supremo: Cloud-assisted low-latency super-resolution in mobile devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spectrum activity surveillance: Modeling and analysis from
perspectives of surveillance coverage and culprit detection.
<em>TMC</em>, <em>21</em>(5), 1829–1846. (<a
href="https://doi.org/10.1109/TMC.2020.3032434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum activity surveillance (SAS) is essential to dynamic spectrum access (DSA)-enabled systems with a two-fold impact: it is a primitive mechanism to collect usage data for spectrum efficiency improvement; it is also a prime widget to collect misuse forensics of unauthorized or malicious users. While realizing SAS for DSA-enabled systems appears to be intuitive and trivial, it is, however, a challenging yet open problem. On one hand, a large-scale SAS function is costly to implement in practice; on the other hand, it is not clear how to characterize the efficacy and performance of monitor deployment strategies. To address such challenges, we introduce a three-factor space, composed of spectrum , time , and geographic region , over which the SAS problem is formulated by a two-step solution: 3D-tessellation for sweep (monitoring) coverage and graph walk for detecting spectrum culprits , that is, devices responsible for unauthorized spectrum occupancy. In particular, our system model transforms SAS from a globally collective activity to localized actions, and strategy objectives from qualitative attributes to quantitative measures. With this model, we design low-cost deterministic strategies for dedicated monitors, which outperform strategies found by genetic algorithms, and performance-guaranteed random strategies for crowd-source monitors, which can detect adversarial spectrum culprits in bounded time.},
  archive      = {J_TMC},
  author       = {Jie Wang and Wenye Wang and Cliff Wang and Min Song},
  doi          = {10.1109/TMC.2020.3032434},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1829-1846},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Spectrum activity surveillance: Modeling and analysis from perspectives of surveillance coverage and culprit detection},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ShopSense: Customer localization in multi-person scenario
with passive RFID tags. <em>TMC</em>, <em>21</em>(5), 1812–1828. (<a
href="https://doi.org/10.1109/TMC.2020.3029833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor localization serves as the basis of sensing and understanding human behaviors and further providing personalized services in many scenarios, such as retail stores, warehouses and libraries. However, existing indoor localization technologies cannot fulfill the requirement of such scenarios due to incapable of identifying different persons, severe object occlusion when there are multiple persons, or privacy concerns. On the basis of wide deployment of RFID tags in such scenarios, in this paper we develop a RFID-based localization system, i.e., ShopSense, which is not only able to accurately localize multiple people simultaneously but also differentiate them even when there are a lot of obstacles in the environment. Extensive experiments demonstrate that ShopSense can locate the shopping cart at a median tracking error of 20 cm and can locate the customer’s location with a median tracking error of 25 cm.},
  archive      = {J_TMC},
  author       = {Pei Wang and Bin Guo and Zhu Wang and Zhiwen Yu},
  doi          = {10.1109/TMC.2020.3029833},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1812-1828},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ShopSense: Customer localization in multi-person scenario with passive RFID tags},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Push the limit of acoustic gesture recognition.
<em>TMC</em>, <em>21</em>(5), 1798–1811. (<a
href="https://doi.org/10.1109/TMC.2020.3032278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the flourish of the smart devices and their applications, controlling devices using gestures has attracted increasing attention for ubiquitous sensing and interaction. Recent works use acoustic signals to track hand movement and recognize gestures. However, they suffer from low robustness due to frequency selective fading, interference and insufficient training data. In this work, we propose RobuCIR, a robust contact-free gesture recognition system that can work under different practical impact factors with high accuracy and robustness. RobuCIR adopts frequency-hopping mechanism to mitigate frequency selective fading and avoid signal interference. To further increase system robustness, we investigate a series of data augmentation techniques based on a small volume of collected data to emulate different practical impact factors. The augmented data is used to effectively train neural network models and cope with various influential factors (e.g., gesture speed, distance to transceiver, etc .). Our experiment results show that RobuCIR can recognize 15 gestures and outperform state-of-the-art works in terms of accuracy and robustness.},
  archive      = {J_TMC},
  author       = {Yanwen Wang and Jiaxing Shen and Yuanqing Zheng},
  doi          = {10.1109/TMC.2020.3032278},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1798-1811},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Push the limit of acoustic gesture recognition},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing BLE-like neighbor discovery. <em>TMC</em>,
<em>21</em>(5), 1779–1797. (<a
href="https://doi.org/10.1109/TMC.2020.3028270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighbor discovery (ND) protocols are used for establishing a first contact between multiple wireless devices. The energy consumption and discovery latency of this procedure are determined by the parametrization of the protocol. In most existing protocols, reception and transmission are temporally coupled. Such schemes are referred to as slotted , for which the problem of finding optimized parametrizations has been studied thoroughly in the literature. However, slotted approaches are not efficient in applications in which new devices join the network gradually and only the joining devices and a master node need to run the ND protocol simultaneously. For example, this is typically the case in IoT scenarios or bluetooth low energy (BLE) piconets. Here, slotless protocols that decouple reception and transmission can achieve significantly lower worst-case latencies than slotted ones. In this paper, we study slotless, BLE-like protocols, which schedule receptions and transmissions independently using periodic intervals (PI). For this class of protocols, optimal parameter values remain unknown. To address this, we propose an optimization framework for PI-based protocols, which translates any specified duty-cycle (and therefore energy budget) into a set of optimized parameter values. We show that the parametrizations resulting from one variant of our proposed scheme are optimal when one receiver discovers one transmitter, and no other parametrization or ND protocol – neither slotted nor slotless – can guarantee lower discovery latencies for a given duty-cycle in this scenario. Since the resulting protocol utilizes the channel more aggressively than other ND protocols, beacons will collide more frequently. Hence, due to collisions, the rate of successful discoveries gracefully decreases for larger numbers of devices discovering each other simultaneously. We also propose a scheme for configuring the BLE protocol (and not just BLE- like protocols). Though it is not clear whether the resulting parametrizations minimize the latencies of BLE, reasonably low worst-case latencies can be guaranteed.},
  archive      = {J_TMC},
  author       = {Philipp H. Kindt and Swaminathan Narayanaswamy and Marco Saur and Samarjit Chakraborty},
  doi          = {10.1109/TMC.2020.3028270},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1779-1797},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing BLE-like neighbor discovery},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MUSE: A multistage assembling algorithm for simultaneous
localization of large-scale massive passive RFIDs. <em>TMC</em>,
<em>21</em>(5), 1766–1778. (<a
href="https://doi.org/10.1109/TMC.2020.3030039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, MUSE, an algorithm enabled by backscattering tag-to-tag network (BTTN) is presented to accomplish simultaneous 2-D localization of large-scale (10 m &amp;#x00D7; 10 m) massive (20&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\sim$&lt;/tex-math&gt;&lt;mml:math&gt;&lt;mml:mo&gt;&amp;#x223C;&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;ma-ieq1-3030039.gif&quot;/&gt;&lt;/inline-formula&gt;50) passive UHF RFIDs. In BTTNs, the most intractable problem is the high-frequency loss of range measurements. In a particular case of 30 tags to be located with maximum communication range being 3 m, the rate is nearly up to 85.75 percent. In the proposed framework, we utilize relevant knowledge in the theory of graphs to obtain underlying subsets in which tags can communicate with each other and then assemble them stage by stage to achieve overall localization. Theoretical analysis shows that multistage assembly imparts extraordinary characteristics to MUSE: Assembling rectifies fragment maps given some condition, and in later stages prevents errors flowing down into the next stage. Experimental analysis shows that the condition is easy to satisfy. Furthermore, an analytical expression for the Cram&amp;#x00E9;r-Rao lower bound is also derived as a benchmark to evaluate the localization performance. Extensive simulations demonstrate that MUSE outperforms existing algorithms for simultaneous localization.},
  archive      = {J_TMC},
  author       = {Yongtao Ma and Chenglong Tian and Hankai Liu},
  doi          = {10.1109/TMC.2020.3030039},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1766-1778},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {MUSE: A multistage assembling algorithm for simultaneous localization of large-scale massive passive RFIDs},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monetizing edge service in mobile internet ecosystem.
<em>TMC</em>, <em>21</em>(5), 1751–1765. (<a
href="https://doi.org/10.1109/TMC.2020.3025286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile Internet ecosystem, mobile users (MUs) purchase wireless data services from Internet service provider (ISP) to access to Internet and acquire the interested content services (e.g., online game) from Content Provider (CP). The popularity of intelligent functions (e.g., AI and 3D modeling) increases the computation-intensity of the content services, leading to a growing computation pressure for the MUs&amp;#x2019; resource-limited devices. To this end, edge computing service is emerging as a promising approach to alleviate the MUs&amp;#x2019; computation pressure while keeping their quality-of-service, via offloading some computation tasks of MUs to edge (computing) servers deployed at the local network edge. Thus, edge service provider (ESP), who deploys the edge servers and offers the edge computing service, becomes an upcoming new stakeholder in the ecosystem. In this work, we study the economic interactions of MUs, ISP, CP, and ESP in the new ecosystem with edge computing service, where MUs can acquire the computation-intensive content services (offered by CP) and offload some computation tasks, together with the necessary raw input data, to edge servers (deployed by ESP) through ISP. We first study the MU&amp;#x0027;s Joint Content Acquisition and Task Offloading (J-CATO) problem, which aims to maximize his long-term payoff. We derive the off-line solution with crucial insights, based on which we design an online strategy with provable performance. Then, we study the ESP&amp;#x0027;s edge service monetization problem. We propose a pricing policy that can achieve a constant fraction of the ex post optimal revenue with an extra constant loss for the ESP. Numerical results show that the edge computing service can stimulate the MUs&amp;#x2019; content acquisition and improve the payoffs of MUs, ISP, and CP.},
  archive      = {J_TMC},
  author       = {Zhiyuan Wang and Lin Gao and Tong Wang and Jingjing Luo},
  doi          = {10.1109/TMC.2020.3025286},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1751-1765},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Monetizing edge service in mobile internet ecosystem},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-power and low-delay WLAN using wake-up receivers.
<em>TMC</em>, <em>21</em>(5), 1739–1750. (<a
href="https://doi.org/10.1109/TMC.2020.3030313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-efficient communication technologies are a key enabler for many IoT applications. Many existing communication protocols are based on duty-cycling techniques, that have an inherent tradeoff between delay and energy consumption. In the field of sensor networks, wake-up receivers have been investigated to overcome these problems and to further reduce energy consumption. We now go one step further and investigate the use of wake-up receivers in combination with IEEE 802.11 WLAN. We extend the protocol used to communicate between the access point and the client to introduce a wake-up signal. This can be implemented in a way that is fully compatible with existing wireless LAN (WLAN) standards, thus, it can be deployed gradually with little effort and no need to change existing systems. As a proof of concept and to perform first lab experiments, we developed a hardware prototype using a selective wake-up receiver and off-the-shelf USB-WLAN dongles. All experimental results are verified using an analytical model and a detailed simulation study. We show that our wake-up WLAN can provide connectivity for low-power devices with low delays and low energy consumption at the same time.},
  archive      = {J_TMC},
  author       = {Johannes Blobel and Florian Menne and Dongxiao Yu and Xiuzhen Cheng and Falko Dressler},
  doi          = {10.1109/TMC.2020.3030313},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1739-1750},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Low-power and low-delay WLAN using wake-up receivers},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-latency and fresh content provision in
information-centric vehicular networks. <em>TMC</em>, <em>21</em>(5),
1723–1738. (<a href="https://doi.org/10.1109/TMC.2020.3025201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the content service provision of information-centric vehicular networks (ICVNs) is investigated from the aspect of mobile edge caching, considering the dynamic driving-related context information. To provide up-to-date information with low latency, two schemes are designed for cache update and content delivery at the roadside units (RSUs). The roadside unit centric (RSUC) scheme decouples cache update and content delivery through bandwidth splitting, where the cached content items are updated regularly in a round-robin manner. The request adaptive (ReA) scheme updates the cached content items upon user requests with certain probabilities. The performance of both proposed schemes are analyzed, whereby the average age of information (AoI) and service latency are derived in closed forms. Surprisingly, the AoI-latency trade-off does not always exist, and frequent cache update can degrade both performances. Thus, the RSUC and ReA schemes are further optimized to balance the AoI and latency. Extensive simulations are conducted on SUMO and OMNeT++ simulators, and the results show that the proposed schemes can reduce service latency by up to 80 percent while guaranteeing content freshness in heavily loaded ICVNs.},
  archive      = {J_TMC},
  author       = {Shan Zhang and Junjie Li and Hongbin Luo and Jie Gao and Lian Zhao and Xuemin Sherman Shen},
  doi          = {10.1109/TMC.2020.3025201},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1723-1738},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Low-latency and fresh content provision in information-centric vehicular networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Localization of networks on 3D terrain surfaces.
<em>TMC</em>, <em>21</em>(5), 1710–1722. (<a
href="https://doi.org/10.1109/TMC.2020.3029249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of current research on sensor network localization focuses on wireless sensor networks deployed on two-dimensional (2D) plane or in three-dimensional (3D) space, very few on the 3D terrain surface. However, many real-world applications require large-scale sensor networks deployed on the surface of a complex 3D terrain. Compared with planar and 3D network localization, terrain surface network localization generates unique and fundamental hardness. We explore 3D surface network localization with terrain models. A digital terrain model (DTM), available to the public with a variable resolution of up to one meter, is a 3D representation of a terrain&#39;s surface. It is commonly built using remote sensing technology or from land surveying and can be easily converted to a triangular mesh. Given a sensor network deployed on the surface of a 3D terrain with one-hop distance information available, we can extract a triangular mesh from the connectivity graph of the network. The constraint that the sensors must be on the known 3D terrain&#39;s surface ensures that the triangular meshes of the network and the terrain&#39;s surface overlap and approximate the same geometric shape. The basic idea of the localization algorithms is to map the two triangular meshes extracted from the connectivity graph of a sensor network and the DTM of its deployed terrain surface to the plane. The two meshes mapped to the plane can be easily aligned if the location information of anchor nodes is available. We introduce a fully distributed algorithm to construct a well-aligned mapping between the two triangular meshes in the plane based on anchor nodes information. However, accidents may happen on anchor nodes. We then introduce an anchor-free algorithm to extract feature points with geometric properties intrinsic to surface distances and independent of the embedding of the two meshes in 3D. The matched feature points induce transformations to align the two meshes in the plane. With the aligned triangular meshes of a network and its deployed terrain surface, each sensor node of the network can easily locate reference grid points from the DTM of the terrain to calculate its own geographic location. We carry out extensive simulations under various scenarios to evaluate the overall performance of the proposed algorithms with different factors such as the one-hop distance measurement error, the resolution of a DTM, and the performance of the algorithm in the situation of connectivity only.},
  archive      = {J_TMC},
  author       = {Xuan Li and Buri Ban and Yang Yang and Miao Jin},
  doi          = {10.1109/TMC.2020.3029249},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1710-1722},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Localization of networks on 3D terrain surfaces},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Latency and mobility–aware service function chain placement
in 5G networks. <em>TMC</em>, <em>21</em>(5), 1697–1709. (<a
href="https://doi.org/10.1109/TMC.2020.3028216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G networks are expected to support numerous novel services and applications with versatile quality of service (QoS) requirements such as high data rates and low end-to-end (E2E) latency. It is widely agreed that E2E latency can be reduced by moving the computational capability closer to the network edge. The limited amount of computational resources of the edge nodes, however, poses the challenge of efficiently utilizing these resources while, at the same time, satisfying QoS requirements. In this work, we employ mixed-integer linear programming (MILP) techniques to formulate and solve a joint user association, service function chain (SFC) placement, where SFCs are composed of virtualized service functions (VSFs), and resource allocation problem in 5G networks composed of decentralized units (DUs), centralized units (CUs), and a core network (5GC). Specifically, we compare four approaches to solving the problem. The first two approaches minimize, respectively, the E2E latency experienced by users and the service provisioning cost. The other two instead aim at minimizing VSF migrations along with their impact on users&amp;#x2019; quality of experience with the last one minimizing also the number of inter-CU handovers. We then propose a heuristic to address the scalability issue of the MILP-based solutions. Simulations results demonstrate the effectiveness of the proposed heuristic algorithm.},
  archive      = {J_TMC},
  author       = {Davit Harutyunyan and Nashid Shahriar and Raouf Boutaba and Roberto Riggio},
  doi          = {10.1109/TMC.2020.3028216},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1697-1709},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Latency and Mobility&amp;#x2013;Aware service function chain placement in 5G networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ITrust: An anomaly-resilient trust model based on isolation
forest for underwater acoustic sensor networks. <em>TMC</em>,
<em>21</em>(5), 1684–1696. (<a
href="https://doi.org/10.1109/TMC.2020.3028369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic sensor networks (UASNs) have been widely promoted for developing various categories of marine applications, where the sensor nodes cooperate to complete specific tasks. Given the fact that the sensor nodes are unattended while continuously exposed to harsh environments, an associated trust model plays a significant role in node trustworthiness evaluation and defective node detection, such as the case of adverse attacks on the network. However, the existing trust models only evaluate the communication behavior and the energy of the sensor nodes, ignoring the effects of underwater environmental noise on trust reliability. Further, most trust models are designed with arbitraty weighted trust metrics, causing inevitable evaluation errors. To achieve the accurate calculation of node trust, we propose a new anomaly and attack resilient trust model, based on the isolation forest. We refer to this model as ITrust. The proposed ITrust model consists of two phases: trust metrics specifics and defective node detection. In the first phase, the trust dataset is integrated from four types of trust metrics: communication trust, data trust, energy trust, and environment trust. In the second stage, trust is evaluated with the obtained trust dataset using the isolation forest algorithm. Simulation results demonstrate that the proposed ITrust can detect defective nodes effectively, and achieves higher detection accuracy than that of the existing trust models in a noisy environment.},
  archive      = {J_TMC},
  author       = {Jiaxin Du and Guangjie Han and Chuan Lin and Miguel Mart&amp;#x00ED;nez-Garc&amp;#x00ED;a},
  doi          = {10.1109/TMC.2020.3028369},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1684-1696},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ITrust: An anomaly-resilient trust model based on isolation forest for underwater acoustic sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imperfect CSI based intelligent dynamic spectrum management
using cooperative reinforcement learning framework in cognitive radio
networks. <em>TMC</em>, <em>21</em>(5), 1672–1683. (<a
href="https://doi.org/10.1109/TMC.2020.3026415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of wireless traffic pushed the wireless community to research different solutions towards the efficient utilization of the available radio spectrum. However, a recent study shows that most of the dynamically allocated spectrum bands (radio frequency resources), experience significant underutilization as cognitive radio (CR) technology still lacks intelligence. An intelligence in CRs can be incorporated with machine learning algorithms. Further, the perfect channel state information (CSI) is hardly obtained and CSI imperfections play a crucial role in Dynamic Spectrum Management. Thus, for efficient utilization of available spectrum, a decentralized Multi-Agent Reinforcement Learning based resource allocation scheme has been proposed. A robust resource allocation scheme is proposed which integrates machine learning and CR technology into a sophisticated multi-agent system (MAS). Moreover, assisted with cloud computing which provides a huge amount of storage space, reduces operating expenditures, and provides wider flexibility of cooperation. Hence, to foster the performance of the proposed scheme, a cooperative framework in MAS is introduced which enhances the performance of the proposed scheme in terms of network capacity, outage probability, and convergence speed. Numerical results verify the effectiveness of the proposed scheme and show the non-negligible impact of imperfect CSI, thus highlighting the importance of robust designs that maintains users’ QoS in practical wireless networks.},
  archive      = {J_TMC},
  author       = {Amandeep Kaur and Krishan Kumar},
  doi          = {10.1109/TMC.2020.3026415},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1672-1683},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Imperfect CSI based intelligent dynamic spectrum management using cooperative reinforcement learning framework in cognitive radio networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Identity-based attack detection and classification utilizing
reciprocal RSS variations in mobile wireless networks. <em>TMC</em>,
<em>21</em>(5), 1657–1671. (<a
href="https://doi.org/10.1109/TMC.2020.3032412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identity-based attacks (IBAs) are one of the most serious threats to wireless networks. Recently, there is an increasing interest in using the received signal strength (RSS) to detect IBAs in wireless networks. However, current schemes tend to generate excessive false alarms in the mobile scenario. In this paper, we propose a stronger Reciprocal Channel Variation-based Identification and classification (RCVIC) scheme for the mobile wireless networks, which exploits the reciprocity of the wireless fading channel and RSS variations naturally incurred by mobility to improve the detection performance. Different from current schemes only detect IBAs, RCVIC scheme conducts a multi-stage detection processes. If the IBAs are detected, RCVIC scheme partitions the received frames into two classes. The frames in the same class should be sent from the same senders, which could benefit the further analysis, such as network forensics, attacker localizing and trajectory analysis, etc. The feasibility of RCVIC are numerically evaluated through theoretical analysis and simulations. It is further validated through experiments using off-the-shelf 802.11 devices under different attacking patterns in real indoor and outdoor mobile scenarios.},
  archive      = {J_TMC},
  author       = {Jie Tang and Long Jiao and Kai Zeng and Hong Wen and Kannan Govindan and Daniel Wu and Prasant Mohapatra},
  doi          = {10.1109/TMC.2020.3032412},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1657-1671},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Identity-based attack detection and classification utilizing reciprocal RSS variations in mobile wireless networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Epidemic heterogeneity and hierarchy: A study of wireless
hybrid worm propagation. <em>TMC</em>, <em>21</em>(5), 1639–1656. (<a
href="https://doi.org/10.1109/TMC.2020.3026342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth in the use of smart mobile devices and the development of information technologies, worms and malware can spread from mobile networks into heterogeneous and hierarchical networks. Thus, the spread of these worms constitutes an increasing potential threat. For understanding the propagation of the aforementioned wireless hybrid worms, current researches have three critical problems: Structural simplification of network topologies (previous research object for wireless worms is the mobile network), Homogenous population of network devices (properties of network devices are the same), and Inaccuracy of propagation models (traditional deterministic differential or stochastic difference models cannot model propagation of wireless hybrid worms accurately). To address them, we propose a novel compartmental population-based propagation model oriented towards heterogeneous and hierarchical networks with human behaviors, and then study the impacts of user mobility and operation behaviors on worm propagation. Meanwhile, we conduct extensive simulations to show our model can characterize propagation features accurately. The results in this paper not only provide a deep understanding of new worm propagation, but also serve as fundamental defense guidelines.},
  archive      = {J_TMC},
  author       = {Tianbo Wang and Chunhe Xia and Xiaojian Li and Yang Xiang},
  doi          = {10.1109/TMC.2020.3026342},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1639-1656},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Epidemic heterogeneity and hierarchy: A study of wireless hybrid worm propagation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep reinforcement learning based MAC protocol for
underwater acoustic networks. <em>TMC</em>, <em>21</em>(5), 1625–1638.
(<a href="https://doi.org/10.1109/TMC.2020.3029844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long propagation delay that causes throughput degradation of underwater acoustic networks (UWANs) is a critical issue in the medium access control (MAC) protocol design in UWANs. This paper develops a deep reinforcement learning (DRL) based MAC protocol for UWANs, referred to as delayed-reward deep-reinforcement learning multiple access (DR-DLMA), to maximize the network throughput by judiciously utilizing the available time slots resulted from propagation delays or not used by other nodes. In the DR-DLMA design, we first put forth a new DRL algorithm, termed as delayed-reward deep Q-network (DR-DQN). Then we formulate the multiple access problem in UWANs as a reinforcement learning (RL) problem by defining state, action, and reward in the parlance of RL, and thereby realizing the DR-DLMA protocol. In traditional DRL algorithms, e.g., the original DQN algorithm, the agent can get access to the &amp;#x201C;reward&amp;#x201D; from the environment immediately after taking an action. In contrast, in our design, the &amp;#x201C;reward&amp;#x201D; (i.e., the ACK packet) is only available after twice the one-way propagation delay after the agent takes an action (i.e., to transmit a data packet). The essence of DR-DQN is to incorporate the propagation delay into the DRL framework and modify the DRL algorithm accordingly. In addition, in order to reduce the cost of online training deep neural network (DNN), we provide a nimble training mechanism for DR-DQN. The optimal network throughputs in various cases are given as a benchmark. Simulation results show that our DR-DLMA protocol with nimble training mechanism can: (i) find the optimal transmission strategy when coexisting with other protocols in a heterogeneous environment; (ii) outperform state-of-the-art MAC protocols (e.g., slotted FAMA and DOTS) in a homogeneous environment; and (iii) greatly reduce energy consumption and run-time compared with DR-DLMA with traditional DNN training mechanism.},
  archive      = {J_TMC},
  author       = {Xiaowen Ye and Yiding Yu and Liqun Fu},
  doi          = {10.1109/TMC.2020.3029844},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1625-1638},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deep reinforcement learning based MAC protocol for underwater acoustic networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross technology distributed MIMO for low power IoT.
<em>TMC</em>, <em>21</em>(5), 1609–1624. (<a
href="https://doi.org/10.1109/TMC.2020.3029218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is scaling rapidly to billions of low power devices, with diverse radio technologies sharing common unlicensed spectrum. Inevitably, this results in rampant cross-technology collisions between the devices that lead to wasteful re-transmissions, draining the battery life of low-power devices significantly. We present CharIoT, the first cross-technology distributed MIMO receiver system that exploits the potential of distributed MIMO to facilitate better co-existence and decoding of a large number of simultaneous low power uplink transmissions from unmodified low-power clients. CharIoT is a recovery-based system that intelligently collects radio samples from teams of light-weight IoT gateways and streams them to the cloud to effectively resolve collisions. At the cloud, CharIoT develops a suite of technology-specific software filters that decouple collisions across diverse technologies, facilitating seamless co-existence across low power radios. An implementation of CharIoT on inexpensive RTL-SDR gateways connected to Raspberry Pis decode collisions of four popular IoT technologies in the 868MHz ISM bands &amp;#x2013; LoRa, XBee, Z-Wave, and SIGFOX showing gains in throughput of up to 4&amp;#x00D7; and battery life of up to 3.5 years.},
  archive      = {J_TMC},
  author       = {Revathy Narayanan and Swarun Kumar and C. Siva Ram Murthy},
  doi          = {10.1109/TMC.2020.3029218},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1609-1624},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cross technology distributed MIMO for low power IoT},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cognitive balance for fog computing resource in internet of
things: An edge learning approach. <em>TMC</em>, <em>21</em>(5),
1596–1608. (<a href="https://doi.org/10.1109/TMC.2020.3026580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the highly dynamic fog computing resource requirements introduced by the diverse services of the Internet of Things (IoT) result in an imbalance between computing resource providers and consumers. However, current computing resource scheduling schemes cannot cognize the dynamic resources available and do not possess decision-making or management capabilities, which leads to inefficient use of computing resources and a decreased quality of service (QoS). Balancing computing resources cognitively at the IoT edge remains unresolved. In this paper, a cognition-centric fog computing resource balancing (CFCRB) scheme is proposed for edge intelligence-enabled IoT. First, we propose a cognitive balance architecture with a cognition plane, which includes service demand monitoring, policy processing and knowledge storage of cognitive fog resources. Second, we propose the fog functions structure with sensing, interaction and learning functionalities, realizing the knowledge-based proactive discovery and dynamic orchestration of resource sharing nodes. Finally, a distributed edge learning algorithm is proposed to construct knowledge of the balance between computing resource helpers and requesters in cognitive fogs, which is further proved with mathematics. The simulation results indicate the efficiency of the proposed scheme.},
  archive      = {J_TMC},
  author       = {Siyi Liao and Jun Wu and Shahid Mumtaz and Jianhua Li and Rosario Morello and Mohsen Guizani},
  doi          = {10.1109/TMC.2020.3026580},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1596-1608},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cognitive balance for fog computing resource in internet of things: An edge learning approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Auction design for edge computation offloading in SDN-based
ultra dense networks. <em>TMC</em>, <em>21</em>(5), 1580–1595. (<a
href="https://doi.org/10.1109/TMC.2020.3026319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relying on offloading computation tasks to the network edge, ultra dense networks (UDNs) are capable of providing delay-aware service to nearby users. Meanwhile, software defined networking (SDN) is deemed as an effective technology to ease the management of infrastructure plane and control plane in UDNs, which is termed as SDN-based ultra dense networks. Specifically, the centralized SDN controller is capable of managing the whole network globally. With the increasing demands for various applications as well as the limitation of computation, storage and communication resource, how to allocate spectrum resource appropriately is imperative. In this article, we mainly show solicitude for spectrum sharing and edge computation offloading problems in SDN-based ultra dense networks, constituted of various macro base stations (MBSs), small-cell base stations (SBSs) and user equipments (UEs). To address this issue, we propose a second-price auction scheme for ensuring the fair bidding for spectrum rent, which enables the MBS edge cloud and SBS edge cloud to occupy the channel in cooperative and competitive modes. Moreover, the MBS edge cloud is termed as the buyer, and the SBS edge clouds are the sellers who sell the offloading resource to the MBS edge cloud. To be specific, the spectrum sharing and computation offloading scheme is executed in the SDN controller, and the controller is responsible for distributing spectrum allocation instructions to the infrastructure plane. Finally, experimental results validate the effectiveness of our proposed scheme in SDN-based ultra dense networks.},
  archive      = {J_TMC},
  author       = {Feixiang Li and Haipeng Yao and Jun Du and Chunxiao Jiang and Zhu Han and Yunjie Liu},
  doi          = {10.1109/TMC.2020.3026319},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1580-1595},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Auction design for edge computation offloading in SDN-based ultra dense networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). App popularity prediction by incorporating time-varying
hierarchical interactions. <em>TMC</em>, <em>21</em>(5), 1566–1579. (<a
href="https://doi.org/10.1109/TMC.2020.3029718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {App popularity prediction is a significant task in mobile service development, which predicts an app&#39;s future popularity based on its current behaviors. It provides benefits from app development to targeted investment. Popularity is affected by two factors, i.e., internal ones like reviews and external ones like interaction among apps. However, most related studies only explore internal factors but neglect external ones. In fact, external factor plays an important role in popularity prediction modelling since it is the promoting and/or inhibiting influence resulted by app interaction. The app interaction has two major characteristics, i.e., interactivity and dynamicity, which brings challenges to app popularity prediction due to two reasons: 1) interactivity—it is hard to evaluate the existence and influence intensity of interactions; 2) dynamicity—the nature of interaction influence, e.g., promoting or inhibiting, and its intensity on popularity change with time. In this paper, we propose DeePOP, a popularity prediction model that innovatively leverages time-varying hierarchical interactions. First, we propose Hierarchical Interaction Graph, which is first studied in this work, to organically characterize the relationship and influence among apps. Second, DeePOP integrates internal factors and time-varying hierarchical interactions as inputs to build the prediction model. It develops multi-level modules based on Recurrent Neural Network with attention mechanism and generates multi-step time series predictions by fusing the outputs of modules. Experiments on a real-world dataset show that DeePOP outperforms state-of-the-art methods in prediction accuracy, effectively reducing the Root Mean Square Error (RMSE) to 0.088.},
  archive      = {J_TMC},
  author       = {Yixuan Zhang and Jiaqi Liu and Bin Guo and Zhu Wang and Yunji Liang and Zhiwen Yu},
  doi          = {10.1109/TMC.2020.3029718},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1566-1579},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {App popularity prediction by incorporating time-varying hierarchical interactions},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An analysis of a stochastic ON-OFF queueing mobility model
for software-defined vehicle networks. <em>TMC</em>, <em>21</em>(5),
1552–1565. (<a href="https://doi.org/10.1109/TMC.2020.3031319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have recently witnessed a number of new software-defined paradigms of VANET in what is referred to as software-defined vehicle networks (SDVN). In order to evaluate the performance of these new proposals and architectures, analytical and simulation models are needed. In this paper, we propose an analytical model based on ON-OFF queueing networks under exponential and general service time distributions. The model can be used to evaluate the performance of SDVNs and takes into account the effect of mobility such as, hand overs, node turning ON/OFF, node going temporary out of coverage, and intermittent connections. This mobility effect was modelled as a queueing station with exponentially random ON-OFF service times, where traffic arrives according to a Poisson random process during the exponentially random ON period and the service time is exponentially distributed. However, during the OFF period the service time is exponentially distributed but with lower rates. We studied the ON-OFF queueing behaviour extensively for both finite-capacity and infinite-capacity queues. Three hypothetical SDVN scenarios were considered, taking into account the effect of mobility and the large number of connected nodes. Results were cross-validated with those obtained by a simulation model. These tools will be valuable for researchers interested in getting quantitative answers for their SDVN architectures.},
  archive      = {J_TMC},
  author       = {Talal A. Edwan and Ashraf Tahat and Halim Yanikomeroglu and Jon Crowcroft},
  doi          = {10.1109/TMC.2020.3031319},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1552-1565},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An analysis of a stochastic ON-OFF queueing mobility model for software-defined vehicle networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A queueing game based management framework for fog computing
with strategic computing speed control. <em>TMC</em>, <em>21</em>(5),
1537–1551. (<a href="https://doi.org/10.1109/TMC.2020.3026194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel management framework for fog computing with strategic computing speed control at fog nodes (FNs) is studied. In the considered model, mobile users declare requests of offloading resource-hungry computation tasks that are dynamically collected at a dedicated edge server (ES). Upon receiving these requests, the ES can decide to either self-process or delegate some workloads to third-party FNs for maximizing the overall management profit. Unlike the existing work, this paper takes into account strategic behaviors of FNs in computing speed control, i.e., each FN can strategically allocate its computing resource to maximize its utility, which consists of the benefit gained from executing offloaded tasks and the cost incurred by dissatisfied (delayed) service to its own subscribed tasks. To jointly address the long-term system performance and FNs&amp;#x2019; strategic interactions, a scheduling mechanism integrating a noncooperative game and a queueing model is formulated. We then investigate two delegation reward settings, i.e., constant and utility-dependent delegation prices, and propose efficient adaptive algorithms to determine the optimal workload distribution at the ES and the computing speed equilibrium among FNs. Both theoretical analyses and simulations are conducted to evaluate the performance of the proposed solutions and demonstrate their superiorities over counterparts.},
  archive      = {J_TMC},
  author       = {Changyan Yi and Jun Cai and Kun Zhu and Ran Wang},
  doi          = {10.1109/TMC.2020.3026194},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {5},
  number       = {5},
  pages        = {1537-1551},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A queueing game based management framework for fog computing with strategic computing speed control},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tuft: Tree based heuristic data dissemination for mobile
sink wireless sensor networks. <em>TMC</em>, <em>21</em>(4), 1520–1536.
(<a href="https://doi.org/10.1109/TMC.2020.3022403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) with a static sink suffer from concentrated data traffic in the vicinity of the sink, which increases the burden on the nodes surrounding the sink, and impels them to deplete their batteries faster than other nodes in the network. Mobile sinks solve this corollary by providing a more balanced traffic dispersion, by shifting the traffic concentration with the mobility of the sink. However, it brings about a new expenditure to the network, where prior to delivering data, nodes are obligated to procure the sink&#39;s current position. This paper proposes Tuft, a novel hierarchical tree structure that is able to avert the overhead cost from delivering the fresh sink&#39;s position while maintaining a uniform dispersion of data traffic concentration. Tuft appropriates the mobility of the sink to its advantage, to increase the uniformity of energy consumption throughout the network. Moreover, we propose Tuft-Cells, a distributed dissemination protocol that models data routing as a multi-criteria decision making (MCDM) in three steps. To begin with, each criterion constitutes a random variable defined by a mass function. Each of these cirterion serves a proportionately distinguishable alternative, and hence, may conflict. Therefore, the analytic hierarchy process (AHP) quantifies the relationship between criteria. Finally, the final forwarding decision is derived by a weighted aggregation. Tuft is compared with state-of-the-art protocols, and the performance evaluation illustrates that our protocol adheres to the requirements of WSNs, in terms of energy consumption, and success ratio, considering the additional overhead cost brought by the mobility of the sink.},
  archive      = {J_TMC},
  author       = {Omar Busaileh and Ammar Hawbani and Xingfu Wang and Ping Liu and Liang Zhao and Ahmed Al-Dubai},
  doi          = {10.1109/TMC.2020.3022403},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1520-1536},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Tuft: Tree based heuristic data dissemination for mobile sink wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward a realistic approach for the deployment of 3D
wireless sensor networks. <em>TMC</em>, <em>21</em>(4), 1508–1519. (<a
href="https://doi.org/10.1109/TMC.2020.3024939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying wireless sensor networks (WSNs) in real-world applications is still a challenging problem. Indeed, the number, locations, and orientations of directional sensors determine the topology of the WSN, which will further influence its overall cost and performance. Existing works have assumed simple sensor behavior and/or ideal environmental factors; thus, often they do not produce practical results. On the contrary, in this paper, we revisit the 3D WSNs deployment problem while considering realistic assumptions regarding the modeling of both the sensors and the environment. More precisely, we propose a Bresenham line-of-sight based realistic coverage model for 3D environments. This latter is used to re-formalize the 3D WSNs deployment problem while considering a realistic spatial model of the environment. The problem is then solved using a multi-objective genetic algorithm endowed with new adaptive and guided genetic operators. Moreover, we enhance the performance of the proposed approach by introducing two optimization techniques, namely: search space reduction and sampling-based evaluation. We show the effectiveness and efficiency of the proposed approach through extensive simulations.},
  archive      = {J_TMC},
  author       = {Ayoub Saad and Mustapha Reda Senouci and Oussama Benyattou},
  doi          = {10.1109/TMC.2020.3024939},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1508-1519},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Toward a realistic approach for the deployment of 3D wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). To what extent we repeat ourselves? Discovering daily
activity patterns across mobile app usage. <em>TMC</em>, <em>21</em>(4),
1492–1507. (<a href="https://doi.org/10.1109/TMC.2020.3021987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence of smartphones, people have left abundant behavior records in cyberspace. Discovering and understanding individuals’ cyber activities can provide useful implications for policymakers, service providers, and app developers. In this paper, we propose a framework to discover daily cyber activity patterns across people&#39;s mobile app usage. The framework first segments app usage traces into short time windows and then applies a probabilistic topic model to infer users’ cyber activities in each window. By constructing and exploring the coherence of users’ activity sequences, the framework can identify individuals’ daily patterns. Next, the framework uses a hierarchical clustering algorithm to recognize the common patterns across diverse groups of individuals. We apply the framework on a large-scale and real-world dataset, consisting of 653,092 users with 971,818,946 usage records of 2,000 popular mobile apps. Our analysis shows that people usually follow yesterday&#39;s activity patterns, but the patterns tend to deviate as the time-lapse increases. We also discover five common daily cyber activity patterns, including afternoon reading, nightly entertainment, pervasive socializing, commuting, and nightly socializing. Our findings have profound implications on identifying the demographics of users and their lifestyles, habits, service requirements, and further detecting other disrupting trends such as working overtime and addiction to the game and social media.},
  archive      = {J_TMC},
  author       = {Tong Li and Yong Li and Mohammad Ashraful Hoque and Tong Xia and Sasu Tarkoma and Pan Hui},
  doi          = {10.1109/TMC.2020.3021987},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1492-1507},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {To what extent we repeat ourselves? discovering daily activity patterns across mobile app usage},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time efficient tag searching in large-scale RFID systems: A
compact exclusive validation method. <em>TMC</em>, <em>21</em>(4),
1476–1491. (<a href="https://doi.org/10.1109/TMC.2020.3021678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RFID technology has been widely applied in a range of applications such as inventory control, warehouse management and supply chain logistics. Many practical applications need to search a given set of tags (called wanted tags ) to determine which of them are present in the system, which is usually called tag searching . Existing tag searching protocols suffer performance bottleneck and the time efficiency and need to be improved. The bottleneck stems from two factors. First, the existing methods validate the wanted tags in a random way due to the randomness of the hash function, which unavoidably generate many useless slots. Second, in order to achieve the predefined reliability requirement, the existing methods have to repeatedly validate target tags multiple times. In this paper, we design new tag searching techniques of compact exclusive validation that break through the existing performance bottleneck from two aspects. First, our protocols avoid slot waste. Different from random tag validation, our protocols validate tags orderly by mapping the wanted tags and the slots in a one-to-one manner, which makes the reader be able to validate tags in every slot. Second, our protocols avoid repeated tag responding. By combining two lightweight indicators, we rapidly filter out non-wanted tags so that there is no interference when validating the wanted tags. Hence, we need to validate each wanted tag only once, which avoids redundant validation and greatly improves time efficiency. Our protocols work with the assumption that the rough number of tags in the system can be obtained by using existing estimation algorithms, but they do not need to know exactly which tags are in the system. Theoretical analysis illustrates our methods achieve linear time complexity. Extensive experimental results show that, our best protocol can improve the time efficiency by up to 81 percent when compared with the-state-of-art solution.},
  archive      = {J_TMC},
  author       = {Xuan Liu and Jiangjin Yin and Jia Liu and Shigeng Zhang and Bin Xiao},
  doi          = {10.1109/TMC.2020.3021678},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1476-1491},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Time efficient tag searching in large-scale RFID systems: A compact exclusive validation method},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Throughput analysis of NOMA-ALOHA. <em>TMC</em>,
<em>21</em>(4), 1463–1475. (<a
href="https://doi.org/10.1109/TMC.2020.3024767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers from the perspective of MAC layer, a throughput maximization problem of NOMA-ALOHA, ALOHA implemented over NOMA (non-orthogonal multiple access), that can decode simultaneously transmitted multiple packets via successive interference cancellation (SIC) if each of the multiple packets has a different power level from those of others. We start with a throughput optimization problem for two power levels and extend it to a problem for a general number of power levels. For the case of two power levels, we find upper and lower bounds of the maximum throughput and suggest a practical sub-optimal transmission probability whose throughput is close to the maximum. The maximum throughput of NOMA-ALOHA is at least 1.774 times higher than that of traditional slotted ALOHA in our numerical example. We extend the optimization problem into a general one with arbitrary number of power levels. We numerically analyze the performance through a relaxed problem of the original one with high complexity. Our numerical analysis shows that the maximum throughput of NOMA-ALOHA with three power levels is 2.33 times higher than simple ALOHA’s maximum throughput and that adding one power level to NOMA-ALOHA with two power levels enhances throughput at least by more than 28 percent.},
  archive      = {J_TMC},
  author       = {Youngmi Jin and Tae-Jin Lee},
  doi          = {10.1109/TMC.2020.3024767},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1463-1475},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Throughput analysis of NOMA-ALOHA},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Surveillance of uneven surface with self-organizing unmanned
aerial vehicles. <em>TMC</em>, <em>21</em>(4), 1449–1462. (<a
href="https://doi.org/10.1109/TMC.2020.3022075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring or surveillance needs Unmanned Aerial Vehicles or Drones to cover each point within the area of interest. In general, any outdoor region can be modeled as a surface. Thus we focus on surveillance of a surface with a random connected distribution of drones such that a reorganization of drones maximizes the covered area without creating any coverage hole. In addition, the target is to provide a compact coverage to minimize the diameter of the network formed by the drones, which helps in faster communications. We present a centralized algorithm that achieves a maximal compact coverage. We propose two distributed algorithms based on Virtual Force and Local Voronoi , respectively. Extensive simulation studies show that our proposed algorithms result in hole-free maximal compact coverage with limited displacement. The self-organizing behavior of our Local Voronoi based algorithm can be replicated even in the presence of failures in the drones. The algorithm is capable of recovering a maximal coverage with the remaining non-faulty drones. Also, it is robust with respect to the addition of new drones in real-time. We finally supplement the simulation results to include churn in the network in the context of fault-tolerance and scalability.},
  archive      = {J_TMC},
  author       = {Dibakar Saha and Debasish Pattanayak and Partha Sarathi Mandal},
  doi          = {10.1109/TMC.2020.3022075},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1449-1462},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Surveillance of uneven surface with self-organizing unmanned aerial vehicles},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strategic network slicing management in radio access
networks. <em>TMC</em>, <em>21</em>(4), 1434–1448. (<a
href="https://doi.org/10.1109/TMC.2020.3025027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing might radically change the relations among different actors of the telecommunications ecosystem, where new players, active in different markets, could benefit of tailored connectivity services based on different business strategies. We argue that for fully exploiting the opportunities offered by network slicing, dynamic sharing of resources is crucial not only for efficiency and cost savings, but also for enabling a resource negotiation that can unleash the potential of new business relations. We develop an automated mechanism that allows tenants to take strategic decisions to optimize the management of their slices based on their instantaneous demands and model their interaction as in marketplace. We integrate our solution, based on game theory, on a 3GPP calibrated system level simulator, where a slice-aware scheduler enforces the tenants’ decisions at the Nash Equilibrium (NE). We compare our proposal with a static baseline, that assigns a fixed share of resources to each slice, and show that, by dynamically trading resources in the market, tenants achieve lower costs, and, therefore, higher profits. We provide an algorithmic implementation that guarantees the convergence to a single NE and test the computational complexity of our algorithm to an increasing number of slices in the system.},
  archive      = {J_TMC},
  author       = {Alessandro Lieto and Ilaria Malanchini and Silvio Mandelli and Eugenio Moro and Antonio Capone},
  doi          = {10.1109/TMC.2020.3025027},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1434-1448},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Strategic network slicing management in radio access networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Secure voice input on augmented reality headsets.
<em>TMC</em>, <em>21</em>(4), 1420–1433. (<a
href="https://doi.org/10.1109/TMC.2020.3020470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice-based input is usually used as the primary input method for augmented reality (AR) headsets due to immersive AR experience and good recognition performance. However, recent researches show that attackers can inject inaudible voice commands to the devices that lack voice verification. Even if we secure voice input with voice verification techniques, attackers can record the victim’s voice and replay it. To defend against voice-spoofing attacks, AR headsets should be able to determine whether the voice is from the person who is using the AR headsets. Existing voice-spoofing defense systems are designed for smartphone platforms and usually fail to work due to the special locations of microphones and loudspeakers on AR headsets. To address this challenge, in this paper, we propose a voice-spoofing defense system for AR headsets by leveraging both the internal body propagation and the air propagation of human voices. Experimental results show that our system can successfully accept normal users with average accuracy of 97 percent and defend against two basic types of attacks with average accuracy of at least 98 percent. More importantly, even if the attackers can fool our line-fitting model by manipulating special voice signals, our MCD-SVDD model can still reject them with accuracy of 100 percent.},
  archive      = {J_TMC},
  author       = {Jiacheng Shang and Jie Wu},
  doi          = {10.1109/TMC.2020.3020470},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1420-1433},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Secure voice input on augmented reality headsets},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SchrodinText: Strong protection of sensitive textual content
of mobile applications. <em>TMC</em>, <em>21</em>(4), 1402–1419. (<a
href="https://doi.org/10.1109/TMC.2020.3025119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many mobile applications deliver and show sensitive and private textual content to users including messages, social network posts, account information, and verification codes. All such textual content must be displayed to users but must be strongly protected from unauthorized access in mobile devices. Unfortunately, this is not the case in mobile devices today: malware that can compromise the OS can easily access textual content of other applications. We present SchrodinText, a system solution for strongly protecting the confidentiality of an application&#39;s selected UI textual content from a fully compromised OS. SchrodinText leverages a novel security monitor based on two hardware features on ARM processors: virtualization hardware and TrustZone. Our key contribution is a set of novel techniques that allow the OS to perform text rendering without needing access to the text itself, hence minimizing the trusted computing base (TCB). These techniques, collectively called oblivious rendering , enable the OS to rasterize and lay out all the characters without access to the text; the monitor resolves the right character glyphs onto the framebuffer observed by the user and protects them from the OS. Using our prototypes, we show that SchrodinText incurs noticeable overhead but that its performance is usable.},
  archive      = {J_TMC},
  author       = {Nicholas Wei and Ardalan Amiri Sani},
  doi          = {10.1109/TMC.2020.3025119},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1402-1419},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {SchrodinText: Strong protection of sensitive textual content of mobile applications},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust fuzzy learning for partially overlapping channels
allocation in UAV communication networks. <em>TMC</em>, <em>21</em>(4),
1388–1401. (<a href="https://doi.org/10.1109/TMC.2020.3023789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With significantly dynamic characteristics of the new aerial users, the emerging cellular-enabled unmanned aerial vehicle (UAV) communication paradigm raises great challenges to current research of UAV applications. As far as the robust channel allocation is concerned, the high mobility of UAV nodes and the unexpected disturbance of external environment would render most existing methods which rely on definite information and are vulnerable to dynamic environment, become less attractive or even invalid. In this paper, we particularly investigate a cellular-enabled mesh UAV network exploiting partially overlapping channels (POCs), and propose a distributed fuzzy space based learning scheme for POCs allocation to combat the dynamic environment. Rather than the perfect channel state information (CSI) assumption, the dynamic and uncertain CSI of UAVs is characterized by fuzzy number. On this basis, the allocation process can be implemented in a mapped fuzzy space. Integrating fuzzy-logic and game based learning, we formulate the problem of POCs assignment as a fuzzy payoffs game (FPG), and demonstrate the existence of fuzzy Nash equilibrium for our designed FPG. Then, with the derived priority vector in the fuzzy space, the equilibrium solution can be achieved by the proposed algorithm. Numerical simulations demonstrate the advantages of our new scheme.},
  archive      = {J_TMC},
  author       = {Chaoqiong Fan and Bin Li and Jia Hou and Yi Wu and Weisi Guo and Chenglin Zhao},
  doi          = {10.1109/TMC.2020.3023789},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1388-1401},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Robust fuzzy learning for partially overlapping channels allocation in UAV communication networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Revenue-optimal auction for resource allocation in wireless
virtualization: A deep learning approach. <em>TMC</em>, <em>21</em>(4),
1374–1387. (<a href="https://doi.org/10.1109/TMC.2020.3021416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless virtualization has become a key concept in future cellular networks which can provide multiple virtualized wireless networks for different mobile virtual network operators (MVNOs) over the same physical infrastructure. Resource allocation is a main challenging issue in wireless virtualization for which auction approaches have been widely used. However, for most existing auction-based allocation schemes, the objective is to maximize the social welfare (i.e., the sum of all valuations of winning bidders) due to its simplicity. While in reality, MVNOs are more interested in maximizing their own revenues (i.e., received payments from auction winners). However, the revenue-optimal auction problem is much more complex since the payment price is unknown before calculation. In this paper, we aim to design a revenue-optimal auction mechanism for resource allocation in wireless virtualization. Considering the complexity, deep learning techniques are applied. Specifically, we construct a multi-layer feed-forward neural network based on the analysis of optimal auction design. The neural network adopts users’ bids as the input and the allocation rule and conditional payment rule for the users as the output. The proposed auction mechanism possesses several desirable properties, e.g., individual rationality, incentive compatibility and budget constraint. Finally, simulation results demonstrate the effectiveness of the proposed scheme. Comparing with second-price auction and optimization-based schemes, the proposed scheme can increase the revenue by 10 and 30 percent on average, for single MVNO and multi-MVNO cases, respectively.},
  archive      = {J_TMC},
  author       = {Kun Zhu and Yuanyuan Xu and Qian Jun and Dusit Niyato},
  doi          = {10.1109/TMC.2020.3021416},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1374-1387},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Revenue-optimal auction for resource allocation in wireless virtualization: A deep learning approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PRIME: An optimal pricing scheme for mobile
sensors-as-a-service. <em>TMC</em>, <em>21</em>(4), 1362–1373. (<a
href="https://doi.org/10.1109/TMC.2020.3023885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a pricing scheme, named PRIME, for provisioning mobile Sensors-as-a-Service ( mSe-aaS ) in the mobile sensor-cloud (MSC) architecture, with an aim to optimally distribute the financial profit among different actors of MSC. Unlike traditional sensor-cloud, MSC introduces a new actor as device owner, whose mobile device hosts the physical sensor nodes. On the other hand, the device and sensor owners earn certain revenues, based on the usage of the sensor nodes and the mobile devices, for provisioning mSe-aaS to the end-users. MSC is a contemporary architecture, and therefore, no pricing scheme exists for it. In this work, we consider the presence of the device owner, sensor owner, Sensor-Cloud Service Provider (SCSP), and end-user to determine an optimal pricing strategy. In order to design such a strategy, we use the Lagrangian multiplier method and apply Karush-Kuhn-Tucker ( KKT ) conditions. On the other hand, an end-user has multiple options to select an SCSP among the available ones. Therefore, based on the reputation of all the available SCSPs, PRIME enables an end-user to select a suitable one. Extensive experimental results report that PRIME increases the profit of sensor and device owners by 25.67% and 29.12%, respectively. We also compare PRIME with an existing pricing scheme for traditional sensor-cloud architecture. We notice that the service return using PRIME increases by 55.31% as compared to the same using the traditional sensor-cloud architecture.},
  archive      = {J_TMC},
  author       = {Arijit Roy and Sudip Misra and Soumi Nag},
  doi          = {10.1109/TMC.2020.3023885},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1362-1373},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {PRIME: An optimal pricing scheme for mobile sensors-as-a-service},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pricing and resource allocation optimization for IoT fog
computing and NFV: An EPEC and matching based perspective. <em>TMC</em>,
<em>21</em>(4), 1349–1361. (<a
href="https://doi.org/10.1109/TMC.2020.3025189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of devices connected to the Internet of Things (IoT) is growing at an enormous rate globally. In the next generation networks, distributed fog computing deployments at the network edge can provide computing resources to the users, especially for latency-sensitive applications. Further, the heterogeneous needs of the fifth generation (5G) networks demand the virtualization of network functions, termed as network function virtualization (NFV). Therefore, an integrated NFV and fog computing resource allocation framework for IoT is of prime importance. Accordingly, in this paper, we model the interactions between the data service operators (DSOs) and the authorized data service subscribers (ADSSs) as an equilibrium problem with equilibrium constraints (EPEC), and utilize the alternating direction method of multipliers (ADMM) as a large-scale optimization tool to obtain solutions. This results in the optimization of resource pricing for the DSOs and the amount of resources to be purchased by the ADSSs. Moreover, we propose a many-to-many matching based model to allocate the fog node (FN) resources according to the VNF resource requirements of the ADSSs. Simulation results show the effectiveness of our proposed approach in achieving efficient resource allocation in NFV enabled IoT fog computing.},
  archive      = {J_TMC},
  author       = {Neetu Raveendran and Huaqing Zhang and Lingyang Song and Li-Chun Wang and Choong Seon Hong and Zhu Han},
  doi          = {10.1109/TMC.2020.3025189},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1349-1361},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Pricing and resource allocation optimization for IoT fog computing and NFV: An EPEC and matching based perspective},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Performance analysis and optimization of cache-assisted CoMP
for clustered D2D networks. <em>TMC</em>, <em>21</em>(4), 1334–1348. (<a
href="https://doi.org/10.1109/TMC.2020.3020552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caching at mobile devices and leveraging cooperative device-to-device (D2D) communications are two promising approaches to support massive content delivery over wireless networks while mitigating the effects of interference. To show the impact of cooperative communication on the performance of cache-enabled D2D networks, the notion of device clustering must be factored in to convey a realistic description of the network performance. In this regard, this paper develops a novel mathematical model, based on stochastic geometry and an optimization framework for cache-assisted coordinated multi-point (CoMP) transmissions with clustered devices. Devices are spatially distributed into disjoint clusters and are assumed to have a surplus memory to cache files from a known library, following a random probabilistic caching scheme. Desired contents that are not self-cached can be obtained via D2D CoMP transmissions from neighboring devices or, as a last resort, from the network. For this model, we analytically characterize the offloading gain and rate coverage probability as functions of the system parameters. An optimal caching strategy is then defined as the content placement scheme that maximizes the offloading gain. For a tractable optimization framework, we pursue two separate approaches to obtain a lower bound and a provably accurate approximation of the offloading gain, which allows us to obtain optimized caching strategies. Remarkably, if we replace the obtained expression for offloading gain with its lower bound, we can find a suboptimal caching strategy that is not only described via analytical formulas but can also show an improvement over the state-of-the-art caching schemes. Results reveal that cooperative transmission becomes more appealing in denser D2D caching networks and adverse interference conditions, which is the case of the imminent Internet of Things (IoT) and ns era.},
  archive      = {J_TMC},
  author       = {Ramy Amer and Hesham ElSawy and Jacek Kibilda and M. Majid Butt and Nicola Marchetti},
  doi          = {10.1109/TMC.2020.3020552},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1334-1348},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Performance analysis and optimization of cache-assisted CoMP for clustered D2D networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Partial computation offloading and adaptive task scheduling
for 5G-enabled vehicular networks. <em>TMC</em>, <em>21</em>(4),
1319–1333. (<a href="https://doi.org/10.1109/TMC.2020.3025116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variety of novel mobile applications are developed to attract the interests of potential users in the emerging 5G-enabled vehicular networks. Although computation offloading and task scheduling have been widely investigated, it is rather challenging to decide the optimal offloading ratio and perform adaptive task scheduling in high-dynamic networks. Furthermore, the scheduling policy made by the network operator may be violated, since vehicular users are rational and selfish to maximize their own profits. By considering the incentive compatibility and individual rationality of vehicular users, we present POETS, an efficient partial computation offloading and adaptive task scheduling algorithm to maximize the overall system-wide profit. Specially, a two-sided matching algorithm is first proposed to derive the optimal transmission scheduling discipline. After that, the offloading ratio of vehicular users can be obtained through convex optimization, without any information of other users. Furthermore, a non-cooperative game is constructed to derive the payoff of vehicular users that can reach the equilibrium between users and the network operator. Theoretical analyses and performance evaluations based on real-world traces of taxies demonstrate the effectiveness of our proposed solution.},
  archive      = {J_TMC},
  author       = {Zhaolong Ning and Peiran Dong and Xiaojie Wang and Xiping Hu and Jiangchuan Liu and Lei Guo and Bin Hu and Ricky Y. K. Kwok and Victor C. M. Leung},
  doi          = {10.1109/TMC.2020.3025116},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1319-1333},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Partial computation offloading and adaptive task scheduling for 5G-enabled vehicular networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimizing mobile crowdsensing platforms for boundedly
rational users. <em>TMC</em>, <em>21</em>(4), 1305–1318. (<a
href="https://doi.org/10.1109/TMC.2020.3023757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In participatory mobile crowdsensing (MCS) users repeatedly make choices among a finite set of alternatives, i.e., whether to contribute to a task or not and which task to contribute to. The platform coordinating the MCS campaigns often engineers these choices by selecting MCS tasks to recommend to users and offering monetary or in-kind rewards to motivate their contributions to them. In this paper, we revisit the well-investigated question of how to optimize the contributions of mobile end users to MCS tasks. However, we depart from the bulk of related literature by explicitly accounting for the bounded rationality evidenced in human decision making. Bounded rationality is a consequence of cognitive and other kinds of constraints, e.g., time pressure, and has been studied extensively in behavioral science. We first draw on work in the field of cognitive psychology to model the way boundedly rational users respond to MCS task offers as Fast-and-Frugal-Trees (FFTs) . With each MCS task modeled as a vector of feature values, the decision process in FFTs proceeds through sequentially parsing lexicographically ordered features, resulting in choices that are satisfying but not necessarily optimal. We then formulate, analyze and solve the novel optimization problems that emerge for both nonprofit and for-profit MCS platforms in this context. The evaluation of our optimization approach highlights significant gains in both platform revenue and quality of task contributions when compared to heuristic rules that do not account for the lexicographic structure in human decision making. We show how this modeling framework readily extends to platforms that present multiple task offers to the users. Finally, we discuss how these models can be trained, iterate on their assumptions, and point to their implications for applications beyond MCS, where end-users make choices through the mediation of mobile/online platforms.},
  archive      = {J_TMC},
  author       = {Merkouris Karaliopoulos and Eleni Bakali},
  doi          = {10.1109/TMC.2020.3023757},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1305-1318},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Optimizing mobile crowdsensing platforms for boundedly rational users},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measurement errors in range-based localization algorithms
for UAVs: Analysis and experimentation. <em>TMC</em>, <em>21</em>(4),
1291–1304. (<a href="https://doi.org/10.1109/TMC.2020.3020584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localizing ground devices (GDs) is an important requirement for a wide variety of applications, such as infrastructure monitoring, precision agriculture, search and rescue operations, to name a few. To this end, unmanned aerial vehicles (UAVs) or drones offer a promising technology due to their flexibility. However, the distance measurements performed using a drone, an integral part of a localization procedure, incur several errors that affect the localization accuracy. In this paper, we provide analytical expressions for the impact of different kinds of measurement errors on the ground distance between the UAV and GDs. We review three range-based and three range-free localization algorithms, identify their source of errors, and analytically derive the error bounds resulting from aggregating multiple inaccurate measurements. We then extend the range-free algorithms for improved accuracy. We validate our theoretical analysis and compare the observed localization error of the algorithms after collecting data from a testbed using ten GDs and one drone, equipped with ultra wide band (UWB) antennas and operating in an open field. Results show that our analysis closely matches with experimental localization errors. Moreover, compared to their original counterparts, the extended range-free algorithms significantly improve the accuracy.},
  archive      = {J_TMC},
  author       = {Francesco Betti Sorbelli and Cristina M. Pinotti and Simone Silvestri and Sajal K. Das},
  doi          = {10.1109/TMC.2020.3020584},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1291-1304},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Measurement errors in range-based localization algorithms for UAVs: Analysis and experimentation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint charging and relocation recommendation for e-taxi
drivers via multi-agent mean field hierarchical reinforcement learning.
<em>TMC</em>, <em>21</em>(4), 1274–1290. (<a
href="https://doi.org/10.1109/TMC.2020.3022173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, most of the taxi drivers have become users of the relocation recommendation service offered by online ride-hailing platforms (e.g., Uber and Didi Chuxing), which could oftentimes lead drivers to places with profitable orders. At the same time, electric taxis (e-taxis) are increasingly adopted and gradually replacing gasoline taxis in today’s public transportation systems due to their environmental-friendly nature. Though effective for traditional gasoline taxis, existing relocation recommendation schemes are rather suboptimal for e-taxi drivers’ user experience. On one hand, the existing schemes take no account of taxis’ refueling decisions, as the refueling durations of gasoline taxis are usually short enough to be ignored. However, the charging duration of the e-taxis spent at charging stations can be as long as hours. Obviously, an e-taxi’s battery could be easily depleted by the continuous relocations suggested by existing schemes, and thus will have to be charged for a long time afterwards, making the e-taxi driver miss numerous order-serving opportunities. On the other hand, charging posts are typically sparsely and unevenly distributed across a city. With no consideration of charging opportunities, existing schemes could probably send an e-taxi to an area with no charging post around, even though its battery is running low. To optimize e-taxi drivers’ user experience, in this paper, we design a joint charging and relocation recommendation system for e-taxi drivers (CARE) . We take the perspective of e-taxi drivers and formulate their decision making as a multi-agent reinforcement learning problem where each e-taxi driver aims to maximize his own cumulative rewards. More specifically, we propose a novel multi-agent mean field hierarchical reinforcement learning (MFHRL) framework. The hierarchical architecture of MFHRL helps the proposed CARE provide far-sighted charging and relocation recommendations for e-taxi drivers. Besides, we integrate each hierarchical level of MFHRL separately with the mean field approximation to incorporate e-taxis’ mutual influences in decision making. We set up a simulator with one of the largest real-world e-taxi datasets in Shenzhen, China, which contains the GPS trajectory data and transaction data of 3848 e-taxis from June 1st to June 30th, 2017, coupled with 165 charging stations including 317 fast charging posts and 1421 slow charging posts. We adopt this simulator to generate 6 dynamic urban environments, which reflect the different real-world scenarios faced by e-taxi drivers. In all of these environments, we conduct extensive experiments to validate that the proposed MFHRL framework greatly outperforms all baselines by significantly increasing the rewards obtained by e-taxi drivers. Besides, we also show that the charging policy learned by MFHRL can effectively reduce the range anxiety of e-taxi drivers, which significantly boosts e-taxi drivers’ quality of experience.},
  archive      = {J_TMC},
  author       = {Enshu Wang and Rong Ding and Zhaoxing Yang and Haiming Jin and Chenglin Miao and Lu Su and Fan Zhang and Chunming Qiao and Xinbing Wang},
  doi          = {10.1109/TMC.2020.3022173},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1274-1290},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint charging and relocation recommendation for E-taxi drivers via multi-agent mean field hierarchical reinforcement learning},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IoT vs. Human: A comparison of mobility. <em>TMC</em>,
<em>21</em>(4), 1257–1273. (<a
href="https://doi.org/10.1109/TMC.2020.3019988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Thing (IoT) devices are rapidly becoming an indispensable part of our life with their increasing deployment in many promising areas, including tele-health, smart city, intelligent agriculture. Understanding the mobility of IoT devices is essential to improve quality of service in IoT applications, such as route planning in logistic management, infrastructure deployment, cellular network update and congestion detection in intelligent traffic. Despite its importance, there are not many results pertaining to the mobility of IoT devices. In this article, we aim to answer three research questions: (i) what are the mobility patterns of IoT device? (ii) what are the differences between IoT device and smartphone mobility patterns? (iii) how the IoT device mobility patterns differ among device types and usage scenarios? We present a comprehensive characterization of IoT device mobility patterns from the perspective of cellular data networks, using a 36-days long signal trace, including 1.5 million IoT devices and 0.425 million smartphones, collected from a nation-wide cellular network in China. We first investigate the basic patterns of IoT devices from two perspectives: temporal and spatial characteristics. Our study finds that IoT device mobility exhibits significantly different patterns compared with smartphones in multiple aspects. For instance, IoT devices move more frequently and have larger radius of gyration. Then we explore the essential mobility of IoT devices by utilizing two models that reveal the nature of human mobility, i.e., exploration and preferential return (EPR) model and entropy based predictability model. We find that IoT devices, with few exceptions, behave totally different from human, and we further derive a new formulation to describe their movement. We also find the gap mobility predictability and predictability limit between IoT and human is not as big as people expected.},
  archive      = {J_TMC},
  author       = {Dianlei Xu and Huandong Wang and Yong Li and Sasu Tarkoma and Depeng Jin and Pan Hui},
  doi          = {10.1109/TMC.2020.3019988},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1257-1273},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {IoT vs. human: A comparison of mobility},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph attention spatial-temporal network with collaborative
global-local learning for citywide mobile traffic prediction.
<em>TMC</em>, <em>21</em>(4), 1244–1256. (<a
href="https://doi.org/10.1109/TMC.2020.3020582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile cellular technologies and the increasing popularity of mobile and Internet of Things (IoT) devices, timely mobile traffic forecasting with high accuracy becomes more and more critical for proactive network service provisioning and efficient network resource allocation in smart cities. Traditional traffic forecasting methods mostly rely on time series prediction techniques, which fail to capture the complicated dynamic nature and spatial relations of mobile traffic demand. In this paper, we propose a novel deep learning framework, graph attention spatial-temporal network (GASTN), for accurate citywide mobile traffic forecasting, which can capture not only local geographical dependency but also distant inter-region relationship when considering spatial factor. Specifically, GASTN considers spatial correlation through our constructed spatial relation graph and utilizes structural recurrent neural networks to model the global near-far spatial relationships as well as the temporal dependencies. In the framework of GASTN, two attention mechanisms are designed to integrate different effects in a holistic way. Besides, in order to further enhance the prediction performance, we propose a collaborative global-local learning strategy for the training of GASTN, which takes full advantage of the knowledge from both the global model and local models for individual regions and enhance the effectiveness of our model. Extensive experiments on a large-scale real-world mobile traffic dataset demonstrate that our GASTN model dramatically outperforms the state-of-the-art methods. And it reveals that a significant enhancement in the prediction performance of GASTN can be obtained by leveraging the collaborative global-local learning strategy.},
  archive      = {J_TMC},
  author       = {Kaiwen He and Xu Chen and Qiong Wu and Shuai Yu and Zhi Zhou},
  doi          = {10.1109/TMC.2020.3020582},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1244-1256},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Graph attention spatial-temporal network with collaborative global-local learning for citywide mobile traffic prediction},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coordinated framework for spectrum allocation and user
association in 5G HetNets with mmWave. <em>TMC</em>, <em>21</em>(4),
1226–1243. (<a href="https://doi.org/10.1109/TMC.2020.3022681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense deployment of small cells operating on different frequency bands based on multiple technologies provides a fundamental way to face the imminent thousand-fold traffic augmentation. This heterogeneous network (HetNet) architecture enables efficient traffic offloading among different tiers and technologies. However, research on multi-tier HetNets where various tiers share the same microwave spectrum has been well-addressed over the past years. Therefore, our work is targeted towards novel multi-tier HetNets with disparate spectrum (microwave and millimeter wave). In fact, despite the huge capacity brought by millimeter-wave technology, the latter will fail to provide universal coverage, especially indoor, and so mmWave will inevitably co-exist with a traditional sub-6GHz cellular network. In this work, we propose a coordinated user association and spectrum allocation by resorting to non-cooperative game theory. In fact, in such an arduous context, efficient distributed solutions are imperative. Extensive simulation results show the precedence of our coordinated approach in comparison with state-of-the-art heuristics. Moreover, we evaluate the impact of various network parameters, such as mmWave density, cell load, and user distribution and density, offering valuable guidelines into practical 5G HetNet design. Finally, we assess the benefit brought by massive MIMO for mmWave in such a highly heterogeneous setting.},
  archive      = {J_TMC},
  author       = {Kinda Khawam and Samer Lahoud and Melhem El Helou and Steven Martin and Feng Gang},
  doi          = {10.1109/TMC.2020.3022681},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1226-1243},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Coordinated framework for spectrum allocation and user association in 5G HetNets with mmWave},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-aware telco outdoor localization. <em>TMC</em>,
<em>21</em>(4), 1211–1225. (<a
href="https://doi.org/10.1109/TMC.2020.3025127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the fast growth in telecommunication (Telco) techniques from 2G to upcoming 5G. Precise outdoor localization is important for Telco operators to manage, operate and optimize Telco networks. Differing from GPS, Telco localization is a technique employed by Telco operators to localize outdoor mobile devices by using measurement report (MR) data. When given MR samples containing noisy signals (e.g., caused by Telco signal interference and attenuation), Telco localization often suffers from high errors. To this end, the main focus of this paper is how to improve Telco localization accuracy via the algorithms to detect and repair outlier positions with high errors. Specifically, we propose a context-aware Telco localization technique, namely &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf RLoc}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , which consists of three main components: a machine-learning-based localization algorithm, a detection algorithm to find flawed samples, and a repair algorithm to replace outlier localization results by better ones (ideally ground truth positions). Unlike most existing works to detect and repair every flawed MR sample independently, we instead take into account spatio-temporal locality of MR locations and exploit trajectory context to detect and repair flawed positions. Our experiments on the real MR data sets from 2G GSM and 4G LTE Telco networks verify that our work &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf RLoc}$&lt;/tex-math&gt;&lt;/inline-formula&gt; can greatly improve Telco location accuracy. For example, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sf RLoc}$&lt;/tex-math&gt;&lt;/inline-formula&gt; on a large 4G MR data set can achieve 32.2 meters of median errors, around 17.4 percent better than state-of-the-art.},
  archive      = {J_TMC},
  author       = {Yige Zhang and Weixiong Rao and Mingxuan Yuan and Jia Zeng and Pan Hui},
  doi          = {10.1109/TMC.2020.3025127},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1211-1225},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Context-aware telco outdoor localization},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Compressive RF fingerprint acquisition and broadcasting for
dense BLE networks. <em>TMC</em>, <em>21</em>(4), 1196–1210. (<a
href="https://doi.org/10.1109/TMC.2020.3024842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel bluetooth low energy (BLE) protocol enabling a BLE node to perform RF fingerprint acquisition by measuring the received signal strength (RSS) from its neighboring nodes and simultaneously broadcast the acquired fingerprint via its advertising packet. However, the fingerprint acquisition and broadcast process in a dense BLE network is very challenging owing to: 1) the likelihood of packet collision; and 2) the length-constrained packet. To this end, we exploit a compressive sensing (CS) framework allowing each node to acquire no more than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$M$&lt;/tex-math&gt;&lt;/inline-formula&gt; measurements from a very dense network, in which the number of nodes &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N$&lt;/tex-math&gt;&lt;/inline-formula&gt; is far greater than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$M$&lt;/tex-math&gt;&lt;/inline-formula&gt; . By aggregating the &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$M$&lt;/tex-math&gt;&lt;/inline-formula&gt; -dimensional compressed fingerprint vector from &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$s&amp;lt;N$&lt;/tex-math&gt;&lt;/inline-formula&gt; nodes, the receiver is able to reconstruct the fingerprints broadcast by all &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$N$&lt;/tex-math&gt;&lt;/inline-formula&gt; nodes. This is the very first work that implements CS on a low power device for fingerprint acquisition. Our proposed compressive RF fingerprinting (CRF) has been demonstrated with real and dense BLE networks, consisting of 300 nodes randomly distributed around a confined area. We also conducted extensive simulations to verify the performance of three different reconstruction algorithms. The low reconstruction error at the receiving end indicates the feasibility of our proposed CRF in achieving efficient fingerprint acquisition for dense BLE networks.},
  archive      = {J_TMC},
  author       = {Pai Chet Ng and James She and Rong Ran},
  doi          = {10.1109/TMC.2020.3024842},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1196-1210},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Compressive RF fingerprint acquisition and broadcasting for dense BLE networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Capture-aware identification of mobile RFID tags with
unreliable channels. <em>TMC</em>, <em>21</em>(4), 1182–1195. (<a
href="https://doi.org/10.1109/TMC.2020.3024076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio frequency identification (RFID) has been widely applied in large-scale applications such as logistics, merchandise and transportation. However, it is still a technical challenge to effectively estimate the number of tags in complex mobile environments. Most of existing tag identification protocols assume that readers and tags remain stationary throughout the whole identification process and ideal channel assumptions are typically considered between them. Hence, conventional algorithms may fail in mobile scenarios with unreliable channels. In this paper, we propose a novel RFID anti-collision algorithm for tag identification considering path loss. Based on a probabilistic identification model, we derive the collision, empty and success probabilities in a mobile RFID environment, which will be used to define the cardinality estimation method and the optimal frame length. Both simulation and experimental results of the proposed solution show noticeable performance improvement over the commercial solutions.},
  archive      = {J_TMC},
  author       = {Jian Su and Zhengguo Sheng and Alex. X. Liu and Yu Han and Yongrui Chen},
  doi          = {10.1109/TMC.2020.3024076},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1182-1195},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Capture-aware identification of mobile RFID tags with unreliable channels},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A virtual emotion detection architecture with two-way
enabled delay bound toward evolutional emotion-based IoT services.
<em>TMC</em>, <em>21</em>(4), 1172–1181. (<a
href="https://doi.org/10.1109/TMC.2020.3024059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an original property of human beings, human emotion recognition has gained a lot of interests of many researchers. The recent emotion recognition scheme using wireless signal is considered as one of emerging techniques toward intelligent smart cities. It is highly reasonable to form virtual emotion barrier that can detect human emotion when people move from one side to another side through at least one device in the barrier using wireless signal. Also, it is critical that the emotion recognition delay by virtual emotion barrier with possible two-way detection must be minimized to provide emotion-based services to citizen in timely manner. In this article, we introduce a virtual emotion detection model with two-way enabled delay bound, which pursues to provide timely emotion-based IoT services in advanced smart cities. Also, we formally define a problem whose objective is to generate two-way enabled virtual emotion barriers such that the virtual emotion detection maximum delay of those barriers should be minimized. Then, we propose a novel Two-Way-Enabled-Border-Slab scheme and evaluate its performance through extensive simulations with various settings and scenarios. Furthermore, relevant to the proposed system, we discuss possible research issues, challenges and future works.},
  archive      = {J_TMC},
  author       = {Hyunbum Kim and Jalel Ben-othman and Lynda Mokdad and Paolo Bellavista},
  doi          = {10.1109/TMC.2020.3024059},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1172-1181},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A virtual emotion detection architecture with two-way enabled delay bound toward evolutional emotion-based IoT services},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A nonlinearity-based secure face-to-face device
authentication for mobile devices. <em>TMC</em>, <em>21</em>(4),
1155–1171. (<a href="https://doi.org/10.1109/TMC.2020.3025023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of mobile devices, face-to-face device-to-device (D2D) communication has been applied to a variety of daily scenarios such as mobile payment and short distance file transfer. In D2D communications, a critical security problem is to verify the device legitimacy when they share no secrets in advance. Previous research proposed device authentication schemes based on pre-built database or exploiting physical properties. However, a remaining challenge is to secure face-to-face D2D communication even in the middle of a crowd, within which an attacker may hide. In this paper, we present NAuth , a nonlinearity-enhanced, location-sensitive authentication mechanism. Especially, we target at the secure authentication within a limited range such as 20 cm, which is typical for face-to-face scenarios. NAuth designs a verification scheme based on the nonlinear distortion of speaker-microphone systems and a location-based validation model . The verification scheme guarantees device authentication consistency by extracting acoustic nonlinearity patterns (ANP) while the validation model ensures device legitimacy by measuring the time difference of arrival (TDOA) at two microphones. We analyze the feasibility and security of NAuth theoretically and evaluate its performance experimentally. Results demonstrate that NAuth can verify the device legitimacy in the presence of nearby attackers.},
  archive      = {J_TMC},
  author       = {Xiaoyu Ji and Xinyan Zhou and Chen Yan and Jiangyi Deng and Wenyuan Xu},
  doi          = {10.1109/TMC.2020.3025023},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {4},
  number       = {4},
  pages        = {1155-1171},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A nonlinearity-based secure face-to-face device authentication for mobile devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). To predict or to relay: Tracking neighbors via beaconing in
heterogeneous vehicle conditions. <em>TMC</em>, <em>21</em>(3),
1142–1154. (<a href="https://doi.org/10.1109/TMC.2020.3017682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the capabilities for vehicular communications have become widespread, periodic beaconing is becoming fundamental to tracking neighbors. Specifically, a vehicle periodically broadcasts its kinematic data and receivers estimate the sender’s evolving position. To ensure safety, tracking neighbors via beaconing requires position errors and transmission delay to be small. To satisfy stringent requirements, previous proposals have employed multiple RF devices based on the unrealistic assumption that vehicles have the same type of RF devices. In reality, vehicles possess different RF devices ( heterogeneous vehicle conditions ). Satisfying the requirements under heterogeneous conditions is challenging because network connectivity is low and multi-hop transmissions to improve the connectivity aggravate network congestion. To address this challenge, we propose a novel scheme using a model-based trajectory prediction and multi-hop transmissions adaptively. To maintain accuracy of the model, each vehicle creates a model for predicting its own trajectory and distributes the model. For reliable multihop transmissions, our scheme employs periodic scan for translator and disconnected neighbors (PSTN) and probabilistic relay (PR). To our knowledge, this is the first to consider heterogeneous vehicle conditions for tracking neighbors via beaconing. Evaluation confirms that our scheme tracks neighbors more accurately than previous work.},
  archive      = {J_TMC},
  author       = {Jae-Han Lim and Katsuhiro Naito and Ji-Hoon Yun and Eun-Kyu Lee},
  doi          = {10.1109/TMC.2020.3017682},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1142-1154},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {To predict or to relay: Tracking neighbors via beaconing in heterogeneous vehicle conditions},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The coverage overlapping problem of serving arbitrary crowds
in 3D drone cellular networks. <em>TMC</em>, <em>21</em>(3), 1124–1141.
(<a href="https://doi.org/10.1109/TMC.2020.3019106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing coverage for flash crowds is an important application for drone base stations (DBSs). However, any arbitrary crowd is likely to be distributed at a high density. Under the condition for each DBS to serve the same number of ground users, multiple DBSs may be placed at the same horizontal location but different altitudes and will cause severe co-channel interference, to which we refer as the coverage overlapping problem. To solve this problem, we then proposed the data-driven 3D placement (DDP) and the enhanced DDP (eDDP) algorithms. The proposed DDP and eDDP can effectively find the appropriate number, altitude, location, and coverage of DBSs in the serving area in polynomial time to maximize the system sum rate and guarantee the minimum data rate requirement of the user equipment. The simulation results show that, compared with the balanced &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -means approach, the proposed eDDP can increase the system sum rate by 200 percent and reduce the computation time by 50 percent. In particular, eDDP can effectively reduce the occurrence of the coverage overlapping problem and then outperform DDP by about 100 percent in terms of system sum rate.},
  archive      = {J_TMC},
  author       = {Chuan-Chi Lai and Li-Chun Wang and Zhu Han},
  doi          = {10.1109/TMC.2020.3019106},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1124-1141},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {The coverage overlapping problem of serving arbitrary crowds in 3D drone cellular networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). TARA: An efficient random access mechanism for NB-IoT by
exploiting TA value difference in collided preambles. <em>TMC</em>,
<em>21</em>(3), 1110–1123. (<a
href="https://doi.org/10.1109/TMC.2020.3019224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To meet the tremendous demand of Internet of Things (IoT) applications, the 3rd generation partnership project (3GPP) has specified the narrowband IoT (NB-IoT) standard. However, collisions in the random access (RA) channel of NB-IoT can be severe due to the mismatch between frequent random access attempts by a huge number of devices and the limited radio resources. In this paper, a new random access mechanism called time-alignment-value based random access (TARA) is designed to improve the efficiency of random access of NB-IoT. The key mechanism of TARA is to conduct quick retries upon failure by exploiting the difference of time-alignment (TA) values in collided preambles. To analyze TARA rigorously, a theoretical model of TARA is derived, and its validity is verified via simulations. Further simulations are carried out to evaluate TARA with respect to different system parameters. Comparisons with existing schemes are also conducted. Both analytical and simulation results show that, under various system parameters, TARA achieves 30 percent higher success probability of random access, 75 percent higher throughput, and 40 percent lower access delay than the original slotted Aloha mechanism of NB-IoT. It also highly outperforms other random access schemes.},
  archive      = {J_TMC},
  author       = {Jiawei Zhang and Dianhan Xie and Xudong Wang},
  doi          = {10.1109/TMC.2020.3019224},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1110-1123},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {TARA: An efficient random access mechanism for NB-IoT by exploiting TA value difference in collided preambles},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Systematic analysis of fine-grained mobility prediction with
on-device contextual data. <em>TMC</em>, <em>21</em>(3), 1096–1109. (<a
href="https://doi.org/10.1109/TMC.2020.3015921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User mobility prediction is widely considered by the research community. Many studies have explored various algorithms to predict where a user is likely to visit based on their contexts and trajectories. Most of existing studies focus on specific targets of predictions. While successful cases are often reported, few discussions have been done on what happens if the prediction targets vary: whether coarser locations are easier to be predicted, and whether predicting the immediate next location on the trajectory is easier than predicting the destination. On the other hand, while spatiotemporal tags and content information are commonly used in current prediction tasks, few have utilized the finer grained, on-device user behavioral data, which are supposed to be more informative and indicative of user intentions. In this paper, we conduct a systematic study on the mobility prediction using a large-scale real-world dataset that contains plentiful contextual information. Based on a series of learning models, including a Markov model, two recurrent neural network models, and a multi-modal learning method, we perform extensive experiments to comprehensively investigate the predictability of different types of granularities of targets and the effectiveness of different types of signals. The results provide insightful knowledge on what can be predicted along with how, which sheds light on the real-world mobility prediction from a relatively general perspective.},
  archive      = {J_TMC},
  author       = {Huoran Li and Fuqi Lin and Xuan Lu and Chenren Xu and Gang Huang and Jun Zhang and Qiaozhu Mei and Xuanzhe Liu},
  doi          = {10.1109/TMC.2020.3015921},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1096-1109},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Systematic analysis of fine-grained mobility prediction with on-device contextual data},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spatial-temporal inventory rebalancing for bike sharing
systems with worker recruitment. <em>TMC</em>, <em>21</em>(3),
1081–1095. (<a href="https://doi.org/10.1109/TMC.2020.3018469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-sharing systems usually suffer from out-of-service events due to bike underflow or overflow. We propose to recruit workers to rebalance station loads. We partition the complex rebalancing problem in temporal and spatial domains. The temporal domain is divided into a sequence of slices with a fixed duration. In each slice, we allocate a pair of overflow/underflow stations to a worker such that the cost is minimized, which is NP-hard. A 3-approximation algorithm is proposed. We further investigate the worker shortage case and extend the matching algorithm to consider the number of unsatisfied users. Then, the configuration dynamic in the sequence of slices is captured by determining the rebalancing target for each rebalancing operation. We investigate heuristic approaches to minimize the total number of bike movements. Furthermore, we extend our scheme to dockless BSSs using clustering techniques. We simulate our algorithms on both real-world and synthetic datasets. Experiment results show that our approaches can reduce the average total detour per slice. In worker shortage, considering the number of unsatisfied users could improve the long-term performance of rebalancing. Besides, we find that our scheme could maintain worker satisfaction over multiple time slices, which indicates the sustainability of our rebalancing scheme.},
  archive      = {J_TMC},
  author       = {Yubin Duan and Jie Wu},
  doi          = {10.1109/TMC.2020.3018469},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1081-1095},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Spatial-temporal inventory rebalancing for bike sharing systems with worker recruitment},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RF-dial: Rigid motion tracking and touch gesture detection
for interaction via RFID tags. <em>TMC</em>, <em>21</em>(3), 1061–1080.
(<a href="https://doi.org/10.1109/TMC.2020.3017721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rising of demands for novel human-computer interaction approaches in the 2D plane, a number of intelligent devices come into being. For example, Microsoft Surface Dial supports simple clicks and rotations for the interaction with computer. However, these approaches are dedicated devices, and they might require batteries or have limited functions. In this paper, we propose RF-Dial to realize a light-weight, battery-free and functional 2D human-computer interaction solution via commercial off-the-shelf (COTS) passive RFID tags. What RF-Dial shines is that it can easily turn an ordinary object, e.g., a board eraser, into an intelligent interaction device. By deploying a tag array on the side face of the object together with a dipole tag on the top face, RF-Dial cannot only track the rigid motion of the object but also detect the touch gesture of a user on the surface of the object, including translation, rotation, click, press and hold, and swipe. To do the motion tracking, RF-Dial builds a phase-based model that captures the translation and the rotation of the tagged object simultaneously, by jointly exploiting the information of phase variations and the topology of the tag array. To detect the touch gesture, RF-Dial builds an RSSI-based model that uses the impact of the touching finger on the tag antenna’s impedance to estimate the touch position in real time, which is robust to environmental factors like position or orientation. We implemented a prototype of RF-Dial with commodity RFID devices. Extensive experiments show that RF-Dial achieves an accurate rigid motion tracking, with a small error of 0.6cm for the translation tracking, and a small error of 1.9 degrees for the rotation estimation. Besides, RF-Dial can also detect the touch gesture accurately, as the 90 percent of touch position errors are less than 2.09mm.},
  archive      = {J_TMC},
  author       = {Yanling Bu and Lei Xie and Yinyin Gong and Chuyu Wang and Lei Yang and Jia Liu and Sanglu Lu},
  doi          = {10.1109/TMC.2020.3017721},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1061-1080},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {RF-dial: Rigid motion tracking and touch gesture detection for interaction via RFID tags},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource allocation in full-duplex UAV enabled multismall
cell networks. <em>TMC</em>, <em>21</em>(3), 1049–1060. (<a
href="https://doi.org/10.1109/TMC.2020.3017137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flying platforms, such as unmanned aerial vehicles (UAVs) are a promising solution for future small cell networks. UAVs can be used as aerial base stations (BSs) to enhance coverage, capacity and reliability of wireless networks. Also, with recent advances of self interference cancellation (SIC) techniques in full-duplex (FD) systems, practical implementation of FD BSs is feasible. In this paper, we investigate the problem of resource allocation for multi-small cell networks with FD-UAVs as aerial BSs with imperfect SIC. We consider three different scenarios: a) maximizing the DL sum-rate; b) maximizing the UL sum-rate; and finally c) maximizing the sum of UL and DL sum-rates. The aforementioned problems result in non-convex optimization problems, therefore, successive convex approximation algorithms are developed by leveraging D.C. (Difference of Convex functions) programming to find sub-optimal solutions. Simulation results illustrated validity and effectiveness of the proposed radio resource management algorithms in comparison with ground BSs, in both FD mode and its half-duplex (HD) counterpart. The results also indicate those situations where using aerial BS is advantageous over ground BS and reveal how FD transmission enhances the network performance in comparison with HD one.},
  archive      = {J_TMC},
  author       = {Amirhosein Hajihoseini Gazestani and Seyed Ali Ghorashi and Zhaohui Yang and Mohammad Shikh-Bahaei},
  doi          = {10.1109/TMC.2020.3017137},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1049-1060},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Resource allocation in full-duplex UAV enabled multismall cell networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monitoring browsing behavior of customers in retail stores
via RFID imaging. <em>TMC</em>, <em>21</em>(3), 1034–1048. (<a
href="https://doi.org/10.1109/TMC.2020.3019652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose to use commercial off-the-shelf (COTS) monostatic RFID devices (i.e. which use a single antenna at a time for both transmitting and receiving RFID signals to and from the tags) to monitor browsing activity of customers in front of display items in places such as retail stores. To this end, we propose TagSee , a multi-person imaging system based on monostatic RFID imaging. TagSee is based on the insight that when customers are browsing the items on a shelf, they stand between the tags deployed along the boundaries of the shelf and the reader, which changes the multi-paths that the RFID signals travel along, and both the RSS and phase values of the RFID signals that the reader receives change. Based on these variations observed by the reader, TagSee constructs a coarse grained image of the customers. Afterwards, TagSee identifies the items that are being browsed by the customers by analyzing the constructed images. The key novelty of this paper is on achieving browsing behavior monitoring of multiple customers in front of display items by constructing coarse grained images via robust, analytical model-driven deep learning based, RFID imaging. To achieve this, we first mathematically formulate the problem of imaging humans using monostatic RFID devices and derive an approximate analytical imaging model that correlates the variations caused by human obstructions in the RFID signals. Based on this model, we then develop a deep learning framework to robustly image customers with high accuracy. We implement TagSee scheme using a Impinj Speedway R420 reader and SMARTRAC DogBone RFID tags. TagSee can achieve a TPR of more than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sim }90\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; and a FPR of less than &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${\sim }10\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; in multi-person scenarios using training data from just 3-4 users.},
  archive      = {J_TMC},
  author       = {Kamran Ali and Alex X. Liu and Eugene Chai and Karthikeyan Sundaresan},
  doi          = {10.1109/TMC.2020.3019652},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1034-1048},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Monitoring browsing behavior of customers in retail stores via RFID imaging},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging acoustic signals for fine-grained breathing
monitoring in driving environments. <em>TMC</em>, <em>21</em>(3),
1018–1033. (<a href="https://doi.org/10.1109/TMC.2020.3015828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the increasing amount of time people spent on driving, the physical and mental health of drivers is essential to road safety. Breathing patterns are critical indicators of the wellbeing of drivers on the road. Existing studies on breathing monitoring require active user participation of wearing special sensors or relatively quiet environments during sleep, which are hardly applicable to noisy driving environments. In this work, we propose a fine-grained breathing monitoring system, BreathListener , which leverages audio devices on smartphones to estimate the fine-grained breathing waveform in driving environments. By investigating the data collected from real driving environments, we find that energy spectrum density (ESD) of acoustic signals can be utilized to capture breathing procedures in driving environments. To extract breathing pattern in ESD signals, BreathListener eliminates interference from driving environments in ESD signals utilizing background subtraction and variational mode decomposition (VMD). After that, the extracted breathing pattern is transformed into Hilbert spectrum, and we further design a deep learning architecture based on generative adversarial network (GAN) to generate fine-grained breathing waveform from the Hilbert spectrum of extracted breathing patterns in ESD signals. Experiments with ten drivers in real driving environments show that BreathListener can accurately capture breathing patterns of drivers in driving environments.},
  archive      = {J_TMC},
  author       = {Xiangyu Xu and Jiadi Yu and Yingying Chen},
  doi          = {10.1109/TMC.2020.3015828},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1018-1033},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Leveraging acoustic signals for fine-grained breathing monitoring in driving environments},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Impact of cell association on energy-efficiency and hit rate
of femto-caching. <em>TMC</em>, <em>21</em>(3), 1004–1017. (<a
href="https://doi.org/10.1109/TMC.2020.3017766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content caching at femto base stations (F-BSs) enhances user experience. In practice, the storage size of F-BSs is often minuscule compared to the size of the content library, which calls for effective content placement strategy aligned with user association (UA), networking issues, and possible content retransmissions. The common assumption is to associate user equipments with the closes F-BS that holds the requested content—content-centric user association (CC-UA). We argue that CC-UA could deteriorate hit rate and energy efficiency (EE), and then propose three cache-agnostic UA schemes to tackle this issue: baseline (CA-B), Macro-to-femto (CA-M2F), and femto-to-femto (CA-F2F). Under CA-B if the requested content is not found at the cache, it is retrieved via backhaul. The CA-M2F scheme uses the communication between Macro-BSs and F-BSs to improve the performance. Finally, the CA-F2F scheme uses the direct F2F communication paradigm allowing F-BSs to share contents between themselves on-demand. By the aid of stochastic geometry we model and analyze all these UA schemes and derive associated hit rate and EE performances based on main system parameters. We then utilize the analysis to study the performance of the developed UA-C schemes under several (heuristic) probabilistic content placement strategies. For a chosen choice of the content placement strategy, the numerical results confirm that CA-F2F and CA-M2F outperform CC-UA and CA-B by large margins. For example, we observe that via CA-F2F one can achieve 1200 percent growth of EE compared to CC-UA.},
  archive      = {J_TMC},
  author       = {Mohammad G. Khoshkholgh and Victor C. M. Leung},
  doi          = {10.1109/TMC.2020.3017766},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {1004-1017},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Impact of cell association on energy-efficiency and hit rate of femto-caching},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Flipping free conditions and their application in sparse
network localization. <em>TMC</em>, <em>21</em>(3), 986–1003. (<a
href="https://doi.org/10.1109/TMC.2020.3015480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring network topology via inter-node distance measurements is an important problem. It is challenging when the distance measurements are sparse because the lack of edge constraints may lead to ambiguous realizations that differ greatly from the ground truth. The flipping ambiguities are caused by binary vertex cut sets in 2D and triple vertex cut sets in 3D, which are called separators . This paper investigates conditions on whether the flipping ambiguities caused by these separators can be disambiguated using neighborhood, full graph, and component-level conditions. Accordingly, local flipping-free condition (LFFC), global flipping-free condition (GFFC), and component-based flipping free condition (CFFC) are proposed. Then a disambiguating framework based on a combinatorial application of these conditions is proposed. It detects separators and first disambiguate separators locally by LFFC, which converts the graph to a binary tree, whose leaf nodes are flipping-free components and edges are LFFC unsolvable separators. Then the CFFC condition is further applied to disambiguate LFFC unsolvable separators between components. If &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$g$&lt;/tex-math&gt;&lt;/inline-formula&gt; separators are disambiguated by LFFC and CFFC respectively, the number of ambiguous solutions for network localization will be reduced by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${2^{k+g}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; times. Finally, the flipping-free components realize node coordinates in their local coordinate systems and a residue-based weighted component stitching algorithm (RWCS) is proposed to iteratively synchronize components’ local coordinates to generate global coordinates of the network. Extensive simulations show the LFFC, CFFC and RWCS frameworks are efficient, which resolve a major portion of flipping ambiguities and greatly improve the localization accuracy than the state of art algorithms in various sparse network settings.},
  archive      = {J_TMC},
  author       = {Haodi Ping and Yongcai Wang and Deying Li and Tianyuan Sun},
  doi          = {10.1109/TMC.2020.3015480},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {986-1003},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Flipping free conditions and their application in sparse network localization},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolving bipartite model reveals the bounded weights in
mobile social networks. <em>TMC</em>, <em>21</em>(3), 971–985. (<a
href="https://doi.org/10.1109/TMC.2020.3017630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many realistic mobile social networks can be characterized by evolving bipartite graphs, in which dynamically added elements are divided into two entities and connected by links between these two entities, such as users and items in recommendation networks, authors and scientific topics in scholarly networks, male and female in dating social networks, etc. However, given the fact that connections between two entities are often weighted, how to mathematically model such weighted evolving bipartite relationships, along with quantitative characterizations, remains unexplored. Motivated by this, we develop a novel evolving bipartite model (EBM), which, based on empirically validated power-law distribution on multiple realistic mobile social networks, discloses that the distribution of total weights of incoming and outgoing edges in networks is determined by the weighting scale and bounded by certain ceilings and floors. Based on these theoretical results, for evolving bipartite networks whose degree follows power-law distribution, their overall weights of vertices can be predicted by EBM. To illustrate, in recommendation networks, the evaluation of items, i.e., total rating scores, can be estimated through the given bounds; in scholarly networks, the total numbers of publications under specific topics can be anticipated within a certain range; in dating social networks, the favorability of male/female can be roughly measured. Finally, we perform extensive experiments on 10 realistic datasets and a synthetic network with varying weights, i.e., rating scales, to further evaluate the performance of EBM, and experimental results demonstrate that given weighting scales, both the upper bound and the lower bound of total weights of vertices in mobile social networks can be properly predicted by the EBM.},
  archive      = {J_TMC},
  author       = {Jiaqi Liu and Cheng Deng and Luoyi Fu and Huan Long and Xiaoying Gan and Xinbing Wang and Guihai Chen and Jun Xu},
  doi          = {10.1109/TMC.2020.3017630},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {971-985},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Evolving bipartite model reveals the bounded weights in mobile social networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enabling optimal control under demand elasticity for
electric vehicle charging systems. <em>TMC</em>, <em>21</em>(3),
955–970. (<a href="https://doi.org/10.1109/TMC.2020.3015121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the proliferation of electric vehicles (EVs) that enable environment-friendly commuting and traveling. However, the increasing number of EVs inevitably create massive charging demands that are challenging to satisfy. Oftentimes in practice, EVs have to wait in queues for a long time outside charging stations before chargers become available. To address this challenge, we fully capture the elasticity of EVs’ charging demands in response to the charging prices, and propose a dynamic charging pricing mechanism that jointly controls the lengths of the demand queues at multiple charging stations and maximizes the charging platform’s long-term profit for offering charging services. Clearly, such an approach is more feasible than the financially and temporally expensive way of constructing extra charging facilities. Technically, we augment the Lyapunov stochastic optimization technique to decompose the challenging long-term decision-making problem into a series of single-time-slot optimization programs which require zero knowledge of future system parameters. However, due to the correlation of charging demands among different stations, the aforementioned optimization program in each time slot is non-convex. We handle the non-convexity by jointly constructing independent sets of charging stations and adapting the block coordinate descent method to iteratively obtain approximately optimal charging prices. Through rigorous theoretical analysis and extensive simulations based on the real-world dataset in the Chinese city Shenzhen which consists of 4000 taxis and 171 charging stations, we demonstrate that our control policy ensures an arbitrarily close-to-optimal profit with a flexible trade-off between the profit and queue lengths, has a low computational complexity, and requires zero knowledge of future system dynamics.},
  archive      = {J_TMC},
  author       = {Guiyun Fan and Zhaoxing Yang and Haiming Jin and Xiaoying Gan and Xinbing Wang},
  doi          = {10.1109/TMC.2020.3015121},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {955-970},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Enabling optimal control under demand elasticity for electric vehicle charging systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic scheduling for stochastic edge-cloud computing
environments using A3C learning and residual recurrent neural networks.
<em>TMC</em>, <em>21</em>(3), 940–954. (<a
href="https://doi.org/10.1109/TMC.2020.3017079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquitous adoption of Internet-of-Things (IoT) based applications has resulted in the emergence of the Fog computing paradigm, which allows seamlessly harnessing both mobile-edge and cloud resources. Efficient scheduling of application tasks in such environments is challenging due to constrained resource capabilities, mobility factors in IoT, resource heterogeneity, network hierarchy, and stochastic behaviors. Existing heuristics and Reinforcement Learning based approaches lack generalizability and quick adaptability, thus failing to tackle this problem optimally. They are also unable to utilize the temporal workload patterns and are suitable only for centralized setups. However, asynchronous-advantage-actor-critic (A3C) learning is known to quickly adapt to dynamic scenarios with less data and residual recurrent neural network (R2N2) to quickly update model parameters. Thus, we propose an A3C based real-time scheduler for stochastic Edge-Cloud environments allowing decentralized learning, concurrently across multiple agents. We use the R2N2 architecture to capture a large number of host and task parameters together with temporal patterns to provide efficient scheduling decisions. The proposed model is adaptive and able to tune different hyper-parameters based on the application requirements. We explicate our choice of hyper-parameters through sensitivity analysis. The experiments conducted on real-world data set show a significant improvement in terms of energy consumption, response time, Service-Level-Agreement and running cost by 14.4, 7.74, 31.9, and 4.64 percent, respectively when compared to the state-of-the-art algorithms.},
  archive      = {J_TMC},
  author       = {Shreshth Tuli and Shashikant Ilager and Kotagiri Ramamohanarao and Rajkumar Buyya},
  doi          = {10.1109/TMC.2020.3017079},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {940-954},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic scheduling for stochastic edge-cloud computing environments using A3C learning and residual recurrent neural networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic buffer sizing and pacing as enablers of 5G
low-latency services. <em>TMC</em>, <em>21</em>(3), 926–939. (<a
href="https://doi.org/10.1109/TMC.2020.3017011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3GPP standards organization is performing an impressive effort trying to reach sub-millisecond latencies for 5G. However, such efforts may become fruitless if exogenously generated delays at transport layer are not considered. Nowadays, Radio Access Networks (RANs) are deployed with large buffers to achieve full utilization and avoid squandering wireless resources. Unfortunately, and since the data path’s bottleneck resides on the radio link, RAN’s buffers are bloated by TCP’s congestion control algorithm. Thus, a flow with low-latency requirements that encounters a bloated buffer, suffers from inevitable large sojourn times associated with the buffer depletion time, severely downgrading its Quality of Service (QoS). This paper presents different solutions for efficiently multiplexing distinct traffic patterns that share buffers on the 5G stack. Bufferbloat is extensively studied within the actual 5G QoS scenario, which presents multiple challenges inherited from the dynamic radio link nature and the presence of multiple queues at different entities. We propose and extensively emulate different algorithms in order to avoid the exogenous delay caused by the bufferbloat phenomena. We use real cellular network traces with realistic delay-sensitive and background traffic patterns in different scenarios. The outcome presents valuable insights in the algorithms that will enable low-latency services to be delivered through the 5G network stack satisfying restrictive envisioned constraints.},
  archive      = {J_TMC},
  author       = {Mikel Irazabal and Elena Lopez-Aguilera and Ilker Demirkol and Navid Nikaein},
  doi          = {10.1109/TMC.2020.3017011},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {926-939},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic buffer sizing and pacing as enablers of 5G low-latency services},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decoupled uplink-downlink association in full-duplex
cellular networks: A contract-theory approach. <em>TMC</em>,
<em>21</em>(3), 911–925. (<a
href="https://doi.org/10.1109/TMC.2020.3017646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User association is a crucial aspect which greatly affects the performance of wireless networks. In this work, we investigate the user association problem in full-duplex cellular networks, wherein base stations (BSs) are densely deployed with highly variable transmit powers and topologies (e.g., heterogeneous networks). To enhance the system performance, decoupled UL-DL (DUDe) association is considered, which enables each user equipment (UE) to associate with different BSs in uplink (UL) and downlink (DL), respectively. Considering the challenges raised by asymmetric information (e.g., channel gains and intercell interferences) between UEs and BSs, we propose a contract-theory based distributed user association approach. Specifically, the association process is modeled as a labor market, where the BSs act as employers and offer two-dimensional contracts to employees (i.e., UEs) for maximizing the utility of the BS. Theoretical proof for contract feasibility is presented by providing sufficient and necessary conditions. To reach the optimality, a contract-theoretic decoupled user association algorithm is developed, in which a BS broadcasts the drafted contracts, and each UE self-selects the optimal contract by considering her own demands. Numerical results are presented to demonstrate the performance of the proposed approach in terms of node utilities and social surplus. Impacts of system settings on the network performance are also investigated.},
  archive      = {J_TMC},
  author       = {Chen Dai and Kun Zhu and Changyan Yi and Ekram Hossain},
  doi          = {10.1109/TMC.2020.3017646},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {911-925},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Decoupled uplink-downlink association in full-duplex cellular networks: A contract-theory approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DaRe: Data recovery through application layer coding for
LoRaWAN. <em>TMC</em>, <em>21</em>(3), 895–910. (<a
href="https://doi.org/10.1109/TMC.2020.3016654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-range wide-area network (LoRaWAN) is an energy-efficient and inexpensive networking technology that is rapidly being adopted for many Internet-of-Things applications. In this study, we perform extensive measurements on a new LoRaWAN deployment to characterise the spatio-temporal properties of the LoRaWAN channel. Our experiments reveal that LoRaWAN frames are mostly lost due to the channel effects, which are adverse when the end-devices are mobile. The frame losses are up to 70 percent, which can be bursty for both mobile and stationary scenarios. Frame losses result in data losses since the frames are transmitted only once in the basic configuration. To reduce data losses in LoRaWAN, we design a novel coding scheme for data recovery called DaRe that works on the application layer. DaRe combines techniques from convolutional and fountain codes. By implementing DaRe, we show that 99 percent of the data can be recovered with a code rate of 1/2 when the frame loss is up to 40 percent. Compared to the repetition coding scheme, DaRe provides 21 percent higher data recovery and can save up to 42 percent of the energy consumed on a transmission for 10-byte data units. We also show that DaRe provides better resilience to bursty frame losses.},
  archive      = {J_TMC},
  author       = {Paul J. Marcelis and Nikolaos Kouvelas and Vijay S. Rao and R. Venkatesha Prasad},
  doi          = {10.1109/TMC.2020.3016654},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {895-910},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {DaRe: Data recovery through application layer coding for LoRaWAN},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CrowdOS: A ubiquitous operating system for crowdsourcing and
mobile crowd sensing. <em>TMC</em>, <em>21</em>(3), 878–894. (<a
href="https://doi.org/10.1109/TMC.2020.3015750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of crowdsourcing and mobile crowdsensing techniques, a large number of crowdsourcing applications or platforms ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathbb {CAP}$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) have appeared. In the mean time, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathbb {CAP}$&lt;/tex-math&gt;&lt;/inline-formula&gt; -related models and frameworks based on different research hypotheses are rapidly emerging, and they usually address specific issues from a certain perspective. Due to different settings and conditions, different models are not compatible with each other. However, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathbb {CAP}$&lt;/tex-math&gt;&lt;/inline-formula&gt; urgently needs to combine these techniques to form a unified framework. In addition, these models needs to be learned and updated online with the extension of crowdsourced data and task types; thus, requiring a unified architecture that integrates lifelong learning concepts and breaks down the barriers between different modules. This paper draws on the idea of ubiquitous operating systems and proposes a novel OS (CrowdOS), which is an abstract software layer running between native OS and application layer. In particular, based on an in-depth analysis of the complex crowd environment and diverse characteristics of heterogeneous tasks, we construct the OS kernel and three core frameworks including task resolution and assignment framework ( TRAF ), integrated resource management ( IRM ), and task result quality optimization ( TRO ). In addition, we validate the usability of CrowdOS, module correctness and development efficiency. Our evaluation further reveals TRO brings enormous improvement in efficiency and a reduction in energy consumption.},
  archive      = {J_TMC},
  author       = {Yimeng Liu and Zhiwen Yu and Bin Guo and Qi Han and Jiangbin Su and Jiahao Liao},
  doi          = {10.1109/TMC.2020.3015750},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {878-894},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {CrowdOS: A ubiquitous operating system for crowdsourcing and mobile crowd sensing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Context-aware and energy-aware video streaming on
smartphones. <em>TMC</em>, <em>21</em>(3), 862–877. (<a
href="https://doi.org/10.1109/TMC.2020.3019341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High quality video streaming for mobile devices implies high energy consumption due to the transmitted data and the variation of wireless signals. As an example, transmissions in mobile scenarios (e.g., inside a moving bus) consumes more energy for devices than when accessing from a static environment (e.g., at home). The QoE for the user does not substantially increase when watching high bitrate videos in a vibrating environment (i.e., a moving vehicle), as the context, in this case vehicle’s vibration, affects the perceived QoE. To address this problem, we propose to save energy by considering the context (environment) of video streaming. To model the impact of context, we exploit the embedded accelerometer in smartphones to record the vibration level during video streaming. Based on quality assessment experiments, we collect traces and model the impact of video bitrate and vibration level on QoE, and model the impact of video bitrate and signal strength on power consumption. Based on the QoE model and the power model, we formulate the context-aware and energy-aware video streaming problem as an optimization problem. We present an optimal algorithm which can maximize QoE and minimize energy. Since the optimal algorithm requires perfect knowledge of future tasks, we propose an online bitrate selection algorithm. To further improve the performance of the online algorithm, we propose a crowdsourcing based bitrate selection algorithm. Through real measurements and trace-driven simulations, we demonstrate that the proposed algorithms can significantly outperform existing approaches when considering both energy and QoE.},
  archive      = {J_TMC},
  author       = {Xianda Chen and Tianxiang Tan and Guohong Cao and Thomas F. La Porta},
  doi          = {10.1109/TMC.2020.3019341},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {862-877},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Context-aware and energy-aware video streaming on smartphones},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boundary tracking of continuous objects based on binary tree
structured SVM for industrial wireless sensor networks. <em>TMC</em>,
<em>21</em>(3), 849–861. (<a
href="https://doi.org/10.1109/TMC.2020.3019393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the flammability, explosiveness and toxicity of continuous objects (e.g., chemical gas, oil spill, radioactive waste) in the petrochemical and nuclear industries, boundary tracking of continuous objects is a critical issue for industrial wireless sensor networks (IWSNs). In this article, we propose a continuous object boundary tracking algorithm for IWSNs – which fully exploits the collective intelligence and machine learning capability within the sensor nodes. The proposed algorithm first determines an upper bound of the event region covered by the continuous objects. A binary tree-based partition is performed within the event region, obtaining a coarse-grained boundary area mapping. To study the irregularity of continuous objects in detail, the boundary tracking problem is then transformed into a binary classification problem; a hierarchical soft margin support vector machine training strategy is designed to address the binary classification problem in a distributed fashion. Simulation results demonstrate that the proposed algorithm shows a reduction in the number of nodes required for boundary tracking by at least 50 percent. Without additional fault-tolerant mechanisms, the proposed algorithm is inherently robust to false sensor readings, even for high ratios of faulty nodes ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\approx 9\%$&lt;/tex-math&gt;&lt;/inline-formula&gt; ).},
  archive      = {J_TMC},
  author       = {Li Liu and Guangjie Han and Zhengwei Xu and Jinfang Jiang and Lei Shu and Miguel Martínez-García},
  doi          = {10.1109/TMC.2020.3019393},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {849-861},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Boundary tracking of continuous objects based on binary tree structured SVM for industrial wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Arbitrator2.0: Preventing unauthorized access on passive
tags. <em>TMC</em>, <em>21</em>(3), 835–848. (<a
href="https://doi.org/10.1109/TMC.2020.3017484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the ultra high frequency (UHF) passive radio frequency identification (RFID) technology becomes increasingly deployed, it faces an array of new security attacks. In this paper, we consider a type of attack in which a malicious RFID reader could arbitrarily access the tags, e.g., retrieve or modify IDs or other data in the memory, via standard commands. To deal with this type of attack, we propose a physical-layer tag protection framework, namely Arbitrator2.0, that involves two operating mode, i.e., one is to passively listen on RF channels and identify unauthorized readers, the other is working as normal reader to access tag information but resilient to one-antenna eavesdropper. Our solution does not need to modify RFID tags or the underlying communication standards. In this study, we have implemented a prototype Arbitrator2.0 over the universal software radio peripheral (USRP) platform, and conducted extensive experiments to evaluate its performance. The results show that Arbitrator2.0 can effectively diminish the unauthorized access attacks and prevent eavesdropping.},
  archive      = {J_TMC},
  author       = {Han Ding and Jinsong Han and Cui Zhao and Ge Wang and Wei Xi and Zhiping Jiang and Jizhong Zhao},
  doi          = {10.1109/TMC.2020.3017484},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {835-848},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Arbitrator2.0: Preventing unauthorized access on passive tags},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accurate angular inference for 802.11ad devices using
beam-specific measurements. <em>TMC</em>, <em>21</em>(3), 822–834. (<a
href="https://doi.org/10.1109/TMC.2020.3015936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their sparsity, 60GHz channels are characterized by a few dominant paths. Knowing the angular information of their dominant paths, we can develop various applications, such as the prediction of link performance and the tracking of 802.11ad devices. Although they are equipped with phased arrays, the angular inference for 802.11ad devices is still challenging due to their limited number of RF chains and limited phase control capabilities. Considering the beam sweeping operation and the high communication bandwidth of 802.11ad devices, we propose variation-based angle estimation (VAE), called VAE-CIR , by utilizing beam-specific channel impulse responses (CIRs) measured under different beams and the directional gains of the corresponding beams to infer the angular information of dominant paths. Unlike state-of-the-arts, VAE-CIR exploits the variations between different beam-specific CIRs for angular inference and provides a performance guarantee in the high signal-to-noise-ratio regime. To evaluate VAE-CIR , we generate the beam-specific CIRs by simulating the beam sweeping of 802.11ad devices with the beam patterns measured on off-the-shelf 802.11ad devices. The 60GHz channel is generated via a ray-tracing-based simulator and the CIRs are extracted via channel estimation based on Golay sequences. Through extensive experiments, VAE-CIR is shown to achieve more accurate angle estimation than existing schemes.},
  archive      = {J_TMC},
  author       = {Haichuan Ding and Kang G. Shin},
  doi          = {10.1109/TMC.2020.3015936},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {822-834},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Accurate angular inference for 802.11ad devices using beam-specific measurements},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A trust update mechanism based on reinforcement learning in
underwater acoustic sensor networks. <em>TMC</em>, <em>21</em>(3),
811–821. (<a href="https://doi.org/10.1109/TMC.2020.3020313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic sensor networks (UASNs) have been widely applied in marine scenarios, such as offshore exploration, auxiliary navigation and marine military. Due to the limitations in communication, computation, and storage of underwater sensor nodes, traditional security mechanisms are not applicable to UASNs. Recently, various trust models have been investigated as effective tools towards improving the security of UASNs. However, the existing trust models lack flexible trust update rules, particularly when facing the inevitable dynamic fluctuations in the underwater environment and a wide spectrum of potential attack modes. In this study, a novel trust update mechanism for UASNs based on reinforcement learning (TUMRL) is proposed. The scheme is developed in three phases. First, an environment model is designed to quantify the impact of underwater fluctuations in the sensor data, which assists in updating the trust scores. Then, the definition of key degree is given; in the process of trust update, nodes with higher key degree react more sensitively to malicious attacks, thereby better protecting important nodes in the network. Finally, a novel trust update mechanism based on reinforcement learning is presented, to withstand changing attack modes while achieving efficient trust update. The experimental results prove that our proposed scheme has satisfactory performance in improving trust update efficiency and network security.},
  archive      = {J_TMC},
  author       = {Yu He and Guangjie Han and Jinfang Jiang and Hao Wang and Miguel Martínez-García},
  doi          = {10.1109/TMC.2020.3020313},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {811-821},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A trust update mechanism based on reinforcement learning in underwater acoustic sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sensors based deep learning model for unseen locomotion
mode identification using multiple semantic matrices. <em>TMC</em>,
<em>21</em>(3), 799–810. (<a
href="https://doi.org/10.1109/TMC.2020.3015546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the availability of various sensors in the smartphone, identifying a locomotion mode becomes convenient and effortless in recent years. Information about locomotion mode helps to improve journey planning, travel time estimation, and traffic management. Though there exists a significant amount of work towards locomotion mode recognition, the performance of these work is not pertinent and heavily depends on the labeled training instances. As it is impractical to gather a prior information (labeled instances) about all types of locomotion modes, the recognition model should be able to identify a new or unseen locomotion mode without having any corresponding training instance. This paper proposes a sensors based deep learning model to identify a locomotion mode by using labeled training instances. The approach also incorporates a concept of Zero-Shot learning to identify an unseen locomotion mode. The model obtains an attribute matrix based on the fusion of three semantic matrices. It also constructs a feature matrix by extracting the deep learning and hand-crafted features from the training instances. Later, the model builds a classifier by learning a mapping between attribute and feature matrices. Finally, this work evaluates the performance of the approach on collected and existing datasets using accuracy and F1 score.},
  archive      = {J_TMC},
  author       = {Rahul Mishra and Ashish Gupta and Hari Prabhat Gupta and Tanima Dutta},
  doi          = {10.1109/TMC.2020.3015546},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {799-810},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A sensors based deep learning model for unseen locomotion mode identification using multiple semantic matrices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A novel framework for the coverage problem in battery-free
wireless sensor networks. <em>TMC</em>, <em>21</em>(3), 783–798. (<a
href="https://doi.org/10.1109/TMC.2020.3019470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery-free wireless sensor network (BF-WSN) is a newly proposed network architecture to address the limitation of traditional wireless sensor networks (WSNs). The special features of BF-WSNs make the coverage problem quite different and even more challenging from and than that in traditional WSNs. This paper defines a new coverage problem in BF-WSNs which aims at maximizing coverage quality rather than prolonging network lifetime. The newly defined coverage problem is proved to be at least NP-Hard. Two sufficient conditions, under which the optimal solution of the problem can be derived in polynomial time, are given in this paper. Furthermore, three approximate algorithms are proposed to derive nearly optimal coverage when the sufficient conditions are unsatisfied. The time complexity and approximate ratio of the three algorithms are analyzed. Extensive simulations are carried out to examine the performance of the proposed algorithms. The simulation results show that these algorithms are efficient and effective.},
  archive      = {J_TMC},
  author       = {Tuo Shi and Jianzhong Li and Hong Gao and Zhipeng Cai},
  doi          = {10.1109/TMC.2020.3019470},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {783-798},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A novel framework for the coverage problem in battery-free wireless sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A comprehensive and reproducible comparison of clustering
and optimization rules in wi-fi fingerprinting. <em>TMC</em>,
<em>21</em>(3), 769–782. (<a
href="https://doi.org/10.1109/TMC.2020.3017176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi fingerprinting is a well-known technique used for indoor positioning. It relies on a pattern recognition method that compares the captured operational fingerprint with a set of previously collected reference samples (radio map) using a similarity function. The matching algorithms suffer from a scalability problem in large deployments with a huge density of fingerprints, where the number of reference samples in the radio map is prohibitively large. This paper presents a comprehensive comparative study of existing methods to reduce the complexity and size of the radio map used at the operational stage. Our empirical results show that most of the methods reduce the computational burden at the expense of a degraded accuracy. Among the studied methods, only &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -means, affinity propagation, and the rules based on the strongest access point properly balance the positioning accuracy and computational time. In addition to the comparative results, this paper also introduces a new evaluation framework with multiple datasets, aiming at getting more general results and contributing to a better reproducibility of new proposed solutions in the future.},
  archive      = {J_TMC},
  author       = {Joaquín Torres-Sospedra and Philipp Richter and Adriano Moreira and Germán M. Mendoza-Silva and Elena Simona Lohan and Sergio Trilles and Miguel Matey-Sanz and Joaquín Huerta},
  doi          = {10.1109/TMC.2020.3017176},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {3},
  number       = {3},
  pages        = {769-782},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A comprehensive and reproducible comparison of clustering and optimization rules in wi-fi fingerprinting},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WiHF: Gesture and user recognition with WiFi. <em>TMC</em>,
<em>21</em>(2), 757–768. (<a
href="https://doi.org/10.1109/TMC.2020.3009561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User identified gesture recognition is a fundamental step towards ubiquitous WiFi based sensing. We propose WiHF, which first simultaneously enables cross-domain gesture recognition and user identification using commodity WiFi in a real-time manner. The basic idea of WiHF is to derive a domain-independent motion change pattern of arm gestures from WiFi signals, rendering the unique gesture characteristics and the personalized user performing styles. To extract the motion change pattern in real time, we develop an efficient method based on the seam carving algorithm. Moreover, taking as input the motion change pattern, a deep neural network (DNN) is adopted for both gesture recognition and user identification tasks. In DNN, we apply splitting and splicing schemes to optimize collaborative learning for dual tasks. We implement WiHF and extensively evaluate its performance on a public dataset including 6 users and 6 gestures performed across 5 locations and 5 orientations in 3 environments. Experimental results show that WiHF achieves 97.65 and 96.74 percent for in-domain gesture recognition and user identification accuracy, respectively. The cross-domain gesture recognition accuracy is comparable with the state-of-the-art method, but the processing time is reduced by 30×.},
  archive      = {J_TMC},
  author       = {Chenning Li and Manni Liu and Zhichao Cao},
  doi          = {10.1109/TMC.2020.3009561},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {757-768},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WiHF: Gesture and user recognition with WiFi},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Wi-fi RTT ranging performance characterization and
positioning system design. <em>TMC</em>, <em>21</em>(2), 740–756. (<a
href="https://doi.org/10.1109/TMC.2020.3012563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this research is to implement a precise Wi-Fi indoor positioning system (IPS) or localization system based upon the IEEE 802.11mc fine-timing measurement (FTM) scheme also known as the Wi-Fi round trip time (RTT) ranging technique, where ranging refers to a sub-process of positioning that determines the distance between a transmitter and receiver. Our system and its algorithms were implemented using a COTS (Commercial-Off-The-Shelf) smartphone and Wi-Fi access points. Experiments were conducted in several real-life indoor environments. This paper presents the detailed Wi-Fi RTT ranging performance of these devices in different system configurations and characterizes the systematic biases and noise model to improve the ranging accuracy. A novel three-step-positioning method is proposed to overcome the issues of no or multiple intersect points in trilateration due to ranging errors to improve positioning accuracy. This consists of the following: 1) systematic bias determination and removal; 2) clustering-based trilateration (CbT) supported by weighted concentric circle generation (WCCG), namely CbT &amp; WCCG; 3) positioning result and trajectory optimization using a Kalman filter. As a result, the evaluation experiments gave a position accuracy of ±1.2 m in 2D static positioning and ±1.3 m for dynamic motion tracking. Also, our CbT &amp; WCCG method demonstrate good tolerance against ranging errors. Moreover, the computational cost and positioning accuracy of CbT &amp; WCCG methods are compared with least square (LS) and recursive least square (RLS) methods and the accuracy standard deviation of our algorithm is the closest to the Cramer–Rao bound (CRB).},
  archive      = {J_TMC},
  author       = {Chengqi Ma and Bang Wu and Stefan Poslad and David R. Selviah},
  doi          = {10.1109/TMC.2020.3012563},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {740-756},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Wi-fi RTT ranging performance characterization and positioning system design},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Which app is going to die? A framework for app survival
prediction with multitask learning. <em>TMC</em>, <em>21</em>(2),
728–739. (<a href="https://doi.org/10.1109/TMC.2020.3012767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {App survival prediction is a significant task in mobile service development. It differs from existing prediction tasks in two aspects. First, rather than the traditional survival prediction in bioinformatics where all the patients’ survival probabilities decay in a similar way, apps’ survival pattern varies from each other. Second, affected by multiple factors, an app&#39;s popularity is time-varying and sequence-dependent, which makes existing short-term prediction methods not applicable due to error accumulation. These characteristics bring great difficulties in app survival prediction. In this paper, we propose AppLife, a framework that fuses multi-source influence factors and utilizes Multi-Task Learning (MTL) to combine the state information of mobile app for survival prediction. First, we analyze how the app survival is affected by multi-source factors, including download history, ratings, and reviews. Second, to overcome error accumulation in long-term prediction, we propose a novel MTL based approach. The approach estimates whether an app is surviving at each time interval during the life cycle of apps and leverages relatedness among tasks to improve the prediction performance. Last, we collect a large-scale dataset with more than 35,000 apps, based on which we evaluate our proposed framework and results show that it outperforms the seven state-of-the-art methods.},
  archive      = {J_TMC},
  author       = {Yixuan Zhang and Bin Guo and Jiaqi Liu and Tong Guo and Yi Ouyang and Zhiwen Yu},
  doi          = {10.1109/TMC.2020.3012767},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {728-739},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Which app is going to die? a framework for app survival prediction with multitask learning},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Timestamp-free clock syntonization for IoT using carrier
frequency offset. <em>TMC</em>, <em>21</em>(2), 712–727. (<a
href="https://doi.org/10.1109/TMC.2020.3009132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System-level timing fluctuations caused by unstable low-cost clocks and end-to-end communication delays are the main sources of uncertainties in existing synchronization mechanisms that rely on timestamp exchanges. This paper introduces a timestamp-free clock syntonization approach, carrier frequency offset (CFO)-assisted syntonization (CFOSynt), to estimate the clock skew between a pair of nodes by utilizing carrier frequency offset. To enable CFOSynt, we leverage the fact that RF oscillators in the radio can be used as the reference to calibrate the system clock oscillators, and the pairwise RF clock information is carried in the transmission carrier frequency. By incorporating CFO and capturing the clock frequency relationship in system clock skew estimation, CFOSynt can eliminate the need for timestamping and the impact of delay uncertainties. To validate the design, CFOSynt is implemented on two common off-the-shelf (COTS) IoT platforms with access to the CFO estimation from the radio chip. Extensive experiments are conducted to evaluate CFOSynt, and CFOSynt can estimate the clock skew of 32 kHz low-cost electronic oscillators with a mean error of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$-2.46$&lt;/tex-math&gt;&lt;/inline-formula&gt; Hz. In comparison with timestamp-based approaches, CFOSynt achieves up to 70-90 percent improvement in skew estimation error and shows significant reliability when low-cost oscillators are used.},
  archive      = {J_TMC},
  author       = {Baofeng Zhou and Fujuan Guo and Mehmet C. Vuran},
  doi          = {10.1109/TMC.2020.3009132},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {712-727},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Timestamp-free clock syntonization for IoT using carrier frequency offset},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Throughput maximization in cloud-radio access networks using
cross-layer network coding. <em>TMC</em>, <em>21</em>(2), 696–711. (<a
href="https://doi.org/10.1109/TMC.2020.3012935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud radio access networks (C-RANs) are promising paradigms for the fifth-generation (5G) networks due to their interference management capabilities. In a C-RAN, a central processor (CP) is responsible for coordinating multiple Remote Radio Heads (RRHs) and scheduling users to their radio resource blocks (RRBs). In this paper, we develop a novel cross-layer network coding (CLNC) approach that proposes to optimize RRH’s transmit powers and user’s rates in making the coding decisions. As such, cross-layer throughput of the network is maximized. The joint user scheduling, file encoding, and power adaptation problem is solved by designing a subgraph for each RRB, in which each vertex represents potential user-RRH associations, encoded files, transmission rates, and power levels (PLs) for one RRB. It is then shown that the C-RAN throughput maximization problem is equivalent to a maximum-weight clique problem over the union of all such subgraphs, called herein the CRAN-CLNC graph. Numerical results revealed that the proposed joint and iterative schemes offer improved throughput performances as compared to the existing algorithms in the literature. Compared to our proposed joint scheme, our proposed iterative scheme has a certain degradation, roughly in the range of 9%–14%. This small degradation in the throughput performance of the iterative scheme comes at the achieved low computational complexity as compared to the high complexity of the joint scheme.},
  archive      = {J_TMC},
  author       = {Mohammed S. Al-Abiad and Ahmed Douik and Sameh Sorour and Md. Jahangir Hossain},
  doi          = {10.1109/TMC.2020.3012935},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {696-711},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Throughput maximization in cloud-radio access networks using cross-layer network coding},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Smartphone based indoor path estimation and localization
without human intervention. <em>TMC</em>, <em>21</em>(2), 681–695. (<a
href="https://doi.org/10.1109/TMC.2020.3013113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing commercial interest in indoor localization-based services has stimulated the development of many indoor positioning systems. Despite extensive research on localization, system requirements, such as site survey, user intervention, or specific hardware/software, place limitations on the widespread deployment of localization. To overcome these limitations, we propose a path estimation and localization system for indoor environments, termed PYLON , that runs on a smartphone and a server without any human intervention. PYLON uses an actual floor plan and measurements from widely deployed WiFi access points (APs) and Bluetooth Low Energy (BLE) beacons to estimate the user’s path. It creates virtual rooms according to received signal strength indicator (RSSI) values and matches them to actual rooms in the real-world floor plan. After room mapping, PYLON uses door passing times to precisely refine a user’s estimated path. Unlike conventional path estimation and localization systems, PYLON works independently of device types. We implement PYLON on five Android smartphones and conduct evaluation with three users in an office building. Our experimental results show that PYLON achieves 97 percent floor plan mapping accuracy with a localization error of 1.42 m.},
  archive      = {J_TMC},
  author       = {Junyoung Choi and Gyujin Lee and Sunghyun Choi and Saewoong Bahk},
  doi          = {10.1109/TMC.2020.3013113},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {681-695},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Smartphone based indoor path estimation and localization without human intervention},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Say no to price discrimination: Decentralized and automated
incentives for price auditing in ride-hailing services. <em>TMC</em>,
<em>21</em>(2), 663–680. (<a
href="https://doi.org/10.1109/TMC.2020.3008315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the most successful application of the sharing economy, ride-hailing service is popular worldwide and serves millions of users per day worldwide. Ride-hailing service providers (SPs) usually collect users’ personal data to improve their services via big data technologies. However, SPs may also use the collected user data to apply personalized prices to different users, which raises price fairness concerns. In this paper, we propose a smart price auditing system named Spas. Spas allows a user to purchase Fair Price Insurance in the form of Price Auditing Contract , then the price of ride-hailing service (RHS) order will be audited automatically once completed. According to the auditing result, the contract punishes misbehaving SPs and also compensates affected users automatically. By replacing an untrustworthy centralized auditor with carefully designed smart contracts, we construct a decentralized price auditing system which is trustworthy and transparent. We demonstrate a theoretical model for practical payment flows based on real RHS user data and we implement Spas in Hyperledger Fabric to show that decentralizing and automating price auditing for RHS with financial incentives is technically feasible.},
  archive      = {J_TMC},
  author       = {Youshui Lu and Yong Qi and Saiyu Qi and Yue Li and Hongyu Song and Yuhao Liu},
  doi          = {10.1109/TMC.2020.3008315},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {663-680},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Say no to price discrimination: Decentralized and automated incentives for price auditing in ride-hailing services},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Millimeter-wave base stations in the sky: An experimental
study of UAV-to-ground communications. <em>TMC</em>, <em>21</em>(2),
644–662. (<a href="https://doi.org/10.1109/TMC.2020.3013575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper adopts a systems approach to study how millimeter wave (mmWave) radio transmitters on UAVs provide high throughput links under typical hovering conditions. With Terragraph channel sounder units, we experimentally study the impact of signal fluctuations and sub-optimal beam selection on a testbed involving DJI M600 UAVs. From the hovering-related insights and the measured antenna radiation patterns, we develop and validate the first stochastic UAV-to-Ground mmWave channel model with UAVs as transmitters. Our UAV-centric analytical model complements the classical fading with additional losses expected in the mmWave channel during hovering, considering 3-D antenna configuration and beamforming training parameters. We specifically consider lateral displacement, roll, pitch, and yaw, whose magnitude vary depending on the availability of specialized hardware such as real-time kinematic GPS. We then leverage this model to mitigate the hovering impact on the UAV-to-Ground link by selecting a near-to-optimum pair of beams. Importantly, our work does not change the wireless standard nor require any cross-layer information, making it compatible with current mmWave devices. Results demonstrate that our channel model drops estimation error to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\approx$&lt;/tex-math&gt;&lt;/inline-formula&gt; 0.2 percent, i.e., 18x lower, and improves the average PHY bit-rate by &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\approx$&lt;/tex-math&gt;&lt;/inline-formula&gt; 10 percent when compared to existing state-of-the-art channel models and beamforming methods for UAVs.},
  archive      = {J_TMC},
  author       = {Sara Garcia Sanchez and Subhramoy Mohanti and Dheryta Jaisinghani and Kaushik Roy Chowdhury},
  doi          = {10.1109/TMC.2020.3013575},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {644-662},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Millimeter-wave base stations in the sky: An experimental study of UAV-to-ground communications},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Location-flexible mobile data service in overseas market.
<em>TMC</em>, <em>21</em>(2), 629–643. (<a
href="https://doi.org/10.1109/TMC.2020.3014621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile network operators (MNOs) provide wireless data services based on a tariff data plan with a month data cap. Traditionally, the data cap is only valid for domestic data consumption and users have to pay extra roaming fees for overseas data consumption. A recently emerged location-flexible service allows users to access the domestic data cap in overseas locations (by configuring location-flexibility with a daily fee). This paper studies the economic impact of the location-flexibility on the overseas market. The overseas market tracks the travelers on a monthly basis, hence it is month-variant. Each user in overseas market decides his joint flexibility configuration and data consumption (J-FCDC) every day, which corresponds to an on-line payoff maximization problem. We first analyze the off-line version of J-FCDC problem (which is NP-hard), and then we design an on-line strategy with a provable performance guarantee. Moreover, we propose a pricing policy for the location-flexible service without the need of knowing the market statistic information. We find that the location-flexibility induces users to consume more data in low-valuation days, and the MNO benefits from stimulating users’ data consumption through an appropriate pricing. Numerical results show that the location-flexibility improves the MNO’s revenue and the users’ payoffs.},
  archive      = {J_TMC},
  author       = {Zhiyuan Wang and Lin Gao and Jianwei Huang},
  doi          = {10.1109/TMC.2020.3014621},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {629-643},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Location-flexible mobile data service in overseas market},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). In-band secret-free pairing for COTS wireless devices.
<em>TMC</em>, <em>21</em>(2), 612–628. (<a
href="https://doi.org/10.1109/TMC.2020.3015010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many IoT devices lack the necessary interfaces (keyboards, screens) for entering passwords or changing default ones. For these devices, bootstrapping trust can be challenging. We address the problem of device pairing in the absence of any shared secrets. Pairing is a two-phase process that requires mutual authentication between the two parties and the agreement to a common key that can be used to further bootstrap essential cryptographic mechanisms. We propose a secret-free and in-band trust establishment protocol that achieves the secure pairing of commercial off-the-shelf (COTS) wireless devices with a hub. As compared to the state-of-the-art, our protocol does not require any hardware/firmware modification to the devices, or any out-of-band channels, but can be applied to any COTS device. Furthermore, our protocol is resistant to active signal manipulations attacks that include recently demonstrated signal nullification at an intended receiver. These security properties are achieved in-band with the assistance of a helper device such as a smartphone and by exploiting hard-to-forge signal propagation laws. We perform extensive theoretical analysis to verify the security of the proposed protocol. In addition, we validate our theoretical results with experiments using COTS devices and USRP radios.},
  archive      = {J_TMC},
  author       = {Nirnimesh Ghose and Loukas Lazos and Ming Li},
  doi          = {10.1109/TMC.2020.3015010},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {612-628},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {In-band secret-free pairing for COTS wireless devices},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imitation learning enabled task scheduling for online
vehicular edge computing. <em>TMC</em>, <em>21</em>(2), 598–611. (<a
href="https://doi.org/10.1109/TMC.2020.3012509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular edge computing (VEC) is a promising paradigm based on the Internet of vehicles to provide computing resources for end users and relieve heavy traffic burden for cellular networks. In this paper, we consider a VEC network with dynamic topologies, unstable connections and unpredictable movements. Vehicles inside can offload computation tasks to available neighboring VEC clusters formed by onboard resources, with the purpose of both minimizing system energy consumption and satisfying task latency constraints. For online task scheduling, existing researches either design heuristic algorithms or leverage machine learning, e.g., deep reinforcement learning (DRL). However, these algorithms are not efficient enough because of their low searching efficiency and slow convergence speeds for large-scale networks. Instead, we propose an imitation learning enabled online task scheduling algorithm with near-optimal performance from the initial stage. Specially, an expert can obtain the optimal scheduling policy by solving the formulated optimization problem with a few samples offline. For online learning, we train agent policies by following the expert’s demonstration with an acceptable performance gap in theory. Performance results show that our solution has a significant advantage with more than 50 percent improvement compared with the benchmark.},
  archive      = {J_TMC},
  author       = {Xiaojie Wang and Zhaolong Ning and Song Guo and Lei Wang},
  doi          = {10.1109/TMC.2020.3012509},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {598-611},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Imitation learning enabled task scheduling for online vehicular edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Health-radio: Towards contactless myocardial infarction
detection using radio signals. <em>TMC</em>, <em>21</em>(2), 585–597.
(<a href="https://doi.org/10.1109/TMC.2020.3012681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Myocardial infarction (MI) is the myocardial necrosis caused by persistent ischemia and hypoxia of coronary arteries. People do not realize that they are suffering from MI until they have a heart attack. Early MI detection plays a vital role in symptom relief and improvement in the performance of daily activities. However, conventional MI detection methods require expensive and inconvenient medical tests, e.g., intrusive blood tests or wear electrocardiogram (ECG) sensors, which can only be performed in medical institutions. In this paper, we introduce a contactless and non-intrusive MI detection method based on wireless sensing that monitors abnormalities in heartbeats. Specifically, we present Health-Radio, a radar-based system towards early MI detection. Health-Radio extracts heart rate variability (HRV) from the RF signals reflected from users. In particular, with our carefully designed signal processing algorithms, Health-Radio is able to not only obtain heartbeat signals when the user is stationary, but also tolerate interference when the user is performing certain activities, e.g., eating, reading and browsing the Internet. We have recruited 30 MI patients from the Central Hospital of Wuhan, China, and 30 healthy university students to conduct comprehensive evaluations of the performance of Health-Radio. The experiment results show that Health-Radio can achieve a median MI detection accuracy of 81.2 percent when the users are stationary, which is comparable to ECG-based MI detection. Even when the users are not stationary, Health-Radio can still achieve a median detection accuracy of 66.5 percent. Health-Radio is promising in providing a new paradigm for smart-home healthcare in the future.},
  archive      = {J_TMC},
  author       = {Jian Zhang and Yuan Wu and Yanjiao Chen and Tong Chen},
  doi          = {10.1109/TMC.2020.3012681},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {585-597},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Health-radio: Towards contactless myocardial infarction detection using radio signals},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast globally optimal transmit antenna selection and
resource allocation scheme in mmWave D2D networks. <em>TMC</em>,
<em>21</em>(2), 573–584. (<a
href="https://doi.org/10.1109/TMC.2020.3009183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transmit antenna selection (TAS) at base station has been widely studied and employed in many communication networks (such as those using massive multiple-input multiple-output (MIMO) systems). Thanks to the small size of microstrip antenna elements applicable to millimeter-wave (mmWave) frequencies, the implementation of TAS in small user equipments (UEs) employing switchable directional antennas is recently becoming popular. In this paper, we consider device-to-device (D2D) communications underlaying a cellular network wherein each D2D UE is equipped with switchable transmit antennas. By employing Generalized Bender’s Decomposition (GBD) algorithm, we obtained the solution to the problem of globally optimal transmit antenna selection and channel allocation to D2D UEs together with transmit powers of cellular and D2D UEs. Although we reformulated the non-convex primal subproblem of the proposed GBD-based method into convex form, we further managed to obtain the corresponding closed-form solution through analytical manipulations; this extensively increased (at least 60 times) the execution speed of the proposed method as shown in the simulation results.},
  archive      = {J_TMC},
  author       = {Omid Yazdani and Mehdi Monemi and Ghasem Mirjalily},
  doi          = {10.1109/TMC.2020.3009183},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {573-584},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fast globally optimal transmit antenna selection and resource allocation scheme in mmWave D2D networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EspialCog: General, efficient and robust mobile user
implicit authentication in noisy environment. <em>TMC</em>,
<em>21</em>(2), 555–572. (<a
href="https://doi.org/10.1109/TMC.2020.3012491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile authentication is a fundamental factor in the protection of user’s private resources. In recent years, motion sensor-based biometric authentication has been widely used for privacy-preserving. However, it faces with the problems including low data collection efficiency, insufficient authentication scenario coverage rate, weak de-noising ability, and poor robustness of models, rendering existing methods difficult to meet the security, privacy, and usability requirements jointly in the real-world scenario. To overcome these difficulties, we propose a system called EspialCog , which is able to 1) collect the sensor data embedded in mobile devices self-adaptively, unobtrusively and efficiently through the evolutionary stable participation game mechanism (ESPGM) with a high scenario coverage rate; 2) minimize noise from collected data by analyzing three types of abnormalities; and 3) authenticate the ownership of mobile devices in real-time by adopting optimized LSTM model with an enhanced stochastic gradient descent (SGD) algorithm. The simulation experiment on 6000 users shows that the efficiency and coverage rates increase dramatically by deploying our ESPGM. Moreover, we conduct experiments on a large-scale real-world noisy dataset with 1513 users and two other small pure real-world datasets. The experimental results show the high accuracy and favorable robustness of EspialCog in the noisy environment.},
  archive      = {J_TMC},
  author       = {Tiantian Zhu and Zhengqiu Weng and Qijie Song and Yuan Chen and Qiang Liu and Yan Chen and Mingqi Lv and Tieming Chen},
  doi          = {10.1109/TMC.2020.3012491},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {555-572},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {EspialCog: General, efficient and robust mobile user implicit authentication in noisy environment},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Environment-robust device-free human activity recognition
with channel-state-information enhancement and one-shot learning.
<em>TMC</em>, <em>21</em>(2), 540–554. (<a
href="https://doi.org/10.1109/TMC.2020.3012433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning plays an increasingly important role in device-free WiFi Sensing for human activity recognition (HAR). Despite its strong potential, significant challenges exist and are associated with the fact that one may require a large amount of samples for training, and the trained network cannot be easily adapted to a new environment. To address these challenges, we develop a novel scheme using matching network with enhanced channel state information (MatNet-eCSI) to facilitate one-shot learning HAR. We propose a CSI correlation feature extraction (CCFE) method to improve and condense the activity-related information in input signals. It can also significantly reduce the computational complexity by decreasing the dimensions of input signals. We also propose novel training strategy which effectively utilizes the data set from the previously seen environments (PSE). In the least, the strategy can effectively realize human activity recognition using only one sample for each activity from the testing environment and the data set from one PSE. Numerous experiments are conducted and the results demonstrate that our proposed scheme significantly outperforms state-of-the-art HAR methods, achieving higher recognition accuracy and less training time.},
  archive      = {J_TMC},
  author       = {Zhenguo Shi and J. Andrew Zhang and Richard Yida Xu and Qingqing Cheng},
  doi          = {10.1109/TMC.2020.3012433},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {540-554},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Environment-robust device-free human activity recognition with channel-state-information enhancement and one-shot learning},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient forwarding and data acquisition in NDN-based
MANET. <em>TMC</em>, <em>21</em>(2), 530–539. (<a
href="https://doi.org/10.1109/TMC.2020.3012483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The named data networking (NDN) might help improve data acquisition efficiency for a mobile ad hoc network (MANET) due to its advantages, but the inherent characteristics of MANET and the architecture differences between MANET and NDN make it challenging to deploy NDN in MANET. In NDN, data routers are static and servers usually work as providers, so Forwarding Information Bases (FIBs) are relatively stable. In MANET, mobile nodes assume roles of both data routers and providers, so FIBs are unstable. Frequent FIB update may cause broadcast storm and stale FIBs, which results in data acquisition failures. Moreover, in NDN reverse paths are made up of static data routers, so they are relatively steady. In MANET reverse paths involve a large number of mobile nodes, so they frequently disrupt. This leads to frequent data acquisition failures and considerable data retrieval costs and delays. Taking these challenges into account, we propose an efficient data acquisition solution for NDN-based MANET and aim to improve data acquisition success rates and reduce data acquisition costs. In the proposal, mobile nodes perform data retrieval without FIBs and multiple consumers retrieve data via one data acquisition process. Furthermore, mobility support is achieved to guarantee reverse-path continuity and successful reception of data. Finally, the proposed solution is evaluated, and the experimental results show that the solution effectively improves data retrieval success rates and reduce data retrieval costs and delays.},
  archive      = {J_TMC},
  author       = {Xiaonan Wang and Yimi Lu},
  doi          = {10.1109/TMC.2020.3012483},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {530-539},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Efficient forwarding and data acquisition in NDN-based MANET},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distributed energy efficient channel allocation in underlay
multicast D2D communications. <em>TMC</em>, <em>21</em>(2), 514–529. (<a
href="https://doi.org/10.1109/TMC.2020.3012451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the optimization of the energy efficiency of underlay multicast device-to-device (D2MD) communications on cellular networks. In particular, we maximize the energy efficiency of both the global network and the individual users considering various fairness factors such as maximum power and minimum rate constraints. For this, we employ a canonical mixed-integer non-linear formulation of the joint power control and resource allocation problem. To cope with its NP-hard nature, we propose a two-stage semi-distributed solution. In the first stage, we find a stable, yet sub-optimal, channel allocation for D2MD groups using a cooperative coalitional game framework that allows co-channel transmission over a set of shared resource blocks and/or transmission over several different channels per D2MD group. In the second stage, a central entity determines the optimal transmission power for each user in the system via fractional programming. We performed extensive simulations to analyze the resulting energy efficiency and attainable transmission rates. The results show that the performance of our semi-distributed approach is very close to that obtained with a pure optimal centralized one.},
  archive      = {J_TMC},
  author       = {Mariem Hmila and Manuel Fernández-Veiga and Miguel Rodríguez-Pérez and Sergio Herrería-Alonso},
  doi          = {10.1109/TMC.2020.3012451},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {514-529},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Distributed energy efficient channel allocation in underlay multicast D2D communications},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deployment of unmanned aerial vehicles for anisotropic
monitoring tasks. <em>TMC</em>, <em>21</em>(2), 495–513. (<a
href="https://doi.org/10.1109/TMC.2020.3012791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the fundamental problem of deployment of Unmanned Aerial V eh I cles for ani S otropic mon I toring T asks (VISIT), that is, given a set of objects with determined coordinates and directions in 2D area, deploy a fixed number of UAVs by adjusting their coordinates and orientations such that the overall monitoring utility for all objects is maximized. We develop a theoretical framework to address VISIT problem. First, we establish monitoring model whose quality of monitoring (QoM is anisotropic with monitoring angle and varying with various monitoring distance. To the best of our knowledge, we are the first considering the anisotropy of monitoring angle. Then, we propose a framework consisting of area discretization and Monitoring Dominating Set (MDS) extraction to reduce the infinite solution space of VISIT to a limited one with performance bound. Finally, we model the reformulated problem as maximizing a monotone submodular function subject to a matroid constraint, and present a greedy algorithm with &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$1-1/e-\epsilon$&lt;/tex-math&gt;&lt;/inline-formula&gt; approximation ratio. We conduct both simulations and field experiments to evaluate our framework, and the results show that our algorithm outperforms comparison algorithms by at least 41.3 percent.},
  archive      = {J_TMC},
  author       = {Weijun Wang and Haipeng Dai and Chao Dong and Fu Xiao and Jiaqi Zheng and Xiao Cheng and Guihai Chen and Xiaoming Fu},
  doi          = {10.1109/TMC.2020.3012791},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {495-513},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Deployment of unmanned aerial vehicles for anisotropic monitoring tasks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cooperative sweep coverage problem with mobile sensors.
<em>TMC</em>, <em>21</em>(2), 480–494. (<a
href="https://doi.org/10.1109/TMC.2020.3008348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sweep coverage plays an important role in many applications such as data gathering, sensing coverage and devices control. In this paper, we deal with the cooperative sweep coverage problem with multiple mobile sensors to periodically cover all positions of interest (PoIs) in the surveillance region. Different from traditional sweep coverage scenarios, the cooperative sweep coverage (CSC) problem allows the deployment of multiple sensors on the same trajectory to further reduce the sweep period or detection delay. We also consider the multi-sink sweep coverage (MSSC) problem where each mobile sensor must periodically transmit its collected data to a base station due to the limited storage capacity and power supply. Correspondingly, we propose two constant-factor approximations, namely &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{CoCycle}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{SinkCycle}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; , to minimize the maximum sweep period for these two problems. The approximation ratios of &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{CoCycle}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{SinkCycle}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; are proved to be 4 and 6 respectively. As far as we know, &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{SinkCycle}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; is the first approximation for the sweep coverage problem with multiple sinks. We also provide two optimal algorithms for the CSC problem in one dimensional case and a useful insight regarding the MSSC problem with only one available sink. Finally, we conduct various numerical experiments to validate the effectiveness and efficiency of our designs.},
  archive      = {J_TMC},
  author       = {Xiaofeng Gao and Jiahao Fan and Fan Wu and Guihai Chen},
  doi          = {10.1109/TMC.2020.3008348},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {480-494},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Cooperative sweep coverage problem with mobile sensors},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-based gait recognition and walking direction
estimation in wi-fi networks. <em>TMC</em>, <em>21</em>(2), 465–479. (<a
href="https://doi.org/10.1109/TMC.2020.3012784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing Wi-Fi-based gait recognition systems consider gait cycle detection as a critical process. However, the noise mixed in dynamic measurements obtained from commercial Wi-Fi devices makes it hard to detect gait cycles. Herein, we adopt the attention-based Recurrent Neural Network (RNN) encoder-decoder and propose a cycle-independent human gait recognition and walking direction estimation system, termed AGait, in Wi-Fi networks. For capturing more human walking dynamics, two receivers together with one transmitter are deployed in different spatial layouts. The Channel State Information (CSI) from different receivers are first assembled and refined to form an integrated walking profile. Then, the RNN encoder reads and encodes the walking profile into primary feature vectors. Given a specific gait or direction sensing task, a corresponding and particular attention vector is computed by the decoder and is finally used to predict the target. The attention scheme motivates AGait to learn to adaptively align with different critical clips of CSI data for different tasks. We implement AGait on commercial Wi-Fi devices in three different indoor environments, and the experimental results demonstrate that AGait can achieve average &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$F_1$&lt;/tex-math&gt;&lt;/inline-formula&gt; scores of 97.32 to 89.77 percent for gait recognition from a group of 4 to 10 subjects and 97.41 percent for direction estimation from 8 walking directions.},
  archive      = {J_TMC},
  author       = {Yang Xu and Wei Yang and Min Chen and Sheng Chen and Liusheng Huang},
  doi          = {10.1109/TMC.2020.3012784},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {465-479},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Attention-based gait recognition and walking direction estimation in wi-fi networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Astute video transmission for geographically dispersed
devices in visual IoT systems. <em>TMC</em>, <em>21</em>(2), 448–464.
(<a href="https://doi.org/10.1109/TMC.2020.3009745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual IoT (VIoT) is a promising IoT paradigm that visualizes sensing data from massive numbers of dispersed devices. A key objective in VIoT is to efficiently manage the devices to perform complex task-related visual data processing. Prior multimedia IoT systems have mainly focused on the delivery of captured video to remote servers, without considering the video tasks’ characteristics and the devices’ heterogeneous capabilities. In this work, we propose an astute video transmission framework for such a VIoT system composed of heterogeneous visual devices. First, we formulate the problem of joint video task allocation and heterogeneous device management by constructing a device hypergraph (DH) structure, which enables devices with different capabilities to perform complex video tasks cooperatively. Second, we model the video transmission within a VIoT system by applying fractal theory considering the NP-hardness of the optimization. In particular, we construct a comprehensive fractal submodular optimization framework through a DH and explore the inner submodular property to effectively leverage both video-task complexity and device heterogeneity. Third, we consider the geographically dispersed characteristic of massive numbers of VIoT devices and propose a multi-hop dispersed transmission mechanism for achieving globally cooperative optimality. The proposed architecture has been evaluated under diverse parameter settings. Numerical results are provided to validate the proposed algorithm in terms of delay, computational efficiency, and bandwidth utilization. Simulation results confirm the effectiveness and superiority of the proposed method.},
  archive      = {J_TMC},
  author       = {Wen Ji and Lingyu Duan and Xi Huang and Yueting Chai},
  doi          = {10.1109/TMC.2020.3009745},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {448-464},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Astute video transmission for geographically dispersed devices in visual IoT systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ARSpy: Breaking location-based multi-player augmented
reality application for user location tracking. <em>TMC</em>,
<em>21</em>(2), 433–447. (<a
href="https://doi.org/10.1109/TMC.2020.3007740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Augmented reality (AR) applications that overlay the perception of the real world with digitally generated information are on the cusp of commercial viability. AR has appeared in several commercial platforms like Microsoft HoloLens and smartphones. They extend the user experience beyond two dimensions and supplement the normal 3D world of a user. A typical location-based multi-player AR application works through a three-step process, wherein the system collects sensory data from the real world, identifies objects based on their context, and finally, renders information on top of senses of a user. However, because these AR applications frequently exchange data with users, they have exposed new individual and public safety issues. In this paper, we develop ARSpy, a user location tracking system solely based on network traffic information of the user, and we test it on location-based multi-player AR applications. We demonstrate the effectiveness and efficiency of the proposed scheme via real-world experiments on 12 volunteers and show that we could obtain the geolocation of any target with high accuracy. We also propose three mitigation methods to mitigate these side channel attacks. Our results reveal a potential security threat in current location-based multi-player AR applications and serve as a critical security reminder to a vast number of AR users.},
  archive      = {J_TMC},
  author       = {Jiacheng Shang and Si Chen and Jie Wu and Shu Yin},
  doi          = {10.1109/TMC.2020.3007740},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {433-447},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {ARSpy: Breaking location-based multi-player augmented reality application for user location tracking},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An edge computing-based photo crowdsourcing framework for
real-time 3D reconstruction. <em>TMC</em>, <em>21</em>(2), 421–432. (<a
href="https://doi.org/10.1109/TMC.2020.3007654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based three-dimensional (3D) reconstruction utilizes a set of photos to build 3D model and can be widely used in many emerging applications such as augmented reality (AR) and disaster recovery. Most of existing 3D reconstruction methods require a mobile user to walk around the target area and reconstruct objectives with a hand-held camera, which is inefficient and time-consuming. To meet the requirements of delay intensive and resource hungry applications in 5G, we propose an edge computing-based photo crowdsourcing (EC-PCS) framework in this paper. The main objective is to collect a set of representative photos from ubiquitous mobile and Internet of Things (IoT) devices at the network edge for real-time 3D model reconstruction, with network resource and monetary cost considerations. Specifically, we first propose a photo pricing mechanism by jointly considering their freshness, resolution and data size. Then, we design a novel photo selection scheme to dynamically select a set of photos with the required target coverage and the minimum monetary cost. We prove the NP-hardness of such problem, and develop an efficient greedy-based approximation algorithm to obtain a near-optimal solution. Moreover, an optimal network resource allocation scheme is presented, in order to minimize the maximum uploading delay of the selected photos to the edge server. Finally, a 3D reconstruction algorithm and a 3D model caching scheme are performed by the edge server in real time. Extensive experimental results based on real-world datasets demonstrate the superior performance of our EC-PCS system over the existing mechanisms.},
  archive      = {J_TMC},
  author       = {Shuai Yu and Xu Chen and Shuai Wang and Lingjun Pu and Di Wu},
  doi          = {10.1109/TMC.2020.3007654},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {421-432},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An edge computing-based photo crowdsourcing framework for real-time 3D reconstruction},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An approach for multi-level visibility scoping of IoT
services in enterprise environments. <em>TMC</em>, <em>21</em>(2),
408–420. (<a href="https://doi.org/10.1109/TMC.2020.3012875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In IoT, what services from which nearby devices are available, must be discovered by a user&#39;s device (e.g., smartphone) before she can issue commands to access them. Service visibility scoping in large scale, heterogeneous enterprise environments has multiple unique features, e.g., proximity based interactions, differentiated visibility according to device natures and user attributes, frequent user churns thus revocation. They render existing solutions completely insufficient. We propose Argus, a distributed algorithm offering three-level, fine-grained visibility scoping in parallel: i) Level 1 public visibility where services are identically visible to everyone; ii) Level 2 differentiated visibility where service visibility depends on users’ non-sensitive attributes; iii) Level 3 covert visibility where service visibility depends on users’ sensitive attributes that are never explicitly disclosed. Extensive analysis and experiments show that: i) Argus is secure; ii) its Level 2 is 10x as scalable and computationally efficient as work using Attribute-based Encryption, Level 3 is 10x as efficient as work using Paring-based Cryptography; iii) it is fast and agile for satisfactory user experience, costing 0.25 s to discover 20 Level 1 devices, and 0.63 s for Level 2 or Level 3 devices.},
  archive      = {J_TMC},
  author       = {Qian Zhou and Omkant Pandey and Fan Ye},
  doi          = {10.1109/TMC.2020.3012875},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {408-420},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An approach for multi-level visibility scoping of IoT services in enterprise environments},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A fingertip profiled RF identifier. <em>TMC</em>,
<em>21</em>(2), 392–407. (<a
href="https://doi.org/10.1109/TMC.2020.3014092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents RF-Mehndi, a passive commercial RFID tag array formed identifier. The key RF-Mehndi novelty is that when the user’s fingertip touching on the tag array surface during the communication, the backscattered signals by the tag array become user-dependent and unique. Hence, if we enhance the communication modality of many personal cards nowadays by RF-Mehndi, in case that a card gets lost or stolen, it cannot be used illegally by the adversaries. To harvest such a benefit, we leverage two key observations in designing RF-Mehndi. The first one is when tags are nearby, their interrogated currents can change each other’s circuit characteristics, based on which unique phase features can be obtained from backscattered signals. The second observation is that when the user’s fingertip touches the tag array surface during communication, the phase feature can be further profiled by this user. Based on these observations, the card and its holder can be potentially authenticated at the same time. To transfer the RF-Mehndi idea to a practical system, we further address technical challenges. We implement a prototype system. Extensive evaluations show the effectiveness of RF-Mehndi, achieving excellent authentication performance.},
  archive      = {J_TMC},
  author       = {Cui Zhao and Zhenjiang Li and Han Ding and Wei Xi and Ting Liu and Ruowei Gui and Jinsong Han},
  doi          = {10.1109/TMC.2020.3014092},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {2},
  number       = {2},
  pages        = {392-407},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A fingertip profiled RF identifier},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). WiFace: Facial expression recognition using wi-fi signals.
<em>TMC</em>, <em>21</em>(1), 378–391. (<a
href="https://doi.org/10.1109/TMC.2020.3001989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expressions are an essential form of human nonverbal communication. Recognition of this nonverbal sign may enable developers to understand the feedbacks on smart device functionality and advertising. Existing approaches for facial expression recognition are mainly based on cameras or on-body sensors, which are either sensitive to lighting conditions or cumbersome for users to wear devices on their faces. In this paper, we propose a new facial expression recognition system based on Wi-Fi signals, named WiFace. Our fundamental intuition is that facial muscle movements in different expressions will induce distinctive waveform patterns in the time-series of channel state information (CSI) in Wi-Fi signals. We develop a series of algorithms to process the CSI signals and extract the most representative waveform patterns for facial expression classification. We build a fully-functional prototype of WiFace using commercial off-the-shelf devices, which can recognize six typical facial expressions. We conduct extensive experiments to evaluate the performance of WiFace, and the experimental results show that the average recognition accuracy is 94.80 percent.},
  archive      = {J_TMC},
  author       = {Yanjiao Chen and Runmin Ou and Zhiyang Li and Kaishun Wu},
  doi          = {10.1109/TMC.2020.3001989},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {378-391},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {WiFace: Facial expression recognition using wi-fi signals},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). User existence-aware BLE beacon firmware for maximized
battery lifetime. <em>TMC</em>, <em>21</em>(1), 366–377. (<a
href="https://doi.org/10.1109/TMC.2020.3006221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bluetooth low energy (BLE) beacon networks are one common infrastructure for IoT and smart city applications because of their scalability and affordability, as well as the proliferation of Bluetooth-enabled devices. However, BLE beacon networks suffer from short battery lifetime, which induces additional maintenance costs. In this paper, we propose a novel user existence-aware BLE beacon firmware, User-B, that extends BLE beacon lifetime by changing its operating configuration. Leveraging scan response and request features of Bluetooth Core Specifications, a mechanism for the detection of nearby user smartphones is proposed. Furthermore, we present an energy consumption model of the proposed firmware, along with an optimization problem for finding the optimal configuration that minimizes the overall energy consumption and overhead induced by switching delay. Last but not least, we introduce a prototype of the User-B firmware and demonstrate experiments. Through the experiments, we prove that the User-B firmware can extend a beacon&#39;s lifetime up to 250 percent under low user-existence frequency and high energy demand application conditions.},
  archive      = {J_TMC},
  author       = {Kang Eun Jeon and James She},
  doi          = {10.1109/TMC.2020.3006221},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {366-377},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {User existence-aware BLE beacon firmware for maximized battery lifetime},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards personalized privacy-preserving incentive for truth
discovery in mobile crowdsensing systems. <em>TMC</em>, <em>21</em>(1),
352–365. (<a href="https://doi.org/10.1109/TMC.2020.3003673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incentive mechanisms are essential for stimulating adequate worker participation to achieve good truth discovery performance in mobile crowdsensing (MCS) systems. However, most of existing incentive mechanisms only consider compensating workers’ sensing cost, while the cost incurred by potential privacy leakage has been largely neglected. Moreover, none of existing privacy-preserving incentive mechanisms has incorporated workers’ different privacy preferences to provide personalized payments for them. In this paper, we propose a contract-based personalized privacy-preserving incentive mechanism for truth discovery in MCS systems, named Paris-TD, which provides personalized payments for workers as a compensation for privacy cost while achieving accurate truth discovery. The basic idea is that the platform offers a set of different contracts to workers with different privacy preferences, and each worker chooses to sign a contract which specifies a privacy-preserving degree (PPD) and the corresponding payment the worker will receive if she submits perturbed data with that PPD. Specifically, we respectively design a set of optimal contracts analytically under both full and incomplete information models, which maximize the truth discovery accuracy under a given budget, while satisfying the individual rationality and incentive compatibility properties. The feasibility and effectiveness of Paris-TD are validated through experiments on both synthetic and real-world datasets.},
  archive      = {J_TMC},
  author       = {Peng Sun and Zhibo Wang and Liantao Wu and Yunhe Feng and Xiaoyi Pang and Hairong Qi and Zhi Wang},
  doi          = {10.1109/TMC.2020.3003673},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {352-365},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Towards personalized privacy-preserving incentive for truth discovery in mobile crowdsensing systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Timestamp scheme to mitigate replay attacks in secure ZigBee
networks. <em>TMC</em>, <em>21</em>(1), 342–351. (<a
href="https://doi.org/10.1109/TMC.2020.3006905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ZigBee is one of the communication protocols used in the Internet of Things (IoT) applications. In typical deployment scenarios involving low-cost and low-power IoT devices, many communication features are disabled, consequently affecting the security offered by ZigBee. The ZigBee specification assumes that deployment of frame counters is sufficient to mitigate replay attacks in secure ZigBee networks. However, we demonstrate that it is insufficient in this paper (i.e., the network is no longer secure after the coordinator restarts). As a countermeasure, we present a timestamp-based scheme to mitigate replay attacks. Our mitigation strategy does not consume power significantly, and fully powered devices will be responsible for providing power-constrained devices with the current timestamp. The proposed scheme is designed for all ZigBee topologies and different states of ZigBee End Devices (ZEDs). Findings from our evaluation show that the proposed scheme can successfully mitigate replay attacks, with no significant network performance degradation even assuming a worst-case scenario (i.e., many devices are sending data simultaneously).},
  archive      = {J_TMC},
  author       = {Fadi Farha and Huansheng Ning and Shunkun Yang and Jiabo Xu and Weishan Zhang and Kim-Kwang Raymond Choo},
  doi          = {10.1109/TMC.2020.3006905},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {342-351},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Timestamp scheme to mitigate replay attacks in secure ZigBee networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistical properties of transmissions subject to rayleigh
fading and ornstein-uhlenbeck mobility. <em>TMC</em>, <em>21</em>(1),
332–341. (<a href="https://doi.org/10.1109/TMC.2020.3001608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we derive closed-form expressions for significant statistical properties of the link signal-to-noise ratio (SNR) and the separation distance in mobile ad hoc networks subject to Ornstein-Uhlenbeck (OU) mobility and Rayleigh fading. In these systems, the SNR is a critical parameter as it directly influences link performance. In the absence of signal fading, the distribution of the link SNR depends exclusively on the squared distance between nodes, which is governed by the mobility model. In our analysis, nodes move randomly according to an Ornstein-Uhlenbeck process, using one tuning parameter to control the temporal dependency in the mobility pattern. We derive a complete statistical description of the squared distance and show that it forms a stationary Markov process. Then, we compute closed-form expressions for the probability density function (pdf), the cumulative distribution function (cdf), the bivariate pdf, and the bivariate cdf of the link SNR. Next, we introduce small-scale fading, modeled by a Rayleigh random variable, and evaluate the pdf of the link SNR for rational path loss exponents. The validity of our theoretical analysis is verified by extensive simulation studies. The results presented in this work can be used to quantify link uncertainty and evaluate stability in mobile ad hoc wireless systems.},
  archive      = {J_TMC},
  author       = {Arta Cika and Mihai-Alin Badiu and Justin P. Coon},
  doi          = {10.1109/TMC.2020.3001608},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {332-341},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Statistical properties of transmissions subject to rayleigh fading and ornstein-uhlenbeck mobility},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Resource-aware feature extraction in mobile edge computing.
<em>TMC</em>, <em>21</em>(1), 321–331. (<a
href="https://doi.org/10.1109/TMC.2020.3007456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile image recognition services, which provide people with image recognition services through the cameras of mobile devices, are revolutionizing our lives. However, most existing cloud/edge-based approaches suffer from two major limitations, (i) Low recognition accuracy and high network bandwidth pressure, and (ii) Not easy to extract features based on currently available resources of mobile devices. In this paper, we propose a resource-aware feature extraction framework for mobile image recognition services. The proposed framework consists of discriminative feature extraction (DFE) and NestDFE algorithms. The DFE algorithm can generate an extractor &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;${{\mathbf E}}$&lt;/tex-math&gt;&lt;/inline-formula&gt; to extract discriminative features from the image data set on the edge server and images on mobile devices. Thus, the proposed framework can achieve higher recognition accuracy and require mobile devices to upload less feature data to the edge server. The NestDFE algorithm generates a single multi-capacity extractor that acts as a series of sub-extractors and enables mobile devices to dynamically select sub-extractors. Experimental results show that the proposed framework improves recognition accuracy by about 23 percent and reduces network traffic by about 76 percent compared with existing approaches.},
  archive      = {J_TMC},
  author       = {Chuntao Ding and Ao Zhou and Xiulong Liu and Xiao Ma and Shangguang Wang},
  doi          = {10.1109/TMC.2020.3007456},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {321-331},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Resource-aware feature extraction in mobile edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning-based collision avoidance and optimal
trajectory planning in UAV communication networks. <em>TMC</em>,
<em>21</em>(1), 306–320. (<a
href="https://doi.org/10.1109/TMC.2020.3003639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a reinforcement learning approach of collision avoidance and investigate optimal trajectory planning for unmanned aerial vehicle (UAV) communication networks. Specifically, each UAV takes charge of delivering objects in the forward path and collecting data from heterogeneous ground IoT devices in the backward path. We adopt reinforcement learning for assisting UAVs to learn collision avoidance without knowing the trajectories of other UAVs in advance. In addition, for each UAV, we use optimization theory to find out a shortest backward path that assures data collection from all associated IoT devices. To obtain an optimal visiting order for IoT devices, we formulate and solve a no-return traveling salesman problem. Given a visiting order, we formulate and solve a sequence of convex optimization problems to obtain line segments of an optimal backward path for heterogeneous ground IoT devices. We use analytical results and simulation results to justify the usage of the proposed approach. Simulation results show that the proposed approach is superior to a number of alternative approaches.},
  archive      = {J_TMC},
  author       = {Yu-Hsin Hsu and Rung-Hung Gau},
  doi          = {10.1109/TMC.2020.3003639},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {306-320},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Reinforcement learning-based collision avoidance and optimal trajectory planning in UAV communication networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Queuing over ever-changing communication scenarios in
tactical networks. <em>TMC</em>, <em>21</em>(1), 291–305. (<a
href="https://doi.org/10.1109/TMC.2020.3005737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a hierarchy of queues complementing each other to handle ever-changing communication scenarios in tactical networks. The first queue stores the QoS-constrained messages from command and control systems. These messages are fragmented into IP packets, which are stored in a queue of packets (second) to be sent to the radio buffer (third), which is a queue with limited space therefore, open to overflow. We start with the hypothesis that these three queues can handle ever-changing user(s) data flows (problem &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) through ever-changing network conditions (problem &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$B$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) using cross-layer information exchange, such as buffer occupancy, data rate, queue size and latency (problem &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A|B$&lt;/tex-math&gt;&lt;/inline-formula&gt; ). We introduce two stochastic models to create sequences of QoS-constrained messages ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A$&lt;/tex-math&gt;&lt;/inline-formula&gt; ) and to create ever-changing network conditions ( &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$B$&lt;/tex-math&gt;&lt;/inline-formula&gt; ). In sequence, we sketch a control loop to shape &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A$&lt;/tex-math&gt;&lt;/inline-formula&gt; to &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$B\;$&lt;/tex-math&gt;&lt;/inline-formula&gt; to test our hypothesis using model &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A|B$&lt;/tex-math&gt;&lt;/inline-formula&gt; , which defines enforcement points at the incoming/outgoing chains of the system together with a control plane. Then, we discuss experimental results in a network with VHF radios using data flows that overflows the radio buffer over ever-changing data rate patterns. We discuss quantitative results showing the performance and limitations of our solutions for problems &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A$&lt;/tex-math&gt;&lt;/inline-formula&gt; , &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$B$&lt;/tex-math&gt;&lt;/inline-formula&gt; , and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$A|B$&lt;/tex-math&gt;&lt;/inline-formula&gt; .},
  archive      = {J_TMC},
  author       = {Roberto Rigolin F. Lopes and Pooja Hanavadi Balaraju and Paulo H. L. Rettore and Peter Sevenich},
  doi          = {10.1109/TMC.2020.3005737},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {291-305},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Queuing over ever-changing communication scenarios in tactical networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QoS driven task offloading with statistical guarantee in
mobile edge computing. <em>TMC</em>, <em>21</em>(1), 278–290. (<a
href="https://doi.org/10.1109/TMC.2020.3004225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile edge computing, popular mobile applications, such as augmented reality, usually offload their tasks to resource-rich edge servers. The user experience can be considerably affected when many mobile users compete for the limited communication and computation resources. The key technical challenge in task offloading is to guarantee the Quality of Service (QoS) for such applications. Existing work on task offloading focus on deterministic QoS (delay) guarantee, which means that tasks have to complete before the given deadline with 100 percent. However, it is impractical to impose a deterministic QoS guarantee for tasks due to the high dynamics of the wireless environment when offloading to edge servers. In this paper, we focus on task offloading with statistical QoS guarantee (tasks are allowed to complete before a given deadline with a probability above the given threshold), which can further save more energy by loosing the QoS requirement. Specially, we first propose a statistical computation model and a statistical transmission model to quantify the correlation between the statistical QoS guarantee and task offloading strategy. Then, we formulate the task offloading problem as a mixed integer non-Linear programming problem with the statistical delay constraint. We transform the statistical delay constraint into the constraints on CPU cycle numbers and the delay exponent respectively. We propose an algorithm to provide the statistical QoS guarantee for tasks using convex optimization theory and Gibbs sampling method. Experiment results show that the proposed algorithm outperforms the three baselines.},
  archive      = {J_TMC},
  author       = {Qing Li and Shangguang Wang and Ao Zhou and Xiao Ma and Fangchun Yang and Alex X. Liu},
  doi          = {10.1109/TMC.2020.3004225},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {278-290},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {QoS driven task offloading with statistical guarantee in mobile edge computing},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prediction of traffic flow via connected vehicles.
<em>TMC</em>, <em>21</em>(1), 264–277. (<a
href="https://doi.org/10.1109/TMC.2020.3006713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a short-term traffic flow prediction (STP) framework so that transportation authorities take early actions to control flow and prevent congestion. We anticipate flow at future time frames on a target road segment based on historical flow data and innovative features such as real time feeds and trajectory data provided by connected vehicles (CV) technology. To cope with the fact that existing approaches do not adapt to variation in traffic, we show how this novel approach allows advanced modelling by integrating into the forecasting of flow, the impact of the various events that CV realistically encountered on segments along their trajectory. We solve the STP problem with a Deep Neural Networks (DNN) in a multitask learning setting augmented by input from CV. Results show that our approach, namely MTL-CV, with an average Root-Mean-Square Error (RMSE) of 0.052, outperforms state-of-the-art ARIMA time series (RMSE of 0.255) and baseline classifiers (RMSE of 0.122). Compared to single task learning with artificial neural network (ANN), ANN had a lower performance, 0.113 for RMSE, than MTL-CV. MTL-CV learned historical similarities between segments, in contrast to using direct historical trends in the measure, because trends may not exist in the measure but do in the similarities.},
  archive      = {J_TMC},
  author       = {Ranwa Al Mallah and Alejandro Quintero and Bilal Farooq},
  doi          = {10.1109/TMC.2020.3006713},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {264-277},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Prediction of traffic flow via connected vehicles},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Passenger demand prediction with cellular footprints.
<em>TMC</em>, <em>21</em>(1), 252–263. (<a
href="https://doi.org/10.1109/TMC.2020.3005240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecast of citywide passenger demand helps online car-hailing service providers to better schedule driver supplies. Previous research either uses only passenger order history and fails to capture the deep dependency of passenger demand, or is restricted on grid region partition that loses physical context. Recent advance in mobile traffic analysis has fostered understanding of city functions. In this article, we propose FlowFlexDP, a demand prediction model that integrates regional crowd flow and applies to flexible region partition. Analysis on a cellular dataset covering 1.5 million users in a major city in China reveals strong correlation between passenger demand and crowd flow. FlowFlexDP extracts both order history and crowd flow from cellular data, and adopts Graph Convolutional Neural Network to adapt prediction for regions of arbitrary shapes and sizes in a city. Evaluation on a large scale data set of 6 online car-hailing applications from cellular data shows that FlowFlexDP accurately predicts passenger demand and outperforms the state-of-the-art demand prediction methods.},
  archive      = {J_TMC},
  author       = {Jing Chu and Xu Wang and Kun Qian and Lina Yao and Fu Xiao and Jianbo Li and Zheng Yang},
  doi          = {10.1109/TMC.2020.3005240},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {252-263},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Passenger demand prediction with cellular footprints},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Objective-variable tour planning for mobile data collection
in partitioned sensor networks. <em>TMC</em>, <em>21</em>(1), 239–251.
(<a href="https://doi.org/10.1109/TMC.2020.3003004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data collection with mobile elements can improve energy efficiency and balance load distribution in wireless sensor networks (WSNs). However, complex network environments bring about inconvenience of path design. This work addresses the network environment issue, by presenting an objective-variable tour planning (OVTP) strategy for mobile data gathering in partitioned WSNs. Unlike existing studies of connected networks, our work focuses on disjoint networks with connectivity requirement and serves delay-hash applications as well as energy-efficient scenarios respectively. We first design a converging-aware location selection mechanism, which macroscopically converges rendezvous points (RPs) to lay a foundation of a short tour. We then develop a delay-aware path formation mechanism, which constructs a short tour connecting all segments by a new convex hull algorithm and a new genetic operation. In addition, we devise an energy-aware path extension mechanism, which selects appropriate extra RPs according to specific metrics in order to reduce the energy depletion of data transmission. Extensive simulations demonstrate the effectiveness and advantages of the new strategy in terms of path length, energy depletion, and data collection ratio.},
  archive      = {J_TMC},
  author       = {Xuxun Liu and Peihang Lin and Tang Liu and Tian Wang and Anfeng Liu and Wenzheng Xu},
  doi          = {10.1109/TMC.2020.3003004},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {239-251},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Objective-variable tour planning for mobile data collection in partitioned sensor networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). &lt;Inline-formula&gt;&lt;tex-math notation=“LaTeX”&gt;<span
class="math inline">NCF</span>&lt;/tex-math&gt;&lt;mml:math
xmlns:mml=“http://www.w3.org/1998/math/MathML”&gt;&lt;mml:mi
mathvariant=“sans-serif”&gt;NCF&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic
xlink:href=“hu-ieq1-3003542.gif”
xmlns:xlink=“http://www.w3.org/1999/xlink”/&gt;&lt;/inline-formula&gt;:
A neural context fusion approach to raw mobility annotation.
<em>TMC</em>, <em>21</em>(1), 226–238. (<a
href="https://doi.org/10.1109/TMC.2020.3003542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding human mobility patterns at the point-of-interest (POI) scale plays an important role in enhancing business intelligence in mobile environments. While large efforts have been made in this direction, most studies simply utilize POI check-ins to mine the concerned mobility patterns, the effectiveness of which is usually hindered due to data sparsity. To obtain better POI-based human mobility for mining, in this paper, we strive to directly annotate the POIs associated with raw user-generated mobility records. We propose a neural context fusion approach which integrates various context factors in people&#39;s POI-visiting behaviors. Our approach evaluates the preference and transition factors via representation learning. Notably, we incorporate an attention mechanism to deal with the randomized transitions in raw mobility. The domain knowledge factors, i.e., distance, time and popularity, remain effective and our approach further includes them from a data-driven perspective. Factors are automatically fused with a feed-forward neural network. Furthermore, we exploit a multi-head architecture to enhance the model expressiveness. Using two real-life data sets, we conduct our experimental study and find that our approach consistently outperforms the state-of-the-art baselines by at least 32 percent in accuracy. Besides, we demonstrate the utility of the obtained POI-based human mobility with a POI recommendation example.},
  archive      = {J_TMC},
  author       = {Renjun Hu and Jingbo Zhou and Xinjiang Lu and Hengshu Zhu and Shuai Ma and Hui Xiong},
  doi          = {10.1109/TMC.2020.3003542},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {226-238},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {&lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$\mathsf{NCF}$&lt;/tex-math&gt;&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi mathvariant=&quot;sans-serif&quot;&gt;NCF&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;hu-ieq1-3003542.gif&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot;/&gt;&lt;/inline-formula&gt;: a neural context fusion approach to raw mobility annotation},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-hop deflection routing algorithm based on
reinforcement learning for energy-harvesting nanonetworks. <em>TMC</em>,
<em>21</em>(1), 211–225. (<a
href="https://doi.org/10.1109/TMC.2020.3006535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanonetworks are composed of interacting nano-nodes, whose size ranges from several hundred cubic nanometers to several cubic micrometers. The extremely constrained computational resources of nano-nodes, the fluctuations in their energy caused by energy harvesting processes, and their very limited transmission range at Terahertz (THz)-band frequencies (0.1-10 THz), make the design of routing protocols in nanonetworks very challenging. A multi-hop deflection routing algorithm based on reinforcement learning (MDR-RL) is proposed in this paper to dynamically and efficiently explore the routing paths during packet transmissions. First, new routing and deflection tables are implemented in nano-nodes, so that nano-nodes can deflect packets to other neighbors when route entries in the routing table are invalid. Second, one forward updating scheme and two feedback updating schemes based on reinforcement learning are designed to update the tables, namely, on-policy and off-policy updating schemes. Finally, extensive simulations in networks simulator-3 are conducted to analyze the performance of MDR-RL using different updating policies, as well as to compare the performance with other machine learning routing algorithms based on Neural Networks and Decision Tree. The results show that the MDR-RL can increase the packet delivery ratio and number of delivered packets, and can decrease the packet average hop count.},
  archive      = {J_TMC},
  author       = {Chao-Chao Wang and Xin-Wei Yao and Wan-Liang Wang and Josep Miquel Jornet},
  doi          = {10.1109/TMC.2020.3006535},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {211-225},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Multi-hop deflection routing algorithm based on reinforcement learning for energy-harvesting nanonetworks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mobility-aware and delay-sensitive service provisioning in
mobile edge-cloud networks. <em>TMC</em>, <em>21</em>(1), 196–210. (<a
href="https://doi.org/10.1109/TMC.2020.3006507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) has emerged as a promising technology to push the cloud frontier to the network edge, provisioning network services in proximity of mobile users. Serving users at edge clouds can reduce service latency, lower operational cost, and improve network resource availability. Along with the MEC technology, network function virtualization (NFV) is another promising technique that implements various network service functions as pieces of software in cloudlets (servers or clusters of servers). Providing virtualized network service for mobile users can improve user service experience, simplify network service deployment, and ease network resource management. However, mobile users move in networks arbitrarily, and different users usually request different services with different resource demands and delay requirements. It thus poses a great challenge to providing reliable and seamless virtualized network services for mobile users in an MEC network while meeting their individual delay requirements, subject to resource capacities on the network. In this paper, we focus on the provisioning of virtualized network function services for mobile users in MEC that takes into account user mobility and service delay requirements. We first formulate two novel optimization problems of user service request admissions with the aims to maximize the accumulative network utility and accumulative network throughput for a given time horizon, respectively. We then devise a constant approximation algorithm for the utility maximization problem. We also develop an online algorithm for the accumulative throughput maximization problem. We finally evaluate the performance of the proposed algorithms through experimental simulations. Experimental results demonstrate that the proposed algorithms are promising.},
  archive      = {J_TMC},
  author       = {Yu Ma and Weifa Liang and Jing Li and Xiaohua Jia and Song Guo},
  doi          = {10.1109/TMC.2020.3006507},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {196-210},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Mobility-aware and delay-sensitive service provisioning in mobile edge-cloud networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memory-aware active learning in mobile sensing systems.
<em>TMC</em>, <em>21</em>(1), 181–195. (<a
href="https://doi.org/10.1109/TMC.2020.3003936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel active learning framework for activity recognition using wearable sensors. Our work is unique in that it takes limitations of the oracle into account when selecting sensor data for annotation by the oracle. Our approach is inspired by human-beings’ limited capacity to respond to prompts on their mobile device. This capacity constraint is manifested not only in the number of queries that a person can respond to in a given time-frame but also in the time lag between the query issuance and the oracle response. We introduce the notion of mindful active learning and propose a computational framework, called EMMA , to maximize the active learning performance taking informativeness of sensor data, query budget, and human memory into account. We formulate this optimization problem, propose an approach to model memory retention, discuss the complexity of the problem, and propose a greedy heuristic to solve the optimization problem. Additionally, we design an approach to perform mindful active learning in batch where multiple sensor observations are selected simultaneously for querying the oracle. We demonstrate the effectiveness of our approach using three publicly available activity datasets and by simulating oracles with various memory strengths. We show that the activity recognition accuracy ranges from 21 to 97 percent depending on memory strength, query budget, and difficulty of the machine learning task. Our results also indicate that EMMA achieves an accuracy level that is, on average, 13.5 percent higher than the case when only informativeness of the sensor data is considered for active learning. Moreover, we show that the performance of our approach is at most 20 percent less than the experimental upper-bound and up to 80 percent higher than the experimental lower-bound. To evaluate the performance of EMMA for batch active learning, we design two instantiations of EMMA to perform active learning in batch mode. We show that these algorithms improve the algorithm training time at the cost of a reduced accuracy in performance. Another finding in our work is that integrating clustering into the process of selecting sensor observations for batch active learning improves the activity learning performance by 11.1 percent on average, mainly due to reducing the redundancy among the selected sensor observations. We observe that mindful active learning is most beneficial when the query budget is small and/or the oracle’s memory is weak. This observation emphasizes advantages of utilizing mindful active learning strategies in mobile health settings that involve interaction with older adults and other populations with cognitive impairments.},
  archive      = {J_TMC},
  author       = {Zhila Esna Ashari and Naomi S. Chaytor and Diane J. Cook and Hassan Ghasemzadeh},
  doi          = {10.1109/TMC.2020.3003936},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {181-195},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Memory-aware active learning in mobile sensing systems},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LibRoad: Rapid, online, and accurate detection of TPLs on
android. <em>TMC</em>, <em>21</em>(1), 167–180. (<a
href="https://doi.org/10.1109/TMC.2020.3003336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Third-party library (TPL) detection plays a very important role in Android malware analysis. The focus of recent works has been shifted to the signature-based approach. However, previous methods have several limitations such as high time complexity and low precision, especially with the presence of similar TPLs and various versions of a TPL. To solve these issues, we propose a rapid, online, and accurate TPL detection approach, named LibRoad, which also follows the line of the signature-based research. To reduce the time cost, our approach integrates an application preprocessing component and a pairwise package matching component. The former divides an application into primary modules and non-primary modules to enable us to focus on analyzing packages in non-primary modules that are the most possibly imported from a TPL. The latter adopts a combination of the package name based matching policy for non-obfuscated packages and the signature-based matching policy for obfuscated packages, where the package name based matching policy has a lower time complexity than the signature based one. Further, to improve performance, our approach integrates a perfectly matched package and TPL determination component, which adopts the package filter mechanism, online TPL detection, and local TPL discovery to identify TPLs with low false positive and false negative. We conduct several groups of experiments on real-world applications and two ground truth bases. Experimental results show that compared to state-of-the-art approaches, LibRoad can achieve a high recall of 99.86 percent and a low false positive rate of 11.48 percent without the loss of efficiency.},
  archive      = {J_TMC},
  author       = {Jian Xu and Qianting Yuan},
  doi          = {10.1109/TMC.2020.3003336},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {167-180},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {LibRoad: Rapid, online, and accurate detection of TPLs on android},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Joint transceiver beamforming design for hybrid full-duplex
and half-duplex ad-hoc networks. <em>TMC</em>, <em>21</em>(1), 154–166.
(<a href="https://doi.org/10.1109/TMC.2020.3001071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a joint transceiver beamforming design method for hybrid full-duplex (FD) and half-duplex (HD) ad-hoc networks to cancel co-channel interference, thereby to improve system spectral efficiency. To characterize network performances, we derive a general expression of transmission capacity upper bound (TC-UB) plus its two compact versions by using a stochastic geometry model. Due to the proposed beamforming design and hybrid-duplex consideration, the exact TC and conventional methods to obtain TC-UBs are not applicable. This motivates us to exploit the UB of the largest eigenvalue of desired signals, Alzer’s inequality for the incomplete gamma function, and dominating interference region to formulate one general TC-UB and two of its compact versions. The numerical results show that the proposed beamforming method outperforms the existing beamforming strategies in terms of exact TC, especially when the number of transmit antennas is larger than the number of receiver antennas per node pair. In addition, the derived general TC-UB can provide relatively close TC performance as the exact ones, and its two compact versions can at least give order-wise TC performance. Moreover, we find the break-even points, where FD outperforms HD with different system configurations.},
  archive      = {J_TMC},
  author       = {Jiancao Hou and Zhaohui Yang and Mohammad Shikh-Bahaei},
  doi          = {10.1109/TMC.2020.3001071},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {154-166},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Joint transceiver beamforming design for hybrid full-duplex and half-duplex ad-hoc networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fully and partially distributed incentive mechanism for a
mobile edge computing network. <em>TMC</em>, <em>21</em>(1), 139–153.
(<a href="https://doi.org/10.1109/TMC.2020.3003079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing has become a major trend in networking research. The rapid growth in the number of data analytics based mobile applications has resulted in an exponential rise in processing demand. One way to cope with this increased processing demand is to use edge networks (EN), which is a wireless ad-hoc network of mobile cloudlets, vehicular cloudlets, dedicated edge devices, and cloud platforms. Typically these devices have different owners and service providers. In this work, we propose a distributed incentive mechanism for an EN, which does not require a trusted third party (TTP). We consider a multi hop EN where a user offloads tasks to neighboring nodes, which may further offload them to their neighbours or the cloud. Our scheme is computationally efficient and helps each node decide on the incentives and workload distribution. We conducted simulations to study the performance of our scheme in different scenarios, including those of untruthful behavior by some nodes. Results show the benefit of using multi hop offloading and that our scheme discourages the untruthful behavior of nodes by assigning them lesser workload. We also propose a partially distributed incentive mechanism and compared its performance to our fully distributed scheme.},
  archive      = {J_TMC},
  author       = {Rajarshi Chattopadhyay and Chen-Khong Tham},
  doi          = {10.1109/TMC.2020.3003079},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {139-153},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Fully and partially distributed incentive mechanism for a mobile edge computing network},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Eclipse: Preserving differential location privacy against
long-term observation attacks. <em>TMC</em>, <em>21</em>(1), 125–138.
(<a href="https://doi.org/10.1109/TMC.2020.3000730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanisms built upon geo-indistinguishability render location privacy, where a user can submit obfuscated locations to Location-Based Service providers but still be able to correctly utilize services. However, these mechanisms are vulnerable under inference attacks. Particularly, with background knowledge of a user’s obfuscated locations, an attacker can infer actual locations by carrying out long-term observation attacks. Unfortunately, how to defend long-term observation attacks in the field of differential location privacy remains open. In this paper, we first demonstrate the vulnerabilities of existing mechanisms under long-term observation attacks. In light of these vulnerabilities, we devise a novel mechanism, referred to as Eclipse, which bridges the gap between location protection and usability of services. Specifically, we harness geo-indistinguishability and &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; -anonymity to obfuscate locations and hide each location based on an anonymity set. As a result, our mechanism effectively perturbs the distribution of locations and suppresses leakage under long-term observation attacks. Moreover, the set of possible outputs is utilized to minimize the impacts to usability and correctness. We formally define and rigorously prove the security of the proposed mechanism by leveraging differential privacy. Moreover, we implement the proposed mechanism and conduct a series of experiments on real-world datasets to demonstrate its efficacy and efficiency.},
  archive      = {J_TMC},
  author       = {Ben Niu and Yahong Chen and Zhibo Wang and Fenghua Li and Boyang Wang and Hui Li},
  doi          = {10.1109/TMC.2020.3000730},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {125-138},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Eclipse: Preserving differential location privacy against long-term observation attacks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic backlight scaling considering ambient luminance for
mobile videos on LCD displays. <em>TMC</em>, <em>21</em>(1), 110–124.
(<a href="https://doi.org/10.1109/TMC.2020.3004534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The power consumption of mobile devices is always a concern for users due to the constraints on the size and weight of mobile devices. Up to now, mobile video traffic has accounted for the majority of total traffic, which implies that viewing mobile videos has been the major activity when using mobile devices. Among all the subsystems involving in mobile video playback, the display is the most power consuming subsystem. To reduce the power consumption, dynamic backlight scaling (DBS) technique is developed by adjusting the backlight magnitude when playing the mobile video. However, the convenience of mobile devices makes lots of people watch mobile videos in various luminance environments, which makes the existing DBS methods ineffective since ambient luminance varies greatly. In this paper, we propose a novel DBS strategy to maximally enhance the battery power performance under various ambient luminance conditions through backlight magnitude adjusting, while without negatively impacting users’ quality of experience (QoE). In particular, we conduct a series of subject quality assessment experiments to uncover the quantitative relationship among QoE, ambient luminance, video content luminance, and backlight luminance. We then investigate whether the continuous playback of backlight-scaled videos using the proposed scaling magnitude under various luminance environments would cause flicker effect or not. Motivated by the findings of these studies, we implement a novel DBS strategy for mobile energy saving which is suitable for various ambient luminance conditions. The experimental results demonstrate that the proposed DBS strategy can save more than 40 percent power at most and can save 10 percent power even at a very high ambient luminance condition. We also show that the proposed DBS strategy can be easily adapted to different user preferences and different devices, and can be conveniently integrated into practical applications.},
  archive      = {J_TMC},
  author       = {Wei Sun and Xiongkuo Min and Guangtao Zhai and Ke Gu and Siwei Ma and Xiaokang Yang},
  doi          = {10.1109/TMC.2020.3004534},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {110-124},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Dynamic backlight scaling considering ambient luminance for mobile videos on LCD displays},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Downlink MU-MIMO LTE-LAA for coexistence with asymmetric
hidden wi-fi APs. <em>TMC</em>, <em>21</em>(1), 93–109. (<a
href="https://doi.org/10.1109/TMC.2020.3003314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To maximize the spectral efficiency while satisfying the increasing mobile traffic demand, LTE can offload downlink traffics to unlicensed UNII bands at 5GHz via the standardized technology LTE-LAA (Licensed Assisted Access). In the scenario where LTE-LAA inevitably coexists with already pervasive WiFi devices which were designed without the consideration of LTE-LAA, recent studies have reported that the asymmetric hidden terminal (AHT) problem, caused by the difference in the listen-before-talk clear-channel-assessment (CCA) thresholds of WiFi and LTE-LAA, severely degrades the throughput and delay performance of both LTE-LAA and WiFi. As a remedy to the AHT problem, we propose a multi-antenna multi-user transmit precoding and power control techniques for LTE-LAA base stations to make neighboring Wi-Fi APs defer their new transmissions, thereby peacefully coexisting with them. The proposed scheme does not require any technical amendment or extra work on the conventional Wi-Fi. Based on our realistic simulator with essential MAC and PHY functions implemented, it is confirmed that the proposed scheme improves the throughput and delay performance of LTE-LAA while maintaining or even improving that of Wi-Fi.},
  archive      = {J_TMC},
  author       = {Harim Lee and Hyun Jong Yang},
  doi          = {10.1109/TMC.2020.3003314},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {93-109},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Downlink MU-MIMO LTE-LAA for coexistence with asymmetric hidden wi-fi APs},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Don’t just BYOD, bring-your-own-app too! Protection via
virtual micro security perimeters. <em>TMC</em>, <em>21</em>(1), 76–92.
(<a href="https://doi.org/10.1109/TMC.2020.3000852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices aggregate various types of data from sensitive corporate documents to personal content. While users desire to access this content on a single device via a unified user experience and through any mobile app, protecting this data is challenging. Even though different data types have different security and privacy needs, mobile operating systems include only a few, if any, functionalities for fine-grained data protection. We present SWIRLS, an Android-based mobile OS that provides a policy-based information-flow data protection abstraction for mobile apps to support BYOD (bring-your-own-device) use cases. SWIRLS attaches security policies to individual pieces of data and enforces these policies as the data flows through the device. Unlike current BYOD solutions like VMs that create duplication overload, SWIRLS provides a single environment to access content from different security contexts using the same applications while monitoring for malicious data leakage. SWIRLS leverages a two-level hybrid information flow tracking (IFT) mechanism to track both intra-application flows and a higher level IFT based on processes for application isolation. Our evaluation presents BYOD data protection use-cases such as limiting document sharing, preventing leakage based on document classification and security policies based on geo-fencing. SWIRLS only imposes a low battery consumption and performance overhead.},
  archive      = {J_TMC},
  author       = {Gabriel Salles-Loustau and Vidyasagar Sadhu and Luis Garcia and Kaustubh Joshi and Dario Pompili and Saman Zonouz},
  doi          = {10.1109/TMC.2020.3000852},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {76-92},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Don&#39;t just BYOD, bring-your-own-app too! protection via virtual micro security perimeters},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coloring-based channel allocation for multiple coexisting
wireless body area networks: A game-theoretic approach. <em>TMC</em>,
<em>21</em>(1), 63–75. (<a
href="https://doi.org/10.1109/TMC.2020.3002898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the coexistence problem among multiple wireless body area networks (WBANs), where co-channel interference may occur among different WBANs if the channels are not allocated properly, leading to performance degradation in both energy efficiency and packet transmission reliability. We formulate the channel allocation problem as a graph coloring problem, and develop a solution to increase the co-channel reuse and the number of WBANs with assigned channels. We propose a distributed two-hop incomplete coloring (DTIC) algorithm that adopts a game-theoretic approach to solve the graph coloring problem. The DTIC algorithm exploits two-hop information to enable high channel reuse among two-hop neighbors and allows for incomplete coloring when the number of colors (or channels) is insufficient to color all vertices without conflict. A distributed message-passing protocol is also proposed to achieve collision-free message exchange, and to ensure that consistent coloring information is shared among WBANs. Simulation results show that our proposed algorithm achieves better co-channel reuse and higher throughput than existing methods.},
  archive      = {J_TMC},
  author       = {Kai-Ju Wu and Y.-W. Peter Hong and Jang-Ping Sheu},
  doi          = {10.1109/TMC.2020.3002898},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {63-75},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {Coloring-based channel allocation for multiple coexisting wireless body area networks: A game-theoretic approach},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An incentive mechanism based on behavioural economics in
location-based crowdsensing considering an uneven distribution of
participants. <em>TMC</em>, <em>21</em>(1), 44–62. (<a
href="https://doi.org/10.1109/TMC.2020.3002586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The location of participants in Location-based CrowdSensing (LCS) represents important information for task completion. Tasks in areas with high concentration of participants (AHCP) can be completed quickly, whereas task completion is difficult in areas with sparse participants (ASP). Incentive mechanisms are necessary to motivate participants to move toward ASP. Previous studies have faced two main problems. First, most incentive mechanisms assume that participant motivation is not affected by external factors. Second, when participants fail to complete tasks, only the cost of the participant is considered the loss. However, reference effect from behavioral economics proves that participants are influenced by both internal and external factors. Furthermore, loss aversion studies have shown that participant evaluations of loss are more severe than simple costs. Therefore we propose an incentive mechanism based on behavioral economics (IBE) consisting of two schemes for participant selection (IBE-PS) and payment decisions (IBE-PD). Based on reference effect, IBE-PS is proposed to control the task selection and pricing of participants. Based on loss aversion, IBE-PD is proposed to encourage participants to complete tasks in ASP many times. Theoretical analysis and simulation results demonstrate that IBE can improve the task completion rate, the participant utility, and the platform welfare.},
  archive      = {J_TMC},
  author       = {Jiaqi Liu and Yuying Yang and Deng Li and Xiaoheng Deng and Shiyue Huang and Hui Liu},
  doi          = {10.1109/TMC.2020.3002586},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {44-62},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An incentive mechanism based on behavioural economics in location-based crowdsensing considering an uneven distribution of participants},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An energy-efficient framework for internet of things
underlaying heterogeneous small cell networks. <em>TMC</em>,
<em>21</em>(1), 31–43. (<a
href="https://doi.org/10.1109/TMC.2020.3005908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term evolution advanced (LTE-A) heterogeneous networks have been observed to offer reliable and service-differentiated communication, thereby enabling numerous mobile applications such as smart meters, remote sensors, and vehicular applications. This fact envisions the trend of Internet of Things (IoT) underlaying heterogeneous small cell networks. On this basis, this paper proposes an energy-efficient framework for such a scenario, where multitier heterogeneous small cell networks provide wireless connection and seamless coverage for mobile users and IoT nodes. In our proposed framework, an elastic cell-zooming algorithm based on the quality of service and traffic loads of end-users is performed by adaptively adjusting the transmission power of small cells in order to reduce energy consumption. In addition, aiming at the high energy efficiency of IoT underlaying small cell networks, a clustering-based IoT structure is used, where a SWIPT-CH selection algorithm is proposed to maximize the average residual energy of IoT nodes and to mitigate resource competition between IoT nodes and mobile users. Extensive simulations demonstrate that our proposed framework can significantly enhance the energy efficiency for IoT underlaying small cell networks with guaranteed outage probability.},
  archive      = {J_TMC},
  author       = {Hongbo Jiang and Zhu Xiao and Zexian Li and Jisheng Xu and Fanzi Zeng and Dong Wang},
  doi          = {10.1109/TMC.2020.3005908},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {31-43},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {An energy-efficient framework for internet of things underlaying heterogeneous small cell networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multi-modal neural embeddings approach for detecting
mobile counterfeit apps: A case study on google play store.
<em>TMC</em>, <em>21</em>(1), 16–30. (<a
href="https://doi.org/10.1109/TMC.2020.3007260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfeit apps impersonate existing popular apps in attempts to misguide users to install them for various reasons such as collecting personal information, spreading malware, or simply to increase their advertisement revenue. Many counterfeits can be identified once installed, however even a tech-savvy user may struggle to detect them before installation as app icons and descriptions can be quite similar to the original app. To this end, this paper proposes to leverage the recent advances in deep learning methods to create image and text embeddings so that counterfeit apps can be efficiently identified when they are submitted to be published in app markets. We show that for the problem of counterfeit detection, a novel approach of combining content embeddings and style embeddings (given by the Gram matrix of CNN feature maps) outperforms the baseline methods for image similarity such as SIFT, SURF, LATCH, and various image hashing methods. We first evaluate the performance of the proposed method on two well-known datasets for evaluating image similarity methods and show that, content, style, and combined embeddings increase precision@k and recall@k by 10-15 percent and 12-25 percent, respectively when retrieving five nearest neighbours. Second specifically for the app counterfeit detection problem, combined content and style embeddings achieve 12 and 14 percent increase in precision@k and recall@k , respectively compared to the baseline methods. We also show that adding text embeddings further increases the performance by 5 and 6 percent in terms of precision@k and recall@k , respectively when &lt;inline-formula&gt;&lt;tex-math notation=&quot;LaTeX&quot;&gt;$k$&lt;/tex-math&gt;&lt;/inline-formula&gt; is five. Third, we present an analysis of approximately 1.2 million apps from Google Play Store and identify a set of potential counterfeits for top-10,000 popular apps. Under a conservative assumption, we were able to find 2,040 potential counterfeits that contain malware in a set of 49,608 apps that showed high similarity to one of the top-10,000 popular apps in Google Play Store. We also find 1,565 potential counterfeits asking for at least five additional dangerous permissions than the original app and 1,407 potential counterfeits having at least five extra third party advertisement libraries.},
  archive      = {J_TMC},
  author       = {Naveen Karunanayake and Jathushan Rajasegaran and Ashanie Gunathillake and Suranga Seneviratne and Guillaume Jourjon},
  doi          = {10.1109/TMC.2020.3007260},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {16-30},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A multi-modal neural embeddings approach for detecting mobile counterfeit apps: A case study on google play store},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A framework for proactive indoor positioning in densely
deployed WiFi networks. <em>TMC</em>, <em>21</em>(1), 1–15. (<a
href="https://doi.org/10.1109/TMC.2020.3001127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A framework that incorporates channel modeling, position estimation, and error analysis methods is developed for network-based indoor positioning with radio signal strength (RSS) measurements of WiFi access points (APs). To construct an accurate channel model with RSS measurements severely influenced by propagation attenuations, multipath reflections, and shadowing effects, a novel sparse Bayesian learning algorithm is developed to model the radio power map (RPM) in indoor space. Based on the proposed RPM model, a 2-stage positioning method is further developed. In the first stage for coarse positioning, the location is determined up to a room-scale indoor space. Then, in the second stage for fine positioning, the RPMs of the given indoor space are used for location estimation in the space with a Bayesian estimator. The mean squared positioning errors are verified with the Bayesian Cramer-Rao lower bound. Extensive experiments show that the average positioning error of the proposed RPM-based approach is 1.98 meters which achieve 22 percent improvements over the state-of-the-art RSS-based indoor positioning methods. More importantly, the proposed modeling and positioning method can effectively exploit the spatial relationship in the RSS samples to improve positioning accuracy.},
  archive      = {J_TMC},
  author       = {Chun-Hsien Ko and Sau-Hsuan Wu},
  doi          = {10.1109/TMC.2020.3001127},
  journal      = {IEEE Transactions on Mobile Computing},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Mobile Comput.},
  title        = {A framework for proactive indoor positioning in densely deployed WiFi networks},
  volume       = {21},
  year         = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
