<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij---138">AIJ - 138</h2>
<ul>
<li><details>
<summary>
(2023). Language, common sense, and the winograd schema challenge.
<em>AIJ</em>, <em>325</em>, 104031. (<a
href="https://doi.org/10.1016/j.artint.2023.104031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the 1950s, philosophers and AI researchers have held that disambiguating natural language sentences depended on common sense. In 2012, the Winograd Schema Challenge was established to evaluate the common-sense reasoning abilities of a machine by testing its ability to disambiguate sentences. The designers argued only a system capable of “thinking in the full-bodied sense” would be able to pass the test. However, by 2023, the original authors concede the test has been soundly defeated by large language models which still seem to lack common sense of full-bodied thinking. In this paper, we argue that disambiguating sentences only seemed like a good test of common-sense based on a certain picture of the relationship between linguistic comprehension and semantic knowledge—one typically associated with the early computational theory of mind and Symbolic AI . If this picture is rejected, as it is by most LLM researchers, then disambiguation ceases to look like a comprehensive test of common-sense and instead appear only to test linguistic competence. The upshot is that any linguistic test, not just disambiguation, is unlikely to tell us much about common sense or genuine intelligence.},
  archive      = {J_AIJ},
  author       = {Jacob Browning and Yann LeCun},
  doi          = {10.1016/j.artint.2023.104031},
  journal      = {Artificial Intelligence},
  pages        = {104031},
  shortjournal = {Artif. Intell.},
  title        = {Language, common sense, and the winograd schema challenge},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general framework for preferences in answer set
programming. <em>AIJ</em>, <em>325</em>, 104023. (<a
href="https://doi.org/10.1016/j.artint.2023.104023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a general, flexible, and extensible framework for quantitative and qualitative preferences among the stable models of logic programs. Since it is straightforward to capture propositional theories and constraint satisfaction problems with logic programs, our approach is also relevant to optimization in satisfiability testing and constraint processing. We show how complex preference relations can be specified through user-defined preference types and their arguments. We describe how preference specifications are handled internally by so-called preference programs, which are used for dominance testing. We also provide algorithms for computing one, or all, preferred stable models of a logic program, and study the complexity of these problems. We implemented our approach in the asprin system by means of multi-shot answer set solving technology. We demonstrate the generality and flexibility of our methodology by showing how easily existing preference languages can be implemented in asprin . Finally, we empirically evaluate our contributions and contrast them with dedicated implementations.},
  archive      = {J_AIJ},
  author       = {Gerhard Brewka and James Delgrande and Javier Romero and Torsten Schaub},
  doi          = {10.1016/j.artint.2023.104023},
  journal      = {Artificial Intelligence},
  pages        = {104023},
  shortjournal = {Artif. Intell.},
  title        = {A general framework for preferences in answer set programming},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ascending-price mechanism for general multi-sided markets.
<em>AIJ</em>, <em>325</em>, 104022. (<a
href="https://doi.org/10.1016/j.artint.2023.104022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an ascending-price mechanism for a multi-sided market with a variety of participants, such as manufacturers, logistics agents, insurance providers, and assemblers. Each deal in the market may consist of a combination of agents from separate categories, and different such combinations are simultaneously allowed. This flexibility lets multiple intersecting markets be resolved as a single global market. Our mechanism is obviously-truthful, strongly budget-balanced, individually rational, and attains almost the optimal gain-from-trade when the market for every allowed combination of categories is sufficiently large. We evaluate the performance of the suggested mechanism with experiments on real stock market data and synthetically produced data.},
  archive      = {J_AIJ},
  author       = {Dvir Gilor and Rica Gonen and Erel Segal-Halevi},
  doi          = {10.1016/j.artint.2023.104022},
  journal      = {Artificial Intelligence},
  pages        = {104022},
  shortjournal = {Artif. Intell.},
  title        = {Ascending-price mechanism for general multi-sided markets},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced q-learning: Combining the influence of optimistic
and pessimistic targets. <em>AIJ</em>, <em>325</em>, 104021. (<a
href="https://doi.org/10.1016/j.artint.2023.104021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimistic nature of the Q −learning target leads to an overestimation bias, which is an inherent problem associated with standard Q −learning. Such a bias fails to account for the possibility of low returns, particularly in risky scenarios. However, the existence of biases, whether overestimation or underestimation, need not necessarily be undesirable. In this paper, we analytically examine the utility of biased learning, and show that specific types of biases may be preferable, depending on the scenario. Based on this finding, we design a novel reinforcement learning algorithm, Balanced Q-learning , in which the target is modified to be a convex combination of a pessimistic and an optimistic term, whose associated weights are determined online, analytically. Such a balanced target inherently promotes risk-averse behavior, which we examine through the lens of the agent&#39;s exploration. We prove the convergence of this algorithm in a tabular setting, and empirically demonstrate its consistently good learning performance in various environments.},
  archive      = {J_AIJ},
  author       = {Thommen George Karimpanal and Hung Le and Majid Abdolshah and Santu Rana and Sunil Gupta and Truyen Tran and Svetha Venkatesh},
  doi          = {10.1016/j.artint.2023.104021},
  journal      = {Artificial Intelligence},
  pages        = {104021},
  shortjournal = {Artif. Intell.},
  title        = {Balanced Q-learning: Combining the influence of optimistic and pessimistic targets},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust vehicle lane keeping control with networked proactive
adaptation. <em>AIJ</em>, <em>325</em>, 104020. (<a
href="https://doi.org/10.1016/j.artint.2023.104020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road condition is an important environmental factor for autonomous vehicle control. A dramatic change in the road condition from the nominal status is a source of uncertainty that can lead to a system failure. Once the vehicle encounters an uncertain environment, such as hitting an ice patch, it is too late to reduce the speed, and the vehicle can lose control. To cope with unforeseen uncertainties in advance, we study a proactive robust adaptive control architecture for autonomous vehicles&#39; lane-keeping control problems. In the proposed framework, the data center generates a prior environmental uncertainty estimate with a quantified uncertainty by combining weather forecasts and measurements from anonymous vehicles through a spatio-temporal filter. The prior estimate and quantified uncertainty contribute to designing a robust heading controller and nominal longitudinal velocity for proactive adaptation to each new abnormal condition. Then the control parameters are updated based on posterior information fusion with on-board measurements.},
  archive      = {J_AIJ},
  author       = {Hunmin Kim and Wenbin Wan and Naira Hovakimyan and Lui Sha and Petros Voulgaris},
  doi          = {10.1016/j.artint.2023.104020},
  journal      = {Artificial Intelligence},
  pages        = {104020},
  shortjournal = {Artif. Intell.},
  title        = {Robust vehicle lane keeping control with networked proactive adaptation},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DEED: DEep evidential doctor. <em>AIJ</em>, <em>325</em>,
104019. (<a href="https://doi.org/10.1016/j.artint.2023.104019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Deep Neural Networks (DNN) make their way into safety-critical decision processes, it becomes imperative to have robust and reliable uncertainty estimates for their predictions for both in-distribution and out-of-distribution (OOD) examples. This is particularly important in real-life high-risk settings such as healthcare, where OOD examples (e.g., patients with previously unseen or rare labels, i.e., diagnoses) are frequent, and an incorrect clinical decision might put human life in danger, in addition to having severe ethical and financial costs. While evidential uncertainty estimates for deep learning have been studied for multi-class problems, research in multi-label settings remains untapped. In this paper, we propose a DEep Evidential Doctor (DEED), which is a novel deterministic approach to estimate multi-label targets along with uncertainty. We achieve this by placing evidential priors over the original likelihood functions and directly estimating the parameters of the evidential distribution using a novel loss function. Additionally, we build a redundancy layer (particularly for high uncertainty and OOD examples) to minimize the risk associated with erroneous decisions based on dubious predictions. We achieve this by learning the mapping between the evidential space and a continuous semantic label embedding space via a recurrent decoder. Thereby inferring, even in the case of OOD examples, reasonably close predictions to avoid catastrophic consequences . We demonstrate the effectiveness of DEED on a digit classification task based on a modified multi-label MNIST dataset, and further evaluate it on a diagnosis prediction task from a real-life electronic health record dataset. We highlight that in terms of prediction scores, our approach is on par with the existing state-of-the-art having a clear advantage of generating reliable, memory and time-efficient uncertainty estimates with minimal changes to any multi-label DNN classifier.},
  archive      = {J_AIJ},
  author       = {Awais Ashfaq and Markus Lingman and Murat Sensoy and Sławomir Nowaczyk},
  doi          = {10.1016/j.artint.2023.104019},
  journal      = {Artificial Intelligence},
  pages        = {104019},
  shortjournal = {Artif. Intell.},
  title        = {DEED: DEep evidential doctor},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-averse receding horizon motion planning for obstacle
avoidance using coherent risk measures. <em>AIJ</em>, <em>325</em>,
104018. (<a href="https://doi.org/10.1016/j.artint.2023.104018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of risk-averse receding horizon motion planning for agents with uncertain dynamics, in the presence of stochastic, dynamic obstacles. We propose a model predictive control (MPC) scheme that formulates the obstacle avoidance constraint using coherent risk measures. To handle disturbances, or process noise, in the state dynamics, the state constraints are tightened in a risk-aware manner to provide a disturbance feedback policy . We also propose a waypoint following algorithm that uses the proposed MPC scheme for discrete distributions and prove its risk-sensitive recursive feasibility while guaranteeing finite-time task completion. We further investigate some commonly used coherent risk metrics, namely, conditional value-at-risk (CVaR), entropic value-at-risk (EVaR), and g-entropic risk measures, and propose a tractable incorporation within MPC. We illustrate our framework via simulation studies.},
  archive      = {J_AIJ},
  author       = {Anushri Dixit and Mohamadreza Ahmadi and Joel W. Burdick},
  doi          = {10.1016/j.artint.2023.104018},
  journal      = {Artificial Intelligence},
  pages        = {104018},
  shortjournal = {Artif. Intell.},
  title        = {Risk-averse receding horizon motion planning for obstacle avoidance using coherent risk measures},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hedonic diversity games: A complexity picture with more than
two colors. <em>AIJ</em>, <em>325</em>, 104017. (<a
href="https://doi.org/10.1016/j.artint.2023.104017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hedonic diversity games are a variant of the classical hedonic games designed to better model a variety of questions concerning diversity and fairness. Previous works mainly targeted the case with two diversity classes (represented as colors in the model) and provided some initial complexity-theoretic and existential results concerning Nash and individually stable outcomes. Here, we design new algorithms accompanied with lower bounds which provide a comprehensive parameterized-complexity picture for computing Nash and individually stable outcomes with respect to the most natural parameterizations of the problem. Crucially, our results hold for general hedonic diversity games where the number of colors is not necessarily restricted to two, and show that—apart from two trivial cases—a necessary condition for tractability in this setting is that the number of colors is bounded by the parameter. Moreover, for the special case of two colors we resolve an open question asked in previous work (Boehmer and Elkind, AAAI 2020).},
  archive      = {J_AIJ},
  author       = {Robert Ganian and Thekla Hamm and Dušan Knop and Šimon Schierreich and Ondřej Suchý},
  doi          = {10.1016/j.artint.2023.104017},
  journal      = {Artificial Intelligence},
  pages        = {104017},
  shortjournal = {Artif. Intell.},
  title        = {Hedonic diversity games: A complexity picture with more than two colors},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mathematical runtime analysis for the non-dominated sorting
genetic algorithm II (NSGA-II). <em>AIJ</em>, <em>325</em>, 104016. (<a
href="https://doi.org/10.1016/j.artint.2023.104016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-dominated sorting genetic algorithm II (NSGA-II) is the most intensively used multi-objective evolutionary algorithm (MOEA) in real-world applications. However, in contrast to several simple MOEAs analyzed also via mathematical means, no such study exists for the NSGA-II so far. In this work, we show that mathematical runtime analyses are feasible also for the NSGA-II. As particular results, we prove that with a population size four times larger than the size of the Pareto front , the NSGA-II with two classic mutation operators and four different ways to select the parents satisfies the same asymptotic runtime guarantees as the SEMO and GSEMO algorithms on the basic OneMinMax and LeadingOnesTrailingZeroes benchmarks. However, if the population size is only equal to the size of the Pareto front, then the NSGA-II cannot efficiently compute the full Pareto front: for an exponential number of iterations, the population will always miss a constant fraction of the Pareto front. Our experiments confirm the above findings.},
  archive      = {J_AIJ},
  author       = {Weijie Zheng and Benjamin Doerr},
  doi          = {10.1016/j.artint.2023.104016},
  journal      = {Artificial Intelligence},
  pages        = {104016},
  shortjournal = {Artif. Intell.},
  title        = {Mathematical runtime analysis for the non-dominated sorting genetic algorithm II (NSGA-II)},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computing optimal hypertree decompositions with SAT.
<em>AIJ</em>, <em>325</em>, 104015. (<a
href="https://doi.org/10.1016/j.artint.2023.104015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypertree width is a prominent hypergraph invariant with many algorithmic applications in constraint satisfaction and databases. We propose two novel characterisations for hypertree width in terms of linear orderings. We utilize these characterisations to obtain SAT, MaxSAT, and SMT encodings for computing the hypertree width exactly. We evaluate the encodings on an extensive set of benchmark instances and compare them to state-of-the-art exact methods for computing optimal hypertree width. Our results show that our approach outperforms these state-of-the-art algorithms.},
  archive      = {J_AIJ},
  author       = {André Schidler and Stefan Szeider},
  doi          = {10.1016/j.artint.2023.104015},
  journal      = {Artificial Intelligence},
  pages        = {104015},
  shortjournal = {Artif. Intell.},
  title        = {Computing optimal hypertree decompositions with SAT},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A k-additive choquet integral-based approach to approximate
the SHAP values for local interpretability in machine learning.
<em>AIJ</em>, <em>325</em>, 104014. (<a
href="https://doi.org/10.1016/j.artint.2023.104014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Besides accuracy, recent studies on machine learning models have been addressing the question on how the obtained results can be interpreted. Indeed, while complex machine learning models are able to provide very good results in terms of accuracy even in challenging applications, it is difficult to interpret them. Aiming at providing some interpretability for such models, one of the most famous methods, called SHAP, borrows the Shapley value concept from game theory in order to locally explain the predicted outcome of an instance of interest. As the SHAP values calculation needs previous computations on all possible coalitions of attributes, its computational cost can be very high. Therefore, a SHAP-based method called Kernel SHAP adopts a strategy that approximates such values with less computational effort. However, we see two weaknesses in Kernel SHAP: its formulation is difficult to understand and it does not consider further game theory assumptions that could reduce the computational cost. Therefore, in this paper, we propose a novel approach that addresses such weaknesses. Firstly, we provide a straightforward formulation of a SHAP-based method for local interpretability by using the Choquet integral, which leads to both Shapley values and Shapley interaction indices. Thereafter, we propose to adopt the concept of k -additive games from game theory, which contributes to reduce the computational effort when estimating the SHAP values. The obtained results attest that our proposal needs less computations on coalitions of attributes to approximate the SHAP values.},
  archive      = {J_AIJ},
  author       = {Guilherme Dean Pelegrina and Leonardo Tomazeli Duarte and Michel Grabisch},
  doi          = {10.1016/j.artint.2023.104014},
  journal      = {Artificial Intelligence},
  pages        = {104014},
  shortjournal = {Artif. Intell.},
  title        = {A k-additive choquet integral-based approach to approximate the SHAP values for local interpretability in machine learning},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monitoring of perception systems: Deterministic,
probabilistic, and learning-based fault detection and identification.
<em>AIJ</em>, <em>325</em>, 103998. (<a
href="https://doi.org/10.1016/j.artint.2023.103998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates runtime monitoring of perception systems. Perception is a critical component of high-integrity applications of robotics and autonomous systems , such as self-driving cars. In these applications, failure of perception systems may put human life at risk, and a broad adoption of these technologies requires the development of methodologies to guarantee and monitor safe operation. Despite the paramount importance of perception, currently there is no formal approach for system-level perception monitoring. In this paper, we formalize the problem of runtime fault detection and identification in perception systems and present a framework to model diagnostic information using a diagnostic graph . We then provide a set of deterministic, probabilistic, and learning-based algorithms that use diagnostic graphs to perform fault detection and identification. Moreover, we investigate fundamental limits and provide deterministic and probabilistic guarantees on the fault detection and identification results. We conclude the paper with an extensive experimental evaluation, which recreates several realistic failure modes in the LGSVL open-source autonomous driving simulator, and applies the proposed system monitors to a state-of-the-art autonomous driving software stack (Baidu&#39;s Apollo Auto). The results show that the proposed system monitors outperform baselines, have the potential of preventing accidents in realistic autonomous driving scenarios, and incur a negligible computational overhead.},
  archive      = {J_AIJ},
  author       = {Pasquale Antonante and Heath G. Nilsen and Luca Carlone},
  doi          = {10.1016/j.artint.2023.103998},
  journal      = {Artificial Intelligence},
  pages        = {103998},
  shortjournal = {Artif. Intell.},
  title        = {Monitoring of perception systems: Deterministic, probabilistic, and learning-based fault detection and identification},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Response to “reward is enough” – this is not a review; it’s
a response. <em>AIJ</em>, <em>325</em>, 103977. (<a
href="https://doi.org/10.1016/j.artint.2023.103977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has recently been a flood-let of important articles whose titles are variations on the theme, “X is Enough” or “Y is All You Need”. As an expression of a strongly held prior, I am inclined to skepticism about all such claims, but… one should try to keep on an open mind. One such claim was expressed in an AIJ Position Paper by Silver , Singh, Precup and Sutton, in particular that Reward Is Enough. The following is a response to (not a review of!) that position.},
  archive      = {J_AIJ},
  author       = {David Israel},
  doi          = {10.1016/j.artint.2023.103977},
  journal      = {Artificial Intelligence},
  pages        = {103977},
  shortjournal = {Artif. Intell.},
  title        = {Response to ‘Reward is enough’ – this is not a review; it&#39;s a response},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The defeat of the winograd schema challenge. <em>AIJ</em>,
<em>325</em>, 103971. (<a
href="https://doi.org/10.1016/j.artint.2023.103971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Winograd Schema Challenge—a set of twin sentences involving pronoun reference disambiguation that seem to require the use of commonsense knowledge—was proposed by Hector Levesque in 2011. By 2019, a number of AI systems, based on large pre-trained transformer-based language models and fine-tuned on these kinds of problems, achieved better than 90\% accuracy. In this paper, we review the history of the Winograd Schema Challenge and discuss the lasting contributions of the flurry of research that has taken place on the WSC in the last decade. We discuss the significance of various datasets developed for WSC, and the research community&#39;s deeper understanding of the role of surrogate tasks in assessing the intelligence of an AI system.},
  archive      = {J_AIJ},
  author       = {Vid Kocijan and Ernest Davis and Thomas Lukasiewicz and Gary Marcus and Leora Morgenstern},
  doi          = {10.1016/j.artint.2023.103971},
  journal      = {Artificial Intelligence},
  pages        = {103971},
  shortjournal = {Artif. Intell.},
  title        = {The defeat of the winograd schema challenge},
  volume       = {325},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifted inference with tree axioms. <em>AIJ</em>,
<em>324</em>, 103997. (<a
href="https://doi.org/10.1016/j.artint.2023.103997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of weighted first-order model counting (WFOMC): given a first-order sentence ϕ and domain size n ∈ N n∈N , determine the weighted sum of models of ϕ over the domain { 1 , … , n } {1, …, n} . Past work has shown that any sentence using at most two logical variables admits an algorithm for WFOMC that runs in time polynomial in the given domain size [1] , [2] . The same property was later also shown to hold for C 2 C2 , the two-variable fragment with counting quantifiers [3] . In this paper, we further expand this result to any C 2 C2 sentence ϕ with the addition of a tree axiom , stating that some distinguished binary relation in ϕ forms a tree in the graph-theoretic sense.},
  archive      = {J_AIJ},
  author       = {Timothy van Bremen and Ondřej Kuželka},
  doi          = {10.1016/j.artint.2023.103997},
  journal      = {Artificial Intelligence},
  pages        = {103997},
  shortjournal = {Artif. Intell.},
  title        = {Lifted inference with tree axioms},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving graph convolution network for federated
item recommendation. <em>AIJ</em>, <em>324</em>, 103996. (<a
href="https://doi.org/10.1016/j.artint.2023.103996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional recommender systems , we often build models based on a centralized storage of user data, which however will lead to user privacy concerns and risks. In this paper, we study an emerging and important recommendation problem called federated item recommendation (FIR), in which a recommendation model is built with decentralized data of user-item interactions in a privacy-aware manner, i.e., the personal behavior data of each user does not leave the owner. Recently, graph neural network (GNN) has been widely recognized as a state-of-the-art solution for item recommendation with implicit feedback since it is able to model the high-order connectivity between users and items. However, it is very challenging to exploit the high-order connectivity information in a decentralized user-item interaction graph without compromising user privacy. To address that, we propose a GNN-based federated recommendation framework, i.e., privacy-preserving graph convolution network (P-GCN), for the studied problem of FIR. Our P-GCN can leverage the high-order connectivity information like a centralized GCN model such as LightGCN, though it is built using a decentralized user-item graph. To achieve that, we design a novel privacy-preserving graph convolution approach based on secure aggregation and employ item-based user representation to compensate for the performance loss it causes due to the protection of user privacy. Moreover, we improve a group-wise concealing strategy for protecting user privacy. Empirical studies on three datasets show that our P-GCN can achieve similar or even better performance comparing with the non-federated (i.e., centralized) counterpart, and outperforms all the existing federated methods for the studied problem.},
  archive      = {J_AIJ},
  author       = {Pengqing Hu and Zhaohao Lin and Weike Pan and Qiang Yang and Xiaogang Peng and Zhong Ming},
  doi          = {10.1016/j.artint.2023.103996},
  journal      = {Artificial Intelligence},
  pages        = {103996},
  shortjournal = {Artif. Intell.},
  title        = {Privacy-preserving graph convolution network for federated item recommendation},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactual explanations for misclassified images: How
human and machine explanations differ. <em>AIJ</em>, <em>324</em>,
103995. (<a href="https://doi.org/10.1016/j.artint.2023.103995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual explanations have emerged as a popular solution for the eXplainable AI (XAI) problem of elucidating the predictions of black-box deep-learning systems because people easily understand them, they apply across different problem domains and seem to be legally compliant. Although over 100 counterfactual methods exist in the XAI literature, each claiming to generate plausible explanations akin to those preferred by people, few of these methods have actually been tested on users (∼7\%). Even fewer studies adopt a user-centered perspective; for instance, asking people for their counterfactual explanations to determine their perspective on a “good explanation”. This gap in the literature is addressed here using a novel methodology that (i) gathers human-generated counterfactual explanations for misclassified images, in two user studies and, then, (ii) compares these human-generated explanations to computationally-generated explanations for the same misclassifications . Results indicate that humans do not “minimally edit” images when generating counterfactual explanations. Instead, they make larger, “meaningful” edits that better approximate prototypes in the counterfactual class. An analysis based on “explanation goals” is proposed to account for this divergence between human and machine explanations. The implications of these proposals for future work are discussed.},
  archive      = {J_AIJ},
  author       = {Eoin Delaney and Arjun Pakrashi and Derek Greene and Mark T. Keane},
  doi          = {10.1016/j.artint.2023.103995},
  journal      = {Artificial Intelligence},
  pages        = {103995},
  shortjournal = {Artif. Intell.},
  title        = {Counterfactual explanations for misclassified images: How human and machine explanations differ},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnosis of intermittent faults in multi-agent systems: An
SFL approach. <em>AIJ</em>, <em>324</em>, 103994. (<a
href="https://doi.org/10.1016/j.artint.2023.103994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Systems (MAS) can be found in a wide variety of applications, including industrial systems, transportation, software systems and more. In such systems, agents may experience faults that affect the performance of the whole system. However, faulty agents might not consistently experience their fault, but rather in certain conditions. For example, a robot with a faulty rotating mechanism will appear healthy if it is tasked to only move in a straight line. Those faults are called Intermittent Faults. Such faults may cause the entire system to fail, but not always. Previous work proposed diagnosis algorithms for MAS, assuming faulty agents persistently behave abnormally. To the best of our knowledge, intermittent faults in MAS have not been concretely explored. In this paper we formally present a novel problem called Diagnosis of Intermittent Faults in Multi-Agent Systems ( DIFMAS ): a group of agents are observed across multiple runs. In each run, the success/failure of the agents and the system is observed, aiming to explain all the failed runs by diagnosing which agent(s) are faulty. The contributions of this paper are: (1) formalizing DIFMAS as a Model-Based Diagnosis problem, (2) solving it by presenting a Spectrum-Based Fault Localization (SFL) based method, called Multi-Run SFL-based Diagnosis Algorithm ( MRSD ). Experiments demonstrate that MRSD &#39;s outperforms competing SFL-based algorithms. Moreover, the algorithm&#39;s performance increases if planned interactions are considered.},
  archive      = {J_AIJ},
  author       = {Avraham Natan and Meir Kalech and Roman Barták},
  doi          = {10.1016/j.artint.2023.103994},
  journal      = {Artificial Intelligence},
  pages        = {103994},
  shortjournal = {Artif. Intell.},
  title        = {Diagnosis of intermittent faults in multi-agent systems: An SFL approach},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maintenance commitments: Conception, semantics, and
coherence. <em>AIJ</em>, <em>324</em>, 103993. (<a
href="https://doi.org/10.1016/j.artint.2023.103993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social commitments are recognized as an abstraction that enables flexible coordination between autonomous agents . We make these contributions. First, we introduce and formalize a concept of a maintenance commitment , a kind of social commitment characterized by a maintenance condition whose truthhood an agent commits to maintain. This concept of maintenance commitments enables us to capture a richer variety of real-world scenarios than possible using achievement commitments with a temporal condition. Second, we develop a rule-based operational semantics , by which we study the relationship between agents&#39; achievement and maintenance goals, achievement commitments, and maintenance commitments. Third, we motivate a notion of coherence between an agents&#39; achievement and maintenance cognitive and social constructs, and prove that, under specified conditions, the goals and commitments of both rational agents individually and of a multiagent system altogether are coherent. Fourth, we illustrate our approach with a detailed real-world scenario from an aerospace aftermarket domain.},
  archive      = {J_AIJ},
  author       = {Pankaj Telang and Munindar P. Singh and Neil Yorke-Smith},
  doi          = {10.1016/j.artint.2023.103993},
  journal      = {Artificial Intelligence},
  pages        = {103993},
  shortjournal = {Artif. Intell.},
  title        = {Maintenance commitments: Conception, semantics, and coherence},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning for collaborative recommendation with
biased and unbiased data. <em>AIJ</em>, <em>324</em>, 103992. (<a
href="https://doi.org/10.1016/j.artint.2023.103992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recommender system , a user&#39;s interaction is often biased by the items&#39; displaying positions and popularity, as well as the user&#39;s self-selection. Most existing recommendation models are built using such a biased user-system interaction data alone. In this paper, we introduce an additional specially collected unbiased data, and then have a new problem called collaborative recommendation with biased and unbiased data. We first formalize the studied problem and list three challenges, including the bias challenge, the heterogeneity challenge and the unbalance challenge. Then we propose a novel transfer learning-based AI solution, i.e., transfer via joint reconstruction (TJR), to achieve knowledge transfer and sharing between the biased data and unbiased data. Specifically, in our TJR, we use two different models to extract the users&#39; preferences and bias information, and then refine the prediction via the latent features containing the bias information in order to obtain a more accurate and unbiased recommendation. We further integrate the two data by reconstructing their interaction in a joint learning manner. Moreover, in order to better address the unbalance challenge, we introduce a bias regularization term and integrate bidirectional knowledge distillation . Finally, we adopt four representative methods, i.e., variational autoencoders , matrix factorization , neural collaborative filtering and graph convolution network , as the backbone models of our TJR and conduct extensive empirical studies on three public datasets, showcasing the effectiveness of our transfer learning solution over some very competitive baselines.},
  archive      = {J_AIJ},
  author       = {Zinan Lin and Dugang Liu and Weike Pan and Qiang Yang and Zhong Ming},
  doi          = {10.1016/j.artint.2023.103992},
  journal      = {Artificial Intelligence},
  pages        = {103992},
  shortjournal = {Artif. Intell.},
  title        = {Transfer learning for collaborative recommendation with biased and unbiased data},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bayesian approach to (online) transfer learning: Theory
and algorithms. <em>AIJ</em>, <em>324</em>, 103991. (<a
href="https://doi.org/10.1016/j.artint.2023.103991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning is a machine learning paradigm where knowledge from one problem is utilized to solve a new but related problem. While conceivable that knowledge from one task could help solve a related task, if not executed properly, transfer learning algorithms can impair the learning performance instead of improving it – commonly known as negative transfer. In this paper, we use a parametric statistical model to study transfer learning from a Bayesian perspective . Specifically, we study three variants of transfer learning problems, instantaneous, online, and time-variant transfer learning. We define an appropriate objective function for each problem and provide either exact expressions or upper bounds on the learning performance using information-theoretic quantities, which allow simple and explicit characterizations when the sample size becomes large. Furthermore, examples show that the derived bounds are accurate even for small sample sizes. The obtained bounds give valuable insights into the effect of prior knowledge on transfer learning, at least with respect to our Bayesian formulation of the transfer learning problem. In particular, we formally characterize the conditions under which negative transfer occurs. Lastly, we devise several (online) transfer learning algorithms that are amenable to practical implementations, some of which do not require the parametric assumption. We demonstrate the effectiveness of our algorithms with real data sets , focusing primarily on when the source and target data have strong similarities.},
  archive      = {J_AIJ},
  author       = {Xuetong Wu and Jonathan H. Manton and Uwe Aickelin and Jingge Zhu},
  doi          = {10.1016/j.artint.2023.103991},
  journal      = {Artificial Intelligence},
  pages        = {103991},
  shortjournal = {Artif. Intell.},
  title        = {A bayesian approach to (online) transfer learning: Theory and algorithms},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-aware shielding of partially observable monte carlo
planning policies. <em>AIJ</em>, <em>324</em>, 103987. (<a
href="https://doi.org/10.1016/j.artint.2023.103987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partially Observable Monte Carlo Planning (POMCP) is a powerful online algorithm that can generate approximate policies for large Partially Observable Markov Decision Processes . The online nature of this method supports scalability by avoiding complete policy representation. However, the lack of an explicit policy representation hinders interpretability and a proper evaluation of the risks an agent may incur. In this work, we propose a methodology based on Maximum Satisfiability Modulo Theory (MAX-SMT) for analyzing POMCP policies by inspecting their traces, namely, sequences of belief-action pairs generated by the algorithm. The proposed method explores local properties of the policy to build a compact and informative summary of the policy behaviour. Moreover, we introduce a rich and formal language that a domain expert can use to describe the expected behaviour of a policy. In more detail, we present a formulation that directly computes the risk involved in taking actions by considering the high-level elements specified by the expert. The final formula can identify risky decisions taken by POMCP that violate the expert indications. We show that this identification process can be used offline (to improve the policy&#39;s explainability and identify anomalous behaviours) or online (to shield the risky decisions of the POMCP algorithm). We present an extended evaluation of our approach on four domains: the well-known tiger and rocksample benchmarks, a problem of velocity regulation in mobile robots, and a problem of battery management in mobile robots. We test the methodology against a state-of-the-art anomaly detection algorithm to show that our approach can be used to identify anomalous behaviours in faulty POMCP. We also show, comparing the performance of shielded and unshielded POMCP, that the shielding mechanism can improve the system&#39;s performance. We provide an open-source implementation of the proposed methodologies at https://github.com/GiuMaz/XPOMCP .},
  archive      = {J_AIJ},
  author       = {Giulio Mazzi and Alberto Castellini and Alessandro Farinelli},
  doi          = {10.1016/j.artint.2023.103987},
  journal      = {Artificial Intelligence},
  pages        = {103987},
  shortjournal = {Artif. Intell.},
  title        = {Risk-aware shielding of partially observable monte carlo planning policies},
  volume       = {324},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Increasing revenue in bayesian posted price auctions through
signaling. <em>AIJ</em>, <em>323</em>, 103990. (<a
href="https://doi.org/10.1016/j.artint.2023.103990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study single-item single-unit Bayesian posted price auctions , where buyers arrive sequentially and their valuations for the item being sold depend on a random, unknown state of nature. The seller has complete knowledge of the actual state and can send signals to the buyers so as to disclose information about it. For instance, the state of nature may reflect the condition and/or some particular features of the item, which are known to the seller only. The problem faced by the seller is about how to partially disclose information about the state so as to maximize revenue . Unlike classical signaling problems, in this setting, the seller must also correlate the signals being sent to the buyers with some price proposals for them. This introduces additional challenges compared to standard settings. As a preliminary step, we show that, w.l.o.g., the seller can deterministically propose a price to each buyer on the basis of the signal being sent to that buyer, rather than selecting prices stochastically and arbitrarily correlating them with signals sent to all the buyers. Next, we consider two cases: the one where the seller can only send signals publicly visible to all buyers, and the case in which the seller can privately send a different signal to each buyer. As a first step, we prove that, in both settings, the problem of maximizing the seller&#39;s revenue does not admit an additive FPTAS unless P = NP P=NP , even for basic instances with a single buyer. As a result, in the rest of the paper, we focus on designing additive PTASs. In order to do so, we first introduce a unifying framework encompassing both public and private signaling, whose core result is a decomposition lemma that allows focusing on a finite set of possible buyers&#39; posteriors. This forms the basis on which our additive PTASs are developed. In particular, in the public signaling setting, our PTAS employs some ad hoc techniques based on linear programming, while our PTAS for the private setting relies on the ellipsoid method to solve an exponentially-sized LP in polynomial time . In the latter case, we need a custom approximate separation oracle, which we implement with a dynamic programming approach.},
  archive      = {J_AIJ},
  author       = {Matteo Castiglioni and Alberto Marchesi and Giulia Romano and Nicola Gatti},
  doi          = {10.1016/j.artint.2023.103990},
  journal      = {Artificial Intelligence},
  pages        = {103990},
  shortjournal = {Artif. Intell.},
  title        = {Increasing revenue in bayesian posted price auctions through signaling},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning reward machines: A study in partially observable
reinforcement learning. <em>AIJ</em>, <em>323</em>, 103989. (<a
href="https://doi.org/10.1016/j.artint.2023.103989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) is a machine learning paradigm wherein an artificial agent interacts with an environment with the purpose of learning behaviour that maximizes the expected cumulative reward it receives from the environment. Reward machines (RMs) provide a structured, automata-based representation of a reward function that enables an RL agent to decompose an RL problem into structured subproblems that can be efficiently learned via off-policy learning. Here we show that RMs can be learned from experience, instead of being specified by the user, and that the resulting problem decomposition can be used to effectively solve partially observable RL problems. We pose the task of learning RMs as a discrete optimization problem where the objective is to find an RM that decomposes the problem into a set of subproblems such that the combination of their optimal memoryless policies is an optimal policy for the original problem. We show the effectiveness of this approach on three partially observable domains, where it significantly outperforms A3C, PPO, and ACER, and discuss its advantages, limitations, and broader potential. 1},
  archive      = {J_AIJ},
  author       = {Rodrigo Toro Icarte and Toryn Q. Klassen and Richard Valenzano and Margarita P. Castro and Ethan Waldie and Sheila A. McIlraith},
  doi          = {10.1016/j.artint.2023.103989},
  journal      = {Artificial Intelligence},
  pages        = {103989},
  shortjournal = {Artif. Intell.},
  title        = {Learning reward machines: A study in partially observable reinforcement learning},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequential model-based diagnosis by systematic search.
<em>AIJ</em>, <em>323</em>, 103988. (<a
href="https://doi.org/10.1016/j.artint.2023.103988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based diagnosis aims at identifying the real cause of a system&#39;s malfunction based on a formal system model and observations of the system behavior. To discriminate between multiple fault hypotheses ( diagnoses ), sequential diagnosis approaches iteratively pose queries to an oracle to acquire additional knowledge about the diagnosed system. Depending on the system type, queries can capture, e.g., system tests, probes, measurements, or expert questions. As the determination of optimal queries is NP-hard, state-of-the-art sequential diagnosis methods rely on a myopic one-step-lookahead analysis which has proven to constitute a particularly favorable trade-off between computational efficiency and diagnostic effectivity. Yet, this solves only a part of the problem, as various sources of complexity, such as the reliance on costly reasoning services and large numbers of or not explicitly given query candidates, remain. To deal with such issues, existing approaches often make assumptions about the (i) type of diagnosed system, (ii) formalism to describe the system, (iii) inference engine, (iv) type of query to be of interest, (v) query quality criterion to be adopted, or (vi) diagnosis computation algorithm to be employed. Moreover, they (vii) often cannot deal with large or implicit query spaces or with expressive logics, or (viii) require inputs that cannot always be provided. As a remedy, we propose a novel one-step lookahead query computation technique for sequential diagnosis that overcomes the said issues of existing methods. Our approach (1) is based on a solid theory, (2) involves a systematic search for optimal queries, (3) can operate on implicit and huge query spaces , (4) allows for a two-stage optimization of queries (wrt. their number and cost), (5) is designed to reduce expensive logical inferences to a minimum , and (6) is generally applicable . The latter means that it can deal with any type of diagnosis problem as per Reiter&#39;s theory, is applicable with any monotonic knowledge representation language, can interact with a multitude of diagnosis engines and logical reasoners, and allows for a quality optimization of queries based on any of the common criteria in the literature. We extensively study the performance of the novel technique using a benchmark of real-world diagnosis problems. Our findings are that our approach enables the computation of optimal queries with hardly any delay, independently of the size and complexity of the considered benchmark problem. Moreover, it proves to be highly scalable, and it outperforms the state-of-the-art method in the domain of our benchmarks by orders of magnitude in terms of computation time while always returning a qualitatively as good or better query.},
  archive      = {J_AIJ},
  author       = {Patrick Rodler},
  doi          = {10.1016/j.artint.2023.103988},
  journal      = {Artificial Intelligence},
  pages        = {103988},
  shortjournal = {Artif. Intell.},
  title        = {Sequential model-based diagnosis by systematic search},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal graph contrastive encoding for neural machine
translation. <em>AIJ</em>, <em>323</em>, 103986. (<a
href="https://doi.org/10.1016/j.artint.2023.103986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important extension of conventional text-only neural machine translation (NMT), multi-modal neural machine translation (MNMT) aims to translate input source sentences paired with images into the target language. Although a lot of MNMT models have been proposed to perform multi-modal semantic fusion, they do not consider fine-grained semantic correspondences between semantic units of different modalities (i.e., words and visual objects), which can be exploited to refine multi-modal representation learning via fine-grained semantic interactions. To address this issue, we propose a graph-based multi-modal fusion encoder for NMT. Concretely, we first employ a unified multi-modal graph to represent the input sentence and image, in which the multi-modal semantic units are considered as the nodes in the graph, connected by two kinds of edges with different semantic relationships . Then, we stack multiple graph-based multi-modal fusion layers that iteratively conduct intra- and inter-modal interactions to learn node representations. Finally, via an attention mechanism , we induce a multi-modal context from the top node representations for the decoder. Particularly, we introduce a progressive contrastive learning strategy based on the multi-modal graph to refine the training of our proposed model, where hard negative samples are introduced gradually. To evaluate our model, we conduct experiments on commonly-used datasets. Experimental results and analysis show that our MNMT model obtains significant improvements over competitive baselines, achieving state-of-the-art performance on the Multi30K dataset.},
  archive      = {J_AIJ},
  author       = {Yongjing Yin and Jiali Zeng and Jinsong Su and Chulun Zhou and Fandong Meng and Jie Zhou and Degen Huang and Jiebo Luo},
  doi          = {10.1016/j.artint.2023.103986},
  journal      = {Artificial Intelligence},
  pages        = {103986},
  shortjournal = {Artif. Intell.},
  title        = {Multi-modal graph contrastive encoding for neural machine translation},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The notion of abstraction in ontology-based data management.
<em>AIJ</em>, <em>323</em>, 103976. (<a
href="https://doi.org/10.1016/j.artint.2023.103976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a novel reasoning task in Ontology-based Data Management (OBDM), called Abstraction, which aims at associating formal semantic descriptions to data services . In OBDM a domain ontology is used to provide a semantic layer mapped to the data sources of an organization. The basic idea of the work presented in this paper is to explain the semantics of a data service in terms of a query over the ontology. We illustrate a formal framework for this problem, based on three different notions of abstraction, called sound, complete, and perfect, respectively. We present a thorough complexity analysis of two computational problems, namely verification (checking whether a query is an abstraction of a given data service), and computation (computing an abstraction of a given data service).},
  archive      = {J_AIJ},
  author       = {Gianluca Cima and Antonella Poggi and Maurizio Lenzerini},
  doi          = {10.1016/j.artint.2023.103976},
  journal      = {Artificial Intelligence},
  pages        = {103976},
  shortjournal = {Artif. Intell.},
  title        = {The notion of abstraction in ontology-based data management},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Budget-feasible mechanisms for proportionally selecting
agents from groups. <em>AIJ</em>, <em>323</em>, 103975. (<a
href="https://doi.org/10.1016/j.artint.2023.103975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many social domains involving collective decision-making ( e.g. , committee selection and survey sampling), it is often desirable to select individuals from different population groups to achieve proportional representation ( e.g. , to represent the opinions of each group). For instance, in the selection of a committee ( e.g. , to form a working group within a company), the planner would like to select agents from different groups to represent their respective groups proportionally. Typically, there are intrinsic private costs for agents to represent their groups, and the planner would like to compensate the selected agents via some form of payments, which is constrained by the planner&#39;s available budget. As the costs are unknown to the planner, the planner is required to design incentive mechanisms to elicit agents&#39; real costs and provide payments (or monetary incentives) to the selected agents to ensure proportional representation and the total payments do not exceed the budget. Such a mechanism design setting falls into the budget-feasible mechanism design paradigm. However, existing budget-feasible mechanisms only consider all agents to be in the same group with non-proportional objectives. To study the above-mentioned setting, we consider the problem of designing budget-feasible mechanisms for selecting agents with private costs from various groups to ensure proportional representation, where the minimum proportion of the overall value of the selected agents from each group is maximized. We study this problem by first considering the setting with homogeneous agents who have identical values to the planner. Depending on agents&#39; membership in the groups, we consider two models: a single group model where each agent belongs to only one group, and a multiple group model where each agent may belong to multiple groups. We propose novel budget-feasible proportion-representative mechanisms for these models that require different selection methods, i.e. , a novel greedy mechanism that considers all possible proportion ratios for the single group model and a novel mechanism that leverages the Max-Flow algorithm to evaluate the proportional representation for the multiple group model, to choose representative agents from each group. The proposed mechanisms guarantee theoretical properties of individual rationality , budget-feasibility, truthfulness, and approximation performance on maximizing the minimum proportional representation of each group. We also provide a matching lower bound for budget-feasible proportion-representative mechanisms. Finally, we non-trivially extend these mechanisms to the settings of heterogeneous agents who can have different values to the planner under the two models.},
  archive      = {J_AIJ},
  author       = {Xiang Liu and Hau Chan and Minming Li and Weiwei Wu and Yingchao Zhao},
  doi          = {10.1016/j.artint.2023.103975},
  journal      = {Artificial Intelligence},
  pages        = {103975},
  shortjournal = {Artif. Intell.},
  title        = {Budget-feasible mechanisms for proportionally selecting agents from groups},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic generation of dominance breaking nogoods for a
class of constraint optimization problems. <em>AIJ</em>, <em>323</em>,
103974. (<a href="https://doi.org/10.1016/j.artint.2023.103974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint Optimization Problems (COPs) ask for an assignment of values to variables in order to optimize an objective subject to constraints that restrict the value combinations in the assignment. They are usually solved by the classical Branch and Bound (B&amp;B) search algorithm. Dominance breaking is an important technique in B&amp;B to prune assignments that are subordinate to others concerning the objective value and/or the satisfiability of constraints. In practice, the addition of constraints for dominance breaking can drastically speed up the B&amp;B search for solving many COPs. However, identification of suboptimal assignments in COPs and derivation of useful constraints for dominance breaking are usually problem-specific and require sophisticated human insights on the problem structure. This paper proposes the first theoretical and practical framework for automatic generation of dominance breaking constraints for a class of COPs consisting of efficiently checkable objectives and constraints. In particular, the framework focuses on generating nogood constraints representing incompatible value assignments and formulates nogood generation as solving auxiliary constraint satisfaction problems . The proposed method can generate nogoods of varying strengths for dominance breaking by controlling the number of involved variables. Experimentation on various benchmarks demonstrates the effectiveness of the proposal in both efficiency and ease of use. The superior performance is also supported by a theoretical analysis to compare the relative strength of automatically generated nogoods with manually derived dominance breaking constraints in the literature.},
  archive      = {J_AIJ},
  author       = {Jimmy H.M. Lee and Allen Z. Zhong},
  doi          = {10.1016/j.artint.2023.103974},
  journal      = {Artificial Intelligence},
  pages        = {103974},
  shortjournal = {Artif. Intell.},
  title        = {Automatic generation of dominance breaking nogoods for a class of constraint optimization problems},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast and accurate data-driven goal recognition using process
mining techniques. <em>AIJ</em>, <em>323</em>, 103973. (<a
href="https://doi.org/10.1016/j.artint.2023.103973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of goal recognition requests to automatically infer an accurate probability distribution over possible goals an autonomous agent is attempting to achieve in the environment. The state-of-the-art approaches for goal recognition operate under full knowledge of the environment and possible operations the agent can take. This knowledge, however, is often not available in real-world applications. Given historical observations of the agents&#39; behaviors in the environment, we learn skill models that capture how the agents achieved the goals in the past. Next, given fresh observations of an agent, we infer their goals by diagnosing deviations between the observations and all the available skill models. We present a framework that serves as an outline for implementing such data-driven goal recognition systems and its instance system implemented using process mining techniques . The evaluations we conducted using our publicly available implementation confirm that the approach is well-defined, i.e., all system parameters impact its performance, has high accuracy over a wide range of synthetic and real-world domains, which is comparable with the more knowledge-demanding state-of-the-art approaches, and operates fast.},
  archive      = {J_AIJ},
  author       = {Zihang Su and Artem Polyvyanyy and Nir Lipovetzky and Sebastian Sardiña and Nick van Beest},
  doi          = {10.1016/j.artint.2023.103973},
  journal      = {Artificial Intelligence},
  pages        = {103973},
  shortjournal = {Artif. Intell.},
  title        = {Fast and accurate data-driven goal recognition using process mining techniques},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A conflict-directed approach to chance-constrained mixed
logical linear programming. <em>AIJ</em>, <em>323</em>, 103972. (<a
href="https://doi.org/10.1016/j.artint.2023.103972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resistance to the adoption of autonomous systems comes in part from the perceived unreliability of the systems. The concerns can be addressed by deploying decision making algorithms that defines what it means to fail, and look for plans with the highest reward while limiting the probability of failure. This chance-constrained approach thus explicitly imposes a set of constraints that must be satisfied for success, and provides upper-bounds on the probability of violating such constraints. A chance-constrained mixed logical-linear program (CC-MLLP) is a natural formulation, allowing for the specification of linear and logical constraints, with probabilistic continuous variables. The formalism can be used to describe problems ranging from autonomous underwater vehicle path planning , to network routing under uncertainty. While naive encodings of CC-MLLPs can be solved with generalised solvers, the solution time may be unreasonable. In this work, we study architectures to speed up solutions by partitioning CC-MLLPs into the discrete and continuous portions. In order to provide faster solutions, we investigate methods for speeding up the solutions to the continuous chance-constrained linear programs. Further, by exploiting the new solution methods, we develop techniques for guiding the discrete decision making portion of the problem. The resulting algorithm achieves 10 times speed up over prior approaches on autonomous path planning benchmarks.},
  archive      = {J_AIJ},
  author       = {Cheng Fang and Brian C. Williams},
  doi          = {10.1016/j.artint.2023.103972},
  journal      = {Artificial Intelligence},
  pages        = {103972},
  shortjournal = {Artif. Intell.},
  title        = {A conflict-directed approach to chance-constrained mixed logical linear programming},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactuals as modal conditionals, and their
probability. <em>AIJ</em>, <em>323</em>, 103970. (<a
href="https://doi.org/10.1016/j.artint.2023.103970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a semantic analysis of Lewis&#39; counterfactuals. By exploiting the structural properties of the recently introduced boolean algebras of conditionals, we show that counterfactuals can be expressed as formal combinations of a conditional object and a normal necessity modal operator . Specifically, we introduce a class of algebras that serve as modal expansions of boolean algebras of conditionals, together with their dual relational structures . Moreover, we show that Lewis&#39; semantics based on sphere models can be reconstructed in this framework. As a consequence, we establish the soundness and completeness of a slightly stronger variant of Lewis&#39; logic for counterfactuals with respect to our algebraic models. In the second part of the paper, we present a novel approach to the probability of counterfactuals showing that it aligns with the uncertainty degree assigned by a belief function, as per Dempster-Shafer theory, to its associated conditional formula. Furthermore, we characterize the probability of a counterfactual in terms of Gärdenfors&#39; imaging rule for the probabilistic update.},
  archive      = {J_AIJ},
  author       = {Giuliano Rosella and Tommaso Flaminio and Stefano Bonzio},
  doi          = {10.1016/j.artint.2023.103970},
  journal      = {Artificial Intelligence},
  pages        = {103970},
  shortjournal = {Artif. Intell.},
  title        = {Counterfactuals as modal conditionals, and their probability},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Erratum to “dynamic term-modal logics for first-order
epistemic planning” [artif. Intell. 286 (2020) 103305]. <em>AIJ</em>,
<em>323</em>, 103969. (<a
href="https://doi.org/10.1016/j.artint.2023.103969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIJ},
  author       = {Andrés Occhipinti Liberman and Andreas Achen and Rasmus Kræmmer Rendsvig},
  doi          = {10.1016/j.artint.2023.103969},
  journal      = {Artificial Intelligence},
  pages        = {103969},
  shortjournal = {Artif. Intell.},
  title        = {Erratum to “Dynamic term-modal logics for first-order epistemic planning” [Artif. intell. 286 (2020) 103305]},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximability and efficient algorithms for constrained
fixed-horizon POMDPs with durative actions. <em>AIJ</em>, <em>323</em>,
103968. (<a href="https://doi.org/10.1016/j.artint.2023.103968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partially Observable Markov Decision Process (POMDP) is a fundamental model for probabilistic planning in stochastic domains. More recently, constrained POMDP and chance-constrained POMDP extend the model allowing constraints to be specified on some aspects of the policy in addition to the objective function. Despite their expressive power , these models assume all actions take a fixed duration, which poses a limitation in modeling real-world planning problems. In this work, we propose a unified model for durative POMDP and its constrained extensions. First, we convert these extensions into an Integer Linear Programming (ILP) formulation, which can be solved using existing solvers in the ILP literature. Second, a heuristic search approach is provided that can efficiently prune the search space, guided by solving successive partial ILP programs. Third, we give a theoretical analysis of the problem: unlike short-horizon POMDPs, with policies of a constant depth, which can be solved in polynomial time , the constrained extensions are NP-Hard even with a planning horizon of two and non-negative rewards. To alleviate that, we propose a Fully Polynomial Time Approximation Scheme (FPTAS) that computes (near) optimal deterministic policies in polynomial time. The FPTAS is among the best achievable in theory in terms of approximation ratio. Finally, evaluation results show that our approach is empirically superior to the state-of-the-art fixed-horizon chance-constrained POMDP solver.},
  archive      = {J_AIJ},
  author       = {Majid Khonji},
  doi          = {10.1016/j.artint.2023.103968},
  journal      = {Artificial Intelligence},
  pages        = {103968},
  shortjournal = {Artif. Intell.},
  title        = {Approximability and efficient algorithms for constrained fixed-horizon POMDPs with durative actions},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable acceptance in probabilistic and incomplete
abstract argumentation frameworks. <em>AIJ</em>, <em>323</em>, 103967.
(<a href="https://doi.org/10.1016/j.artint.2023.103967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dung&#39;s Argumentation Framework (AF) has been extended in several directions, including the possibility of representing uncertainty about the existence of arguments and attacks. In this regard, two main proposals have been introduced in the literature: Probabilistic Argumentation Framework (PrAF) and Incomplete Argumentation Framework (iAF). PrAF is an extension of AF with probability theory, thus representing quantified uncertainty. In contrast, iAF represents unquantified uncertainty, that is it can be seen as a special case where we only know that some elements (arguments or attacks) are uncertain. In this paper, we first address the problem of computing the probability that a given argument is accepted in PrAF. This is carried out by introducing the concept of probabilistic explanation for any given (probabilistic) extension. We show that the complexity of the problem is FP # P FP#P -hard and propose polynomial approximation algorithms with bounded additive error for PrAFs where odd-length cycles are forbidden. We investigate the approximate complexity of the related FP # P FP#P -hard problems of credulous and skeptical acceptance in PrAF, showing that they are generally harder than the problem of computing the probability that a given argument is accepted. Next we consider iAF and, after showing some equivalence properties among classes of iAFs, we study iAF as a special case of PrAF where uncertain elements have associated a probability equal to 1/2. Finally, given this result, we investigate the relationships between iAF acceptance problems and probabilistic acceptance in PrAF.},
  archive      = {J_AIJ},
  author       = {Gianvincenzo Alfano and Marco Calautti and Sergio Greco and Francesco Parisi and Irina Trubitsyna},
  doi          = {10.1016/j.artint.2023.103967},
  journal      = {Artificial Intelligence},
  pages        = {103967},
  shortjournal = {Artif. Intell.},
  title        = {Explainable acceptance in probabilistic and incomplete abstract argumentation frameworks},
  volume       = {323},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A postulate-driven study of logical argumentation.
<em>AIJ</em>, <em>322</em>, 103966. (<a
href="https://doi.org/10.1016/j.artint.2023.103966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logical argumentation is a well-known approach to modeling non-monotonic reasoning with conflicting information. In this paper we provide a comprehensive postulate-based study of properties of logical argumentation frameworks and a full characterization of their semantics and inference relations. In this way we identify well-behaved formal argumentative models of drawing logically justified inferences from a given set of possibly conflicting defeasible, as well as strict assumptions. Given some desiderata in terms of rationality postulates, we consider the conditions that an argumentation framework should fulfill for the desiderata to hold. One purpose of this approach is to assist designers to “plug-in” pre-defined formalisms according to actual needs. To this end, we present a classification of argumentation frameworks relative to the types of attacks they implement. In turn, for each class we determine which desiderata are satisfied. Our study is highly abstract, supposing only a minimal set of requirements on the considered underlying deductive systems , and in this way covering a broad range of formalisms, including classical, intuitionistic and modal logics.},
  archive      = {J_AIJ},
  author       = {Ofer Arieli and AnneMarie Borg and Christian Straßer},
  doi          = {10.1016/j.artint.2023.103966},
  journal      = {Artificial Intelligence},
  pages        = {103966},
  shortjournal = {Artif. Intell.},
  title        = {A postulate-driven study of logical argumentation},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair division of indivisible goods: Recent progress and open
questions. <em>AIJ</em>, <em>322</em>, 103965. (<a
href="https://doi.org/10.1016/j.artint.2023.103965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allocating resources to individuals in a fair manner has been a topic of interest since ancient times, with most of the early mathematical work on the problem focusing on resources that are infinitely divisible. Over the last decade, there has been a surge of papers studying computational questions regarding the indivisible case, for which exact fairness notions such as envy-freeness and proportionality are hard to satisfy. One main theme in the recent research agenda is to investigate the extent to which their relaxations, like maximin share fairness (MMS) and envy-freeness up to any good (EFX), can be achieved. In this survey, we present a comprehensive review of the recent progress made in the related literature by highlighting different ways to relax fairness notions, common algorithm design techniques, and the most interesting questions for future research.},
  archive      = {J_AIJ},
  author       = {Georgios Amanatidis and Haris Aziz and Georgios Birmpas and Aris Filos-Ratsikas and Bo Li and Hervé Moulin and Alexandros A. Voudouris and Xiaowei Wu},
  doi          = {10.1016/j.artint.2023.103965},
  journal      = {Artificial Intelligence},
  pages        = {103965},
  shortjournal = {Artif. Intell.},
  title        = {Fair division of indivisible goods: Recent progress and open questions},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sound and complete causal identification with latent
variables given local background knowledge. <em>AIJ</em>, <em>322</em>,
103964. (<a href="https://doi.org/10.1016/j.artint.2023.103964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Great efforts have been devoted to causal discovery from observational data , and it is well known that introducing some background knowledge attained from experiments or human expertise can be very helpful. However, it remains unknown that what causal relations are identifiable given background knowledge in the presence of latent confounders . In this paper, we solve the problem with sound and complete orientation rules when the background knowledge is given in a local form. Furthermore, based on the solution to the problem, this paper proposes two applications that are of independent interests. One is that we give a maximal ancestral graph (MAG) listing algorithm, to output all the MAGs consistent to the observational data in the presence of latent variables. The other application is that we present a general active learning framework for causal discovery in the presence of latent confounders, where we propose a baseline criterion to select the intervention variable with a Metropolis-Hastings MAG-sampling method. Experiments validate the efficiency of the proposed MAG listing method and the effectiveness of the active learning framework.},
  archive      = {J_AIJ},
  author       = {Tian-Zuo Wang and Tian Qin and Zhi-Hua Zhou},
  doi          = {10.1016/j.artint.2023.103964},
  journal      = {Artificial Intelligence},
  pages        = {103964},
  shortjournal = {Artif. Intell.},
  title        = {Sound and complete causal identification with latent variables given local background knowledge},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discovering agents. <em>AIJ</em>, <em>322</em>, 103963. (<a
href="https://doi.org/10.1016/j.artint.2023.103963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal models of agents have been used to analyse the safety aspects of machine learning systems . But identifying agents is non-trivial – often the causal model is just assumed by the modeller without much justification – and modelling failures can lead to mistakes in the safety analysis. This paper proposes the first formal causal definition of agents – roughly that agents are systems that would adapt their policy if their actions influenced the world in a different way. From this we derive the first causal discovery algorithm for discovering the presence of agents from empirical data, given a set of variables and under certain assumptions. We also provide algorithms for translating between causal models and game-theoretic influence diagrams. We demonstrate our approach by resolving some previous confusions caused by incorrect causal modelling of agents.},
  archive      = {J_AIJ},
  author       = {Zachary Kenton and Ramana Kumar and Sebastian Farquhar and Jonathan Richens and Matt MacDermott and Tom Everitt},
  doi          = {10.1016/j.artint.2023.103963},
  journal      = {Artificial Intelligence},
  pages        = {103963},
  shortjournal = {Artif. Intell.},
  title        = {Discovering agents},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iterative genetic improvement: Scaling stochastic program
synthesis. <em>AIJ</em>, <em>322</em>, 103962. (<a
href="https://doi.org/10.1016/j.artint.2023.103962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Program synthesis aims to automatically find programs from an underlying programming language that satisfy a given specification. While this has the potential to revolutionize computing, how to search over the vast space of programs efficiently is an unsolved challenge in program synthesis. In cases where large programs are required for a solution, it is generally believed that stochastic search has advantages over other classes of search techniques. Unfortunately, existing stochastic program synthesizers do not meet this expectation very well, suffering from the scalability issue. To overcome this problem, we propose a new framework for stochastic program synthesis, called iterative genetic improvement. The key idea is to apply genetic improvement to improve a current reference program , and then iteratively replace the reference program by the best program found. Compared to traditional stochastic synthesis approaches, iterative genetic improvement can build up the complexity of programs incrementally in a more robust way. We evaluate the approach on two program synthesis domains: list manipulation and string transformation, along with a number of general program synthesis problems. Our empirical results indicate that this method has considerable advantages over several representative stochastic program synthesizer techniques, both in terms of scalability and of solution quality.},
  archive      = {J_AIJ},
  author       = {Yuan Yuan and Wolfgang Banzhaf},
  doi          = {10.1016/j.artint.2023.103962},
  journal      = {Artificial Intelligence},
  pages        = {103962},
  shortjournal = {Artif. Intell.},
  title        = {Iterative genetic improvement: Scaling stochastic program synthesis},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Walrasian pricing in multi-unit auctions. <em>AIJ</em>,
<em>322</em>, 103961. (<a
href="https://doi.org/10.1016/j.artint.2023.103961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-unit auctions are a paradigmatic model of resource allocation, where a seller brings multiple units of a good to a set of buyers equipped with monetary budgets. It is well known that Walrasian equilibria do not always exist in this model, however compelling relaxations such as Walrasian envy-free pricing do. We design a best possible envy-free and prior-free mechanism for multi-unit auctions with budgets. When the market is even mildly competitive, the approximation ratios of this mechanism are small constants for both the revenue and welfare objectives, and in fact for welfare the approximation converges to 1 as the market becomes fully competitive. We also give an impossibility theorem, showing that truthfulness requires discarding resources and is thus incompatible with (Pareto) efficiency.},
  archive      = {J_AIJ},
  author       = {Simina Brânzei and Aris Filos-Ratsikas and Peter Bro Miltersen and Yulong Zeng},
  doi          = {10.1016/j.artint.2023.103961},
  journal      = {Artificial Intelligence},
  pages        = {103961},
  shortjournal = {Artif. Intell.},
  title        = {Walrasian pricing in multi-unit auctions},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Entropy estimation via uniformization. <em>AIJ</em>,
<em>322</em>, 103954. (<a
href="https://doi.org/10.1016/j.artint.2023.103954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entropy estimation is of practical importance in information theory and statistical science. Many existing entropy estimators suffer from fast growing estimation bias with respect to dimensionality, rendering them unsuitable for high-dimensional problems. In this work we propose a transform-based method for high-dimensional entropy estimation, which consists of the following two main ingredients. Firstly, we provide a modified k-nearest neighbors (k-NN) entropy estimator that can reduce estimation bias for samples closely resembling a uniform distribution. Second we design a normalizing flow based mapping that pushes samples toward the uniform distribution, and the relation between the entropy of the original samples and the transformed ones is also derived. As a result the entropy of a given set of samples is estimated by first transforming them toward the uniform distribution and then applying the proposed estimator to the transformed samples. The performance of the proposed method is compared against several existing entropy estimators, with both mathematical examples and real-world applications.},
  archive      = {J_AIJ},
  author       = {Ziqiao Ao and Jinglai Li},
  doi          = {10.1016/j.artint.2023.103954},
  journal      = {Artificial Intelligence},
  pages        = {103954},
  shortjournal = {Artif. Intell.},
  title        = {Entropy estimation via uniformization},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Are the BERT family zero-shot learners? A study on their
potential and limitations. <em>AIJ</em>, <em>322</em>, 103953. (<a
href="https://doi.org/10.1016/j.artint.2023.103953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Starting from the resurgence of deep learning , language models (LMs) have never been so popular. Through simply increasing model scale and data size, large LMs pre-trained with self-supervision objectives demonstrate awe-inspiring results on both task performance and generalization. At the early stage, supervised fine-tuning is indispensable in adapting pre-trained language models (PLMs) to downstream tasks. Later on, the sustained growth of model capacity and data size, as well as newly presented pre-training techniques, make the PLMs perform well under the few-shot setting, especially in the recent paradigm of prompt-based learning. After witnessing the success of PLMs for few-shot tasks, we propose to further study the potential and limitations of PLMs for the zero-shot setting. We utilize 3 models from the most popular BERT family to launch the empirical study on 20 different datasets. We are surprised to find that some simple strategies (without the need of human efforts or unsupervised data) can yield very promising results on a few widely-used datasets, e.g., 88.34\% ( ± 0.60 ) 88.34\%(±0.60) accuracy on the IMDB dataset, and 84.88\% ( ± 2.83 ) 84.88\%(±2.83) accuracy on the Amazon dataset, which outperforms manually created prompts without engineering in achieving much better and stable performance with the accuracy of 74.06\% ( ± 13.04 ) 74.06\%(±13.04) , 75.54\% ( ± 11.77 ) 75.54\%(±11.77) for comparison. However, we also observe some limitations of PLMs under the zero-shot setting, particularly for the language understanding tasks (e.g., GLUE, SuperGLUE). 2},
  archive      = {J_AIJ},
  author       = {Yue Wang and Lijun Wu and Juntao Li and Xiaobo Liang and Min Zhang},
  doi          = {10.1016/j.artint.2023.103953},
  journal      = {Artificial Intelligence},
  pages        = {103953},
  shortjournal = {Artif. Intell.},
  title        = {Are the BERT family zero-shot learners? a study on their potential and limitations},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effects of explanations on automation bias.
<em>AIJ</em>, <em>322</em>, 103952. (<a
href="https://doi.org/10.1016/j.artint.2023.103952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we explore the effect of explanations on reducing errors in the human decision making process caused by placing excessive reliance on automated decision support systems. We develop and implement different forms of explanations based on cognitive principles and evaluate their effect over two different domains: our new version of the Coloured Trails game, and over a simulated radiological task. We found that explanations did not reduce this aspect of automation bias and sometimes increased it. However, they reduced completion time and often increased user decision accuracy, despite not altering the perceived task load. Overall, explanations were beneficial though the benefits were highly context dependent. This work contributes to the complex interplay between automation bias, performance and explanations.},
  archive      = {J_AIJ},
  author       = {Mor Vered and Tali Livni and Piers Douglas Lionel Howe and Tim Miller and Liz Sonenberg},
  doi          = {10.1016/j.artint.2023.103952},
  journal      = {Artificial Intelligence},
  pages        = {103952},
  shortjournal = {Artif. Intell.},
  title        = {The effects of explanations on automation bias},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral complexity-scaled generalisation bound of
complex-valued neural networks. <em>AIJ</em>, <em>322</em>, 103951. (<a
href="https://doi.org/10.1016/j.artint.2023.103951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex-valued neural networks (CVNNs) have been widely applied in various fields, primarily in signal processing and image recognition. Few studies have focused on the generalisation of CVNNs, although it is vital to ensure the performance of CVNNs on unseen data. This study is the first to prove a generalisation bound for complex-valued neural networks. The bounds increase as the spectral complexity increases, with the dominant factor being the product of the spectral norms of the weight matrices. Furthermore, this work provides a generalisation bound for CVNNs trained on sequential data, which is also affected by the spectral complexity. Theoretically, these bounds are derived using the Maurey Sparsification Lemma and Dudley entropy integral. We conducted empirical experiments on various datasets including MNIST, ashionMNIST, CIFAR-10, CIFAR-100, Tiny ImageNet, and IMDB by training complex-valued convolutional neural networks . The Spearman rank-order correlation coefficient and the corresponding p-values on these datasets provide strong proof of the statistically significant correlation between the spectral complexity of a network and its generalisation ability , as measured by the spectral norm product of the weight matrices. The code is available at https://github.com/LeavesLei/cvnn_generalization .},
  archive      = {J_AIJ},
  author       = {Haowen Chen and Fengxiang He and Shiye Lei and Dacheng Tao},
  doi          = {10.1016/j.artint.2023.103951},
  journal      = {Artificial Intelligence},
  pages        = {103951},
  shortjournal = {Artif. Intell.},
  title        = {Spectral complexity-scaled generalisation bound of complex-valued neural networks},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conflict-tolerant and conflict-free multi-agent meeting.
<em>AIJ</em>, <em>322</em>, 103950. (<a
href="https://doi.org/10.1016/j.artint.2023.103950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Multi-Agent Meeting problem (MAM), the task is to find the optimal meeting location for multiple agents , as well as a path for each agent to that location. Among all possible meeting locations, the optimal meeting location has the minimum cost according to a given cost function. Two cost functions are considered in this research: (1) the sum of all agents paths&#39; costs to the meeting location (SOC) and (2) the cost of the longest path among them (MKSP). MAM has many real-life applications, such as choosing a gathering point for multiple traveling agents (humans, cars, or robots). In this paper, we divide MAM into two variants. In its basic version, MAM allows multiple agents to occupy the same location, i.e., it is conflict tolerant . For MAM, we introduce MM*, a Multi-Directional Heuristic Search algorithm, that finds the optimal meeting location under different cost functions. MM* generalizes the Meet in the Middle (MM) bidirectional search algorithm to the case of finding an optimal meeting location for multiple agents. Several admissible heuristics are proposed for MM*, and experiments demonstrate the benefits of MM*. As agents may be embodied in the world, a solution to MAM may contain conflicting paths, where more than one agent occupies the same location at the same time. The second variant of the MAM problem is called Conflict-Free Multi-Agent Meeting (CF-MAM), where the task is to find the optimal meeting location for multiple agents (as in MAM) as well as conflict-free paths (in the same manner as the prominent Multi-Agent Path Finding problem (MAPF)) to that location. For optimally solving CF-MAM, we introduce two novel algorithms, which combine MAM and MAPF solvers. We prove the optimality of both algorithms and compare them experimentally, showing the pros and cons of each algorithm. 1},
  archive      = {J_AIJ},
  author       = {Dor Atzmon and Ariel Felner and Jiaoyang Li and Shahaf Shperberg and Nathan Sturtevant and Sven Koenig},
  doi          = {10.1016/j.artint.2023.103950},
  journal      = {Artificial Intelligence},
  pages        = {103950},
  shortjournal = {Artif. Intell.},
  title        = {Conflict-tolerant and conflict-free multi-agent meeting},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Certified reinforcement learning with logic guidance.
<em>AIJ</em>, <em>322</em>, 103949. (<a
href="https://doi.org/10.1016/j.artint.2023.103949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) is a widely employed machine learning architecture that has been applied to a variety of control problems. However, applications in safety-critical domains require a systematic and formal approach to specifying requirements as tasks or goals. We propose a model-free RL algorithm that enables the use of Linear Temporal Logic (LTL) to formulate a goal for unknown continuous-state/action Markov Decision Processes (MDPs). The given LTL property is translated into a Limit-Deterministic Generalised Büchi Automaton (LDGBA), which is then used to shape a synchronous reward function on-the-fly. Under certain assumptions, the algorithm is guaranteed to synthesise a control policy whose traces satisfy the LTL specification with maximal probability.},
  archive      = {J_AIJ},
  author       = {Hosein Hasanbeig and Daniel Kroening and Alessandro Abate},
  doi          = {10.1016/j.artint.2023.103949},
  journal      = {Artificial Intelligence},
  pages        = {103949},
  shortjournal = {Artif. Intell.},
  title        = {Certified reinforcement learning with logic guidance},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How to find a good explanation for clustering? <em>AIJ</em>,
<em>322</em>, 103948. (<a
href="https://doi.org/10.1016/j.artint.2023.103948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {k -means and k -median clustering are powerful unsupervised machine learning techniques . However, due to complicated dependencies on all the features, it is challenging to interpret the resulting cluster assignments. Moshkovitz, Dasgupta, Rashtchian, and Frost proposed an elegant model of explainable k -means and k -median clustering in ICML 2020. In this model, a decision tree with k leaves provides a straightforward characterization of the data set into clusters. We study two natural algorithmic questions about explainable clustering. (1) For a given clustering, how to find the “best explanation” by using a decision tree with k leaves? (2) For a given set of points, how to find a decision tree with k leaves minimizing the k -means/median objective of the resulting explainable clustering? To address the first question, we introduce a new model of explainable clustering. Our model, inspired by the notion of outliers in robust statistics, is the following. We are seeking a small number of points (outliers) whose removal makes the existing clustering well-explainable. For addressing the second question, we initiate the study of the model of Moshkovitz et al. from the perspective of multivariate complexity. Our rigorous algorithmic analysis sheds some light on the influence of parameters like the input size, dimension of the data, the number of outliers, the number of clusters, and the approximation ratio, on the computational complexity of explainable clustering.},
  archive      = {J_AIJ},
  author       = {Sayan Bandyapadhyay and Fedor V. Fomin and Petr A. Golovach and William Lochet and Nidhi Purohit and Kirill Simonov},
  doi          = {10.1016/j.artint.2023.103948},
  journal      = {Artificial Intelligence},
  pages        = {103948},
  shortjournal = {Artif. Intell.},
  title        = {How to find a good explanation for clustering?},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the progression of belief. <em>AIJ</em>, <em>322</em>,
103947. (<a href="https://doi.org/10.1016/j.artint.2023.103947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on weighted possible-world semantics, Belle and Lakemeyer recently proposed the logic DS, a probabilistic extension of a modal variant of the situation calculus with a model of belief. The logic has many desirable properties like full introspection and it is able to precisely capture the beliefs of a probabilistic knowledge base in terms of the notion of only-believing. While the proposal is intuitively appealing, it is unclear how to do planning with such logic. The reason behind this is that the logic lacks projection reasoning mechanisms and projection lies at the heart of planning. Projection reasoning, in general, is to decide what holds after actions. Two main solutions to projection exist: regression and progression. Roughly, regression reduces a query about the future to a query about the initial state while progression, on the other hand, changes the initial state according to the effects of actions and then checks whether the formula holds in the updated state. In this paper, we study projection by progression in the logic DS. It is known that the progression of a categorical knowledge base wrt a noise-free action corresponds to what is only-known after that action. We show how to progress a type of probabilistic knowledge base wrt noisy actions by the notion of only-believing after actions. Our notion of only-believing is closely related to Lin and Reiter&#39;s notion of progression.},
  archive      = {J_AIJ},
  author       = {Daxin Liu and Qihui Feng},
  doi          = {10.1016/j.artint.2023.103947},
  journal      = {Artificial Intelligence},
  pages        = {103947},
  shortjournal = {Artif. Intell.},
  title        = {On the progression of belief},
  volume       = {322},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving simultaneous target assignment and path planning
efficiently with time-independent execution. <em>AIJ</em>, <em>321</em>,
103946. (<a href="https://doi.org/10.1016/j.artint.2023.103946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time planning for a combined problem of target assignment and path planning for multiple agents , also known as the unlabeled version of multi-agent path finding (MAPF), is crucial for high-level coordination in multi-agent systems, such as pattern formation by robot swarms. This paper studies two aspects of unlabeled-MAPF: (1) offline scenario: solving large instances using centralized approaches with a small computation time, and (2) online scenario: executing unlabeled-MAPF, despite the timing uncertainties real robots face. For this purpose, we propose TSWAP , a novel sub-optimal complete algorithm that takes an arbitrary initial target assignment and then repeats one-timestep path planning with target swapping. TSWAP can adapt to both offline and online scenarios. We empirically demonstrate that offline TSWAP is highly scalable, and provides near-optimal solutions while reducing runtime by orders of magnitude compared with existing approaches. In addition, we present the benefits of online TSWAP , such as delay tolerance, through real-robot demonstrations.},
  archive      = {J_AIJ},
  author       = {Keisuke Okumura and Xavier Défago},
  doi          = {10.1016/j.artint.2023.103946},
  journal      = {Artificial Intelligence},
  pages        = {103946},
  shortjournal = {Artif. Intell.},
  title        = {Solving simultaneous target assignment and path planning efficiently with time-independent execution},
  volume       = {321},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human performance consequences of normative and contrastive
explanations: An experiment in machine learning for reliability
maintenance. <em>AIJ</em>, <em>321</em>, 103945. (<a
href="https://doi.org/10.1016/j.artint.2023.103945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision aids based on artificial intelligence and machine learning can benefit human decisions and system performance, but can also provide incorrect advice, and invite operators to inappropriately rely on automation. This paper examined the extent to which example-based explanations could improve reliance on a decision aid that is based on machine learning . Participants engaged in a preventive maintenance task by providing their diagnosis of the conditions of three components of a hydraulic system. A decision aid based on machine learning provided advice but was not always reliable. Three explanation displays (baseline, normative, normative plus contrastive) were manipulated within-participants. With the normative explanation display, we found improvements in participants&#39; decision time and subjective workload. With the addition of contrastive explanations, we found improvements in participants&#39; hit rate and sensitivity in discriminating between correct and incorrect ML advice. Implications for the design of explainable interfaces to support human-AI interaction in data intensive environments are discussed.},
  archive      = {J_AIJ},
  author       = {Davide Gentile and Birsen Donmez and Greg A. Jamieson},
  doi          = {10.1016/j.artint.2023.103945},
  journal      = {Artificial Intelligence},
  pages        = {103945},
  shortjournal = {Artif. Intell.},
  title        = {Human performance consequences of normative and contrastive explanations: An experiment in machine learning for reliability maintenance},
  volume       = {321},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum to “separators and adjustment sets in causal
graphs: Complete criteria and an algorithmic framework” [artif. Intell.
270 (2019) 1–40]. <em>AIJ</em>, <em>321</em>, 103938. (<a
href="https://doi.org/10.1016/j.artint.2023.103938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIJ},
  author       = {Benito van der Zander and Maciej Liśkiewicz and Johannes Textor},
  doi          = {10.1016/j.artint.2023.103938},
  journal      = {Artificial Intelligence},
  pages        = {103938},
  shortjournal = {Artif. Intell.},
  title        = {Corrigendum to “Separators and adjustment sets in causal graphs: Complete criteria and an algorithmic framework” [Artif. intell. 270 (2019) 1–40]},
  volume       = {321},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial state-action features for general games.
<em>AIJ</em>, <em>321</em>, 103937. (<a
href="https://doi.org/10.1016/j.artint.2023.103937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many board games and other abstract games, patterns have been used as features that can guide automated game-playing agents. Such patterns or features often represent particular configurations of pieces, empty positions, etc., which may be relevant for a game&#39;s strategies. Their use has been particularly prevalent in the game of Go, but also many other games used as benchmarks for AI research. In this paper, we formulate a design and efficient implementation of spatial state-action features for general games. These are patterns that can be trained to incentivise or disincentivise actions based on whether or not they match variables of the state in a local area around action variables. We provide extensive details on several design and implementation choices, with a primary focus on achieving a high degree of generality to support a wide variety of different games using different board geometries or other graphs. Secondly, we propose an efficient approach for evaluating active features for any given set of features. In this approach, we take inspiration from heuristics used in problems such as SAT to optimise the order in which parts of patterns are matched and prune unnecessary evaluations. This approach is defined for a highly general and abstract description of the problem—phrased as optimising the order in which propositions of formulas in disjunctive normal form are evaluated—and may therefore also be of interest to other types of problems than board games. An empirical evaluation on 33 distinct games in the Ludii general game system demonstrates the efficiency of this approach in comparison to a naive baseline, as well as a baseline based on prefix trees, and demonstrates that the additional efficiency significantly improves the playing strength of agents using the features to guide search.},
  archive      = {J_AIJ},
  author       = {Dennis J.N.J. Soemers and Éric Piette and Matthew Stephenson and Cameron Browne},
  doi          = {10.1016/j.artint.2023.103937},
  journal      = {Artificial Intelligence},
  pages        = {103937},
  shortjournal = {Artif. Intell.},
  title        = {Spatial state-action features for general games},
  volume       = {321},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Polynomial combined first-order rewritings for linear and
guarded existential rules. <em>AIJ</em>, <em>321</em>, 103936. (<a
href="https://doi.org/10.1016/j.artint.2023.103936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of ontological query answering , that is, the problem of answering a database query (typically a conjunctive query) in the presence of an ontology. This means that during the query answering process we also need to take into account the knowledge that can be inferred from the given database and ontology. Building, however, ontology-aware database systems from scratch, with sophisticated optimization techniques, is a highly non-trivial task that requires a great engineering effort. Therefore, exploiting conventional database systems is an important route towards efficient ontological query answering. Nevertheless, standard database systems are unaware of ontologies. An approach to ontological query answering that enables the use of standard database systems is the so-called polynomial combined query rewriting , originally introduced in the context of description logics : the conjunctive query q and the ontology Σ are rewritten in polynomial time into a first-order query q Σ qΣ (in a database-independent way), while the database D and the ontology Σ are rewritten in polynomial time into a new database D Σ DΣ (in a query-independent way), such that the answer to q in the presence of Σ over D coincides with the answer to q Σ qΣ over D Σ DΣ . The latter can then be computed by exploiting a conventional database system. In this work, we focus on linear and guarded existential rules, which form robust rule-based languages for modeling ontologies, and investigate the limits of polynomial combined query rewriting. In particular, we show that this type of rewriting can be successfully applied to (i) linear existential rules when the rewritten query can use the full power of first-order queries, (ii) linear existential rules when the arity of the underlying schema is fixed and the rewritten query is positive existential , namely it uses only existential quantification, conjunction, and disjunction, and (iii) guarded existential rules when the underlying schema is fixed and the rewritten query is positive existential. We can show that the above results reach the limits (under standard complexity-theoretic assumptions such as ) of polynomial combined query rewriting in the case of linear and guarded existential rules.},
  archive      = {J_AIJ},
  author       = {Georg Gottlob and Marco Manna and Andreas Pieris},
  doi          = {10.1016/j.artint.2023.103936},
  journal      = {Artificial Intelligence},
  pages        = {103936},
  shortjournal = {Artif. Intell.},
  title        = {Polynomial combined first-order rewritings for linear and guarded existential rules},
  volume       = {321},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Syntactic reasoning with conditional probabilities in
deductive argumentation. <em>AIJ</em>, <em>321</em>, 103934. (<a
href="https://doi.org/10.1016/j.artint.2023.103934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidence from studies, such as in science or medicine, often corresponds to conditional probability statements. Furthermore, evidence can conflict, in particular when coming from multiple studies. Whilst it is natural to make sense of such evidence using arguments, there is a lack of a systematic formalism for representing and reasoning with conditional probability statements in computational argumentation. We address this shortcoming by providing a formalization of conditional probabilistic argumentation based on probabilistic conditional logic . We provide a semantics and a collection of comprehensible inference rules that give different insights into evidence. We show how arguments constructed from proofs and attacks between them can be analyzed as arguments graphs using dialectical semantics and via the epistemic approach to probabilistic argumentation. Our approach allows for a transparent and systematic way of handling uncertainty that often arises in evidence.},
  archive      = {J_AIJ},
  author       = {Anthony Hunter and Nico Potyka},
  doi          = {10.1016/j.artint.2023.103934},
  journal      = {Artificial Intelligence},
  pages        = {103934},
  shortjournal = {Artif. Intell.},
  title        = {Syntactic reasoning with conditional probabilities in deductive argumentation},
  volume       = {321},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving logical flow in english-as-a-foreign-language
learner essays by reordering sentences. <em>AIJ</em>, <em>320</em>,
103935. (<a href="https://doi.org/10.1016/j.artint.2023.103935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Argumentation is ubiquitous in everyday discourse, and it is a skill that can be learned. In our society, it is also one that must be learned: education systems all over the world agree on the importance of argumentation skills. However, writing effective argumentation is difficult, and even more so if it has to be expressed in a foreign language. Existing artificial intelligence systems for language learning can help learners: they can provide objective feedback (e.g., concerning grammar and spelling), as well as providing learners with opportunities to identify errors and subsequently improve their texts. Even so, systems aiming at higher discourse-level skills, such as persuasiveness and content organisation, are still limited. In this article, we propose the novel task of sentence reordering for improving the logical flow of argumentative essays. To train such a computational system, we present a new corpus called ICNALE-AS2R, containing essays written by English-as-foreign-language learners from various Asian countries, that have been annotated with argumentative structure and sentence reordering. We also propose a novel method to automatically reorder sentences in imperfect essays, which is based on argumentative structure analysis. Given an input essay and its corresponding argumentative structure, we cast the reordering task as a traversal problem. Our sentence reordering system first determines the pairwise ordering relation between pairs of sentences that are connected by argumentative relations. In the second step, the system traverses the argumentative structure that has been augmented with pairwise ordering information, in order to generate the final output text. Empirical evaluation shows that in the task of reconstructing the final reordered essays in the dataset, our reordering system achieves .926 and .879 in longest common subsequence ratio and Kendall&#39;s Tau metrics, respectively. The system is also able to perform the reordering operation selectively, that is, it reorders sentences when necessary and retains the original input order when it is already optimal.},
  archive      = {J_AIJ},
  author       = {Jan Wira Gotama Putra and Simone Teufel and Takenobu Tokunaga},
  doi          = {10.1016/j.artint.2023.103935},
  journal      = {Artificial Intelligence},
  pages        = {103935},
  shortjournal = {Artif. Intell.},
  title        = {Improving logical flow in english-as-a-foreign-language learner essays by reordering sentences},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ASP and subset minimality: Enumeration, cautious reasoning
and MUSes. <em>AIJ</em>, <em>320</em>, 103931. (<a
href="https://doi.org/10.1016/j.artint.2023.103931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer Set Programming (ASP) is a well-known logic-based formalism that has been used to model and solve a variety of AI problems. For several years, ASP implementations primarily focused on the main computational task: the computation of one answer set of a (logic) program. Nonetheless, several AI problems, that can be conveniently modelled in ASP, require to enumerate solutions characterized by an optimality property that can be expressed in terms of subset-minimality with respect to some objective atoms. In this context, solutions are often either (i) answer sets that are subset-minimal w.r.t. the objective atoms or (ii) atoms that are contained in all subset-minimal answer sets, or (iii) sets of atoms that enforce the absence of answer sets on the ASP program at hand — such sets are referred to as minimal unsatisfiable subsets (MUSes). In all the above-mentioned cases, the corresponding computational task is currently not supported by plain state-of-the-art ASP solvers. In this paper, we study formally these tasks and fill the gap in current implementations by proposing several algorithms to enumerate MUSes and subset-minimal answer sets, as well as perform cautious reasoning on subset-minimal answer sets. We implement our algorithms on top of wasp and perform an experimental analysis on several hard benchmarks showing the good performance of our implementation.},
  archive      = {J_AIJ},
  author       = {Mario Alviano and Carmine Dodaro and Salvatore Fiorentino and Alessandro Previti and Francesco Ricca},
  doi          = {10.1016/j.artint.2023.103931},
  journal      = {Artificial Intelligence},
  pages        = {103931},
  shortjournal = {Artif. Intell.},
  title        = {ASP and subset minimality: Enumeration, cautious reasoning and MUSes},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral clustering with robust self-learning constraints.
<em>AIJ</em>, <em>320</em>, 103924. (<a
href="https://doi.org/10.1016/j.artint.2023.103924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering is a leading unsupervised classification algorithm widely used to capture complex clusters in unlabeled data . Additional prior information can further enhance the quality of spectral clustering results to satisfy users&#39; expectations. However, it is challenging for users to find the prior information under unsupervised scenes. To get rid of the deficiency, we propose a spectral clustering model with robust self-learning constraints. In this model, we first extend the optimization problem of spectral clustering by seeing label constraints as variables to learn the constraints and the clustering result simultaneously. Furthermore, we add a robust term to the proposed model so that we can learn multiple groups of label constraints to guide the clustering process and find a robust self-constrained spectral clustering result . The robust term can reduce the impact of uncertainty in the quality of a single set of label constraints on the performance of the proposed model. An iterative strategy with update formulas for variables is proposed to solve the self-constrained spectral clustering problem. We provide the theoretical analysis to explain the importance of the learned constraints in spectral clustering. Furthermore, we analyze the convergence of our optimization scheme. Finally, we have done many experiments on benchmark data sets to illustrate the effectiveness of the proposed algorithm.},
  archive      = {J_AIJ},
  author       = {Liang Bai and Minxue Qi and Jiye Liang},
  doi          = {10.1016/j.artint.2023.103924},
  journal      = {Artificial Intelligence},
  pages        = {103924},
  shortjournal = {Artif. Intell.},
  title        = {Spectral clustering with robust self-learning constraints},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-aware controller for autonomous vehicles using
model-based collision prediction and reinforcement learning.
<em>AIJ</em>, <em>320</em>, 103923. (<a
href="https://doi.org/10.1016/j.artint.2023.103923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Vehicles (AVs) have the potential to save millions of lives and increase the efficiency of transportation services. However, the successful deployment of AVs requires tackling multiple challenges related to modeling and certifying safety. State-of-the-art decision-making methods usually rely on end-to-end learning or imitation learning approaches, which still pose significant safety risks. Hence the necessity of risk-aware AVs that can better predict and handle dangerous situations. Furthermore, current approaches tend to lack explainability due to their reliance on end-to-end Deep Learning , where significant causal relationships are not guaranteed to be learned from data. This paper introduces a novel risk-aware framework for training AV agents using a bespoke collision prediction model and Reinforcement Learning (RL). The collision prediction model is based on Gaussian Processes and vehicle dynamics, and is used to generate the RL state vector. Using an explicit risk model increases the post-hoc explainability of the AV agent, which is vital for reaching and certifying the high safety levels required for AVs and other safety-sensitive applications. Experimental results obtained with a simulator and state-of-the-art RL algorithms show that the risk-aware RL framework decreases average collision rates by 15\%, makes AVs more robust to sudden harsh braking situations, and achieves better performance in both safety and speed when compared to a standard rule-based method (the Intelligent Driver Model). Moreover, the proposed collision prediction model outperforms other models in the literature.},
  archive      = {J_AIJ},
  author       = {Eduardo Candela and Olivier Doustaly and Leandro Parada and Felix Feng and Yiannis Demiris and Panagiotis Angeloudis},
  doi          = {10.1016/j.artint.2023.103923},
  journal      = {Artificial Intelligence},
  pages        = {103923},
  shortjournal = {Artif. Intell.},
  title        = {Risk-aware controller for autonomous vehicles using model-based collision prediction and reinforcement learning},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GoSafeOpt: Scalable safe exploration for global optimization
of dynamical systems. <em>AIJ</em>, <em>320</em>, 103922. (<a
href="https://doi.org/10.1016/j.artint.2023.103922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning optimal control policies directly on physical systems is challenging. Even a single failure can lead to costly hardware damage. Most existing model-free learning methods that guarantee safety, i.e., no failures, during exploration are limited to local optima. This work proposes GoSafeOpt as the first provably safe and optimal algorithm that can safely discover globally optimal policies for systems with high-dimensional state space. We demonstrate the superiority of GoSafeOpt over competing model-free safe learning methods in simulation and hardware experiments on a robot arm.},
  archive      = {J_AIJ},
  author       = {Bhavya Sukhija and Matteo Turchetta and David Lindner and Andreas Krause and Sebastian Trimpe and Dominik Baumann},
  doi          = {10.1016/j.artint.2023.103922},
  journal      = {Artificial Intelligence},
  pages        = {103922},
  shortjournal = {Artif. Intell.},
  title        = {GoSafeOpt: Scalable safe exploration for global optimization of dynamical systems},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dealing with expert bias in collective decision-making.
<em>AIJ</em>, <em>320</em>, 103921. (<a
href="https://doi.org/10.1016/j.artint.2023.103921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quite some real-world problems can be formulated as decision-making problems wherein one must repeatedly make an appropriate choice from a set of alternatives. Multiple expert judgments, whether human or artificial, can help in taking correct decisions, especially when exploration of alternative solutions is costly. As expert opinions might deviate, the problem of finding the right alternative can be approached as a collective decision making problem (CDM) via aggregation of independent judgments. Current state-of-the-art approaches focus on efficiently finding the optimal expert, and thus perform poorly if all experts are not qualified or if they display consistent biases, thereby potentially derailing the decision-making process. In this paper, we propose a new algorithmic approach based on contextual multi-armed bandit problems (CMAB) to identify and counteract such biased expertise. We explore homogeneous, heterogeneous and polarized expert groups and show that this approach is able to effectively exploit the collective expertise, outperforming state-of-the-art methods, especially when the quality of the provided expertise degrades. Our novel CMAB-inspired approach achieves a higher final performance and does so while converging more rapidly than previous adaptive algorithms.},
  archive      = {J_AIJ},
  author       = {Axel Abels and Tom Lenaerts and Vito Trianni and Ann Nowé},
  doi          = {10.1016/j.artint.2023.103921},
  journal      = {Artificial Intelligence},
  pages        = {103921},
  shortjournal = {Artif. Intell.},
  title        = {Dealing with expert bias in collective decision-making},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe, learning-based MPC for highway driving under
lane-change uncertainty: A distributionally robust approach.
<em>AIJ</em>, <em>320</em>, 103920. (<a
href="https://doi.org/10.1016/j.artint.2023.103920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a case study applying learning-based distributionally robust model predictive control to highway motion planning under stochastic uncertainty of the lane change behavior of surrounding road users. The dynamics of road users are modeled using Markov jump systems, in which the switching variable describes the desired lane of the vehicle under consideration and the continuous state describes the pose and velocity of the vehicles. We assume the switching probabilities of the underlying Markov chain to be unknown. As the vehicle is observed and thus, samples from the Markov chain are drawn, the transition probabilities are estimated along with an ambiguity set which accounts for misestimations of these probabilities. Correspondingly, a distributionally robust optimal control problem is formulated over a scenario tree, and solved in receding horizon. As a result, a motion planning procedure is obtained which through observation of the target vehicle gradually becomes less conservative while avoiding overconfidence in estimates obtained from small sample sizes. We present an extensive numerical case study, comparing the effects of several different design aspects on the controller performance and safety.},
  archive      = {J_AIJ},
  author       = {Mathijs Schuurmans and Alexander Katriniok and Christopher Meissen and H. Eric Tseng and Panagiotis Patrinos},
  doi          = {10.1016/j.artint.2023.103920},
  journal      = {Artificial Intelligence},
  pages        = {103920},
  shortjournal = {Artif. Intell.},
  title        = {Safe, learning-based MPC for highway driving under lane-change uncertainty: A distributionally robust approach},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reasoning about causality in games. <em>AIJ</em>,
<em>320</em>, 103919. (<a
href="https://doi.org/10.1016/j.artint.2023.103919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal reasoning and game-theoretic reasoning are fundamental topics in artificial intelligence , among many other disciplines: this paper is concerned with their intersection. Despite their importance, a formal framework that supports both these forms of reasoning has, until now, been lacking. We offer a solution in the form of (structural) causal games , which can be seen as extending Pearl&#39;s causal hierarchy to the game-theoretic domain, or as extending Koller and Milch&#39;s multi-agent influence diagrams to the causal domain. We then consider three key questions:},
  archive      = {J_AIJ},
  author       = {Lewis Hammond and James Fox and Tom Everitt and Ryan Carey and Alessandro Abate and Michael Wooldridge},
  doi          = {10.1016/j.artint.2023.103919},
  journal      = {Artificial Intelligence},
  pages        = {103919},
  shortjournal = {Artif. Intell.},
  title        = {Reasoning about causality in games},
  volume       = {320},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The first AI4TSP competition: Learning to solve stochastic
routing problems. <em>AIJ</em>, <em>319</em>, 103918. (<a
href="https://doi.org/10.1016/j.artint.2023.103918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports on the first international competition on AI for the traveling salesman problem (TSP) at the International Joint Conference on Artificial Intelligence 2021 (IJCAI-21). The TSP is one of the classical combinatorial optimization problems , with many variants inspired by real-world applications. This first competition asked the participants to develop algorithms to solve an orienteering problem with stochastic weights and time windows (OPSWTW). It focused on two learning approaches: surrogate-based optimization and deep reinforcement learning . In this paper, we describe the problem, the competition setup, and the winning methods, and give an overview of the results. The winning methods described in this work have advanced the state-of-the-art in using AI for stochastic routing problems. Overall, by organizing this competition we have introduced routing problems as an interesting problem setting for AI researchers. The simulator of the problem has been made open-source and can be used by other researchers as a benchmark for new learning-based methods. The instances and code for the competition are available at https://github.com/paulorocosta/ai-for-tsp-competition .},
  archive      = {J_AIJ},
  author       = {Yingqian Zhang and Laurens Bliek and Paulo da Costa and Reza Refaei Afshar and Robbert Reijnen and Tom Catshoek and Daniël Vos and Sicco Verwer and Fynn Schmitt-Ulms and André Hottung and Tapan Shah and Meinolf Sellmann and Kevin Tierney and Carl Perreault-Lafleur and Caroline Leboeuf and Federico Bobbio and Justine Pepin and Warley Almeida Silva and Ricardo Gama and Hugo L. Fernandes and Martin Zaefferer and Manuel López-Ibáñez and Ekhine Irurozki},
  doi          = {10.1016/j.artint.2023.103918},
  journal      = {Artificial Intelligence},
  pages        = {103918},
  shortjournal = {Artif. Intell.},
  title        = {The first AI4TSP competition: Learning to solve stochastic routing problems},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Situated conditional reasoning. <em>AIJ</em>, <em>319</em>,
103917. (<a href="https://doi.org/10.1016/j.artint.2023.103917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditionals are useful for modelling many forms of everyday human reasoning but are not always sufficiently expressive to represent the information we want to reason about. In this paper, we make a case for a form of situated conditional. By ‘situated’, we mean that there is a context, based on an agent&#39;s beliefs and expectations, that works as background information in evaluating a conditional, and we allow such a context to vary. These conditionals are able to distinguish, for example, between expectations and counterfactuals . Formally, they are shown to generalise the conditional setting in the style of Kraus, Lehmann, and Magidor. We show that situated conditionals can be described in terms of a set of rationality postulates. We then propose an intuitive semantics for these conditionals and present a representation result which shows that our semantic construction corresponds exactly to the description in terms of postulates. With the semantics in place, we define a form of entailment for situated conditional knowledge bases, which we refer to as minimal closure . Finally, we proceed to show that it is possible to reduce the computation of minimal closure to a series of propositional entailment and satisfiability checks. While this is also the case for rational closure, it is somewhat surprising that the result carries over to minimal closure.},
  archive      = {J_AIJ},
  author       = {Giovanni Casini and Thomas Meyer and Ivan Varzinczak},
  doi          = {10.1016/j.artint.2023.103917},
  journal      = {Artificial Intelligence},
  pages        = {103917},
  shortjournal = {Artif. Intell.},
  title        = {Situated conditional reasoning},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy preserving solution of DCOPs by mediation.
<em>AIJ</em>, <em>319</em>, 103916. (<a
href="https://doi.org/10.1016/j.artint.2023.103916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a new paradigm for solving DCOPs, whereby the agents delegate the computational task to a set of external mediators who perform the computations for them in an oblivious manner. That is, the mediators perfectly simulate the operation of the chosen DCOP algorithm, but without getting access to the problem inputs or to its outputs. Specifically, we propose MD-Max-Sum , a mediated implementation of the Max-Sum algorithm. MD-Max-Sum offers topology, constraint, and decision privacy. Moreover, MD-Max-Sum is collusion-secure, as long as the set of mediators has an honest majority. We evaluate the performance of MD-Max-Sum on different benchmarks, problem sizes, and constraint densities. In particular, we compare its performance to PC-SyncBB , the only privacy-preserving DCOP algorithm to date that is collusion-secure, and show the significant advantages of MD-Max-Sum in terms of runtime. We conclude that MD-Max-Sum can be used in practice for solving DCOPs when strong privacy guarantees are required. The main takeaway from this study is a demonstration of the power of mediated computing. It allows either a single party or a set of parties, who may have limited computational or communication resources, to delegate an intricate computation to external dedicated servers who can perform the computation for them in an oblivious manner that protects the privacy of the initiating parties.},
  archive      = {J_AIJ},
  author       = {Pablo Kogan and Tamir Tassa and Tal Grinshpoun},
  doi          = {10.1016/j.artint.2023.103916},
  journal      = {Artificial Intelligence},
  pages        = {103916},
  shortjournal = {Artif. Intell.},
  title        = {Privacy preserving solution of DCOPs by mediation},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated streamliner portfolios for constraint satisfaction
problems. <em>AIJ</em>, <em>319</em>, 103915. (<a
href="https://doi.org/10.1016/j.artint.2023.103915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint Programming (CP) is a powerful technique for solving large-scale combinatorial problems . Solving a problem proceeds in two distinct phases: modelling and solving. Effective modelling has a huge impact on the performance of the solving process. Even with the advance of modern automated modelling tools, search spaces involved can be so vast that problems can still be difficult to solve. To further constrain the model, a more aggressive step that can be taken is the addition of streamliner constraints, which are not guaranteed to be sound but are designed to focus effort on a highly restricted but promising portion of the search space. Previously, producing effective streamlined models was a manual, difficult and time-consuming task. This paper presents a completely automated process to the generation, search and selection of streamliner portfolios to produce a substantial reduction in search effort across a diverse range of problems. The results demonstrate a marked improvement in performance for both Chuffed, a CP solver with clause learning, and lingeling, a modern SAT solver.},
  archive      = {J_AIJ},
  author       = {Patrick Spracklen and Nguyen Dang and Özgür Akgün and Ian Miguel},
  doi          = {10.1016/j.artint.2023.103915},
  journal      = {Artificial Intelligence},
  pages        = {103915},
  shortjournal = {Artif. Intell.},
  title        = {Automated streamliner portfolios for constraint satisfaction problems},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Levi and harper identities for non-prioritized belief base
change. <em>AIJ</em>, <em>319</em>, 103907. (<a
href="https://doi.org/10.1016/j.artint.2023.103907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the relation between shielded base contraction postulates and credibility-limited (CL) base revision postulates. More precisely, we identify (i) the relation between the postulates satisfied by a shielded base contraction operator and the postulates satisfied by the CL base revision operator that is defined from it by means of the consistency-preserving Levi identity and (ii) the relation between the postulates satisfied by a CL base revision operator and the postulates satisfied by the shielded base contraction operator that is defined from it by means of the Harper identity. Furthermore, we show that the consistency-preserving Levi identity and the Harper identity establish a one-to-one correspondence between the twenty classes of shielded base contractions presented in [21] and the twenty classes of credibility-limited base revisions presented in [22] .},
  archive      = {J_AIJ},
  author       = {Marco Garapa and Eduardo Fermé and Maurício D.L. Reis},
  doi          = {10.1016/j.artint.2023.103907},
  journal      = {Artificial Intelligence},
  pages        = {103907},
  shortjournal = {Artif. Intell.},
  title        = {Levi and harper identities for non-prioritized belief base change},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). (1+1) genetic programming with functionally complete
instruction sets can evolve boolean conjunctions and disjunctions with
arbitrarily small error. <em>AIJ</em>, <em>319</em>, 103906. (<a
href="https://doi.org/10.1016/j.artint.2023.103906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently it has been proven that simple GP systems can efficiently evolve a conjunction of n variables if they are equipped with the minimal required components. In this paper, we make a considerable step forward by analysing the behaviour and performance of a GP system for evolving a Boolean conjunction or disjunction of n variables using a complete function set that allows the expression of any Boolean function of up to n variables. First we rigorously prove that a GP system using the complete truth table to evaluate the program quality, and equipped with both the AND and OR operators and positive literals, evolves the exact target function in O ( ℓ n log 2 ⁡ n ) O(ℓnlog2⁡n) iterations in expectation, where ℓ ≥ n ℓ≥n is a limit on the size of any accepted tree. Additionally, we show that when a polynomial sample of possible inputs is used to evaluate the solution quality, conjunctions or disjunctions with any polynomially small generalisation error can be evolved with probability 1 − O ( log 2 ⁡ ( n ) / n ) 1−O(log2⁡(n)/n) . The latter result also holds if GP uses AND, OR and positive and negated literals, thus has the power to express any Boolean function of n distinct variables. To prove our results we introduce a super-multiplicative drift theorem that gives significantly stronger runtime bounds when the expected progress is only slightly super-linear in the distance from the optimum.},
  archive      = {J_AIJ},
  author       = {Benjamin Doerr and Andrei Lissovoi and Pietro S. Oliveto},
  doi          = {10.1016/j.artint.2023.103906},
  journal      = {Artificial Intelligence},
  pages        = {103906},
  shortjournal = {Artif. Intell.},
  title        = {(1+1) genetic programming with functionally complete instruction sets can evolve boolean conjunctions and disjunctions with arbitrarily small error},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe multi-agent reinforcement learning for multi-robot
control. <em>AIJ</em>, <em>319</em>, 103905. (<a
href="https://doi.org/10.1016/j.artint.2023.103905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A challenging problem in robotics is how to control multiple robots cooperatively and safely in real-world applications. Yet, developing multi-robot control methods from the perspective of safe multi-agent reinforcement learning (MARL) has merely been studied. To fill this gap, in this study, we investigate safe MARL for multi-robot control on cooperative tasks, in which each individual robot has to not only meet its own safety constraints while maximising their reward, but also consider those of others to guarantee safe team behaviours. Firstly, we formulate the safe MARL problem as a constrained Markov game and employ policy optimisation to solve it theoretically. The proposed algorithm guarantees monotonic improvement in reward and satisfaction of safety constraints at every iteration. Secondly, as approximations to the theoretical solution, we propose two safe multi-agent policy gradient methods : Multi-Agent Constrained Policy Optimisation (MACPO) and MAPPO-Lagrangian . Thirdly, we develop the first three safe MARL benchmarks—Safe Multi-Agent MuJoCo (Safe MAMuJoCo), Safe Multi-Agent Robosuite (Safe MARobosuite) and Safe Multi-Agent Isaac Gym (Safe MAIG) to expand the toolkit of MARL and robot control research communities. Finally, experimental results on the three safe MARL benchmarks indicate that our methods can achieve state-of-the-art performance in the balance between improving reward and satisfying safety constraints compared with strong baselines. Demos and code are available at the link ( https://sites.google.com/view/aij-safe-marl/ ). 2},
  archive      = {J_AIJ},
  author       = {Shangding Gu and Jakub Grudzien Kuba and Yuanpei Chen and Yali Du and Long Yang and Alois Knoll and Yaodong Yang},
  doi          = {10.1016/j.artint.2023.103905},
  journal      = {Artificial Intelligence},
  pages        = {103905},
  shortjournal = {Artif. Intell.},
  title        = {Safe multi-agent reinforcement learning for multi-robot control},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On existence of truthful fair cake cutting mechanisms.
<em>AIJ</em>, <em>319</em>, 103904. (<a
href="https://doi.org/10.1016/j.artint.2023.103904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fair division problem on divisible heterogeneous resources (the cake cutting problem) with strategic agents, where each agent can manipulate his/her private valuation to receive a better allocation. A (direct-revelation) mechanism takes agents&#39; reported valuations as input and outputs an allocation that satisfies a given fairness requirement. A natural and fundamental open problem, first raised by Chen, Lai, Parkes, and Procaccia [1] and subsequently raised in reference [2] , [3] , [4] , [5] , [6] , [7] , etc., is whether there exists a deterministic, truthful, and envy-free (or even proportional) cake cutting mechanism. In this paper, we resolve this open problem by proving that there does not exist a deterministic, truthful and proportional cake cutting mechanism, even in the special case where all of the following hold: We also present a truthful and envy-free mechanism when each agent&#39;s valuation is piecewise-constant and monotone. However, if we require Pareto-optimality, we show that truthful is incompatible with approximate proportionality for any positive approximation ratio even for piecewise-constant and monotone value density functions. To circumvent the main impossibility result, we aim to design mechanisms that possess a certain degree of truthfulness. Motivated by the kind of truthfulness possessed by the classical I-cut-you-choose protocol, we propose a weaker notion of truthfulness, the proportional risk-averse truthfulness . We show that the well-known moving-knife (Dubins-Spanier) procedure and Even-Paz algorithm do not have this truthful property. We propose a mechanism that is proportionally risk-averse truthful and envy-free, and a mechanism that is proportionally risk-averse truthful that always outputs allocations with connected pieces.},
  archive      = {J_AIJ},
  author       = {Xiaolin Bu and Jiaxin Song and Biaoshuai Tao},
  doi          = {10.1016/j.artint.2023.103904},
  journal      = {Artificial Intelligence},
  pages        = {103904},
  shortjournal = {Artif. Intell.},
  title        = {On existence of truthful fair cake cutting mechanisms},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epistemic uncertainty aware semantic localization and
mapping for inference and belief space planning. <em>AIJ</em>,
<em>319</em>, 103903. (<a
href="https://doi.org/10.1016/j.artint.2023.103903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the problem of autonomous object classification and semantic SLAM , which generally exhibits a tight coupling between classification, metric SLAM , and planning under uncertainty. We contribute a unified framework for inference and belief space planning (BSP) that addresses prominent sources of uncertainty in this context: classification aliasing (classifier cannot distinguish between candidate classes from certain viewpoints), classifier epistemic uncertainty (classifier receives data “far” from its training set), and localization uncertainty (camera and object poses are uncertain). Specifically, two methods are developed for maintaining a joint distribution over robot and object poses, and over a posterior class probability vector that considers epistemic uncertainty in a Bayesian fashion. The first approach is Multi-Hybrid (MH), where multiple hybrid beliefs over poses and classes are maintained to approximate the joint belief over poses and posterior class probability. The second approach is Joint Lambda Pose (JLP), where the joint belief is maintained directly using a novel JLP factor. Furthermore, we extend both methods to BSP, while reasoning about future posterior epistemic uncertainty indirectly or directly via a novel information-theoretic reward function. Both inference methods utilize a novel viewpoint-dependent classifier uncertainty model that leverages the coupling between poses and classification scores and predicts the epistemic uncertainty from certain viewpoints. In addition, this model is used to generate predicted measurements during planning. To the best of our knowledge, this is the first work that reasons about classifier epistemic uncertainty within semantic SLAM and BSP. We extensively evaluate our inference and BSP approaches in simulation using real image data from the Active Vision Dataset. Results clearly indicate superior classification performance of our methods compared to an approach that is not epistemic uncertainty aware.},
  archive      = {J_AIJ},
  author       = {Vladimir Tchuiev and Vadim Indelman},
  doi          = {10.1016/j.artint.2023.103903},
  journal      = {Artificial Intelligence},
  pages        = {103903},
  shortjournal = {Artif. Intell.},
  title        = {Epistemic uncertainty aware semantic localization and mapping for inference and belief space planning},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid planning for challenging construction problems: An
answer set programming approach. <em>AIJ</em>, <em>319</em>, 103902. (<a
href="https://doi.org/10.1016/j.artint.2023.103902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study construction problems where multiple robots rearrange stacks of prefabricated blocks to build stable structures. These problems are challenging due to ramifications of actions, true concurrency, and requirements of supportedness of blocks by a surface or a robot and stability of the overall structure at all times. We propose a general elaboration tolerant method to solve a wide range of construction problems, based on the knowledge representation and reasoning paradigm of Answer Set Programming . This method not only (i) determines a stable final configuration of the structure, but also (ii) computes the order of manipulation tasks for multiple autonomous robots to build the structure from an initial configuration , (iii) while simultaneously ensuring the requirements of supportedness and stability at all times. We prove the soundness and completeness of our method with respect to these properties. We introduce a set of challenging construction benchmark instances, including construction of (uneven) bridges and overhangs, and discuss the usefulness of our framework over these instances. Furthermore, we perform experiments to investigate the computational performance of our hybrid method , and demonstrate the applicability of our method using a bimanual Baxter robot.},
  archive      = {J_AIJ},
  author       = {Faseeh Ahmad and Volkan Patoglu and Esra Erdem},
  doi          = {10.1016/j.artint.2023.103902},
  journal      = {Artificial Intelligence},
  pages        = {103902},
  shortjournal = {Artif. Intell.},
  title        = {Hybrid planning for challenging construction problems: An answer set programming approach},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The quarks of attention: Structure and capacity of neural
attention building blocks. <em>AIJ</em>, <em>319</em>, 103901. (<a
href="https://doi.org/10.1016/j.artint.2023.103901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention plays a fundamental role in both natural and artificial intelligence systems. In deep learning, attention-based neural architectures, such as transformer architectures, are widely used to tackle problems in natural language processing and beyond. Here we investigate the most fundamental building blocks of attention and their computational properties within the standard model of deep learning. We first derive a systematic taxonomy of all possible attention mechanisms within, or as extensions of the standard model into 18 classes depending on the origin of the attention signal, the target of the attention signal, and whether the interaction is additive or multiplicative. Second, using this taxonomy, we identify three key attention mechanisms: additive activation attention (multiplexing), multiplicative output attention (output gating), and multiplicative synaptic attention (synaptic gating). Output gating and synaptic gating are proper extensions of the standard model and all current attention-based architectures, including transformers, use either output gating or synaptic gating, or a combination of both. Third, we develop a theory of attention capacity and derive mathematical results about the capacity of basic attention networks comprising linear or polynomial threshold gates. For example, the output gating of a linear threshold gate of n variables by another linear threshold gate of the same n variables has capacity 2 n 2 ( 1 + o ( 1 ) ) 2n2(1+o(1)) , achieving the maximal doubling of the capacity for a doubling of the number of parameters. Perhaps surprisingly, multiplexing attention is used in the proofs of these results. Synaptic and output gating provide computationally efficient extensions of the standard model enabling sparse quadratic activation functions. They can also be viewed as primitives for collapsing several layers of processing in the standard model into shallow compact representations.},
  archive      = {J_AIJ},
  author       = {Pierre Baldi and Roman Vershynin},
  doi          = {10.1016/j.artint.2023.103901},
  journal      = {Artificial Intelligence},
  pages        = {103901},
  shortjournal = {Artif. Intell.},
  title        = {The quarks of attention: Structure and capacity of neural attention building blocks},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning constraints through partial queries. <em>AIJ</em>,
<em>319</em>, 103896. (<a
href="https://doi.org/10.1016/j.artint.2023.103896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning constraint networks is known to require a number of membership queries exponential in the number of variables. In this paper, we learn constraint networks by asking the user partial queries. That is, we ask the user to classify assignments to subsets of the variables as positive or negative. We provide an algorithm, called QuAcq2 , that, given a negative example, elucidates a constraint of the target network in a number of queries logarithmic in the size of the example. The whole constraint network can then be learned with a polynomial number of partial queries. We give information theoretic lower bounds for learning some simple classes of constraint networks and show that our generic algorithm is optimal in some cases. We provide a version of QuAcq2 with a cutoff mechanism that controls the time to generate a query. Our experiments illustrate the good behavior of QuAcq2 in practice, especially in the case where QuAcq2 is executed to learn the missing constraints in a partially filled constraint model. Our experiments also show that QuAcq2 requires significantly fewer queries to learn a network than its predecessor QuAcq1 .},
  archive      = {J_AIJ},
  author       = {Christian Bessiere and Clément Carbonnel and Anton Dries and Emmanuel Hebrard and George Katsirelos and Nina Narodytska and Claude-Guy Quimper and Kostas Stergiou and Dimosthenis C. Tsouros and Toby Walsh},
  doi          = {10.1016/j.artint.2023.103896},
  journal      = {Artificial Intelligence},
  pages        = {103896},
  shortjournal = {Artif. Intell.},
  title        = {Learning constraints through partial queries},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Search-engine-augmented dialogue response generation with
cheaply supervised query production. <em>AIJ</em>, <em>319</em>, 103874.
(<a href="https://doi.org/10.1016/j.artint.2023.103874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-aided dialogue response generation aims at augmenting chatbots with relevant external knowledge in the hope of generating more informative responses. The majority of previous work assumes that the relevant knowledge is given as input or retrieved from a static pool of knowledge. However, this assumption violates the real-world situation, where knowledge is continually updated and a chatbot has to dynamically retrieve useful knowledge. We propose a dialogue model that can access the vast and dynamic information from any search engine for response generation. As the core module, a query producer is used to generate queries from a dialogue context to interact with a search engine. We design a training algorithm using cheap noisy supervision for the query producer, where the signals are obtained by comparing retrieved articles with the next dialogue response. As the result, the query producer is adjusted without any human annotation of gold queries, making it easily transferable to other domains and search engines. Experiments show that our query producer can achieve R@1 and R@5 rates of 62.4\% and 74.8\% for retrieving gold knowledge, and the overall model generates better responses over strong knowledge-aided baselines using BART [1] and other typical systems.},
  archive      = {J_AIJ},
  author       = {Ante Wang and Linfeng Song and Qi Liu and Haitao Mi and Longyue Wang and Zhaopeng Tu and Jinsong Su and Dong Yu},
  doi          = {10.1016/j.artint.2023.103874},
  journal      = {Artificial Intelligence},
  pages        = {103874},
  shortjournal = {Artif. Intell.},
  title        = {Search-engine-augmented dialogue response generation with cheaply supervised query production},
  volume       = {319},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Axiomatic characterization of PageRank. <em>AIJ</em>,
<em>318</em>, 103900. (<a
href="https://doi.org/10.1016/j.artint.2023.103900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the fundamental problem of identifying the most important nodes in a network. To date, more than a hundred centrality measures have been proposed, each evaluating the position of a node in a network from a different perspective. Our work focuses on PageRank which is one of the most important centrality measures in computer science used in a wide range of scientific applications. To build a theoretical foundation for choosing (or rejecting) PageRank in a specific setting, we propose to use an axiomatic approach. Specifically, we propose six simple properties and prove that PageRank is the only centrality measure that satisfies all of them. In this way, we provide the first axiomatic characterization of PageRank in its general form.},
  archive      = {J_AIJ},
  author       = {Tomasz Wąs and Oskar Skibski},
  doi          = {10.1016/j.artint.2023.103900},
  journal      = {Artificial Intelligence},
  pages        = {103900},
  shortjournal = {Artif. Intell.},
  title        = {Axiomatic characterization of PageRank},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoSTG+: An automatic framework to discover the optimal
network for spatio-temporal graph prediction. <em>AIJ</em>,
<em>318</em>, 103899. (<a
href="https://doi.org/10.1016/j.artint.2023.103899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal graphs (STGs) are important structures to describe urban sensory data, e.g. , traffic speed and air quality. Predicting over spatio-temporal graphs enables many essential applications in intelligent cities, such as traffic management and environment analysis. Recently, many deep learning models have been proposed for spatio-temporal graph prediction and achieved significant results. However, manually designing neural networks requires rich domain knowledge and heavy expert efforts, making it impractical for real-world deployments. Therefore, we study automated neural architecture search for spatio-temporal graphs, which meets three challenges: 1) how to define search space for capturing complex spatio-temporal correlations; 2) how to jointly model the explicit and implicit relationships between nodes of an STG; and 3) how to learn network weight parameters related to meta graphs of STGs. To tackle these challenges, we propose a novel neural architecture search framework, entitled AutoSTG + , for automated spatio-temporal graph prediction. In our AutoSTG + , spatial graph convolution and temporal convolution operations are adopted in the search space of AutoSTG + to capture complex spatio-temporal correlations. Besides, we propose to employ the meta-learning technique to learn the adjacency matrices of spatial graph convolution layers and kernels of temporal convolution layers from the meta knowledge of meta graphs. And specifically, such meta-knowledge is learned by graph meta-knowledge learners, which iteratively aggregate knowledge on the attributed graphs and the similarity graphs . Finally, extensive experiments have been conducted on multiple real-world datasets to demonstrate that AutoSTG + can find effective network architectures and achieve up to about 20\% relative improvements compared to human-designed networks.},
  archive      = {J_AIJ},
  author       = {Songyu Ke and Zheyi Pan and Tianfu He and Yuxuan Liang and Junbo Zhang and Yu Zheng},
  doi          = {10.1016/j.artint.2023.103899},
  journal      = {Artificial Intelligence},
  pages        = {103899},
  shortjournal = {Artif. Intell.},
  title        = {AutoSTG+: An automatic framework to discover the optimal network for spatio-temporal graph prediction},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On approximating shortest paths in weighted triangular
tessellations. <em>AIJ</em>, <em>318</em>, 103898. (<a
href="https://doi.org/10.1016/j.artint.2023.103898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the quality of weighted shortest paths when a continuous 2-dimensional space is discretized by a weighted triangular tessellation. In order to evaluate how well the tessellation approximates the 2-dimensional space, we study three types of shortest paths: a weighted shortest path S P w ( s , t ) SPw(s, t) , which is a shortest path from s to t in the space; a weighted shortest vertex path SV P w ( s , t ) SVPw(s, t) , which is an any-angle shortest path; and a weighted shortest grid path SG P w ( s , t ) SGPw(s, t) , which is a shortest path whose edges are edges of the tessellation. Given any arbitrary weight assignment to the faces of a triangular tessellation, thus extending recent results by Bailey et al. (2021) [6] , we prove upper and lower bounds on the ratios ‖ SG P w ( s , t ) ‖ ‖ S P w ( s , t ) ‖ ‖SGPw(s, t)‖‖SPw(s, t)‖ , ‖ SV P w ( s , t ) ‖ ‖ S P w ( s , t ) ‖ ‖SVPw(s, t)‖‖SPw(s, t)‖ , ‖ SG P w ( s , t ) ‖ ‖ SV P w ( s , t ) ‖ ‖SGPw(s, t)‖‖SVPw(s, t)‖ , which provide estimates on the quality of the approximation . It turns out, surprisingly, that our worst-case bounds are independent of any weight assignment. Our main result is that ‖ SG P w ( s , t ) ‖ ‖ S P w ( s , t ) ‖ = 2 3 ≈ 1.15 ‖SGPw(s, t)‖‖SPw(s, t)‖=23≈1.15 in the worst case, and this is tight. As a corollary, for the weighted any-angle path SV P w ( s , t ) SVPw(s, t) we obtain the approximation result ‖ SV P w ( s , t ) ‖ ‖ S P w ( s , t ) ‖ ⪅ 1.15 ‖SVPw(s, t)‖‖SPw(s, t)‖⪅1.15 .},
  archive      = {J_AIJ},
  author       = {Prosenjit Bose and Guillermo Esteban and David Orden and Rodrigo I. Silveira},
  doi          = {10.1016/j.artint.2023.103898},
  journal      = {Artificial Intelligence},
  pages        = {103898},
  shortjournal = {Artif. Intell.},
  title        = {On approximating shortest paths in weighted triangular tessellations},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal logic explanations for dynamic decision systems
using anchors and monte carlo tree search. <em>AIJ</em>, <em>318</em>,
103897. (<a href="https://doi.org/10.1016/j.artint.2023.103897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many automated perception and decision tasks, state-of-the-art performance may be obtained by algorithms that are too complex for their behavior to be completely understandable or predictable by human users, e.g., because they employ large machine learning models. To integrate these algorithms into safety-critical decision and control systems, it is particularly important to develop methods that can promote trust into their decisions and help explore their failure modes. In this article, we combine the anchors methodology with Monte Carlo Tree Search to provide local model-agnostic explanations for the behaviors of a given black-box model making decisions by processing time-varying input signals. Our approach searches for descriptive explanations for these decisions in the form of properties of the input signals, expressed in Signal Temporal Logic, which are highly likely to reproduce the observed behavior. To illustrate the methodology, we apply it in simulations to the analysis of a hybrid (continuous-discrete) control system and a collision avoidance system for unmanned aircraft (ACAS Xu) implemented by a neural network .},
  archive      = {J_AIJ},
  author       = {Tzu-Yi Chiu and Jerome Le Ny and Jean-Pierre David},
  doi          = {10.1016/j.artint.2023.103897},
  journal      = {Artificial Intelligence},
  pages        = {103897},
  shortjournal = {Artif. Intell.},
  title        = {Temporal logic explanations for dynamic decision systems using anchors and monte carlo tree search},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better bounds on the adaptivity gap of influence
maximization under full-adoption feedback. <em>AIJ</em>, <em>318</em>,
103895. (<a href="https://doi.org/10.1016/j.artint.2023.103895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the influence maximization (IM) problem, we are given a social network and a budget k , and we look for a set of k nodes in the network, called seeds, that maximize the expected number of nodes that are reached by an influence cascade generated by the seeds, according to some stochastic model for influence diffusion. Extensive studies have been done on the IM problem, since this definition by Kempe et al. [26] . However, most of the work focuses on the non-adaptive version of the problem where all the k seed nodes must be selected before the cascade starts. In this paper we study the adaptive IM, where the nodes are selected sequentially one by one, and the decision on the i -th seed can be based on the observed cascade produced by the first i − 1 i−1 seeds. We focus on the full-adoption feedback in which we can observe the entire cascade of each previously selected seed under the independent cascade model where each edge is associated with an independent probability of diffusing influence. Previous works showed that there are constant upper bounds on the adaptivity gap, which compares the performance of an adaptive algorithm against a non-adaptive one, but the analyses used to prove these bounds only work for specific graph classes such as in-arborescences, out-arborescences, and one-directional bipartite graphs . Our main result is the first sub-linear upper bound that holds for any graph. Specifically, we show that the adaptivity gap is upper-bounded by n 3 + 1 n3+1 , where n is the number of nodes in the graph. Moreover, we improve over the known upper bound for in-arborescences from 2 e / ( e − 1 ) ≈ 3.16 2e/(e−1)≈3.16 to 2 e 2 / ( e 2 − 1 ) ≈ 2.31 2e2/(e2−1)≈2.31 . Then, we consider ( β , γ ) (β, γ) -bounded-activation graphs, where all nodes but β influence in expectation at most γ ∈ [ 0 , 1 ) γ∈[0, 1) neighbors each; for this class of influence graphs we show that the adaptivity gap is at most β + 1 1 − γ β+11−γ . Finally, we study α -bounded-degree graphs, that is the class of undirected graphs in which the sum of node degrees higher than two is at most α , and show that the adaptivity gap is upper-bounded by α + O ( 1 ) α+O(1) ; we also show that in 0-bounded-degree graphs, i.e. undirected graphs in which each connected component is a path or a cycle, the adaptivity gap is at most 3 e 3 / ( e 3 − 1 ) ≈ 3.16 3e3/(e3−1)≈3.16 . To prove our bounds, we introduce new techniques to relate adaptive policies with non-adaptive ones that might be of their own interest.},
  archive      = {J_AIJ},
  author       = {Gianlorenzo D&#39;Angelo and Debashmita Poddar and Cosimo Vinci},
  doi          = {10.1016/j.artint.2023.103895},
  journal      = {Artificial Intelligence},
  pages        = {103895},
  shortjournal = {Artif. Intell.},
  title        = {Better bounds on the adaptivity gap of influence maximization under full-adoption feedback},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expanding the prediction capacity in long sequence
time-series forecasting. <em>AIJ</em>, <em>318</em>, 103886. (<a
href="https://doi.org/10.1016/j.artint.2023.103886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications show growing demand for the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) requires a higher prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to accommodate the capacity requirements. However, three real challenges that may have prevented expanding the prediction capacity in LSTF are that the Transformer is limited by quadratic time complexity , high memory usage, and slow inference speed under the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics. (i) a ProbSparse self-attention mechanism, which achieves O ( L log ⁡ L ) O(Llog⁡L) in time complexity and memory usage, and has comparable performance on sequences&#39; dependency alignment. (ii) the self-attention distilling promotes dominating attention by convolutional operators. Besides, the halving of layer width is intended to reduce the expense of building a deeper network on extremely long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on ten large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem.},
  archive      = {J_AIJ},
  author       = {Haoyi Zhou and Jianxin Li and Shanghang Zhang and Shuai Zhang and Mengyi Yan and Hui Xiong},
  doi          = {10.1016/j.artint.2023.103886},
  journal      = {Artificial Intelligence},
  pages        = {103886},
  shortjournal = {Artif. Intell.},
  title        = {Expanding the prediction capacity in long sequence time-series forecasting},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Taking into account “who said what” in abstract
argumentation: Complexity results. <em>AIJ</em>, <em>318</em>, 103885.
(<a href="https://doi.org/10.1016/j.artint.2023.103885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new paradigm for reasoning over abstract argumentation frameworks where the “ who said what ” relation, associating each argument with the set of agents who claimed it, is taken into account, along with possible information on the trustworthiness of the agents. Specifically, we extend the traditional reasoning based on the classical verification and acceptance problems and introduce a reasoning paradigm investigating how the “robustness” of a set of arguments S (in terms of being an extension or not) or of an argument a (in terms of being accepted or not) can change if what has been claimed by some agents is ignored (as if these agents were removed from the dispute modeled by the argumentation framework). In this regard, we address the problems of searching the “minimum extent” of the removal of agents that makes a set S an extension or an argument a accepted. Compared with the case where only the “ yes/no ” answer of the traditional verification and acceptance problems are available, the knowledge of such a minimum provides the analyst with further insights allowing them to better judge the robustness of S and a . We consider the above minimization problems in two variants, where the agents are associated with a measure of their trustworthiness or not and provide a thorough characterization of their complexities.},
  archive      = {J_AIJ},
  author       = {Bettina Fazzinga and Sergio Flesca and Filippo Furfaro},
  doi          = {10.1016/j.artint.2023.103885},
  journal      = {Artificial Intelligence},
  pages        = {103885},
  shortjournal = {Artif. Intell.},
  title        = {Taking into account “who said what” in abstract argumentation: Complexity results},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On measuring inconsistency in definite and indefinite
databases with denial constraints. <em>AIJ</em>, <em>318</em>, 103884.
(<a href="https://doi.org/10.1016/j.artint.2023.103884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world databases are often inconsistent. Although there has been an extensive body of work on handling inconsistency, little work has been done on measuring inconsistency in databases. In this paper, building on work done on measuring inconsistency in propositional knowledge bases, we explore inconsistency measures (IMs) for definite and indefinite databases with denial constraints. We first introduce database IMs that are inspired by well-established methods to quantify inconsistency in propositional knowledge bases, but are tailored to the relational database context where data is generally the reason for inconsistency, not the integrity constraints. Then, we analyze the compliance of the database IMs with rationality postulates for both definite and indefinite databases. Finally, we investigate the complexity of the inconsistency measurement problem as well as of the problems of deciding whether the inconsistency is lower than, greater than, or equal to a given threshold for both the definite and the indefinite cases.},
  archive      = {J_AIJ},
  author       = {Francesco Parisi and John Grant},
  doi          = {10.1016/j.artint.2023.103884},
  journal      = {Artificial Intelligence},
  pages        = {103884},
  shortjournal = {Artif. Intell.},
  title        = {On measuring inconsistency in definite and indefinite databases with denial constraints},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Width-based search for multi agent privacy-preserving
planning. <em>AIJ</em>, <em>318</em>, 103883. (<a
href="https://doi.org/10.1016/j.artint.2023.103883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent planning, preserving the agents&#39; privacy has become an increasingly popular research topic. For preserving the agents&#39; privacy, agents jointly compute a plan that achieves mutual goals by keeping certain information private to the individual agents. Unfortunately, this can severely restrict the accuracy of the heuristic functions used while searching for solutions. It has been recently shown that, for centralized planning, blind search algorithms such as width-based search can solve instances of many existing domains in low polynomial time when they feature atomic goals. Moreover, the performance of goal-oriented search can be improved by combining it with width-based search. In this paper, we investigate the usage of width-based search in the context of (decentralised) collaborative multi-agent privacy-preserving planning, addressing the challenges related to the agents&#39; privacy and performance. In particular, we show that width-based search is a very effective approach over several benchmark domains, even when the search is driven by heuristics that roughly estimate the distance from goal states, computed without using the private information of other involved agents. Moreover, we show that the use of width-based techniques can significantly reduce the number of messages transmitted among the agents, better preserving their privacy and improving their performance. An experimental study presented in the paper analyses the effectiveness of our techniques, and compares them with the state-of-the-art of collaborative multi-agent planning.},
  archive      = {J_AIJ},
  author       = {Alfonso E. Gerevini and Nir Lipovetzky and Francesco Percassi and Alessandro Saetti and Ivan Serina},
  doi          = {10.1016/j.artint.2023.103883},
  journal      = {Artificial Intelligence},
  pages        = {103883},
  shortjournal = {Artif. Intell.},
  title        = {Width-based search for multi agent privacy-preserving planning},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Post-trained convolution networks for single image
super-resolution. <em>AIJ</em>, <em>318</em>, 103882. (<a
href="https://doi.org/10.1016/j.artint.2023.103882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new method is proposed to increase the accuracy of the state-of-the-art single image super-resolution (SISR) using novel training procedure. The proposed method, named post-trained convolutional neural network (CNN), is carried out stochastic dual simplex algorithm (SDSA) in the last reconstruction layer. The method utilizes contextual information to update the last reconstruction layer of CNN. The extracted contextual information is projected to the last reconstructed layer by optimized weights and the bias is managed through SDSA. Post-trained CNN is applied to the very deep super-resolution (VDSR) method to show its performance. The quantitative and visual results demonstrate that the proposed post-trained VDSR (PTVDSR) exhibits excellent and competitive performance when compared with the VDSR and other super-resolution methods.},
  archive      = {J_AIJ},
  author       = {Seid Miad Zandavi},
  doi          = {10.1016/j.artint.2023.103882},
  journal      = {Artificial Intelligence},
  pages        = {103882},
  shortjournal = {Artif. Intell.},
  title        = {Post-trained convolution networks for single image super-resolution},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing menus of contracts efficiently: The power of
randomization. <em>AIJ</em>, <em>318</em>, 103881. (<a
href="https://doi.org/10.1016/j.artint.2023.103881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study hidden-action principal-agent problems in which a principal commits to an outcome-dependent payment scheme (called contract ) so as to incentivize the agent to take a costly, unobservable action leading to favorable outcomes. In particular, we focus on Bayesian settings where the agent has private information . This is collectively encoded by the agent&#39;s type , which is unknown to the principal but randomly drawn according to a finitely-supported, commonly-known probability distribution. In our model, the agent&#39;s type determines both the probability distribution over outcomes and the cost associated with each agent&#39;s action. In Bayesian principal-agent problems, the principal may be better off by committing to a menu of contracts specifying a contract for each agent&#39;s type, rather than committing to a single contract. This induces a two-stage process that resembles interactions studied in classical mechanism design : after the principal has committed to a menu, the agent first reports a type to the principal, and, then, the latter puts in place the contract in the menu that corresponds to the reported type. Thus, the principal&#39;s computational problem boils down to designing a menu of contracts that incentivizes the agent to report their true type and maximizes expected utility. Previous works showed that, in Bayesian principal-agent problems, computing an optimal menu of contracts or an optimal (single) contract is APX APX -hard, which is in sharp contrast from what happens in non-Bayesian settings, where an optimal contract can be computed efficiently. Crucially, previous works focus on menus of deterministic contracts. Surprisingly, in this paper, we show that, if one instead considers menus of randomized contracts defined as probability distributions over payment vectors, then an “almost-optimal” menu can be computed in polynomial time . Indeed, the problem of computing a principal-optimal menu of randomized contracts may not admit a maximum, but only a supremum . Nevertheless, we show how to design a polynomial-time algorithm that guarantees the principal with an expected utility arbitrarily close to the supremum. Besides this main result, we also close several gaps in the computational complexity analysis of the problem of computing menus of deterministic contracts. In particular, we prove that the problem cannot be approximated up to within any multiplicative factor and it does not admit an additive FPTAS unless P P = NP NP , even in basic instances with a constant number of actions and only four outcomes. This considerably extends previously-known negative results. Then, we show that our hardness result is tight, by providing an additive PTAS that works in instances with a constant number of outcomes. We complete our analysis by showing that an optimal menu of deterministic contracts can be computed in polynomial time when either there are only two outcomes or there is a constant number of types.},
  archive      = {J_AIJ},
  author       = {Matteo Castiglioni and Alberto Marchesi and Nicola Gatti},
  doi          = {10.1016/j.artint.2023.103881},
  journal      = {Artificial Intelligence},
  pages        = {103881},
  shortjournal = {Artif. Intell.},
  title        = {Designing menus of contracts efficiently: The power of randomization},
  volume       = {318},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving infinite-domain CSPs using the patchwork property.
<em>AIJ</em>, <em>317</em>, 103880. (<a
href="https://doi.org/10.1016/j.artint.2023.103880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constraint satisfaction problem (CSP) has important applications in computer science and AI . In particular, infinite-domain CSPs have been intensively used in subareas of AI such as spatio-temporal reasoning. Since constraint satisfaction is a computationally hard problem, much work has been devoted to identifying restricted problems that are efficiently solvable. One way of doing this is to restrict the interactions of variables and constraints, and a highly successful approach is to bound the treewidth of the underlying primal graph. Bodirsky &amp; Dalmau (2013) [14] and Huang et al. (2013) [47] proved that CSP(Γ) can be solved in n f ( w ) nf(w) time (where n is the size of the instance, w is the treewidth of the primal graph and f is a computable function) for certain classes of constraint languages Γ. We improve this bound to f ( w ) ⋅ n O ( 1 ) f(w)⋅nO(1) , where the function f only depends on the language Γ, for CSPs whose basic relations have the patchwork property. Hence, such problems are fixed-parameter tractable and our algorithm is asymptotically faster than the previous ones. Additionally, our approach is not restricted to binary constraints , so it is applicable to a strictly larger class of problems than that of Huang et al. However, there exist natural problems that are covered by Bodirsky &amp; Dalmau&#39;s algorithm but not by ours, and we begin investigating ways of generalising our results to larger families of languages. We also analyse our algorithm with respect to its running time and show that it is optimal (under the Exponential Time Hypothesis) for certain languages such as Allen&#39;s Interval Algebra .},
  archive      = {J_AIJ},
  author       = {Konrad K. Dabrowski and Peter Jonsson and Sebastian Ordyniak and George Osipov},
  doi          = {10.1016/j.artint.2023.103880},
  journal      = {Artificial Intelligence},
  pages        = {103880},
  shortjournal = {Artif. Intell.},
  title        = {Solving infinite-domain CSPs using the patchwork property},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online learning of energy consumption for navigation of
electric vehicles. <em>AIJ</em>, <em>317</em>, 103879. (<a
href="https://doi.org/10.1016/j.artint.2023.103879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficient navigation constitutes an important challenge in electric vehicles, due to their limited battery capacity. We employ a Bayesian approach to model the energy consumption at road segments for efficient navigation. In order to learn the model parameters, we develop an online learning framework and investigate several exploration strategies such as Thompson Sampling and Upper Confidence Bound. We then extend our online learning framework to the multi-agent setting, where multiple vehicles adaptively navigate and learn the parameters of the energy model. We analyze Thompson Sampling and establish rigorous regret bounds on its performance in the single-agent and multi-agent settings, through an analysis of the algorithm under batched feedback. Finally, we demonstrate the performance of our methods via experiments on several real-world city road networks.},
  archive      = {J_AIJ},
  author       = {Niklas Åkerblom and Yuxin Chen and Morteza Haghir Chehreghani},
  doi          = {10.1016/j.artint.2023.103879},
  journal      = {Artificial Intelligence},
  pages        = {103879},
  shortjournal = {Artif. Intell.},
  title        = {Online learning of energy consumption for navigation of electric vehicles},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Corrigendum to “accurate parameter estimation for
safety-critical systems with unmodeled dynamics” [artif. Intell. 316
(2023) 103857]. <em>AIJ</em>, <em>317</em>, 103878. (<a
href="https://doi.org/10.1016/j.artint.2023.103878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIJ},
  author       = {Arnab Sarker and Peter Fisher and Joseph E. Gaudio and Anuradha M. Annaswamy},
  doi          = {10.1016/j.artint.2023.103878},
  journal      = {Artificial Intelligence},
  pages        = {103878},
  shortjournal = {Artif. Intell.},
  title        = {Corrigendum to “Accurate parameter estimation for safety-critical systems with unmodeled dynamics” [Artif. intell. 316 (2023) 103857]},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating robust overfitting via self-residual-calibration
regularization. <em>AIJ</em>, <em>317</em>, 103877. (<a
href="https://doi.org/10.1016/j.artint.2023.103877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overfitting in adversarial training has attracted the interest of researchers in the community of artificial intelligence and machine learning in recent years. To address this issue, in this paper we begin by evaluating the defense performances of several calibration methods on various robust models. Our analysis and experiments reveal two intriguing properties: 1) a well-calibrated robust model is decreasing the confidence of robust model; 2) there is a trade-off between the confidences of natural and adversarial images . These new properties offer a straightforward insight into designing a simple but effective regularization , called Self-Residual-Calibration (SRC). The proposed SRC calculates the absolute residual between adversarial and natural logit features corresponding to the ground-truth labels. Furthermore, we utilize the pinball loss to minimize the quantile residual between them, resulting in more robust regularization . Extensive experiments indicate that our SRC can effectively mitigate the overfitting problem while improving the robustness of state-of-the-art models. Importantly, SRC is complementary to various regularization methods . When combined with them, we are capable of achieving the top-rank performance on the AutoAttack benchmark leaderboard.},
  archive      = {J_AIJ},
  author       = {Hong Liu and Zhun Zhong and Nicu Sebe and Shin&#39;ichi Satoh},
  doi          = {10.1016/j.artint.2023.103877},
  journal      = {Artificial Intelligence},
  pages        = {103877},
  shortjournal = {Artif. Intell.},
  title        = {Mitigating robust overfitting via self-residual-calibration regularization},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revision, defeasible conditionals and non-monotonic
inference for abstract dialectical frameworks. <em>AIJ</em>,
<em>317</em>, 103876. (<a
href="https://doi.org/10.1016/j.artint.2023.103876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For propositional beliefs, there are well-established connections between belief revision, defeasible conditionals, and nonmonotonic inference. In argumentative contexts, such connections have not yet been investigated. On the one hand, the exact relationship between formal argumentation and nonmonotonic inference relations is a research topic that keeps on eluding researchers despite recently intensified efforts, whereas argumentative revision has been studied in numerous works during recent years. In this paper, we show that relationships between belief revision, defeasible conditionals, and nonmonotonic inference similar to those in propositional logic hold in argumentative contexts as well. We first define revision operators for abstract dialectical frameworks, and use such revision operators to define dynamic conditionals by means of the Ramsey test. We show that such conditionals can be equivalently defined using a total preorder over three-valued interpretations, and study the inferential behaviour of the resulting conditional inference relations.},
  archive      = {J_AIJ},
  author       = {Jesse Heyninck and Gabriele Kern-Isberner and Tjitze Rienstra and Kenneth Skiba and Matthias Thimm},
  doi          = {10.1016/j.artint.2023.103876},
  journal      = {Artificial Intelligence},
  pages        = {103876},
  shortjournal = {Artif. Intell.},
  title        = {Revision, defeasible conditionals and non-monotonic inference for abstract dialectical frameworks},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards well-generalizing meta-learning via adversarial task
augmentation. <em>AIJ</em>, <em>317</em>, 103875. (<a
href="https://doi.org/10.1016/j.artint.2023.103875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning aims to use the knowledge from previous tasks to facilitate the learning of novel tasks. Many meta-learning models elaborately design various task-shared inductive bias, and learn it from a large number of tasks, so the generalization capability of the learned inductive bias depends on the diversity of the training tasks. A common assumption in meta-learning is that the training tasks and the test tasks come from the same or similar task distributions. However, this is usually not strictly satisfied in practice, so meta-learning models need to cope with various novel in-domain or cross-domain tasks. To this end, we propose to use task augmentation to increase the diversity of training tasks, thereby improving the generalization capability of meta-learning models. Concretely, we consider the worst-case problem around the base task distribution, and derive the adversarial task augmentation method which can generate inductive bias-adaptive ‘challenging’ tasks. Our method can be used as a simple plug-and-play module for various meta-learning models, and improve their generalization capability. We conduct extensive experiments under in-domain and cross-domain few-shot learning and unsupervised few-shot learning settings, and evaluate our method on different types of data (images and text). Experimental results show that our method can effectively improve the generalization capability of various meta-learning models under different settings.},
  archive      = {J_AIJ},
  author       = {Haoqing Wang and Huiyu Mai and Yuhang Gong and Zhi-Hong Deng},
  doi          = {10.1016/j.artint.2023.103875},
  journal      = {Artificial Intelligence},
  pages        = {103875},
  shortjournal = {Artif. Intell.},
  title        = {Towards well-generalizing meta-learning via adversarial task augmentation},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The complexity landscape of claim-augmented argumentation
frameworks. <em>AIJ</em>, <em>317</em>, 103873. (<a
href="https://doi.org/10.1016/j.artint.2023.103873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Claim-augmented argumentation frameworks (CAFs) provide a formal basis to analyze conclusion-oriented problems in argumentation by adapting a claim-focused perspective; they extend Dung AFs by associating a claim to each argument representing its conclusion. This additional layer offers various possibilities to generalize abstract argumentation semantics, i.e. the re-interpretation of arguments in terms of their claims can be performed at different stages in the evaluation of the framework: One approach is to perform the evaluation entirely at argument-level before interpreting arguments by their claims (inherited semantics); alternatively, one can perform certain steps in the process (e.g., maximization) already in terms of the arguments&#39; claims (claim-level semantics). The inherent difference of these approaches not only potentially results in different outcomes but, as we will show in this paper, is also mirrored in terms of computational complexity . To this end, we provide a comprehensive complexity analysis of the four main reasoning problems with respect to claim-level variants of preferred, naive, stable, semi-stable and stage semantics and complete the complexity results of inherited semantics by providing corresponding results for semi-stable and stage semantics. Furthermore, we provide complexity results for these types of frameworks when restricted to specific graph classes and when parameterized by the number of claims within the framework. Moreover, we show that deciding, whether for a given framework the two approaches of a semantics coincide (concurrence) can be surprisingly hard, ranging up to the third level of the polynomial hierarchy.},
  archive      = {J_AIJ},
  author       = {Wolfgang Dvořák and Alexander Greßler and Anna Rapberger and Stefan Woltran},
  doi          = {10.1016/j.artint.2023.103873},
  journal      = {Artificial Intelligence},
  pages        = {103873},
  shortjournal = {Artif. Intell.},
  title        = {The complexity landscape of claim-augmented argumentation frameworks},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-aware analysis for interpretations of probabilistic
achievement and maintenance commitments. <em>AIJ</em>, <em>317</em>,
103864. (<a href="https://doi.org/10.1016/j.artint.2023.103864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic commitments provide a computational framework for multi-agent coordination, where one autonomous agent (the commitment provider), commits to a future course of action that probabilistically influences the local state of another agent (the commitment recipient) in ways that the recipient desires. Conventionally, a probabilistic commitment is specified abstractly so as to give the provider latitude at run time about how to achieve it. Unfortunately, as we analyze in this article, this abstraction incurs a risk of suboptimal performance for the recipient. For (achievement) commitments by the provider to achieve conditions that the recipient prefers but that do not initially hold, we prove that the recipient can make modeling choices that bound its risk of suboptimality. Somewhat surprisingly, however, for (maintenance) commitments by the provider to maintain conditions whose initial values are already ones the recipient prefers, we prove that no such bounds on suboptimality risk are possible. We study the two types of commitments empirically to measure the suboptimality they incur under different conditions, and based on our theoretical and empirical results suggest that adding selective details when specifying probabilistic maintenance commitments can be beneficial.},
  archive      = {J_AIJ},
  author       = {Qi Zhang and Edmund H. Durfee and Satinder Singh},
  doi          = {10.1016/j.artint.2023.103864},
  journal      = {Artificial Intelligence},
  pages        = {103864},
  shortjournal = {Artif. Intell.},
  title        = {Risk-aware analysis for interpretations of probabilistic achievement and maintenance commitments},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DivGAN: A diversity enforcing generative adversarial network
for mode collapse reduction. <em>AIJ</em>, <em>317</em>, 103863. (<a
href="https://doi.org/10.1016/j.artint.2023.103863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are one of the most efficient generative models to generate data. They have made breakthroughs in many computer vision tasks . However, the generic GAN suffers from a mode collapse problem. To alleviate this problem, the present work proposes a new GAN framework called diversified GAN (DivGAN). DivGAN can be incorporated into any existing GAN. It includes a new network called DivNet that aims at enforcing the GANs to produce diverse data. One advantage of the proposed network is that it does not alter the architectures of the GANs and hence can be easily incorporated into them. Extensive experiments on synthetic and real datasets show that the proposed framework significantly contributes to mode collapse reduction and performs better than recent state-of-the-art GANs.},
  archive      = {J_AIJ},
  author       = {Manal Allahyani and Rahaf Alsulami and Taif Alwafi and Tarik Alafif and Heyfa Ammar and Sari Sabban and Xuewen Chen},
  doi          = {10.1016/j.artint.2023.103863},
  journal      = {Artificial Intelligence},
  pages        = {103863},
  shortjournal = {Artif. Intell.},
  title        = {DivGAN: A diversity enforcing generative adversarial network for mode collapse reduction},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast certifiable relative pose estimation with gravity
prior. <em>AIJ</em>, <em>317</em>, 103862. (<a
href="https://doi.org/10.1016/j.artint.2023.103862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Redundant and complementary information from different types of sensors boosts the robustness of autonomous systems , making them more reliable and safer. In particular, inertial measurement units (IMUs) are increasingly being integrated with cameras for that purpose, since the information provided by the IMU helps to simplify some visual problems and improves the accuracy of the results. In the context of estimating the motion of a camera, which is the problem we address in this work, the gravity vector delivers by the IMU reduces the unknown rotation to only one degree of freedom instead of three, hence simplifying the relative pose problem (RPp). Despite this simplification, the RPp is still nonconvex, therefore the quality (optimality) of the solution returned by iterative solvers cannot be guaranteed. These suboptimal solutions may have serious consequences for applications that have this solver as a key block, and may even cause their complete failure. In this paper, we contribute a certifiable solver for the RPp with gravity prior. We propose an iterative certifier that does not assume any condition on the problem, and returns an optimality certification even for an overconstrained formulation with 28 constraints in less than 1.5 milliseconds. Since the certifier doesn&#39;t obtain the solution to the problem, we also provide a fast, iterative on-manifold estimation of the relative pose, which is shown to return solutions with lower costs than other nonminimal solvers in less time. We make the code available at https://www.github.com/mergarsal .},
  archive      = {J_AIJ},
  author       = {Mercedes Garcia-Salguero and Javier Gonzalez-Jimenez},
  doi          = {10.1016/j.artint.2023.103862},
  journal      = {Artificial Intelligence},
  pages        = {103862},
  shortjournal = {Artif. Intell.},
  title        = {Fast certifiable relative pose estimation with gravity prior},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable AI tools for legal reasoning about cases: A
study on the european court of human rights. <em>AIJ</em>, <em>317</em>,
103861. (<a href="https://doi.org/10.1016/j.artint.2023.103861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we report on a significant research project undertaken to design, implement and evaluate explainable decision-support tools for deciding legal cases. We provide a model of a legal domain, Article 6 of the European Convention on Human Rights , constructed using a methodology from the field of computational models of argument. We describe how the formal model has been developed, extended and transformed into practical tools, which were then used in evaluation exercises to determine the effectiveness and usability of the tools. The underpinning AI techniques used yield a level of explanation that is firmly grounded in legal reasoning and is also digestible by the target end users, as demonstrated through our evaluation activities. The results of our experimental evaluation show that on the first pass, our tool achieved an accuracy rate of 97\% in matching the actual decisions of the cases and the user studies conducted gave highly encouraging results with respect to usability. As such, our project demonstrates how trustworthy AI tools can be built for a real world legal domain where critical needs of the end users are accounted for.},
  archive      = {J_AIJ},
  author       = {Joe Collenette and Katie Atkinson and Trevor Bench-Capon},
  doi          = {10.1016/j.artint.2023.103861},
  journal      = {Artificial Intelligence},
  pages        = {103861},
  shortjournal = {Artif. Intell.},
  title        = {Explainable AI tools for legal reasoning about cases: A study on the european court of human rights},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-tuning transformers: Vocabulary transfer. <em>AIJ</em>,
<em>317</em>, 103860. (<a
href="https://doi.org/10.1016/j.artint.2023.103860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers are responsible for the vast majority of recent advances in natural language processing . The majority of practical natural language processing applications of these models are typically enabled through transfer learning . This paper studies if corpus-specific tokenization used for fine-tuning improves the resulting performance of the model. Through a series of experiments, we demonstrate that such tokenization combined with the initialization and fine-tuning strategy for the vocabulary tokens speeds up the transfer and boosts the performance of the fine-tuned model. We call this aspect of transfer facilitation vocabulary transfer .},
  archive      = {J_AIJ},
  author       = {Vladislav Mosin and Igor Samenko and Borislav Kozlovskii and Alexey Tikhonov and Ivan P. Yamshchikov},
  doi          = {10.1016/j.artint.2023.103860},
  journal      = {Artificial Intelligence},
  pages        = {103860},
  shortjournal = {Artif. Intell.},
  title        = {Fine-tuning transformers: Vocabulary transfer},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Natural language watermarking via paraphraser-based lexical
substitution. <em>AIJ</em>, <em>317</em>, 103859. (<a
href="https://doi.org/10.1016/j.artint.2023.103859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although powerful pretrained language models generate high-quality output text, they bring new concerns about the potential misuse of such models for malicious purposes. Natural language watermarking (NLW) is a technique that is desgined to help tracing the provenance of texts for againsting possible attacks, where the watermark signals are embedded into cover texts using synonym substitutions. The up-to-date BERT-based NLW methods have made remarkable progress on performance improvement of watermarking through generating substitutes for a masked target word. Yet, the BERT-based NLWs focus on the context of texts rather than the meaning of target words, which might make the capacity of watermark embeddings being lower. To address the limitations, this study proposes a novel NLW method by incorporating a paraphraser-based lexical substitution method. Under the promise of paraphrase preservation, the proposed NLW method utilizes the knowledge of paraphrase modeling to generate the substitute candidates to replace the words in original sentences capable of carrying the watermark signal in local contexts. We empirically show that our NLW method not only has a better meaning-preserved, but improves the payload more than 2 times compared with the BERT-based NLW method. Besides, compared with previous state-of-the-art method Compared with other state-of-the-art baselines, the experimental results show that the proposed LS method improves the Precision@1 score from 51.7\% to 58.3\% and from 50.5\% to 62.6\% on LS07 and CoInCo benchmarks, respectively.},
  archive      = {J_AIJ},
  author       = {Jipeng Qiang and Shiyu Zhu and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu},
  doi          = {10.1016/j.artint.2023.103859},
  journal      = {Artificial Intelligence},
  pages        = {103859},
  shortjournal = {Artif. Intell.},
  title        = {Natural language watermarking via paraphraser-based lexical substitution},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chaos game representation for authorship attribution.
<em>AIJ</em>, <em>317</em>, 103858. (<a
href="https://doi.org/10.1016/j.artint.2023.103858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The authorship attribution task assumes the presence of several examples of documents written by various authors and it must be determined who wrote a given anonymous text. For each author, a specific writing style is hypothesized, with characteristics that the authors themselves are not aware of. The writing style acts as a fingerprint, as various features have been demonstrated to remain consistent for one author over the years. The Chaos Game Representation, a method for creating images from nucleotide sequences, is modified to make images from chunks of text documents. A text is transformed into a representation similar to a fingerprint that is used to check for similarities between the patterns existing in such marks from texts of distinct authors. Results indicate that this representation encodes sufficient particularities from an author writing style to make the methodology competitive for this field, with applications of both historic and current importance.},
  archive      = {J_AIJ},
  author       = {Daniel Lichtblau and Catalin Stoean},
  doi          = {10.1016/j.artint.2023.103858},
  journal      = {Artificial Intelligence},
  pages        = {103858},
  shortjournal = {Artif. Intell.},
  title        = {Chaos game representation for authorship attribution},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task-guided IRL in POMDPs that scales. <em>AIJ</em>,
<em>317</em>, 103856. (<a
href="https://doi.org/10.1016/j.artint.2023.103856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In inverse reinforcement learning (IRL), a learning agent infers a reward function encoding the underlying task using demonstrations from experts. However, many existing IRL techniques make the often unrealistic assumption that the agent has access to full information about the environment. We remove this assumption by developing an algorithm for IRL in partially observable Markov decision processes (POMDPs). We address two limitations of existing IRL techniques . First, they require an excessive amount of data due to the information asymmetry between the expert and the learner. Second, most of these IRL techniques require solving the computationally intractable forward problem —computing an optimal policy given a reward function—in POMDPs. The developed algorithm reduces the information asymmetry while increasing the data efficiency by incorporating task specifications expressed in temporal logic into IRL. Such specifications may be interpreted as side information available to the learner a priori in addition to the demonstrations. Further, the algorithm avoids a common source of algorithmic complexity by building on causal entropy as the measure of the likelihood of the demonstrations as opposed to entropy. Nevertheless, the resulting problem is nonconvex due to the so-called forward problem . We solve the intrinsic nonconvexity of the forward problem in a scalable manner through a sequential linear programming scheme that guarantees to converge to a locally optimal policy . In a series of examples, including experiments in a high-fidelity Unity simulator, we demonstrate that even with a limited amount of data and POMDPs with tens of thousands of states, our algorithm learns reward functions and policies that satisfy the task while inducing similar behavior to the expert by leveraging the provided side information.},
  archive      = {J_AIJ},
  author       = {Franck Djeumou and Christian Ellis and Murat Cubuktepe and Craig Lennon and Ufuk Topcu},
  doi          = {10.1016/j.artint.2023.103856},
  journal      = {Artificial Intelligence},
  pages        = {103856},
  shortjournal = {Artif. Intell.},
  title        = {Task-guided IRL in POMDPs that scales},
  volume       = {317},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Accurate parameter estimation for safety-critical systems
with unmodeled dynamics. <em>AIJ</em>, <em>316</em>, 103857. (<a
href="https://doi.org/10.1016/j.artint.2023.103857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis and synthesis of safety-critical autonomous systems are carried out using models which are often dynamic. Two central features of these dynamic systems are parameters and unmodeled dynamics. Much of feedback control design is parametric in nature and as such, accurate and fast estimation of the parameters in the modeled part of the dynamic system is a crucial property for designing risk-aware autonomous systems . This paper addresses the use of a spectral lines-based approach for estimating parameters of the dynamic model of an autonomous system. Existing literature has treated all unmodeled components of the dynamic system as sub-Gaussian noise and proposed parameter estimation using Gaussian noise-based exogenous signals. In contrast, we allow the unmodeled part to have deterministic unmodeled dynamics, which are almost always present in physical systems, in addition to sub-Gaussian noise. In addition, we propose a deterministic construction of the exogenous signal in order to carry out parameter estimation. We introduce a new tool kit which employs the theory of spectral lines , retains the stochastic setting, and leads to non-asymptotic bounds on the parameter estimation error. Unlike the existing stochastic approach , these bounds are tunable through an optimal choice of the spectrum of the exogenous signal leading to accurate parameter estimation. We also show that this estimation is robust to unmodeled dynamics, a property that is not assured by the existing approach. Finally, we show that under ideal conditions with no deterministic unmodeled dynamics, the proposed approach can ensure a O ˜ ( T ) O˜(T) Regret, matching existing literature. Experiments are provided to support all theoretical derivations, which show that the spectral lines-based approach outperforms the Gaussian noise-based method when unmodeled dynamics are present, in terms of both parameter estimation error and Regret obtained using the parameter estimates with a Linear Quadratic Regulator in feedback.},
  archive      = {J_AIJ},
  author       = {Arnab Sarker and Peter Fisher and Joseph E. Gaudio and Anuradha M. Annaswamy},
  doi          = {10.1016/j.artint.2023.103857},
  journal      = {Artificial Intelligence},
  pages        = {103857},
  shortjournal = {Artif. Intell.},
  title        = {Accurate parameter estimation for safety-critical systems with unmodeled dynamics},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strategyproof mechanism for two-sided matching with resource
allocation. <em>AIJ</em>, <em>316</em>, 103855. (<a
href="https://doi.org/10.1016/j.artint.2023.103855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a student-project-resource matching-allocation problem, where students have preferences over projects and the projects have preferences over students. In this problem, students and indivisible resources are many-to-one matched to projects whose capacities are endogenously determined by the resources allocated to them. Traditionally, this problem is decomposed into two separate problems: (1) resources are allocated to projects based on expectations (a resource allocation problem), and (2) students are matched to projects based on the capacities determined in the previous problem (a matching problem). Although both problems are well-understood, if the expectations used in the first are incorrect, we obtain a sub-optimal outcome. Thus, this problem should be solved as a whole without dividing it into two parts. We show that no strategyproof mechanism satisfies fairness and weak efficiency requirements. Given this impossibility result, we develop a new class of strategyproof mechanisms called Sample and Deferred Acceptance (SDA), which satisfies several properties on fairness and efficiency. We experimentally compare several SDA instances as well as existing mechanisms, and show that an SDA instance strikes a good balance of fairness and efficiency when students are divided into different types according to their preferences.},
  archive      = {J_AIJ},
  author       = {Kwei-guu Liu and Kentaro Yahiro and Makoto Yokoo},
  doi          = {10.1016/j.artint.2023.103855},
  journal      = {Artificial Intelligence},
  pages        = {103855},
  shortjournal = {Artif. Intell.},
  title        = {Strategyproof mechanism for two-sided matching with resource allocation},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GUBS criterion: Arbitrary trade-offs between cost and
probability-to-goal in stochastic planning based on expected utility
theory. <em>AIJ</em>, <em>316</em>, 103848. (<a
href="https://doi.org/10.1016/j.artint.2022.103848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Shortest Path MDPs (SSP-MDPs) are used to model probabilistic sequential decision problems where the objective is to minimize the expected accumulated cost to goal. However, in the presence of dead-ends, the conventional criterion for SSP-MDPs, which minimizes the expected accumulated cost, can become ill-defined. Lexicographic criteria can solve this by preferring policies that reach the goal with the highest possible probability. Other criteria can instead make a trade-off between some cost measure and probability-to-goal. However, both of these approaches can lead to policies that might not represent the choice of a real decision-maker. In this work, we propose the GUBS criterion to address these problems. GUBS combines goal prioritization over histories with Expected Utility Theory and is the only criterion between all criteria analyzed that not only allows for a trade-off between a large accumulated cost and a small loss in probability-to-goal, but also guarantees arbitrary trade-offs that can be tuned from its parameters without previous knowledge of the problem being solved. We also propose eGUBS, which is a particular case of GUBS when the exponential utility function is used, and two algorithms for optimally solving these problems: eGUBS-VI, a VI-based algorithm; and eGUBS-AO*, a heuristic search algorithm . Results indicate that, when there is a good heuristic function available or when the state space is too large, eGUBS-AO* can perform better than eGUBS-VI by doing an efficient search. In other cases, eGUBS-VI&#39;s simpler approach might have better results.},
  archive      = {J_AIJ},
  author       = {Gabriel Nunes Crispino and Valdinei Freire and Karina Valdivia Delgado},
  doi          = {10.1016/j.artint.2022.103848},
  journal      = {Artificial Intelligence},
  pages        = {103848},
  shortjournal = {Artif. Intell.},
  title        = {GUBS criterion: Arbitrary trade-offs between cost and probability-to-goal in stochastic planning based on expected utility theory},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An abstraction-refinement framework for verifying strategic
properties in multi-agent systems with imperfect information.
<em>AIJ</em>, <em>316</em>, 103847. (<a
href="https://doi.org/10.1016/j.artint.2022.103847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the verification of Multi-Agent Systems against strategic properties expressed in Alternating-time Temporal Logic under the assumptions of imperfect information and perfect recall. To this end, we develop a three-valued semantics for concurrent game structures upon which we define an abstraction method. We prove that concurrent game structures with imperfect information admit perfect information abstractions that preserve three-valued satisfaction. Furthermore, to deal with cases in which the value of a specification is undefined, we develop a novel automata-theoretic technique for the linear-time logic ( LTL ), then apply it to finding “failure” states. The latter can then be fed into a refinement procedure, thus providing a sound, albeit incomplete, verification method. We illustrate the overall procedure in a variant of the Train Gate Controller scenario and a simple voting protocol under imperfect information and perfect recall. We also present an implementation of our procedure and provide preliminary experimental results.},
  archive      = {J_AIJ},
  author       = {Francesco Belardinelli and Angelo Ferrando and Vadim Malvone},
  doi          = {10.1016/j.artint.2022.103847},
  journal      = {Artificial Intelligence},
  pages        = {103847},
  shortjournal = {Artif. Intell.},
  title        = {An abstraction-refinement framework for verifying strategic properties in multi-agent systems with imperfect information},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An anytime algorithm for constrained stochastic shortest
path problems with deterministic policies. <em>AIJ</em>, <em>316</em>,
103846. (<a href="https://doi.org/10.1016/j.artint.2022.103846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential decision-making problems arise in every arena of daily life and pose unique challenges for research in decision-theoretic planning. Although there has been a wide variety of research in this field, most of the studies have largely focused on single objective problem without constraints. In many real-world applications, however, it is often desirable to bound certain costs or resources under some predefined level. Constrained stochastic shortest path problem (C-SSP), one of the most well-known mathematical frameworks for stochastic decision-making problems with constraints, can formally model such problems, by incorporating constraints in the model formulation. However, it remains an open challenge to produce a deterministic optimal policy with desirable computation time due to its intrinsic complexity. In this paper, we propose a method that produces an optimal and deterministic policy for a C-SSP based on the Lagrangian duality theory and the heuristic forward search method. To address the intrinsic complexity of C-SSP, the proposed method is designed to have an anytime property. In other words, the proposed algorithm tries to find a feasible but decent solution quickly, then improves the solution incrementally until it converges to a true optimal solution. An extensive experimental evaluation on three problem domains shows that the proposed method outperforms the state-of-the-art methods in terms of the near-optimal solution with an optimality gap of less than 0.1\%.},
  archive      = {J_AIJ},
  author       = {Sungkweon Hong and Brian C. Williams},
  doi          = {10.1016/j.artint.2022.103846},
  journal      = {Artificial Intelligence},
  pages        = {103846},
  shortjournal = {Artif. Intell.},
  title        = {An anytime algorithm for constrained stochastic shortest path problems with deterministic policies},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-averse optimization of reward-based coherent risk
measures. <em>AIJ</em>, <em>316</em>, 103845. (<a
href="https://doi.org/10.1016/j.artint.2022.103845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world problems such as robotics, finance and healthcare, randomness is always present, thus, it is important to take risk into consideration in order to limit the chance of rare but dangerous events. The literature on risk-averse reinforcement learning has produced many different approaches to tackle the problem, but they either struggle to scale up to complex instances, or they exhibit irrational behaviors. Here we present two novel risk-averse objectives that are both coherent and easy to optimize: the reward-based mean-mean absolute deviation (Mean-RMAD) and the reward-based conditional value at risk (RCVaR). Instead of reducing the return risk, these measures minimize the per-step reward one. We prove that these risk measures bound the corresponding return-based risk measures, so that they can be also used as proxies for their return-based versions. We develop safe algorithms for these risk measures with guaranteed monotonic improvement, and their practical trust-region versions. Furthermore, we propose a decomposition for the RCVaR optimization problem into a sequence of risk-neutral problems. Finally, we conduct an empirical analysis on the introduced approaches, demonstrating their effectiveness in retrieving a variety of risk-averse behaviors on both toy problems and more challenging ones, such as a simulated trading environment and robotic locomotion tasks.},
  archive      = {J_AIJ},
  author       = {Massimiliano Bonetti and Lorenzo Bisi and Marcello Restelli},
  doi          = {10.1016/j.artint.2022.103845},
  journal      = {Artificial Intelligence},
  pages        = {103845},
  shortjournal = {Artif. Intell.},
  title        = {Risk-averse optimization of reward-based coherent risk measures},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Competence-aware systems. <em>AIJ</em>, <em>316</em>,
103844. (<a href="https://doi.org/10.1016/j.artint.2022.103844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building autonomous systems for deployment in the open world has been a longstanding objective in both artificial intelligence and robotics. The open world, however, presents challenges that question some of the assumptions often made in contemporary AI models. Autonomous systems that operate in the open world face complex, non-stationary environments wherein enumerating all situations the system may face over the course of its deployment is intractable. Nevertheless, these systems are expected to operate safely and reliably for extended durations. Consequently, AI systems often rely on some degree of human assistance to mitigate risks while completing their tasks, and are hence better treated as semi-autonomous systems . In order to reduce unnecessary reliance on humans and optimize autonomy, we propose a novel introspective planning model— competence-aware systems (CAS)—that enables a semi-autonomous system to reason about its own competence and allowed level of autonomy by leveraging human feedback or assistance. A CAS learns to adjust its level of autonomy based on experience and interactions with a human authority so as to reduce improper reliance on the human and optimize the degree of autonomy it employs in any given circumstance. To handle situations in which the initial CAS model has insufficient state information to properly discriminate feedback received from humans, we introduce a methodology called iterative state space refinement that gradually increases the granularity of the state space online. The approach exploits information that exists in the standard CAS model and requires no additional input from the human. The result is an agent that can more confidently predict the correct feedback from the human authority in each level of autonomy, enabling it learn its competence in a larger portion of the state space.},
  archive      = {J_AIJ},
  author       = {Connor Basich and Justin Svegliato and Kyle H. Wray and Stefan Witwicki and Joydeep Biswas and Shlomo Zilberstein},
  doi          = {10.1016/j.artint.2022.103844},
  journal      = {Artificial Intelligence},
  pages        = {103844},
  shortjournal = {Artif. Intell.},
  title        = {Competence-aware systems},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PeerNomination: A novel peer selection algorithm to handle
strategic and noisy assessments. <em>AIJ</em>, <em>316</em>, 103843. (<a
href="https://doi.org/10.1016/j.artint.2022.103843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In peer selection a group of agents must choose a subset of themselves, as winners for, e.g., peer-reviewed grants or prizes. We take a Condorcet view of this aggregation problem, assuming that there is an objective ground-truth ordering over the agents. We study agents that have a noisy perception of this ground truth and give assessments that, even when truthful, can be inaccurate. Our goal is to select the best set of agents according to the underlying ground truth by looking at the potentially unreliable assessments of the peers. Besides being potentially unreliable, we also allow agents to be self-interested, attempting to influence the outcome of the decision in their favour. Hence, we are focused on tackling the problem of impartial (or strategyproof) peer selection – how do we prevent agents from manipulating their reviews while still selecting the most deserving individuals, all in the presence of noisy evaluations? We propose a novel impartial peer selection algorithm , PeerNomination , that aims to fulfil the above desiderata. We provide a comprehensive theoretical analysis of the recall of PeerNomination and prove various properties, including impartiality and monotonicity. We also provide empirical results based on computer simulations to show its effectiveness compared to the state-of-the-art impartial peer selection algorithms. We then investigate the robustness of PeerNomination to various levels of noise in the reviews. In order to maintain good performance under such conditions, we extend PeerNomination by using weights for reviewers which, informally, capture some notion of reliability of the reviewer. We show, theoretically, that the new algorithm preserves strategyproofness and, empirically, that the weights help identify the noisy reviewers and hence to increase selection performance. 1},
  archive      = {J_AIJ},
  author       = {Omer Lev and Nicholas Mattei and Paolo Turrini and Stanislav Zhydkov},
  doi          = {10.1016/j.artint.2022.103843},
  journal      = {Artificial Intelligence},
  pages        = {103843},
  shortjournal = {Artif. Intell.},
  title        = {PeerNomination: A novel peer selection algorithm to handle strategic and noisy assessments},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epistemic planning: Perspectives on the special issue.
<em>AIJ</em>, <em>316</em>, 103842. (<a
href="https://doi.org/10.1016/j.artint.2022.103842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epistemic planning is the enrichment of automated planning with epistemic notions such as knowledge and belief. In general, single-agent epistemic planning considers the following problem: given an agent&#39;s current state of knowledge, and a desirable state of knowledge, how does it get from one to the other? In multi-agent epistemic planning, the current and desirable states of knowledge might also refer to the states of knowledge of other agents, including higher-order knowledge like ensuring that agent A doesn&#39;t get to know that agent B knows P. Single-agent epistemic planning is of central importance in settings where agents need to be able to reason about their own lack of knowledge and, e.g., make plans of how to achieve the required knowledge. Multi-agent epistemic planning is essential for coordination and collaboration among multiple agents, where success can only be expected if agents are able to reason about the knowledge, uncertainty and capabilities of other agents. It is a relatively recent area of research involving several sub-areas of artificial intelligence, such as automated planning, decision-theoretic planning, epistemic logic, strategic reasoning and knowledge representation &amp; reasoning. In order to achieve formalisms and systems for epistemic planning that are both expressive and practically efficient, it is necessary to combine state of the art from several such sub-areas of artificial intelligence that have so far been considered mostly in separation. Application areas of epistemic planning include mobile service robots, explaining planning, game playing, human-robot interaction and social robotics. For this special issue of AIJ, we invited papers on theory, applications, and implemented systems of epistemic planning. In this document, we summarize the accepted papers whilst recapping the essentials of epistemic planning.},
  archive      = {J_AIJ},
  author       = {Vaishak Belle and Thomas Bolander and Andreas Herzig and Bernhard Nebel},
  doi          = {10.1016/j.artint.2022.103842},
  journal      = {Artificial Intelligence},
  pages        = {103842},
  shortjournal = {Artif. Intell.},
  title        = {Epistemic planning: Perspectives on the special issue},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tractability of explaining classifier decisions.
<em>AIJ</em>, <em>316</em>, 103841. (<a
href="https://doi.org/10.1016/j.artint.2022.103841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explaining decisions is at the heart of explainable AI . We investigate the computational complexity of providing a formally-correct and minimal explanation of a decision taken by a classifier. In the case of threshold (i.e. score-based) classifiers, we show that a complexity dichotomy follows from the complexity dichotomy for languages of cost functions. In particular, submodular classifiers allow tractable explanation of positive decisions, but not negative decisions (assuming P≠NP). This is an example of the possible asymmetry between the complexity of explaining positive and negative decisions of a particular classifier. Nevertheless, there are large families of classifiers for which explaining both positive and negative decisions is tractable, such as monotone or modular (e.g. linear) classifiers. We extend the characterisation of tractable cases to constrained classifiers (when there are constraints on the possible input vectors) and to the search for contrastive rather than abductive explanations . Indeed, we show that tractable classes coincide for abductive and contrastive explanations in the constrained or unconstrained settings. We show the intractability of returning a set of k diverse explanations even for linear classifiers and k = 2 k=2 . Finding a minimum-cardinality explanation is tractable for the family of modular classifiers, i.e. when the score function is the sum of unary functions, but becomes intractable when any non-modular function is also allowed.},
  archive      = {J_AIJ},
  author       = {Martin C. Cooper and João Marques-Silva},
  doi          = {10.1016/j.artint.2022.103841},
  journal      = {Artificial Intelligence},
  pages        = {103841},
  shortjournal = {Artif. Intell.},
  title        = {Tractability of explaining classifier decisions},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the robustness of sparse counterfactual explanations to
adverse perturbations. <em>AIJ</em>, <em>316</em>, 103840. (<a
href="https://doi.org/10.1016/j.artint.2022.103840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual explanations (CEs) are a powerful means for understanding how decisions made by algorithms can be changed. Researchers have proposed a number of desiderata that CEs should meet to be practically useful, such as requiring minimal effort to enact, or complying with causal models. In this paper, we consider the interplay between the desiderata of robustness (i.e., that enacting CEs remains feasible and cost-effective even if adverse events take place) and sparsity (i.e., that CEs require only a subset of the features to be changed). In particular, we study the effect of addressing robustness separately for the features that are recommended to be changed and those that are not. We provide definitions of robustness for sparse CEs that are workable in that they can be incorporated as penalty terms in the loss functions that are used for discovering CEs. To carry out our experiments, we create and release code where five data sets (commonly used in the field of fair and explainable machine learning) have been enriched with feature-specific annotations that can be used to sample meaningful perturbations. Our experiments show that CEs are often not robust and, if adverse perturbations take place (even if not worst-case), the intervention they prescribe may require a much larger cost than anticipated, or even become impossible. However, accounting for robustness in the search process, which can be done rather easily, allows discovering robust CEs systematically. Robust CEs make additional intervention to contrast perturbations much less costly than non-robust CEs. We also find that robustness is easier to achieve for the features to change, posing an important point of consideration for the choice of what counterfactual explanation is best for the user. Our code is available at: https://github.com/marcovirgolin/robust-counterfactuals .},
  archive      = {J_AIJ},
  author       = {Marco Virgolin and Saverio Fracaros},
  doi          = {10.1016/j.artint.2022.103840},
  journal      = {Artificial Intelligence},
  pages        = {103840},
  shortjournal = {Artif. Intell.},
  title        = {On the robustness of sparse counterfactual explanations to adverse perturbations},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing the communication gap between AI models and
healthcare professionals: Explainability, utility and trust in AI-driven
clinical decision-making. <em>AIJ</em>, <em>316</em>, 103839. (<a
href="https://doi.org/10.1016/j.artint.2022.103839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper contributes with a pragmatic evaluation framework for explainable Machine Learning (ML) models for clinical decision support . The study revealed a more nuanced role for ML explanation models, when these are pragmatically embedded in the clinical context. Despite the general positive attitude of healthcare professionals (HCPs) towards explanations as a safety and trust mechanism, for a significant set of participants there were negative effects associated with confirmation bias, accentuating model over-reliance and increased effort to interact with the model. Also, contradicting one of its main intended functions, standard explanatory models showed limited ability to support a critical understanding of the limitations of the model. However, we found new significant positive effects which repositions the role of explanations within a clinical context: these include reduction of automation bias, addressing ambiguous clinical cases (cases where HCPs were not certain about their decision) and support of less experienced HCPs in the acquisition of new domain knowledge.},
  archive      = {J_AIJ},
  author       = {Oskar Wysocki and Jessica Katharine Davies and Markel Vigo and Anne Caroline Armstrong and Dónal Landers and Rebecca Lee and André Freitas},
  doi          = {10.1016/j.artint.2022.103839},
  journal      = {Artificial Intelligence},
  pages        = {103839},
  shortjournal = {Artif. Intell.},
  title        = {Assessing the communication gap between AI models and healthcare professionals: Explainability, utility and trust in AI-driven clinical decision-making},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving zero-sum one-sided partially observable stochastic
games. <em>AIJ</em>, <em>316</em>, 103838. (<a
href="https://doi.org/10.1016/j.artint.2022.103838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world situations are dynamic, with long-term interactions between multiple agents with uncertainty and limited observations. The agents must reason about which actions to take while also predicting and learning about what actions the other agents will take and how their choices will interact. In the most general setting, there is no limitation on the length of the sequence of actions the agent can perform — that is, there is no fixed horizon that can be used as an endpoint for analysis. These settings can be modeled as partially observable stochastic games (POSGs). Many adversarial domains (e.g., security settings) can be modeled as strictly competitive (or zero-sum) variants of these games. While these models are capable of modeling a wide variety of realistic problems, solving general POSGs is computationally intractable, so we focus on a broad subclass of POSGs called one-sided POSGs . In these games, only one agent has imperfect information while their opponent has full knowledge of the current situation. We provide a complete approach for solving zero-sum, one-sided POSGs: we (1) give a theoretical analysis of one-sided POSGs and their value functions, (2) show that a variant of a value-iteration algorithm converges in this setting, (3) adapt the heuristic search value-iteration algorithm for solving one-sided POSGs, (4) describe how to use approximate value functions to derive strategies in the game, and (5) experimentally demonstrate that our algorithm can solve one-sided POSGs of non-trivial sizes and analyze the scalability of our algorithm in three different domains: pursuit-evasion, patrolling, and search games.},
  archive      = {J_AIJ},
  author       = {Karel Horák and Branislav Bošanský and Vojtěch Kovařík and Christopher Kiekintveld},
  doi          = {10.1016/j.artint.2022.103838},
  journal      = {Artificial Intelligence},
  pages        = {103838},
  shortjournal = {Artif. Intell.},
  title        = {Solving zero-sum one-sided partially observable stochastic games},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reward (mis)design for autonomous driving. <em>AIJ</em>,
<em>316</em>, 103829. (<a
href="https://doi.org/10.1016/j.artint.2022.103829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the problem of diagnosing certain common errors in reward design. Its insights are also applicable to the design of cost functions and performance metrics more generally. To diagnose common errors, we develop 8 simple sanity checks for identifying flaws in reward functions. We survey research that is published in top-tier venues and focuses on reinforcement learning (RL) for autonomous driving (AD). Specifically, we closely examine the reported reward function in each publication and present these reward functions in a complete and standardized format in the appendix. Wherever we have sufficient information, we apply the 8 sanity checks to each surveyed reward function, revealing near-universal flaws in reward design for AD that might also exist pervasively across reward design for other tasks. Lastly, we explore promising directions that may aid the design of reward functions for AD in subsequent research, following a process of inquiry that can be adapted to other domains.},
  archive      = {J_AIJ},
  author       = {W. Bradley Knox and Alessandro Allievi and Holger Banzhaf and Felix Schmitt and Peter Stone},
  doi          = {10.1016/j.artint.2022.103829},
  journal      = {Artificial Intelligence},
  pages        = {103829},
  shortjournal = {Artif. Intell.},
  title        = {Reward (Mis)design for autonomous driving},
  volume       = {316},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recursive reasoning-based training-time adversarial machine
learning. <em>AIJ</em>, <em>315</em>, 103837. (<a
href="https://doi.org/10.1016/j.artint.2022.103837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training process of a machine learning (ML) model may be subject to adversarial attacks from an attacker who attempts to undermine the test performance of the ML model by perturbing the training minibatches, and thus needs to be protected by a defender. Such a problem setting is referred to as training-time adversarial ML. We formulate it as a two-player game and propose a principled Recursive Reasoning-based Training-Time adversarial ML (R2T2) framework to model this game. R2T2 models the reasoning process between the attacker and the defender and captures their bounded reasoning capabilities (due to bounded computational resources) through the recursive reasoning formalism. In particular, we associate a deeper level of recursive reasoning with the use of a higher-order gradient to derive the attack (defense) strategy, which naturally improves its performance while requiring greater computational resources. Interestingly, our R2T2 framework encompasses a variety of existing adversarial ML methods which correspond to attackers (defenders) with different recursive reasoning capabilities. We show how an R2T2 attacker (defender) can utilize our proposed nested projected gradient descent-based method to approximate the optimal attack (defense) strategy at an arbitrary level of reasoning. R2T2 can empirically achieve state-of-the-art attack and defense performances on benchmark image datasets.},
  archive      = {J_AIJ},
  author       = {Yizhou Chen and Zhongxiang Dai and Haibin Yu and Bryan Kian Hsiang Low and Teck-Hua Ho},
  doi          = {10.1016/j.artint.2022.103837},
  journal      = {Artificial Intelligence},
  pages        = {103837},
  shortjournal = {Artif. Intell.},
  title        = {Recursive reasoning-based training-time adversarial machine learning},
  volume       = {315},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general approach to extension-based semantics in abstract
argumentation. <em>AIJ</em>, <em>315</em>, 103836. (<a
href="https://doi.org/10.1016/j.artint.2022.103836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After a few decades of development, computational argumentation has become one of the active areas in AI . This paper proposes a general approach to deal with semantic related problems of abstract argumentation frameworks (AAFs, for short) and further develops the graded semantics presented by Grossi and Modgil. We pay attention not only to issues of various extension-based semantics at the object level but also the metatheoretical level. First, an alternative fundamental lemma is given, which generalizes the corresponding result due to Grossi and Modgil by relaxing the constraint on parameters. This lemma provides a new sufficient condition for preserving conflict-freeness and brings a Galois adjunction between admissible sets and complete extensions, which is of vital importance in constructing some special extensions in terms of iterations of the defense function. Applying such a lemma, some flaws in Grossi and Modgil&#39;s work are corrected, and the structural property, universal definability of various extension-based semantics and relationships among semantics are considered. Second, the operator ⋂ D ⋂D so-called reduced meet modulo an ultrafilter is presented, which is a simple but powerful tool in exploring infinite AAFs. The neutrality function and the defense function, which play central roles in Dung&#39;s abstract argumentation theory , are shown to be distributive over reduced meets modulo any ultrafilter. A variety of fundamental semantics for AAFs (including conflict-free, admissible, complete and stable semantics , etc) and some derived semantics are shown to be closed under this operator. Based on these facts, a number of applications of the operator ⋂ D ⋂D are considered, which show this operator can deal with various aspects of argumentation theory . In particular, we provide a simple and uniform method to prove the universal definability of a family of range related semantics. In addition to these results at the object level, this paper also explores ones at the metatheoretical level. To illustrate the universal applicability of the operator ⋂ D ⋂D as a tool for handling semantic related problems, we introduce the first order language FS ( Ω ) FS(Ω) and establish a connection between ultraproducts of models in model theory and reduced meets of extensions modulo ultrafilters. On the basis of this, we characterize the extension-based semantics that is closed under the operator ⋂ D ⋂D in terms of the FS ( Ω ) FS(Ω) -definability, which provides an example of utilizing model theory to explore the theoretical problems of AAFs and brings a series of metatheorems about extension-based semantics. In a word, our work shows that the operator ⋂ D ⋂D can deal with various problems related to various semantics, which suggests that it provides a general method to study AAFs.},
  archive      = {J_AIJ},
  author       = {Lixing Tan and Zhaohui Zhu and Jinjin Zhang},
  doi          = {10.1016/j.artint.2022.103836},
  journal      = {Artificial Intelligence},
  pages        = {103836},
  shortjournal = {Artif. Intell.},
  title        = {A general approach to extension-based semantics in abstract argumentation},
  volume       = {315},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rationalizing predictions by adversarial information
calibration. <em>AIJ</em>, <em>315</em>, 103828. (<a
href="https://doi.org/10.1016/j.artint.2022.103828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explaining the predictions of AI models is paramount in safety-critical applications, such as in legal or medical domains. One form of explanation for a prediction is an extractive rationale, i.e., a subset of features of an instance that lead the model to give its prediction on that instance. For example, the subphrase “he stole the mobile phone” can be an extractive rationale for the prediction of “Theft”. Previous works on generating extractive rationales usually employ a two-phase model: a selector that selects the most important features (i.e., the rationale) followed by a predictor that makes the prediction based exclusively on the selected features. One disadvantage of these works is that the main signal for learning to select features comes from the comparison of the answers given by the predictor to the ground-truth answers. In this work, we propose to squeeze more information from the predictor via an information calibration method . More precisely, we train two models jointly: one is a typical neural model that solves the task at hand in an accurate but black-box manner, and the other is a selector-predictor model that additionally produces a rationale for its prediction. The first model is used as a guide for the second model. We use an adversarial technique to calibrate the information extracted by the two models such that the difference between them is an indicator of the missed or over-selected features. In addition, for natural language tasks, we propose a language-model-based regularizer to encourage the extraction of fluent rationales. Experimental results on a sentiment analysis task, a hate speech recognition task, as well as on three tasks from the legal domain show the effectiveness of our approach to rationale extraction.},
  archive      = {J_AIJ},
  author       = {Lei Sha and Oana-Maria Camburu and Thomas Lukasiewicz},
  doi          = {10.1016/j.artint.2022.103828},
  journal      = {Artificial Intelligence},
  pages        = {103828},
  shortjournal = {Artif. Intell.},
  title        = {Rationalizing predictions by adversarial information calibration},
  volume       = {315},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterized complexity of envy-free resource allocation in
social networks. <em>AIJ</em>, <em>315</em>, 103826. (<a
href="https://doi.org/10.1016/j.artint.2022.103826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the classical problem of allocating indivisible resources among agents in an envy-free (and, where applicable, proportional) way. Recently, the basic model was enriched by introducing the concept of a social network which allows to capture situations where agents might not have full information about the allocation of all resources. We initiate the study of the parameterized complexity of these resource allocation problems by considering natural parameters which capture structural properties of the network and similarities between agents and resources. In particular, we show that even very general fragments of the considered problems become tractable as long as the social network has constant treewidth or clique-width. We complement our results with matching lower bounds which show that our algorithms cannot be substantially improved.},
  archive      = {J_AIJ},
  author       = {Eduard Eiben and Robert Ganian and Thekla Hamm and Sebastian Ordyniak},
  doi          = {10.1016/j.artint.2022.103826},
  journal      = {Artificial Intelligence},
  pages        = {103826},
  shortjournal = {Artif. Intell.},
  title        = {Parameterized complexity of envy-free resource allocation in social networks},
  volume       = {315},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strategyproof allocation mechanisms with endowments and
m-convex distributional constraints. <em>AIJ</em>, <em>315</em>, 103825.
(<a href="https://doi.org/10.1016/j.artint.2022.103825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an allocation problem of multiple types of objects to agents, where each type of object has multiple copies (e.g., multiple seats in a school), each agent is endowed with an object, and some distributional constraints are imposed on the allocation (e.g., minimum/maximum quotas). We develop two mechanisms that are strategyproof, feasible (they always satisfy distributional constraints), and individually rational, assuming the distributional constraints are represented by an M-convex set. One mechanism, based on Top Trading Cycles, is Pareto efficient ; the other, which belongs to the mechanism class specified by Kojima et al. [1] , satisfies a relaxed fairness requirement. The class of distributional constraints we consider contains many situations raised from realistic matching problems, including individual minimum/maximum quotas, regional maximum quotas, type-specific quotas, and distance constraints. Finally, we experimentally evaluate the performance of these mechanisms by a computer simulation.},
  archive      = {J_AIJ},
  author       = {Takamasa Suzuki and Akihisa Tamura and Kentaro Yahiro and Makoto Yokoo and Yuzhe Zhang},
  doi          = {10.1016/j.artint.2022.103825},
  journal      = {Artificial Intelligence},
  pages        = {103825},
  shortjournal = {Artif. Intell.},
  title        = {Strategyproof allocation mechanisms with endowments and M-convex distributional constraints},
  volume       = {315},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A kinematics principle for iterated revision. <em>AIJ</em>,
<em>314</em>, 103827. (<a
href="https://doi.org/10.1016/j.artint.2022.103827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In probabilistic belief revision, the kinematics principle is a well-known and powerful principle which ensures that changing the probabilities of facts does not change unnecessarily conditional probabilities . A related principle, the principle of conditional preservation, has also been one of the main guidelines for the axioms of iterated belief revision in the seminal paper by Darwiche and Pearl. However, to date, a fully elaborated kinematics principle for iterated revision has not been presented. We aim to fill this gap in this paper by proposing a qualitative kinematics principle for iterated revision of epistemic states represented by total preorders. As new information, we allow sets of conditional beliefs, going far beyond the current state of the art of belief revision. We introduce a qualitative conditioning operator for total preorders which is compatible with conditioning for Spohn&#39;s ranking functions as far as possible, and transfer the technique of c-revisions to total preorders to provide a proof of concept for our kinematics principle at least for special revision scenarios.},
  archive      = {J_AIJ},
  author       = {Gabriele Kern-Isberner and Meliha Sezgin and Christoph Beierle},
  doi          = {10.1016/j.artint.2022.103827},
  journal      = {Artificial Intelligence},
  pages        = {103827},
  shortjournal = {Artif. Intell.},
  title        = {A kinematics principle for iterated revision},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi resource allocation with partial preferences.
<em>AIJ</em>, <em>314</em>, 103824. (<a
href="https://doi.org/10.1016/j.artint.2022.103824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide efficient, fair, and non-manipulable mechanisms for the multi-type resource allocation problems (MTRAs) and multiple assignment problems where agents have partial preferences over bundles consisting of multiple divisible items. We uncover a natural reduction from multiple assignment problems to MTRAs, which preserves the properties of MTRA mechanisms. We extend the well-known random priority (RP) and probabilistic serial (PS) mechanisms to MTRAs with partial preferences as multi-type PS (MPS) and multi-type RP (MRP) and propose a new mechanism, multi-type general dictatorship (MGD), which combines the ideas of MPS and MRP. We show that for the unrestricted domain of partial order preferences, unfortunately, no mechanism satisfies both sd-efficiency and sd-envy-freeness, even as they each satisfy different weaker notions of the desirable properties of efficiency, fairness, and non-manipulability we consider. Notwithstanding this impossibility result, our main message is positive: When agents&#39; preferences are represented by acyclic CP-nets, MRP satisfies ex-post-efficiency, sd-strategyproofness, and upper invariance, while MPS satisfies sd-efficiency, sd-envy-freeness, ordinal fairness, and upper invariance, recovering the properties of RP and PS; the MGD satisfies sd-efficiency, equal treatment of equals, and decomposability under the unrestricted domain of partial preferences. We introduce a natural domain of bundle net preferences, which generalizes previously studied domain restrictions of partial preferences for multiple assignment problems and is incomparable to the domain of acyclic CP-nets. We show that MRP and MPS satisfy all properties of the RP and PS under bundle net preferences as well.},
  archive      = {J_AIJ},
  author       = {Haibin Wang and Sujoy Sikdar and Xiaoxi Guo and Lirong Xia and Yongzhi Cao and Hanpin Wang},
  doi          = {10.1016/j.artint.2022.103824},
  journal      = {Artificial Intelligence},
  pages        = {103824},
  shortjournal = {Artif. Intell.},
  title        = {Multi resource allocation with partial preferences},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). G-LIME: Statistical learning for local interpretations of
deep neural networks using global priors. <em>AIJ</em>, <em>314</em>,
103823. (<a href="https://doi.org/10.1016/j.artint.2022.103823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explain the prediction result of a Deep Neural Network (DNN) model based on a given sample, LIME [1] and its derivatives have been proposed to approximate the local behavior of the DNN model around the data point via linear surrogates. Though these algorithms interpret the DNN by finding the key features used for classification, the random interpolations used by LIME would perturb the explanation result and cause the instability and inconsistency between repetitions of LIME computations. To tackle this issue, we propose G G -LIME that extends the vanilla LIME through high-dimensional Bayesian linear regression using the sparsity and informative global priors. Specifically, with a dataset representing the population of samples (e.g., the training set), G G -LIME first pursues the global explanation of the DNN model using the whole dataset. Then, with a new data point, G G -LIME incorporates an modified estimator of ElasticNet-alike to refine the local explanation result through balancing the distance to the global explanation and the sparsity/feature selection in the explanation. Finally, G G -LIME uses Least Angle Regression (LARS) and retrieves the solution path of a modified ElasticNet under varying ℓ 1 ℓ1 -regularization, to screen and rank the importance of features [2] as the explanation result. Through extensive experiments on real world tasks, we show that the proposed method yields more stable, consistent, and accurate results compared to LIME.},
  archive      = {J_AIJ},
  author       = {Xuhong Li and Haoyi Xiong and Xingjian Li and Xiao Zhang and Ji Liu and Haiyan Jiang and Zeyu Chen and Dejing Dou},
  doi          = {10.1016/j.artint.2022.103823},
  journal      = {Artificial Intelligence},
  pages        = {103823},
  shortjournal = {Artif. Intell.},
  title        = {G-LIME: Statistical learning for local interpretations of deep neural networks using global priors},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logic explained networks. <em>AIJ</em>, <em>314</em>,
103822. (<a href="https://doi.org/10.1016/j.artint.2022.103822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large and still increasing popularity of deep learning clashes with a major limit of neural network architectures , that consists in their lack of capability in providing human-understandable motivations of their decisions. In situations in which the machine is expected to support the decision of human experts, providing a comprehensible explanation is a feature of crucial importance. The language used to communicate the explanations must be formal enough to be implementable in a machine and friendly enough to be understandable by a wide audience. In this paper, we propose a general approach to Explainable Artificial Intelligence in the case of neural architectures, showing how a mindful design of the networks leads to a family of interpretable deep learning models called Logic Explained Networks (LENs). LENs only require their inputs to be human-understandable predicates, and they provide explanations in terms of simple First-Order Logic (FOL) formulas involving such predicates. LENs are general enough to cover a large number of scenarios. Amongst them, we consider the case in which LENs are directly used as special classifiers with the capability of being explainable, or when they act as additional networks with the role of creating the conditions for making a black-box classifier explainable by FOL formulas. Despite supervised learning problems are mostly emphasized, we also show that LENs can learn and provide explanations in unsupervised learning settings. Experimental results on several datasets and tasks show that LENs may yield better classifications than established white-box models, such as decision trees and Bayesian rule lists, while providing more compact and meaningful explanations.},
  archive      = {J_AIJ},
  author       = {Gabriele Ciravegna and Pietro Barbiero and Francesco Giannini and Marco Gori and Pietro Liò and Marco Maggini and Stefano Melacci},
  doi          = {10.1016/j.artint.2022.103822},
  journal      = {Artificial Intelligence},
  pages        = {103822},
  shortjournal = {Artif. Intell.},
  title        = {Logic explained networks},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regret minimization in online bayesian persuasion: Handling
adversarial receiver’s types under full and partial feedback models.
<em>AIJ</em>, <em>314</em>, 103821. (<a
href="https://doi.org/10.1016/j.artint.2022.103821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Bayesian persuasion, an informed sender has to design a signaling scheme that discloses the right amount of information so as to influence the behavior of a self-interested receiver. This kind of strategic interaction is ubiquitous in real-world economic scenarios. However, the seminal model by Kamenica and Gentzkow makes some stringent assumptions that limit its applicability in practice. One of the most limiting assumptions is, arguably, that the sender is required to know the receiver&#39;s utility function to compute an optimal signaling scheme. We relax this assumption through an online learning framework in which the sender repeatedly faces a receiver whose type is unknown and chosen adversarially at each round from a finite set of possible types. We are interested in no-regret algorithms prescribing a signaling scheme at each round of the repeated interaction with performances close to that of a best-in-hindsight signaling scheme. First, we prove a hardness result on the per-round running time required to achieve no- α -regret for any α α&amp;lt; 1 . Then, we provide algorithms for the full and partial feedback models with regret bounds sublinear in the number of rounds and polynomial in the size of the instance. Finally, we show that, by relaxing the persuasiveness constraints on signaling schemes, it is possible to design an algorithm with a better running time and small regret.},
  archive      = {J_AIJ},
  author       = {Matteo Castiglioni and Andrea Celli and Alberto Marchesi and Nicola Gatti},
  doi          = {10.1016/j.artint.2022.103821},
  journal      = {Artificial Intelligence},
  pages        = {103821},
  shortjournal = {Artif. Intell.},
  title        = {Regret minimization in online bayesian persuasion: Handling adversarial receiver&#39;s types under full and partial feedback models},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair and efficient allocation with few agent types, few item
types, or small value levels. <em>AIJ</em>, <em>314</em>, 103820. (<a
href="https://doi.org/10.1016/j.artint.2022.103820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fair division of indivisible goods, allocations that satisfy fairness and efficiency simultaneously are highly desired but may not exist or, even if they do exist, are computationally hard to find. Conditions under which such allocations, or allocations satisfying specific levels of fairness and efficiency simultaneously, can be efficiently found have thus been explored. Following this line of research, this study is concerned with the problem in a high-multiplicity setting where instances come with certain parameters, including agent types, item types, and value levels. Particularly, we address two computational problems. First, we wish to compute fair and Pareto-optimal allocations, w.r.t. any of the common fairness criteria: proportionality, maximin share, and max-min fairness. Second, we seek to find a max-min fair allocation that is efficient in the sense of maximizing utilitarian social welfare. We show that the first problem is tractable for most of the fairness criteria when the number of item types is fixed, or when at least two of the three parameters are fixed. For the second problem, we model it as a bi-criteria optimization problem that is solved approximately by determining an approximate Pareto set of bounded size. Our results are obtained based on dynamic programming and linear programming approaches. Our techniques strengthen known methods and can be potentially applied to other notions of fairness and efficiency.},
  archive      = {J_AIJ},
  author       = {Trung Thanh Nguyen and Jörg Rothe},
  doi          = {10.1016/j.artint.2022.103820},
  journal      = {Artificial Intelligence},
  pages        = {103820},
  shortjournal = {Artif. Intell.},
  title        = {Fair and efficient allocation with few agent types, few item types, or small value levels},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved local search for the minimum weight dominating set
problem in massive graphs by using a deep optimization mechanism.
<em>AIJ</em>, <em>314</em>, 103819. (<a
href="https://doi.org/10.1016/j.artint.2022.103819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum weight dominating set (MWDS) problem is an important generalization of the minimum dominating set problem with various applications. In this work, we develop an efficient local search scheme that can dynamically adjust the number of added and removed vertices according to the information of the candidate solution. Based on this scheme, we further develop three novel ideas to improve performance, resulting in our so-called DeepOpt-MWDS algorithm. First, we use a new construction method with five reduction rules to significantly reduce massive graphs and construct an initial solution efficiently. Second, an improved configuration checking strategy called CC 2 V3+ is designed to reduce the cycling phenomenon in local search. Third, a general perturbation framework called deep optimization mechanism (DeepOpt) is proposed to help the algorithm avoid local optima and to converge to a new solution quickly. Extensive experiments based on eight popular benchmarks of different scales are carried out to evaluate the proposed algorithm. Compared to seven state-of-the-art heuristic algorithms , DeepOpt-MWDS performs better on random and classic benchmarks and obtains the best solutions on almost all massive graphs. We investigate three main algorithmic ingredients to understand their impacts on the performance of the proposed algorithm. Moreover, we adapt the proposed general framework DeepOpt to another NP-hard problem to verify its generality and achieve good performance.},
  archive      = {J_AIJ},
  author       = {Jiejiang Chen and Shaowei Cai and Yiyuan Wang and Wenhao Xu and Jia Ji and Minghao Yin},
  doi          = {10.1016/j.artint.2022.103819},
  journal      = {Artificial Intelligence},
  pages        = {103819},
  shortjournal = {Artif. Intell.},
  title        = {Improved local search for the minimum weight dominating set problem in massive graphs by using a deep optimization mechanism},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk bounded nonlinear robot motion planning with integrated
perception &amp; control. <em>AIJ</em>, <em>314</em>, 103812. (<a
href="https://doi.org/10.1016/j.artint.2022.103812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust autonomy stacks require tight integration of perception, motion planning, and control layers, but these layers often inadequately incorporate inherent perception and prediction uncertainties, either ignoring them altogether or making questionable assumptions of Gaussianity . Robots with nonlinear dynamics and complex sensing modalities operating in an uncertain environment demand more careful consideration of how uncertainties propagate across stack layers. We propose a framework to integrate perception, motion planning, and control by explicitly incorporating perception and prediction uncertainties into planning so that risks of constraint violation can be mitigated. Specifically, we use a nonlinear model predictive control based steering law coupled with a decorrelation scheme based Unscented Kalman Filter for state and environment estimation to propagate the robot state and environment uncertainties. Subsequently, we use distributionally robust risk constraints to limit the risk in the presence of these uncertainties. Finally, we present a layered autonomy stack consisting of a nonlinear steering-based distributionally robust motion planning module and a reference trajectory tracking module. Our numerical experiments with nonlinear robot models and an urban driving simulator show the effectiveness of our proposed approaches.},
  archive      = {J_AIJ},
  author       = {Venkatraman Renganathan and Sleiman Safaoui and Aadi Kothari and Benjamin Gravell and Iman Shames and Tyler Summers},
  doi          = {10.1016/j.artint.2022.103812},
  journal      = {Artificial Intelligence},
  pages        = {103812},
  shortjournal = {Artif. Intell.},
  title        = {Risk bounded nonlinear robot motion planning with integrated perception &amp; control},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sim-to-lab-to-real: Safe reinforcement learning with
shielding and generalization guarantees. <em>AIJ</em>, <em>314</em>,
103811. (<a href="https://doi.org/10.1016/j.artint.2022.103811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety is a critical component of autonomous systems and remains a challenge for learning-based policies to be utilized in the real world. In particular, policies learned using reinforcement learning often fail to generalize to novel environments due to unsafe behavior. In this paper, we propose Sim-to-Lab-to-Real to bridge the reality gap with a probabilistically guaranteed safety-aware policy distribution. To improve safety, we apply a dual policy setup where a performance policy is trained using the cumulative task reward and a backup (safety) policy is trained by solving the Safety Bellman Equation based on Hamilton-Jacobi (HJ) reachability analysis. In Sim-to-Lab transfer, we apply a supervisory control scheme to shield unsafe actions during exploration; in Lab-to-Real transfer, we leverage the Probably Approximately Correct (PAC)-Bayes framework to provide lower bounds on the expected performance and safety of policies in unseen environments. Additionally, inheriting from the HJ reachability analysis, the bound accounts for the expectation over the worst-case safety in each environment. We empirically study the proposed framework for ego-vision navigation in two types of indoor environments with varying degrees of photorealism. We also demonstrate strong generalization performance through hardware experiments in real indoor spaces with a quadrupedal robot. See https://sites.google.com/princeton.edu/sim-to-lab-to-real for supplementary material.},
  archive      = {J_AIJ},
  author       = {Kai-Chieh Hsu and Allen Z. Ren and Duy P. Nguyen and Anirudha Majumdar and Jaime F. Fisac},
  doi          = {10.1016/j.artint.2022.103811},
  journal      = {Artificial Intelligence},
  pages        = {103811},
  shortjournal = {Artif. Intell.},
  title        = {Sim-to-lab-to-real: Safe reinforcement learning with shielding and generalization guarantees},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving projected model counting by utilizing treewidth and
its limits. <em>AIJ</em>, <em>314</em>, 103810. (<a
href="https://doi.org/10.1016/j.artint.2022.103810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel algorithm to solve projected model counting ( PMC ). PMC asks to count solutions of a Boolean formula with respect to a given set of projection variables , where multiple solutions that are identical when restricted to the projection variables count as only one solution. Inspired by the observation that the so-called “treewidth” is one of the most prominent structural parameters, our algorithm utilizes small treewidth of the primal graph of the input instance. More precisely, it runs in time O ( 2 2 k + 4 n 2 ) O(22k+4n2) where k is the treewidth and n is the input size of the instance. In other words, we obtain that the problem PMC is fixed-parameter tractable when parameterized by treewidth. Further, we take the exponential time hypothesis (ETH) into consideration and establish lower bounds of bounded treewidth algorithms for PMC , yielding asymptotically tight runtime bounds of our algorithm. While the algorithm above serves as a first theoretical upper bound and although it might be quite appealing for small values of k , unsurprisingly a naive implementation adhering to this runtime bound suffers already from instances of relatively small width. Therefore, we turn our attention to several measures in order to resolve this issue towards exploiting treewidth in practice: We present a technique called nested dynamic programming , where different levels of abstractions of the primal graph are used to (recursively) compute and refine tree decompositions of a given instance. Further, we integrate the concept of hybrid solving, where subproblems hidden by the abstraction are solved by classical search-based solvers, which leads to an interleaving of parameterized and classical solving. Finally, we provide a nested dynamic programming algorithm and an implementation that relies on database technology for PMC and a prominent special case of PMC, namely model counting ( #Sat ). Experiments indicate that the advancements are promising, allowing us to solve instances of treewidth upper bounds beyond 200.},
  archive      = {J_AIJ},
  author       = {Johannes K. Fichte and Markus Hecher and Michael Morak and Patrick Thier and Stefan Woltran},
  doi          = {10.1016/j.artint.2022.103810},
  journal      = {Artificial Intelligence},
  pages        = {103810},
  shortjournal = {Artif. Intell.},
  title        = {Solving projected model counting by utilizing treewidth and its limits},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Portioning using ordinal preferences: Fairness and
efficiency. <em>AIJ</em>, <em>314</em>, 103809. (<a
href="https://doi.org/10.1016/j.artint.2022.103809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A divisible public resource is to be divided among projects. We study rules that decide on a distribution of the budget when voters have ordinal preference rankings over projects. Examples of such portioning problems are participatory budgeting, time shares, and parliament elections. We introduce a family of rules for portioning, inspired by positional scoring rules. Rules in this family are given by a scoring vector (such as plurality or Borda) associating a positive value with each rank in a vote, and an aggregation function such as leximin or the Nash product. Our family contains well-studied rules, but most are new. We discuss computational and normative properties of our rules. We focus on fairness, and introduce the SD-core, a group fairness notion. Our Nash rules are in the SD-core, and the leximin rules satisfy individual fairness properties. Both are Pareto-efficient.},
  archive      = {J_AIJ},
  author       = {Stéphane Airiau and Haris Aziz and Ioannis Caragiannis and Justin Kruger and Jérôme Lang and Dominik Peters},
  doi          = {10.1016/j.artint.2022.103809},
  journal      = {Artificial Intelligence},
  pages        = {103809},
  shortjournal = {Artif. Intell.},
  title        = {Portioning using ordinal preferences: Fairness and efficiency},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Answering regular path queries mediated by unrestricted SQ
ontologies. <em>AIJ</em>, <em>314</em>, 103808. (<a
href="https://doi.org/10.1016/j.artint.2022.103808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A prime application of description logics is ontology-mediated query answering , with the query language often reaching far beyond instance queries. Here, we investigate this task for positive existential two-way regular path queries and ontologies formulated in the expressive description logic SQ u SQu , where SQ u SQu denotes the extension of the basic description logic ALC ALC with transitive roles ( S S ) and qualified number restrictions ( Q Q ) which can be unrestrictedly applied to both non-transitive and transitive roles ( ⋅ u ⋅u ). Notably, the latter is usually forbidden in expressive description logics. As the main contribution, we show decidability of ontology-mediated query answering in that setting and establish tight complexity bounds, namely 2ExpTime -completeness in combined complexity and coNP -completeness in data complexity. Since the lower bounds are inherited from the fragment ALC ALC , we concentrate on providing upper bounds. As main technical tools we establish a tree-like countermodel property and a characterization of when a query is not satisfied in a tree-like interpretation. Together, these results allow us to use an automata-based approach to query answering.},
  archive      = {J_AIJ},
  author       = {Víctor Gutiérrez-Basulto and Yazmín Ibáñez-García and Jean Christoph Jung and Filip Murlak},
  doi          = {10.1016/j.artint.2022.103808},
  journal      = {Artificial Intelligence},
  pages        = {103808},
  shortjournal = {Artif. Intell.},
  title        = {Answering regular path queries mediated by unrestricted SQ ontologies},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simple and efficient bi-objective search algorithms via fast
dominance checks. <em>AIJ</em>, <em>314</em>, 103807. (<a
href="https://doi.org/10.1016/j.artint.2022.103807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many interesting search problems can be formulated as bi-objective search problems, that is, search problems where two kinds of costs have to be minimized, for example, travel distance and time for transportation problems. Instead of looking for a single optimal path, we compute a Pareto-optimal frontier in bi-objective search, which is a set of paths in which no two paths dominate each other. Bi-objective search algorithms perform dominance checks each time a new path is discovered. Thus, the efficiency of these checks is key to performance. In this article, we propose algorithms for two kinds of bi-objective search problems. First, we consider the problem of computing the Pareto-optimal frontier of the paths that connect a given start state with a given goal state. We propose Bi-Objective A* (BOA*), a heuristic search algorithm based on A*, for this problem. Second, we consider the problem of computing one Pareto-optimal frontier for each state s of the search graph, which contains the paths that connect a given start state with s . We propose Bi-Objective Dijkstra (BOD), which is based on BOA*, for this problem. A common feature of BOA* and BOD is that all dominance checks are performed in constant time, unlike the dominance checks of previous algorithms. We show in our experimental evaluation that both BOA* and BOD are substantially faster than state-of-the-art bi-objective search algorithms.},
  archive      = {J_AIJ},
  author       = {Carlos Hernández and William Yeoh and Jorge A. Baier and Han Zhang and Luis Suazo and Sven Koenig and Oren Salzman},
  doi          = {10.1016/j.artint.2022.103807},
  journal      = {Artificial Intelligence},
  pages        = {103807},
  shortjournal = {Artif. Intell.},
  title        = {Simple and efficient bi-objective search algorithms via fast dominance checks},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative concurrent games. <em>AIJ</em>, <em>314</em>,
103806. (<a href="https://doi.org/10.1016/j.artint.2022.103806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In rational verification , the aim is to verify which temporal logic properties will obtain in a multi-agent system, under the assumption that agents (“players”) in the system choose strategies for acting that form a game theoretic equilibrium. Preferences are typically defined by assuming that agents act in pursuit of individual goals, specified as temporal logic formulae. To date, rational verification has been studied using non-cooperative solution concepts—Nash equilibrium and refinements thereof. Such non-cooperative solution concepts assume that there is no possibility of agents forming binding agreements to cooperate, and as such they are restricted in their applicability. In this article, we extend rational verification to cooperative solution concepts, as studied in the field of cooperative game theory . We focus on the core , as this is the most fundamental (and most widely studied) cooperative solution concept. We begin by presenting a variant of the core that seems well-suited to the concurrent game setting, and we show that this version of the core can be characterised using ATL ⁎ . We then study the computational complexity of key decision problems associated with the core, which range from problems in PSpace to problems in 3ExpTime . We also investigate conditions that are sufficient to ensure that the core is non-empty, and explore when it is invariant under bisimilarity. We then introduce and study a number of variants of the main definition of the core, leading to the issue of credible deviations, and to stronger notions of collective stable behaviour. Finally, we study cooperative rational verification using an alternative model of preferences, in which players seek to maximise the mean-payoff they obtain over an infinite play in games where quantitative information is allowed.},
  archive      = {J_AIJ},
  author       = {Julian Gutierrez and Szymon Kowara and Sarit Kraus and Thomas Steeples and Michael Wooldridge},
  doi          = {10.1016/j.artint.2022.103806},
  journal      = {Artificial Intelligence},
  pages        = {103806},
  shortjournal = {Artif. Intell.},
  title        = {Cooperative concurrent games},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Value functions for depth-limited solving in zero-sum
imperfect-information games. <em>AIJ</em>, <em>314</em>, 103805. (<a
href="https://doi.org/10.1016/j.artint.2022.103805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a formal definition of depth-limited games together with an accessible and rigorous explanation of the underlying concepts, both of which were previously missing in imperfect-information games. The definition works for an arbitrary (perfect recall) extensive-form game and is not tied to any specific game-solving algorithm. Moreover, this framework unifies and significantly extends three approaches to depth-limited solving that previously existed in extensive-form games and multiagent reinforcement learning but were not known to be compatible. A key ingredient of these depth-limited games is value functions. Focusing on two-player zero-sum imperfect-information games, we show how to obtain optimal value functions and prove that public information provides both necessary and sufficient context for computing them. We provide a domain-independent encoding of the domains that allows for approximating value functions even by simple feed-forward neural networks, which are then able to generalize to unseen parts of the game. We use the resulting value network to implement a depth-limited version of counterfactual regret minimization. In three distinct domains, we show that the algorithm&#39;s exploitability is roughly linearly dependent on the value network&#39;s quality and that it is not difficult to train a value network with which depth-limited CFR&#39;s performance is as good as that of CFR with access to the full game.},
  archive      = {J_AIJ},
  author       = {Vojtěch Kovařík and Dominik Seitz and Viliam Lisý and Jan Rudolf and Shuo Sun and Karel Ha},
  doi          = {10.1016/j.artint.2022.103805},
  journal      = {Artificial Intelligence},
  pages        = {103805},
  shortjournal = {Artif. Intell.},
  title        = {Value functions for depth-limited solving in zero-sum imperfect-information games},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When move acceptance selection hyper-heuristics outperform
metropolis and elitist evolutionary algorithms and when not.
<em>AIJ</em>, <em>314</em>, 103804. (<a
href="https://doi.org/10.1016/j.artint.2022.103804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selection hyper-heuristics (HHs) are automated algorithm selection methodologies that choose between different heuristics during the optimisation process. Recently, selection HHs choosing between a collection of elitist randomised local search heuristics with different neighbourhood sizes have been shown to optimise standard unimodal benchmark functions from evolutionary computation in the optimal expected runtime achievable with the available low-level heuristics. In this paper, we extend our understanding of the performance of HHs to the domain of multimodal optimisation by considering a Move Acceptance HH (MAHH) from the literature that can switch between elitist and non-elitist heuristics during the run. In essence, MAHH is a non-elitist search heuristic that differs from other search heuristics in the source of non-elitism. We first identify the range of parameters that allow MAHH to hillclimb efficiently and prove that it can optimise the standard hillclimbing benchmark function OneMax in the best expected asymptotic time achievable by unbiased mutation-based randomised search heuristics. Afterwards, we use standard multimodal benchmark functions to highlight function characteristics where MAHH outperforms elitist evolutionary algorithms and the well-known Metropolis non-elitist algorithm by quickly escaping local optima, and ones where it does not. Since MAHH is essentially a non-elitist random local search heuristic, the paper is of independent interest to researchers in the fields of artificial intelligence and randomised search heuristics.},
  archive      = {J_AIJ},
  author       = {Andrei Lissovoi and Pietro S. Oliveto and John Alasdair Warwicker},
  doi          = {10.1016/j.artint.2022.103804},
  journal      = {Artificial Intelligence},
  pages        = {103804},
  shortjournal = {Artif. Intell.},
  title        = {When move acceptance selection hyper-heuristics outperform metropolis and elitist evolutionary algorithms and when not},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning MAX-SAT from contextual examples for combinatorial
optimisation. <em>AIJ</em>, <em>314</em>, 103794. (<a
href="https://doi.org/10.1016/j.artint.2022.103794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimisation problems are ubiquitous in artificial intelligence . Designing the underlying models, however, requires substantial expertise, which is a limiting factor in practice. The models typically consist of hard and soft constraints, or combine hard constraints with an objective function. We introduce a novel setting for learning combinatorial optimisation problems from contextual examples. These positive and negative examples show – in a particular context – whether the solutions are good enough or not. We develop our framework using the MAX-SAT formalism as it is a simple yet powerful setting having these features. We study the learnability of MAX-SAT models. Our theoretical results show that high-quality MAX-SAT models can be learned from contextual examples in the realisable and agnostic settings, as long as the data satisfies an intuitive “representativeness” condition. We also contribute two implementations based on our theoretical results: one leverages ideas from syntax-guided synthesis while the other makes use of stochastic local search techniques. The two implementations are evaluated by recovering synthetic and benchmark models from contextual examples. The experimental results support our theoretical analysis, showing that MAX-SAT models can be learned from contextual examples. Among the two implementations, the stochastic local search learner scales much better than the syntax-guided implementation while providing comparable or better models.},
  archive      = {J_AIJ},
  author       = {Mohit Kumar and Samuel Kolb and Stefano Teso and Luc De Raedt},
  doi          = {10.1016/j.artint.2022.103794},
  journal      = {Artificial Intelligence},
  pages        = {103794},
  shortjournal = {Artif. Intell.},
  title        = {Learning MAX-SAT from contextual examples for combinatorial optimisation},
  volume       = {314},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
