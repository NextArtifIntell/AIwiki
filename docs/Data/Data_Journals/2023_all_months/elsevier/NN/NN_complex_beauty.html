<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nn---513">NN - 513</h2>
<ul>
<li><details>
<summary>
(2023). Competitive learning to generate sparse representations for
associative memory. <em>NN</em>, <em>168</em>, 32–43. (<a
href="https://doi.org/10.1016/j.neunet.2023.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most well established brain principles, Hebbian learning , has led to the theoretical concept of neural assemblies. Based on it, many interesting brain theories have spawned. Palm’s work implements this concept through multiple binary Willshaw associative memories , in a model that not only has a wide cognitive explanatory power but also makes neuroscientific predictions. Yet, Willshaw’s associative memory can only achieve top capacity when the stored vectors are extremely sparse (number of active bits can grow logarithmically with the vector’s length). This strict requirement makes it difficult to apply any model that uses this associative memory, like Palm’s, to real data. Hence the fact that most works apply the memory to optimal randomly generated codes that do not represent any information. This issue creates the need for encoders that can take real data, and produce sparse representations - a problem which is also raised following Barlow’s efficient coding principle. In this work, we propose a biologically-constrained network that encodes images into codes that are suitable for Willshaw’s associative memory. The network is organized into groups of neurons that specialize on local receptive fields, and learn through a competitive scheme. After conducting auto- and hetero-association experiments on two visual data sets, we can conclude that our network not only beats sparse coding baselines, but also that it comes close to the performance achieved using optimal random codes.},
  archive      = {J_NN},
  author       = {Luis Sacouto and Andreas Wichert},
  doi          = {10.1016/j.neunet.2023.09.005},
  journal      = {Neural Networks},
  pages        = {32-43},
  shortjournal = {Neural Netw.},
  title        = {Competitive learning to generate sparse representations for associative memory},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FOESO-net: A specific neural network for fast sensorless
robot manipulator torque estimation. <em>NN</em>, <em>168</em>, 14–31.
(<a href="https://doi.org/10.1016/j.neunet.2023.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contact torque sensing allows robot manipulators to cooperate with humans and detect accidental collisions in real time to ensure safety. Most sensorless torque estimation schemes, which are based on linear observer approaches, cannot compromise between non-negligible noise and high observation bandwidth. Therefore, fast time-varying nonlinear torque observation cannot be satisfied. To achieve this challenge, a customized network called FOESO-Net based on a novel fractional-order extended state observer is carefully designed in this paper. The network firstly chooses momentum as the benchmark state for torque estimation, which can avoid joint acceleration and model’s inverse inertia matrix solution. Then, a fractional-order extended state observer (FOESO) is proposed from the perspective of momentum control to better adapt to the nonlinear fast time varying torque. In addition, a fractional-order neural network and a weight update neural network parallel architecture are constructed to enable fractional-order and dynamic weight-based adaptive learning of FOESO parameters. Formal analysis and proofs are made to show that the error of FOESO-Net is convergent. Finally, the effectiveness of the proposed method is verified by numerical simulations and a real collaborative robot platform. Moreover, compared with existing methods, the FOESO-Net based torque estimation method can reduce the estimation error and response time, which illustrates the superiority of the designed method.},
  archive      = {J_NN},
  author       = {Shike Long and Xuanju Dang and Jia Huang},
  doi          = {10.1016/j.neunet.2023.09.020},
  journal      = {Neural Networks},
  pages        = {14-31},
  shortjournal = {Neural Netw.},
  title        = {FOESO-net: A specific neural network for fast sensorless robot manipulator torque estimation},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RASP: Regularization-based amplitude saliency pruning.
<em>NN</em>, <em>168</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neunet.2023.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the prevalent data-dependent nature of existing pruning criteria, norm criteria with data independence play a crucial role in filter pruning criteria, providing promising prospects for deploying deep neural networks on resource-constrained devices. However, norm criteria based on amplitude measurements have long posed challenges in terms of theoretical feasibility. Existing methods rely on data-derived information such as derivatives to establish reasonable pruning standards. Nonetheless, achieving quantitative analysis of the “smaller-norm-less-important” notion remains elusive within the norm criterion context. To address the need for data independence and theoretical feasibility, we conducted saliency analysis on filters and proposed a regularization-based amplitude saliency pruning criterion (RASP). This amplitude saliency not only attains data independence but also establishes norm criteria for usage guidelines. Furthermore, we further investigated the amplitude saliency, addressing the issues of data dependency in model evaluation and inter-class filter selection. We introduced model saliency and an adaptive parameter group lasso (AGL) regularization approach sensitive to different layers. Theoretically, we thoroughly analyzed the feasibility of amplitude saliency and employed quantitative saliency analysis to validate the advantages of our method over previous approaches. Experimentally, conducted on the CIFAR-10 and ImageNet image classification benchmarks, we extensively validated the improved top-level performance of our method compared to previous methods. Even when the pruned model has the same or even smaller number of FLOP, our method can achieve equivalent or higher model accuracy. Notably, in our ImageNet experiment, RASP achieved a 51.9\% reduction in FLOPs while maintaining an accuracy of 76.19\% on ResNet-50.},
  archive      = {J_NN},
  author       = {Chenghui Zhen and Weiwei Zhang and Jian Mo and Ming Ji and Hongbo Zhou and Jianqing Zhu},
  doi          = {10.1016/j.neunet.2023.09.002},
  journal      = {Neural Networks},
  pages        = {1-13},
  shortjournal = {Neural Netw.},
  title        = {RASP: Regularization-based amplitude saliency pruning},
  volume       = {168},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient and accurate compound scaling for convolutional
neural networks. <em>NN</em>, <em>167</em>, 787–797. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing efficient and accurate network architectures to support various workloads, from servers to edge devices, is a fundamental problem as the use of Convolutional Neural Networks (ConvNets) becomes increasingly widespread. One simple yet effective method is to scale ConvNets by systematically adjusting the dimensions of the baseline network, including width, depth, and resolution, enabling it to adapt to diverse workloads by varying its computational complexity and representation ability. However, current state-of-the-art (SOTA) scaling methods for neural network architectures overlook the inter-dimensional relationships within the network and the impact of scaling on inference speed, resulting in suboptimal trade-offs between accuracy and inference speed. To overcome those limitations, we propose a scaling method for ConvNets that utilizes dimension relationship and runtime proxy constraints to improve accuracy and inference speed. Specifically, our research notes that higher input resolutions in convolutional layers lead to redundant filters (convolutional width) due to increased similarity between information in different positions, suggesting a potential benefit in reducing filters while increasing input resolution. Based on this observation, the relationship between the width and resolution is empirically quantified in our work, enabling models with higher parametric efficiency to be prioritized through our scaling strategy. Furthermore, we introduce a novel runtime prediction model that focuses on fine-grained layer tasks with different computational properties for more accurate identification of efficient network configurations . Comprehensive experiments show that our method outperforms prior works in creating a set of models with a trade-off between accuracy and inference speed on the ImageNet datasets for various ConvNets.},
  archive      = {J_NN},
  author       = {Chengmin Lin and Pengfei Yang and Quan Wang and Zeyu Qiu and Wenkai Lv and Zhenyi Wang},
  doi          = {10.1016/j.neunet.2023.08.053},
  journal      = {Neural Networks},
  pages        = {787-797},
  shortjournal = {Neural Netw.},
  title        = {Efficient and accurate compound scaling for convolutional neural networks},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse discriminant PCA based on contrastive learning and
class-specificity distribution. <em>NN</em>, <em>167</em>, 775–786. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much mathematical effort has been devoted to developing Principal Component Analysis (PCA), which is the most popular feature extraction method. To suppress the negative effect of noise on PCA performance, there have been extensive studies and applications of a large number of robust PCAs achieving outstanding results. However, existing methods suffer from at least two shortcomings: (1) They expressed PCA as a reconstruction model measured by Euclidean distance , which only considers the relationship between the data and its reconstruction and ignores the differences between different data points; (2) They did not consider the class-specificity distribution information contained in the data itself, thus lacking discriminative properties. To overcome the above problems, we propose a S parse D iscriminant P rincipal C omponents A nalysis (SDPCA) model based on contrastive learning and class-specificity distribution. Specifically, we use contrastive learning to measure the relationship between samples and their reconstructions, which fully takes the discriminative information between data into account in PCA. In order to make the extracted low-dimensional features profoundly reflect the class-specificity distribution of the data, we minimize the squared ℓ 1 , 2 ℓ1,2 -norm of the low-dimensional embedding. In addition, to reduce the effects of redundant features and noise and to improve the interpretability of PCA at the same time, we impose sparsity constraints on the projection matrix using the squared ℓ 1 , 2 ℓ1,2 -norm. Our experimental results on different types of benchmark databases demonstrate that our model has state-of-the-art performance.},
  archive      = {J_NN},
  author       = {Qian Zhou and Quanxue Gao and Qianqian Wang and Ming Yang and Xinbo Gao},
  doi          = {10.1016/j.neunet.2023.08.061},
  journal      = {Neural Networks},
  pages        = {775-786},
  shortjournal = {Neural Netw.},
  title        = {Sparse discriminant PCA based on contrastive learning and class-specificity distribution},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sampled-data exponential consensus of multi-agent systems
with lipschitz nonlinearities. <em>NN</em>, <em>167</em>, 763–774. (<a
href="https://doi.org/10.1016/j.neunet.2023.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the exponential consensus of leaderless and leader-following multi-agent systems with Lipschitz nonlinear dynamics is illustrated with aperiodic sampled-data control using a two-sided loop-based Lyapunov functional (LBLF). Firstly, applying input delay approach to reformulate the resulting sampled-data system as a continuous system with time-varying delay in the control input. A two-sided LBLF which captures the information on sampled-data pattern is constructed and the symmetry of the Laplacian matrix together with Newton–Leibniz formula have been employed to obtain reduced number of decision variables and decreased LMI dimensions for the exponential sampled-data consensus problem. Subsequently, an aperiodic sampled-data controller was designed to simplify and enhance stability conditions for computation and optimization purposes in the proposed approach. Finally, based on the controller design , simulation examples including the power system are proposed to illustrate the theoretical analysis, moreover, a larger sampled-data interval can be acquired by this method than other literature, thereby conserving bandwidth and reducing communication resources.},
  archive      = {J_NN},
  author       = {Wenqing Zhao and Guoliang Chen and Xiangpeng Xie and Jianwei Xia and Ju H. Park},
  doi          = {10.1016/j.neunet.2023.09.003},
  journal      = {Neural Networks},
  pages        = {763-774},
  shortjournal = {Neural Netw.},
  title        = {Sampled-data exponential consensus of multi-agent systems with lipschitz nonlinearities},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Dichotomy value iteration with parallel learning design
towards discrete-time zero-sum games. <em>NN</em>, <em>167</em>,
751–762. (<a
href="https://doi.org/10.1016/j.neunet.2023.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel parallel learning framework is developed to solve zero-sum games for discrete-time nonlinear systems . Briefly, the purpose of this study is to determine a tentative function according to the prior knowledge of the value iteration (VI) algorithm. The learning process of the parallel controllers can be guided by the tentative function. That is to say, the neighborhood of the optimal cost function can be compressed within a small range via two typical exploration policies. Based on the parallel learning framework, a novel dichotomy VI algorithm is established to accelerate the learning speed. It is shown that the parallel controllers will converge to the optimal policy from contrary initial policies. Finally, two typical systems are used to demonstrate the learning performance of the constructed dichotomy VI algorithm.},
  archive      = {J_NN},
  author       = {Jiangyu Wang and Ding Wang and Xin Li and Junfei Qiao},
  doi          = {10.1016/j.neunet.2023.09.009},
  journal      = {Neural Networks},
  pages        = {751-762},
  shortjournal = {Neural Netw.},
  title        = {Dichotomy value iteration with parallel learning design towards discrete-time zero-sum games},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adv-BDPM: Adversarial attack based on boundary diffusion
probability model. <em>NN</em>, <em>167</em>, 730–740. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have become increasingly significant in our daily lives due to their remarkable performance. The issue of adversarial examples, which are responsible for the vulnerability problem of deep neural networks, has attracted the attention of researchers in the study of robustness of these networks. To address the issues caused by the restricted diversity and precision of adversarial perturbations in neural networks, we introduce a novel technique called Adversarial Boundary Diffusion Probability Modeling (Adv-BDPM). This approach combines boundary analysis and diffusion probability modeling. First, we combined the denoising diffusion probability model with the boundary loss to design the boundary diffusion probability model, which can generate corresponding boundary perturbations for a specific neural network. Then, through the iterative process of boundary perturbations and its corresponding orthogonal perturbations, we proposed a decision boundary search algorithm to generate adversarial samples. The comparison experiments with black-box attacks in ImageNet demonstrate that Adv-BDPM has better attack success rate and perturbation precision. The comparison experiments with white-box attacks in CIFAR-10 and CIFAR-100 demonstrate that Adv-BDPM has better attack success rate, attack diversity for the same sample, and can effectively defend against adversarial training with shorter running time.},
  archive      = {J_NN},
  author       = {Dian Zhang and Yunwei Dong},
  doi          = {10.1016/j.neunet.2023.08.048},
  journal      = {Neural Networks},
  pages        = {730-740},
  shortjournal = {Neural Netw.},
  title        = {Adv-BDPM: Adversarial attack based on boundary diffusion probability model},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive embedding procedure for time series forecasting
with deep neural networks. <em>NN</em>, <em>167</em>, 715–729. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, solving time series prediction problems is an open and challenging task. Many solutions are based on the implementation of deep neural architectures, which are able to analyze the structure of the time series and to carry out the prediction. In this work, we present a novel deep learning scheme based on an adaptive embedding mechanism. The latter is exploited to extract a compressed representation of the input time series that is used for the subsequent forecasting. The proposed model is based on a two-layer bidirectional Long Short-Term Memory network, where the first layer performs the adaptive embedding and the second layer acts as a predictor. The performances of the proposed forecasting scheme are compared with several models in two different scenarios, considering both well-known time series and real-life application cases. The experimental results show the accuracy and the flexibility of the proposed approach, which can be used as a prediction tool for any actual application.},
  archive      = {J_NN},
  author       = {Federico Succetti and Antonello Rosato and Massimo Panella},
  doi          = {10.1016/j.neunet.2023.08.051},
  journal      = {Neural Networks},
  pages        = {715-729},
  shortjournal = {Neural Netw.},
  title        = {An adaptive embedding procedure for time series forecasting with deep neural networks},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosting adversarial robustness via self-paced adversarial
training. <em>NN</em>, <em>167</em>, 706–714. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is considered one of the most effective methods to improve the adversarial robustness of deep neural networks . Despite the success, it still suffers from unsatisfactory performance and overfitting. Considering the intrinsic mechanism of adversarial training, recent studies adopt the idea of curriculum learning to alleviate overfitting. However, this also introduces new issues, that is, lacking the quantitative criterion for attacks’ strength and catastrophic forgetting. To mitigate such issues, we propose the self-paced adversarial training (SPAT), which explicitly builds the learning process of adversarial training based on adversarial examples of the whole dataset. Specifically, our model is first trained with “easy” adversarial examples , and then is continuously enhanced by gradually adding “complex” adversarial examples. This way strengthens the ability to fit “complex” adversarial examples while holding in mind “easy” adversarial samples. To balance adversarial examples between classes, we determine the difficulty of the adversarial examples locally in each class. Notably, this learning paradigm can also be incorporated into other advanced methods for further boosting adversarial robustness. Experimental results show the effectiveness of our proposed model against various attacks on widely-used benchmarks. Especially, on CIFAR100, SPAT provides a boost of 1.7\% (relatively 5.4\%) in robust accuracy on the PGD10 attack and 3.9\% (relatively 7.2\%) in natural accuracy for AWP.},
  archive      = {J_NN},
  author       = {Lirong He and Qingzhong Ai and Xincheng Yang and Yazhou Ren and Qifan Wang and Zenglin Xu},
  doi          = {10.1016/j.neunet.2023.08.063},
  journal      = {Neural Networks},
  pages        = {706-714},
  shortjournal = {Neural Netw.},
  title        = {Boosting adversarial robustness via self-paced adversarial training},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A scalable second order optimizer with an adaptive trust
region for neural networks. <em>NN</em>, <em>167</em>, 692–705. (<a
href="https://doi.org/10.1016/j.neunet.2023.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Tadam (Trust region ADAptive Moment estimation), a new optimizer based on the trust region of the second-order approximation of the loss using the Fisher information matrix . Despite the enhanced gradient estimations offered by second-order approximations, their practical implementation requires sizable batch sizes to estimate the second-order approximation matrices and perform matrix inversions . Consequently, integrating second-order approximations entails additional memory consumption and imposes substantial computational demands due to the inversion of large matrices. In light of these challenges, we have devised a second-order approximation algorithm that mitigates these issues by judiciously approximating the pertinent large matrix, requiring only a marginal increase in memory usage while minimizing the computational burden. Tadam approximates the loss up to the second order using the Fisher information matrix . Since estimating the Fisher information matrix is expensive in both memory and time, Tadam approximates the Fisher information matrix and reduces the computational burdens to the O ( N ) O(N) level. Furthermore, Tadam employs an adaptive trust region scheme to reduce approximate errors and guarantee stability. Tadam evaluates how well it minimizes the loss function and uses this information to adjust the trust region dynamically. In addition, Tadam adjusts the learning rate internally, even if we provide the learning rate as a fixed constant. We run several experiments to measure Tadam’s performance against Adam, AMSGrad, Radam, and Nadam, which have the same space and time complexity as Tadam. The test results show that Tadam outperforms the benchmarks and finds reasonable solutions fast and stably.},
  archive      = {J_NN},
  author       = {Donghee Yang and Junhyun Cho and Sungchul Lee},
  doi          = {10.1016/j.neunet.2023.09.010},
  journal      = {Neural Networks},
  pages        = {692-705},
  shortjournal = {Neural Netw.},
  title        = {A scalable second order optimizer with an adaptive trust region for neural networks},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel results on asymptotic stability and synchronization of
fractional-order memristive neural networks with time delays: The
0&lt;δ≤1 case. <em>NN</em>, <em>167</em>, 680–691. (<a
href="https://doi.org/10.1016/j.neunet.2023.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the asymptotic stability and synchronization of fractional-order (FO) memristive neural networks with time delays . Based on the FO comparison principle and inverse Laplace transform method, the novel sufficient conditions for the asymptotic stability of a FO nonlinear system are given. Then, based on the above conclusions, the sufficient conditions for the asymptotic stability and synchronization of FO memristive neural networks with time delays are investigated. The results in this paper have a wider coverage of situations and are more practical than the previous related results. Finally, the validity of the results is checked by two examples.},
  archive      = {J_NN},
  author       = {Jia-Rui Zhang and Jun-Guo Lu and Xiao-Chuang Jin and Xing-Yu Yang},
  doi          = {10.1016/j.neunet.2023.09.007},
  journal      = {Neural Networks},
  pages        = {680-691},
  shortjournal = {Neural Netw.},
  title        = {Novel results on asymptotic stability and synchronization of fractional-order memristive neural networks with time delays: The 0&amp;lt;δ≤1 case},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Switching ETM-based neural adaptive output feedback control
for nonaffine stochastic MIMO nonlinear systems subject to deferred
constraint. <em>NN</em>, <em>167</em>, 668–679. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the neural adaptive output feedback control study related to nonaffine stochastic multiple-input, multiple-output nonlinear plants . First, a K K -filter state observer based on a radial basis function neural network is designed to estimate the remaining unavailable states. Then, a novel adaptive command-filtered backstepping output feedback control framework is established, where an improved command filter with a fractional-order parameter is applied to conquer the calculation size problem. Specifically, the highlight of this work is that it designs a modified error compensation signal and incorporates the concept of deferred constraint to eradicate the negative effect caused by the filter errors. In addition, the network bandwidth resources, control impulse, and control accuracy are synthesized using an amended switching event-triggered mechanism. The theoretical analysis proved that the proposed control approach guarantees that the tracking error can converge to a preassigned region within a user-defined time while the violation of the deferred output constraint can be excluded. Two illustrative studies are provided to demonstrate the validity and superiority of the developed control method .},
  archive      = {J_NN},
  author       = {Xiaona Song and Peng Sun and Choon Ki Ahn and Shuai Song},
  doi          = {10.1016/j.neunet.2023.08.054},
  journal      = {Neural Networks},
  pages        = {668-679},
  shortjournal = {Neural Netw.},
  title        = {Switching ETM-based neural adaptive output feedback control for nonaffine stochastic MIMO nonlinear systems subject to deferred constraint},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving differentiable architecture search via
self-distillation. <em>NN</em>, <em>167</em>, 656–667. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiable Architecture Search (DARTS) is a simple yet efficient Neural Architecture Search (NAS) method. During the search stage, DARTS trains a supernet by jointly optimizing architecture parameters and network parameters. During the evaluation stage, DARTS discretizes the supernet to derive the optimal architecture based on architecture parameters. However, recent research has shown that during the training process, the supernet tends to converge towards sharp minima rather than flat minima. This is evidenced by the higher sharpness of the loss landscape of the supernet, which ultimately leads to a performance gap between the supernet and the optimal architecture. In this paper, we propose Self-Distillation Differentiable Neural Architecture Search (SD-DARTS) to alleviate the discretization gap. We utilize self-distillation to distill knowledge from previous steps of the supernet to guide its training in the current step, effectively reducing the sharpness of the supernet’s loss and bridging the performance gap between the supernet and the optimal architecture. Furthermore, we introduce the concept of voting teachers, where multiple previous supernets are selected as teachers, and their output probabilities are aggregated through voting to obtain the final teacher prediction. Experimental results on real datasets demonstrate the advantages of our novel self-distillation-based NAS method compared to state-of-the-art alternatives.},
  archive      = {J_NN},
  author       = {Xunyu Zhu and Jian Li and Yong Liu and Weiping Wang},
  doi          = {10.1016/j.neunet.2023.08.062},
  journal      = {Neural Networks},
  pages        = {656-667},
  shortjournal = {Neural Netw.},
  title        = {Improving differentiable architecture search via self-distillation},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive self-representation learning for data
clustering. <em>NN</em>, <em>167</em>, 648–655. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with self-representation subspace learning. It is one of the most representative subspace techniques, which has attracted considerable attention for clustering due to its good performance. Among these methods, low-rank representation (LRR) has achieved impressive results for subspace clustering. However, it only considers the similarity between the data itself, while neglecting the differences with other samples. Besides, it cannot well deal with noise and portray cluster-to-cluster relationships well. To solve these problems, we propose a Contrastive Self-representation model for Clustering (CSC). CSC simultaneously takes into account the similarity/dissimilarity between positive/negative pairs when learning the self-representation coefficient matrix of data while the form of the loss function can reduce the effect of noise on the results. Moreover, We use the ℓ 1 , 2 ℓ1,2 -norm regularizer on the coefficient matrix to achieve its sparsity to better characterize the cluster structure. Thus, the learned self-representation coefficient matrix well encodes both the discriminative information and cluster structure. Extensive experiments on seven benchmark databases indicate the superiority of our proposed method.},
  archive      = {J_NN},
  author       = {Wenhui Zhao and Quanxue Gao and Shikun Mei and Ming Yang},
  doi          = {10.1016/j.neunet.2023.08.050},
  journal      = {Neural Networks},
  pages        = {648-655},
  shortjournal = {Neural Netw.},
  title        = {Contrastive self-representation learning for data clustering},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual question generation for explicit questioning purposes
based on target objects. <em>NN</em>, <em>167</em>, 638–647. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question generation aims to focus on some target objects in an image to generate questions with certain questioning purposes. Existing studies mainly utilize an answer to extract the target object corresponding to the questioning purpose for questioning. However, answers fail to accurately and completely map to every target object, such as the objects corresponding to the answer are ambiguous or the answers are the relationship between multiple objects. To address this problem, we propose a content-controlled question generation model, which generates questions based on a given target object set specified from an image. Considering that the target objects have different contributions during the generation process, we design a recurrent generative architecture to explicitly control attention to different objects and their corresponding image information at each generative stage. Extensive experiments on the VQA v2.0 dataset and the Visual7w dataset show that the proposed model outperforms the state-of-the-art models and can controllably generate questions with specified content.},
  archive      = {J_NN},
  author       = {Jiayuan Xie and Jiali Chen and Wenhao Fang and Yi Cai and Qing Li},
  doi          = {10.1016/j.neunet.2023.08.007},
  journal      = {Neural Networks},
  pages        = {638-647},
  shortjournal = {Neural Netw.},
  title        = {Visual question generation for explicit questioning purposes based on target objects},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal multi-label learning for image classification.
<em>NN</em>, <em>167</em>, 626–637. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the problem of causal image classification with multi-label learning. As multi-label learning involves a diversity of supervision signals, it is considered a challenging issue to solve. Previous approaches have attempted to improve performance by identifying label-related image areas or exploiting the co-occurrence of labels. However, these methods are often characterized by complicated procedures, tedious computations, and a lack of intuitive interpretations. To overcome these limitations, we propose a novel approach that incorporates the concept of causal inference, which has been shown to be beneficial in other computer vision problems. Our method, called causal multi-label learning (CMLL), enables the selection of multiple objects from the original image through a multi-class attention module. These objects are then subjected to causal intervention to learn the causal relationships between different labels. Our proposed approach is both elegant and effective, with low computational cost and few parameters required for the multi-class causal intervention approach. Extensive tests and ablation studies demonstrate that the proposed method significantly improves prediction performance without a significant increase in training and inference times.},
  archive      = {J_NN},
  author       = {Yingjie Tian and Kunlong Bai and Xiaotong Yu and Siyu Zhu},
  doi          = {10.1016/j.neunet.2023.08.052},
  journal      = {Neural Networks},
  pages        = {626-637},
  shortjournal = {Neural Netw.},
  title        = {Causal multi-label learning for image classification},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical knowledge propagation and distillation for
few-shot learning. <em>NN</em>, <em>167</em>, 615–625. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research efforts on Few-Shot Learning (FSL) have achieved extensive progress. However, the existing efforts primarily focus on the transductive setting of FSL, which is heavily challenged by the limited quantity of the unlabeled query set. Although a few inductive-based FSL methods have been studied, most of them emphasize learning superb feature extraction networks . As a result, they may ignore the relations between sample-level and class-level representations, which are particularly crucial when labeled samples are scarce. This paper proposes an inductive FSL framework that leverages the Hierarchical Knowledge Propagation and Distillation, named HKPD. To learn more discriminative sample-level representations, HKPD first constructs a sample-level information propagation module that explores pairwise sample relations. Subsequently, a class-level information propagation module is designed to obtain and update the class-level information. Moreover, a self-distillation module is adopted to further improve the learned representations by propagating the obtained knowledge across this hierarchical architecture. Extensive experiments conducted on the commonly used few-shot benchmark datasets demonstrate the superiority of the proposed HKPD method, which outperforms the current state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Chunpeng Zhou and Haishuai Wang and Sheng Zhou and Zhi Yu and Danushka Bandara and Jiajun Bu},
  doi          = {10.1016/j.neunet.2023.08.040},
  journal      = {Neural Networks},
  pages        = {615-625},
  shortjournal = {Neural Netw.},
  title        = {Hierarchical knowledge propagation and distillation for few-shot learning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPCNet: Compressed multi-view video restoration via
motion-parallax complementation network. <em>NN</em>, <em>167</em>,
601–614. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance in restoring compressed multi-view video (MVV) of the existing learning-based methods is limited because they only utilize information of temporally adjacent frames or parallax neighboring views. However, the compression artifacts caused by multi-view coding (MVC) may be related to the reference errors of intra-frame, inter-frame, and inter-view. In this paper, with delicately utilizing the stereo information from both temporal and parallax domains, a motion-parallax complementation network (MPCNet) is proposed to restore the quality of compressed MVV more efficiently. First, we introduce a motion-parallax complementation strategy consisting of a coarse stage and a fine stage. By mutually compensating the feature extracted from multiple domains, useful multi-frame information can be efficiently preserved and aggregated step by step. Second, an attention-based feature filtering and modulation module (AFFM) is proposed, which provides an efficient fusion method for two features by suppressing misleading information. By deploying it in most submodules of the proposed approach, the representational ability of MPCNet can be improved, resulting in a more substantial restoration performance. Experimental results prove the effectiveness of MPCNet by an average increase of 1.978 dB in PSNR, and 0.0282 in MS-SSIM. The BD-rate reduction can reach 47.342\% on average. The subjective quality is greatly improved and lots of compression distortions are eliminated. Meanwhile, this work also benefits the accuracy improvement for high-level vision tasks, e.g., mIoU of semantic segmentation and mAP of object detection achieve 0.352 and 51.71, respectively. Quantitative and qualitative analyses demonstrate that MPCNet outperforms state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Chang Wu and Gang He and Xinquan Lai and Yunsong Li},
  doi          = {10.1016/j.neunet.2023.08.037},
  journal      = {Neural Networks},
  pages        = {601-614},
  shortjournal = {Neural Netw.},
  title        = {MPCNet: Compressed multi-view video restoration via motion-parallax complementation network},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive optimal control of affine nonlinear systems via
identifier–critic neural network approximation with relaxed PE
conditions. <em>NN</em>, <em>167</em>, 588–600. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an optimal control of an affine nonlinear system with unknown system dynamics . A new identifier–critic framework is proposed to solve the optimal control problem . Firstly, a neural network identifier is built to estimate the unknown system dynamics, and a critic NN is constructed to solve the Hamiltonian–Jacobi–Bellman equation associated with the optimal control problem. A dynamic regressor extension and mixing technique is applied to design the weight update laws with relaxed persistence of excitation conditions for the two classes of neural networks. The parameter estimation of the update laws and the stability of the closed-loop system under the adaptive optimal control are analyzed using a Lyapunov function method. Numerical simulation results are presented to demonstrate the effectiveness of the proposed IC learning based optimal control algorithm for the affine nonlinear system.},
  archive      = {J_NN},
  author       = {Rui Luo and Zhinan Peng and Jiangping Hu and Bijoy Kumar Ghosh},
  doi          = {10.1016/j.neunet.2023.08.044},
  journal      = {Neural Networks},
  pages        = {588-600},
  shortjournal = {Neural Netw.},
  title        = {Adaptive optimal control of affine nonlinear systems via identifier–critic neural network approximation with relaxed PE conditions},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chaos and multi-layer attractors in asymmetric neural
networks coupled with discrete fractional memristor. <em>NN</em>,
<em>167</em>, 572–587. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel model of asymmetric neural networks combined with fractional difference memristors , which has both theoretical and practical implications in the rapidly evolving field of computational intelligence. The proposed model includes two types of fractional difference memristor elements: one with hyperbolic tangent memductance and the other with periodic memductance and memristor state described by sine functions . The authenticity of the constructed memristor is confirmed through fingerprint verification. The research extensively investigates the dynamics of a coupled neural network model, analyzing its stability at equilibrium states, studying bifurcation diagrams , and calculating the largest Lyapunov exponents . The results suggest that when incorporating sine memristors , the model demonstrates coexisting state variables depending on the initial conditions, revealing the emergence of multi-layer attractors. The article further demonstrates how the memristor state shifts through numerical simulations with varying memductance values. Notably, the study emphasizes the crucial role of memductance (synaptic weight) in determining the complex dynamical characteristics of neural network systems. To support the analytical results and demonstrate the chaotic response of state variables, the article includes appropriate numerical simulations. These simulations effectively validate the presented findings and provide concrete evidence of the system’s chaotic behavior .},
  archive      = {J_NN},
  author       = {Shaobo He and D. Vignesh and Lamberto Rondoni and Santo Banerjee},
  doi          = {10.1016/j.neunet.2023.08.041},
  journal      = {Neural Networks},
  pages        = {572-587},
  shortjournal = {Neural Netw.},
  title        = {Chaos and multi-layer attractors in asymmetric neural networks coupled with discrete fractional memristor},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On exploring node-feature and graph-structure diversities
for node drop graph pooling. <em>NN</em>, <em>167</em>, 559–571. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been successfully applied to graph-level tasks in various fields such as biology, social networks, computer vision , and natural language processing . For the graph-level representations learning of GNNs, graph pooling plays an essential role. Among many pooling techniques, node drop pooling has garnered significant attention and is considered as a leading approach. However, existing node drop pooling methods, which typically retain the top-k nodes based on their significance scores, often overlook the diversity inherent in node features and graph structures. This limitation leads to suboptimal graph-level representations. To overcome this, we introduce a groundbreaking plug-and-play score scheme, termed MID. MID comprises a M ultidimensional score space and two key operations: fl I pscore and D ropscore. The multidimensional score space depicts the significance of nodes by multiple criteria; the flipscore process promotes the preservation of distinct node features; the dropscore compels the model to take into account a range of graph structures rather than focusing on local structures. To evaluate the effectiveness of our proposed MID, we have conducted extensive experiments by integrating it with a broad range of recent node drop pooling methods, such as TopKPool, SAGPool, GSAPool, and ASAP. In particular, MID has proven to bring a significant average improvement of approximately 2.8\% over the four aforementioned methods when tested on 17 real-world graph classification datasets. Code is available at https://github.com/whuchuang/mid .},
  archive      = {J_NN},
  author       = {Chuang Liu and Yibing Zhan and Baosheng Yu and Liu Liu and Bo Du and Wenbin Hu and Tongliang Liu},
  doi          = {10.1016/j.neunet.2023.08.046},
  journal      = {Neural Networks},
  pages        = {559-571},
  shortjournal = {Neural Netw.},
  title        = {On exploring node-feature and graph-structure diversities for node drop graph pooling},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Glimpse and focus: Global and local-scale graph convolution
network for skeleton-based action recognition. <em>NN</em>,
<em>167</em>, 551–558. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the 3D skeleton-based action recognition task, learning rich spatial and temporal motion patterns from body joints are two foundational yet under-explored problems. In this paper, we propose two methods for improving these problems: (I) a novel glimpse-focus action recognition strategy that captures multi-range pose features from the whole body and key body parts jointly; (II) a powerful temporal feature extractor JD-TC that enriches trajectory features by inferring different inter-frame correlations for different joints . By coupling these two proposals, we develop a powerful skeleton-based action recognition system that extracts rich pose and trajectory features from a skeleton sequence and outperforms previous state-of-the-art methods on three large-scale datasets.},
  archive      = {J_NN},
  author       = {Xuehao Gao and Shaoyi Du and Yang Yang},
  doi          = {10.1016/j.neunet.2023.07.051},
  journal      = {Neural Networks},
  pages        = {551-558},
  shortjournal = {Neural Netw.},
  title        = {Glimpse and focus: Global and local-scale graph convolution network for skeleton-based action recognition},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PEPNet: A barotropic primitive equations-based network for
wind speed prediction. <em>NN</em>, <em>167</em>, 533–550. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wind speed prediction technologies , deep learning-based methods have achieved promising advantages. However, most existing methods focus on learning implicit knowledge in a data-driven manner but neglect some explicit knowledge from the physical theory of meteorological dynamics, failing to make stable and long-term predictions. In this paper, we explore introducing explicit physical knowledge into neural networks and propose Physical Equations Predictive Network (PEPNet) for multi-step wind speed predictions. In PEPNet, a new neural block called the Augmented Neural Barotropic Equations (ANBE) block is designed as its key component, which aims to capture the wind dynamics by combining barotropic primitive equations and deep neural networks . Specifically, the ANBE block adopts a two-branch structure to model wind dynamics, where one branch is physic-based and the other is data-driven-based. The physic-based branch constructs temporal partial derivatives of meteorological elements (including u-component wind, v-component wind, and geopotential height) in a new Neural Barotropic Equations Unit (NBEU). The NBEU is developed based on the barotropic primitive equations mode in numerical weather prediction (NWP). Besides, considering that the barotropic primitive mode is a crude assumption of atmospheric motion, another data-driven-based branch is developed in the ANBE block, which aims at capturing meteorological dynamics beyond barotropic primitive equations. Finally, the PEPNet follows a time-variant structure to enhance the model’s capability to capture wind dynamics over time. To evaluate the predictive performance of PEPNet, we have conducted several experiments on two real-world datasets. Experimental results show that the proposed method outperforms the state-of-the-art techniques and achieve optimal performance.},
  archive      = {J_NN},
  author       = {Rui Ye and Baoquan Zhang and Xutao Li and Yunming Ye},
  doi          = {10.1016/j.neunet.2023.08.042},
  journal      = {Neural Networks},
  pages        = {533-550},
  shortjournal = {Neural Netw.},
  title        = {PEPNet: A barotropic primitive equations-based network for wind speed prediction},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DEBI-NN: Distance-encoding biomorphic-informational neural
networks for minimizing the number of trainable parameters. <em>NN</em>,
<em>167</em>, 517–532. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern artificial intelligence (AI) approaches mainly rely on neural network (NN) or deep NN methodologies. However, these approaches require large amounts of data to train, given, that the number of their trainable parameters has a polynomial relationship to their neuron counts. This property renders deep NNs challenging to apply in fields operating with small, albeit representative datasets such as healthcare. In this paper, we propose a novel neural network architecture which trains spatial positions of neural soma and axon pairs, where weights are calculated by axon-soma distances of connected neurons. We refer to this method as distance-encoding biomorphic-informational (DEBI) neural network. This concept significantly minimizes the number of trainable parameters compared to conventional neural networks. We demonstrate that DEBI models can yield comparable predictive performance in tabular and imaging datasets, where they require a fraction of trainable parameters compared to conventional NNs, resulting in a highly scalable solution.},
  archive      = {J_NN},
  author       = {Laszlo Papp and David Haberl and Boglarka Ecsedi and Clemens P. Spielvogel and Denis Krajnc and Marko Grahovac and Sasan Moradi and Wolfgang Drexler},
  doi          = {10.1016/j.neunet.2023.08.026},
  journal      = {Neural Networks},
  pages        = {517-532},
  shortjournal = {Neural Netw.},
  title        = {DEBI-NN: Distance-encoding biomorphic-informational neural networks for minimizing the number of trainable parameters},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CollectiveNet-AltSpec: A collective concurrent CNN
architecture of alternate specifications for EEG media perception and
emotion tracing aided by multi-domain feature-augmentation. <em>NN</em>,
<em>167</em>, 502–516. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing computability of cerebral recordings and connections made with human/non-human brain have been on track and are expected to propel in our current era. An effective contribution towards said ends is improving accuracy of attempts at discerning intricate phenomena taking place within human brain. Here and in two different capacities of experiments, we attempt to distinguish cerebral perceptions shaped and affective states surfaced during observation of samples of media incorporating distinct audio–visual and emotional contents, through employing electroencephalograph/EEG recorded sessions of two reputable datasets of DEAP and SEED. Here we introduce AltSpec(E3) the inceptive form of CollectiveNet intelligent computational architectures employing collective and concurrent multi-spec analysis to exploit complex patterns in complex data-structures. This processing technique uses a full array of diversification protocols with multifarious parts enabling surgical levels of optimization while integrating a holistic analysis of patterns. Data-structures designed here contain multi-electrode neuroinformatic and neurocognitive features studying emotion reactions and attentive patterns. These spatially and temporally featured 2D/3D constructs of domain-augmented data are eventually AI-processed and outputs are defragmented forming one definitive judgement. The media-perception tracing is arguably first of its kind, at least when implemented on mentioned datasets. Backed by this multi-directional approach and in subject-independent configurations for perception-tracing on 5-media-class basis, mean accuracies of 81.00\% and 68.93\% were obtained on DEAP and SEED, respectively. We also managed to classify emotions with accuracies of 61.59\% and 66.21\% in cross-dataset validation followed by 81.47\% and 88.12\% in cross-subject validation settings trained on DEAP and SEED, consecutively.},
  archive      = {J_NN},
  author       = {Parham Faraji and Mohammad Bagher Khodabakhshi},
  doi          = {10.1016/j.neunet.2023.08.031},
  journal      = {Neural Networks},
  pages        = {502-516},
  shortjournal = {Neural Netw.},
  title        = {CollectiveNet-AltSpec: A collective concurrent CNN architecture of alternate specifications for EEG media perception and emotion tracing aided by multi-domain feature-augmentation},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditioned cooperative training for semi-supervised weapon
detection. <em>NN</em>, <em>167</em>, 489–501. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Violent assaults and homicides occur daily, and the number of victims of mass shootings increases every year. However, this number can be reduced with the help of Closed Circuit Television (CCTV) and weapon detection models, as generic object detectors have become increasingly accurate with more data for training. We present a new semi-supervised learning methodology based on conditioned cooperative student–teacher training with optimal pseudo-label generation using a novel confidence threshold search method and improving both models by conditional knowledge transfer. Furthermore, a novel firearms image dataset of 458,599 images was collected using Instagram hashtags to evaluate our approach and compare the improvements obtained using a specific unsupervised dataset instead of a general one such as ImageNet. We compared our methodology with supervised, semi-supervised and self-supervised learning techniques, outperforming approaches such as YOLOv5 m (up to ＋19.86), YOLOv5l (up to ＋6.52) Unbiased Teacher (up to ＋10.5 AP), DETReg (up to ＋2.8 AP) and UP-DETR (up to ＋1.22 AP).},
  archive      = {J_NN},
  author       = {Jose L. Salazar González and Juan A. Álvarez-García and Fernando J. Rendón-Segador and Fabio Carrara},
  doi          = {10.1016/j.neunet.2023.08.043},
  journal      = {Neural Networks},
  pages        = {489-501},
  shortjournal = {Neural Netw.},
  title        = {Conditioned cooperative training for semi-supervised weapon detection},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A large-scale neurocomputational model of spatial cognition
integrating memory with vision. <em>NN</em>, <em>167</em>, 473–488. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a large-scale neurocomputational model of spatial cognition called ’Spacecog’, which integrates recent findings from mechanistic models of visual and spatial perception. As a high-level cognitive ability, spatial cognition requires the processing of behaviourally relevant features in complex environments and, importantly, the updating of this information during processes of eye and body movement. The Spacecog model achieves this by interfacing spatial memory and imagery with mechanisms of object localisation , saccade execution, and attention through coordinate transformations in parietal areas of the brain. We evaluate the model in a realistic virtual environment where our neurocognitive model steers an agent to perform complex visuospatial tasks. Our modelling approach opens up new possibilities in the assessment of neuropsychological data and human spatial cognition.},
  archive      = {J_NN},
  author       = {Micha Burkhardt and Julia Bergelt and Lorenz Gönner and Helge Ülo Dinkelbach and Frederik Beuth and Alex Schwarz and Andrej Bicanski and Neil Burgess and Fred H. Hamker},
  doi          = {10.1016/j.neunet.2023.08.034},
  journal      = {Neural Networks},
  pages        = {473-488},
  shortjournal = {Neural Netw.},
  title        = {A large-scale neurocomputational model of spatial cognition integrating memory with vision},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Communication-efficient federated learning with stagewise
training strategy. <em>NN</em>, <em>167</em>, 460–472. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of communication across workers is a significant factor that affects the performance of federated learning . Though periodic communication strategy is applied to reduce communication rounds in training, the communication cost is still high when the training data distributions are not independently and identically distributed (non-IID) which is common in federated learning . Recently, some works introduce variance reduction to eliminate the effect caused by non-IID data among workers. Nevertheless the provable optimal communication complexity O ( log ( S T ) ) O(log(ST)) and convergence rate O ( 1 / ( S T ) ) O(1/(ST)) cannot be achieved simultaneously, where S S denotes the number of sampled workers in each round and T T is the number of iterations. To deal with this dilemma, we propose an optimization algorithm SQUARFA that adopts stagewise training framework coupling with variance reduction and uses a quick-start phase in each loop. Theoretical results show that SQUARFA achieves both optimal convergence rate and communication complexity for both strongly convex objectives and non-convex objectives under PL condition, thus fills the gap mentioned above. Then, a variant of SQUARFA yields the optimal theoretical results for general non-convex objectives. We further extend the technique in SQUARFA to the large batch setting and achieve optimal communication complexity. Experimental results demonstrate the superiority of the proposed algorithms.},
  archive      = {J_NN},
  author       = {Yifei Cheng and Shuheng Shen and Xianfeng Liang and Jingchang Liu and Joya Chen and Tie Zhang and Enhong Chen},
  doi          = {10.1016/j.neunet.2023.08.033},
  journal      = {Neural Networks},
  pages        = {460-472},
  shortjournal = {Neural Netw.},
  title        = {Communication-efficient federated learning with stagewise training strategy},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LJIR: Learning joint-action intrinsic reward in cooperative
multi-agent reinforcement learning. <em>NN</em>, <em>167</em>, 450–459.
(<a href="https://doi.org/10.1016/j.neunet.2023.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective exploration is the key to achieving high returns for reinforcement learning . Agents must explore jointly in multi-agent systems to find the optimal joint policy. Due to the exploration problem and the shared reward, the policy-based multi-agent reinforcement learning algorithms face policy overfitting, which may lead to the joint policy falling into a local optimum. This paper introduces a novel general framework called Learning Joint-Action Intrinsic Reward (LJIR) for improving multi-agent reinforcement learners’ joint exploration ability and performance. LJIR observes agents’ state and joint actions to learn to construct an intrinsic reward online that can guide effective joint exploration. With the novel combination of Transformer and random network distillation, LJIR selects the novel states to give more intrinsic rewards, which help agents find the best joint actions. LJIR can dynamically adjust the weight of exploration and exploitation during training and keep the policy invariance finally. To ensure LJIR seamlessly adopts existing MARL algorithms, we also provide a flexible combination method for intrinsic and external rewards. Empirical results on the SMAC benchmark show that the proposed method achieves state-of-the-art performance in challenging tasks.},
  archive      = {J_NN},
  author       = {Zihan Chen and Biao Luo and Tianmeng Hu and Xiaodong Xu},
  doi          = {10.1016/j.neunet.2023.08.016},
  journal      = {Neural Networks},
  pages        = {450-459},
  shortjournal = {Neural Netw.},
  title        = {LJIR: Learning joint-action intrinsic reward in cooperative multi-agent reinforcement learning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information theoretic perspective on sample complexity.
<em>NN</em>, <em>167</em>, 445–449. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The statistical supervised learning framework assumes an input–output set with a joint probability distribution that is reliably represented by the training dataset. The learning system is then required to output a prediction rule learned from the training dataset’s input–output pairs. In this work, we investigate the relationship between the sample complexity, the empirical risk and the generalization error based on the asymptotic equipartition property (AEP) (Shannon, 1948). We provide theoretical guarantees for reliable learning under the information-theoretic AEP, with respect to the generalization error and the sample size in different settings.},
  archive      = {J_NN},
  author       = {Deborah Pereg},
  doi          = {10.1016/j.neunet.2023.08.032},
  journal      = {Neural Networks},
  pages        = {445-449},
  shortjournal = {Neural Netw.},
  title        = {Information theoretic perspective on sample complexity},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Word self-update contrastive adversarial networks for
text-to-image synthesis. <em>NN</em>, <em>167</em>, 433–444. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthesizing realistic fine-grained images from text descriptions is a significant computer vision task. Although many GANs-based methods have been proposed to solve this task, generating high-quality images consistent with text information remains a difficult problem. These existing GANs-based methods ignore important words due to the use of fixed initial word features in generator, and neglect to learn semantic consistency between images and texts for discriminators . In this article, we propose a novel attentional generation and contrastive adversarial framework for fine-grained text-to-image synthesis, termed as Word Self-Update Contrastive Adversarial Networks (WSC-GAN). Specifically, we introduce a dual attention module for modeling color details and semantic information. With a new designed word self-update module, the generator can leverage visually important words to compute attention maps in the feature synthesis module. Furthermore, we contrive multi-branch contrastive discriminators to maintain better consistency between the generated image and text description. Two novel contrastive losses are proposed for our discriminators to impose image-sentence and image-word consistency constraints. Extensive experiments on CUB and MS-COCO datasets demonstrate that our method achieves better performance compared with state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Jian Xiao and Yiwen Sun and Xiaojun Bi},
  doi          = {10.1016/j.neunet.2023.08.038},
  journal      = {Neural Networks},
  pages        = {433-444},
  shortjournal = {Neural Netw.},
  title        = {Word self-update contrastive adversarial networks for text-to-image synthesis},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information theory-guided heuristic progressive multi-view
coding. <em>NN</em>, <em>167</em>, 415–432. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view representation learning aims to capture comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning to different views in a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; evenly measuring the similarities between terms might interfere with optimization. Importantly, few works study the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the perspective of information theory and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided heuristic Progressive Multi-view Coding (IPMC). In the distribution-tier , IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier , IPMC constructs self-adjusted contrasting pools, which are adaptively modified by a view filter. Lastly, in the instance-tier , we adopt a designed unified loss to learn representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Jiangmeng Li and Hang Gao and Wenwen Qiang and Changwen Zheng},
  doi          = {10.1016/j.neunet.2023.08.027},
  journal      = {Neural Networks},
  pages        = {415-432},
  shortjournal = {Neural Netw.},
  title        = {Information theory-guided heuristic progressive multi-view coding},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel feature-scrambling approach reveals the capacity of
convolutional neural networks to learn spatial relations. <em>NN</em>,
<em>167</em>, 400–414. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are one of the most successful computer vision systems to solve object recognition. Furthermore, CNNs have major applications in understanding the nature of visual representations in the human brain. Yet it remains poorly understood how CNNs actually make their decisions, what the nature of their internal representations is, and how their recognition strategies differ from humans. Specifically, there is a major debate about the question of whether CNNs primarily rely on surface regularities of objects, or whether they are capable of exploiting the spatial arrangement of features, similar to humans. Here, we develop a novel feature-scrambling approach to explicitly test whether CNNs use the spatial arrangement of features (i.e. object parts) to classify objects. We combine this approach with a systematic manipulation of effective receptive field sizes of CNNs as well as minimal recognizable configurations (MIRCs) analysis. In contrast to much previous literature, we provide evidence that CNNs are in fact capable of using relatively long-range spatial relationships for object classification. Moreover, the extent to which CNNs use spatial relationships depends heavily on the dataset, e.g. texture vs. sketch. In fact, CNNs even use different strategies for different classes within heterogeneous datasets (ImageNet), suggesting CNNs have a continuous spectrum of classification strategies. Finally, we show that CNNs learn the spatial arrangement of features only up to an intermediate level of granularity, which suggests that intermediate rather than global shape features provide the optimal trade-off between sensitivity and specificity in object classification. These results provide novel insights into the nature of CNN representations and the extent to which they rely on the spatial arrangement of features for object classification.},
  archive      = {J_NN},
  author       = {Amr Farahat and Felix Effenberger and Martin Vinck},
  doi          = {10.1016/j.neunet.2023.08.021},
  journal      = {Neural Networks},
  pages        = {400-414},
  shortjournal = {Neural Netw.},
  title        = {A novel feature-scrambling approach reveals the capacity of convolutional neural networks to learn spatial relations},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple-instance ensemble for construction of deep
heterogeneous committees for high-dimensional low-sample-size data.
<em>NN</em>, <em>167</em>, 380–399. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep ensemble learning , where we combine knowledge learned from multiple individual neural networks , has been widely adopted to improve the performance of neural networks in deep learning . This field can be encompassed by committee learning, which includes the construction of neural network cascades. This study focuses on the high-dimensional low-sample-size (HDLS) domain and introduces multiple instance ensemble (MIE) as a novel stacking method for ensembles and cascades. In this study, our proposed approach reformulates the ensemble learning process as a multiple-instance learning problem. We utilise the multiple-instance learning solution of pooling operations to associate feature representations of base neural networks into joint representations as a method of stacking. This study explores various attention mechanisms and proposes two novel committee learning strategies with MIE. In addition, we utilise the capability of MIE to generate pseudo-base neural networks to provide a proof-of-concept for a “growing” neural network cascade that is unbounded by the number of base neural networks. We have shown that our approach provides (1) a class of alternative ensemble methods that performs comparably with various stacking ensemble methods and (2) a novel method for the generation of high-performing “growing” cascades. The approach has also been verified across multiple HDLS datasets, achieving high performance for binary classification tasks in the low-sample size regime.},
  archive      = {J_NN},
  author       = {Qinghua Zhou and Shuihua Wang and Hengde Zhu and Xin Zhang and Yudong Zhang},
  doi          = {10.1016/j.neunet.2023.08.028},
  journal      = {Neural Networks},
  pages        = {380-399},
  shortjournal = {Neural Netw.},
  title        = {Multiple-instance ensemble for construction of deep heterogeneous committees for high-dimensional low-sample-size data},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning dynamic spatial-temporal regularized correlation
filter tracking with response deviation suppression via multi-feature
fusion. <em>NN</em>, <em>167</em>, 360–379. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking (VOT) for intelligent video surveillance has attracted great attention in the current research community, thanks to advances in computer vision and camera technology. Meanwhile, discriminative correlation filter (DCF) trackers garnered significant interest owing to their high accuracy and low computing cost. Many researchers have introduced spatial and temporal regularization into the DCF framework to achieve a more robust appearance model and further improve tracking performance. However, these algorithms typically set fixed spatial and temporal regularization parameters, which limit flexibility and adaptability under cluttered and challenging scenarios. To overcome these problems, in this work, we propose a new dynamic spatial–temporal regularization for the DCF tracking model that emphasizes the filter to concentrate on more reliable regions during the training stage. Furthermore, we present a response deviation-suppressed regularization term for responses to encourage temporal consistency and avoid model degradation by suppressing relative response changes between two consecutive frames. Moreover, we introduce a multi-memory tracking framework to exploit various features and each memory contributes to tracking the target across all frames. Significant experiments on the OTB-2013, OTB-2015, TC-128, UAV-123, UAVDT, and DTB-70 datasets have revealed that the performance thereof outperformed many state-of-the-art trackers based on DCF and deep-based frameworks in terms of tracking accuracy and tracking success rate.},
  archive      = {J_NN},
  author       = {Sathishkumar Moorthy and Young Hoon Joo},
  doi          = {10.1016/j.neunet.2023.08.019},
  journal      = {Neural Networks},
  pages        = {360-379},
  shortjournal = {Neural Netw.},
  title        = {Learning dynamic spatial-temporal regularized correlation filter tracking with response deviation suppression via multi-feature fusion},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metaheuristics optimization-based ensemble of deep neural
networks for mpox disease detection. <em>NN</em>, <em>167</em>, 342–359.
(<a href="https://doi.org/10.1016/j.neunet.2023.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising number of cases of human Mpox has emerged as a major global concern due to the daily increase of cases in several countries. The disease presents various skin symptoms in infected individuals, making it crucial to promptly identify and isolate them to prevent widespread community transmission. Rapid determination and isolation of infected individuals are therefore essential to curb the spread of the disease. Most research in the detection of Mpox disease has utilized convolutional neural network (CNN) models and ensemble methods . However, to the best of our knowledge, none have utilized a meta-heuristic-based ensemble approach. To address this gap, we propose a novel metaheuristics optimization-based weighted average ensemble model (MO-WAE) for detecting Mpox disease. We first train three transfer learning (TL)-based CNNs (DenseNet201, MobileNet, and DenseNet169) by adding additional layers to improve their classification strength. Next, we use a weighted average ensemble technique to fuse the predictions from each individual model, and the particle swarm optimization (PSO) algorithm is utilized to assign optimized weights to each model during the ensembling process. By using this approach, we obtain more accurate predictions than individual models. To gain a better understanding of the regions indicating the onset of Mpox, we performed a Gradient Class Activation Mapping (Grad-CAM) analysis to explain our model’s predictions. Our proposed MO-WAE ensemble model was evaluated on a publicly available Mpox dataset and achieved an impressive accuracy of 97.78\%. This outperforms state-of-the-art (SOTA) methods on the same dataset, thereby providing further evidence of the efficacy of our proposed model.},
  archive      = {J_NN},
  author       = {Sohaib Asif and Ming Zhao and Fengxiao Tang and Yusen Zhu and Baokang Zhao},
  doi          = {10.1016/j.neunet.2023.08.035},
  journal      = {Neural Networks},
  pages        = {342-359},
  shortjournal = {Neural Netw.},
  title        = {Metaheuristics optimization-based ensemble of deep neural networks for mpox disease detection},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive dynamic programming-based hierarchical
decision-making of non-affine systems. <em>NN</em>, <em>167</em>,
331–341. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of multiplayer hierarchical decision-making problem for non-affine systems is solved by adaptive dynamic programming. Firstly, the control dynamics are obtained according to the theory of dynamic feedback and combined with the original system dynamics to construct the affine augmented system . Thus, the non-affine multiplayer system is transformed into a general affine form. Then, the hierarchical decision problem is modeled as a Stackelberg game . In the Stackelberg game , the leader makes a decision based on the information of all followers, whereas the followers do not know each other’s information and only obtain their optimal control strategy based on the leader’s decision. Then, the augmented system is reconstructed by a neural network (NN) using input–output data. Moreover, a single critic NN is used to approximate the value function to obtain the optimal control strategy for each player. An extra term added to the weight update law makes the initial admissible control law no longer needed. According to the Lyapunov theory , the state of the system and the error of the weights of the NN are both uniformly ultimately bounded. Finally, the feasibility and validity of the algorithm are confirmed by simulation.},
  archive      = {J_NN},
  author       = {Danyu Lin and Shan Xue and Derong Liu and Mingming Liang and Yonghua Wang},
  doi          = {10.1016/j.neunet.2023.07.044},
  journal      = {Neural Networks},
  pages        = {331-341},
  shortjournal = {Neural Netw.},
  title        = {Adaptive dynamic programming-based hierarchical decision-making of non-affine systems},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Layer adaptive node selection in bayesian neural networks:
Statistical guarantees and implementation details. <em>NN</em>,
<em>167</em>, 309–330. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse deep neural networks have proven to be efficient for predictive model building in large-scale studies. Although several works have studied theoretical and numerical properties of sparse neural architectures, they have primarily focused on the edge selection. Sparsity through edge selection might be intuitively appealing; however, it does not necessarily reduce the structural complexity of a network. Instead pruning excessive nodes leads to a structurally sparse network with significant computational speedup during inference. To this end, we propose a Bayesian sparse solution using spike-and-slab Gaussian priors to allow for automatic node selection during training. The use of spike-and-slab prior alleviates the need of an ad-hoc thresholding rule for pruning. In addition, we adopt a variational Bayes approach to circumvent the computational challenges of traditional Markov Chain Monte Carlo (MCMC) implementation. In the context of node selection, we establish the fundamental result of variational posterior consistency together with the characterization of prior parameters. In contrast to the previous works, our theoretical development relaxes the assumptions of the equal number of nodes and uniform bounds on all network weights, thereby accommodating sparse networks with layer-dependent node structures or coefficient bounds. With a layer-wise characterization of prior inclusion probabilities , we discuss the optimal contraction rates of the variational posterior. We empirically demonstrate that our proposed approach outperforms the edge selection method in computational complexity with similar or better predictive performance . Our experimental evidence further substantiates that our theoretical work facilitates layer-wise optimal node recovery.},
  archive      = {J_NN},
  author       = {Sanket Jantre and Shrijita Bhattacharya and Tapabrata Maiti},
  doi          = {10.1016/j.neunet.2023.08.029},
  journal      = {Neural Networks},
  pages        = {309-330},
  shortjournal = {Neural Netw.},
  title        = {Layer adaptive node selection in bayesian neural networks: Statistical guarantees and implementation details},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid learning mechanisms under a neural control network
for various walking speed generation of a quadruped robot. <em>NN</em>,
<em>167</em>, 292–308. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robots that can instantly change motor patterns at different walking speeds are useful and can accomplish various tasks efficiently. However, state-of-the-art control methods either are difficult to develop or require long training times. In this study, we present a comprehensible neural control framework to integrate probability-based black-box optimization ( PI BB PIBB ) and supervised learning for robot motor pattern generation at various walking speeds. The control framework structure is based on a combination of a central pattern generator (CPG), a radial basis function (RBF) -based premotor network and a hypernetwork, resulting in a so-called neural CPG-RBF-hyper control network. First, the CPG-driven RBF network, acting as a complex motor pattern generator , was trained to learn policies (multiple motor patterns) for different speeds using PI BB PIBB . We also introduce an incremental learning strategy to avoid local optima. Second, the hypernetwork, which acts as a task/behavior to control parameter mapping, was trained using supervised learning. It creates a mapping between the internal CPG frequency (reflecting the walking speed) and motor behavior . This map represents the prior knowledge of the robot, which contains the optimal motor joint patterns at various CPG frequencies. Finally, when a user-defined robot walking frequency or speed is provided, the hypernetwork generates the corresponding policy for the CPG-RBF network. The result is a versatile locomotion controller which enables a quadruped robot to perform stable and robust walking at different speeds without sensory feedback. The policy of the controller was trained in the simulation (less than 1 h h ) and capable of transferring to a real robot. The generalization ability of the controller was demonstrated by testing the CPG frequencies that were not encountered during training.},
  archive      = {J_NN},
  author       = {Yanbin Zhang and Mathias Thor and Nat Dilokthanakul and Zhendong Dai and Poramate Manoonpong},
  doi          = {10.1016/j.neunet.2023.08.030},
  journal      = {Neural Networks},
  pages        = {292-308},
  shortjournal = {Neural Netw.},
  title        = {Hybrid learning mechanisms under a neural control network for various walking speed generation of a quadruped robot},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bidirectionally self-normalizing neural networks.
<em>NN</em>, <em>167</em>, 283–291. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of vanishing and exploding gradients has been a long-standing obstacle that hinders the effective training of neural networks . Despite various tricks and techniques that have been employed to alleviate the problem in practice, there still lacks satisfactory theories or provable solutions. In this paper, we address the problem from the perspective of high-dimensional probability theory . We provide a rigorous result that shows, under mild conditions, how the vanishing/exploding gradients problem disappears with high probability if the neural networks have sufficient width. Our main idea is to constrain both forward and backward signal propagation in a nonlinear neural network through a new class of activation functions , namely Gaussian–Poincaré normalized functions, and orthogonal weight matrices . Experiments on both synthetic and real-world data validate our theory and confirm its effectiveness on very deep neural networks when applied in practice.},
  archive      = {J_NN},
  author       = {Yao Lu and Stephen Gould and Thalaiyasingam Ajanthan},
  doi          = {10.1016/j.neunet.2023.08.017},
  journal      = {Neural Networks},
  pages        = {283-291},
  shortjournal = {Neural Netw.},
  title        = {Bidirectionally self-normalizing neural networks},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridged adversarial training. <em>NN</em>, <em>167</em>,
266–282. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial robustness is considered a required property of deep neural networks . In this study, we discover that adversarially trained models might have significantly different characteristics in terms of margin and smoothness, even though they show similar robustness. Inspired by the observation, we investigate the effect of different regularizers and discover the negative effect of the smoothness regularizer on maximizing the margin. Based on the analyses, we propose a new method called bridged adversarial training that mitigates the negative effect by bridging the gap between clean and adversarial examples . We provide theoretical and empirical evidence that the proposed method provides stable and better robustness, especially for large perturbations.},
  archive      = {J_NN},
  author       = {Hoki Kim and Woojin Lee and Sungyoon Lee and Jaewook Lee},
  doi          = {10.1016/j.neunet.2023.08.024},
  journal      = {Neural Networks},
  pages        = {266-282},
  shortjournal = {Neural Netw.},
  title        = {Bridged adversarial training},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multilayered bidirectional associative memory model for
learning nonlinear tasks. <em>NN</em>, <em>167</em>, 244–265. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multilayered bidirectional associative memory neural network is proposed to account for learning nonlinear types of association. The model (denoted as the MF-BAM) is composed of two modules, the Multi-Feature extracting bidirectional associative memory (MF), which contains various unsupervised network layers, and a modified Bidirectional Associative Memory (BAM), which consists of a single supervised network layer. The MF generates successive feature patterns from the original inputs. These patterns change the relationship between the inputs and targets in a way that the BAM can learn. The model was tested on different nonlinear tasks, such as the N -bit, Double Moon and its variants, and the 3-class spiral task. Behaviors were reported through learning errors, decision zones, and recall performances. Results showed that it was possible to learn all tasks consistently. By manipulating the number of units per layer and the number of unsupervised network layers in the MF, it was possible to change the level of nonlinearity observed in the decision boundaries. Furthermore, results indicated that different behaviors were achieved from the same set of inputs by using the different generated patterns. These findings are significant as they showed how a BAM-inspired model could solve nonlinear tasks in a more cognitively plausible fashion.},
  archive      = {J_NN},
  author       = {Damiem Rolon-Mérette and Thaddé Rolon-Mérette and Sylvain Chartier},
  doi          = {10.1016/j.neunet.2023.08.018},
  journal      = {Neural Networks},
  pages        = {244-265},
  shortjournal = {Neural Netw.},
  title        = {A multilayered bidirectional associative memory model for learning nonlinear tasks},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning domain invariant representations by joint
wasserstein distance minimization. <em>NN</em>, <em>167</em>, 233–243.
(<a href="https://doi.org/10.1016/j.neunet.2023.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain shifts in the training data are common in practical applications of machine learning ; they occur for instance when the data is coming from different sources. Ideally, a ML model should work well independently of these shifts, for example, by learning a domain-invariant representation. However, common ML losses do not give strong guarantees on how consistently the ML model performs for different domains, in particular, whether the model performs well on a domain at the expense of its performance on another domain. In this paper, we build new theoretical foundations for this problem, by contributing a set of mathematical relations between classical losses for supervised ML and the Wasserstein distance in joint space (i.e. representation and output space). We show that classification or regression losses, when combined with a GAN-type discriminator between domains, form an upper-bound to the true Wasserstein distance between domains. This implies a more invariant representation and also more stable prediction performance across domains. Theoretical results are corroborated empirically on several image datasets. Our proposed approach systematically produces the highest minimum classification accuracy across domains, and the most invariant representation.},
  archive      = {J_NN},
  author       = {Léo Andéol and Yusei Kawakami and Yuichiro Wada and Takafumi Kanamori and Klaus-Robert Müller and Grégoire Montavon},
  doi          = {10.1016/j.neunet.2023.07.028},
  journal      = {Neural Networks},
  pages        = {233-243},
  shortjournal = {Neural Netw.},
  title        = {Learning domain invariant representations by joint wasserstein distance minimization},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised contrastive graph representation with node
and graph augmentation. <em>NN</em>, <em>167</em>, 223–232. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation is a critical technology in the field of knowledge engineering and knowledge-based applications since most knowledge bases are represented in the graph structure. Nowadays, contrastive learning has become a prominent way for graph representation by contrasting positive–positive and positive–negative node pairs between two augmentation graphs. It has achieved new state-of-the-art in the field of self-supervised graph representation. However, existing contrastive graph representation methods mainly focus on modifying (normally removing some edges/nodes) the original graph structure to generate the augmentation graph for the contrastive. It inevitably changes the original graph structures, meaning the generated augmentation graph is no longer equivalent to the original graph. This harms the performance of the representation in many structure-sensitive graphs such as protein graphs, chemical graphs, molecular graphs, etc. Moreover, there is only one positive–positive node pair but relatively massive positive–negative node pairs in the self-supervised graph contrastive learning. This can lead to the same class, or very similar samples are considered negative samples. To this end, in this work, we propose a Virtual Masking Augmentation (VMA) to generate an augmentation graph without changing any structures from the original graph. Meanwhile, a node augmentation method is proposed to augment the positive node pairs by discovering the most similar nodes in the same graph. Then, two different augmentation graphs are generated and put into a contrastive learning model to learn the graph representation. Extensive experiments on massive datasets demonstrate that our method achieves new state-of-the-art results on self-supervised graph representation. The source code of the proposed method is available at https://github.com/DuanhaoranCC/CGRA .},
  archive      = {J_NN},
  author       = {Haoran Duan and Cheng Xie and Bin Li and Peng Tang},
  doi          = {10.1016/j.neunet.2023.08.039},
  journal      = {Neural Networks},
  pages        = {223-232},
  shortjournal = {Neural Netw.},
  title        = {Self-supervised contrastive graph representation with node and graph augmentation},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HMM-GDAN: Hybrid multi-view and multi-scale graph
duplex-attention networks for drug response prediction in cancer.
<em>NN</em>, <em>167</em>, 213–222. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision medicine is devoted to discovering personalized therapy for complex and difficult diseases like cancer. Many machine learning approaches have been developed for drug response prediction towards precision medicine. Notwithstanding, genetic profiles based multi-view graph learning schemes have not yet been explored for drug response prediction in previous works. Furthermore, multi-scale latent feature fusion is not considered sufficiently in the existing frameworks of graph neural networks (GNNs). Previous works on drug response prediction mainly depend on sequence data or single-view graph data. In this paper, we propose to construct multi-view graph by means of multi-omics data and STRING protein–protein association data , and develop a new architecture of GNNs for drug response prediction in cancer. Specifically, we propose hybrid multi-view and multi-scale graph duplex-attention networks (HMM-GDAN), in which both multi-view self-attention mechanism and view-level attention mechanism are devised to capture the complementary information of views and emphasize on the importance of each view collaboratively, and rich multi-scale features are constructed and integrated to further form high-level representations for better prediction. Experiments on GDSC2 dataset verify the superiority of the proposed HMM-GDAN when compared with state-of-the-art baselines. The effectiveness of multi-view and multi-scale strategies is demonstrated by the ablation study.},
  archive      = {J_NN},
  author       = {Youfa Liu and Shufan Tong and Yongyong Chen},
  doi          = {10.1016/j.neunet.2023.08.036},
  journal      = {Neural Networks},
  pages        = {213-222},
  shortjournal = {Neural Netw.},
  title        = {HMM-GDAN: Hybrid multi-view and multi-scale graph duplex-attention networks for drug response prediction in cancer},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ShuffleTrans: Patch-wise weight shuffle for transparent
object segmentation. <em>NN</em>, <em>167</em>, 199–212. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transparent objects widely exist in the world. The task of transparent object segmentation is challenging as the object lacks its own texture. The cue of shape information therefore gets more critical. Most existing methods, however, rely on the mechanism of simple convolution , which is good at local cues and performs weakly on global cues like shape. To solve this problem, an operation named Patch-wise Weight Shuffle is proposed to bring in the global context cue by being combined with the dynamic convolution . A network ShuffleTrans that recognizes shape better is then designed based on this operation. Besides, fitter for this task, two auxiliary modules are presented in ShuffleTrans: a Boundary and Direction Refinement Module which collects two additional information, and a Channel Attention Enhancement Module that assists the above operation. Experiments on four texture-less object segmentation datasets and two normal datasets verify the effectiveness and generality of the method. Especially, the ShuffleTrans achieved 74.93\% mIoU on the Trans10k v2 test set, which is more accurate than existing methods.},
  archive      = {J_NN},
  author       = {Boxiang Zhang and Zunran Wang and Yonggen Ling and Yuanyuan Guan and Shenghao Zhang and Wenhui Li and Lei Wei and Chunxu Zhang},
  doi          = {10.1016/j.neunet.2023.08.011},
  journal      = {Neural Networks},
  pages        = {199-212},
  shortjournal = {Neural Netw.},
  title        = {ShuffleTrans: Patch-wise weight shuffle for transparent object segmentation},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MI-DAGSC: A domain adaptation approach incorporating
comprehensive information from MI-EEG signals. <em>NN</em>,
<em>167</em>, 183–198. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-stationarity of EEG signals leads to high variability between subjects, making it challenging to directly use data from other subjects (source domain) for the classifier in the current subject (target domain). In this study, we propose MI-DAGSC to address domain adaptation challenges in EEG-based motor imagery (MI) decoding. By combining domain-level information, class-level information, and inter-sample structure information, our model effectively aligns the feature distributions of source and target domains. This work is an extension of our previous domain adaptation work MI-DABAN (Li et al., 2023). Based on MI-DABAN, MI-DAGSC designs Sample-Feature Blocks (SFBs) and Graph Convolution Blocks (GCBs) to focus on intra-sample and inter-sample information. The synergistic integration of SFBs and GCBs enable the model to capture comprehensive information and understand the relationship between samples, thus improving representation learning . Furthermore, we introduce a triplet loss to enhance the alignment and compactness of feature representations. Extensive experiments on real EEG datasets demonstrate the effectiveness of MI-DAGSC, confirming that our method makes a valuable contribution to the MI-EEG decoding. Moreover, it holds great potential for various applications in brain–computer interface systems and neuroscience research. And the code of the proposed architecture in this study is available under https://github.com/zhangdx21/MI-DAGSC.},
  archive      = {J_NN},
  author       = {Dongxue Zhang and Huiying Li and Jingmeng Xie and Dajun Li},
  doi          = {10.1016/j.neunet.2023.08.008},
  journal      = {Neural Networks},
  pages        = {183-198},
  shortjournal = {Neural Netw.},
  title        = {MI-DAGSC: A domain adaptation approach incorporating comprehensive information from MI-EEG signals},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite/fixed-time synchronization of inertial memristive
neural networks by interval matrix method for secure communication.
<em>NN</em>, <em>167</em>, 168–182. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the finite/fixed-time synchronization problem of delayed inertial memristive neural networks (DIMNNs) using interval matrix-based methods within a unified control framework. By employing set-valued mapping and differential inclusion theory, two distinct methods are applied to handle the switching behavior of memristor parameters: the maximum absolute value method and the interval matrix method. Based on these different approaches, two control strategies are proposed to select appropriate control parameters, enabling the system to achieve finite and fixed-time synchronization, respectively. Additionally, the resulting theoretical criteria differ based on the chosen control strategy, with one expressed in algebraic form and the other in the form of linear matrix inequalities (LMIs). Numerical simulations demonstrate that the interval matrix method outperforms the maximum absolute value method in terms of handling memristor parameter switching, achieving faster finite/fixed-time synchronization. Furthermore, the theoretical results are extended to the field of image encryption , where the response system is utilized for decryption and expanding the keyspace.},
  archive      = {J_NN},
  author       = {Fei Wei and Guici Chen and Zhigang Zeng and Nallappan Gunasekaran},
  doi          = {10.1016/j.neunet.2023.08.015},
  journal      = {Neural Networks},
  pages        = {168-182},
  shortjournal = {Neural Netw.},
  title        = {Finite/fixed-time synchronization of inertial memristive neural networks by interval matrix method for secure communication},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drop edges and adapt: A fairness enforcing fine-tuning for
graph neural networks. <em>NN</em>, <em>167</em>, 159–167. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of graph representation learning as the primary solution for many different network science tasks led to a surge of interest in the fairness of this family of methods. Link prediction, in particular, has a substantial social impact. However, link prediction algorithms tend to increase the segregation in social networks by disfavouring the links between individuals in specific demographic groups. This paper proposes a novel way to enforce fairness on graph neural networks with a fine-tuning strategy. We D rop the unfair E dges and, simultaneously, we A dapt the model’s parameters to those modifications, DEA in short. We introduce two covariance-based constraints designed explicitly for the link prediction task. We use these constraints to guide the optimization process responsible for learning the new ‘fair’ adjacency matrix . One novelty of DEA is that we can use a discrete yet learnable adjacency matrix in our fine-tuning. We demonstrate the effectiveness of our approach on five real-world datasets and show that we can improve both the accuracy and the fairness of the link prediction tasks. In addition, we present an in-depth ablation study demonstrating that our training algorithm for the adjacency matrix can be used to improve link prediction performances during training. Finally, we compute the relevance of each component of our framework to show that the combination of both the constraints and the training of the adjacency matrix leads to optimal performances.},
  archive      = {J_NN},
  author       = {Indro Spinelli and Riccardo Bianchini and Simone Scardapane},
  doi          = {10.1016/j.neunet.2023.08.002},
  journal      = {Neural Networks},
  pages        = {159-167},
  shortjournal = {Neural Netw.},
  title        = {Drop edges and adapt: A fairness enforcing fine-tuning for graph neural networks},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event fusion photometric stereo network. <em>NN</em>,
<em>167</em>, 141–158. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photometric stereo methods typically rely on RGB cameras and are usually performed in a dark room to avoid ambient illumination. Ambient illumination poses a great challenge in photometric stereo due to the restricted dynamic range of the RGB cameras. To address this limitation, we present a novel method, namely Event Fusion Photometric Stereo Network (EFPS-Net), which estimates the surface normals of an object in an ambient light environment by utilizing a deep fusion of RGB and event cameras. The high dynamic range of event cameras provides a broader perspective of light representations that RGB cameras cannot provide. Specifically, we propose an event interpolation method to obtain ample light information, which enables precise estimation of the surface normals of an object. By using RGB-event fused observation maps, our EFPS-Net outperforms previous state-of-the-art methods that depend only on RGB frames, resulting in a 7.94\% reduction in mean average error. In addition, we curate a novel photometric stereo dataset by capturing objects with RGB and event cameras under numerous ambient light environments.},
  archive      = {J_NN},
  author       = {Wonjeong Ryoo and Giljoo Nam and Jae-Sang Hyun and Sangpil Kim},
  doi          = {10.1016/j.neunet.2023.08.009},
  journal      = {Neural Networks},
  pages        = {141-158},
  shortjournal = {Neural Netw.},
  title        = {Event fusion photometric stereo network},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph embedding based multi-label zero-shot learning.
<em>NN</em>, <em>167</em>, 129–140. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label Zero-shot Learning (ZSL) is more reasonable and realistic than standard single-label ZSL because several objects can co-exist in a natural image in real scenarios. Intra-class feature entanglement is a significant factor influencing the alignment of visual and semantic features , resulting in the model’s inability to recognize unseen samples comprehensively and completely. We observe that existing multi-label ZSL methods place a greater emphasis on attention-based refinement and decoupling of visual features, while ignoring the relationship between label semantics . Relying on label correlations to solve multi-label ZSL tasks has not been deeply studied. In this paper, we make full use of the co-occurrence relationship between category labels and build a directed weighted semantic graph based on statistics and prior knowledge, in which node features represent category semantics and weighted edges represent conditional probabilities of label co-occurrence. To guide the targeted extraction of visual features, node features and edge set weights are simultaneously updated and refined, and embedded into the visual feature extraction network from a global and local perspective. The proposed method’s effectiveness was demonstrated by simulation results on two challenging multi-label ZSL benchmarks: NUS-WIDE and Open Images. In comparison to state-of-the-art models, our model achieves an absolute gain of 2.4\% mAP on NUS-WIDE and 2.1\% mAP on Open Images respectively.},
  archive      = {J_NN},
  author       = {Haigang Zhang and Xianglong Meng and Weipeng Cao and Ye Liu and Zhong Ming and Jinfeng Yang},
  doi          = {10.1016/j.neunet.2023.08.023},
  journal      = {Neural Networks},
  pages        = {129-140},
  shortjournal = {Neural Netw.},
  title        = {Graph embedding based multi-label zero-shot learning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structure-aware deep clustering network based on contrastive
learning. <em>NN</em>, <em>167</em>, 118–128. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep clustering has been extensively employed for various data mining tasks, and it can be divided into auto-encoder (AE)-based and graph neural networks (GNN)-based methods. However, existing AE-based methods fall short in effectively extracting structural information, while GNN suffer from smoothing and heterophily. Although methods that combine AE and GNN achieve impressive performance, there remains an inadequate balance between preserving the raw structure and exploring the underlying structure. Accordingly, we propose a novel network named Structure-Aware Deep Clustering network (SADC). Firstly, we compute the cumulative influence of non-adjacent nodes at multiple depths and, thus, enhance the adjacency matrix . Secondly, an enhanced graph auto-encoder is designed. Thirdly, the latent space of AE is endowed with the ability to perceive the raw structure during the learning process. Besides, we design self-supervised mechanisms to achieve co-optimization of node representation learning and topology learning. A new loss function is designed to preserve the inherent structure while also allowing for exploration of latent data structure . Extensive experiments on six benchmark datasets validate that our method outperforms state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Bowei Chen and Sen Xu and Heyang Xu and Xuesheng Bian and Naixuan Guo and Xiufang Xu and Xiaopeng Hua},
  doi          = {10.1016/j.neunet.2023.08.020},
  journal      = {Neural Networks},
  pages        = {118-128},
  shortjournal = {Neural Netw.},
  title        = {Structure-aware deep clustering network based on contrastive learning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain policy adaptation with dynamics alignment.
<em>NN</em>, <em>167</em>, 104–117. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of robotic reinforcement learning is hampered by problems such as an unspecified reward function and high training costs. Many previous works have used cross-domain policy transfer to obtain the policy of the problem domain. However, these researches require paired and aligned dynamics trajectories or other interactions with the environment. We propose a cross-domain dynamics alignment framework for the problem domain policy acquisition that can transfer the policy trained in the source domain to the problem domain. Our framework aims to learn dynamics alignment across two domains that differ in agents’ physical parameters (armature, rotation range, or torso mass) or agents’ morphologies (limbs). Most importantly, we learn dynamics alignment between two domains using unpaired and unaligned dynamics trajectories. For these two scenarios, we propose a cross-physics-domain policy adaptation algorithm (CPD) and a cross-morphology-domain policy adaptation algorithm (CMD) based on our cross-domain dynamics alignment framework. In order to improve the performance of policy in the source domain so that a better policy can be transferred to the problem domain, we propose the Boltzmann TD3 (BTD3) algorithm. We conduct diverse experiments on agent continuous control domains to demonstrate the performance of our approaches. Experimental results show that our approaches can obtain better policies and higher rewards for the agents in the problem domains even when the dataset of the problem domain is small.},
  archive      = {J_NN},
  author       = {Haiyuan Gui and Shanchen Pang and Shihang Yu and Sibo Qiao and Yufeng Qi and Xiao He and Min Wang and Xue Zhai},
  doi          = {10.1016/j.neunet.2023.08.025},
  journal      = {Neural Networks},
  pages        = {104-117},
  shortjournal = {Neural Netw.},
  title        = {Cross-domain policy adaptation with dynamics alignment},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ProxyMix: Proxy-based mixup training with label refinery for
source-free domain adaptation. <em>NN</em>, <em>167</em>, 92–103. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to privacy concerns and data transmission issues, Source-free Unsupervised Domain Adaptation (SFDA) has gained popularity. It exploits pre-trained source models, rather than raw source data for target learning, to transfer knowledge from a labeled source domain to an unlabeled target domain. Existing methods solve this problem typically with additional parameters or noisy pseudo labels, and we propose an effective method named Proxy-based Mixup training with label refinery (ProxyMix) to avoid these drawbacks. To avoid additional parameters and leverages information in the source model, ProxyMix defines classifier weights as class prototypes and creates a class-balanced proxy source domain using nearest neighbors of the prototypes. To improve the reliability of pseudo labels, we further propose the frequency-weighted aggregation strategy to generate soft pseudo labels for unlabeled target data. Our strategy utilizes target features’ internal structure, increases weights of low-frequency class samples, and aligns the proxy and target domains using inter- and intra-domain mixup regularization . This mitigates the negative impact of noisy labels. Experiments on three 2D image and 3D point cloud object recognition benchmarks demonstrate that ProxyMix yields state-of-the-art performance for source-free UDA tasks.},
  archive      = {J_NN},
  author       = {Yuhe Ding and Lijun Sheng and Jian Liang and Aihua Zheng and Ran He},
  doi          = {10.1016/j.neunet.2023.08.005},
  journal      = {Neural Networks},
  pages        = {92-103},
  shortjournal = {Neural Netw.},
  title        = {ProxyMix: Proxy-based mixup training with label refinery for source-free domain adaptation},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of fluid flow in porous media by sparse
observations and physics-informed PointNet. <em>NN</em>, <em>167</em>,
80–91. (<a href="https://doi.org/10.1016/j.neunet.2023.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We predict steady-state Stokes flow of fluids within porous media at pore scales using sparse point observations and a novel class of physics-informed neural networks , called “physics-informed PointNet” (PIPN). Taking the advantages of PIPN into account, three new features become available compared to physics-informed convolutional neural networks for porous medium applications. First, the input of PIPN is exclusively the pore spaces of porous media (rather than both the pore and grain spaces). This feature diminishes required computer memory. Second, PIPN represents the boundary of pore spaces smoothly and realistically (rather than pixel-wise representations). Third, spatial resolution can vary over the physical domain (rather than equally spaced resolutions). This feature enables users to reach an optimal resolution with a minimum computational cost. The performance of our framework is evaluated by the study of the influence of noisy sensor data, pressure observations, and spatial correlation length.},
  archive      = {J_NN},
  author       = {Ali Kashefi and Tapan Mukerji},
  doi          = {10.1016/j.neunet.2023.08.006},
  journal      = {Neural Networks},
  pages        = {80-91},
  shortjournal = {Neural Netw.},
  title        = {Prediction of fluid flow in porous media by sparse observations and physics-informed PointNet},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subspace distillation for continual learning. <em>NN</em>,
<em>167</em>, 65–79. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ultimate objective in continual learning is to preserve knowledge learned in preceding tasks while learning new tasks. To mitigate forgetting prior knowledge, we propose a novel knowledge distillation technique that takes into the account the manifold structure of the latent/output space of a neural network in learning novel tasks. To achieve this, we propose to approximate the data manifold up-to its first order, hence benefiting from linear subspaces to model the structure and maintain the knowledge of a neural network while learning novel concepts. We demonstrate that the modeling with subspaces provides several intriguing properties, including robustness to noise and therefore effective for mitigating Catastrophic Forgetting in continual learning. We also discuss and show how our proposed method can be adopted to address both classification and segmentation problems. Empirically, we observe that our proposed method outperforms various continual learning methods on several challenging datasets including Pascal VOC, and Tiny-Imagenet. Furthermore, we show how the proposed method can be seamlessly combined with existing learning approaches to improve their performances. The codes of this article will be available at https://github.com/csiro-robotics/SDCL .},
  archive      = {J_NN},
  author       = {Kaushik Roy and Christian Simon and Peyman Moghadam and Mehrtash Harandi},
  doi          = {10.1016/j.neunet.2023.07.047},
  journal      = {Neural Networks},
  pages        = {65-79},
  shortjournal = {Neural Netw.},
  title        = {Subspace distillation for continual learning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distorted image classification using neural activation
pattern matching loss. <em>NN</em>, <em>167</em>, 50–64. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image classification , a deep neural network (DNN) that is trained on undistorted images constitutes an effective decision boundary. Unfortunately, this boundary does not support distorted images, such as noisy or blurry ones, leading to accuracy drop-off. As a simple approach for classifying distorted images as well as undistorted ones, previous methods have optimized the trained DNN again on both kinds of images. However, in these methods, the decision boundary may become overly complicated during optimization because there is no regularization of the decision boundary. Consequently, this decision boundary limits efficient optimization. In this paper, we study a simple yet effective decision boundary for distorted image classification through the use of a novel loss, called a “neural activation pattern matching (NAPM) loss”. The NAPM loss is based on recent findings that the decision boundary is a piecewise linear function, where each linear segment is constructed from a neural activation pattern in the DNN when an image is fed to it. The NAPM loss extracts the neural activation patterns when the distorted image and its undistorted version are fed to the DNN and then matches them with each other via the sigmoid cross-entropy. Therefore, it constrains the DNN to classify the distorted image and its undistorted version by the same linear segment. As a result, our loss accelerates efficient optimization by preventing the decision boundary from becoming overly complicated. Our experiments demonstrate that our loss increases the accuracy of the previous methods in all conditions evaluated.},
  archive      = {J_NN},
  author       = {Satoshi Suzuki and Shoichiro Takeda and Ryuichi Tanida and Yukihiro Bandoh and Hayaru Shouno},
  doi          = {10.1016/j.neunet.2023.07.050},
  journal      = {Neural Networks},
  pages        = {50-64},
  shortjournal = {Neural Netw.},
  title        = {Distorted image classification using neural activation pattern matching loss},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spiking neural p systems with lateral inhibition.
<em>NN</em>, <em>167</em>, 36–49. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a member of the third generation of artificial neural network models, spiking neural P systems (SN P systems) have gained a hot research spot in recent years. This work introduces the phenomenon of lateral inhibition in biological nervous systems into SN P systems , and proposes SN P systems with lateral inhibition (LISN P systems). LISN P systems add the property of synaptic length to portray the lateral distance between neurons, and adopt a new form of rules, lateral interaction rules, to describe the reception of spikes by postsynaptic neurons with different lateral distances from the presynaptic neuron . Specifically, an excited neuron produces lateral inhibition on surrounding postsynaptic neurons . Postsynaptic neurons close to the excited neuron, i.e., neurons with small lateral distances, are more susceptible to lateral inhibition and either receive a fewer number of spikes generated by the excited neuron or fail to receive spikes. As the lateral distance increases, the lateral inhibition weakens, and the number of spikes received by postsynaptic neurons increases. Based on the above mechanism, four specific LISN P systems are designed for generating arbitrary odd numbers, arbitrary even numbers , arbitrary natural numbers and arithmetic series, respectively, as examples. By designing working modules, LISN P systems provide equivalence in computational power to the universal register machines in both generating and accepting modes. This verifies the computational completeness of LISN P systems. A universal LISN P system using merely 65 neurons is devised for function computation . According to comparisons among several systems, universal LISN P systems require fewer computational resources.},
  archive      = {J_NN},
  author       = {Yuping Liu and Yuzhen Zhao},
  doi          = {10.1016/j.neunet.2023.08.013},
  journal      = {Neural Networks},
  pages        = {36-49},
  shortjournal = {Neural Netw.},
  title        = {Spiking neural p systems with lateral inhibition},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active learning based on similarity level histogram and
adaptive-scale sampling for very high resolution image classification.
<em>NN</em>, <em>167</em>, 22–35. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In remote sensing image classification, active learning aims to obtain an excellent classification model by selecting informative or representative training samples. However, due to the complexity of remote sensing images, the same class of ground objects usually have different spectral representations . The existing active learning methods may not take into account diverse representations of the same targets, which leads to a possible lack of intra-class diversity in the collected samples. To alleviate this problem, we propose an active learning method based on similarity level histogram (SLH) and adaptive-scale sampling to improve very high resolution remote sensing image classification. Specifically, we construct a SLH for each class of ground objects to effectively consider the intra-class diversity of the same target. To avoid the problem of sample imbalance caused by over-sampling or under-sampling, we design an adaptive-scale sampling strategy. Then, we utilize active learning to mine representative samples from each SLH warehouse according to adaptive-scale sampling strategies until the iteration condition is satisfied. Experiments show that the proposed algorithm can achieve better classification performance with limited training samples and is competitive with other methods based on four sets of publicly available data.},
  archive      = {J_NN},
  author       = {Guangfei Li and Quanxue Gao and Ming Yang and Xinbo Gao},
  doi          = {10.1016/j.neunet.2023.08.012},
  journal      = {Neural Networks},
  pages        = {22-35},
  shortjournal = {Neural Netw.},
  title        = {Active learning based on similarity level histogram and adaptive-scale sampling for very high resolution image classification},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial oblivion channel attention targeting intra-class
diversity feature learning. <em>NN</em>, <em>167</em>, 10–21. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have successfully driven many visual recognition tasks including image classification . However, when dealing with classification tasks with intra-class sample style diversity, the network tends to be disturbed by more diverse features, resulting in limited feature learning . In this article, a spatial oblivion channel attention (SOCA) for intra-class diversity feature learning is proposed. Specifically, SOCA performs spatial structure oblivion in a progressive regularization for each channel after convolution , so that the network is not restricted to a limited feature learning, and pays attention to more regionally detailed features. Further, SOCA reassigns channel weights in the progressively oblivious feature space from top to bottom along the channel direction, to ensure the network learns more image details in an orderly manner while not falling into feature redundancy. Experiments are conducted on the standard classification dataset CIFAR-10/100 and two garbage datasets with intra-class diverse styles. SOCA improves SqueezeNet, MobileNet, BN-VGG-19, Inception and ResNet-50 in classification accuracy by 1.31\%, 1.18\%, 1.57\%, 2.09\% and 2.27\% on average, respectively. The feasibility and effectiveness of intra-class diversity feature learning in SOCA-enhanced networks are verified. Besides, the class activation map shows that more local detail feature regions are activated by adding the SOCA module, which also demonstrates the interpretability of the method for intra-class diversity feature learning.},
  archive      = {J_NN},
  author       = {Honggui Han and Qiyu Zhang and Fangyu Li and Yongping Du},
  doi          = {10.1016/j.neunet.2023.07.032},
  journal      = {Neural Networks},
  pages        = {10-21},
  shortjournal = {Neural Netw.},
  title        = {Spatial oblivion channel attention targeting intra-class diversity feature learning},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual-quality-driven unsupervised image dehazing.
<em>NN</em>, <em>167</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing learning-based dehazing methods require a diverse and large collection of paired hazy/clean images, which is intractable to obtain. Therefore, existing dehazing methods resort to training on synthetic images . This may result in a possible domain shift when treating real scenes. In this paper, we propose a novel unsupervised dehazing (lightweight) network without any reference images to directly predict clear images from the original hazy images, which consists of an interactive fusion module (IFM) and an iterative optimization module (IOM). Specifically, IFM interactively fuses multi-level features to make up for the missing information among deep and shallow features while IOM iteratively optimizes dehazed results to obtain pleasing visual effects. Particularly, based on the observation that hazy images usually suffer from quality degradation, four non-reference visual-quality-driven loss functions are designed to enable the network trained in an unsupervised way, including dark channel loss, contrast loss, saturation loss, and edge sharpness loss. Extensive experiments on two synthetic datasets and one real-world dataset demonstrate that our method performs favorably against the state-of-the-art unsupervised dehazing methods and even matches some supervised methods in terms of metrics such as PSNR, SSIM, and UQI.},
  archive      = {J_NN},
  author       = {Aiping Yang and Yumeng Liu and Jinbin Wang and Xiaoxiao Li and Jiale Cao and Zhong Ji and Yanwei Pang},
  doi          = {10.1016/j.neunet.2023.08.010},
  journal      = {Neural Networks},
  pages        = {1-9},
  shortjournal = {Neural Netw.},
  title        = {Visual-quality-driven unsupervised image dehazing},
  volume       = {167},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>166</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(23)00478-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00478-1},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). CURRENT EVENTS. <em>NN</em>, <em>166</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(23)00476-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00476-8},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {CURRENT EVENTS},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Content preserving image translation with texture
co-occurrence and spatial self-similarity for texture debiasing and
domain adaptation. <em>NN</em>, <em>166</em>, 722–737. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models trained on datasets with texture bias usually perform poorly on out-of-distribution samples since biased representations are embedded into the model. Recently, various image translation and debiasing methods have attempted to disentangle texture biased representations for downstream tasks, but accurately discarding biased features without altering other relevant information is still challenging. In this paper, we propose a novel framework that leverages image translation to generate additional training images using the content of a source image and the texture of a target image with a different bias property to explicitly mitigate texture bias when training a model on a target task. Our model ensures texture similarity between the target and generated images via a texture co-occurrence loss while preserving content details from source images with a spatial self-similarity loss. Both the generated and original training images are combined to train improved classification or segmentation models robust to inconsistent texture bias. Evaluation on five classification- and two segmentation-datasets with known texture biases demonstrates the utility of our method, and reports significant improvements over recent state-of-the-art methods in all cases.},
  archive      = {J_NN},
  author       = {Myeongkyun Kang and Dongkyu Won and Miguel Luna and Philip Chikontwe and Kyung Soo Hong and June Hong Ahn and Sang Hyun Park},
  doi          = {10.1016/j.neunet.2023.07.049},
  journal      = {Neural Networks},
  pages        = {722-737},
  shortjournal = {Neural Netw.},
  title        = {Content preserving image translation with texture co-occurrence and spatial self-similarity for texture debiasing and domain adaptation},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sinogram upsampling using primal–dual UNet for undersampled
CT and radial MRI reconstruction. <em>NN</em>, <em>166</em>, 704–721.
(<a href="https://doi.org/10.1016/j.neunet.2023.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed tomography (CT) and magnetic resonance imaging (MRI) are two widely used clinical imaging modalities for non-invasive diagnosis. However, both of these modalities come with certain problems. CT uses harmful ionising radiation , and MRI suffers from slow acquisition speed. Both problems can be tackled by undersampling, such as sparse sampling. However, such undersampled data leads to lower resolution and introduces artefacts. Several techniques, including deep learning based methods, have been proposed to reconstruct such data. However, the undersampled reconstruction problem for these two modalities was always considered as two different problems and tackled separately by different research works. This paper proposes a unified solution for both sparse CT and undersampled radial MRI reconstruction, achieved by applying Fourier transform-based pre-processing on the radial MRI and then finally reconstructing both modalities using sinogram upsampling combined with filtered back-projection. The Primal–Dual network is a deep learning based method for reconstructing sparsely-sampled CT data. This paper introduces Primal–Dual UNet, which improves the Primal–Dual network in terms of accuracy and reconstruction speed. The proposed method resulted in an average SSIM of 0.932±0.021 while performing sparse CT reconstruction for fan-beam geometry with a sparsity level of 16, achieving a statistically significant improvement over the previous model, which resulted in 0.919±0.016. Furthermore, the proposed model resulted in 0.903±0.019 and 0.957±0.023 average SSIM while reconstructing undersampled brain and abdominal MRI data with an acceleration factor of 16, respectively - statistically significant improvements over the original model, which resulted in 0.867±0.025 and 0.949±0.025. Finally, this paper shows that the proposed network not only improves the overall image quality, but also improves the image quality for the regions-of-interest: liver, kidneys, and spleen; as well as generalises better than the baselines in presence the of a needle.},
  archive      = {J_NN},
  author       = {Philipp Ernst and Soumick Chatterjee and Georg Rose and Oliver Speck and Andreas Nürnberger},
  doi          = {10.1016/j.neunet.2023.08.004},
  journal      = {Neural Networks},
  pages        = {704-721},
  shortjournal = {Neural Netw.},
  title        = {Sinogram upsampling using Primal–Dual UNet for undersampled CT and radial MRI reconstruction},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual information processing through the interplay between
fine and coarse signal pathways. <em>NN</em>, <em>166</em>, 692–703. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object recognition is often viewed as a feedforward , bottom-up process in machine learning , but in real neural systems, object recognition is a complicated process which involves the interplay between two signal pathways. One is the parvocellular pathway (P-pathway), which is slow and extracts fine features of objects; the other is the magnocellular pathway (M-pathway), which is fast and extracts coarse features of objects. It has been suggested that the interplay between the two pathways endows the neural system with the capacity of processing visual information rapidly, adaptively, and robustly. However, the underlying computational mechanism remains largely unknown. In this study, we build a two-pathway model to elucidate the computational properties associated with the interactions between two visual pathways . Specifically, we model two visual pathways using two convolution neural networks : one mimics the P-pathway, referred to as FineNet, which is deep, has small-size kernels, and receives detailed visual inputs; the other mimics the M-pathway, referred to as CoarseNet, which is shallow, has large-size kernels, and receives blurred visual inputs. We show that CoarseNet can learn from FineNet through imitation to improve its performance, FineNet can benefit from the feedback of CoarseNet to improve its robustness to noise; and the two pathways interact with each other to achieve rough-to-fine information processing . Using visual backward masking as an example, we further demonstrate that our model can explain visual cognitive behaviors that involve the interplay between two pathways. We hope that this study gives us insight into understanding the interaction principles between two visual pathways.},
  archive      = {J_NN},
  author       = {Xiaolong Zou and Zilong Ji and Tianqiu Zhang and Tiejun Huang and Si Wu},
  doi          = {10.1016/j.neunet.2023.07.048},
  journal      = {Neural Networks},
  pages        = {692-703},
  shortjournal = {Neural Netw.},
  title        = {Visual information processing through the interplay between fine and coarse signal pathways},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-range zero-shot generative deep network quantization.
<em>NN</em>, <em>166</em>, 683–691. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantization approximates a deep network model with floating-point numbers by the model with low bit width numbers, thereby accelerating inference and reducing computation. Zero-shot quantization, which aims to quantize a model without access to the original data, can be achieved by fitting the real data distribution through data synthesis. However, it has been observed that zero-shot quantization leads to inferior performance compared to post-training quantization with real data for two primary reasons: 1) a normal generator has difficulty obtaining a high diversity of synthetic data since it lacks long-range information to allocate attention to global features, and 2) synthetic images aim to simulate the statistics of real data, which leads to weak intra-class heterogeneity and limited feature richness. To overcome these problems, we propose a novel deep network quantizer called long-range zero-shot generative deep network quantization (LRQ). Technically, we propose a long-range generator (LRG) to learn long-range information instead of simple local features . To incorporate more global features into the synthetic data, we use long-range attention with large-kernel convolution in the generator. In addition, we also present an adversarial margin add (AMA) module to force intra-class angular enlargement between the feature vector and class center. The AMA module forms an adversarial process that increases the convergence difficulty of the loss function, which is opposite to the training objective of the original loss function. Furthermore, to transfer knowledge from the full-precision network, we also utilize decoupled knowledge distillation . Extensive experiments demonstrate that LRQ obtains better performance than other competitors.},
  archive      = {J_NN},
  author       = {Yan Luo and Yangcheng Gao and Zhao Zhang and Jicong Fan and Haijun Zhang and Mingliang Xu},
  doi          = {10.1016/j.neunet.2023.07.042},
  journal      = {Neural Networks},
  pages        = {683-691},
  shortjournal = {Neural Netw.},
  title        = {Long-range zero-shot generative deep network quantization},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A biologically inspired auto-associative network with sparse
temporal population coding. <em>NN</em>, <em>166</em>, 670–682. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Associative system has attracted increasing attention for it can store basic information and then infer details to match perception with an efficient self-organization algorithm. However, the implementation of the associative system with the application of real-world data is relatively difficult. To address this issue, we propose a novel biologically inspired auto-associative (BIAA) network to explore the structure, encoding and formation of associative memory as well as to extend the ability to real-world application. Our network is constructed by imitating the organization of the cortical minicolumns where each minicolumn contains plenty of parallel biological spiking neurons . To allow the network to learn and predict one symbol per theta cycle, we incorporate synaptic delay and theta oscillation into the neuron dynamic process. Subsequently, we design a sparse temporal population (STP) coding scheme that allows each input symbol to be represented as stable, unique, and easily recallable sparsely distributed representations. By combining associative learning dynamics with the STP coding, our network realizes efficient storage and inference in an ordered manner. Experimental results indicate that the proposed network successfully performs sequence retrieval from partial text and sequence recovery from distorted information. BIAA network provides new insight into introducing biologically inspired mechanisms into associative system and has enormous potential for hardware and software applications.},
  archive      = {J_NN},
  author       = {Ya Zhang and Kexin Shi and Xiaoling Luo and Yi Chen and Yucheng Wang and Hong Qu},
  doi          = {10.1016/j.neunet.2023.07.040},
  journal      = {Neural Networks},
  pages        = {670-682},
  shortjournal = {Neural Netw.},
  title        = {A biologically inspired auto-associative network with sparse temporal population coding},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Warming up recurrent neural networks to maximise reachable
multistability greatly improves learning. <em>NN</em>, <em>166</em>,
645–669. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training recurrent neural networks is known to be difficult when time dependencies become long. In this work, we show that most standard cells only have one stable equilibrium at initialisation, and that learning on tasks with long time dependencies generally occurs once the number of network stable equilibria increases; a property known as multistability . Multistability is often not easily attained by initially monostable networks, making learning of long time dependencies between inputs and outputs difficult. This insight leads to the design of a novel way to initialise any recurrent cell connectivity through a procedure called “warmup” to improve its capability to learn arbitrarily long time dependencies. This initialisation procedure is designed to maximise network reachable multistability , i.e., the number of equilibria within the network that can be reached through relevant input trajectories, in few gradient steps . We show on several information restitution, sequence classification, and reinforcement learning benchmarks that warming up greatly improves learning speed and performance, for multiple recurrent cells, but sometimes impedes precision. We therefore introduce a double-layer architecture initialised with a partial warmup that is shown to greatly improve learning of long time dependencies while maintaining high levels of precision. This approach provides a general framework for improving learning abilities of any recurrent cell when long time dependencies are present. We also show empirically that other initialisation and pretraining procedures from the literature implicitly foster reachable multistability of recurrent cells.},
  archive      = {J_NN},
  author       = {Gaspard Lambrechts and Florent De Geeter and Nicolas Vecoven and Damien Ernst and Guillaume Drion},
  doi          = {10.1016/j.neunet.2023.07.023},
  journal      = {Neural Networks},
  pages        = {645-669},
  shortjournal = {Neural Netw.},
  title        = {Warming up recurrent neural networks to maximise reachable multistability greatly improves learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving classification tasks by a receptron based on
nonlinear optical speckle fields. <em>NN</em>, <em>166</em>, 634–644.
(<a href="https://doi.org/10.1016/j.neunet.2023.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among several approaches to tackle the problem of energy consumption in modern computing systems, two solutions are currently investigated: one consists of artificial neural networks (ANNs) based on photonic technologies, the other is a different paradigm compared to ANNs and it is based on random networks of non-linear nanoscale junctions resulting from the assembling of nanoparticles or nanowires as substrates for neuromorphic computing. These networks show the presence of emergent complexity and collective phenomena in analogy with biological neural networks characterized by self-organization, redundancy, and non-linearity. Starting from this background, we propose and formalize a generalization of the perceptron model to describe a classification device based on a network of interacting units where the input weights are non-linearly dependent. We show that this model, called “receptron”, provides substantial advantages compared to the perceptron as, for example, the solution of non-linearly separable Boolean functions with a single device. The receptron model is used as a starting point for the implementation of an all-optical device that exploits the non-linearity of optical speckle fields produced by a solid scatterer . By encoding these speckle fields we generated a large variety of target Boolean functions. We demonstrate that by properly setting the model parameters, different classes of functions with different multiplicity can be solved efficiently. The optical implementation of the receptron scheme opens the way for the fabrication of a completely new class of optical devices for neuromorphic data processing based on a very simple hardware.},
  archive      = {J_NN},
  author       = {B. Paroli and G. Martini and M.A.C. Potenza and M. Siano and M. Mirigliano and P. Milani},
  doi          = {10.1016/j.neunet.2023.08.001},
  journal      = {Neural Networks},
  pages        = {634-644},
  shortjournal = {Neural Netw.},
  title        = {Solving classification tasks by a receptron based on nonlinear optical speckle fields},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-based fixed-time synchronization of neural networks
under DoS attack and its applications. <em>NN</em>, <em>166</em>,
622–633. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the fixed-time synchronization control for neural networks with discontinuous data communication is investigated. Due to the transmission blocking caused by DoS attack , it is intractable to establish a monotonically decreasing Lyapunov function like the conventional analysis of fixed-time stability. Therefore, by virtue of recursive and reduction to absurdity approaches, novel fixed-time stability criteria where the estimated upper bound of settling-time is inherently different from existing results are presented. Then, based on the developed conditions, an event-triggered control scheme that can avoid Zeno behavior is designed to achieve synchronization of master–slave neural networks under DoS attack within a prescribed time. For comparison, the established control scheme is further discussed under the case without DoS attack, and the circumstance that there is no attack or event-triggered mechanism, respectively. Simulation results are finally provided to illustrate the significant and validity of our theoretical research. Especially, in terms of encryption and decryption keys generated from the synchronization behavior of chaotic networks, we specifically discuss the application of the proposed fixed-time synchronization scheme to image and audio encryption.},
  archive      = {J_NN},
  author       = {Mengping Xing and Jianquan Lu and Jungang Lou and Lingzhong Zhang},
  doi          = {10.1016/j.neunet.2023.07.046},
  journal      = {Neural Networks},
  pages        = {622-633},
  shortjournal = {Neural Netw.},
  title        = {Event-based fixed-time synchronization of neural networks under DoS attack and its applications},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSSPA-GC: Multi-scale shape prior adaptation with 3D graph
convolutions for category-level object pose estimation. <em>NN</em>,
<em>166</em>, 609–621. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Category-level object pose estimation aims to predict the 6D object pose and size of arbitrary objects from known categories. It remains a challenge due to the large intra-class shape variation. Recently, the introduction of the shape prior adaptation mechanism into the normalized canonical coordinates (i.e., NOCS) reconstruction process has been shown to be effective in mitigating the intra-class shape variation. However, existing shape prior adaptation methods simply map the observed point cloud to the normalized object space, and the extracted object descriptors are not sufficient for the perception of the object pose. As a result, they fail to predict the pose of objects with complex geometric structures (e.g., cameras). To this end, this paper proposes a novel shape prior adaption method named MSSPA-GC for category-level object pose estimation. Specifically, our main network takes the observed instance point cloud converted from the RGB-D image and the prior shape point cloud pre-trained on the object CAD models as inputs. Then, a novel 3D graph convolution network and a PointNet-like MLP network are designed to extract pose-aware object features and shape-aware object features from these two inputs, respectively. After that, the two-stream object features are aggregated through a multi-scale feature propagation mechanism to generate comprehensive 3D object descriptors that maintain both pose-sensitive geometric stability and intra-class shape consistency. Finally, by leveraging object descriptors aware of both object pose and shape when reconstructing the NOCS coordinates, our approach elegantly achieves state-of-the-art performance on the widely used REAL275 and CAMERA25 datasets using only 25\% of the parameters compared with existing shape prior adaptation models. Moreover, our method also exhibits decent generalization ability on the unconstrained REDWOOD75 dataset.},
  archive      = {J_NN},
  author       = {Lu Zou and Zhangjin Huang and Naijie Gu and Guoping Wang},
  doi          = {10.1016/j.neunet.2023.07.037},
  journal      = {Neural Networks},
  pages        = {609-621},
  shortjournal = {Neural Netw.},
  title        = {MSSPA-GC: Multi-scale shape prior adaptation with 3D graph convolutions for category-level object pose estimation},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive neurodynamic approach for solving nonsmooth
n-cluster games. <em>NN</em>, <em>166</em>, 595–608. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, N -cluster games with coupling and private constraints are studied, where each player’s cost function is nonsmooth and depends on the actions of all players. In order to seek the generalized Nash equilibrium (GNE) of the nonsmooth N -cluster games, a distributed seeking neurodynamic approach with two-time-scale structure is proposed. An adaptive leader-following consensus technique is adapted to dynamically adjust parameters according to the degree of consensus violation, so as to quickly obtain accurate estimation information of other players’ actions which facilitates the evaluation of its own cost. Benefitting from the unique structure of the approach based on primal dual and adaptive penalty methods, the players’ actions enter the constraints while completing the seeking for GNE. As a result, the neurodynamic approach is completely distributed, and prior estimation of penalty parameters is avoided. Finally, two engineering examples of power system game and company capacity allocation verify the effectiveness and feasibility of the neurodynamic approach.},
  archive      = {J_NN},
  author       = {Mengxin Wang and Shihui Zhu and Sitian Qin},
  doi          = {10.1016/j.neunet.2023.07.041},
  journal      = {Neural Networks},
  pages        = {595-608},
  shortjournal = {Neural Netw.},
  title        = {An adaptive neurodynamic approach for solving nonsmooth N-cluster games},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A mathematical framework for improved weight initialization
of neural networks using lagrange multipliers. <em>NN</em>,
<em>166</em>, 579–594. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A good weight initialization is crucial to accelerate the convergence of the weights in a neural network . However, training a neural network is still time-consuming, despite recent advances in weight initialization approaches. In this paper, we propose a mathematical framework for the weight initialization in the last layer of a neural network. We first derive analytically a tight constraint on the weights that accelerates the convergence of the weights during the back-propagation algorithm. We then use linear regression and Lagrange multipliers to analytically derive the optimal initial weights and initial bias of the last layer, that minimize the initial training loss given the derived tight constraint. We also show that the restrictive assumption of traditional weight initialization algorithms that the expected value of the weights is zero is redundant for our approach. We first apply our proposed weight initialization approach to a Convolutional Neural Network that predicts the Remaining Useful Life of aircraft engines. The initial training and validation loss are relatively small, the weights do not get stuck in a local optimum, and the convergence of the weights is accelerated. We compare our approach with several benchmark strategies. Compared to the best performing state-of-the-art initialization strategy (Kaiming initialization), our approach needs 34\% less epochs to reach the same validation loss. We also apply our approach to ResNets for the CIFAR-100 dataset, combined with transfer learning . Here, the initial accuracy is already at least 53\%. This gives a faster weight convergence and a higher test accuracy than the benchmark strategies.},
  archive      = {J_NN},
  author       = {Ingeborg de Pater and Mihaela Mitici},
  doi          = {10.1016/j.neunet.2023.07.035},
  journal      = {Neural Networks},
  pages        = {579-594},
  shortjournal = {Neural Netw.},
  title        = {A mathematical framework for improved weight initialization of neural networks using lagrange multipliers},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end neural speaker diarization with an iterative
adaptive attractor estimation. <em>NN</em>, <em>166</em>, 566–578. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-to-end neural diarization (EEND) which has the capability to directly output speaker diarization results and handle overlapping speech has attracted more and more attention due to its promising performance. Although existing EEND-based methods often outperform clustering-based methods, they cannot generalize well to unseen test sets because fixed attractors are often utilized to estimate speech activities of each speaker. An iterative adaptive attractor estimation (IAAE) network was proposed to refine diarization results, in which the self-attentive EEND (SA-EEND) was implemented to initialize diarization results and frame-wise embeddings. There are two main parts in the proposed IAAE network: an attention-based pooling was designed to obtain a rough estimation of the attractors based on the diarization results of the previous iteration, and an adaptive attractor was then calculated by using transformer decoder blocks. A unified training framework was proposed to further improve the diarization performance, making the embeddings more discriminable based on the well separated attractors. We evaluated the proposed method on both the simulated mixtures and the real CALLHOME dataset using the diarization error rate (DER). Our proposed method provides relative reductions in DER by up to 44.8\% on simulated 2-speaker mixtures and 23.6\% on the CALLHOME dataset over the baseline SA-EEND at the 2nd iteration step . We also demonstrated that with an increasing number of refinement steps applied, the DER on the CALLHOME dataset could be further reduced to 7.36\%, achieving the state-of-the-art diarization results when compared with other methods.},
  archive      = {J_NN},
  author       = {Fengyuan Hao and Xiaodong Li and Chengshi Zheng},
  doi          = {10.1016/j.neunet.2023.07.043},
  journal      = {Neural Networks},
  pages        = {566-578},
  shortjournal = {Neural Netw.},
  title        = {End-to-end neural speaker diarization with an iterative adaptive attractor estimation},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class-imbalanced complementary-label learning via weighted
loss. <em>NN</em>, <em>166</em>, 555–565. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complementary-label learning (CLL) is widely used in weakly supervised classification , but it faces a significant challenge in real-world datasets when confronted with class-imbalanced training samples. In such scenarios, the number of samples in one class is considerably lower than in other classes, which consequently leads to a decline in the accuracy of predictions. Unfortunately, existing CLL approaches have not investigate this problem. To alleviate this challenge, we propose a novel problem setting that enables learning from class-imbalanced complementary labels for multi-class classification. To tackle this problem, we propose a novel CLL approach called Weighted Complementary-Label Learning (WCLL). The proposed method models a weighted empirical risk minimization loss by utilizing the class-imbalanced complementary labels, which is also applicable to multi-class imbalanced training samples. Furthermore, we derive an estimation error bound to provide theoretical assurance. To evaluate our approach, we conduct extensive experiments on several widely-used benchmark datasets and a real-world dataset, and compare our method with existing state-of-the-art methods. The proposed approach shows significant improvement in these datasets, even in the case of multiple class-imbalanced scenarios. Notably, the proposed method not only utilizes complementary labels to train a classifier but also solves the problem of class imbalance.},
  archive      = {J_NN},
  author       = {Meng Wei and Yong Zhou and Zhongnian Li and Xinzheng Xu},
  doi          = {10.1016/j.neunet.2023.07.030},
  journal      = {Neural Networks},
  pages        = {555-565},
  shortjournal = {Neural Netw.},
  title        = {Class-imbalanced complementary-label learning via weighted loss},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discrete-time robust event-triggered actuator fault-tolerant
control based on adaptive networks and reinforcement learning.
<em>NN</em>, <em>166</em>, 541–554. (<a
href="https://doi.org/10.1016/j.neunet.2023.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the topic of fault-tolerant control for discrete-time systems with nonlinear uncertainties and actuator faults . It considers both passive and active faults as part of the analysis and design. The proposed adaptive controller , based on a nonlinear electronic circuit , handles offset-biasing, sensitivity variation, and dead-zone effects. An event-triggered mechanism, utilizing a sliding surface, enhances robustness and reduces data transmission. Adaptive networks called MiFRENs are employed, trained using reinforcement learning . Theoretical analysis guarantees boundedness of internal signals and tracking error. Experimental results validate the scheme, demonstrating required conditions, reduced data transmission, and robust performance. Comparative evaluations confirm its superiority},
  archive      = {J_NN},
  author       = {C. Treesatayapun},
  doi          = {10.1016/j.neunet.2023.08.003},
  journal      = {Neural Networks},
  pages        = {541-554},
  shortjournal = {Neural Netw.},
  title        = {Discrete-time robust event-triggered actuator fault-tolerant control based on adaptive networks and reinforcement learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive pinning cluster synchronization of a stochastic
reaction–diffusion complex network. <em>NN</em>, <em>166</em>, 524–540.
(<a href="https://doi.org/10.1016/j.neunet.2023.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to achieve cluster synchronization of a complex network by some pinning control strategies. Firstly, the network not only is affected by the reaction–diffusion and the directed coupling phenomena, but also is disturbed by the stochastic noise and Markovian switching. Secondly, switched constant gain pinning, centralized and decentralized adaptive pinning are proposed respectively to realize the cluster synchronization of the considered network. In these adaptive pinning controllers, the control gain and coupling strength can been adjusted automatically while only a part of the nodes are controlled. Thirdly, the target state of cluster synchronization is taken as the average state related to the directed topology of all nodes in the same cluster, and does not need to be given separately as an isolated node. Finally, to verify the theoretical results, some simulations of directed coupled reaction–diffusion neural networks with stochastic noise and Markovian switching are given.},
  archive      = {J_NN},
  author       = {Binglong Lu and Haijun Jiang and Cheng Hu and Abdujelil Abdurahman and Mei Liu},
  doi          = {10.1016/j.neunet.2023.07.034},
  journal      = {Neural Networks},
  pages        = {524-540},
  shortjournal = {Neural Netw.},
  title        = {Adaptive pinning cluster synchronization of a stochastic reaction–diffusion complex network},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memristor-based spiking neural network with online
reinforcement learning. <em>NN</em>, <em>166</em>, 512–523. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks implemented in memristor-based hardware can provide fast and efficient in-memory computation, but traditional learning methods such as error back-propagation are hardly feasible in it. Spiking neural networks (SNNs) are highly promising in this regard, as their weights can be changed locally in a self-organized manner without the demand for high-precision changes calculated with the use of information almost from the entire network. This problem is rather relevant for solving control tasks with neural-network reinforcement learning methods, as those are highly sensitive to any source of stochasticity in a model initialization, training, or decision-making procedure. This paper presents an online reinforcement learning algorithm in which the change of connection weights is carried out after processing each environment state during interaction-with-environment data generation. Another novel feature of the algorithm is that it is applied to SNNs with memristor-based STDP-like learning rules . The plasticity functions are obtained from real memristors based on poly-p-xylylene and CoFeB-LiNbO 3 3 nanocomposite , which were experimentally assembled and analyzed. The SNN is comprised of leaky integrate-and-fire neurons. Environmental states are encoded by the timings of input spikes, and the control action is decoded by the first spike. The proposed learning algorithm solves the Cart-Pole benchmark task successfully. This result could be the first step towards implementing a real-time agent learning procedure in a continuous-time environment that can be run on neuromorphic systems with memristive synapses.},
  archive      = {J_NN},
  author       = {Danila Vlasov and Anton Minnekhanov and Roman Rybka and Yury Davydov and Alexander Sboev and Alexey Serenko and Alexander Ilyasov and Vyacheslav Demin},
  doi          = {10.1016/j.neunet.2023.07.031},
  journal      = {Neural Networks},
  pages        = {512-523},
  shortjournal = {Neural Netw.},
  title        = {Memristor-based spiking neural network with online reinforcement learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). InfraNet: Accurate forehead temperature measurement
framework for people in the wild with monocular thermal infrared camera.
<em>NN</em>, <em>166</em>, 501–511. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During an epidemic, accurate human temperature screening based on neural networks for disease surveillance is important and challenging. Existing distant human forehead temperature measuring device usually adopts a dual-camera system using paired RGB and thermal infrared images to conduct face detection and temperature measurement. Since the facial RGB image may undermine people’s privacy, we designed a monocular thermal system and proposed an effective framework called the InfraNet to measure and calibrate forehead temperature of people in the wild. To address the challenge of temperature floating, the InfraNet calibrates the subject’s temperature with one’s physical depth and horizontal offset predicted by a single infrared image. Our InfraNet framework mainly consists of three parts: face detection subnet, depth and horizontal offset estimation subnet and temperature calibration subnet. The temperature calibration performance can be improved with the help of spatial regularization term concentrating on predicting precise depth and horizontal offset of people. Besides, we collected a large-scale infrared image dataset in the both lab and wild scenarios, including 8,215 thermal infrared images. Experiments on our wild dataset demonstrated that the InfraNet achieved 91.6\% high accuracy of distant multi-subject temperature measurement on average under the standard temperature threshold of strict 0.3°C.},
  archive      = {J_NN},
  author       = {Xichuan Zhou and Dongshan Lei and Chunqiao Long and Jing Nie and Haijun Liu},
  doi          = {10.1016/j.neunet.2023.07.038},
  journal      = {Neural Networks},
  pages        = {501-511},
  shortjournal = {Neural Netw.},
  title        = {InfraNet: Accurate forehead temperature measurement framework for people in the wild with monocular thermal infrared camera},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconstructing controllable faces from brain activity with
hierarchical multiview representations. <em>NN</em>, <em>166</em>,
487–500. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing visual experience from brain responses measured by functional magnetic resonance imaging (fMRI) is a challenging yet important research topic in brain decoding, especially it has proved more difficult to decode visually similar stimuli, such as faces. Although face attributes are known as the key to face recognition, most existing methods generally ignore how to decode facial attributes more precisely in perceived face reconstruction, which often leads to indistinguishable reconstructed faces. To solve this problem, we propose a novel neural decoding framework called VSPnet (voxel2style2pixel) by establishing hierarchical encoding and decoding networks with disentangled latent representations as media, so that to recover visual stimuli more elaborately. And we design a hierarchical visual encoder (named HVE) to pre-extract features containing both high-level semantic knowledge and low-level visual details from stimuli. The proposed VSPnet consists of two networks: Multi-branch cognitive encoder and style-based image generator. The encoder network is constructed by multiple linear regression branches to map brain signals to the latent space provided by the pre-extracted visual features and obtain representations containing hierarchical information consistent to the corresponding stimuli. We make the generator network inspired by StyleGAN to untangle the complexity of fMRI representations and generate images. And the HVE network is composed of a standard feature pyramid over a ResNet backbone. Extensive experimental results on the latest public datasets have demonstrated the reconstruction accuracy of our proposed method outperforms the state-of-the-art approaches and the identifiability of different reconstructed faces has been greatly improved. In particular, we achieve feature editing for several facial attributes in fMRI domain based on the multiview ( i.e. , visual stimuli and evoked fMRI) latent representations.},
  archive      = {J_NN},
  author       = {Ziqi Ren and Jie Li and Xuetong Xue and Xin Li and Fan Yang and Zhicheng Jiao and Xinbo Gao},
  doi          = {10.1016/j.neunet.2023.07.016},
  journal      = {Neural Networks},
  pages        = {487-500},
  shortjournal = {Neural Netw.},
  title        = {Reconstructing controllable faces from brain activity with hierarchical multiview representations},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse solution of least-squares twin multi-class support
vector machine using ℓ0 and ℓp-norm for classification and feature
selection. <em>NN</em>, <em>166</em>, 471–486. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of multi-class classification, the twin K-class support vector classification (Twin-KSVC) generates ternary outputs {−1,0,+1} by evaluating all training data in a “1-versus-1-versus-rest” structure. Recently, inspired by the least-squares version of Twin-KSVC and Twin-KSVC, a new multi-class classifier called improvements on least-squares twin multi-class classification support vector machine (ILSTKSVC) has been proposed. In this method, the concept of structural risk minimization is achieved by incorporating a regularization term in addition to the minimization of empirical risk. Twin-KSVC and its improvements have an influence on classification accuracy . Another aspect influencing classification accuracy is feature selection, which is a critical stage in machine learning , especially when working with high-dimensional datasets. However, most prior studies have not addressed this crucial aspect. In this study, motivated by ILSTKSVC and the cardinality-constrained optimization problem , we propose ℓp -norm least-squares twin multi-class support vector machine (PLSTKSVC) with 0&amp;lt;p&amp;lt;1 to perform classification and feature selection at the same time. The technique employed to solve the optimization problems associated with PLSTKSVC is user-friendly, as it involves solving systems of linear equations to obtain an approximate solution for the proposed model. Under certain assumptions, we investigate the properties of the optimum solutions to the related optimization problems. Several real-world datasets were tested using the suggested method. According to the results of our experiments, the proposed method outperforms all current strategies in most datasets in terms of classification accuracy while also reducing the number of features.},
  archive      = {J_NN},
  author       = {Hossein Moosaei and Milan Hladík},
  doi          = {10.1016/j.neunet.2023.07.039},
  journal      = {Neural Networks},
  pages        = {471-486},
  shortjournal = {Neural Netw.},
  title        = {Sparse solution of least-squares twin multi-class support vector machine using ℓ0 and ℓp-norm for classification and feature selection},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronization of coupled switched neural networks subject
to hybrid stochastic disturbances. <em>NN</em>, <em>166</em>, 459–470.
(<a href="https://doi.org/10.1016/j.neunet.2023.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the theoretical analysis on exponential synchronization of a class of coupled switched neural networks suffering from stochastic disturbances and impulses is presented. A control law is developed and two sets of sufficient conditions are derived for the synchronization of coupled switched neural networks . First, for desynchronizing stochastic impulses, the synchronization of coupled switched neural networks is analyzed by Lyapunov function method, the comparison principle and a impulsive delay differential inequality . Then, for general stochastic impulses, by partitioning impulse interval and using the convex combination technique, a set of sufficient condition on the basis of linear matrix inequalities (LMIs) is derived for the synchronization of coupled switched neural networks. Eventually, two numerical examples and a practical application are elaborated to illustrate the effectiveness of the theoretical results.},
  archive      = {J_NN},
  author       = {Han Long and Jingxuan Ci and Zhenyuan Guo and Shiping Wen and Tingwen Huang},
  doi          = {10.1016/j.neunet.2023.07.045},
  journal      = {Neural Networks},
  pages        = {459-470},
  shortjournal = {Neural Netw.},
  title        = {Synchronization of coupled switched neural networks subject to hybrid stochastic disturbances},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ATNAS: Automatic termination for neural architecture search.
<em>NN</em>, <em>166</em>, 446–458. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) is a framework for automating the design process of a neural network structure. While the recent one-shot approaches have reduced the search cost, there still exists an inherent trade-off between cost and performance. It is important to appropriately stop the search and further reduce the high cost of NAS. Meanwhile, the differentiable architecture search (DARTS), a typical one-shot approach, is known to suffer from overfitting. Heuristic early-stopping strategies have been proposed to overcome such performance degradation . In this paper, we propose a more versatile and principled early-stopping criterion on the basis of the evaluation of a gap between expectation values of generalisation errors of the previous and current search steps with respect to the architecture parameters. The stopping threshold is automatically determined at each search epoch without cost. In numerical experiments, we demonstrate the effectiveness of the proposed method. We stop the one-shot NAS algorithms and evaluate the acquired architectures on the benchmark datasets: NAS-Bench-201 and NATS-Bench. Our algorithm is shown to reduce the cost of the search process while maintaining a high performance.},
  archive      = {J_NN},
  author       = {Kotaro Sakamoto and Hideaki Ishibashi and Rei Sato and Shinichi Shirakawa and Youhei Akimoto and Hideitsu Hino},
  doi          = {10.1016/j.neunet.2023.07.011},
  journal      = {Neural Networks},
  pages        = {446-458},
  shortjournal = {Neural Netw.},
  title        = {ATNAS: Automatic termination for neural architecture search},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Value iteration for streaming data on a continuous space
with gradient method in an RKHS. <em>NN</em>, <em>166</em>, 437–445. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical theory of reinforcement learning focused on the tabular setting when states and actions are finite, or for linear representation of the value function in a finite-dimensional approximation. Establishing theory on general continuous state and action space requires a careful treatment of complexity theory of appropriately chosen function spaces and the iterative update of the value function when stochastic gradient descent (SGD) is used. For the classical prediction problem in reinforcement learning based on i.i.d. streaming data in the framework of reproducing kernel Hilbert spaces , we establish polynomial sample complexity taking into account the smoothness of the value function. In particular, we prove that the gradient descent algorithm efficiently computes the value function with appropriately chosen step sizes, with a convergence rate that can be close to 1 / N 1/N , which is the best possible rate for parametric SGD. The advantages of using the gradient descent algorithm include its computational convenience and it can naturally deal with streaming data .},
  archive      = {J_NN},
  author       = {Jiamin Liu and Wangli Xu and Yue Wang and Heng Lian},
  doi          = {10.1016/j.neunet.2023.07.036},
  journal      = {Neural Networks},
  pages        = {437-445},
  shortjournal = {Neural Netw.},
  title        = {Value iteration for streaming data on a continuous space with gradient method in an RKHS},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximation of smooth functionals using deep ReLU
networks. <em>NN</em>, <em>166</em>, 424–436. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep neural networks have been employed to approximate nonlinear continuous functionals F defined on L p ( [ − 1 , 1 ] s ) for 1 ≤ p ≤ ∞ . However, the existing theoretical analysis in the literature either is unsatisfactory due to the poor approximation results, or does not apply to the rectified linear unit (ReLU) activation function . This paper aims to investigate the approximation power of functional deep ReLU networks in two settings: F is continuous with restrictions on the modulus of continuity, and F has higher order Fréchet derivatives. A novel functional network structure is proposed to extract features of higher order smoothness harbored by the target functional F . Quantitative rates of approximation in terms of the depth, width and total number of weights of neural networks are derived for both settings. We give logarithmic rates when measuring the approximation error on the unit ball of a Hölder space. In addition, we establish nearly polynomial rates (i.e., rates of the form exp − a ( log M ) b with a &gt; 0 , 0 &lt; b &lt; 1 ) when measuring the approximation error on a space of analytic functions.},
  archive      = {J_NN},
  author       = {Linhao Song and Ying Liu and Jun Fan and Ding-Xuan Zhou},
  doi          = {10.1016/j.neunet.2023.07.012},
  journal      = {Neural Networks},
  pages        = {424-436},
  shortjournal = {Neural Netw.},
  title        = {Approximation of smooth functionals using deep ReLU networks},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparser spiking activity can be better: Feature
refine-and-mask spiking neural network for event-based visual
recognition. <em>NN</em>, <em>166</em>, 410–423. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-based visual, a new visual paradigm with bio-inspired dynamic perception and μ s μs level temporal resolution, has prominent advantages in many specific visual scenarios and gained much research interest. Spiking neural network (SNN) is naturally suitable for dealing with event streams due to its temporal information processing capability and event-driven nature. However, existing works SNN neglect the fact that the input event streams are spatially sparse and temporally non-uniform, and just treat these variant inputs equally. This situation interferes with the effectiveness and efficiency of existing SNNs. In this paper, we propose the feature Refine-and-Mask SNN (RM-SNN), which has the ability of self-adaption to regulate the spiking response in a data-dependent way. We use the Refine-and-Mask (RM) module to refine all features and mask the unimportant features to optimize the membrane potential of spiking neurons , which in turn drops the spiking activity. Inspired by the fact that not all events in spatio-temporal streams are task-relevant, we execute the RM module in both temporal and channel dimensions. Extensive experiments on seven event-based benchmarks, DVS128 Gesture, DVS128 Gait, CIFAR10-DVS, N-Caltech101, DailyAction-DVS, UCF101-DVS, and HMDB51-DVS demonstrate that under the multi-scale constraints of input time window, RM-SNN can significantly reduce the network average spiking activity rate while improving the task performance. In addition, by visualizing spiking responses, we analyze why sparser spiking activity can be better. Code},
  archive      = {J_NN},
  author       = {Man Yao and Hengyu Zhang and Guangshe Zhao and Xiyu Zhang and Dingheng Wang and Gang Cao and Guoqi Li},
  doi          = {10.1016/j.neunet.2023.07.008},
  journal      = {Neural Networks},
  pages        = {410-423},
  shortjournal = {Neural Netw.},
  title        = {Sparser spiking activity can be better: Feature refine-and-mask spiking neural network for event-based visual recognition},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CCGN: Centralized collaborative graphical transformer
multi-agent reinforcement learning for multi-intersection signal
free-corridor. <em>NN</em>, <em>166</em>, 396–409. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tackling traffic signal control through multi-agent reinforcement learning is a widely-employed approach. However, current state-of-the-art models have drawbacks: intersections optimize their own local rewards and cause traffic to waste time and fuel with a start-stop mode at each intersection. They also lack information sharing among intersections and their specialized policy hinders the ability to adapt to new traffic scenarios. To overcome these limitations, This work presents a centralized collaborative graph network (CCGN) with the core objective of a signal-free corridor once the traffic flows have waited at the entry intersection of the traffic intersection network on either side, the subsequent intersection gives the open signal as the traffic flows arrive. CCGN combines local policy networks (LPN) and global policy networks, where LPN employed at each intersection predicts actions based on Transformer and Graph Convolutional Network (GCN). In contrast, GPN is based on GCN and Q-network that receives the LPN states, traffic flow and road information to manage intersections to provide a signal-free corridor. We developed the Deep Graph Convolution Q-Network (DGCQ) by combining Deep Q-Network (DQN) and GCN to achieve a signal-free corridor. DGCQ leverages GCN’s intersection collaboration and DQN’s information aggregation for traffic control decisions Proposed CCGN model is trained on the robust synthetic traffic network and evaluated on the real-world traffic networks that outperform the other state-of-the-art models.},
  archive      = {J_NN},
  author       = {Hamza Mukhtar and Adil Afzal and Sultan Alahmari and Saud Yonbawi},
  doi          = {10.1016/j.neunet.2023.07.027},
  journal      = {Neural Networks},
  pages        = {396-409},
  shortjournal = {Neural Netw.},
  title        = {CCGN: Centralized collaborative graphical transformer multi-agent reinforcement learning for multi-intersection signal free-corridor},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simple and reliable instance selection for fast training
support vector machine: Valid border recognition. <em>NN</em>,
<em>166</em>, 379–395. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines (SVMs) are powerful statistical learning tools, but their application to large datasets can cause time-consuming training complexity. To address this issue, various instance selection (IS) approaches have been proposed, which choose a small fraction of critical instances and screen out others before training. However, existing methods have not been able to balance accuracy and efficiency well. Some methods miss critical instances, while others use complicated selection schemes that require even more execution time than training with all original instances, thus violating the initial intention of IS. In this work, we present a newly developed IS method called Valid Border Recognition (VBR). VBR selects the closest heterogeneous neighbors as valid border instances and incorporates this process into the creation of a reduced Gaussian kernel matrix, thus minimizing the execution time. To improve reliability, we propose a strengthened version of VBR (SVBR). Based on VBR, SVBR gradually adds farther heterogeneous neighbors as complements until the Lagrange multipliers of already selected instances become stable. In numerical experiments, the effectiveness of our proposed methods is verified on benchmark and synthetic datasets in terms of accuracy, execution time and inference time.},
  archive      = {J_NN},
  author       = {Long Tang and Yingjie Tian and Xiaowei Wang and Panos M. Pardalos},
  doi          = {10.1016/j.neunet.2023.07.018},
  journal      = {Neural Networks},
  pages        = {379-395},
  shortjournal = {Neural Netw.},
  title        = {A simple and reliable instance selection for fast training support vector machine: Valid border recognition},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive event-triggered extended dissipative
synchronization of delayed reaction–diffusion neural networks under
deception attacks. <em>NN</em>, <em>166</em>, 366–378. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under spatially averaged measurements (SAMs) and deception attacks, this article mainly studies the problem of extended dissipativity output synchronization of delayed reaction–diffusion neural networks via an adaptive event-triggered sampled-data (AETSD) control strategy. Compared with the existing ETSD control methods with constant thresholds, our scheme can be adaptively adjusted according to the current sampling and latest transmitted signals and is realized based on limited sensors and actuators. Firstly, an AETSD control scheme is proposed to save the limited transmission channel. Secondly, some synchronization criteria under SAMs and deception attacks are established by utilizing Lyapunov–Krasovskii functional and inequality techniques. Then, by solving linear matrix inequalities (LMIs), we obtain the desired AETSD controller , which can satisfy the specified level of extended dissipativity behaviors . Lastly, one numerical example is given to demonstrate the validity of the proposed method.},
  archive      = {J_NN},
  author       = {Feng-Liang Zhao and Zi-Peng Wang and Junfei Qiao and Huai-Ning Wu and Tingwen Huang},
  doi          = {10.1016/j.neunet.2023.07.024},
  journal      = {Neural Networks},
  pages        = {366-378},
  shortjournal = {Neural Netw.},
  title        = {Adaptive event-triggered extended dissipative synchronization of delayed reaction–diffusion neural networks under deception attacks},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time periodic stabilization of discontinuous
reaction–diffusion cohen–grossberg neural networks. <em>NN</em>,
<em>166</em>, 354–365. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to study the fixed-time stabilization of a class of delayed discontinuous reaction–diffusion Cohen–Grossberg neural networks. Firstly, by providing some relaxed conditions containing indefinite functions and based on inequality techniques, a new fixed-time stability lemma is given, which can improve the traditional ones. Secondly, based on state-dependent switching laws, the periodic wave solution of the formulated networks is transformed into the periodic solution of ordinary differential system. By utilizing differential inclusions theory and coincidence theorem, the existence of periodic solutions is obtained. Thirdly, based on the new fixed-time stability lemma, the periodic solutions are stabilized at zero in a fixed-time, which is a new topic on reaction–diffusion networks. Moreover, the established criteria are all delay-dependent, which are less conservative than the previous delay-independent ones for ensuring the stabilization of delayed reaction–diffusion networks. Finally, two examples give numerical explanations of the proposed results and highlight the influence of delays.},
  archive      = {J_NN},
  author       = {Fanchao Kong and Quanxin Zhu and Hamid Reza Karimi},
  doi          = {10.1016/j.neunet.2023.07.017},
  journal      = {Neural Networks},
  pages        = {354-365},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time periodic stabilization of discontinuous reaction–diffusion Cohen–Grossberg neural networks},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EPC-DARTS: Efficient partial channel connection for
differentiable architecture search. <em>NN</em>, <em>166</em>, 344–353.
(<a href="https://doi.org/10.1016/j.neunet.2023.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With weight-sharing and continuous relaxation strategies, the differentiable architecture search (DARTS) proposes a fast and effective solution to perform neural network architecture search in various deep learning tasks. However, unresolved issues, such as the inefficient memory utilization, and the poor stability of the search architecture due to channels randomly selected, which has even caused performance collapses, are still perplexing researchers and practitioners. In this paper, a novel efficient channel attention mechanism based on partial channel connection for differentiable neural architecture search, termed EPC-DARTS, is proposed to address these two issues. Specifically, we design an efficient channel attention module, which is applied to capture cross-channel interactions and assign weight based on channel importance, to dramatically improve search efficiency and reduce memory occupation. Moreover, only partial channels with higher weights in the mixed calculation of operation are used through the efficient channel attention mechanism , and thus unstable network architectures obtained by the random selection operation can also be avoided in the proposed EPC-DARTS. Experimental results show that the proposed EPC-DARTS achieves remarkably competitive performance (CIFAR-10/CIFAR-100: a test accuracy rate of 97.60\%/84.02\%), compared to other state-of-the-art NAS methods using only 0.2 GPU-Days.},
  archive      = {J_NN},
  author       = {Zicheng Cai and Lei Chen and Hai-Lin Liu},
  doi          = {10.1016/j.neunet.2023.07.029},
  journal      = {Neural Networks},
  pages        = {344-353},
  shortjournal = {Neural Netw.},
  title        = {EPC-DARTS: Efficient partial channel connection for differentiable architecture search},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Safe screening rules for multi-view support vector
machines. <em>NN</em>, <em>166</em>, 326–343. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning aims to make use of the advantages of different views to complement each other and fully mines the potential information in the data. However, the complexity of multi-view learning algorithm is much higher than that of single view learning algorithm. Based on the optimality conditions of two classical multi-view models: SVM-2K and multi-view twin support vector machine (MvTwSVM), this paper analyzes the corresponding relationship between dual variables and samples, and derives their safe screening rules for the first time, termed as SSR-SVM-2K and SSR-MvTwSVM. It can assign or delete four groups of different dual variables in advance before solving the optimization problem , so as to greatly reduce the scale of the optimization problem and improve the solution speed. More importantly, the safe screening criterion is “safe”, that is, the solution of the reduced optimization problem is the same as that of the original problem before screening. In addition, we further give a sequence screening rule to speed up the parameter optimization process, and analyze its properties, including the similarities and differences of safe screening rules between multi-view SVMs and single-view SVMs, the computational complexity , and the relationship between the parameter interval and screening rate. Numerical experiments verify the effectiveness of the proposed methods.},
  archive      = {J_NN},
  author       = {Huiru Wang and Jiayi Zhu and Siyuan Zhang},
  doi          = {10.1016/j.neunet.2023.07.021},
  journal      = {Neural Networks},
  pages        = {326-343},
  shortjournal = {Neural Netw.},
  title        = {Safe screening rules for multi-view support vector machines},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perceptual contrastive generative adversarial network based
on image warping for unsupervised image-to-image translation.
<em>NN</em>, <em>166</em>, 313–325. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an unsupervised image-to-image (UI2I) translation model, called Perceptual Contrastive Generative Adversarial Network (PCGAN), which can mitigate the distortion problem to enhance performance of the traditional UI2I methods. The PCGAN is designed with a two-stage UI2I model. In the first stage of the PCGAN, it leverages a novel image warping to transform shapes of objects in input (source) images. In the second stage of the PCGAN, the residual prediction is devised in refinements of the outputs of the first stage of the PCGAN. To promote performance of the image warping, a loss function, called Perceptual Patch-Wise InfoNCE, is developed in the PCGAN to effectively memorize the visual correspondences between warped images and refined images. Experimental results on quantitative evaluation and visualization comparison for UI2I benchmarks show that the PCGAN is superior to other existing methods considered here.},
  archive      = {J_NN},
  author       = {Lin-Chieh Huang and Hung-Hsu Tsai},
  doi          = {10.1016/j.neunet.2023.07.010},
  journal      = {Neural Networks},
  pages        = {313-325},
  shortjournal = {Neural Netw.},
  title        = {Perceptual contrastive generative adversarial network based on image warping for unsupervised image-to-image translation},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inhibitory stabilized network behaviour in a balanced neural
mass model of a cortical column. <em>NN</em>, <em>166</em>, 296–312. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strong inhibitory recurrent connections can reduce the tendency for a neural network to become unstable. This is known as inhibitory stabilization; networks that are unstable in the absence of strong inhibitory feedback because of their unstable excitatory recurrent connections are known as Inhibition Stabilized Networks (ISNs). One of the characteristics of ISNs is their “paradoxical response”, where perturbing the inhibitory neurons with additional excitatory input results in a decrease in their activity after a temporal delay instead of increasing their activity. Here, we develop a model of populations of neurons across different layers of cortex. Within each layer, there is one population of inhibitory neurons and one population of excitatory neurons. The connectivity weights across different populations in the model are derived from a synaptic physiology database provided by the Allen Institute. The model shows a gradient of excitation–inhibition balance across different layers in the cortex, where superficial layers are more inhibitory dominated compared to deeper layers. To investigate the presence of ISNs across different layers, we measured the membrane potentials of neural populations in the model after perturbing inhibitory populations. The results show that layer 2/3 in the model does not operate in the ISN regime but layers 4 and 5 do operate in the ISN regime. These results accord with neurophysiological findings that explored the presence of ISNs across different layers in the cortex. The results show that there may be a systematic macroscopic gradient of inhibitory stabilization across different layers in the cortex that depends on the level of excitation–inhibition balance, and that the strength of the paradoxical response increases as the model moves closer to bifurcation points .},
  archive      = {J_NN},
  author       = {Parvin Zarei Eskikand and Artemio Soto-Breceda and Mark J. Cook and Anthony N. Burkitt and David B. Grayden},
  doi          = {10.1016/j.neunet.2023.07.020},
  journal      = {Neural Networks},
  pages        = {296-312},
  shortjournal = {Neural Netw.},
  title        = {Inhibitory stabilized network behaviour in a balanced neural mass model of a cortical column},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight image super-resolution based multi-order gated
aggregation network. <em>NN</em>, <em>166</em>, 286–295. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Transformer-based models are taken much focus on solving the task of image super-resolution (SR) due to their ability to achieve better performance. However, these models combined huge computational cost during the computing self-attention mechanism. To solve this problem, we proposed a multi-order gated aggregation super-resolution network (MogaSRN) for low-level vision based on the concept of the MogaNet that is developed for high-level vision. The concept of the MogaSRN model is based on spatial multi-order context aggregation and adaptive channel-wise reallocation with the aid of the multi-layer perceptron (MLP). In contrast to the MogaNet model, in which the resolution of each stage decreased by a factor of 2, the resolution of the MogaSRN is stayed fixed during the deep features extraction. Moreover, the structure of the MogaSRN model is built based on balancing the performance and the model complexity. We evaluated our model based on five benchmark datasets concluding that the MogaSRN model can achieve significant improvements compared to the state-of-the-art. Moreover, our model shows the good visual quality and accuracy of the reconstruction. Finally, our model has 3.7 × × faster runtime at the scale of × × 4 compared to LWSwinIR with better performance.},
  archive      = {J_NN},
  author       = {Garas Gendy and Nabil Sabor and Guanghui He},
  doi          = {10.1016/j.neunet.2023.07.002},
  journal      = {Neural Networks},
  pages        = {286-295},
  shortjournal = {Neural Netw.},
  title        = {Lightweight image super-resolution based multi-order gated aggregation network},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RegraphGAN: A graph generative adversarial network model for
dynamic network anomaly detection. <em>NN</em>, <em>166</em>, 273–285.
(<a href="https://doi.org/10.1016/j.neunet.2023.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the wide application of dynamic graph anomaly detection in cybersecurity, social networks, e-commerce, etc., research in this area has received increasing attention. Graph generative adversarial networks can be used in dynamic graph anomaly detection due to their ability to model complex data, but the original graph generative adversarial networks do not have a method to learn reverse mapping and require an expensive process in recovering the potential representation of a given input. Therefore, this paper proposes a novel graph generative adversarial network by adding encoders to map real data to latent space to improve the training efficiency and stability of graph generative adversarial network models, which is named RegraphGAN in this paper. And this paper proposes a dynamic network anomaly edge detection method by combining RegraphGAN with spatiotemporal coding to solve the complex dynamic graph data and the problem of attribute-free node information coding challenges. Meanwhile, anomaly detection experiments are conducted on six real dynamic network datasets, and the results show that the dynamic network anomaly detection method proposed in this paper outperforms other existing methods.},
  archive      = {J_NN},
  author       = {Dezhi Guo and Zhaowei Liu and Ranran Li},
  doi          = {10.1016/j.neunet.2023.07.026},
  journal      = {Neural Networks},
  pages        = {273-285},
  shortjournal = {Neural Netw.},
  title        = {RegraphGAN: A graph generative adversarial network model for dynamic network anomaly detection},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balance guided incomplete multi-view spectral clustering.
<em>NN</em>, <em>166</em>, 260–272. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a large volume of incomplete multi-view data in the real-world. How to partition these incomplete multi-view data is an urgent realistic problem since almost all of the conventional multi-view clustering methods are inapplicable to cases with missing views. In this paper, a novel graph learning-based incomplete multi-view clustering (IMVC) method is proposed to address this issue. Different from existing works, our method aims at learning a common consensus graph from all incomplete views and obtaining a clustering indicator matrix in a unified framework. To achieve a stable clustering result , a relaxed spectral clustering model is introduced to obtain a probability consensus representation with all positive elements that reflect the data clustering result . Considering the different contributions of views to the clustering task , a weighted multi-view learning mechanism is introduced to automatically balance the effects of different views in model optimization. In this way, the intrinsic information of the incomplete multi-view data can be fully exploited. The experiments on several incomplete multi-view datasets show that our method outperforms the compared state-of-the-art clustering methods , which demonstrates the effectiveness of our method for IMVC.},
  archive      = {J_NN},
  author       = {Lilei Sun and Jie Wen and Chengliang Liu and Lunke Fei and Lusi Li},
  doi          = {10.1016/j.neunet.2023.07.022},
  journal      = {Neural Networks},
  pages        = {260-272},
  shortjournal = {Neural Netw.},
  title        = {Balance guided incomplete multi-view spectral clustering},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified semi-supervised model with joint estimation of
graph, soft labels and latent subspace. <em>NN</em>, <em>166</em>,
248–259. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since manually labeling images is expensive and labor intensive, in practice we often do not have enough labeled images to train an effective classifier for the new image classification tasks . The graph-based SSL methods have received more attention in practice due to their convexity, scalability and efficiency. In this paper, we propose a novel graph-based semi-supervised learning method that takes full advantage of a small set of labeled graphs and a large set of unlabeled graph data. First, we explain the concept of graph-based semi-supervised learning. The core idea of these models is to jointly estimate a low-rank graph with soft labels and a latent subspace. The proposed scheme leverages the synergy between the graph structure and the data representation in terms of soft labels and latent features. This improves the monitoring information and leads to better discriminative linear transformation . Several experiments were conducted on five image datasets using state-of-the-art methods. These experiments show the effectiveness of the proposed semi-supervised method.},
  archive      = {J_NN},
  author       = {Fadi Dornaika and Abdullah Baradaaji},
  doi          = {10.1016/j.neunet.2023.07.014},
  journal      = {Neural Networks},
  pages        = {248-259},
  shortjournal = {Neural Netw.},
  title        = {A unified semi-supervised model with joint estimation of graph, soft labels and latent subspace},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Node injection for class-specific network poisoning.
<em>NN</em>, <em>166</em>, 236–247. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are powerful in learning rich network representations that aid the performance of downstream tasks. However, recent studies showed that GNNs are vulnerable to adversarial attacks involving node injection and network perturbation. Among these, node injection attacks are more practical as they do not require manipulation in the existing network and can be performed more realistically. In this paper, we propose a novel problem statement — a class-specific poison attack on graphs in which the attacker aims to misclassify specific nodes in the target class into a different class using node injection. Additionally, nodes are injected in such a way that they camouflage as benign nodes. We propose NICKI , a novel attacking strategy that utilizes an optimization-based approach to sabotage the performance of GNN-based node classifiers. NICKI works in two phases — it first learns the node representation and then generates the features and edges of the injected nodes. Extensive experiments and ablation studies on four benchmark networks show that NICKI is consistently better than four baseline attacking strategies for misclassifying nodes in the target class. We also show that the injected nodes are properly camouflaged as benign, thus making the poisoned graph indistinguishable from its clean version w.r.t various topological properties .},
  archive      = {J_NN},
  author       = {Ansh Kumar Sharma and Rahul Kukreja and Mayank Kharbanda and Tanmoy Chakraborty},
  doi          = {10.1016/j.neunet.2023.07.025},
  journal      = {Neural Networks},
  pages        = {236-247},
  shortjournal = {Neural Netw.},
  title        = {Node injection for class-specific network poisoning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Block-level dependency syntax based model for end-to-end
aspect-based sentiment analysis. <em>NN</em>, <em>166</em>, 225–235. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-to-End aspect-based sentiment analysis (E2E-ABSA) aims to jointly extract aspect terms and identify their sentiment polarities. Although previous research has demonstrated that syntax knowledge can be beneficial for E2E-ABSA, standard syntax dependency parsing struggles to capture the block-level relation between aspect and opinion terms, which hinders the role of syntax in E2E-ABSA. To address this issue, this paper proposes a block-level dependency syntax parsing (BDEP) based model to enhance the performance of E2E-ABSA. BDEP is constructed by incorporating routine dependency syntax parsing and part-of-speech tagging, which enables the capture of block-level relations. Subsequently. the BDEP-guided interactive attention module (BDEP-IAM) is used to obtain the aspect-aware representation of each word. Finally the adaptive fusion module is leveraged to combine the semantic-syntactic representation to simultaneously extract the aspect term and identify aspect-orient sentiment polarity. The model is evaluated on five benchmark datasets, including Laptop14, Rest _ALL, Restaurant14, Restaurant15, and TWITTER, with F1 scores of 62.67\%, 76.53\%, 75.42\%, 62.21\%, and 58.03\%, respectively. The results show that our model outperforms the other compared state-of-the-art (SOTA) methods on all datasets. Additionally, ablation experiments confirm the efficacy of BDEP and IAM in improving aspect-level sentiment analysis.},
  archive      = {J_NN},
  author       = {Yan Xiang and Jiqun Zhang and Junjun Guo},
  doi          = {10.1016/j.neunet.2023.05.008},
  journal      = {Neural Networks},
  pages        = {225-235},
  shortjournal = {Neural Netw.},
  title        = {Block-level dependency syntax based model for end-to-end aspect-based sentiment analysis},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context and detail interaction network for stereo rain
streak and raindrop removal. <em>NN</em>, <em>166</em>, 215–224. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently stereo image deraining has attracted lots of attention due to its superiority of abundant information from cross views. Exploring interaction information across stereo views is the key to improving the performance of stereo image deraining. In this paper, we design a general coarse-to-fine deraining framework for stereo rain streak and raindrop removal, called CDINet, comprising a stereo rain removal subnet and a stereo detail recovery subnet to restore images progressively. Two types of interaction modules are devised to explore interaction information for rain removal and detail recovery, respectively. Specifically, a global context interaction module is proposed to learn long-range dependencies of stereo images and remove rain by utilizing stereo structural information. A local detail interaction module is designed to model local contextual correlation, which aims at restoring the detail information by using neighborhood information from cross views. Extensive experiments are conducted on the two datasets including a synthetic rain streak removal dataset (RainKITTI) and a real raindrop removal dataset (Stereo Waterdrop), which demonstrates that our method sets new state-of-the-art deraining performance in terms of both quantitative and qualitative metrics with faster speed.},
  archive      = {J_NN},
  author       = {Jing Nie and Jin Xie and Jiale Cao and Yanwei Pang},
  doi          = {10.1016/j.neunet.2023.07.013},
  journal      = {Neural Networks},
  pages        = {215-224},
  shortjournal = {Neural Netw.},
  title        = {Context and detail interaction network for stereo rain streak and raindrop removal},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bio-inspired positional embedding network for
transformer-based models. <em>NN</em>, <em>166</em>, 204–214. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the progress of transformer-based networks, there have been significant improvements in the performance of vision models in recent years. However, there is further potential for improvement in positional embeddings that play a crucial role in distinguishing information across different positions. Based on the biological mechanisms of human visual pathways , we propose a positional embedding network that adaptively captures position information by modeling the dorsal pathway, which is responsible for spatial perception in human vision. Our proposed double-stream architecture leverages large zero-padding convolutions to learn local positional features and utilizes transformers to learn global features, effectively capturing the interaction between dorsal and ventral pathways. To evaluate the effectiveness of our method, we implemented experiments on various datasets, employing differentiated designs. Our statistical analysis demonstrates that the simple implementation significantly enhances image classification performance, and the observed trends demonstrate its biological plausibility .},
  archive      = {J_NN},
  author       = {Xue-song Tang and Kuangrong Hao and Hui Wei},
  doi          = {10.1016/j.neunet.2023.07.015},
  journal      = {Neural Networks},
  pages        = {204-214},
  shortjournal = {Neural Netw.},
  title        = {A bio-inspired positional embedding network for transformer-based models},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised feature selection based on variance–covariance
subspace distance. <em>NN</em>, <em>166</em>, 188–203. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace distance is an invaluable tool exploited in a wide range of feature selection methods. The power of subspace distance is that it can identify a representative subspace, including a group of features that can efficiently approximate the space of original features. On the other hand, employing intrinsic statistical information of data can play a significant role in a feature selection process. Nevertheless, most of the existing feature selection methods founded on the subspace distance are limited in properly fulfilling this objective. To pursue this void, we propose a framework that takes a subspace distance into account which is called “Variance–Covariance subspace distance”. The approach gains advantages from the correlation of information included in the features of data, thus determines all the feature subsets whose corresponding Variance–Covariance matrix has the minimum norm property. Consequently, a novel, yet efficient unsupervised feature selection framework is introduced based on the Variance–Covariance distance to handle both the dimensionality reduction and subspace learning tasks. The proposed framework has the ability to exclude those features that have the least variance from the original feature set. Moreover, an efficient update algorithm is provided along with its associated convergence analysis to solve the optimization side of the proposed approach. An extensive number of experiments on nine benchmark datasets are also conducted to assess the performance of our method from which the results demonstrate its superiority over a variety of state-of-the-art unsupervised feature selection methods. The source code is available at https://github.com/SaeedKarami/VCSDFS .},
  archive      = {J_NN},
  author       = {Saeed Karami and Farid Saberi-Movahed and Prayag Tiwari and Pekka Marttinen and Sahar Vahdati},
  doi          = {10.1016/j.neunet.2023.06.018},
  journal      = {Neural Networks},
  pages        = {188-203},
  shortjournal = {Neural Netw.},
  title        = {Unsupervised feature selection based on variance–covariance subspace distance},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual memory model for experience-once task-incremental
lifelong learning. <em>NN</em>, <em>166</em>, 174–187. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experience replay (ER) is a widely-adopted neuroscience-inspired method to perform lifelong learning . Nonetheless, existing ER-based approaches consider very coarse memory modules with simple memory and rehearsal mechanisms that cannot fully exploit the potential of memory replay. Evidence from neuroscience has provided fine-grained memory and rehearsal mechanisms, such as the dual-store memory system consisting of PFC-HC circuits. However, the computational abstraction of these processes is still very challenging. To address these problems, we introduce the Dual-Memory ( Dual-MEM ) model emulating the memorization, consolidation, and rehearsal process in the PFC-HC dual-store memory circuit. Dual-MEM maintains an incrementally updated short-term memory to benefit current-task learning. At the end of the current task, short-term memories will be consolidated into long-term ones for future rehearsal to alleviate forgetting. For the Dual-MEM optimization, we propose two learning policies that emulate different memory retrieval strategies: Direct Retrieval Learning and Mixup Retrieval Learning. Extensive evaluations on eight benchmarks demonstrate that Dual-MEM delivers compelling performance while maintaining high learning and memory utilization efficiencies under the challenging experience-once setting.},
  archive      = {J_NN},
  author       = {Gehua Ma and Runhao Jiang and Lang Wang and Huajin Tang},
  doi          = {10.1016/j.neunet.2023.07.009},
  journal      = {Neural Networks},
  pages        = {174-187},
  shortjournal = {Neural Netw.},
  title        = {Dual memory model for experience-once task-incremental lifelong learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A super-resolution network for medical imaging via
transformation analysis of wavelet multi-resolution. <em>NN</em>,
<em>166</em>, 162–173. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning super-resolution models for progressive reconstruction have achieved great success. However, these models which refer to multi-resolution analysis basically ignore the information contained in the lower subspaces and do not explore the correlation between features in the wavelet and spatial domain, resulting in not fully utilizing the auxiliary information brought by multi-resolution analysis with multiple domains. Therefore, we propose a super-resolution network based on the wavelet multi-resolution framework (WMRSR) to capture the auxiliary information contained in multiple subspaces and to be aware of the interdependencies between spatial domain and wavelet domain features. Initially, the wavelet multi-resolution input (WMRI) is generated by combining wavelet sub-bands obtained from each subspace through wavelet multi-resolution analysis and the corresponding spatial domain image content, which serves as input to the network. Then, the WMRSR captures the corresponding features from the WMRI in the wavelet domain and spatial domain, respectively, and fuses them adaptively, thus learning fully explored features in multi-resolution and multi-domain. Finally, the high-resolution images are gradually reconstructed in the wavelet multi-resolution framework by our convolution-based wavelet transform module which is suitable for deep neural networks . Extensive experiments conducted on two public datasets demonstrate that our method outperforms other state-of-the-art methods in terms of objective and visual qualities.},
  archive      = {J_NN},
  author       = {Yue Yu and Kun She and Jinhua Liu and Xiao Cai and Kaibo Shi and O.M. Kwon},
  doi          = {10.1016/j.neunet.2023.07.005},
  journal      = {Neural Networks},
  pages        = {162-173},
  shortjournal = {Neural Netw.},
  title        = {A super-resolution network for medical imaging via transformation analysis of wavelet multi-resolution},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Quantum recurrent neural networks for sequential learning.
<em>NN</em>, <em>166</em>, 148–161. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum neural network (QNN) is one of the promising directions where the near-term noisy intermediate-scale quantum (NISQ) devices could find advantageous applications against classical resources. Recurrent neural networks are the most fundamental networks for sequential learning , but up to now there is still a lack of canonical model of quantum recurrent neural network (QRNN), which certainly restricts the research in the field of quantum deep learning . In the present work, we propose a new kind of QRNN which would be a good candidate as the canonical QRNN model, where, the quantum recurrent blocks (QRBs) are constructed in the hardware-efficient way, and the QRNN is built by stacking the QRBs in a staggered way that can greatly reduce the algorithm’s requirement with regard to the coherent time of quantum devices . That is, our QRNN is much more accessible on NISQ devices. Furthermore, the performance of the present QRNN model is verified concretely using three different kinds of classical sequential data, i.e., meteorological indicators, stock price, and text categorization. The numerical experiments show that our QRNN achieves much better performance in prediction (classification) accuracy against the classical RNN and state-of-the-art QNN models for sequential learning , and can predict the changing details of temporal sequence data. The practical circuit structure and superior performance indicate that the present QRNN is a promising learning model to find quantum advantageous applications in the near term.},
  archive      = {J_NN},
  author       = {Yanan Li and Zhimin Wang and Rongbing Han and Shangshang Shi and Jiaxin Li and Ruimin Shang and Haiyong Zheng and Guoqiang Zhong and Yongjian Gu},
  doi          = {10.1016/j.neunet.2023.07.003},
  journal      = {Neural Networks},
  pages        = {148-161},
  shortjournal = {Neural Netw.},
  title        = {Quantum recurrent neural networks for sequential learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-rank discrete multi-view spectral clustering.
<em>NN</em>, <em>166</em>, 137–147. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering has attracted intensive attention in multimedia applications due to its good performance on arbitrary shaped clusters and well-defined mathematical framework. However, most existing multi-view spectral clustering methods still have the following demerits: (1) They ignore useful complementary information embedded in indicator matrices of different views. (2) The conventional post-processing methods based on the relax and discrete strategy inevitably result in the sub-optimal discrete solution. To tackle the aforementioned drawbacks, we propose a low-rank discrete multi-view spectral clustering model. Drawing inspiration from the fact that the difference between indicator matrices of different views provides useful complementary information for clustering, our model exploits the complementary information embedded in indicator matrices with tensor Schatten p -norm constraint. Further, we integrate low-rank tensor learning and discrete label recovering into a uniform framework, which avoids the uncertainty of the relaxed and discrete strategy. Extensive experiments on benchmark datasets have demonstrated the effectiveness and superiority of the proposed method.},
  archive      = {J_NN},
  author       = {Yu Yun and Jing Li and Quanxue Gao and Ming Yang and Xinbo Gao},
  doi          = {10.1016/j.neunet.2023.06.038},
  journal      = {Neural Networks},
  pages        = {137-147},
  shortjournal = {Neural Netw.},
  title        = {Low-rank discrete multi-view spectral clustering},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trustworthy medical image segmentation with improved
performance for in-distribution samples. <em>NN</em>, <em>166</em>,
127–136. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the enormous achievements of Deep Learning (DL) based models, their non-transparent nature led to restricted applicability and distrusted predictions. Such predictions emerge from erroneous In-Distribution (ID) and Out-Of-Distribution (OOD) samples, which results in disastrous effects in the medical domain, specifically in Medical Image Segmentation (MIS). To mitigate such effects, several existing works accomplish OOD sample detection; however, the trustworthiness issues from ID samples still require thorough investigation. To this end, a novel method TrustMIS (Trustworthy Medical Image Segmentation) is proposed in this paper, which provides the trustworthiness and improved performance of ID samples for DL-based MIS models. TrustMIS works in three folds: IT (Investigating Trustworthiness), INT (Improving Non-Trustworthy prediction) and CSO (Classifier Switching Operation). Initially, the IT method investigates the trustworthiness of MIS by leveraging similar characteristics and consistency analysis of input and its variants. Subsequently, the INT method employs the IT method to improve the performance of the MIS model. It leverages the observation that an input providing erroneous segmentation can provide correct segmentation with rotated input. Eventually, the CSO method employs the INT method to scrutinise several MIS models and selects the model that delivers the most trustworthy prediction. The experiments conducted on publicly available datasets using well-known MIS models reveal that TrustMIS has successfully provided a trustworthiness measure, outperformed the existing methods, and improved the performance of state-of-the-art MIS models. Our implementation is available at https://github.com/SnehaShukla937/TrustMIS .},
  archive      = {J_NN},
  author       = {Sneha Shukla and Lokendra Birla and Anup Kumar Gupta and Puneet Gupta},
  doi          = {10.1016/j.neunet.2023.06.047},
  journal      = {Neural Networks},
  pages        = {127-136},
  shortjournal = {Neural Netw.},
  title        = {Trustworthy medical image segmentation with improved performance for in-distribution samples},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on neural-symbolic learning systems. <em>NN</em>,
<em>166</em>, 105–126. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural systems have demonstrated highly effective learning ability and superior perception intelligence. However, they have been found to lack effective reasoning and cognitive ability. On the other hand, symbolic systems exhibit exceptional cognitive intelligence but suffer from poor learning capabilities when compared to neural systems. Recognizing the advantages and disadvantages of both methodologies, an ideal solution emerges: combining neural systems and symbolic systems to create neural-symbolic learning systems that possess powerful perception and cognition. The purpose of this paper is to survey the advancements in neural-symbolic learning systems from four distinct perspectives: challenges, methods, applications, and future directions. By doing so, this research aims to propel this emerging field forward, offering researchers a comprehensive and holistic overview. This overview will not only highlight the current state-of-the-art but also identify promising avenues for future research.},
  archive      = {J_NN},
  author       = {Dongran Yu and Bo Yang and Dayou Liu and Hui Wang and Shirui Pan},
  doi          = {10.1016/j.neunet.2023.06.028},
  journal      = {Neural Networks},
  pages        = {105-126},
  shortjournal = {Neural Netw.},
  title        = {A survey on neural-symbolic learning systems},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The deep arbitrary polynomial chaos neural network or how
deep artificial neural networks could benefit from data-driven
homogeneous chaos theory. <em>NN</em>, <em>166</em>, 85–104. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing , physical modeling , computational science, communication science, and stochastic analysis . Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions . In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen as a 1st degree multi-variate polynomial of single neurons from the previous layer, i.e. linear weighted sum of monomials . From this point of view, the conventional DANN structure relies implicitly (but erroneously) on a Gaussian distribution of neural signals. Additionally, this view revels that by design DANNs do not necessarily fulfill any orthogonality or orthonormality condition for a majority of data-driven applications. Therefore, the prevailing handling of neural signals in DANNs could lead to redundant representation as any neural signal could contain some partial information from other neural signals. To tackle that challenge, we suggest to employ the data-driven generalization of PCE theory known as arbitrary polynomial chaos (aPC) to construct a corresponding multi-variate orthonormal representations on each node of a DANN. Doing so, we generalize the conventional structure of DANNs to Deep arbitrary polynomial chaos neural networks (DaPC NN). They decompose the neural signals that travel through the multi-layer structure by an adaptive construction of data-driven multi-variate orthonormal bases for each layer. Moreover, the introduced DaPC NN provides an opportunity to go beyond the linear weighted superposition of single neurons on each node. Inheriting fundamentals of PCE theory, the DaPC NN offers an additional possibility to account for high-order neural effects reflecting simultaneous interaction in multi-layer networks. Introducing the high-order weighted superposition on each node of the network mitigates the necessity to introduce non-linearity via activation functions and, hence, reduces the room for potential subjectivity in the modeling procedure. Although the current DaPC NN framework has no theoretical restrictions on the use of activation functions. The current paper also summarizes relevant properties of DaPC NNs inherited from aPC as analytical expressions for statistical quantities and sensitivity indexes on each node. We also offer an analytical form of partial derivatives that could be used in various training algorithms . Technically, DaPC NNs require similar training procedures as conventional DANNs, and all trained weights determine automatically the corresponding multi-variate data-driven orthonormal bases for all layers of DaPC NN. The paper makes use of three test cases to illustrate the performance of DaPC NN, comparing it with the performance of the conventional DANN and also with plain aPC expansion. Evidence of convergence over the training data size against validation data sets demonstrates that the DaPC NN outperforms the conventional DANN systematically. Overall, the suggested re-formulation of the kernel network structure in terms of homogeneous chaos theory is not limited to any particular architecture or any particular definition of the loss function. The DaPC NN Matlab Toolbox is available online and users are invited to adopt it for own needs.},
  archive      = {J_NN},
  author       = {Sergey Oladyshkin and Timothy Praditia and Ilja Kroeker and Farid Mohammadi and Wolfgang Nowak and Sebastian Otte},
  doi          = {10.1016/j.neunet.2023.06.036},
  journal      = {Neural Networks},
  pages        = {85-104},
  shortjournal = {Neural Netw.},
  title        = {The deep arbitrary polynomial chaos neural network or how deep artificial neural networks could benefit from data-driven homogeneous chaos theory},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tackling higher-order relations and heterogeneity: Dynamic
heterogeneous hypergraph network for spatiotemporal activity prediction.
<em>NN</em>, <em>166</em>, 70–84. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal activity prediction aims to predict user activities at a particular time and location, which is applicable in city planning, activity recommendations, and other domains. The fundamental endeavor in spatiotemporal activity prediction is to model the intricate interaction patterns among users, locations, time, and activities, which is characterized by higher-order relations and heterogeneity. Recently, graph-based methods have gained popularity due to the advancements in graph neural networks . However, these methods encounter two significant challenges. Firstly, higher-order relations and heterogeneity are not adequately modeled. Secondly, the majority of established methods are designed around the static graph structures that rely solely on co-occurrence relations, which can be imprecise. To overcome these challenges, we propose Dy H 2 H2 N, a dynamic heterogeneous hypergraph network for spatiotemporal activity prediction. Specifically, to enhance the capacity for modeling higher-order relations, hypergraphs are employed in lieu of graphs. Then we propose a set representation learning-inspired heterogeneous hyperedge learning module , which models higher-order relations and heterogeneity in spatiotemporal activity prediction using a non-decomposable manner. To improve the encoding of heterogeneous spatiotemporal activity hyperedges, a knowledge representation-regularized loss is introduced. Moreover, we present a hypergraph structure learning module to update the hypergraph structures dynamically. Our proposed Dy H 2 H2 N model has been extensively tested on four real-world datasets, proving to outperform previous state-of-the-art methods by 5.98\% to 27.13\%. The effectiveness of all framework components is demonstrated through ablation experiments.},
  archive      = {J_NN},
  author       = {Changyuan Tian and Zequn Zhang and Fanglong Yao and Zhi Guo and Shiyao Yan and Xian Sun},
  doi          = {10.1016/j.neunet.2023.07.006},
  journal      = {Neural Networks},
  pages        = {70-84},
  shortjournal = {Neural Netw.},
  title        = {Tackling higher-order relations and heterogeneity: Dynamic heterogeneous hypergraph network for spatiotemporal activity prediction},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online dynamic ensemble deep random vector functional link
neural network for forecasting. <em>NN</em>, <em>166</em>, 51–69. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a three-stage online deep learning model for time series based on the ensemble deep random vector functional link (edRVFL). The edRVFL stacks multiple randomized layers to enhance the single-layer RVFL’s representation ability. Each hidden layer’s representation is utilized for training an output layer, and the ensemble of all output layers forms the edRVFL’s output. However, the original edRVFL is not designed for online learning, and the randomized nature of the features is harmful to extracting meaningful temporal features. In order to address the limitations and extend the edRVFL to an online learning mode, this paper proposes a dynamic edRVFL consisting of three online components, the online decomposition, the online training, and the online dynamic ensemble. First, an online decomposition is utilized as a feature engineering block for the edRVFL. Then, an online learning algorithm is designed to learn the edRVFL. Finally, an online dynamic ensemble method , which can measure the change in the distribution, is proposed for aggregating all layers’ outputs. This paper evaluates and compares the proposed model with state-of-the-art methods on sixteen time series.},
  archive      = {J_NN},
  author       = {Ruobin Gao and Ruilin Li and Minghui Hu and P.N. Suganthan and Kum Fai Yuen},
  doi          = {10.1016/j.neunet.2023.06.042},
  journal      = {Neural Networks},
  pages        = {51-69},
  shortjournal = {Neural Netw.},
  title        = {Online dynamic ensemble deep random vector functional link neural network for forecasting},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view graph representation with similarity diffusion
for general zero-shot learning. <em>NN</em>, <em>166</em>, 38–50. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) aims to predict unseen classes without using samples of these classes in model training. The ZSL has been widely used in many knowledge-based models and applications to predict various parameters, including categories, subjects, and anomalies, in different domains. Nonetheless, most existing ZSL methods require the pre-defined semantics or attributes of particular data environments. Therefore, these methods are difficult to be applied to general data environments, such as ImageNet and other real-world datasets and applications. Recent research has tried to use open knowledge to enhance the ZSL methods to adapt it to an open data environment. However, the performance of these methods is relatively low, namely the accuracy is normally below 10\%, which is due to the inadequate semantics that can be used from open knowledge. Moreover, the latest methods suffer from a significant ”semantic gap” problem between the generated features of unseen classes and the real features of seen classes. To this end, this paper proposes a multi-view graph representation with a similarity diffusion model , applying the ZSL tasks to general data environments. This model applies a multi-view graph to enhance the semantics fully and proposes an innovative diffusion method to augment the graph representation. In addition, a feature diffusion method is proposed to augment the multi-view graph representation and bridge the semantic gap to realize zero-shot predicting. The results of numerous experiments in general data environments and on benchmark datasets show that the proposed method can achieve new state-of-the-art results in the field of general zero-shot learning. Furthermore, seven ablation studies analyze the effects of the settings and different modules of the proposed method on its performance in detail and prove the effectiveness of each module.},
  archive      = {J_NN},
  author       = {Beibei Yu and Cheng Xie and Peng Tang and Haoran Duan},
  doi          = {10.1016/j.neunet.2023.06.045},
  journal      = {Neural Networks},
  pages        = {38-50},
  shortjournal = {Neural Netw.},
  title        = {Multi-view graph representation with similarity diffusion for general zero-shot learning},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A look into feedback neural computation upon collision
selectivity. <em>NN</em>, <em>166</em>, 22–37. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physiological studies have shown that a group of locust’s lobula giant movement detectors (LGMDs) has a diversity of collision selectivity to approaching objects, relatively darker or brighter than their backgrounds in cluttered environments. Such diversity of collision selectivity can serve locusts to escape from attack by natural enemies, and migrate in swarm free of collision. For computational studies, endeavours have been made to realize the diverse selectivity which, however, is still one of the most challenging tasks especially in complex and dynamic real world scenarios. The existing models are mainly formulated as multi-layered neural networks with merely feed-forward information processing, and do not take into account the effect of re-entrant signals in feedback loop, which is an essential regulatory loop for motion perception, yet never been explored in looming perception. In this paper, we inaugurate feedback neural computation for constructing a new LGMD-based model, named F-LGMD to look into the efficacy upon implementing different collision selectivity. Accordingly, the proposed neural network model features both feed-forward processing and feedback loop. The feedback control propagates output signals of parallel ON/OFF channels back into their starting neurons, thus makes part of the feed-forward neural network, i.e. the ON/OFF channels and the feedback loop form an iterative cycle system. Moreover, the feedback control is instantaneous, which leads to the existence of a fixed point whereby the fixed point theorem is applied to rigorously derive valid range of feedback coefficients. To verify the effectiveness of the proposed method, we conduct systematic experiments covering synthetic and natural collision datasets, and also online robotic tests. The experimental results show that the F-LGMD, with a unified network, can fulfil the diverse collision selectivity revealed in physiology, which not only reduces considerably the handcrafted parameters compared to previous studies, but also offers a both efficient and robust scheme for collision perception through feedback neural computation.},
  archive      = {J_NN},
  author       = {Zefang Chang and Qinbing Fu and Hao Chen and Haiyang Li and Jigen Peng},
  doi          = {10.1016/j.neunet.2023.06.039},
  journal      = {Neural Networks},
  pages        = {22-37},
  shortjournal = {Neural Netw.},
  title        = {A look into feedback neural computation upon collision selectivity},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive event-triggered synchronization of neural networks
under stochastic cyber-attacks with application to chua’s circuit.
<em>NN</em>, <em>166</em>, 11–21. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the synchronization control problem for neural networks (NNs) subject to stochastic cyber-attacks. Firstly, an adaptive event-triggered scheme (AETS) is adopted to improve the utilization rate of network resources, and an output feedback controller is constructed for improving the performance of the system subject to the conventional deception attack and accumulated dynamic cyber-attack. Secondly, the synchronization problem of master–slave NNs is transformed into the stability analysis problem of the synchronization error system. Thirdly, by constructing a customized Lyapunov–Krasovskii functional (LKF), the adaptive event-triggered output feedback controller is designed to ensure the synchronization error system is asymptotically stable with a given H ∞ H∞ performance index. Lastly, in the simulation part, two examples, including Chua’s circuit, illustrate the feasibility and universality of the related technologies in this paper.},
  archive      = {J_NN},
  author       = {Yao Xu and Chunyu Yang and Linna Zhou and Lei Ma and Song Zhu},
  doi          = {10.1016/j.neunet.2023.07.004},
  journal      = {Neural Networks},
  pages        = {11-21},
  shortjournal = {Neural Netw.},
  title        = {Adaptive event-triggered synchronization of neural networks under stochastic cyber-attacks with application to chua’s circuit},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive prescribed settling time periodic event-triggered
control for uncertain robotic manipulators with state constraints.
<em>NN</em>, <em>166</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive prescribed settling time periodic event-triggered control (APST-PETC) is investigated for uncertain robotic manipulators with state constraints. In order to economize network bandwidth occupancy and reduce computational burden, a periodic event-triggered control (PETC) strategy is proposed to reduce the update frequency of the control signal and avoid unnecessary continuous monitoring. Besides, considering that the maneuverable space of the actual robotic manipulators is often limited, the barrier Lyapunov function (BLF) is applied to deal with the influence of the constraint characteristics on the robotic manipulators. Further, based on the one-to-one nonlinear mapping function of the system tracking error, an adaptive prescribed settling time control (APSTC) is designed to ensure that the system tracking error reaches the predetermined precision residual set within the prescribed settling time. Finally, theoretical analysis and comparative experiments are given to verify its feasibility.},
  archive      = {J_NN},
  author       = {Zicong Chen and Hui Zhang and Jianqi Liu and Qinruo Wang and Jianhui Wang},
  doi          = {10.1016/j.neunet.2023.06.032},
  journal      = {Neural Networks},
  pages        = {1-10},
  shortjournal = {Neural Netw.},
  title        = {Adaptive prescribed settling time periodic event-triggered control for uncertain robotic manipulators with state constraints},
  volume       = {166},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>165</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(23)00411-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00411-2},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Current events. <em>NN</em>, <em>165</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(23)00410-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00410-0},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {Current events},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced regularization for on-chip training using analog
and temporary memory weights. <em>NN</em>, <em>165</em>, 1050–1057. (<a
href="https://doi.org/10.1016/j.neunet.2023.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-memory computing techniques are used to accelerate artificial neural network (ANN) training and inference tasks. Memory technology and architectural innovations allow efficient matrix–vector multiplications, gradient calculations , and updates to network weights. However, on-chip learning for edge devices is quite challenging due to the frequent updates. Here, we propose using an analog and temporary on-chip memory (ATOM) cell with controllable retention timescales for implementing the weights of an on-chip training task. Measurement results for Read–Write timescales are presented for an ATOM cell fabricated in GlobalFoundries’ 45 nm RFSOI technology. The effect of limited retention and its variability is evaluated for training a fully connected neural network with a variable number of layers for the MNIST hand-written digit recognition task. Our studies show that weight decay due to temporary memory can have benefits equivalent to regularization , achieving a ∼ 33\% ∼33\% reduction in the validation error (from 3 . 6\% 3.6\% to 2 . 4\% 2.4\% ). We also show that the controllability of the decay timescale can be advantageous in achieving a further ∼ 26\% ∼26\% reduction in the validation error. This strongly suggests the utility of temporary memory during learning before on-chip non-volatile memories can take over for the storage and inference tasks using the neural network weights. We thus propose an algorithm-circuit codesign in the form of temporary analog memory for high-performing on-chip learning of ANNs.},
  archive      = {J_NN},
  author       = {Raghav Singhal and Vivek Saraswat and Shreyas Deshmukh and Sreenivas Subramoney and Laxmeesha Somappa and Maryam Shojaei Baghini and Udayan Ganguly},
  doi          = {10.1016/j.neunet.2023.07.001},
  journal      = {Neural Networks},
  pages        = {1050-1057},
  shortjournal = {Neural Netw.},
  title        = {Enhanced regularization for on-chip training using analog and temporary memory weights},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentiating brain states via multi-clip random fragment
strategy-based interactive bidirectional recurrent neural network.
<em>NN</em>, <em>165</em>, 1035–1049. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG is widely adopted to study the brain and brain computer interface (BCI) for its non-invasiveness and low costs. Specifically EEG can be applied to differentiate brain states, which is important for better understanding the working mechanisms of the brain . Recurrent neural network (RNN)-based learning strategy has been widely utilized to differentiate brain states, because its optimization architectures improve the classification performance for differentiating brain states at the group level. However, present classification performance is still far from satisfactory. We have identified two major focal points for improvements: one is about organizing the input EEG signals, and the other is related to the design of the RNN architecture. To optimize the above-mentioned issues and achieve better brain state classification performance, we propose a novel multi-clip random fragment strategy-based interactive bidirectional recurrent neural network (McRFS-IBiRNN) model in this work. This model has two advantages over previous methods. First, the McRFS component is designed to re-organize the input EEG signals to make them more suitable for the RNN architecture. Second, the IBiRNN component is an innovative design to model the RNN layers with interaction connections to enhance the fusion of bidirectional features. By adopting the proposed model, promising brain states classification performances are obtained. For example, 96.97\% and 99.34\% of individual and group level four-category classification accuracies are successfully obtained on the EEG motor/imagery dataset, respectively. A 99.01\% accuracy can be observed for four-category classification tasks with new subjects not seen before, which demonstrates the generalization of our proposed method. Compared with existing methods, our model outperforms them with superior results. Overall, the proposed McRFS-IBiRNN model demonstrates great superiority in differentiating brain states on EEG signals},
  archive      = {J_NN},
  author       = {Shu Zhang and Enze Shi and Lin Wu and Ruoyang Wang and Sigang Yu and Zhengliang Liu and Shaochen Xu and Tianming Liu and Shijie Zhao},
  doi          = {10.1016/j.neunet.2023.06.040},
  journal      = {Neural Networks},
  pages        = {1035-1049},
  shortjournal = {Neural Netw.},
  title        = {Differentiating brain states via multi-clip random fragment strategy-based interactive bidirectional recurrent neural network},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SNR: Symbolic network-based rectifiable learning framework
for symbolic regression. <em>NN</em>, <em>165</em>, 1021–1034. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic regression (SR) can be utilized to unveil the underlying mathematical expressions that describe a given set of observed data. At present, SR can be categorized into two methods: learning-from-scratch and learning-with-experience. Compared to learning-from-scratch, learning-with-experience yields results that are comparable to those of several benchmarks and incurs significantly lower time costs for obtaining expressions. However, the learning-with-experience model performs poorly in terms of unseen data distributions and lacks a rectification tool, apart from constant optimization, which exhibits limited performance. In this study, we propose a S ymbolic N etwork-based R ectifiable Learning Framework (SNR) that possesses the ability to correct errors. SNR adopts Symbolic Network (SymNet) to represent an expression, and the encoding of SymNet is designed to provide supervised information , with numerous self-generated expressions, to train a policy net (PolicyNet). The training of PolicyNet can offer prior knowledge to guide effective searches. Subsequently, the incorrectly predicted expressions are revised via a rectification mechanism. This rectification mechanism endows SNR with broader applicability. Experimental results demonstrate that our proposed method achieves the highest averaged coefficient of determination on self-generated datasets when compared with other state-of-the-art methods and yields more accurate results in public datasets.},
  archive      = {J_NN},
  author       = {Jingyi Liu and Weijun Li and Lina Yu and Min Wu and Linjun Sun and Wenqiang Li and Yanjie Li},
  doi          = {10.1016/j.neunet.2023.06.046},
  journal      = {Neural Networks},
  pages        = {1021-1034},
  shortjournal = {Neural Netw.},
  title        = {SNR: Symbolic network-based rectifiable learning framework for symbolic regression},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph structure learning layer and its graph convolution
clustering application. <em>NN</em>, <em>165</em>, 1010–1020. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To learn the embedding representation of graph structure data corrupted by noise and outliers, existing graph structure learning networks usually follow the two-step paradigm, i.e., constructing a “good” graph structure and achieving the message passing for signals supported on the learned graph. However, the data corrupted by noise may make the learned graph structure unreliable. In this paper, we propose an adaptive graph convolutional clustering network that alternatively adjusts the graph structure and node representation layer-by-layer with back-propagation. Specifically, we design a Graph Structure Learning layer before each Graph Convolutional layer to learn the sparse graph structure from the node representations, where the graph structure is implicitly determined by the solution to the optimal self-expression problem. This is one of the first works that uses an optimization process as a Graph Network layer, which is obviously different from the function operation in traditional deep learning layers. An efficient iterative optimization algorithm is given to solve the optimal self-expression problem in the Graph Structure Learning layer. Experimental results show that the proposed method can effectively defend the negative effects of inaccurate graph structures. The code is available at https://github.com/HeXiax/SSGNN .},
  archive      = {J_NN},
  author       = {Xiaxia He and Boyue Wang and Ruikun Li and Junbin Gao and Yongli Hu and Guangyu Huo and Baocai Yin},
  doi          = {10.1016/j.neunet.2023.06.024},
  journal      = {Neural Networks},
  pages        = {1010-1020},
  shortjournal = {Neural Netw.},
  title        = {Graph structure learning layer and its graph convolution clustering application},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigate forgetting in few-shot class-incremental learning
using different image views. <em>NN</em>, <em>165</em>, 999–1009. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the few-shot class incremental learning (FSCIL) setting, new classes with few training examples become available incrementally, and deep learning models suffer from catastrophic forgetting of the previous classes when trained on new classes. Data augmentation techniques are generally used to increase the training data and improve the model performance. In this work, we demonstrate that differently augmented views of the same image obtained by applying data augmentations may not necessarily activate the same set of neurons in the model. Therefore, the information gained by a model regarding a class, when trained using data augmentation, may not necessarily be stored in the same set of neurons in the model. Consequently, during incremental training, even if some of the model weights that store the previously seen class information for a particular view get overwritten, the information of the previous classes for the other views may still remain intact in the other model weights. Therefore, the impact of catastrophic forgetting on the model predictions is different for different data augmentations used during training. Based on this, we present an Augmentation-based Prediction Rectification (APR) approach to reduce the impact of catastrophic forgetting in the FSCIL setting. APR can also augment other FSCIL approaches and significantly improve their performance. We also propose a novel feature synthesis module (FSM) for synthesizing features relevant to the previously seen classes without requiring training data from these classes. FSM outperforms other generative approaches in this setting. We experimentally show that our approach outperforms other methods on benchmark datasets.},
  archive      = {J_NN},
  author       = {Pratik Mazumder and Pravendra Singh},
  doi          = {10.1016/j.neunet.2023.06.043},
  journal      = {Neural Networks},
  pages        = {999-1009},
  shortjournal = {Neural Netw.},
  title        = {Mitigate forgetting in few-shot class-incremental learning using different image views},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attribute-driven streaming edge partitioning with
reconciliations for distributed graph neural network training.
<em>NN</em>, <em>165</em>, 987–998. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current distributed graph training frameworks evenly partition a large graph into small chunks to suit distributed storage, leverage a uniform interface to access neighbors, and train graph neural networks in a cluster of machines to update weights. Nevertheless, they consider a separate design of storage and training, resulting in huge communication costs for retrieving neighborhoods. During the storage phase, traditional heuristic graph partitioning not only suffers from memory overhead because of loading the full graph into the memory but also damages semantically related structures because of its neglecting meaningful node attributes. What is more, in the weight-update phase, directly averaging synchronization is difficult to tackle with heterogeneous local models where each machine’s data are loaded from different subgraphs, resulting in slow convergence. To solve these problems, we propose a novel distributed graph training approach, attribute-driven streaming edge partitioning with reconciliations (ASEPR), where the local model loads only the subgraph stored on its own machine to make fewer communications. ASEPR firstly clusters nodes with similar attributes in the same partition to maintain semantic structure and keep multihop neighbor locality. Then streaming partitioning combined with attribute clustering is applied to subgraph assignment to alleviate memory overhead. After local graph neural network training on distributed machines, we deploy cross-layer reconciliation strategies for heterogeneous local models to improve the averaged global model by knowledge distillation and contrastive learning . Extensive experiments conducted on four large graph datasets on node classification and link prediction tasks show that our model outperforms DistDGL, with fewer resource requirements and up to quadruple the convergence speed.},
  archive      = {J_NN},
  author       = {Zongshen Mu and Siliang Tang and Yueting Zhuang and Dianhai Yu},
  doi          = {10.1016/j.neunet.2023.06.026},
  journal      = {Neural Networks},
  pages        = {987-998},
  shortjournal = {Neural Netw.},
  title        = {Attribute-driven streaming edge partitioning with reconciliations for distributed graph neural network training},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analytical interpretation of the gap of CNN’s cognition
between SAR and optical target recognition. <em>NN</em>, <em>165</em>,
982–986. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic aperture radar (SAR) automatic target recognition (ATR) is a crucial technique utilized in various scenarios of geoscience and remote sensing. Despite the remarkable success of convolutional neural networks (CNNs) in optical vision tasks, the application of CNNs in SAR ATR is still a challenging area due to the significant differences in the imaging mechanisms of SAR and optical images. This paper analytically addresses the cognitive gap of CNNs between optical and SAR images by leveraging multi-order interactions to measure their representation capacity. Furthermore, we propose a subjective evaluation strategy to compare human interactions with those of CNNs. Our findings reveal that CNNs operate differently for optical and SAR images . Specifically, for SAR images, CNNs’ representation capacity is comparable to that of humans, as they can encode intermediate interactions better than simple and complex ones. In contrast, for optical images, CNNs excel at encoding simple and complex interactions, but not intermediate interactions.},
  archive      = {J_NN},
  author       = {Zhenpeng Feng and Hongbing Ji and Miloš Daković and Mingzhe Zhu and Ljubiša Stanković},
  doi          = {10.1016/j.neunet.2023.06.037},
  journal      = {Neural Networks},
  pages        = {982-986},
  shortjournal = {Neural Netw.},
  title        = {Analytical interpretation of the gap of CNN’s cognition between SAR and optical target recognition},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurodynamic optimization approaches with finite/fixed-time
convergence for absolute value equations. <em>NN</em>, <em>165</em>,
971–981. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes three novel accelerated inverse-free neurodynamic approaches to solve absolute value equations (AVEs). The first two are finite-time converging approaches and the third one is a fixed-time converging approach. It is shown that the proposed first two neurodynamic approaches converge to the solution of the concerned AVEs in a finite-time while, under some mild conditions, the third one converges to the solution in a fixed-time. It is also shown that the settling time for the proposed fixed-time converging approach has an uniform upper bound for all initial conditions, while the settling times for the proposed finite-time converging approaches are dependent on initial conditions. The proposed neurodynamic approaches have the advantage that they are all robust against bounded vanishing perturbations. The theoretical results are validated by means of a numerical example and an application in boundary value problems .},
  archive      = {J_NN},
  author       = {Xingxing Ju and Xinsong Yang and Gang Feng and Hangjun Che},
  doi          = {10.1016/j.neunet.2023.06.041},
  journal      = {Neural Networks},
  pages        = {971-981},
  shortjournal = {Neural Netw.},
  title        = {Neurodynamic optimization approaches with finite/fixed-time convergence for absolute value equations},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GBT: Two-stage transformer framework for non-stationary time
series forecasting. <em>NN</em>, <em>165</em>, 953–970. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows that time series forecasting Transformer (TSFT) suffers from severe over-fitting problem caused by improper initialization method of unknown decoder inputs, especially when handling non-stationary time series. Based on this observation, we propose GBT , a novel two-stage T ransformer framework with G ood B eginning. It decouples the prediction process of TSFT into two stages, including Auto-Regression stage and Self-Regression stage to tackle the problem of different statistical properties between input and prediction sequences. Prediction results of Auto-Regression stage serve as a ‘ Good Beginning ’, i.e., a better initialization for inputs of Self-Regression stage. We also propose the E rror S core M odification module to further enhance the forecasting capability of the Self-Regression stage in GBT. Extensive experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting models (SCINet, N-HiTS, etc.) with only canonical attention and convolution while owning less time and space complexity. It is also general enough to couple with these models to strengthen their forecasting capability. The source code is available at: https://github.com/OrigamiSL/GBT},
  archive      = {J_NN},
  author       = {Li Shen and Yuning Wei and Yangzhu Wang},
  doi          = {10.1016/j.neunet.2023.06.044},
  journal      = {Neural Networks},
  pages        = {953-970},
  shortjournal = {Neural Netw.},
  title        = {GBT: Two-stage transformer framework for non-stationary time series forecasting},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-informed graph neural networks: A quantum chemistry
case study. <em>NN</em>, <em>165</em>, 938–952. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore different strategies to integrate prior domain knowledge into the design of graph neural networks (GNN). Our study is supported by a use-case of estimating the potential energy of chemical systems (molecules and crystals) represented as graphs. We integrate two elements of domain knowledge into the design of the GNN to constrain and regularise its learning, towards higher accuracy and generalisation. First, knowledge on the existence of different types of relations/graph edges (e.g. chemical bonds in our case study) between nodes of the graph is used to modulate their interactions. We formulate and compare two strategies, namely specialised message production and specialised update of internal states. Second, knowledge of the relevance of some physical quantities is used to constrain the learnt features towards a higher physical relevance using a simple multi-task learning (MTL) paradigm. We explore the potential of MTL to better capture the underlying mechanisms behind the studied phenomenon. We demonstrate the general applicability of our two knowledge integrations by applying them to three architectures that rely on different mechanisms to propagate information between nodes and to update node states. Our implementations are made publicly available. To support these experiments, we release three new datasets of out-of-equilibrium molecules and crystals of various complexities.},
  archive      = {J_NN},
  author       = {Jay Paul Morgan and Adeline Paiement and Christian Klinke},
  doi          = {10.1016/j.neunet.2023.06.030},
  journal      = {Neural Networks},
  pages        = {938-952},
  shortjournal = {Neural Netw.},
  title        = {Domain-informed graph neural networks: A quantum chemistry case study},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strengthening transferability of adversarial examples by
adaptive inertia and amplitude spectrum dropout. <em>NN</em>,
<em>165</em>, 925–937. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are sensitive to adversarial examples and would produce wrong results with high confidence. However, most existing attack methods exhibit weak transferability, especially for adversarially trained models and defense models. In this paper, two methods are proposed to generate highly transferable adversarial examples , namely Adaptive Inertia Iterative Fast Gradient Sign Method (AdaI 2 2 -FGSM) and Amplitude Spectrum Dropout Method (ASDM). Specifically, AdaI 2 2 -FGSM aims to integrate adaptive inertia into the gradient-based attack, and leverage the looking ahead property to search for a flatter maximum, which is essential to strengthen the transferability of adversarial examples. By introducing a loss-preserving transformation in the frequency domain, the proposed ASDM with the dropout invariance property can craft the copies of input images to overcome the poor generalization on the surrogate models . Furthermore, AdaI 2 2 -FGSM and ASDM can be naturally integrated as an efficient gradient-based attack method to yield more transferable adversarial examples. Extensive experimental results on the ImageNet-compatible dataset demonstrate that higher transferability is achieved by our method than some advanced gradient-based attacks.},
  archive      = {J_NN},
  author       = {Huanhuan Li and Wenbo Yu and He Huang},
  doi          = {10.1016/j.neunet.2023.06.031},
  journal      = {Neural Networks},
  pages        = {925-937},
  shortjournal = {Neural Netw.},
  title        = {Strengthening transferability of adversarial examples by adaptive inertia and amplitude spectrum dropout},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Graph convolutional network with tree-guided anisotropic
message passing. <em>NN</em>, <em>165</em>, 909–924. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) with naive message passing mechanisms have limited performance due to the isotropic aggregation strategy. To remedy this drawback, some recent works focus on how to design anisotropic aggregation strategies with tricks on feature mapping or structure mining. However, these models still suffer from the low ability of expressiveness and long-range modeling for the needs of high performance in practice. To this end, this paper proposes a tree-guided anisotropic GCN, which applies an anisotropic aggregation strategy with competitive expressiveness and a large receptive field. Specifically, the anisotropic aggregation is decoupled into two stages. The first stage is to establish the path of the message passing on a tree-like hypergraph consisting of substructures. The second one is to aggregate the messages with constrained intensities by employing an effective gating mechanism. In addition, a novel anisotropic readout mechanism is constructed to generate representative and discriminative graph-level features for downstream tasks. Our model outperforms baseline methods and recent works on several synthetic benchmarks and datasets from different real-world tasks. In addition, extensive ablation studies and theoretical analyses indicate the effectiveness of our proposed method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Yuhu Wang and Chunxia Zhang and Shiming Xiang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2023.06.034},
  journal      = {Neural Networks},
  pages        = {909-924},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with tree-guided anisotropic message passing},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight image de-snowing: A better trade-off between
network capacity and performance. <em>NN</em>, <em>165</em>, 896–908.
(<a href="https://doi.org/10.1016/j.neunet.2023.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single image de-snowing task is an essential topic in computer vision , as images captured on snowy days degrade the performance of current vision-based intelligent systems. Existing methods build complex network structures with numerous parameters to pursue continuous performance improvement. Nonetheless, they generally ignore the negative impact of large memory consumption in real applications. This paper aims to address the above problem by making a trade-off between network capacity and performance. We propose two novel networks suitable for different application scenarios. For devices with small memory and requiring fast inference speed, we propose an extremely lightweight recursive network (XLRNet). XLRNet is constructed by a single recursive strategy and two novel lightweight modules. For devices with large memory and pursuing better de-snowing performance, we propose a coupled lightweight dual recursive network (CLDRNet). CLDRNet cascades two XLRNets by a novel dual recursive strategy and a novel dual coupled LSTM module (DC-LSTM). Extensive experiments demonstrate the effectiveness and superiority of our two models on three synthetic datasets and real-world datasets.},
  archive      = {J_NN},
  author       = {Zheng Chen and Yiwen Sun and Xiaojun Bi and Jianyu Yue},
  doi          = {10.1016/j.neunet.2023.06.029},
  journal      = {Neural Networks},
  pages        = {896-908},
  shortjournal = {Neural Netw.},
  title        = {Lightweight image de-snowing: A better trade-off between network capacity and performance},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe control of logical control networks with random
impulses. <em>NN</em>, <em>165</em>, 884–895. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the framework of a hybrid-index model, this paper investigates safe control problems of state-dependent random impulsive logical control networks (RILCNs) on both finite and infinite horizons, respectively. By using the ξ ξ -domain method and the constructed transition probability matrix , the necessary and sufficient conditions for the solvability of safe control problems have been established. Further, based on the technique of state-space partition, two algorithms are proposed to design feedback controllers such that RILCNs can achieve the goal of safe control. Finally, two examples are shared to demonstrate the main results.},
  archive      = {J_NN},
  author       = {Rongpei Zhou and Yuqian Guo and Yuhao Wang and Zejun Sun and Xinzhi Liu},
  doi          = {10.1016/j.neunet.2023.06.035},
  journal      = {Neural Networks},
  pages        = {884-895},
  shortjournal = {Neural Netw.},
  title        = {Safe control of logical control networks with random impulses},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TCGAN: Convolutional generative adversarial network for time
series classification and clustering. <em>NN</em>, <em>165</em>,
868–883. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.},
  archive      = {J_NN},
  author       = {Fanling Huang and Yangdong Deng},
  doi          = {10.1016/j.neunet.2023.06.033},
  journal      = {Neural Networks},
  pages        = {868-883},
  shortjournal = {Neural Netw.},
  title        = {TCGAN: Convolutional generative adversarial network for time series classification and clustering},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stereoscopic scalable quantum convolutional neural networks.
<em>NN</em>, <em>165</em>, 860–867. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the noisy intermediate-scale quantum (NISQ) era has begun, a quantum neural network (QNN) is definitely a promising solution to many problems that classical neural networks cannot solve. In addition, a quantum convolutional neural network (QCNN) is now receiving a lot of attention because it can process high dimensional inputs comparing to QNN. However, due to the nature of quantum computing , it is difficult to scale up the QCNN to extract a sufficient number of features due to barren plateaus. This is especially challenging in classification operations with high-dimensional data input. However, due to the nature of quantum computing , it is difficult to scale up the QCNN to extract a sufficient number of features due to barren plateaus. This is especially challenging in classification operations with high dimensional data input. Motivated by this, a novel stereoscopic 3D scalable QCNN (sQCNN-3D) is proposed for point cloud data processing in classification applications. Furthermore, reverse fidelity training (RF-Train) is additionally considered on top of sQCNN-3D for diversifying features with a limited number of qubits using the fidelity of quantum computing. Our data-intensive performance evaluation verifies that the proposed algorithm achieves desired performance.},
  archive      = {J_NN},
  author       = {Hankyul Baek and Won Joon Yun and Soohyun Park and Joongheon Kim},
  doi          = {10.1016/j.neunet.2023.06.027},
  journal      = {Neural Networks},
  pages        = {860-867},
  shortjournal = {Neural Netw.},
  title        = {Stereoscopic scalable quantum convolutional neural networks},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive neural-network-based sliding mode control of
switching distributed delay systems with markov jump parameters.
<em>NN</em>, <em>165</em>, 846–859. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the issue of observer-based adaptive sliding mode control of distributed delay systems with deterministic switching rules and stochastic jumping process, simultaneously, through a neural network approach. Firstly, relying on the designed Lebesgue observer, a sliding mode hyperplane in the integral form is put forward, on which a desired sliding mode dynamic system is derived. Secondly, in consideration of complexity of real transition rates information, a novel adaptive dynamic controller that fits to universal mode information is designed to ensure the existence of sliding motion in finite-time, especially for the case that the mode information is totally unknown. In addition, an observer-based neural compensator is developed to attenuate the effectiveness of unknown system nonlinearity. Thirdly, an average dwell-time approach is utilized to check the mean-square exponential stability of the obtained sliding mode dynamics, particularly, the proposed criteria conditions are successfully unified with the designed controller in the type of mode information. Finally, a practical example is provided to verify the validity of the proposed method.},
  archive      = {J_NN},
  author       = {Baoping Jiang and Hamid Reza Karimi and Xin Zhang and Zhengtian Wu},
  doi          = {10.1016/j.neunet.2023.06.022},
  journal      = {Neural Networks},
  pages        = {846-859},
  shortjournal = {Neural Netw.},
  title        = {Adaptive neural-network-based sliding mode control of switching distributed delay systems with markov jump parameters},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic momentum methods for non-convex learning without
bounded assumptions. <em>NN</em>, <em>165</em>, 830–845. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic momentum methods are widely used to solve stochastic optimization problems in machine learning . However, most of the existing theoretical analyses rely on either bounded assumptions or strong stepsize conditions. In this paper, we focus on a class of non-convex objective functions satisfying the Polyak–Łojasiewicz (PL) condition and present a unified convergence rate analysis for stochastic momentum methods without any bounded assumptions, which covers stochastic heavy ball (SHB) and stochastic Nesterov accelerated gradient (SNAG). Our analysis achieves the more challenging last-iterate convergence rate of function values under the relaxed growth (RG) condition, which is a weaker assumption than those used in related work. Specifically, we attain the sub-linear rate for stochastic momentum methods with diminishing stepsizes, and the linear convergence rate for constant stepsizes if the strong growth (SG) condition holds. We also examine the iteration complexity for obtaining an ϵ -accurate solution of the last-iterate. Moreover, we provide a more flexible stepsize scheme for stochastic momentum methods in three points: ( i ) relaxing the last-iterate convergence stepsize from square summable to zero limitation; ( i i ) extending the minimum-iterate convergence rate stepsize to the non-monotonic case; ( i i i ) expanding the last-iterate convergence rate stepsize to a more general form. Finally, we conduct numerical experiments on benchmark datasets to validate our theoretical findings.},
  archive      = {J_NN},
  author       = {Yuqing Liang and Jinlan Liu and Dongpo Xu},
  doi          = {10.1016/j.neunet.2023.06.021},
  journal      = {Neural Networks},
  pages        = {830-845},
  shortjournal = {Neural Netw.},
  title        = {Stochastic momentum methods for non-convex learning without bounded assumptions},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reliable anchor regenerative-based transformer model for
x-small and dense objects recognition. <em>NN</em>, <em>165</em>,
809–829. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decade has witnessed significant progress in detecting objects by using enormous features of deep learning models. But, most of the existing models are unable to detect x-small and dense objects, due to the futility of feature extraction, and substantial misalignments between anchor boxes and axis-aligned convolution features, which leads to the discrepancy between the categorization score and positioning accuracy. This paper introduces an anchor regenerative-based transformer module in a feature refinement network to solve this problem. The anchor-regenerative module can generate anchor scales based on the semantic statistics of the objects present in the image, which avoids the inconsistency between the anchor boxes and axis-aligned convolution features. Whereas, the Multi-Head-Self-Attention (MHSA) based transformer module extracts the in-depth information from the feature maps based on the query, key, and value parameter information. This proposed model is experimentally verified on the VisDrone, VOC, and SKU-110K datasets. This model generates different anchor scales for these three datasets and achieves higher mAP, precision, and recall values on three datasets. These tested results prove that the suggested model has outstanding achievements compared with existing models in detecting x-small objects as well as dense objects. Finally, we evaluated the performance of these three datasets by using accuracy, kappa coefficient , and ROC metrics. These evaluated metrics demonstrate that our model is a good fit for VOC, and SKU-110K datasets.},
  archive      = {J_NN},
  author       = {Ponduri Vasanthi and Laavanya Mohan},
  doi          = {10.1016/j.neunet.2023.06.020},
  journal      = {Neural Networks},
  pages        = {809-829},
  shortjournal = {Neural Netw.},
  title        = {A reliable anchor regenerative-based transformer model for x-small and dense objects recognition},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An unsupervised STDP-based spiking neural network inspired
by biologically plausible learning rules and connections. <em>NN</em>,
<em>165</em>, 799–808. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The backpropagation algorithm has promoted the rapid development of deep learning , but it relies on a large amount of labeled data and still has a large gap with how humans learn. The human brain can quickly learn various conceptual knowledge in a self-organized and unsupervised manner , accomplished through coordinating various learning rules and structures in the human brain. Spike-timing-dependent plasticity (STDP) is a general learning rule in the brain, but spiking neural networks (SNNs) trained with STDP alone is inefficient and perform poorly. In this paper, taking inspiration from short-term synaptic plasticity , we design an adaptive synaptic filter and introduce the adaptive spiking threshold as the neuron plasticity to enrich the representation ability of SNNs. We also introduce an adaptive lateral inhibitory connection to adjust the spikes balance dynamically to help the network learn richer features. To speed up and stabilize the training of unsupervised spiking neural networks, we design a samples temporal batch STDP (STB-STDP), which updates weights based on multiple samples and moments. By integrating the above three adaptive mechanisms and STB-STDP, our model greatly accelerates the training of unsupervised spiking neural networks and improves the performance of unsupervised SNNs on complex tasks. Our model achieves the current state-of-the-art performance of unsupervised STDP-based SNNs in the MNIST and FashionMNIST datasets. Further, we tested on the more complex CIFAR10 dataset, and the results fully illustrate the superiority of our algorithm. Our model is also the first work to apply unsupervised STDP-based SNNs to CIFAR10. At the same time, in the small-sample learning scenario, it will far exceed the supervised ANN using the same structure.},
  archive      = {J_NN},
  author       = {Yiting Dong and Dongcheng Zhao and Yang Li and Yi Zeng},
  doi          = {10.1016/j.neunet.2023.06.019},
  journal      = {Neural Networks},
  pages        = {799-808},
  shortjournal = {Neural Netw.},
  title        = {An unsupervised STDP-based spiking neural network inspired by biologically plausible learning rules and connections},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysis on the inherent noise tolerance of feedforward
network and one noise-resilient structure. <em>NN</em>, <em>165</em>,
786–798. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few decades, feedforward neural networks have gained much attraction in their hardware implementations. However, when we realize a neural network in analog circuits , the circuit-based model is sensitive to hardware nonidealities. The nonidealities, such as random offset voltage drifts and thermal noise, may lead to variation in hidden neurons and further affect neural behaviors . This paper considers that time-varying noise exists at the input of hidden neurons , with zero-mean Gaussian distribution . First, we derive lower and upper bounds on the mean square error loss to estimate the inherent noise tolerance of a noise-free trained feedforward network. Then, the lower bound is extended for any non-Gaussian noise cases based on the Gaussian mixture model concept. The upper bound is generalized for any non-zero-mean noise case. As the noise could degrade the neural performance, a new network architecture is designed to suppress the noise effect. This noise-resilient design does not require any training process. We also discuss its limitation and give a closed-form expression to describe the noise tolerance when the limitation is exceeded.},
  archive      = {J_NN},
  author       = {Wenhao Lu and Zhengyuan Zhang and Feng Qin and Wenwen Zhang and Yuncheng Lu and Yue Liu and Yuanjin Zheng},
  doi          = {10.1016/j.neunet.2023.06.011},
  journal      = {Neural Networks},
  pages        = {786-798},
  shortjournal = {Neural Netw.},
  title        = {Analysis on the inherent noise tolerance of feedforward network and one noise-resilient structure},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A continuation method for image registration based on
dynamic adaptive kernel. <em>NN</em>, <em>165</em>, 774–785. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image registration is a fundamental problem in computer vision and robotics. Recently, learning-based image registration methods have made great progress. However, these methods are sensitive to abnormal transformation and have insufficient robustness, which leads to more mismatched points in the actual environment. In this paper, we propose a new registration framework based on ensemble learning and dynamic adaptive kernel. Specifically, we first use a dynamic adaptive kernel to extract deep features at the coarse level to guide fine-level registration. Then we added an adaptive feature pyramid network based on the integrated learning principle to realize the fine-level feature extraction. Through different scale, receptive fields, not only the local geometric information of each point is considered, but also its low texture information at the pixel level is considered. According to the actual registration environment, fine features are adaptively obtained to reduce the sensitivity of the model to abnormal transformation. We use the global receptive field provided in the transformer to obtain feature descriptors based on these two levels. In addition, we use the cosine loss directly defined on the corresponding relationship to train the network and balance the samples, to achieve feature point registration based on the corresponding relationship. Extensive experiments on object-level and scene-level datasets show that the proposed method outperforms existing state-of-the-art techniques by a large margin. More critically, it has the best generalization ability in unknown scenes with different sensor modes.},
  archive      = {J_NN},
  author       = {Yuandong Ma and Boyuan Wang and Hezheng Lin and Chun Liu and Mengjie Hu and Qing Song},
  doi          = {10.1016/j.neunet.2023.06.025},
  journal      = {Neural Networks},
  pages        = {774-785},
  shortjournal = {Neural Netw.},
  title        = {A continuation method for image registration based on dynamic adaptive kernel},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel framework of prescribed time/fixed time/finite time
stochastic synchronization control of neural networks and its
application in image encryption. <em>NN</em>, <em>165</em>, 755–773. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a novel framework for achieving prescribed-time (PAT), fixed-time (FXT) and finite-time (FNT) stochastic synchronization control of semi-Markov switching quaternion-valued neural networks (SMS-QVNNs), where the setting time (ST) of PAT/FXT/FNT stochastic synchronization control is effectively preassigned beforehand and estimated. Different from the existing frameworks of PAT/FXT/FNT control and PAT/FXT control (where PAT control is deeply dependent on FXT control, meaning that if the FXT control task is removed, it is impossible to implement the PAT control task), and different from the existing frameworks of PAT control (where a time-varying control gain such as μ ( t ) = T / ( T − t ) μ(t)=T/(T−t) with t ∈ [ 0 , T ) t∈[0,T) was employed, leading to an unbounded control gain as t → T − t→T− from the initial time to prescribed time T T ), the investigated framework is only built on a control strategy, which can accomplish its three control tasks (PAT/FXT/FNT control), and the control gains are bounded even though time t t tends to the prescribed time T T . Four numerical examples and an application of image encryption/decryption are given to illustrate the feasibility of our proposed framework.},
  archive      = {J_NN},
  author       = {Xin Wang and Jinde Cao and Xianghui Zhou and Ying Liu and Yaoxi Yan and Jiangtao Wang},
  doi          = {10.1016/j.neunet.2023.06.023},
  journal      = {Neural Networks},
  pages        = {755-773},
  shortjournal = {Neural Netw.},
  title        = {A novel framework of prescribed time/fixed time/finite time stochastic synchronization control of neural networks and its application in image encryption},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preassigned-time projective synchronization of delayed fully
quaternion-valued discontinuous neural networks with parameter
uncertainties. <em>NN</em>, <em>165</em>, 740–754. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns with the preassigned-time projective synchronization issue for delayed fully quaternion-valued discontinuous neural networks involving parameter uncertainties through the non-separation method. Above all, based on the existing works, a new preassigned-time stability theorem is established. Subsequently, to realize the control goals, two types of novel and simple chattering-free quaternion controllers are designed, one without the power-law term and the other with a hyperbolic-tangent function. They are different from the existing common power-law controller and exponential controller. Thirdly, under the Filippov discontinuity theories and with the aid of quaternion inequality techniques, some novel succinct sufficient criteria are obtained to ensure the addressed systems to achieve the preassigned-time synchronization by using the preassigned-time stability theory . The preassigned settling time is free from any parameter and any initial value of the system, and can be preset according to the actual task demands. Particularly, unlike the existing results, the proposed control methods can effectively avoid the chattering phenomenon, and the time delay part is removed for simplicity. Additionally, the projection coefficient is generic quaternion-valued instead of real-valued or complex-valued, and some of the previous relevant results are extended. Lastly, numerical simulations are reported to substantiate the effectiveness of the control strategies, the merits of preassigned settling time, and the correctness of the acquired results.},
  archive      = {J_NN},
  author       = {Hao Pu and Fengjun Li and Qingyun Wang and Pengzhen Li},
  doi          = {10.1016/j.neunet.2023.06.017},
  journal      = {Neural Networks},
  pages        = {740-754},
  shortjournal = {Neural Netw.},
  title        = {Preassigned-time projective synchronization of delayed fully quaternion-valued discontinuous neural networks with parameter uncertainties},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). De rham compatible deep neural network FEM. <em>NN</em>,
<em>165</em>, 721–739. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On general regular simplicial partitions T T of bounded polytopal domains Ω ⊂ R d Ω⊂Rd , d ∈ { 2 , 3 } d∈{2,3} , we construct exact neural network (NN) emulations of all lowest order finite element spaces in the discrete de Rham complex. These include the spaces of piecewise constant functions, continuous piecewise linear (CPwL) functions, the classical “Raviart–Thomas element”, and the “Nédélec edge element”. For all but the CPwL case, our network architectures employ both ReLU (rectified linear unit) and BiSU (binary step unit) activations to capture discontinuities. In the important case of CPwL functions, we prove that it suffices to work with pure ReLU nets. Our construction and DNN architecture generalizes previous results in that no geometric restrictions on the regular simplicial partitions T T of Ω Ω are required for DNN emulation. In addition, for CPwL functions our DNN construction is valid in any dimension d ≥ 2 d≥2 . Our “FE-Nets” are required in the variationally correct, structure-preserving approximation of boundary value problems of electromagnetism in nonconvex polyhedra Ω ⊂ R 3 Ω⊂R3 . They are thus an essential ingredient in the application of e.g., the methodology of “physics-informed NNs” or “deep Ritz methods” to electromagnetic field simulation via deep learning techniques. We indicate generalizations of our constructions to higher-order compatible spaces and other, non-compatible classes of discretizations , in particular the “Crouzeix–Raviart” elements and Hybridized, Higher Order (HHO) methods.},
  archive      = {J_NN},
  author       = {Marcello Longo and Joost A.A. Opschoor and Nico Disch and Christoph Schwab and Jakob Zech},
  doi          = {10.1016/j.neunet.2023.06.008},
  journal      = {Neural Networks},
  pages        = {721-739},
  shortjournal = {Neural Netw.},
  title        = {De rham compatible deep neural network FEM},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SiamDF: Tracking training data-free siamese tracker.
<em>NN</em>, <em>165</em>, 705–720. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much progress has been made in siamese tracking, primarily benefiting from increasing huge training data. However, very little attention has been really paid to the role of huge training data in learning an effective siamese tracker. In this study, we undertake an in-depth analysis of this issue from a novel optimization perspective, and observe that training data is particularly adept at background suppression, thereby refining target representation. Inspired by this insight, we present a data-free siamese tracking algorithm named SiamDF, which requires only a pre-trained backbone and no further fine-tuning on additional training data. Particularly, to suppress background distractors , we separately improve two branches of siamese tracking by retaining the pure target region as target input with the removal of template background, and by exploring an efficient inverse transformation to maintain the constant aspect ratio of target state in search region. Besides, we further promote the center displacement prediction of the entire backbone by eliminating its spatial stride deviations caused by convolution-like quantification operations. Our experimental results on several popular benchmarks demonstrate that SiamDF, free from both offline fine-tuning and online update, achieves impressive performance compared to well-established unsupervised and supervised tracking methods.},
  archive      = {J_NN},
  author       = {Huayue Cai and Long Lan and Jing Zhang and Xiang Zhang and Zhigang Luo},
  doi          = {10.1016/j.neunet.2023.06.012},
  journal      = {Neural Networks},
  pages        = {705-720},
  shortjournal = {Neural Netw.},
  title        = {SiamDF: Tracking training data-free siamese tracker},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive encoder pre-training-based clustered federated
learning for heterogeneous data. <em>NN</em>, <em>165</em>, 689–704. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising approach that enables distributed clients to collaboratively train a global model while preserving their data privacy. However, FL often suffers from data heterogeneity problems, which can significantly affect its performance. To address this, clustered federated learning (CFL) has been proposed to construct personalized models for different client clusters. One effective client clustering strategy is to allow clients to choose their own local models from a model pool based on their performance. However, without pre-trained model parameters, such a strategy is prone to clustering failure, in which all clients choose the same model. Unfortunately, collecting a large amount of labeled data for pre-training can be costly and impractical in distributed environments. To overcome this challenge, we leverage self-supervised contrastive learning to exploit unlabeled data for the pre-training of FL systems. Together, self-supervised pre-training and client clustering can be crucial components for tackling the data heterogeneity issues of FL. Leveraging these two crucial strategies, we propose contrastive pre-training-based clustered federated learning (CP-CFL) to improve the model convergence and overall performance of FL systems. In this work, we demonstrate the effectiveness of CP-CFL through extensive experiments in heterogeneous FL settings, and present various interesting observations.},
  archive      = {J_NN},
  author       = {Ye Lin Tun and Minh N.H. Nguyen and Chu Myaet Thwal and Jinwoo Choi and Choong Seon Hong},
  doi          = {10.1016/j.neunet.2023.06.010},
  journal      = {Neural Networks},
  pages        = {689-704},
  shortjournal = {Neural Netw.},
  title        = {Contrastive encoder pre-training-based clustered federated learning for heterogeneous data},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive hierarchical reinforcement learning for
path-efficient mapless navigation with moving target. <em>NN</em>,
<em>165</em>, 677–688. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has been proven as a powerful approach for robot navigation over the past few years. DRL-based navigation does not require the pre-construction of a map, instead, high-performance navigation skills can be learned from trial-and-error experiences. However, recent DRL-based approaches mostly focus on a fixed navigation target. It is noted that when navigating to a moving target without maps, the performance of the standard RL structure drops dramatically on both the success rate and path efficiency. To address the mapless navigation problem with moving target, the predictive hierarchical DRL (pH-DRL) framework is proposed by integrating the long-term trajectory prediction to provide a cost-effective solution. In the proposed framework, the lower-level policy of the RL agent learns robot control actions to a specified goal, and the higher-level policy learns to make long-range planning of shorter navigation routes by sufficiently exploiting the predicted trajectories. By means of making decisions over two level of policies, the pH-DRL framework is robust to the unavoidable errors in long-term predictions. With the application of deep deterministic policy gradient (DDPG) for policy optimization , the pH-DDPG algorithm is developed based on the pH-DRL structure. Finally, through comparative experiments on the Gazebo simulator with several variants of the DDPG algorithm, the results demonstrate that the pH-DDPG outperforms other algorithms and achieves a high success rate and efficiency even though the target moves fast and randomly.},
  archive      = {J_NN},
  author       = {Hanxiao Li and Biao Luo and Wei Song and Chunhua Yang},
  doi          = {10.1016/j.neunet.2023.06.007},
  journal      = {Neural Networks},
  pages        = {677-688},
  shortjournal = {Neural Netw.},
  title        = {Predictive hierarchical reinforcement learning for path-efficient mapless navigation with moving target},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum to “electrical coupling regulated by GABAergic
nucleo-olivary afferent fibres facilitates cerebellar sensory–motor
adaptation” [neural netw. 155 (2022) 422–438]. <em>NN</em>,
<em>165</em>, 676. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Niceto R. Luque and Francisco Naveros and Ignacio Abadía and Eduardo Ros and Angelo Arleo},
  doi          = {10.1016/j.neunet.2023.05.055},
  journal      = {Neural Networks},
  pages        = {676},
  shortjournal = {Neural Netw.},
  title        = {Corrigendum to “Electrical coupling regulated by GABAergic nucleo-olivary afferent fibres facilitates cerebellar sensory–motor adaptation” [Neural netw. 155 (2022) 422–438]},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High speed human action recognition using a photonic
reservoir computer. <em>NN</em>, <em>165</em>, 662–675. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of human actions in videos is one of the most active research fields in computer vision . The canonical approach consists in a more or less complex preprocessing stages of the raw video data, followed by a relatively simple classification algorithm . Here we address recognition of human actions using the reservoir computing algorithm, which allows us to focus on the classifier stage. We introduce a new training method for the reservoir computer, based on “Timesteps Of Interest”, which combines in a simple way short and long time scales. We study the performance of this algorithm using both numerical simulations and a photonic implementation based on a single non-linear node and a delay line on the well known KTH dataset. We solve the task with high accuracy and speed, to the point of allowing for processing multiple video streams in real time. The present work is thus an important step towards developing efficient dedicated hardware for video processing.},
  archive      = {J_NN},
  author       = {Enrico Picco and Piotr Antonik and Serge Massar},
  doi          = {10.1016/j.neunet.2023.06.014},
  journal      = {Neural Networks},
  pages        = {662-675},
  shortjournal = {Neural Netw.},
  title        = {High speed human action recognition using a photonic reservoir computer},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximation of classifiers by deep perceptron networks.
<em>NN</em>, <em>165</em>, 654–661. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We employ properties of high-dimensional geometry to obtain some insights into capabilities of deep perceptron networks to classify large data sets. We derive conditions on network depths, types of activation functions , and numbers of parameters that imply that approximation errors behave almost deterministically. We illustrate general results by concrete cases of popular activation functions : Heaviside, ramp sigmoid, rectified linear, and rectified power. Our probabilistic bounds on approximation errors are derived using concentration of measure type inequalities (method of bounded differences) and concepts from statistical learning theory .},
  archive      = {J_NN},
  author       = {Věra Kůrková and Marcello Sanguineti},
  doi          = {10.1016/j.neunet.2023.06.004},
  journal      = {Neural Networks},
  pages        = {654-661},
  shortjournal = {Neural Netw.},
  title        = {Approximation of classifiers by deep perceptron networks},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial–temporal recurrent reinforcement learning for
autonomous ships. <em>NN</em>, <em>165</em>, 634–653. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a spatial–temporal recurrent neural network architecture for deep Q Q -networks that can be used to steer an autonomous ship. The network design makes it possible to handle an arbitrary number of surrounding target ships while offering robustness to partial observability . Furthermore, a state-of-the-art collision risk metric is proposed to enable an easier assessment of different situations by the agent. The COLREG rules of maritime traffic are explicitly considered in the design of the reward function. The final policy is validated on a custom set of newly created single-ship encounters called ‘Around the Clock’ problems and the commonly used Imazu (1987) problems, which include 18 multi-ship scenarios. Performance comparisons with artificial potential field and velocity obstacle methods demonstrate the potential of the proposed approach for maritime path planning . Furthermore, the new architecture exhibits robustness when it is deployed in multi-agent scenarios and it is compatible with other deep reinforcement learning algorithms, including actor-critic frameworks.},
  archive      = {J_NN},
  author       = {Martin Waltz and Ostap Okhrin},
  doi          = {10.1016/j.neunet.2023.06.015},
  journal      = {Neural Networks},
  pages        = {634-653},
  shortjournal = {Neural Netw.},
  title        = {Spatial–temporal recurrent reinforcement learning for autonomous ships},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual distillation discriminator networks for domain adaptive
few-shot learning. <em>NN</em>, <em>165</em>, 625–633. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain Adaptive Few-Shot Learning (DA-FSL) aims at accomplishing few-shot classification tasks on a novel domain with the aid of a large number of source-style samples and several target-style samples. It is essential for DA-FSL to transfer task knowledge from the source domain to the target domain and overcome the asymmetry amount of labeled data in both domains. To this end, we propose Dual Distillation Discriminator Networks (D 3 3 Net) from the perspective of the lack of labeled target domain style samples in DA-FSL. Specifically, we employ the idea of distillation discrimination to avoid the over-fitting caused by the unequal number of samples in the target and source domains, which trains the student discriminator by the soft labels from the teacher discriminator. Meanwhile, we design the task propagation stage and the mixed domain stage respectively from the level of feature space and instances to generate more target-style samples, which apply the task distributions and the sample diversity of the source domain to enhance the target domain. Our D 3 3 Net realizes the distribution alignment between the source domain and the target domain and constraints the FSL task distribution by prototype distributions on the mixed domain. Extensive experiments on three DA-FSL benchmark datasets, i.e., mini-ImageNet, tiered-ImageNet, and DomainNet, demonstrate that our D 3 3 Net achieves competitive performance.},
  archive      = {J_NN},
  author       = {Xiyao Liu and Zhong Ji and Yanwei Pang and Zhi Han},
  doi          = {10.1016/j.neunet.2023.06.009},
  journal      = {Neural Networks},
  pages        = {625-633},
  shortjournal = {Neural Netw.},
  title        = {Dual distillation discriminator networks for domain adaptive few-shot learning},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Observer-based state estimation for discrete-time
semi-markovian jump neural networks with round-robin protocol against
cyber attacks. <em>NN</em>, <em>165</em>, 611–624. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an observer-based state estimation issue for discrete-time semi-Markovian jump neural networks with Round-Robin protocol and cyber attacks . In order to avoid the network congestion and save the communication resources, the Round-Robin protocol is used to schedule the data transmissions over the networks. Specifically, the cyber attacks are modeled as a set of random variables satisfying the Bernoulli distribution . On the basis of the Lyapunov functional and the discrete Wirtinger-based inequality technique, some sufficient conditions are established to guarantee the dissipativity performance and mean square exponential stability of the argument system. In order to compute the estimator gain parameters, a linear matrix inequality approach is utilized. Finally, two illustrative examples are provided to demonstrate the effectiveness of the proposed state estimation algorithm .},
  archive      = {J_NN},
  author       = {Ramalingam Sakthivel and Oh-Min Kwon and Seong-Gon Choi and Rathinasamy Sakthivel},
  doi          = {10.1016/j.neunet.2023.05.046},
  journal      = {Neural Networks},
  pages        = {611-624},
  shortjournal = {Neural Netw.},
  title        = {Observer-based state estimation for discrete-time semi-markovian jump neural networks with round-robin protocol against cyber attacks},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DyVGRNN: DYnamic mixture variational graph recurrent neural
networks. <em>NN</em>, <em>165</em>, 596–610. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although graph representation learning has been studied extensively in static graph settings, dynamic graphs are less investigated in this context. This paper proposes a novel integrated variational framework called DYnamic mixture Variational Graph Recurrent Neural Networks (DyVGRNN), which consists of extra latent random variables in structural and temporal modelling . Our proposed framework comprises an integration of Variational Graph Auto-Encoder (VGAE) and Graph Recurrent Neural Network (GRNN) by exploiting a novel attention mechanism . The Gaussian Mixture Model (GMM) and the VGAE framework are combined in DyVGRNN to model the multimodal nature of data, which enhances performance. To consider the significance of time steps, our proposed method incorporates an attention-based module. The experimental results demonstrate that our method greatly outperforms state-of-the-art dynamic graph representation learning methods in terms of link prediction and clustering. 2},
  archive      = {J_NN},
  author       = {Ghazaleh Niknam and Soheila Molaei and Hadi Zare and Shirui Pan and Mahdi Jalili and Tingting Zhu and David Clifton},
  doi          = {10.1016/j.neunet.2023.05.048},
  journal      = {Neural Networks},
  pages        = {596-610},
  shortjournal = {Neural Netw.},
  title        = {DyVGRNN: DYnamic mixture variational graph recurrent neural networks},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Genetic data visualization using literature text-based
neural networks: Examples associated with myocardial infarction.
<em>NN</em>, <em>165</em>, 562–595. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data visualization is critical to unraveling hidden information from complex and high-dimensional data. Interpretable visualization methods are critical, especially in the biology and medical fields, however, there are limited effective visualization methods for large genetic data. Current visualization methods are limited to lower-dimensional data and their performance suffers if there is missing data. In this study, we propose a literature-based visualization method to reduce high-dimensional data without compromising the dynamics of the single nucleotide polymorphisms (SNP) and textual interpretability . Our method is innovative because it is shown to (1) preserves both global and local structures of SNP while reducing the dimension of the data using literature text representations, and (2) enables interpretable visualizations using textual information. For performance evaluations, we examined the proposed approach to classify various classification categories including race, myocardial infarction event age groups, and sex using several machine learning models on the literature-derived SNP data. We used visualization approaches to examine clustering of data as well as quantitative performance metrics for the classification of the risk factors examined above. Our method outperformed all popular dimensionality reduction and visualization methods for both classification and visualization, and it is robust against missing and higher-dimensional data. Moreover, we found it feasible to incorporate both genetic and other risk information obtained from literature with our method.},
  archive      = {J_NN},
  author       = {Jihye Moon and Hugo F. Posada-Quintero and Ki H. Chon},
  doi          = {10.1016/j.neunet.2023.05.015},
  journal      = {Neural Networks},
  pages        = {562-595},
  shortjournal = {Neural Netw.},
  title        = {Genetic data visualization using literature text-based neural networks: Examples associated with myocardial infarction},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-modal deep neural network for multi-class liver
cancer diagnosis. <em>NN</em>, <em>165</em>, 553–561. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver disease is a potentially asymptomatic clinical entity that may progress to patient death. This study proposes a multi-modal deep neural network for multi-class malignant liver diagnosis. In parallel with the portal venous computed tomography (CT) scans, pathology data is utilized to prognosticate primary liver cancer variants and metastasis. The processed CT scans are fed to the deep dilated convolution neural network to explore salient features . The residual connections are further added to address vanishing gradient problems. Correspondingly, five pathological features are learned using a wide and deep network that gives a benefit of memorization with generalization. The down-scaled hierarchical features from CT scan and pathology data are concatenated to pass through fully connected layers for classification between liver cancer variants. In addition, the transfer learning of pre-trained deep dilated convolution layers assists in handling insufficient and imbalanced dataset issues. The fine-tuned network can predict three-class liver cancer variants with an average accuracy of 96.06\% and an Area Under Curve (AUC) of 0.832. To the best of our knowledge, this is the first study to classify liver cancer variants by integrating pathology and image data, hence following the medical perspective of malignant liver diagnosis. The comparative analysis on the benchmark dataset shows that the proposed multi-modal neural network outperformed most of the liver diagnostic studies and is comparable to others.},
  archive      = {J_NN},
  author       = {Rayyan Azam Khan and Minghan Fu and Brent Burbridge and Yigang Luo and Fang-Xiang Wu},
  doi          = {10.1016/j.neunet.2023.06.013},
  journal      = {Neural Networks},
  pages        = {553-561},
  shortjournal = {Neural Netw.},
  title        = {A multi-modal deep neural network for multi-class liver cancer diagnosis},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). H∞ master–slave synchronization for delayed impulsive
implicit hybrid neural networks based on memory-state feedback control.
<em>NN</em>, <em>165</em>, 540–552. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the H ∞ H∞ master–slave synchronization problem for delayed impulsive implicit hybrid neural networks based on memory-state feedback control . By developing a more holistic stochastic impulse-time-dependent Lyapunov–Krasovskii functional and dealing with the nonlinear neuron activation function , the stochastic admissibility and prescribed H ∞ H∞ performance index for the synchronization error closed-loop system are achieved. In addition, the desired mode-dependent memory-state feedback synchronization controller is acquired in the form of linear matrix inequalities. The free-weighting matrix technique is adopted to remove the inherent limitation of time-varying delay derivative for the implicit delayed systems, and the derivative of time-varying delay is relaxed enough to be greater than 1. The simulation of genetic regulatory network in bio-economic system is given to verify validity of the derived results.},
  archive      = {J_NN},
  author       = {Zekun Wang and Guangming Zhuang and Xiangpeng Xie and Jianwei Xia},
  doi          = {10.1016/j.neunet.2023.06.016},
  journal      = {Neural Networks},
  pages        = {540-552},
  shortjournal = {Neural Netw.},
  title        = {H∞ master–slave synchronization for delayed impulsive implicit hybrid neural networks based on memory-state feedback control},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-timescale recurrent neural networks for distributed
minimax optimization. <em>NN</em>, <em>165</em>, 527–539. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present two-timescale neurodynamic optimization approaches to distributed minimax optimization. We propose four multilayer recurrent neural networks for solving four different types of generally nonlinear convex–concave minimax problems subject to linear equality and nonlinear inequality constraints . We derive sufficient conditions to guarantee the stability and optimality of the neural networks . We demonstrate the viability and efficiency of the proposed neural networks in two specific paradigms for Nash-equilibrium seeking in a zero-sum game and distributed constrained nonlinear optimization .},
  archive      = {J_NN},
  author       = {Zicong Xia and Yang Liu and Jiasen Wang and Jun Wang},
  doi          = {10.1016/j.neunet.2023.06.003},
  journal      = {Neural Networks},
  pages        = {527-539},
  shortjournal = {Neural Netw.},
  title        = {Two-timescale recurrent neural networks for distributed minimax optimization},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced covertness class discriminative universal
adversarial perturbations. <em>NN</em>, <em>165</em>, 516–526. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main aim of class discriminative universal adversarial perturbations (CD-UAPs) is that the adversary can flexibly control the targeted class and influence remaining classes limitedly. CD-UAPs generated by the existing attack strategies suffer from a high fooling ratio of non-targeted source classes under non-targeted and targeted attacks, and face the increasing risk of discovery. In this paper, we propose a training framework for generating enhanced covertness CD-UAPs. It trains the targeted source class set and the non-targeted source classes set alternately to update the perturbation and introduces logit pairing to mitigate the influence of perturbation on the non-targeted source classes set. Further, we extend CD-UAPs on the targeted (one-targeted) attack to the multi-targeted attack, which perturbs a targeted source class to multiple targeted sink classes that seriously threaten the current scenario. It can not only provide the adversary with freedom of precise attack but reduce the risk of being detected. This attack poses a strong threat to security-sensitive applications. Extensive experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets show our method can generate more deceptive perturbations and enhance the covertness of CD-UAPs. For example, our method improves the absolute fooling ratio gaps of ResNet-20 and VGG-16 by 9.46\% and 6.94\% compared with the baseline method , respectively. We achieve the multi-targeted attack with a high fooling ratio on the GTSRB dataset. The average absolute target fooling ratio gaps of ResNet-20 and VGG-16 are 81.89\% and 76.33\%, respectively.},
  archive      = {J_NN},
  author       = {Haoran Gao and Hua Zhang and Xin Zhang and Wenmin Li and Jiahui Wang and Fei Gao},
  doi          = {10.1016/j.neunet.2023.06.006},
  journal      = {Neural Networks},
  pages        = {516-526},
  shortjournal = {Neural Netw.},
  title        = {Enhanced covertness class discriminative universal adversarial perturbations},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling limit order trading with a continuous action policy
for deep reinforcement learning. <em>NN</em>, <em>165</em>, 506–515. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Limit Orders allow buyers and sellers to set a “limit price” they are willing to accept in a trade. On the other hand, market orders allow for immediate execution at any price. Thus, market orders are susceptible to slippage, which is the additional cost incurred due to the unfavorable execution of a trade order. As a result, limit orders are often preferred, since they protect traders from excessive slippage costs due to larger than expected price fluctuations. Despite the price guarantees of limit orders, they are more complex compared to market orders. Orders with overly optimistic limit prices might never be executed, which increases the risk of employing limit orders in Machine Learning (ML)-based trading systems. Indeed, the current ML literature for trading almost exclusively relies on market orders. To overcome this limitation, a Deep Reinforcement Learning (DRL) approach is proposed to model trading agents that use limit orders. The proposed method (a) uses a framework that employs a continuous probability distribution to model limit prices, while (b) provides the ability to place market orders when the risk of no execution is more significant than the cost of slippage. Extensive experiments are conducted with multiple currency pairs, using hourly price intervals, validating the effectiveness of the proposed method and paving the way for introducing limit order modeling in DRL-based trading.},
  archive      = {J_NN},
  author       = {Avraam Tsantekidis and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1016/j.neunet.2023.05.051},
  journal      = {Neural Networks},
  pages        = {506-515},
  shortjournal = {Neural Netw.},
  title        = {Modeling limit order trading with a continuous action policy for deep reinforcement learning},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variational gated autoencoder-based feature extraction model
for inferring disease-miRNA associations based on multiview features.
<em>NN</em>, <em>165</em>, 491–505. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MicroRNAs (miRNA) play critical roles in diverse biological processes of diseases. Inferring potential disease-miRNA associations enable us to better understand the development and diagnosis of complex human diseases via computational algorithms. The work presents a variational gated autoencoder-based feature extraction model to extract complex contextual features for inferring potential disease-miRNA associations. Specifically, our model fuses three different similarities of miRNAs into a comprehensive miRNA network and then combines two various similarities of diseases into a comprehensive disease network, respectively. Then, a novel graph autoencoder is designed to extract multilevel representations based on variational gate mechanisms from heterogeneous networks of miRNAs and diseases. Finally, a gate-based association predictor is devised to combine multiscale representations of miRNAs and diseases via a novel contrastive cross-entropy function, and then infer disease-miRNA associations. Experimental results indicate that our proposed model achieves remarkable association prediction performance, proving the efficacy of the variational gate mechanism and contrastive cross-entropy loss for inferring disease-miRNA associations.},
  archive      = {J_NN},
  author       = {Yanbu Guo and Dongming Zhou and Xiaoli Ruan and Jinde Cao},
  doi          = {10.1016/j.neunet.2023.05.052},
  journal      = {Neural Networks},
  pages        = {491-505},
  shortjournal = {Neural Netw.},
  title        = {Variational gated autoencoder-based feature extraction model for inferring disease-miRNA associations based on multiview features},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative neurodynamic optimization for solving
nonlinear equations. <em>NN</em>, <em>165</em>, 483–490. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A distributed optimization method for solving nonlinear equations with constraints is developed in this paper. The multiple constrained nonlinear equations are converted into an optimization problem and we solve it in a distributed manner. Due to the possible presence of nonconvexity, the converted optimization problem might be a nonconvex optimization problem. To this end, we propose a multi-agent system based on an augmented Lagrangian function and prove that it converges to a locally optimal solution to an optimization problem in the presence of nonconvexity. In addition, a collaborative neurodynamic optimization method is adopted to obtain a globally optimal solution . Three numerical examples are elaborated to illustrate the effectiveness of the main results.},
  archive      = {J_NN},
  author       = {Huimin Guan and Yang Liu and Kit Ian Kou and Jinde Cao and Leszek Rutkowski},
  doi          = {10.1016/j.neunet.2023.05.054},
  journal      = {Neural Networks},
  pages        = {483-490},
  shortjournal = {Neural Netw.},
  title        = {Collaborative neurodynamic optimization for solving nonlinear equations},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Decentralized ADMM with compressed and event-triggered
communication. <em>NN</em>, <em>165</em>, 472–482. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the decentralized optimization problem , where agents in a network cooperate to minimize the sum of their local objective functions by communication and local computation. We propose a decentralized second-order communication-efficient algorithm called communication-censored and communication-compressed quadratically approximated alternating direction method of multipliers (ADMM), termed as CC-DQM, by combining event-triggered communication with compressed communication. In CC-DQM, agents are allowed to transmit the compressed message only when the current primal variables have changed greatly compared to its last estimate. Moreover, to relieve the computation cost, the update of Hessian is also scheduled by the trigger condition. Theoretical analysis shows that the proposed algorithm can still maintain an exact linear convergence , despite the existence of compression error and intermittent communication, if the local objective functions are strongly convex and smooth. Finally, numerical experiments demonstrate its satisfactory communication efficiency.},
  archive      = {J_NN},
  author       = {Zhen Zhang and Shaofu Yang and Wenying Xu},
  doi          = {10.1016/j.neunet.2023.06.001},
  journal      = {Neural Networks},
  pages        = {472-482},
  shortjournal = {Neural Netw.},
  title        = {Decentralized ADMM with compressed and event-triggered communication},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of common labels for universal domain adaptation.
<em>NN</em>, <em>165</em>, 463–471. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Universal domain adaptation (UniDA) is an unsupervised domain adaptation that selectively transfers the knowledge between different domains containing different label sets. However, the existing methods do not predict the common labels of different domains and manually set a threshold to discriminate private samples, so they rely on the target domain to finely select the threshold and ignore the problem of negative transfer. In this paper, to address the above problems, we propose a novel classification model named Prediction of Common Labels (PCL) for UniDA, in which the common labels are predicted by Category Separation via Clustering (CSC). It is noted that we devise a new evaluation metric called category separation accuracy to measure the performance of category separation. To weaken negative transfer, we select source samples by the predicted common labels to fine-tune model for better domain alignment. In the test process, the target samples are discriminated by the predicted common labels and the results of clustering. Experimental results on three widely used benchmark datasets indicate the effectiveness of the proposed method.},
  archive      = {J_NN},
  author       = {Xinxin Shan and Tai Ma and Ying Wen},
  doi          = {10.1016/j.neunet.2023.05.057},
  journal      = {Neural Networks},
  pages        = {463-471},
  shortjournal = {Neural Netw.},
  title        = {Prediction of common labels for universal domain adaptation},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MI-CAT: A transformer-based domain adaptation network for
motor imagery classification. <em>NN</em>, <em>165</em>, 451–462. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its convenience and safety, electroencephalography (EEG) data is one of the most widely used signals in motor imagery (MI) brain–computer interfaces (BCIs). In recent years, methods based on deep learning have been widely applied to the field of BCIs, and some studies have gradually tried to apply Transformer to EEG signal decoding due to its superior global information focusing ability. However, EEG signals vary from subject to subject. Based on Transformer, how to effectively use data from other subjects (source domain) to improve the classification performance of a single subject (target domain) remains a challenge. To fill this gap, we propose a novel architecture called MI-CAT. The architecture innovatively utilizes Transformer’s self-attention and cross-attention mechanisms to interact features to resolve differential distribution between different domains. Specifically, we adopt a patch embedding layer for the extracted source and target features to divide the features into multiple patches. Then, we comprehensively focus on the intra-domain and inter-domain features by stacked multiple Cross-Transformer Blocks (CTBs), which can adaptively conduct bidirectional knowledge transfer and information exchange between domains. Furthermore, we also utilize two non-shared domain-based attention blocks to efficiently capture domain-dependent information, optimizing the features extracted from the source and target domains to assist in feature alignment. To evaluate our method, we conduct extensive experiments on two real public EEG datasets, Dataset IIb and Dataset IIa, achieving competitive performance with an average classification accuracy of 85.26\% and 76.81\%, respectively. Experimental results demonstrate that our method is a powerful model for decoding EEG signals and facilitates the development of the Transformer for brain–computer interfaces (BCIs).},
  archive      = {J_NN},
  author       = {Dongxue Zhang and Huiying Li and Jingmeng Xie},
  doi          = {10.1016/j.neunet.2023.06.005},
  journal      = {Neural Networks},
  pages        = {451-462},
  shortjournal = {Neural Netw.},
  title        = {MI-CAT: A transformer-based domain adaptation network for motor imagery classification},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel adaptive zeroing neural dynamics schemes for
temporally-varying linear equation handling applied to arm path
following and target motion positioning. <em>NN</em>, <em>165</em>,
435–450. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the handling for temporally-varying linear equation (TVLE) has received extensive attention, most methods focused on trading off the conflict between computational precision and convergence rate. Different from previous studies, this paper proposes two complete adaptive zeroing neural dynamics (ZND) schemes, including a novel adaptive continuous ZND (ACZND) model, two general variable time discretization techniques, and two resultant adaptive discrete ZND (ADZND) algorithms, to essentially eliminate the conflict. Specifically, an error-related varying-parameter ACZND model with global and exponential convergence is first designed and proposed. To further adapt to the digital hardware, two novel variable time discretization techniques are proposed to discretize the ACZND model into two ADZND algorithms. The convergence properties with respect to the convergence rate and precision of ADZND algorithms are proved via rigorous mathematical analyses. By comparing with the traditional discrete ZND (TDZND) algorithms, the superiority of ADZND algorithms in convergence rate and computational precision is shown theoretically and experimentally. Finally, simulative experiments, including numerical experiments on a specific TVLE solving as well as four application experiments on arm path following and target motion positioning are successfully conducted to substantiate the efficacy, superiority, and practicability of ADZND algorithms.},
  archive      = {J_NN},
  author       = {Wenqi Wu and Yunong Zhang},
  doi          = {10.1016/j.neunet.2023.05.056},
  journal      = {Neural Networks},
  pages        = {435-450},
  shortjournal = {Neural Netw.},
  title        = {Novel adaptive zeroing neural dynamics schemes for temporally-varying linear equation handling applied to arm path following and target motion positioning},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The deep learning generative adversarial random neural
network in data marketplaces: The digital creative. <em>NN</em>,
<em>165</em>, 420–434. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have been proposed as a method to generate multiple replicas from an original version combining a Discriminator and a Generator. The main applications of GANs have been the casual generation of audio and video content. GANs, as a neural method that generates populations of individuals, have emulated genetic algorithms based on biologically inspired operators such as mutation, crossover and selection. This article presents the Deep Learning Generative Adversarial Random Neural Network (RNN) with the same features and functionality as a GAN. Furthermore, the presented algorithm is proposed for an application, the Digital Creative, that generates tradeable replicas in a Data Marketplace, such as 1D functions or audio, 2D and 3D images and video content. The RNN Generator creates individuals mapped from a latent space while the GAN Discriminator evaluates them based on the true data distribution. The performance of the Deep Learning Generative Adversarial RNN has been assessed against several input vectors with different dimensions, in addition to 1D functions and 2D images. The presented results are successful: the learning objective of the RNN Generator creates tradeable replicas at low error, whereas the RNN Discriminator learning target identifies unfit individuals.},
  archive      = {J_NN},
  author       = {Will Serrano},
  doi          = {10.1016/j.neunet.2023.05.028},
  journal      = {Neural Networks},
  pages        = {420-434},
  shortjournal = {Neural Netw.},
  title        = {The deep learning generative adversarial random neural network in data marketplaces: The digital creative},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive closed-loop paradigm of electrophysiology for
neuron models. <em>NN</em>, <em>165</em>, 406–419. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional electrophysiological experiments based on an open-loop paradigm are relatively complicated and limited when facing an individual neuron with uncertain nonlinear factors. Emerging neural technologies enable tremendous growth in experimental data leading to the curse of high-dimensional data, which obstructs the mechanism exploration of spiking activities in the neurons. In this work, we propose an adaptive closed-loop electrophysiology simulation experimental paradigm based on a Radial Basis Function neural network and a highly nonlinear unscented Kalman filter . On account of the complex nonlinear dynamic characteristics of the real neurons , the proposed simulation experimental paradigm could fit the unknown neuron models with different channel parameters and different structures (i.e. single or multiple compartments), and further compute the injected stimulus in time according to the arbitrary desired spiking activities of the neurons. However, the hidden electrophysiological states of the neurons are difficult to be measured directly. Thus, an extra Unscented Kalman filter modular is incorporated in the closed-loop electrophysiology experimental paradigm. The numerical results and theoretical analyses demonstrate that the proposed adaptive closed-loop electrophysiology simulation experimental paradigm achieves desired spiking activities arbitrarily and the hidden dynamics of the neurons are visualized by the unscented Kalman filter modular. The proposed adaptive closed-loop simulation experimental paradigm can avoid the inefficiency of data at increasingly greater scales and enhance the scalability of electrophysiological experiments, thus speeding up the discovery cycle on neuroscience .},
  archive      = {J_NN},
  author       = {Ming Yang and Jiang Wang and Shanshan Li and Kuanchuan Wang and Wei Yue and Chen Liu},
  doi          = {10.1016/j.neunet.2023.05.050},
  journal      = {Neural Networks},
  pages        = {406-419},
  shortjournal = {Neural Netw.},
  title        = {Adaptive closed-loop paradigm of electrophysiology for neuron models},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stable invariant models via koopman spectra. <em>NN</em>,
<em>165</em>, 393–405. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight-tied models have attracted attention in the modern development of neural networks . The deep equilibrium model (DEQ) represents infinitely deep neural networks with weight-tying, and recent studies have shown the potential of this type of approach. DEQs are needed to iteratively solve root-finding problems in training and are built on the assumption that the underlying dynamics determined by the models converge to a fixed point . In this paper, we present the stable invariant model (SIM) , a new class of deep models that in principle approximates DEQs under stability and extends the dynamics to more general ones converging to an invariant set (not restricted in a fixed point). The key ingredient in deriving SIMs is a representation of the dynamics with the spectra of the Koopman and Perron–Frobenius operators. This perspective approximately reveals stable dynamics with DEQs and then derives two variants of SIMs. We also propose an implementation of SIMs that can be learned in the same way as feedforward models. We illustrate the empirical performance of SIMs with experiments and demonstrate that SIMs achieve comparative or superior performance against DEQs in several learning tasks.},
  archive      = {J_NN},
  author       = {Takuya Konishi and Yoshinobu Kawahara},
  doi          = {10.1016/j.neunet.2023.05.040},
  journal      = {Neural Networks},
  pages        = {393-405},
  shortjournal = {Neural Netw.},
  title        = {Stable invariant models via koopman spectra},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BrainS: Customized multi-core embedded multiple scale
neuromorphic system. <em>NN</em>, <em>165</em>, 381–392. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on modeling and mechanisms of the brain remains the most urgent and challenging task. The customized embedded neuromorphic system is one of the most effective approaches for multi-scale simulations ranging from ion channel to network. This paper proposes BrainS, a scalable multi-core embedded neuromorphic system capable of accommodating massive and large-scale simulations. It is designed with rich external extension interfaces to support various types of input/output and communication requirements. The 3D mesh-based topology with an efficient memory access mechanism makes exploring the properties of neuronal networks possible. BrainS operates at 168 MHz and contains a model database ranging from ion channel to network scale within the Fundamental Computing Unit (FCU). At the ion channel scale, the Basic Community Unit (BCU) can perform real-time simulations of a Hodgkin–Huxley (HH) neuron with 16000 ion channels, using 125.54 KB of the SRAM . When the number of ion channels is within 64000, the HH neuron is simulated in real-time by 4 BCUs. At the network scale, the basal ganglia-thalamus (BG-TH) network consisting of 3200 Izhikevich neurons, providing a vital motor regulation function, is simulated in 4 BCUs with a power consumption of 364.8 mW. Overall, BrainS has an excellent performance in real-time and flexible configurability , providing an embedded application solution for multi-scale simulation.},
  archive      = {J_NN},
  author       = {Bo Gong and Jiang Wang and Meili Lu and Gong Meng and Kai Sun and Siyuan Chang and Zhen Zhang and Xile Wei},
  doi          = {10.1016/j.neunet.2023.05.043},
  journal      = {Neural Networks},
  pages        = {381-392},
  shortjournal = {Neural Netw.},
  title        = {BrainS: Customized multi-core embedded multiple scale neuromorphic system},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task guided representation learning using compositional
models for zero-shot domain adaptation. <em>NN</em>, <em>165</em>,
370–380. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot domain adaptation (ZDA) methods aim to transfer knowledge about a task learned in a source domain to a target domain, while task-relevant data from target domain are not available. In this work, we address learning feature representations which are invariant to and shared among different domains considering task characteristics for ZDA. To this end, we propose a method for task-guided ZDA (TG-ZDA) which employs multi-branch deep neural networks to learn feature representations exploiting their domain invariance and shareability properties. The proposed TG-ZDA models can be trained end-to-end without requiring synthetic tasks and data generated from estimated representations of target domains. The proposed TG-ZDA has been examined using benchmark ZDA tasks on image classification datasets. Experimental results show that our proposed TG-ZDA outperforms state-of-the-art ZDA methods for different domains and tasks.},
  archive      = {J_NN},
  author       = {Shuang Liu and Mete Ozay},
  doi          = {10.1016/j.neunet.2023.05.030},
  journal      = {Neural Networks},
  pages        = {370-380},
  shortjournal = {Neural Netw.},
  title        = {Task guided representation learning using compositional models for zero-shot domain adaptation},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial feature hybrid framework for steganography with
shifted window local loss. <em>NN</em>, <em>165</em>, 358–369. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image steganography is a long-standing image security problem that aims at hiding information in cover images. In recent years, the application of deep learning to steganography has the tendency to outperform traditional methods. However, the vigorous development of CNN-based steganalyzers still have a serious threat to steganography methods. To address this gap, we present an end-to-end adversarial steganography framework based on CNN and Transformer learned by shifted window local loss, called StegoFormer, which contains Encoder, Decoder, and Discriminator . Encoder is a hybrid model based on U-shaped network and Transformer block, which effectively integrates high-resolution spatial features and global self-attention features. In particular, Shuffle Linear layer is suggested, which can enhance the linear layer’s competence to extract local features . Given the substantial error in the central patch of the stego image , we propose shifted window local loss learning to assist Encoder in generating accurate stego images via weighted local loss. Furthermore, Gaussian mask augmentation method is designed to augment data for Discriminator , which helps to improve the security of Encoder through adversarial training . Controlled experiments show that StegoFormer is superior to the existing advanced steganography methods in terms of anti-steganalysis ability, steganography effectiveness, and information restoration.},
  archive      = {J_NN},
  author       = {Zhengze Li and Xiaoyuan Yang and Kangqing Shen and Fazhen Jiang and Jin Jiang and Huwei Ren and Yixiao Li},
  doi          = {10.1016/j.neunet.2023.05.053},
  journal      = {Neural Networks},
  pages        = {358-369},
  shortjournal = {Neural Netw.},
  title        = {Adversarial feature hybrid framework for steganography with shifted window local loss},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards global neural network abstractions with
locally-exact reconstruction. <em>NN</em>, <em>165</em>, 344–357. (<a
href="https://doi.org/10.1016/j.neunet.2023.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are a powerful class of non-linear functions. However, their black-box nature makes it difficult to explain their behaviour and certify their safety. Abstraction techniques address this challenge by transforming the neural network into a simpler, over-approximated function. Unfortunately, existing abstraction techniques are slack, which limits their applicability to small local regions of the input domain. In this paper, we propose Global Interval Neural Network Abstractions with Center-Exact Reconstruction (GINNACER). Our novel abstraction technique produces sound over-approximation bounds over the whole input domain while guaranteeing exact reconstructions for any given local input. Our experiments show that GINNACER is several orders of magnitude tighter than state-of-the-art global abstraction techniques, while being competitive with local ones.},
  archive      = {J_NN},
  author       = {Edoardo Manino and Iury Bessa and Lucas C. Cordeiro},
  doi          = {10.1016/j.neunet.2023.06.002},
  journal      = {Neural Networks},
  pages        = {344-357},
  shortjournal = {Neural Netw.},
  title        = {Towards global neural network abstractions with locally-exact reconstruction},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view subspace clustering via adaptive graph learning
and late fusion alignment. <em>NN</em>, <em>165</em>, 333–343. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering has attracted great attention due to its ability to explore data structure by utilizing complementary information from different views. Most of existing methods learn a sample representation coefficient matrix or an affinity graph for each single view, then the final clustering result is obtained from the spectral embedding of a consensus graph using certain traditional clustering techniques , such as k k -means. However, clustering performance will be degenerated if the early fusion of partitions cannot fully exploit relationships between all samples. Different from existing methods, we propose a multi-view subspace clustering method via adaptive graph learning and late fusion alignment (AGLLFA). For each view, AGLLFA learns an affinity graph adaptively to capture the similarity relationship among samples. Moreover, a spectral embedding learning term is designed to exploit the latent feature space of different views. Furthermore, we design a late fusion alignment mechanism to generate an optimal clustering partition by fusing view-specific partitions obtained from multiple views. An alternate updating algorithm with validated convergence is developed to solve the resultant optimization problem . Extensive experiments on several benchmark datasets are conducted to illustrate the effectiveness of the proposed method when compared with other state-of-the-art methods. The demo code of this work is publicly available at https://github.com/tangchuan2000/AGLLFA .},
  archive      = {J_NN},
  author       = {Chuan Tang and Kun Sun and Chang Tang and Xiao Zheng and Xinwang Liu and Jun-Jie Huang and Wei Zhang},
  doi          = {10.1016/j.neunet.2023.05.019},
  journal      = {Neural Networks},
  pages        = {333-343},
  shortjournal = {Neural Netw.},
  title        = {Multi-view subspace clustering via adaptive graph learning and late fusion alignment},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCADA securing system using deep learning to prevent cyber
infiltration. <em>NN</em>, <em>165</em>, 321–332. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervisory Control and Data Acquisition (SCADA) systems are computer-based control architectures specifically engineered for the operation of industrial machinery via hardware and software models. These systems are used to project, monitor, and automate the state of the operational network through the utilization of ethernet links, which enable two-way communications. However, as a result of their constant connectivity to the internet and the lack of security frameworks within their internal architecture, they are susceptible to cyber-attacks. In light of this, we have proposed an intrusion detection algorithm, intending to alleviate this security bottleneck. The proposed algorithm, the Genetically Seeded Flora (GSF) feature optimization algorithm , is integrated with Transformer Neural Network (TNN) and functions by detecting changes in operational patterns that may be indicative of an intruder’s involvement. The proposed Genetically Seeded Flora Transformer Neural Network (GSFTNN) algorithm stands in stark contrast to the signature-based method employed by traditional intrusion detection systems . To evaluate the performance of the proposed algorithm, extensive experiments are conducted using the WUSTL-IIOT-2018 ICS SCADA cyber security dataset. The results of these experiments indicate that the proposed algorithm outperforms traditional algorithms such as Residual Neural Networks (ResNet), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM) in terms of accuracy and efficiency.},
  archive      = {J_NN},
  author       = {Sayawu Yakubu Diaba and Theophilus Anafo and Lord Anertei Tetteh and Michael Alewo Oyibo and Andrew Adewale Alola and Miadreza Shafie-khah and Mohammed Elmusrati},
  doi          = {10.1016/j.neunet.2023.05.047},
  journal      = {Neural Networks},
  pages        = {321-332},
  shortjournal = {Neural Netw.},
  title        = {SCADA securing system using deep learning to prevent cyber infiltration},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retinal vessel segmentation via a multi-resolution
contextual network and adversarial learning. <em>NN</em>, <em>165</em>,
310–320. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and affordable computer-aided diagnosis of retinal diseases is pivotal in precluding blindness. Accurate retinal vessel segmentation plays an important role in disease progression and diagnosis of such vision-threatening diseases. To this end, we propose a Multi-resolution Contextual Network (MRC-Net) that addresses these issues by extracting multi-scale features to learn contextual dependencies between semantically different features and using bi-directional recurrent learning to model former-latter and latter-former dependencies. Another key idea is training in adversarial settings for foreground segmentation improvement through optimization of the region-based scores. This novel strategy boosts the performance of the segmentation network in terms of the Dice score (and correspondingly Jaccard index) while keeping the number of trainable parameters comparatively low. We have evaluated our method on three benchmark datasets, including DRIVE, STARE, and CHASE, demonstrating its superior performance as compared with competitive approaches elsewhere in the literature.},
  archive      = {J_NN},
  author       = {Tariq M. Khan and Syed S. Naqvi and Antonio Robles-Kelly and Imran Razzak},
  doi          = {10.1016/j.neunet.2023.05.029},
  journal      = {Neural Networks},
  pages        = {310-320},
  shortjournal = {Neural Netw.},
  title        = {Retinal vessel segmentation via a multi-resolution contextual network and adversarial learning},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discriminative analysis dictionary learning with adaptively
ordinal locality preserving. <em>NN</em>, <em>165</em>, 298–309. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dictionary learning has found broad applications in signal and image processing . By adding constraints to the traditional dictionary learning model, dictionaries with discriminative capability can be obtained which can deal with the task of image classification . The Discriminative Convolutional Analysis Dictionary Learning (DCADL) algorithm proposed recently has achieved promising results with low computational complexity . However, DCADL is still limited in classification performance because of the lack of constraints on dictionary structures. To solve this problem, this study introduces an adaptively ordinal locality preserving (AOLP) term to the original model of DCADL to further improve the classification performance. With the AOLP term, the distance ranking in the neighborhood of each atom can be preserved, which can improve the discrimination of coding coefficients. In addition, a linear classifier for the classification of coding coefficients is trained along with the dictionary. A new method is designed specifically to solve the optimization problem corresponding to the proposed model. Experiments are performed on several commonly used datasets to show the promising results of the proposed algorithm in classification performance and computational efficiency.},
  archive      = {J_NN},
  author       = {Jing Dong and Kai Wu and Chang Liu and Xue Mei and Wenwu Wang},
  doi          = {10.1016/j.neunet.2023.05.022},
  journal      = {Neural Networks},
  pages        = {298-309},
  shortjournal = {Neural Netw.},
  title        = {Discriminative analysis dictionary learning with adaptively ordinal locality preserving},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stabilization of reaction–diffusion fractional-order
memristive neural networks. <em>NN</em>, <em>165</em>, 290–297. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the stabilization control of fractional-order memristive neural networks with reaction–diffusion terms. With regard to the reaction–diffusion model, a novel processing method based on Hardy–Poincarè inequality is introduced, as a result, the diffusion terms are estimated associated with the information of the reaction–diffusion coefficients and the regional feature, which may be beneficial to obtain conditions with less conservatism. Then, based on Kakutani’s fixed point theorem of set-valued maps, new testable algebraic conclusion for ensuring the existence of the system’s equilibrium point is obtained. Subsequently, by means of Lyapunov stability theory , it is concluded that the resulting stabilization error system is global asymptotic/Mittag-Leffler stable with a prescribed controller. Finally, an illustrative example about is provided to show the effectiveness of the established results.},
  archive      = {J_NN},
  author       = {Ruoxia Li and Jinde Cao and Ning Li},
  doi          = {10.1016/j.neunet.2023.05.042},
  journal      = {Neural Networks},
  pages        = {290-297},
  shortjournal = {Neural Netw.},
  title        = {Stabilization of reaction–diffusion fractional-order memristive neural networks},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Fixed-time synchronization for quaternion-valued
memristor-based neural networks with mixed delays. <em>NN</em>,
<em>165</em>, 274–289. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the fixed-time synchronization (FXTSYN) of unilateral coefficients quaternion-valued memristor-based neural networks (UCQVMNNs) with mixed delays is investigated. A direct analytical approach is suggested to obtain FXTSYN of UCQVMNNs utilizing one-norm smoothness in place of decomposition. When dealing with drive–response system discontinuity issues, use the set-valued map and the differential inclusion theorem. To accomplish the control objective, innovative nonlinear controllers and the Lyapunov functions are designed. Furthermore, some criteria of FXTSYN for UCQVMNNs are given using inequality techniques and the novel FXTSYN theory. And the accurate settling time is obtained explicitly. Finally, in order to show that the obtained theoretical results are accurate, useful, and applicable, numerical simulations are presented at the conclusion.},
  archive      = {J_NN},
  author       = {Yanlin Zhang and Liqiao Yang and Kit Ian Kou and Yang Liu},
  doi          = {10.1016/j.neunet.2023.05.045},
  journal      = {Neural Networks},
  pages        = {274-289},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time synchronization for quaternion-valued memristor-based neural networks with mixed delays},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VLAD: Task-agnostic VAE-based lifelong anomaly detection.
<em>NN</em>, <em>165</em>, 248–273. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong learning represents an emerging machine learning paradigm that aims at designing new methods providing accurate analyses in complex and dynamic real-world environments. Although a significant amount of research has been conducted in image classification and reinforcement learning , very limited work has been done to solve lifelong anomaly detection problems. In this context, a successful method has to detect anomalies while adapting to changing environments and preserving knowledge to avoid catastrophic forgetting. While state-of-the-art online anomaly detection methods are able to detect anomalies and adapt to a changing environment, they are not designed to preserve past knowledge. On the other hand, while lifelong learning methods are focused on adapting to changing environments and preserving knowledge, they are not tailored for detecting anomalies , and often require task labels or task boundaries which are not available in task-agnostic lifelong anomaly detection scenarios. This paper proposes VLAD , a novel V AE-based L ifelong A nomaly D etection method addressing all these challenges simultaneously in complex task-agnostic scenarios. VLAD leverages the combination of lifelong change point detection and an effective model update strategy supported by experience replay with a hierarchical memory maintained by means of consolidation and summarization. An extensive quantitative evaluation showcases the merit of the proposed method in a variety of applied settings. VLAD outperforms state-of-the-art methods for anomaly detection, presenting increased robustness and performance in complex lifelong settings.},
  archive      = {J_NN},
  author       = {Kamil Faber and Roberto Corizzo and Bartlomiej Sniezynski and Nathalie Japkowicz},
  doi          = {10.1016/j.neunet.2023.05.032},
  journal      = {Neural Networks},
  pages        = {248-273},
  shortjournal = {Neural Netw.},
  title        = {VLAD: Task-agnostic VAE-based lifelong anomaly detection},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forward propagation dropout in deep neural networks using
jensen–shannon and random forest feature importance ranking.
<em>NN</em>, <em>165</em>, 238–247. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dropout is a mechanism to prevent deep neural networks from overfitting and improving their generalization. Random dropout is the simplest method, where nodes are randomly terminated at each step of the training phase, which may lead to network accuracy reduction. In dynamic dropout, the importance of each node and its impact on the network performance is calculated, and the important nodes do not participate in the dropout. But the problem is that the importance of the nodes is not calculated consistently. A node may be considered less important and be dropped in one training epoch and on a batch of data before entering the next epoch, in which it may be an important node. On the other hand, calculating the importance of each unit in every training step is costly. In the proposed method, using random forest and Jensen–Shannon divergence, the importance of each node is calculated once. Then, in the forward propagation steps, the importance of the nodes is propagated and used in the dropout mechanism. This method is evaluated and compared with some previously proposed dropout approaches using two different deep neural network architectures on the MNIST, NorB, CIFAR10, CIFAR100, SVHN, and ImageNet datasets . The results suggest that the proposed method has better accuracy with fewer nodes and better generalizability . Also, the evaluations show that the approach has comparable complexity with other approaches and its convergence time is low as compared with state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Mohsen Heidari and Mohammad Hossein Moattar and Hamidreza Ghaffari},
  doi          = {10.1016/j.neunet.2023.05.044},
  journal      = {Neural Networks},
  pages        = {238-247},
  shortjournal = {Neural Netw.},
  title        = {Forward propagation dropout in deep neural networks using Jensen–Shannon and random forest feature importance ranking},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time cluster synchronization for complex dynamical
networks under FDI attack: A periodic control approach. <em>NN</em>,
<em>165</em>, 228–237. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time cluster synchronization problem is addressed for complex dynamical networks (CDNs) with cluster characteristics under false data injection (FDI) attacks. A type of FDI attack is taken into consideration to reflect the data manipulation that controllers in CDNs may suffer. In order to improve the synchronization effect while reducing the control cost, a new periodic secure control (PSC) strategy is proposed in which the set of pinning nodes changes periodically. The aim of this paper is to derive the gains of the periodic secure controller such that the synchronization error of the CDN remains at a certain threshold in finite time with the presence of external disturbances and false control signals simultaneously. Through considering the periodic characteristics of PSC, a sufficient condition is obtained to guarantee the desired cluster synchronization performance, based on which the gains of the periodic cluster synchronization controllers are acquired by resolving an optimization problem proposed in this paper. A numerical case is carried out to validate the cluster synchronization performance of the PSC strategy under cyber attacks .},
  archive      = {J_NN},
  author       = {Jun-Yi Li and Yang-Cheng Huang and Hong-Xia Rao and Yong Xu and Renquan Lu},
  doi          = {10.1016/j.neunet.2023.04.013},
  journal      = {Neural Networks},
  pages        = {228-237},
  shortjournal = {Neural Netw.},
  title        = {Finite-time cluster synchronization for complex dynamical networks under FDI attack: A periodic control approach},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reachable set estimation and stochastic sampled-data
exponential synchronization of markovian jump neural networks with
time-varying delays. <em>NN</em>, <em>165</em>, 213–227. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stochastic sampled-data exponential synchronization problem for Markovian jump neural networks (MJNNs) with time-varying delays and the reachable set estimation (RSE) problem for MJNNs subjected to external disturbances are investigated. Firstly, assuming that two sampled-data periods satisfy Bernoulli distribution , and introducing two stochastic variables to represent the unknown input delay and the sampled-data period respectively, the mode-dependent two-sided loop-based Lyapunov functional (TSLBLF) is constructed, and the conditions for the mean square exponential stability of the error system are derived. Furthermore, a mode-dependent stochastic sampled-data controller is designed. Secondly, by analyzing the unit-energy bounded disturbance of MJNNs, a sufficient condition is proved that all states of MJNNs are confined to an ellipsoid under zero initial condition. In order to make the target ellipsoid contain the reachable set of the system, a stochastic sampled-data controller with RSE is designed. Eventually, two numerical examples and an analog resistor–capacitor network circuit are provided to show that the textual approach can obtain a larger sampled-data period than the existing approach.},
  archive      = {J_NN},
  author       = {Linqi Wang and Jianwei Xia and Ju H. Park and Guoliang Chen and Xiangpeng Xie},
  doi          = {10.1016/j.neunet.2023.05.034},
  journal      = {Neural Networks},
  pages        = {213-227},
  shortjournal = {Neural Netw.},
  title        = {Reachable set estimation and stochastic sampled-data exponential synchronization of markovian jump neural networks with time-varying delays},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epicasting: An ensemble wavelet neural network for
forecasting epidemics. <em>NN</em>, <em>165</em>, 185–212. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious diseases remain among the top contributors to human illness and death worldwide, among which many diseases produce epidemic waves of infection. The lack of specific drugs and ready-to-use vaccines to prevent most of these epidemics worsens the situation. These force public health officials and policymakers to rely on early warning systems generated by accurate and reliable epidemic forecasters. Accurate forecasts of epidemics can assist stakeholders in tailoring countermeasures , such as vaccination campaigns, staff scheduling, and resource allocation, to the situation at hand, which could translate to reductions in the impact of a disease. Unfortunately, most of these past epidemics exhibit nonlinear and non-stationary characteristics due to their spreading fluctuations based on seasonal-dependent variability and the nature of these epidemics. We analyze various epidemic time series datasets using a maximal overlap discrete wavelet transform (MODWT) based autoregressive neural network and call it Ensemble Wavelet Neural Network (EWNet) model. MODWT techniques effectively characterize non-stationary behavior and seasonal dependencies in the epidemic time series and improve the nonlinear forecasting scheme of the autoregressive neural network in the proposed ensemble wavelet network framework. From a nonlinear time series viewpoint, we explore the asymptotic stationarity of the proposed EWNet model to show the asymptotic behavior of the associated Markov Chain . We also theoretically investigate the effect of learning stability and the choice of hidden neurons in the proposal. From a practical perspective, we compare our proposed EWNet framework with twenty-two statistical, machine learning , and deep learning models for fifteen real-world epidemic datasets with three test horizons using four key performance indicators . Experimental results show that the proposed EWNet is highly competitive compared to the state-of-the-art epidemic forecasting methods.},
  archive      = {J_NN},
  author       = {Madhurima Panja and Tanujit Chakraborty and Uttam Kumar and Nan Liu},
  doi          = {10.1016/j.neunet.2023.05.049},
  journal      = {Neural Networks},
  pages        = {185-212},
  shortjournal = {Neural Netw.},
  title        = {Epicasting: An ensemble wavelet neural network for forecasting epidemics},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforced mixture learning. <em>NN</em>, <em>165</em>,
175–184. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we formulate the standard mixture learning problem as a Markov Decision Process (MDP). We theoretically show that the objective value of the MDP is equivalent to the log-likelihood of the observed data with a slightly different parameter space constrained by the policy. Different from some classic mixture learning methods such as Expectation–Maximization (EM) algorithm, the proposed reinforced algorithm requires no distribution assumptions and can handle the non-convex clustered data by constructing a model-free reward to evaluate the mixture assignment based on the spectral graph theory and Linear Discriminant Analysis (LDA). Extensive experiments on both synthetic and real examples demonstrate that the proposed method is comparable with the EM algorithm when the Gaussian mixture assumption is satisfied, and significantly outperforms it and other clustering methods in most scenarios when the model is misspecified. A Python implementation of our proposed method is available at https://github.com/leyuanheart/Reinforced-Mixture-Learning .},
  archive      = {J_NN},
  author       = {Yuan Le and Fan Zhou and Yang Bai},
  doi          = {10.1016/j.neunet.2023.05.018},
  journal      = {Neural Networks},
  pages        = {175-184},
  shortjournal = {Neural Netw.},
  title        = {Reinforced mixture learning},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A regularization perspective based theoretical analysis for
adversarial robustness of deep spiking neural networks. <em>NN</em>,
<em>165</em>, 164–174. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Network (SNN) has been recognized as the third generation of neural networks. Conventionally, a SNN can be converted from a pre-trained Artificial Neural Network (ANN) with less computation and memory than training from scratch. But, these converted SNNs are vulnerable to adversarial attacks . Numerical experiments demonstrate that the SNN trained by optimizing the loss function will be more adversarial robust, but the theoretical analysis for the mechanism of robustness is lacking. In this paper, we provide a theoretical explanation by analyzing the expected risk function . Starting by modeling the stochastic process introduced by the Poisson encoder, we prove that there is a positive semidefinite regularizer. Perhaps surprisingly, this regularizer can make the gradients of the output with respect to input closer to zero, thus resulting in inherent robustness against adversarial attacks . Extensive experiments on the CIFAR10 and CIFAR100 datasets support our point of view. For example, we find that the sum of squares of the gradients of the converted SNNs is 13 ∼ ∼ 160 times that of the trained SNNs. And, the smaller the sum of the squares of the gradients, the smaller the degradation of accuracy under adversarial attack.},
  archive      = {J_NN},
  author       = {Hui Zhang and Jian Cheng and Jun Zhang and Hongyi Liu and Zhihui Wei},
  doi          = {10.1016/j.neunet.2023.05.038},
  journal      = {Neural Networks},
  pages        = {164-174},
  shortjournal = {Neural Netw.},
  title        = {A regularization perspective based theoretical analysis for adversarial robustness of deep spiking neural networks},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Topology identification for stochastic multi-layer networks
via graph-theoretic method. <em>NN</em>, <em>165</em>, 150–163. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topological structures of multi-layer networks have an important influence on their dynamical properties, but in most cases the topological structures of networks are unknown. Hence, this paper pays attention to investigating topology identification problems for multi-layer networks with stochastic perturbations. Both intra-layer coupling and inter-layer coupling are incorporated into the research model. Based on the graph-theoretic method and Lyapunov function , topology identification criteria for stochastic multi-layer networks are obtained by designing a suitable adaptive controller . Furthermore, to estimate the time of identification, the finite-time identification criteria are obtained by finite-time control technique. Finally, double-layer Watts–Strogatz small-world networks are presented for numerical simulations to illustrate the correctness of theoretical results.},
  archive      = {J_NN},
  author       = {Chunmei Zhang and Ran Li and Quanxin Zhu and Qin Xu},
  doi          = {10.1016/j.neunet.2023.05.036},
  journal      = {Neural Networks},
  pages        = {150-163},
  shortjournal = {Neural Netw.},
  title        = {Topology identification for stochastic multi-layer networks via graph-theoretic method},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention guided learnable time-domain filterbanks for
speech depression detection. <em>NN</em>, <em>165</em>, 135–149. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression, as a global mental health problem , is lacking effective screening methods that can help with early detection and treatment. This paper aims to facilitate the large-scale screening of depression by focusing on the speech depression detection (SDD) task. Currently, direct modeling on the raw signal yields a large number of parameters, and the existing deep learning-based SDD models mainly use the fixed Mel-scale spectral features as input. However, these features are not designed for depression detection, and the manual settings limit the exploration of fine-grained feature representations. In this paper, we learn the effective representations of the raw signals from an interpretable perspective. Specifically, we present a joint learning framework with attention-guided learnable time-domain filterbanks for depression classification (DALF), which collaborates with the depression filterbanks features learning (DFBL) module and multi-scale spectral attention learning (MSSA) module. DFBL is capable of producing biologically meaningful acoustic features by employing learnable time-domain filters, and MSSA is used to guide the learnable filters to better retain the useful frequency sub-bands. We collect a new dataset, the Neutral Reading-based Audio Corpus (NRAC), to facilitate the research in depression analysis, and we evaluate the performance of DALF on the NRAC and the public DAIC-woz datasets. The experimental results demonstrate that our method outperforms the state-of-the-art SDD methods with an F1 of 78.4\% on the DAIC-woz dataset. In particular, DALF achieves F1 scores of 87.3\% and 81.7\% on two parts of the NRAC dataset. By analyzing the filter coefficients , we find that the most important frequency range identified by our method is 600–700Hz, which corresponds to the Mandarin vowels / e / /e/ and / e ˆ / /eˆ/ and can be considered as an effective biomarker for the SDD task. Taken together, our DALF model provides a promising approach to depression detection.},
  archive      = {J_NN},
  author       = {Wenju Yang and Jiankang Liu and Peng Cao and Rongxin Zhu and Yang Wang and Jian K. Liu and Fei Wang and Xizhe Zhang},
  doi          = {10.1016/j.neunet.2023.05.041},
  journal      = {Neural Networks},
  pages        = {135-149},
  shortjournal = {Neural Netw.},
  title        = {Attention guided learnable time-domain filterbanks for speech depression detection},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSCDA: Multi-level semantic-guided contrast improves
unsupervised domain adaptation for breast MRI segmentation in small
datasets. <em>NN</em>, <em>165</em>, 119–134. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) applied to breast tissue segmentation in magnetic resonance imaging (MRI) has received increased attention in the last decade, however, the domain shift which arises from different vendors, acquisition protocols, and biological heterogeneity, remains an important but challenging obstacle on the path towards clinical implementation. In this paper, we propose a novel Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA) framework to address this issue in an unsupervised manner . Our approach incorporates self-training with contrastive learning to align feature representations between domains. In particular, we extend the contrastive loss by incorporating pixel-to-pixel, pixel-to-centroid, and centroid-to-centroid contrasts to better exploit the underlying semantic information of the image at different levels. To resolve the data imbalance problem, we utilize a category-wise cross-domain sampling strategy to sample anchors from target images and build a hybrid memory bank to store samples from source images. We have validated MSCDA with a challenging task of cross-domain breast MRI segmentation between datasets of healthy volunteers and invasive breast cancer patients . Extensive experiments show that MSCDA effectively improves the model’s feature alignment capabilities between domains, outperforming state-of-the-art methods. Furthermore, the framework is shown to be label-efficient, achieving good performance with a smaller source dataset . The code is publicly available at https://github.com/ShengKuangCN/MSCDA .},
  archive      = {J_NN},
  author       = {Sheng Kuang and Henry C. Woodruff and Renee Granzier and Thiemo J.A. van Nijnatten and Marc B.I. Lobbes and Marjolein L. Smidt and Philippe Lambin and Siamak Mehrkanoon},
  doi          = {10.1016/j.neunet.2023.05.014},
  journal      = {Neural Networks},
  pages        = {119-134},
  shortjournal = {Neural Netw.},
  title        = {MSCDA: Multi-level semantic-guided contrast improves unsupervised domain adaptation for breast MRI segmentation in small datasets},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An insect-inspired model facilitating autonomous navigation
by incorporating goal approaching and collision avoidance. <em>NN</em>,
<em>165</em>, 106–118. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being one of the most fundamental and crucial capacity of robots and animals, autonomous navigation that consists of goal approaching and collision avoidance enables completion of various tasks while traversing different environments. In light of the impressive navigational abilities of insects despite their tiny brains compared to mammals, the idea of seeking solutions from insects for the two key problems of navigation, i.e., goal approaching and collision avoidance , has fascinated researchers and engineers for many years. However, previous bio-inspired studies have focused on merely one of these two problems at one time. Insect-inspired navigation algorithms that synthetically incorporate both goal approaching and collision avoidance , and studies that investigate the interactions of these two mechanisms in the context of sensory–motor closed-loop autonomous navigation are lacking. To fill this gap, we propose an insect-inspired autonomous navigation algorithm to integrate the goal approaching mechanism as the global working memory inspired by the sweat bee’s path integration (PI) mechanism, and the collision avoidance model as the local immediate cue built upon the locust’s lobula giant movement detector (LGMD) model. The presented algorithm is utilized to drive agents to complete navigation task in a sensory–motor closed-loop manner within a bounded static or dynamic environment. Simulation results demonstrate that the synthetic algorithm is capable of guiding the agent to complete challenging navigation tasks in a robust and efficient way. This study takes the first tentative step to integrate the insect-like navigation mechanisms with different functionalities (i.e., global goal and local interrupt) into a coordinated control system that future research avenues could build upon.},
  archive      = {J_NN},
  author       = {Xuelong Sun and Qinbing Fu and Jigen Peng and Shigang Yue},
  doi          = {10.1016/j.neunet.2023.05.033},
  journal      = {Neural Networks},
  pages        = {106-118},
  shortjournal = {Neural Netw.},
  title        = {An insect-inspired model facilitating autonomous navigation by incorporating goal approaching and collision avoidance},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D graph neural network with few-shot learning for
predicting drug–drug interactions in scaffold-based cold start scenario.
<em>NN</em>, <em>165</em>, 94–105. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding drug–drug interactions (DDI) of new drugs is critical for minimizing unexpected adverse drug reactions. The modeling of new drugs is called a cold start scenario. In this scenario, Only a few structural information or physicochemical information about new drug is available. The 3D conformation of drug molecules usually plays a crucial role in chemical properties compared to the 2D structure. 3D graph network with few-shot learning is a promising solution. However, the 3D heterogeneity of drug molecules and the discretization of atomic distributions lead to spatial confusion in few-shot learning. Here, we propose a 3D graph neural network with few-shot learning, Meta3D-DDI, to predict DDI events in cold start scenario. The 3DGNN ensures rotation and translation invariance by calculating atomic pairwise distances , and incorporates 3D structure and distance information in the information aggregation stage. The continuous filter interaction module can continuously simulate the filter to obtain the interaction between the target atom and other atoms. Meta3D-DDI further develops a FSL strategy based on bilevel optimization to transfer meta-knowledge for DDI prediction tasks from existing drugs to new drugs. In addition, the existing cold start setting may cause the scaffold structure information in the training set to leak into the test set. We design scaffold-based cold start scenario to ensure that the drug scaffolds in the training set and test set do not overlap. The extensive experiments demonstrate that our architecture achieves the SOTA performance for DDI prediction under scaffold-based cold start scenario on two real-world datasets. The visual experiment shows that Meta3D-DDI significantly improves the learning for DDI prediction of new drugs. We also demonstrate how Meta3D-DDI can reduce the amount of data required to make meaningful DDI predictions.},
  archive      = {J_NN},
  author       = {Qiujie Lv and Jun Zhou and Ziduo Yang and Haohuai He and Calvin Yu-Chian Chen},
  doi          = {10.1016/j.neunet.2023.05.039},
  journal      = {Neural Networks},
  pages        = {94-105},
  shortjournal = {Neural Netw.},
  title        = {3D graph neural network with few-shot learning for predicting drug–drug interactions in scaffold-based cold start scenario},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HybridBranchNet: A novel structure for branch hybrid
convolutional neural networks architecture. <em>NN</em>, <em>165</em>,
77–93. (<a href="https://doi.org/10.1016/j.neunet.2023.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ConvNet deep neural networks are developed with a consistent structure. The availability of abundant resources helps these structures to be scaled and redesigned in different sizes so that they can be optimized for different applications. By increasing one or more dimensions of the network, such as depth, resolution and width, the number of trainable network parameters will increase and, as a result, the accuracy and performance It should be noted that the backtracking of the convolutional neural network will improve. However, but increasing the number of network parameters increases the complexity of the network, which is not desirable. Therefore, adjusting the structure of the network, increasing the speed, and reducing the number of network parameters along with ensuring accuracy optimization will be important. This study aims to examine a branch network structure systematically, which can lead to better performance. In this study, in order to increase the speed, to reduce the size of the convolutional network model, and to increase the accuracy optimization, a new scaling method, which optimally designs all dimensions of depth, width, and resolution, is proposed based on a branch neural network. A family of HybridBranchNet networks, which is more accurate and efficient than ConvNets, has been created along with this design. HybridBranchNet3 has a classification accuracy of 83.1\%. The proposed model was compared with a family of EfficientNet convolutional networks. The comparison results revealed that the proposed network exceeded the mentioned models in terms of accuracy and speed by 1.03\% and 39\%, respectively. They also showed that the number of trainable parameters is 13\% less than that of the EfficientNet network. The proposed method has an accuracy of 92.3\% in the CIFAR-100 dataset and 98.8\% in the Flowers-102 dataset. Although the architectures such as CoAtNet have slightly higher classification accuracy than the proposed method, they have a greater number of parameters that cannot be used in a conventional system.},
  archive      = {J_NN},
  author       = {Ebrahim Parcham and Mansoor Fateh},
  doi          = {10.1016/j.neunet.2023.05.025},
  journal      = {Neural Networks},
  pages        = {77-93},
  shortjournal = {Neural Netw.},
  title        = {HybridBranchNet: A novel structure for branch hybrid convolutional neural networks architecture},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal hashing with missing labels. <em>NN</em>,
<em>165</em>, 60–76. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing-based cross-modal retrieval methods have become increasingly popular due to their advantages in storage and speed. While current methods have demonstrated impressive results, there are still several issues that have not been addressed. Specifically, many of these approaches assume that labels are perfectly assigned, despite the fact that in real-world scenarios, labels are often incomplete or partially missing. There are two reasons for this, as manual labeling can be a complex and time-consuming task, and annotators may only be interested in certain objects. As such, cross-modal retrieval with missing labels is a significant challenge that requires further attention. Moreover, the similarity between labels is frequently ignored, which is important for exploring the high-level semantics of labels. To address these limitations, we propose a novel method called Cross-Modal Hashing with Missing Labels (CMHML). Our method consists of several key components. First, we introduce Reliable Label Learning to preserve reliable information from the observed labels. Next, to infer the uncertain part of the predicted labels, we decompose the predicted labels into latent representations of labels and samples. The representation of samples is extracted from different modalities, which assists in inferring missing labels. We also propose Label Correlation Preservation to enhance the similarity between latent representations of labels. Hash codes are then learned from the representation of samples through Global Approximation Learning. We also construct a similarity matrix according to predicted labels and embed it into hash codes learning to explore the value of labels. Finally, we train linear classifiers to map original samples to a low-dimensional Hamming space. To evaluate the efficacy of CMHML, we conduct extensive experiments on four publicly available datasets. Our method is compared to other state-of-the-art methods, and the results demonstrate that our model performs competitively even when most labels are missing.},
  archive      = {J_NN},
  author       = {Haomin Ni and Jianjun Zhang and Peipei Kang and Xiaozhao Fang and Weijun Sun and Shengli Xie and Na Han},
  doi          = {10.1016/j.neunet.2023.05.035},
  journal      = {Neural Networks},
  pages        = {60-76},
  shortjournal = {Neural Netw.},
  title        = {Cross-modal hashing with missing labels},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributional generative adversarial imitation learning
with reproducing kernel generalization. <em>NN</em>, <em>165</em>,
43–59. (<a href="https://doi.org/10.1016/j.neunet.2023.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial imitation learning (GAIL) regards imitation learning (IL) as a distribution matching problem between the state–action distributions of the expert policy and the learned policy. In this paper, we focus on the generalization and computational properties of policy classes. We prove that the generalization can be guaranteed in GAIL when the class of policies is well controlled. With the capability of policy generalization, we introduce distributional reinforcement learning (RL) into GAIL and propose the greedy distributional soft gradient (GDSG) algorithm to solve GAIL. The main advantages of GDSG can be summarized as: (1) Q-value overestimation, a crucial factor leading to the instability of GAIL with off-policy training, can be alleviated by distributional RL. (2) By considering the maximum entropy objective, the policy can be improved in terms of performance and sample efficiency through sufficient exploration. Moreover, GDSG attains a sublinear convergence rate to a stationary solution. Comprehensive experimental verification in MuJoCo environments shows that GDSG can mimic expert demonstrations better than previous GAIL variants.},
  archive      = {J_NN},
  author       = {Yirui Zhou and Mengxiao Lu and Xiaowei Liu and Zhengping Che and Zhiyuan Xu and Jian Tang and Yangchun Zhang and Yan Peng and Yaxin Peng},
  doi          = {10.1016/j.neunet.2023.05.027},
  journal      = {Neural Networks},
  pages        = {43-59},
  shortjournal = {Neural Netw.},
  title        = {Distributional generative adversarial imitation learning with reproducing kernel generalization},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auditory perception architecture with spiking neural network
and implementation on FPGA. <em>NN</em>, <em>165</em>, 31–42. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spike-based perception brings up a new research idea in the field of neuromorphic engineering. A high-performance biologically inspired flexible spiking neural network (SNN) architecture provides a novel method for the exploration of perception mechanisms and the development of neuromorphic computing systems . In this article, we present a biological-inspired spike-based SNN perception digital system that can realize robust perception. The system employs a fully paralleled pipeline scheme to improve the performance and accelerate the processing of feature extraction. An auditory perception system prototype is realized on ten Intel Cyclone field-programmable gate arrays, which can reach the maximum frequency of 107.28 MHz and the maximum throughput of 5364 Mbps. Our design also achieves the power of 5. 148 W/system and energy efficiency of 845.85 μ μ J. Our auditory perception implementation is also proved to have superior robustness compared with other SNN systems. We use TIMIT digit speech in noise in accuracy testing. Result shows that it achieves up to 85.75\% speech recognition accuracy under obvious noise conditions (signal-to-noise ratio of 20 dB) and maintain small accuracy attenuation with the decline of the signal-to-noise ratio. The overall performance of our proposed system outperforms the state-of-the-art perception system on SNN.},
  archive      = {J_NN},
  author       = {Bin Deng and Yanrong Fan and Jiang Wang and Shuangming Yang},
  doi          = {10.1016/j.neunet.2023.05.026},
  journal      = {Neural Networks},
  pages        = {31-42},
  shortjournal = {Neural Netw.},
  title        = {Auditory perception architecture with spiking neural network and implementation on FPGA},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCL: Self-supervised contrastive learning for few-shot image
classification. <em>NN</em>, <em>165</em>, 19–30. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning aims to train a model with a limited number of base class samples to classify the novel class samples. However, to attain generalization with a limited number of samples is not a trivial task. This paper proposed a novel few-shot learning approach named Self-supervised Contrastive Learning (SCL) that enriched the model representation with multiple self-supervision objectives. Given the base class samples, the model is trained with the base class loss. Subsequently, contrastive-based self-supervision is introduced to minimize the distance between each training sample with their augmented variants to improve the sample discrimination. To recognize the distant sample, rotation-based self-supervision is proposed to enable the model to learn to recognize the rotation degree of the samples for better sample diversity. The multitask environment is introduced where each training sample is assigned with two class labels: base class label and rotation class label. Complex augmentation is put forth to help the model learn a deeper understanding of the object. The image structure of the training samples are augmented independent of the base class information. The proposed SCL is trained to minimize the base class loss, contrastive distance loss, and rotation class loss simultaneously to learn the generic features and improve the novel class performance . With the multiple self-supervision objectives, the proposed SCL outperforms state-of-the-art few-shot approaches on few-shot image classification benchmark datasets.},
  archive      = {J_NN},
  author       = {Jit Yan Lim and Kian Ming Lim and Chin Poo Lee and Yong Xuan Tan},
  doi          = {10.1016/j.neunet.2023.05.037},
  journal      = {Neural Networks},
  pages        = {19-30},
  shortjournal = {Neural Netw.},
  title        = {SCL: Self-supervised contrastive learning for few-shot image classification},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Motion perception based on ON/OFF channels: A survey.
<em>NN</em>, <em>165</em>, 1–18. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion perception is an essential ability for animals and artificially intelligent systems interacting effectively, safely with surrounding objects and environments. Biological visual systems, that have naturally evolved over hundreds-million years, are quite efficient and robust for motion perception, whereas artificial vision systems are far from such capability. This paper argues that the gap can be significantly reduced by formulation of ON/OFF channels in motion perception models encoding luminance increment (ON) and decrement (OFF) responses within receptive field, separately. Such signal-bifurcating structure has been found in neural systems of many animal species articulating early motion is split and processed in segregated pathways. However, the corresponding biological substrates, and the necessity for artificial vision systems have never been elucidated together, leaving concerns on uniqueness and advantages of ON/OFF channels upon building dynamic vision systems to address real world challenges. This paper highlights the importance of ON/OFF channels in motion perception through surveying current progress covering both neuroscience and computationally modelling works with applications. Compared to related literature, this paper for the first time provides insights into implementation of different selectivity to directional motion of looming, translating, and small-sized target movement based on ON/OFF channels in keeping with soundness and robustness of biological principles. Existing challenges and future trends of such bio-plausible computational structure for visual perception in connection with hotspots of machine learning , advanced vision sensors like event-driven camera finally are discussed.},
  archive      = {J_NN},
  author       = {Qinbing Fu},
  doi          = {10.1016/j.neunet.2023.05.031},
  journal      = {Neural Networks},
  pages        = {1-18},
  shortjournal = {Neural Netw.},
  title        = {Motion perception based on ON/OFF channels: A survey},
  volume       = {165},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>164</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(23)00318-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00318-0},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {NN/ENNS/JNNS - membership applic. form},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). CURRENT EVENTS. <em>NN</em>, <em>164</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(23)00317-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00317-9},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {CURRENT EVENTS},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cost-effective framework for gradual domain adaptation with
multifidelity. <em>NN</em>, <em>164</em>, 731–741. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In domain adaptation , when there is a large distance between the source and target domains, the prediction performance will degrade. Gradual domain adaptation is one of the solutions to such an issue, assuming that we have access to intermediate domains, which shift gradually from the source to the target domain. In previous works, it was assumed that the number of samples in the intermediate domains was sufficiently large; hence, self-training was possible without the need for labeled data. If the number of accessible intermediate domains is restricted, the distances between domains become large, and self-training will fail. Practically, the cost of samples in intermediate domains will vary, and it is natural to consider that the closer an intermediate domain is to the target domain, the higher the cost of obtaining samples from the intermediate domain is. To solve the trade-off between cost and accuracy, we propose a framework that combines multifidelity and active domain adaptation. The effectiveness of the proposed method is evaluated by experiments with real-world datasets.},
  archive      = {J_NN},
  author       = {Shogo Sagawa and Hideitsu Hino},
  doi          = {10.1016/j.neunet.2023.03.035},
  journal      = {Neural Networks},
  pages        = {731-741},
  shortjournal = {Neural Netw.},
  title        = {Cost-effective framework for gradual domain adaptation with multifidelity},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LoyalDE: Improving the performance of graph neural networks
with loyal node discovery and emphasis. <em>NN</em>, <em>164</em>,
719–730. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed an increasing focus on graph-based semi-supervised learning with Graph Neural Networks (GNNs). Despite existing GNNs having achieved remarkable accuracy, research on the quality of graph supervision information has inadvertently been ignored. In fact, there are significant differences in the quality of supervision information provided by different labeled nodes, and treating supervision information with different qualities equally may lead to sub-optimal performance of GNNs. We refer to this as the graph supervision loyalty problem, which is a new perspective for improving the performance of GNNs. In this paper, we devise FT-Score to quantify node loyalty by considering both the local feature similarity and the local topology similarity, and nodes with higher loyalty are more likely to provide higher-quality supervision. Based on this, we propose LoyalDE ( Loyal Node D iscovery and E mphasis), a model-agnostic hot-plugging training strategy, which can discover potential nodes with high loyalty to expand the training set, and then emphasize nodes with high loyalty during model training to improve performance. Experiments demonstrate that the graph supervision loyalty problem will fail most existing GNNs. In contrast, LoyalDE brings about at most 9.1\% performance improvement to vanilla GNNs and consistently outperforms several state-of-the-art training strategies for semi-supervised node classification .},
  archive      = {J_NN},
  author       = {Haotong Wei and Yinlin Zhu and Xunkai Li and Bin Jiang},
  doi          = {10.1016/j.neunet.2023.05.023},
  journal      = {Neural Networks},
  pages        = {719-730},
  shortjournal = {Neural Netw.},
  title        = {LoyalDE: Improving the performance of graph neural networks with loyal node discovery and emphasis},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative bi-aggregation for directed graph embedding.
<em>NN</em>, <em>164</em>, 707–718. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed graph is able to model asymmetric relationships between nodes and research on directed graph embedding is of great significance in downstream graph analysis and inference. Learning source and target embeddings of nodes separately to preserve edge asymmetry has become the dominant approach, but also poses challenge for learning representations of low or even zero in/out degree nodes that are ubiquitous in sparse graphs . In this paper, a collaborative bi-directional aggregation method (COBA) for directed graph embedding is proposed. Firstly, the source and target embeddings of the central node are learned by aggregating from the counterparts of the source and target neighbors, respectively; Secondly, the source/target embeddings of the zero in/out degree central nodes are enhanced by aggregating the counterparts of opposite-directional neighbors (i.e. target/source neighbors); Finally, source and target embeddings of the same node are correlated to achieve collaborative aggregation. Both the feasibility and rationality of the model are theoretically analyzed. Extensive experiments on real-world datasets demonstrate that COBA comprehensively outperforms state-of-the-art methods on multiple tasks and meanwhile validates the effectiveness of proposed aggregation strategies.},
  archive      = {J_NN},
  author       = {Linsong Liu and Ke-Jia Chen and Zheng Liu},
  doi          = {10.1016/j.neunet.2023.05.024},
  journal      = {Neural Networks},
  pages        = {707-718},
  shortjournal = {Neural Netw.},
  title        = {Collaborative bi-aggregation for directed graph embedding},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximate spectral decomposition of fisher information
matrix for simple ReLU networks. <em>NN</em>, <em>164</em>, 691–706. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We argue the Fisher information matrix (FIM) of one hidden layer networks with the ReLU activation function . For a network, let W W denote the d × p d×p weight matrix from the d d -dimensional input to the hidden layer consisting of p p neurons, and v v the p p -dimensional weight vector from the hidden layer to the scalar output. We focus on the FIM of v v , which we denote as I I . Under certain conditions, we characterize the first three clusters of eigenvalues and eigenvectors of the FIM. Specifically, we show that the following approximately holds. (1) Since I I is non-negative owing to the ReLU, the first eigenvalue is the Perron–Frobenius eigenvalue. (2) For the cluster of the next maximum values, the eigenspace is spanned by the row vectors of W W . (3) The direct sum of the eigenspace of the first eigenvalue and that of the third cluster is spanned by the set of all the vectors obtained as the Hadamard product of any pair of the row vectors of W W . We confirmed by numerical calculation that the above is approximately correct when the number of hidden nodes is about 10000.},
  archive      = {J_NN},
  author       = {Yoshinari Takeishi and Masazumi Iida and Jun’ichi Takeuchi},
  doi          = {10.1016/j.neunet.2023.05.017},
  journal      = {Neural Networks},
  pages        = {691-706},
  shortjournal = {Neural Netw.},
  title        = {Approximate spectral decomposition of fisher information matrix for simple ReLU networks},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Credit assignment with predictive contribution measurement
in multi-agent reinforcement learning. <em>NN</em>, <em>164</em>,
681–690. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit assignment is a crucial issue in multi-agent tasks employing a centralized training and decentralized execution paradigm. While value decomposition has demonstrated strong performance in Q-learning-based approaches and certain Actor–Critic variants, it remains challenging to achieve efficient credit assignment in multi-agent tasks using policy gradient methods due to decomposable value limitations. This paper introduces Predictive Contribution Measurement, an explicit credit assignment method that compares prediction errors among agents and allocates surrogate rewards based on their relevance to global state transitions, with a theoretical guarantee. With multi-agent proximal policy optimization (MAPPO) as a training backend, we propose Predictive Contribution MAPPO (PC-MAPPO). Our experiments demonstrate that PC-MAPPO, with a 10\% warm-up phase, outperforms MAPPO, QMIX, and Weighted QMIX on StarCraft multi-agent challenge tasks, particularly in maps requiring heightened cooperation to defeat enemies, such as the map corridor . Employing a pre-trained predictor, PC-MAPPO achieves significantly improved performance on all tested super-hard maps. In parallel training scenarios, PC-MAPPO exhibits superior data efficiency and achieves state-of-the-art performance compared to other methods.},
  archive      = {J_NN},
  author       = {Renlong Chen and Ying Tan},
  doi          = {10.1016/j.neunet.2023.05.021},
  journal      = {Neural Networks},
  pages        = {681-690},
  shortjournal = {Neural Netw.},
  title        = {Credit assignment with predictive contribution measurement in multi-agent reinforcement learning},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ProductGraphSleepNet: Sleep staging using product
spatio-temporal graph learning with attentive temporal aggregation.
<em>NN</em>, <em>164</em>, 667–680. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of sleep stages plays a crucial role in understanding and diagnosing sleep pathophysiology. Sleep stage scoring relies heavily on visual inspection by an expert, which is a time-consuming and subjective procedure. Recently, deep learning neural network approaches have been leveraged to develop a generalized automated sleep staging and account for shifts in distributions that may be caused by inherent inter/intra-subject variability, heterogeneity across datasets, and different recording environments. However, these networks (mostly) ignore the connections among brain regions and disregard modeling the connections between temporally adjacent sleep epochs . To address these issues, this work proposes an adaptive product graph learning-based graph convolutional network , named ProductGraphSleepNet, for learning joint spatio-temporal graphs along with a bidirectional gated recurrent unit and a modified graph attention network to capture the attentive dynamics of sleep stage transitions. Evaluation on two public databases: the Montreal Archive of Sleep Studies (MASS) SS3; and the SleepEDF, which contain full night polysomnography recordings of 62 and 20 healthy subjects, respectively, demonstrates performance comparable to the state-of-the-art (Accuracy: 0.867;0.838, F1-score: 0.818;0.774 and Kappa: 0.802;0.775, on each database respectively). More importantly, the proposed network makes it possible for clinicians to comprehend and interpret the learned spatial and temporal connectivity graphs for sleep stages.},
  archive      = {J_NN},
  author       = {Aref Einizade and Samaneh Nasiri and Sepideh Hajipour Sardouie and Gari D. Clifford},
  doi          = {10.1016/j.neunet.2023.05.016},
  journal      = {Neural Networks},
  pages        = {667-680},
  shortjournal = {Neural Netw.},
  title        = {ProductGraphSleepNet: Sleep staging using product spatio-temporal graph learning with attentive temporal aggregation},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of sum–product networks structural learning.
<em>NN</em>, <em>164</em>, 645–666. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sum–product networks (SPNs) in deep probabilistic models have made great progress in computer vision , robotics, neuro-symbolic artificial intelligence , natural language processing , probabilistic programming languages , and other fields. Compared with probabilistic graphical models and deep probabilistic models, SPNs can balance the tractability and expressive efficiency. In addition, SPNs remain more interpretable than deep neural models . The expressiveness and complexity of SPNs depend on their own structure. Thus, how to design an effective SPN structure learning algorithm that can balance expressiveness and complexity has become a hot research topic in recent years. In this paper, we review SPN structure learning comprehensively, including the motivation of SPN structure learning, a systematic review of related theories, the proper categorization of different SPN structure learning algorithms, several evaluation approaches and some helpful online resources. Moreover, we discuss some open issues and research directions for SPN structure learning. To our knowledge, this is the first survey to focus specifically on SPN structure learning, and we hope to provide useful references for researchers in related fields.},
  archive      = {J_NN},
  author       = {Riting Xia and Yan Zhang and Xueyan Liu and Bo Yang},
  doi          = {10.1016/j.neunet.2023.05.010},
  journal      = {Neural Networks},
  pages        = {645-666},
  shortjournal = {Neural Netw.},
  title        = {A survey of sum–product networks structural learning},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distance metric learning based on the class center and
nearest neighbor relationship. <em>NN</em>, <em>164</em>, 631–644. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning has been a promising technology to improve the performance of algorithms related to distance metrics. The existing distance metric learning methods are either based on the class center or the nearest neighbor relationship. In this work, we propose a new distance metric learning method based on the class center and nearest neighbor relationship (DMLCN). Specifically, when centers of different classes overlap, DMLCN first splits each class into several clusters and uses one center to represent one cluster. Then, a distance metric is learned such that each example is close to the corresponding cluster center and the nearest neighbor relationship is kept for each receptive field. Therefore, while characterizing the local structure of data, the proposed method leads to intra-class compactness and inter-class dispersion simultaneously. Further, to better process complex data, we introduce multiple metrics into DMLCN (MMLCN) by learning a local metric for each center. Following that, a new classification decision rule is designed based on the proposed methods. Moreover, we develop an iterative algorithm to optimize the proposed methods. The convergence and complexity are analyzed theoretically. Experiments on different types of data sets including artificial data sets, benchmark data sets and noise data sets show the feasibility and effectiveness of the proposed methods.},
  archive      = {J_NN},
  author       = {Yifeng Zhao and Liming Yang},
  doi          = {10.1016/j.neunet.2023.05.004},
  journal      = {Neural Networks},
  pages        = {631-644},
  shortjournal = {Neural Netw.},
  title        = {Distance metric learning based on the class center and nearest neighbor relationship},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-granularity knowledge distillation and prototype
consistency regularization for class-incremental learning. <em>NN</em>,
<em>164</em>, 617–630. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are prone to the notorious catastrophic forgetting problem when learning new tasks incrementally. Class-incremental learning (CIL) is a promising solution to tackle the challenge and learn new classes while not forgetting old ones. Existing CIL approaches adopted stored representative exemplars or complex generative models to achieve good performance. However, storing data from previous tasks causes memory or privacy issues, and the training of generative models is unstable and inefficient. This paper proposes a method based on multi-granularity knowledge distillation and prototype consistency regularization (MDPCR) that performs well even when the previous training data is unavailable. First, we propose to design knowledge distillation losses in the deep feature space to constrain the incremental model trained on the new data. Thereby, multi-granularity is captured from three aspects: by distilling multi-scale self-attentive features, the feature similarity probability , and global features to maximize the retention of previous knowledge, effectively alleviating catastrophic forgetting. Conversely, we preserve the prototype of each old class and employ prototype consistency regularization (PCR) to ensure that the old prototypes and semantically enhanced prototypes produce consistent prediction, which excels in enhancing the robustness of old prototypes and reduces the classification bias. Extensive experiments on three CIL benchmark datasets confirm that MDPCR performs significantly better over exemplar-free methods and outperforms typical exemplar-based approaches.},
  archive      = {J_NN},
  author       = {Yanyan Shi and Dianxi Shi and Ziteng Qiao and Zhen Wang and Yi Zhang and Shaowu Yang and Chunping Qiu},
  doi          = {10.1016/j.neunet.2023.05.006},
  journal      = {Neural Networks},
  pages        = {617-630},
  shortjournal = {Neural Netw.},
  title        = {Multi-granularity knowledge distillation and prototype consistency regularization for class-incremental learning},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual learning with invertible generative models.
<em>NN</em>, <em>164</em>, 606–616. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catastrophic forgetting (CF) happens whenever a neural network overwrites past knowledge while being trained on new tasks. Common techniques to handle CF include regularization of the weights (using, e.g., their importance on past tasks), and rehearsal strategies, where the network is constantly re-trained on past data. Generative models have also been applied for the latter, in order to have endless sources of data. In this paper, we propose a novel method that combines the strengths of regularization and generative-based rehearsal approaches. Our generative model consists of a normalizing flow (NF), a probabilistic and invertible neural network , trained on the internal embeddings of the network. By keeping a single NF throughout the training process, we show that our memory overhead remains constant. In addition, exploiting the invertibility of the NF, we propose a simple approach to regularize the network’s embeddings with respect to past tasks. We show that our method performs favorably with respect to state-of-the-art approaches in the literature, with bounded computational power and memory overheads.},
  archive      = {J_NN},
  author       = {Jary Pomponi and Simone Scardapane and Aurelio Uncini},
  doi          = {10.1016/j.neunet.2023.05.020},
  journal      = {Neural Networks},
  pages        = {606-616},
  shortjournal = {Neural Netw.},
  title        = {Continual learning with invertible generative models},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of continuous-time recurrent neural networks with
piecewise-linear activation function for generation of prescribed
sequences of bipolar vectors. <em>NN</em>, <em>164</em>, 588–605. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recurrent neural network (RNN) can generate a sequence of patterns as the temporal evolution of the output vector. This paper focuses on a continuous-time RNN model with a piecewise-linear activation function that has neither external inputs nor hidden neurons , and studies the problem of finding the parameters of the model so that it generates a given sequence of bipolar vectors. First, a sufficient condition for the model to generate the desired sequence is derived, which is expressed as a system of linear inequalities in the parameters. Next, three approaches to finding solutions of the system of linear inequalities are proposed: One is formulated as a convex quadratic programming problem and others are linear programming problems . Then, two types of sequences of bipolar vectors that can be generated by the model are presented. Finally, the case where the model generates a periodic sequence of bipolar vectors is considered, and a sufficient condition for the trajectory of the state vector to converge to a limit cycle is provided.},
  archive      = {J_NN},
  author       = {Norikazu Takahashi and Tsuyoshi Yamakawa and Yasuhiro Minetoma and Tetsuo Nishi and Tsuyoshi Migita},
  doi          = {10.1016/j.neunet.2023.05.013},
  journal      = {Neural Networks},
  pages        = {588-605},
  shortjournal = {Neural Netw.},
  title        = {Design of continuous-time recurrent neural networks with piecewise-linear activation function for generation of prescribed sequences of bipolar vectors},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Input-to-state stability of positive delayed neural networks
via impulsive control. <em>NN</em>, <em>164</em>, 576–587. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the positivity and impulsive stabilization of equilibrium points of delayed neural networks (DNNs) subject to bounded disturbances . With the aid of the continuous dependence theorem for impulsive delay differential equations , a relaxed positivity condition is derived, which allows the neuron interconnection matrix to be Metzler if the activation functions satisfy a certain condition. The notion of input-to-state stability (ISS) is introduced to characterize internal global stability and disturbance attenuation performance for impulsively controlled DNNs. The ISS property is analyzed by employing a time-dependent max-separable Lyapunov function which is able to capture the positivity characterization and hybrid structure of the considered DNNs. A ranged dwell-time-dependent ISS condition is obtained, which allows to design an impulsive control law via partial state variables. As a byproduct, an improved global exponential stability criterion for impulse-free positive DNNs is obtained. The applicability of the achieved results is illustrated through three numerical examples.},
  archive      = {J_NN},
  author       = {Wu-Hua Chen and Xiujuan Li and Shuning Niu and Xiaomei Lu},
  doi          = {10.1016/j.neunet.2023.05.011},
  journal      = {Neural Networks},
  pages        = {576-587},
  shortjournal = {Neural Netw.},
  title        = {Input-to-state stability of positive delayed neural networks via impulsive control},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Corrigendum to “functional connectivity learning via
siamese-based SPD matrix representation of brain imaging data” [neural
networks 163 (2023) 272–285]. <em>NN</em>, <em>164</em>, 575. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Yunbo Tang and Dan Chen and Jia Wu and Weiping Tu and Jessica J.M. Monaghan and Paul Sowman and David Mcalpine},
  doi          = {10.1016/j.neunet.2023.05.012},
  journal      = {Neural Networks},
  pages        = {575},
  shortjournal = {Neural Netw.},
  title        = {Corrigendum to “Functional connectivity learning via siamese-based SPD matrix representation of brain imaging data” [Neural networks 163 (2023) 272–285]},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A spectral graph convolution for signed directed graphs via
magnetic laplacian. <em>NN</em>, <em>164</em>, 562–574. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed directed graphs contain both sign and direction information on their edges, providing richer information about real-world phenomena compared to unsigned or undirected graphs. However, analyzing such graphs is more challenging due to their complexity, and the limited availability of existing methods. Consequently, despite their potential uses, signed directed graphs have received less research attention. In this paper, we propose a novel spectral graph convolution model that effectively captures the underlying patterns in signed directed graphs. To this end, we introduce a complex Hermitian adjacency matrix that can represent both sign and direction of edges using complex numbers. We then define a magnetic Laplacian matrix based on the adjacency matrix, which we use to perform spectral convolution. We demonstrate that the magnetic Laplacian matrix is positive semi-definite (PSD), which guarantees its applicability to spectral methods . Compared to traditional Laplacians , the magnetic Laplacian captures additional edge information, which makes it a more informative tool for graph analysis. By leveraging the information of signed directed edges, our method generates embeddings that are more representative of the underlying graph structure. Furthermore, we showed that the proposed method has wide applicability for various graph types and is the most generalized Laplacian form. We evaluate the effectiveness of the proposed model through extensive experiments on several real-world datasets. The results demonstrate that our method outperforms state-of-the-art techniques in signed directed graph embedding.},
  archive      = {J_NN},
  author       = {Taewook Ko and Yoonhyuk Choi and Chong-Kwon Kim},
  doi          = {10.1016/j.neunet.2023.05.009},
  journal      = {Neural Networks},
  pages        = {562-574},
  shortjournal = {Neural Netw.},
  title        = {A spectral graph convolution for signed directed graphs via magnetic laplacian},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating post-hoc explanations for skip-gram-based node
embeddings by identifying important nodes with bridgeness. <em>NN</em>,
<em>164</em>, 546–561. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node representation learning in a network is an important machine learning technique for encoding relational information in a continuous vector space while preserving the inherent properties and structures of the network. Recently, unsupervised node embedding methods such as DeepWalk (Perozzi et al., 2014), LINE (Tang et al., 2015), struc2vec (Ribeiro et al., 2017), PTE (Tang et al., 2015), UserItem2vec (Wu et al., 2020), and RWJBG (Li et al., 2021) have emerged from the Skip-gram model (Mikolov et al., 2013) and perform better performance in several downstream tasks such as node classification and link prediction than the existing relational models . However, providing post-hoc explanations of unsupervised embeddings remains a challenging problem because of the lack of explanation methods and theoretical studies applicable for embeddings. In this paper, we first show that global explanations to the Skip-gram-based embeddings can be found by computing bridgeness under a spectral cluster-aware local perturbation. Moreover, a novel gradient-based explanation method, which we call GRAPH-wGD, is proposed that allows the top- q q global explanations about learned graph embedding vectors more efficiently. Experiments show that the ranking of nodes by scores using GRAPH-wGD is highly correlated with true bridgeness scores. We also observe that the top- q q node-level explanations selected by GRAPH-wGD have higher importance scores and produce more changes in class label prediction when perturbed, compared with the nodes selected by recent alternatives, using five real-world graphs.},
  archive      = {J_NN},
  author       = {Hogun Park and Jennifer Neville},
  doi          = {10.1016/j.neunet.2023.04.029},
  journal      = {Neural Networks},
  pages        = {546-561},
  shortjournal = {Neural Netw.},
  title        = {Generating post-hoc explanations for skip-gram-based node embeddings by identifying important nodes with bridgeness},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An accelerated end-to-end method for solving routing
problems. <em>NN</em>, <em>164</em>, 535–545. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of neural network models to solve combinatorial optimization has recently drawn much attention and shown promising results in dealing with similar problems, like Travelling Salesman Problem . The neural network allows to learn solutions based on given problem instances, using reinforcement learning or supervised learning. In this paper, we present a novel end-to-end method to solve routing problems. In specific, we propose a gated cosine-based attention model (GCAM) to train policies, which accelerates the training process and the convergence of policy. Extensive experiments on different scale of routing problems show that the proposed method can achieve faster convergence of the training process than the state-of-the-art deep learning models while achieving solutions of the same quality.},
  archive      = {J_NN},
  author       = {Tianyu Zhu and Xinli Shi and Xiangping Xu and Jinde Cao},
  doi          = {10.1016/j.neunet.2023.05.003},
  journal      = {Neural Networks},
  pages        = {535-545},
  shortjournal = {Neural Netw.},
  title        = {An accelerated end-to-end method for solving routing problems},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transformer-based deep neural network model for SSVEP
classification. <em>NN</em>, <em>164</em>, 521–534. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steady-state visual evoked potential (SSVEP) is one of the most commonly used control signals in the brain–computer interface (BCI) systems. However, the conventional spatial filtering methods for SSVEP classification highly depend on the subject-specific calibration data . The need for the methods that can alleviate the demand for the calibration data becomes urgent. In recent years, developing the methods that can work in inter-subject scenario has become a promising new direction. As a popular deep learning model nowadays, Transformer has been used in EEG signal classification tasks owing to its excellent performance. Therefore, in this study, we proposed a deep learning model for SSVEP classification based on Transformer architecture in inter-subject scenario, termed as SSVEPformer, which was the first application of Transformer on the SSVEP classification. Inspired by previous studies, we adopted the complex spectrum features of SSVEP data as the model input, which could enable the model to simultaneously explore the spectral and spatial information for classification. Furthermore, to fully utilize the harmonic information, an extended SSVEPformer based on the filter bank technology (FB-SSVEPformer) was proposed to improve the classification performance. Experiments were conducted using two open datasets (Dataset 1: 10 subjects, 12 targets; Dataset 2: 35 subjects, 40 targets). The experimental results show that the proposed models could achieve better results in terms of classification accuracy and information transfer rate than other baseline methods . The proposed models validate the feasibility of deep learning models based on Transformer architecture for SSVEP data classification , and could serve as potential models to alleviate the calibration procedure in the practical application of SSVEP-based BCI systems.},
  archive      = {J_NN},
  author       = {Jianbo Chen and Yangsong Zhang and Yudong Pan and Peng Xu and Cuntai Guan},
  doi          = {10.1016/j.neunet.2023.04.045},
  journal      = {Neural Networks},
  pages        = {521-534},
  shortjournal = {Neural Netw.},
  title        = {A transformer-based deep neural network model for SSVEP classification},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered fault-tolerant control for input-constrained
nonlinear systems with mismatched disturbances via adaptive dynamic
programming. <em>NN</em>, <em>164</em>, 508–520. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the issue of event-triggered optimal fault-tolerant control is investigated for input-constrained nonlinear systems with mismatched disturbances. To eliminate the effect of abrupt faults and ensure the optimal performance of general nonlinear dynamics , an adaptive dynamic programming (ADP) algorithm is employed to develop a sliding mode fault-tolerant control strategy. When the system trajectories converge to the sliding-mode surface, the equivalent sliding mode dynamics is transformed into a reformulated auxiliary system with a modified cost function. Then, a single critic neural network (NN) is adopted to solve the modified Hamilton–Jacobi–Bellman (HJB) equation. In order to overcome the difficulty that arises from the persistence of excitation (PE) condition, the experience replay technique is utilized to update the critic weights. In this study, a novel control method is proposed, which can effectively eliminate the effects of abrupt faults while achieving optimal control with the minimum cost under a single network architecture . Furthermore, the closed-loop nonlinear system is proved to be uniformly ultimate boundedness based on Lyapunov stability theory . Finally, three examples are presented to verify the validity of the control strategy.},
  archive      = {J_NN},
  author       = {Heng Zhao and Huanqing Wang and Ben Niu and Xudong Zhao and Khalid H. Alharbi},
  doi          = {10.1016/j.neunet.2023.05.001},
  journal      = {Neural Networks},
  pages        = {508-520},
  shortjournal = {Neural Netw.},
  title        = {Event-triggered fault-tolerant control for input-constrained nonlinear systems with mismatched disturbances via adaptive dynamic programming},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Quasi-projective and complete synchronization of
discrete-time fractional-order delayed neural networks. <em>NN</em>,
<em>164</em>, 497–507. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents new theoretical results on quasi-projective synchronization (Q-PS) and complete synchronization (CS) of one kind of discrete-time fractional-order delayed neural networks (DFDNNs). At first, three new fractional difference inequalities for exploring the upper bound of quasi-synchronization error and adaptive synchronization are established by dint of Laplace transform and properties of discrete Mittag-Leffler function, which vastly expand a number of available results. Furthermore, two controllers are designed including nonlinear controller and adaptive controller . And on the basis of Lyapunov method , the aforementioned inequalities and properties of fractional-order difference operators, some sufficient synchronization criteria of DFDNNs are derived. Because of the above controllers, synchronization criteria in this paper are less conservative. At last, numerical examples are carried out to illustrate the usefulness of theoretical upshots.},
  archive      = {J_NN},
  author       = {Xiao-Li Zhang and Hong-Li Li and Yongguang Yu and Long Zhang and Haijun Jiang},
  doi          = {10.1016/j.neunet.2023.05.005},
  journal      = {Neural Networks},
  pages        = {497-507},
  shortjournal = {Neural Netw.},
  title        = {Quasi-projective and complete synchronization of discrete-time fractional-order delayed neural networks},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive reinforcement learning-based multimodal data
fusion framework for human–robot confrontation gaming. <em>NN</em>,
<em>164</em>, 489–496. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Playing games between humans and robots have become a widespread human–robot confrontation (HRC) application. Although many approaches were proposed to enhance the tracking accuracy by combining different information, the problems of the intelligence degree of the robot and the anti-interference ability of the motion capture system still need to be solved. In this paper, we present an adaptive reinforcement learning (RL) based multimodal data fusion (AdaRL-MDF) framework teaching the robot hand to play Rock–Paper–Scissors (RPS) game with humans. It includes an adaptive learning mechanism to update the ensemble classifier , an RL model providing intellectual wisdom to the robot, and a multimodal data fusion structure offering resistance to interference. The corresponding experiments prove the mentioned functions of the AdaRL-MDF model. The comparison accuracy and computational time show the high performance of the ensemble model by combining k-nearest neighbor (k-NN) and deep convolutional neural network (DCNN). In addition, the depth vision-based k-NN classifier obtains a 100\% identification accuracy so that the predicted gestures can be regarded as the real value. The demonstration illustrates the real possibility of HRC application. The theory involved in this model provides the possibility of developing HRC intelligence.},
  archive      = {J_NN},
  author       = {Wen Qi and Haoyu Fan and Hamid Reza Karimi and Hang Su},
  doi          = {10.1016/j.neunet.2023.04.043},
  journal      = {Neural Networks},
  pages        = {489-496},
  shortjournal = {Neural Netw.},
  title        = {An adaptive reinforcement learning-based multimodal data fusion framework for human–robot confrontation gaming},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolution-communication spiking neural p systems with energy
request rules. <em>NN</em>, <em>164</em>, 476–488. (<a
href="https://doi.org/10.1016/j.neunet.2023.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolution-communication spiking neural P systems with energy request rules (ECSNP-ER systems) are proposed and developed as a new variant of evolution-communication spiking neural P systems . In ECSNP-ER systems, in addition to spike-evolution rules and spike-communication rules, neurons also have energy request rules. Energy request rules are used to obtain energy from the environment needed for spike evolution and communication in neurons. The definition, structure and operations of ECSNP-ER systems are presented in detail. ECSNP-ER systems are proved to have the same computing capabilities as Turing machines by using them as number generating/accepting devices and function computing devices. Working non-deterministically, ECSNP-ER systems are used to solve NP-complete problems, using the SAT problem as an example, in linear time.},
  archive      = {J_NN},
  author       = {Liping Wang and Xiyu Liu and Minghe Sun and Yuzhen Zhao},
  doi          = {10.1016/j.neunet.2023.05.007},
  journal      = {Neural Networks},
  pages        = {476-488},
  shortjournal = {Neural Netw.},
  title        = {Evolution-communication spiking neural p systems with energy request rules},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatized offline and online exploration to achieve a
target dynamics in biohybrid neural circuits built with living and model
neurons. <em>NN</em>, <em>164</em>, 464–475. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biohybrid circuits of interacting living and model neurons are an advantageous means to study neural dynamics and to assess the role of specific neuron and network properties in the nervous system . Hybrid networks are also a necessary step to build effective artificial intelligence and brain hybridization. In this work, we deal with the automatized online and offline adaptation, exploration and parameter mapping to achieve a target dynamics in hybrid circuits and, in particular, those that yield dynamical invariants between living and model neurons. We address dynamical invariants that form robust cycle-by-cycle relationships between the intervals that build neural sequences from such interaction. Our methodology first attains automated adaptation of model neurons to work in the same amplitude regime and time scale of living neurons. Then, we address the automatized exploration and mapping of the synapse parameter space that lead to a specific dynamical invariant target. Our approach uses multiple configurations and parallel computing from electrophysiological recordings of living neurons to build full mappings, and genetic algorithms to achieve an instance of the target dynamics for the hybrid circuit in a short time. We illustrate and validate such strategy in the context of the study of functional sequences in neural rhythms, which can be easily generalized for any variety of hybrid circuit configuration. This approach facilitates both the building of hybrid circuits and the accomplishment of their scientific goal.},
  archive      = {J_NN},
  author       = {Manuel Reyes-Sanchez and Rodrigo Amaducci and Pablo Sanchez-Martin and Irene Elices and Francisco B. Rodriguez and Pablo Varona},
  doi          = {10.1016/j.neunet.2023.04.034},
  journal      = {Neural Networks},
  pages        = {464-475},
  shortjournal = {Neural Netw.},
  title        = {Automatized offline and online exploration to achieve a target dynamics in biohybrid neural circuits built with living and model neurons},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A multi-view co-training network for semi-supervised
medical image-based prognostic prediction. <em>NN</em>, <em>164</em>,
455–463. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostic prediction has long been a hotspot in disease analysis and management, and the development of image-based prognostic prediction models has significant clinical implications for current personalized treatment strategies. The main challenge in prognostic prediction is to model a regression problem based on censored observations , and semi-supervised learning has the potential to play an important role in improving the utilization efficiency of censored data . However, there are yet few effective semi-supervised paradigms to be applied. In this paper, we propose a semi-supervised co-training deep neural network incorporating a support vector regression layer for survival time estimation (Co-DeepSVS) that improves the efficiency in utilizing censored data for prognostic prediction. First, we introduce a support vector regression layer in deep neural networks to deal with censored data and directly predict survival time, and more importantly to calculate the labeling confidence of each case. Then, we apply a semi-supervised multi-view co-training framework to achieve accurate prognostic prediction, where labeling confidence estimation with prior knowledge of pseudo time is conducted for each view. Experimental results demonstrate that the proposed Co-DeepSVS has a promising prognostic ability and surpasses most widely used methods on a multi-phase CT dataset. Besides, the introduction of SVR layer makes the model more robust in the presence of follow-up bias.},
  archive      = {J_NN},
  author       = {Hailin Li and Siwen Wang and Bo Liu and Mengjie Fang and Runnan Cao and Bingxi He and Shengyuan Liu and Chaoen Hu and Di Dong and Ximing Wang and Hexiang Wang and Jie Tian},
  doi          = {10.1016/j.neunet.2023.04.030},
  journal      = {Neural Networks},
  pages        = {455-463},
  shortjournal = {Neural Netw.},
  title        = {A multi-view co-training network for semi-supervised medical image-based prognostic prediction},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-adaptive message passing graph neural network.
<em>NN</em>, <em>164</em>, 439–454. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-network node classification (CNNC), which aims to classify nodes in a label-deficient target network by transferring the knowledge from a source network with abundant labels, draws increasing attention recently. To address CNNC, we propose a d omain-adaptive m essage passing g raph n eural n etwork (DM-GNN), which integrates graph neural network (GNN) with conditional adversarial domain adaptation . DM-GNN is capable of learning informative representations for node classification that are also transferrable across networks. Firstly, a GNN encoder is constructed by dual feature extractors to separate ego-embedding learning from neighbor-embedding learning so as to jointly capture commonality and discrimination between connected nodes. Secondly, a label propagation node classifier is proposed to refine each node’s label prediction by combining its own prediction and its neighbors’ prediction. In addition, a label-aware propagation scheme is devised for the labeled source network to promote intra-class propagation while avoiding inter-class propagation, thus yielding label-discriminative source embeddings. Thirdly, conditional adversarial domain adaptation is performed to take the neighborhood-refined class-label information into account during adversarial domain adaptation, so that the class-conditional distributions across networks can be better matched. Comparisons with eleven state-of-the-art methods demonstrate the effectiveness of the proposed DM-GNN.},
  archive      = {J_NN},
  author       = {Xiao Shen and Shirui Pan and Kup-Sze Choi and Xi Zhou},
  doi          = {10.1016/j.neunet.2023.04.038},
  journal      = {Neural Networks},
  pages        = {439-454},
  shortjournal = {Neural Netw.},
  title        = {Domain-adaptive message passing graph neural network},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A direct discretization recurrent neurodynamics method for
time-variant nonlinear optimization with redundant robot manipulators.
<em>NN</em>, <em>164</em>, 428–438. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete time-variant nonlinear optimization (DTVNO) problems are commonly encountered in various scientific researches and engineering application fields. Nowadays, many discrete-time recurrent neurodynamics (DTRN) methods have been proposed for solving the DTVNO problems. However, these traditional DTRN methods currently employ an indirect technical route in which the discrete-time derivation process requires to interconvert with continuous-time derivation process. In order to break through this traditional research method, we develop a novel DTRN method based on the inspiring direct discrete technique for solving the DTVNO problem more concisely and efficiently. To be specific, firstly, considering that the DTVNO problem emerging in the discrete-time tracing control of robot manipulator , we further abstract and summarize the mathematical definition of DTVNO problem, and then we define the corresponding error function. Secondly, based on the second-order Taylor expansion , we can directly obtain the DTRN method for solving the DTVNO problem, which no longer requires the derivation process in the continuous-time environment. Whereafter, such a DTRN method is theoretically analyzed and its convergence is demonstrated. Furthermore, numerical experiments confirm the effectiveness and superiority of the DTRN method. In addition, the application experiments of the robot manipulators are presented to further demonstrate the superior performance of the DTRN method.},
  archive      = {J_NN},
  author       = {Yang Shi and Wangrong Sheng and Shuai Li and Bin Li and Xiaobing Sun and Dimitrios K. Gerontitis},
  doi          = {10.1016/j.neunet.2023.04.040},
  journal      = {Neural Networks},
  pages        = {428-438},
  shortjournal = {Neural Netw.},
  title        = {A direct discretization recurrent neurodynamics method for time-variant nonlinear optimization with redundant robot manipulators},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforcement learning algorithm acquires demonstration
from the training agent by dividing the task space. <em>NN</em>,
<em>164</em>, 419–427. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although reinforcement learning (RL) has made numerous breakthroughs in recent years, addressing reward-sparse environments remains challenging and requires further exploration. Many studies improve the performance of the agents by introducing the state-action pairs experienced by an expert. However, such kinds of strategies almost depend on the quality of the demonstration by the expert, which is rarely optimal in a real-world environment, and struggle with learning from sub-optimal demonstrations. In this paper, a self-imitation learning algorithm based on the task space division is proposed to realize an efficient high-quality demonstration acquire while the training process. To determine the quality of the trajectory, some well-designed criteria are defined in the task space for finding a better demonstration. The results show that the proposed algorithm will improve the success rate of robot control and achieve a high mean Q value per step. The algorithm framework proposed in this paper has illustrated a great potential to learn from a demonstration generated by using self-policy in sparse environments and can be used in reward-sparse environments where the task space can be divided.},
  archive      = {J_NN},
  author       = {Lipeng Zu and Xiao He and Jia Yang and Lianqing Liu and Wenxue Wang},
  doi          = {10.1016/j.neunet.2023.04.042},
  journal      = {Neural Networks},
  pages        = {419-427},
  shortjournal = {Neural Netw.},
  title        = {A reinforcement learning algorithm acquires demonstration from the training agent by dividing the task space},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint feature selection and optimal bipartite graph learning
for subspace clustering. <em>NN</em>, <em>164</em>, 408–418. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been tremendous interest in developing graph-based subspace clustering in high-dimensional data, which does not require a priori knowledge of the number of dimensions and subspaces. The general steps of such algorithms are dictionary representation and spectral clustering . Traditional methods use the dataset itself as a dictionary when performing dictionary representation. There are some limitations that the redundant information present in the dictionary and features may make the constructed graph structure unclear and require post-processing to obtain labels. To address these problems, we propose a novel subspace clustering model that first introduces feature selection to process the input data, randomly selects some samples to construct a dictionary to remove redundant information and learns the optimal bipartite graph with K-connected components under the constraint of the (normalized) Laplacian rank. Finally, the labels are obtained directly from the graphs. The experimental results on motion segmentation and face recognition datasets demonstrate the superior effectiveness and stability of our algorithm.},
  archive      = {J_NN},
  author       = {Shikun Mei and Wenhui Zhao and Quanxue Gao and Ming Yang and Xinbo Gao},
  doi          = {10.1016/j.neunet.2023.04.044},
  journal      = {Neural Networks},
  pages        = {408-418},
  shortjournal = {Neural Netw.},
  title        = {Joint feature selection and optimal bipartite graph learning for subspace clustering},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tree-structured neural networks: Spatiotemporal dynamics and
optimal control. <em>NN</em>, <em>164</em>, 395–407. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How the network topology drives the response dynamic is a basic question that has not yet been fully answered in neural networks . Elucidating the internal relation between topological structures and dynamics is instrumental in our understanding of brain function. Recent studies have revealed that the ring structure and star structure have a great influence on the dynamical behavior of neural networks . In order to further explore the role of topological structures in the response dynamic, we construct a new tree structure that differs from the ring structure and star structure of traditional neural networks. Considering the diffusion effect, we propose a diffusion neural network model with binary tree structure and multiple delays. How to design control strategies to optimize brain function has also been an open question. Thus, we put forward a novel full-dimensional nonlinear state feedback control strategy to optimize relevant neurodynamics. Some conditions about the local stability and Hopf bifurcation are obtained, and it is proved that the Turing instability does not occur. Moreover, for the formation of the spatially homogeneous periodic solution, some diffusion conditions are also fused together. Finally, several numerical examples are carried out to illustrate the results’ correctness. Meanwhile, some comparative experiments are rendered to reveal the effectiveness of the proposed control strategy.},
  archive      = {J_NN},
  author       = {Jiajin He and Min Xiao and Jing Zhao and Zhengxin Wang and Yi Yao and Jinde Cao},
  doi          = {10.1016/j.neunet.2023.04.039},
  journal      = {Neural Networks},
  pages        = {395-407},
  shortjournal = {Neural Netw.},
  title        = {Tree-structured neural networks: Spatiotemporal dynamics and optimal control},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability analysis of stochastic gradient descent for
homogeneous neural networks and linear classifiers. <em>NN</em>,
<em>164</em>, 382–394. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove new generalization bounds for stochastic gradient descent when training classifiers with invariances. Our analysis is based on the stability framework and covers both the convex case of linear classifiers and the non-convex case of homogeneous neural networks . We analyze stability with respect to the normalized version of the loss function used for training. This leads to investigating a form of angle-wise stability instead of euclidean stability in weights. For neural networks , the measure of distance we consider is invariant to rescaling the weights of each layer. Furthermore, we exploit the notion of on-average stability in order to obtain a data-dependent quantity in the bound. This data-dependent quantity is seen to be more favorable when training with larger learning rates in our numerical experiments. This might help to shed some light on why larger learning rates can lead to better generalization in some practical scenarios.},
  archive      = {J_NN},
  author       = {Alexandre Lemire Paquin and Brahim Chaib-draa and Philippe Giguère},
  doi          = {10.1016/j.neunet.2023.04.028},
  journal      = {Neural Networks},
  pages        = {382-394},
  shortjournal = {Neural Netw.},
  title        = {Stability analysis of stochastic gradient descent for homogeneous neural networks and linear classifiers},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). B-mode ultrasound based CAD for liver cancers via multi-view
privileged information learning. <em>NN</em>, <em>164</em>, 369–381. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {B-mode ultrasound-based computer-aided diagnosis model can help sonologists improve the diagnostic performance for liver cancers, but it generally suffers from the bottleneck due to the limited structure and internal echogenicity information in B-mode ultrasound images . Contrast-enhanced ultrasound images provide additional diagnostic information on dynamic blood perfusion of liver lesions for B-mode ultrasound images with improved diagnostic accuracy . Since transfer learning has indicated its effectiveness in promoting the performance of target computer-aided diagnosis model by transferring knowledge from related imaging modalities , a multi-view privileged information learning framework is proposed to improve the diagnostic accuracy of the single-modal B-mode ultrasound-based diagnosis for liver cancers. This framework can make full use of the shared label information between the paired B-mode ultrasound images and contrast-enhanced ultrasound images to guide knowledge transfer It consists of a novel supervised dual-view deep Boltzmann machine and a new deep multi-view SVM algorithm. The former is developed to implement knowledge transfer from the multi-phase contrast-enhanced ultrasound images to the B-mode ultrasound-based diagnosis model via a feature-level learning using privileged information paradigm, which is totally different from the existing learning using privileged information paradigm that performs knowledge transfer in the classifier. The latter further fuses and enhances feature representation learned from three pre-trained supervised dual-view deep Boltzmann machine networks for the classification task . An experiment is conducted on a bimodal ultrasound liver cancer dataset. The experimental results show that the proposed framework outperforms all the compared algorithms with the best classification accuracy of 88.91 ± 1.52\%, sensitivity of 88.31 ± 2.02\%, and specificity of 89.50 ± 3.12\%. It suggests the effectiveness of our proposed MPIL framework for the BUS-based CAD of liver cancers.},
  archive      = {J_NN},
  author       = {Xiangmin Han and Bangming Gong and Lehang Guo and Jun Wang and Shihui Ying and Shuo Li and Jun Shi},
  doi          = {10.1016/j.neunet.2023.03.028},
  journal      = {Neural Networks},
  pages        = {369-381},
  shortjournal = {Neural Netw.},
  title        = {B-mode ultrasound based CAD for liver cancers via multi-view privileged information learning},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SpikeSEE: An energy-efficient dynamic scenes processing
framework for retinal prostheses. <em>NN</em>, <em>164</em>, 357–368.
(<a href="https://doi.org/10.1016/j.neunet.2023.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent and low-power retinal prostheses are highly demanded in this era, where wearable and implantable devices are used for numerous healthcare applications. In this paper, we propose an energy-efficient dynamic scenes processing framework (SpikeSEE) that combines a spike representation encoding technique and a bio-inspired spiking recurrent neural network (SRNN) model to achieve intelligent processing and extreme low-power computation for retinal prostheses . The spike representation encoding technique could interpret dynamic scenes with sparse spike trains , decreasing the data volume. The SRNN model, inspired by the human retina’s special structure and spike processing method, is adopted to predict the response of ganglion cells to dynamic scenes. Experimental results show that the Pearson correlation coefficient of the proposed SRNN model achieves 0.93, which outperforms the state-of-the-art processing framework for retinal prostheses. Thanks to the spike representation and SRNN processing, the model can extract visual features in a multiplication-free fashion. The framework achieves 8 times power reduction compared with the convolutional recurrent neural network (CRNN) processing-based framework. Our proposed SpikeSEE predicts the response of ganglion cells more accurately with lower energy consumption , which alleviates the precision and power issues of retinal prostheses and provides a potential solution for wearable or implantable prostheses.},
  archive      = {J_NN},
  author       = {Chuanqing Wang and Chaoming Fang and Yong Zou and Jie Yang and Mohamad Sawan},
  doi          = {10.1016/j.neunet.2023.05.002},
  journal      = {Neural Networks},
  pages        = {357-368},
  shortjournal = {Neural Netw.},
  title        = {SpikeSEE: An energy-efficient dynamic scenes processing framework for retinal prostheses},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-teacher knowledge distillation based on joint guidance
of probe and adaptive corrector. <em>NN</em>, <em>164</em>, 345–356. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has been widely used in model compression . But, in the current multi-teacher KD algorithms, the student can only passively acquire the knowledge of the teacher’s middle layer in a single form and all teachers use identical a guiding scheme to the student. To solve these problems, this paper proposes a multi-teacher KD based on joint Guidance of Probe and Adaptive Corrector (GPAC) method. First, GPAC proposes a teacher selection strategy guided by the Linear Classifier Probe (LCP). This strategy allows the student to select better teachers in the middle layer. Teachers are evaluated using the classification accuracy detected by LCP. Then, GPAC designs an adaptive multi-teacher instruction mechanism. The mechanism uses instructional weights to emphasize the student’s predicted direction and reduce the student’s difficulty learning from teachers. At the same time, every teacher can formulate guiding scheme according to the Kullback–Leibler divergence loss of the student and itself. Finally, GPAC develops a multi-level mechanism for adjusting spatial attention loss. this mechanism uses a piecewise function that varies with the number of epochs to adjust the spatial attention loss. This piecewise function classifies the student’ learning about spatial attention into three levels, which can efficiently use spatial attention of teachers. GPAC and the current state-of-the-art distillation methods are tested on CIFAR-10 and CIFAR-100 datasets. The experimental results demonstrate that the proposed method in this paper can obtain higher classification accuracy .},
  archive      = {J_NN},
  author       = {Ronghua Shang and Wenzheng Li and Songling Zhu and Licheng Jiao and Yangyang Li},
  doi          = {10.1016/j.neunet.2023.04.015},
  journal      = {Neural Networks},
  pages        = {345-356},
  shortjournal = {Neural Netw.},
  title        = {Multi-teacher knowledge distillation based on joint guidance of probe and adaptive corrector},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prospective classification of alzheimer’s disease conversion
from mild cognitive impairment. <em>NN</em>, <em>164</em>, 335–344. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is emerging as a serious problem with the rapid aging of the population, but due to the unclear cause of the disease and the absence of therapy, appropriate preventive measures are the next best thing. For this reason, it is important to early detect whether the disease converts from mild cognitive impairment (MCI) which is a prodromal phase of AD. With the advance in brain imaging techniques, various machine learning algorithms have become able to predict the conversion from MCI to AD by learning brain atrophy patterns. However, at the time of diagnosis, it is difficult to distinguish between the conversion group and the non-conversion group of subjects because the difference between groups is small, but the within-group variability is large in brain images. After a certain period of time , the subjects of conversion group show significant brain atrophy, whereas subjects of non-conversion group show only subtle changes due to the normal aging effect. This difference on brain atrophy makes the brain images more discriminative for learning. Motivated by this, we propose a method to perform classification by projecting brain images into the future, namely prospective classification. The experiments on the Alzheimer’s Disease Neuroimaging Initiative dataset show that the prospective classification outperforms ordinary classification. Moreover, the features of prospective classification indicate the brain regions that significantly influence the conversion from MCI to AD.},
  archive      = {J_NN},
  author       = {Sunghong Park and Chang Hyung Hong and Dong-gi Lee and Kanghee Park and Hyunjung Shin and Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.neunet.2023.04.018},
  journal      = {Neural Networks},
  pages        = {335-344},
  shortjournal = {Neural Netw.},
  title        = {Prospective classification of alzheimer’s disease conversion from mild cognitive impairment},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Capsule neural tensor networks with multi-aspect information
for few-shot knowledge graph completion. <em>NN</em>, <em>164</em>,
323–334. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Knowledge Graph Completion (FKGC) has recently attracted significant research interest due to its ability to expand few-shot relation coverage in Knowledge Graphs. Prevailing FKGC approaches focus on exploiting the one-hop neighbor information of entities to enhance few-shot relation embedding. However, these methods select one-hop neighbors randomly and neglect the rich multi-aspect information of entities. Although some methods have attempted to leverage Long Short-Term Memory (LSTM) to learn few-shot relation embedding, they are sensitive to the input order. To address these limitations, we propose the Capsule Neural Tensor Networks with Multi-Aspect Information approach (short for InforMix-FKGC). InforMix-FKGC employs a one-hop neighbor selection strategy based on how valuable they are and encodes multi-aspect information of entities, including one-hop neighbors, attributes and literal description. Then, a capsule network is responsible for integrating the support set and deriving few-shot relation embedding. Moreover, a neural tensor network is used to match the query set with the support set. In this way, InforMix-FKGC can learn few-shot relation embedding more precisely so as to enhance the accuracy of FKGC. Extensive experiments on the NELL-One and Wiki-One datasets demonstrate that InforMix-FKGC significantly outperforms ten state-of-the-art methods in terms of Mean Reciprocal Rank and Hits@K.},
  archive      = {J_NN},
  author       = {Qianyu Li and Jiale Yao and Xiaoli Tang and Han Yu and Siyu Jiang and Haizhi Yang and Hengjie Song},
  doi          = {10.1016/j.neunet.2023.04.041},
  journal      = {Neural Networks},
  pages        = {323-334},
  shortjournal = {Neural Netw.},
  title        = {Capsule neural tensor networks with multi-aspect information for few-shot knowledge graph completion},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised deep embedded clustering with pairwise
constraints and subset allocation. <em>NN</em>, <em>164</em>, 310–322.
(<a href="https://doi.org/10.1016/j.neunet.2023.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised deep clustering methods attract much attention due to their excellent performance on the end-to-end clustering task . However, it is hard to obtain satisfying clustering results since many overlapping samples in industrial text datasets strongly and incorrectly influence the learning process. Existing methods incorporate prior knowledge in the form of pairwise constraints or class labels, which not only largely ignore the correlation between these two supervision information but also cause the problem of weak-supervised constraint or incorrect strong-supervised label guidance. In order to tackle these problems, we propose a semi-supervised method based on pairwise constraints and subset allocation (PCSA-DEC). We redefine the similarity-based constraint loss by forcing the similarity of samples in the same class much higher than other samples and design a novel subset allocation loss to precisely learn strong-supervised information contained in labels which consistent with unlabeled data . Experimental results on the two industrial text datasets show that our method can yield 8.2\%–8.7\% improvement in accuracy and 13.4\%–19.8\% on normalized mutual information over the state-of-the-art method.},
  archive      = {J_NN},
  author       = {Yalin Wang and Jiangfeng Zou and Kai Wang and Chenliang Liu and Xiaofeng Yuan},
  doi          = {10.1016/j.neunet.2023.04.016},
  journal      = {Neural Networks},
  pages        = {310-322},
  shortjournal = {Neural Netw.},
  title        = {Semi-supervised deep embedded clustering with pairwise constraints and subset allocation},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Growing dendrites enhance a neuron’s computational power and
memory capacity. <em>NN</em>, <em>164</em>, 275–309. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neocortical pyramidal neurons have many dendrites, and such dendrites are capable of, in isolation of one-another, generating a neuronal spike. It is also now understood that there is a large amount of dendritic growth during the first years of a humans life, arguably a period of prodigious learning. These observations inspire the construction of a local, stochastic algorithm based on an earlier stochastic, homeostatic, Hebbian developmental theory. Here we investigate the neurocomputational advantages and limits on this novel algorithm that combines dendritogenesis with supervised adaptive synaptogenesis . Neurons created with this algorithm have enhanced memory capacity, can avoid catastrophic interference (forgetting), and have the ability to unmix mixture distributions. In particular, individual dendrites develop within each class, in an unsupervised manner , to become feature-clusters that correspond to the mixing elements of class-conditional mixture distribution. Error-free classification is demonstrated with input perturbations up to 40\%. Although discriminative problems are used to understand the capabilities of the stochastic algorithm and the neuronal connectivity it produces, the algorithm is in the generative class, it thus seems ideal for decisions that require generalization, i.e., extrapolation beyond previous learning.},
  archive      = {J_NN},
  author       = {William B Levy and Robert A. Baxter},
  doi          = {10.1016/j.neunet.2023.04.033},
  journal      = {Neural Networks},
  pages        = {275-309},
  shortjournal = {Neural Netw.},
  title        = {Growing dendrites enhance a neuron’s computational power and memory capacity},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aperiodic switching event-triggered stabilization of
continuous memristive neural networks with interval delays. <em>NN</em>,
<em>164</em>, 264–274. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stabilization problem is studied for memristive neural networks with interval delays under aperiodic switching event-triggered control. Note that, most of delayed memristive neural networks models studied are discontinuous, which are not the real memristive neural networks. First, a real model of memristive neural networks is proposed by continuous differential equations, furthermore, it is simplified to neural networks with interval matrix uncertainties. Secondly, an aperiodic switching event-trigger is given, and the considered system switches between aperiodic sampled-data system and continuous event-triggered system. Thirdly, by constructing a time-dependent piecewise-defined Lyapunov functional , the stability criterion and the feedback gain design are obtained by linear matrix inequalities. Compared with the existing results, the stability criterion is with lower conservatism. Finally, two neurons are taken as examples to ensure the feasibility of the results.},
  archive      = {J_NN},
  author       = {Yaning Wang and Huan Tuo and Huiping Lyu and Zunshui Cheng and Youming Xin},
  doi          = {10.1016/j.neunet.2023.04.036},
  journal      = {Neural Networks},
  pages        = {264-274},
  shortjournal = {Neural Netw.},
  title        = {Aperiodic switching event-triggered stabilization of continuous memristive neural networks with interval delays},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Co-attention enabled content-based image retrieval.
<em>NN</em>, <em>164</em>, 245–263. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based image retrieval (CBIR) aims to provide the most similar images to a given query. Feature extraction plays an essential role in retrieval performance within a CBIR pipeline. Current CBIR studies would either uniformly extract feature information from the input image and use it directly or employ some trainable spatial weighting module which is then used for similarity comparison between pairs of query and candidate matching images. These spatial weighting modules are normally query non-sensitive and only based on the knowledge learned during the training stage. They may focus towards incorrect regions, especially when the target image is not salient or is surrounded by distractors. This paper proposes an efficient query sensitive co-attention 1 mechanism for large-scale CBIR tasks. In order to reduce the extra computation cost required by the query sensitivity to the co-attention mechanism, the proposed method employs clustering of the selected local features. Experimental results indicate that the co-attention maps can provide the best retrieval results on benchmark datasets under challenging situations, such as having completely different image acquisition conditions between the query and its match image.},
  archive      = {J_NN},
  author       = {Zechao Hu and Adrian G. Bors},
  doi          = {10.1016/j.neunet.2023.04.009},
  journal      = {Neural Networks},
  pages        = {245-263},
  shortjournal = {Neural Netw.},
  title        = {Co-attention enabled content-based image retrieval},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrast sensitivity function in deep networks. <em>NN</em>,
<em>164</em>, 228–244. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contrast sensitivity function (CSF) is a fundamental signature of the visual system that has been measured extensively in several species. It is defined by the visibility threshold for sinusoidal gratings at all spatial frequencies . Here, we investigated the CSF in deep neural networks using the same 2AFC contrast detection paradigm as in human psychophysics. We examined 240 networks pretrained on several tasks. To obtain their corresponding CSFs, we trained a linear classifier on top of the extracted features from frozen pretrained networks. The linear classifier is exclusively trained on a contrast discrimination task with natural images. It has to find which of the two input images has higher contrast. The network’s CSF is measured by detecting which one of two images contains a sinusoidal grating of varying orientation and spatial frequency. Our results demonstrate characteristics of the human CSF are manifested in deep networks both in the luminance channel (a band-limited inverted U-shaped function) and in the chromatic channels (two low-pass functions of similar properties). The exact shape of the networks’ CSF appears to be task-dependent. The human CSF is better captured by networks trained on low-level visual tasks such as image-denoising or autoencoding. However, human-like CSF also emerges in mid- and high-level tasks such as edge detection and object recognition. Our analysis shows that human-like CSF appears in all architectures but at different depths of processing, some at early layers, while others in intermediate and final layers. Overall, these results suggest that (i) deep networks model the human CSF faithfully, making them suitable candidates for applications of image quality and compression, (ii) efficient/purposeful processing of the natural world drives the CSF shape, and (iii) visual representation from all levels of visual hierarchy contribute to the tuning curve of the CSF, in turn implying a function which we intuitively think of as modulated by low-level visual features may arise as a consequence of pooling from a larger set of neurons at all levels of the visual system.},
  archive      = {J_NN},
  author       = {Arash Akbarinia and Yaniv Morgenstern and Karl R. Gegenfurtner},
  doi          = {10.1016/j.neunet.2023.04.032},
  journal      = {Neural Networks},
  pages        = {228-244},
  shortjournal = {Neural Netw.},
  title        = {Contrast sensitivity function in deep networks},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel time series prediction method based on pooling
compressed sensing echo state network and its application in stock
market. <em>NN</em>, <em>164</em>, 216–227. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the prediction of time series, the echo state network (ESN) exhibits exclusive strengths and a unique training structure . Based on ESN model, a pooling activation algorithm consisting noise value and adjusted pooling algorithm is proposed to enrich the update strategy of the reservoir layer in ESN. The algorithm optimizes the distribution of reservoir layer nodes. And the nodes set will be more matched to the characteristics of the data. In addition, we introduce a more efficient and accurate compressed sensing technique based on the existing research. The novel compressed sensing technique reduces the amount of spatial computation of methods. The ESN model based on the above two techniques overcomes the limitations in traditional prediction. In the experimental part, the model is validated with different chaotic time series as well as multiple stocks, and the method shows its efficiency and accuracy in prediction.},
  archive      = {J_NN},
  author       = {Zijian Wang and Hui Zhao and Mingwen Zheng and Sijie Niu and Xizhan Gao and Lixiang Li},
  doi          = {10.1016/j.neunet.2023.04.031},
  journal      = {Neural Networks},
  pages        = {216-227},
  shortjournal = {Neural Netw.},
  title        = {A novel time series prediction method based on pooling compressed sensing echo state network and its application in stock market},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-shot federated learning without server-side training.
<em>NN</em>, <em>164</em>, 203–215. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has recently made significant progress as a new machine learning paradigm for privacy protection. Due to the high communication cost of traditional FL, one-shot federated learning is gaining popularity as a way to reduce communication cost between clients and the server. Most of the existing one-shot FL methods are based on Knowledge Distillation ; however, distillation based approach requires an extra training phase and depends on publicly available data sets or generated pseudo samples. In this work, we consider a novel and challenging cross-silo setting: performing a single round of parameter aggregation on the local models without server-side training. In this setting, we propose an effective algorithm for Model Aggregation via Exploring Common Harmonized Optima (MA-Echo), which iteratively updates the parameters of all local models to bring them close to a common low-loss area on the loss surface, without harming performance on their own data sets at the same time. Compared to the existing methods, MA-Echo can work well even in extremely non-identical data distribution settings where the support categories of each local model have no overlapped labels with those of the others. We conduct extensive experiments on two popular image classification data sets to compare the proposed method with existing methods and demonstrate the effectiveness of MA-Echo, which clearly outperforms the state-of-the-arts. The source code can be accessed in https://github.com/FudanVI/MAEcho .},
  archive      = {J_NN},
  author       = {Shangchao Su and Bin Li and Xiangyang Xue},
  doi          = {10.1016/j.neunet.2023.04.035},
  journal      = {Neural Networks},
  pages        = {203-215},
  shortjournal = {Neural Netw.},
  title        = {One-shot federated learning without server-side training},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PIPER: A logic-driven deep contrastive optimization pipeline
for event temporal reasoning. <em>NN</em>, <em>164</em>, 186–202. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event temporal relation extraction is an important task for information extraction. The existing methods usually rely on feature engineering and require post-process to achieve optimization, though inconsistent optimization may occur in the post-process module and main neural network due to their independence. Recently, a few works start to incorporate the temporal logic rules into the neural network and achieve joint optimization. However, these methods still suffer from two shortcomings: (1) Although the joint optimization is applied, the differences between rules are neglected in the unified design of rule losses and further the interpretability and flexibility of the design of model are reduced. (2) Because of lacking abundant syntactic connections between events and rule-match features, the performance of the model may be suppressed by the inefficient interaction in training between features and rules. To tackle these issues, this paper proposes PIPER, a logic-driven deep contrastive optimization pipeline for event temporal reasoning. Specifically, we apply joint optimization (including multi-stage and single-stage joint paradigms) by combining independent rule losses (i.e., flexibility) to make PIPER more interpretable. Also, by proposing a hierarchical graph distillation network to obtain more abundant syntactic information , the designed rule-match features can effectively aid in the interaction between low-level features and high-level rules during training. The final experiments on TB-Dense and MATRES demonstrate that the proposed model can achieve competitive performance compared with the recent advances.},
  archive      = {J_NN},
  author       = {Beibei Zhang and Lishuang Li},
  doi          = {10.1016/j.neunet.2023.04.020},
  journal      = {Neural Networks},
  pages        = {186-202},
  shortjournal = {Neural Netw.},
  title        = {PIPER: A logic-driven deep contrastive optimization pipeline for event temporal reasoning},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning defense transformations for counterattacking
adversarial examples. <em>NN</em>, <em>164</em>, 177–185. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are vulnerable to adversarial examples with small perturbations. Adversarial defense thus has been an important means which improves the robustness of DNNs by defending against adversarial examples . Existing defense methods focus on some specific types of adversarial examples and may fail to defend well in real-world applications. In practice, we may face many types of attacks where the exact type of adversarial examples in real-world applications can be even unknown. In this paper, motivated by that adversarial examples are more likely to appear near the classification boundary and are vulnerable to some transformations, we study adversarial examples from a new perspective that whether we can defend against adversarial examples by pulling them back to the original clean distribution. We empirically verify the existence of defense affine transformations that restore adversarial examples. Relying on this, we learn defense transformations to counterattack the adversarial examples by parameterizing the affine transformations and exploiting the boundary information of DNNs. Extensive experiments on both toy and real-world data sets demonstrate the effectiveness and generalization of our defense method. The code is avaliable at https://github.com/SCUTjinchengli/DefenseTransformer .},
  archive      = {J_NN},
  author       = {Jincheng Li and Shuhai Zhang and Jiezhang Cao and Mingkui Tan},
  doi          = {10.1016/j.neunet.2023.03.008},
  journal      = {Neural Networks},
  pages        = {177-185},
  shortjournal = {Neural Netw.},
  title        = {Learning defense transformations for counterattacking adversarial examples},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifelong learning on evolving graphs under the constraints
of imbalanced classes and new classes. <em>NN</em>, <em>164</em>,
156–176. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong graph learning deals with the problem of continually adapting graph neural network (GNN) models to changes in evolving graphs. We address two critical challenges of lifelong graph learning in this work: dealing with new classes and tackling imbalanced class distributions. The combination of these two challenges is particularly relevant since newly emerging classes typically resemble only a tiny fraction of the data, adding to the already skewed class distribution. We make several contributions: First, we show that the amount of unlabeled data does not influence the results, which is an essential prerequisite for lifelong learning on a sequence of tasks. Second, we experiment with different label rates and show that our methods can perform well with only a tiny fraction of annotated nodes. Third, we propose the gDOC method to detect new classes under the constraint of having an imbalanced class distribution. The critical ingredient is a weighted binary cross-entropy loss function to account for the class imbalance. Moreover, we demonstrate combinations of gDOC with various base GNN models such as GraphSAGE, Simplified Graph Convolution , and Graph Attention Networks . Lastly, our k-neighborhood time difference measure provably normalizes the temporal changes across different graph datasets. With extensive experimentation, we find that the proposed gDOC method is consistently better than a naive adaption of DOC to graphs. Specifically, in experiments using the smallest history size, the out-of-distribution detection score of gDOC is 0.09 compared to 0.01 for DOC. Furthermore, gDOC achieves an Open-F1 score, a combined measure of in-distribution classification and out-of-distribution detection, of 0.33 compared to 0.25 of DOC (32\% increase).},
  archive      = {J_NN},
  author       = {Lukas Galke and Iacopo Vagliano and Benedikt Franke and Tobias Zielke and Marcel Hoffmann and Ansgar Scherp},
  doi          = {10.1016/j.neunet.2023.04.022},
  journal      = {Neural Networks},
  pages        = {156-176},
  shortjournal = {Neural Netw.},
  title        = {Lifelong learning on evolving graphs under the constraints of imbalanced classes and new classes},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSAST: Content self-supervised and style contrastive
learning for arbitrary style transfer. <em>NN</em>, <em>164</em>,
146–155. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arbitrary artistic style transfer has achieved great success with deep neural networks , but it is still difficult for existing methods to tackle the dilemma of content preservation and style translation due to the inherent content-and-style conflict. In this paper, we introduce content self-supervised learning and style contrastive learning to arbitrary style transfer for improved content preservation and style translation, respectively. The former one is based on the assumption that stylization of a geometrically transformed image is perceptually similar to applying the same transformation to the stylized result of the original image. This content self-supervised constraint noticeably improves content consistency before and after style translation, and contributes to reducing noises and artifacts as well. Furthermore, it is especially suitable to video style transfer, due to its ability to promote inter-frame continuity, which is of crucial importance to visual stability of video sequences. For the latter one, we construct a contrastive learning that pull close style representations (Gram matrices) of the same style and push away that of different styles. This brings more accurate style translation and more appealing visual effect. A large number of qualitative and quantitative experiments demonstrate superiority of our method in improving arbitrary style transfer quality, both for images and videos.},
  archive      = {J_NN},
  author       = {Yuqi Zhang and Yingjie Tian and Junjie Hou},
  doi          = {10.1016/j.neunet.2023.04.037},
  journal      = {Neural Networks},
  pages        = {146-155},
  shortjournal = {Neural Netw.},
  title        = {CSAST: Content self-supervised and style contrastive learning for arbitrary style transfer},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long short-term memory with activation on gradient.
<em>NN</em>, <em>164</em>, 135–145. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of long short-term memory (LSTM) layers increases, vanishing/exploding gradient problems exacerbate and have a negative impact on the performance of the LSTM. In addition, the ill-conditioned problem occurs in the training process of LSTM and adversely affects its convergence. In this work, a simple and effective method of the gradient activation is applied to the LSTM, while empirical criteria for choosing gradient activation hyperparameters are found. Activating the gradient refers to modifying the gradient with a specific function named the gradient activation function . Moreover, different activation functions and different gradient operations are compared to prove that the gradient activation is effective on LSTM. Furthermore, comparative experiments are conducted, and their results show that the gradient activation alleviates the above problems and accelerates the convergence of the LSTM. The source code is publicly available at https://github.com/LongJin-lab/ACT-In-NLP .},
  archive      = {J_NN},
  author       = {Chuan Qin and Liangming Chen and Zangtai Cai and Mei Liu and Long Jin},
  doi          = {10.1016/j.neunet.2023.04.026},
  journal      = {Neural Networks},
  pages        = {135-145},
  shortjournal = {Neural Netw.},
  title        = {Long short-term memory with activation on gradient},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel sequential structure for lightweight multi-scale
feature learning under limited available images. <em>NN</em>,
<em>164</em>, 124–134. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although multi-scale feature learning can improve the performances of deep models, its parallel structure quadratically increases the model parameters and causes deep models to become larger and larger when enlarging the receptive fields (RFs). This leads to deep models easily suffering from over-fitting issue in many practical applications where the available training samples are always insufficient or limited. In addition, under this limited situation, although lightweight models (with fewer model parameters) can effectively reduce over-fitting, they may suffer from under-fitting because of insufficient training data for effective feature learning . In this work, a lightweight model called Sequential Multi-scale Feature Learning Network (SMF-Net) is proposed to alleviate these two issues simultaneously using a novel sequential structure of multi-scale feature learning. Compared to both deep and lightweight models, the proposed sequential structure in SMF-Net can easily extract features with larger RFs for multi-scale feature learning only with a few and linearly increased model parameters. The experimental results on both classification and segmentation tasks demonstrate that our SMF-Net only has 1.25M model parameters (5.3\% of Res2Net50) with 0.7G FLOPS (14.6\% of Res2Net50) for classification and 1.54M parameters (8.9\% of UNet) with 3.35G FLOPs (10.9\% of UNet) for segmentation but achieves higher accuracy than SOTA deep models and lightweight models, even when the training data is very limited available.},
  archive      = {J_NN},
  author       = {Peng Liu and Jie Du and Chi-Man Vong},
  doi          = {10.1016/j.neunet.2023.04.023},
  journal      = {Neural Networks},
  pages        = {124-134},
  shortjournal = {Neural Netw.},
  title        = {A novel sequential structure for lightweight multi-scale feature learning under limited available images},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable hybrid word representations for sentiment
analysis of financial news. <em>NN</em>, <em>164</em>, 115–123. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing interest of people in the stock and financial market, the sentiment analysis of news and texts related to the sector is of utmost importance . This helps the potential investors in deciding what company to invest in and what are their long-term benefits. However, it is challenging to analyze the sentiments of texts related to the financial domain, given the enormous amount of information available. The existing approaches are unable to capture complex attributes of language such as word usage, including semantics and syntax throughout the context, and polysemy in the context. Further, these approaches failed to interpret the models’ predictability, which is obscure to humans. Models’ interpretability to justify the predictions has remained largely unexplored and has become important to engender users’ trust in the predictions by providing insight into the model prediction. Accordingly, in this paper, we present an explainable hybrid word representation that first augments the data to address the class imbalance issue and then integrates three embeddings to involve polysemy in context, semantics, and syntax in a context. We then fed our proposed word representation to a convolutional neural network (CNN) with attention to capture the sentiment. The experimental results show that our model outperforms several baselines of both classic classifiers and combinations of various word embedding models in the sentiment analysis of financial news. The experimental results also show that the proposed model outperforms several baselines of word embeddings and contextual embeddings when they are separately fed to a neural network model. Further, we show the explainability of the proposed method by presenting the visualization results to explain the reason for a prediction in the sentiment analysis of financial news.},
  archive      = {J_NN},
  author       = {Surabhi Adhikari and Surendrabikram Thapa and Usman Naseem and Hai Ya Lu and Gnana Bharathy and Mukesh Prasad},
  doi          = {10.1016/j.neunet.2023.04.011},
  journal      = {Neural Networks},
  pages        = {115-123},
  shortjournal = {Neural Netw.},
  title        = {Explainable hybrid word representations for sentiment analysis of financial news},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal h∞ tracking control of nonlinear systems with
zero-equilibrium-free via novel adaptive critic designs. <em>NN</em>,
<em>164</em>, 105–114. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel adaptive critic control method is designed to solve an optimal H ∞ H∞ tracking control problem for continuous nonlinear systems with nonzero equilibrium based on adaptive dynamic programming (ADP). To guarantee the finiteness of a cost function, traditional methods generally assume that the controlled system has a zero equilibrium point, which is not true in practical systems. In order to overcome such obstacle and realize H ∞ H∞ optimal tracking control , this paper proposes a novel cost function design with respect to disturbance, tracking error and the derivative of tracking error. Based on the designed cost function, the H ∞ H∞ control problem is formulated as two-player zero-sum differential games, and then a policy iteration (PI) algorithm is proposed to solve the corresponding Hamilton–Jacobi–Isaacs (HJI) equation. In order to obtain the online solution to the HJI equation, a single-critic neural network structure based on PI algorithm is established to learn the optimal control policy and the worst-case disturbance law. It is worth mentioning that the proposed adaptive critic control method can simplify the controller design process when the equilibrium of the systems is not zero. Finally, simulations are conducted to evaluate the tracking performance of the proposed control methods.},
  archive      = {J_NN},
  author       = {Zhinan Peng and Hanqi Ji and Chaobin Zou and Yiqun Kuang and Hong Cheng and Kaibo Shi and Bijoy Kumar Ghosh},
  doi          = {10.1016/j.neunet.2023.04.021},
  journal      = {Neural Networks},
  pages        = {105-114},
  shortjournal = {Neural Netw.},
  title        = {Optimal h∞ tracking control of nonlinear systems with zero-equilibrium-free via novel adaptive critic designs},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep connectome learning network using graph convolution
for connectome-disease association study. <em>NN</em>, <em>164</em>,
91–104. (<a href="https://doi.org/10.1016/j.neunet.2023.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate analysis approaches provide insights into the identification of phenotype associations in brain connectome data. In recent years, deep learning methods including convolutional neural network (CNN) and graph neural network (GNN), have shifted the development of connectome-wide association studies (CWAS) and made breakthroughs for connectome representation learning by leveraging deep embedded features. However, most existing studies remain limited by potentially ignoring the exploration of region-specific features, which play a key role in distinguishing brain disorders with high intra-class variations, such as autism spectrum disorder (ASD), and attention deficit hyperactivity disorder (ADHD). Here, we propose a multivariate distance-based connectome network (MDCN) that addresses the local specificity problem by efficient parcellation-wise learning, as well as associating population and parcellation dependencies to map individual differences. The approach incorporating an explainable method, parcellation-wise gradient and class activation map (p-GradCAM), is feasible for identifying individual patterns of interest and pinpointing connectome associations with diseases. We demonstrate the utility of our method on two largely aggregated multicenter public datasets by distinguishing ASD and ADHD from healthy controls and assessing their associations with underlying diseases. Extensive experiments have demonstrated the superiority of MDCN in classification and interpretation, where MDCN outperformed competitive state-of-the-art methods and achieved a high proportion of overlap with previous findings. As a CWAS-guided deep learning method, our proposed MDCN framework may narrow the bridge between deep learning and CWAS approaches, and provide new insights for connectome-wide association studies.},
  archive      = {J_NN},
  author       = {Yanwu Yang and Chenfei Ye and Ting Ma},
  doi          = {10.1016/j.neunet.2023.04.025},
  journal      = {Neural Networks},
  pages        = {91-104},
  shortjournal = {Neural Netw.},
  title        = {A deep connectome learning network using graph convolution for connectome-disease association study},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TIToK: A solution for bi-imbalanced unsupervised domain
adaptation. <em>NN</em>, <em>164</em>, 81–90. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to transfer knowledge via domain alignment, and typically assumes balanced data distribution. When deployed in real tasks, however, (i) each domain usually suffers from class imbalance, and (ii) different domains may have different class imbalance ratios . In such bi-imbalanced cases with both within-domain and across-domain imbalance, source knowledge transfer may degenerate the target performance. Some recent efforts have adopted source re-weighting to this issue, in order to align label distributions across domains. However, since target label distribution is unknown, the alignment might be incorrect or even risky. In this paper, we propose an alternative solution named TIToK for bi-imbalanced UDA, by directly Transferring Imbalance-Tolerant Knowledge across domains. In TIToK, a class contrastive loss is presented for classification, in order to alleviate the sensitivity to imbalance in knowledge transfer. Meanwhile, knowledge of class correlation is transferred as a supplementary, which is commonly invariant to imbalance. Finally, discriminative feature alignment is developed for a more robust classifier boundary. Experiments over benchmark datasets show that TIToK achieves competitive performance with the state-of-the-arts, and its performance is less sensitive to imbalance.},
  archive      = {J_NN},
  author       = {Yunyun Wang and Quchuan Chen and Yao Liu and Weikai Li and Songcan Chen},
  doi          = {10.1016/j.neunet.2023.04.027},
  journal      = {Neural Networks},
  pages        = {81-90},
  shortjournal = {Neural Netw.},
  title        = {TIToK: A solution for bi-imbalanced unsupervised domain adaptation},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered control for robust exponential
synchronization of inertial memristive neural networks under parameter
disturbance. <em>NN</em>, <em>164</em>, 67–80. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synchronization of memristive neural networks (MNNs) by using network control scheme has been widely and deeply studied. However, these researches are usually restricted to traditional continuous-time control methods for synchronization of the first-order MNNs. In this paper, we study the robust exponential synchronization of inertial memristive neural networks (IMNNs) with time-varying delays and parameter disturbance via event-triggered control (ETC) scheme. First, the delayed IMNNs with parameter disturbance are changed into first-order MNNs with parameter disturbance by constructing proper variable substitutions. Next, a kind of state feedback controller is designed to the response IMNN with parameter disturbance. Based on feedback controller , some ETC methods are provided to largely decrease the update times of controller. Then, some sufficient conditions are provided to realize robust exponential synchronization of delayed IMNNs with parameter disturbance via ETC scheme. Moreover, the Zeno behavior will not happen in all ETC conditions shown in this paper. Finally, numerical simulations are given to verify the advantages of the obtained results such as anti-interference performance and good reliability.},
  archive      = {J_NN},
  author       = {Wei Yao and Chunhua Wang and Yichuang Sun and Shuqing Gong and Hairong Lin},
  doi          = {10.1016/j.neunet.2023.04.024},
  journal      = {Neural Networks},
  pages        = {67-80},
  shortjournal = {Neural Netw.},
  title        = {Event-triggered control for robust exponential synchronization of inertial memristive neural networks under parameter disturbance},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Theoretical bounds of generalization error for generalized
extreme learning machine and random vector functional link network.
<em>NN</em>, <em>164</em>, 49–66. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the prediction accuracy of a learning algorithm on a theoretical basis is crucial and necessary for building the reliability of the learning algorithm. This paper analyzes prediction error obtained through the least square estimation in the generalized extreme learning machine (GELM), which applies the limiting behavior of the Moore–Penrose generalized inverse (M–P GI) to the output matrix of ELM. ELM is the random vector functional link (RVFL) network without direct input to output links Specifically, we analyze tail probabilities associated with upper and lower bounds to the error expressed by norms. The analysis employs the concepts of the L 2 L2 norm, the Frobenius norm , the stable rank, and the M–P GI. The coverage of theoretical analysis extends to the RVFL network. In addition, a criterion for more precise bounds of prediction errors that may give stochastically better network environments is provided. The analysis is applied to simple examples and large-size datasets to illustrate the procedure and verify the analysis and execution speed with big data. Based on this study, we can immediately obtain the upper and lower bounds of prediction errors and their associated tail probabilities through matrices calculations appearing in the GELM and RVFL. This analysis provides criteria for the reliability of the learning performance of a network in real-time and for network structure that enables obtaining better performance reliability. This analysis can be applied in various areas where the ELM and RVFL are adopted. The proposed analytical method will guide the theoretical analysis of errors occurring in DNNs , which employ a gradient descent algorithm.},
  archive      = {J_NN},
  author       = {Meejoung Kim},
  doi          = {10.1016/j.neunet.2023.04.014},
  journal      = {Neural Networks},
  pages        = {49-66},
  shortjournal = {Neural Netw.},
  title        = {Theoretical bounds of generalization error for generalized extreme learning machine and random vector functional link network},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Imitating the oracle: Towards calibrated model for class
incremental learning. <em>NN</em>, <em>164</em>, 38–48. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-incremental learning (CIL) aims to recognize classes that emerged in different phases. The joint-training (JT), which trains the model jointly with all classes, is often considered as the upper bound of CIL. In this paper, we thoroughly analyze the difference between CIL and JT in feature space and weight space. Motivated by the comparative analysis, we propose two types of calibration: feature calibration and weight calibration to imitate the oracle (ItO), i.e., JT. Specifically, on the one hand, feature calibration introduces deviation compensation to maintain the class decision boundary of old classes in feature space. On the other hand, weight calibration leverages forgetting-aware weight perturbation to increase transferability and reduce forgetting in parameter space. With those two calibration strategies, the model is forced to imitate the properties of joint-training at each incremental learning stage, thus yielding better CIL performance. Our ItO is a plug-and-play method and can be implemented into existing methods easily. Extensive experiments on several benchmark datasets demonstrate that ItO can significantly and consistently improve the performance of existing state-of-the-art methods. Our code is publicly available at https://github.com/Impression2805/ItO4CIL .},
  archive      = {J_NN},
  author       = {Fei Zhu and Zhen Cheng and Xu-Yao Zhang and Cheng-Lin Liu},
  doi          = {10.1016/j.neunet.2023.04.010},
  journal      = {Neural Networks},
  pages        = {38-48},
  shortjournal = {Neural Netw.},
  title        = {Imitating the oracle: Towards calibrated model for class incremental learning},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Basis operator network: A neural network-based model for
learning nonlinear operators via neural basis. <em>NN</em>,
<em>164</em>, 21–37. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely acknowledged that neural networks can approximate any continuous (even measurable) functions between finite-dimensional Euclidean spaces to arbitrary accuracy. Recently, the use of neural networks has started emerging in infinite-dimensional settings. Universal approximation theorems of operators guarantee that neural networks can learn mappings between infinite-dimensional spaces. In this paper, we propose a neural network-based method (BasisONet) capable of approximating mappings between function spaces. To reduce the dimension of an infinite-dimensional space, we propose a novel function autoencoder that can compress the function data. Our model can predict the output function at any resolution using the corresponding input data at any resolution once trained. Numerical experiments demonstrate that the performance of our model is competitive with existing methods on the benchmarks, and our model can address the data on a complex geometry with high precision. We further analyze some notable characteristics of our model based on the numerical results.},
  archive      = {J_NN},
  author       = {Ning Hua and Wenlian Lu},
  doi          = {10.1016/j.neunet.2023.04.017},
  journal      = {Neural Networks},
  pages        = {21-37},
  shortjournal = {Neural Netw.},
  title        = {Basis operator network: A neural network-based model for learning nonlinear operators via neural basis},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervision assisted multimodal remote sensing image
classification with coupled self-looping convolution networks.
<em>NN</em>, <em>164</em>, 1–20. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, remote sensing community has seen a surge in the use of multimodal data for different tasks such as land cover classification, change detection and many more. However, handling multimodal data requires synergistically using the information from different sources. Currently, deep learning (DL) techniques are being religiously used in multimodal data fusion owing to their superior feature extraction capabilities. But, DL techniques have their share of challenges. Firstly, DL models are mostly constructed in the forward fashion limiting their feature extraction capability. Secondly, multimodal learning is generally addressed in a supervised setting, which leads to high labelled data requirement. Thirdly, the models generally handle each modality separately, thus preventing any cross-modal interaction. Hence, we propose a novel self-supervision oriented method of multimodal remote sensing data fusion. For effective cross-modal learning, our model solves a self-supervised auxiliary task to reconstruct input features of one modality from the extracted features of another modality, thus enabling more representative pre-fusion features. To counter the forward architecture, our model is composed of convolutions both in backward and forward directions, thus creating self-looping connections, leading to a self-correcting framework. To facilitate cross-modal communication, we have incorporated coupling across modality-specific extractors using shared parameters. We evaluate our approach on three remote sensing datasets, namely Houston 2013 and Houston 2018, which are HSI-LiDAR datasets and TU Berlin, which is an HSI-SAR dataset, where we achieve the respective accuracy of 93.08\%, 84.59\% and 73.21\%, thus beating the state of the art by a minimum of 3.02\%, 2.23\% and 2.84\%.},
  archive      = {J_NN},
  author       = {Shivam Pande and Biplab Banerjee},
  doi          = {10.1016/j.neunet.2023.04.019},
  journal      = {Neural Networks},
  pages        = {1-20},
  shortjournal = {Neural Netw.},
  title        = {Self-supervision assisted multimodal remote sensing image classification with coupled self-looping convolution networks},
  volume       = {164},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>163</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(23)00242-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00242-3},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). CURRENT EVENTS. <em>NN</em>, <em>163</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(23)00241-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00241-1},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {CURRENT EVENTS},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adams-based hierarchical features fusion network for image
dehazing. <em>NN</em>, <em>163</em>, 379–394. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in Convolutional Neural Networks (CNNs) have made them one of the most powerful image dehazing methods. In particular, the Residual Networks (ResNets), which can avoid the vanishing gradient problem effectively, are widely deployed. To understand the success of ResNets, recent mathematical analysis of ResNets reveals that a ResNet has a similar formulation as the Euler method in solving the Ordinary Differential Equations (ODE’s). Hence, image dehazing which can be formulated as an optimal control problem in dynamical systems can be solved by a single-step optimal control method, such as the Euler method . This optimal control viewpoint provides a new perspective to address the problem of image restoration. Motivated by the advantages of multi-step optimal control solvers in ODE’s, which include better stability and efficiency than single-step solvers, e.g. Euler, we propose the Adams-based Hierarchical Feature Fusion Network (AHFFN) for image dehazing with modules inspired by a multi-step optimal control method named the Adams–Bashforth method. Firstly, we extend a multi-step Adams–Bashforth method to the corresponding Adams block, which achieves a higher accuracy than that of single-step solvers because of its more effective use of intermediate results. Then, we stack multiple Adams blocks to mimic the discrete approximation process of an optimal control in a dynamical system. To improve the results, the hierarchical features from stacked Adams blocks are fully used by combining Hierarchical Feature Fusion (HFF) and Lightweight Spatial Attention (LSA) with Adams blocks to form a new Adams module. Finally, we not only use HFF and LSA to fuse features, but also highlight important spatial information in each Adams module for estimating the clear image. The experimental results using synthetic and real images demonstrate that the proposed AHFFN obtains better accuracy and visual results than that of state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Shibai Yin and Shuhao Hu and Yibin Wang and Weixing Wang and Yee-Hong Yang},
  doi          = {10.1016/j.neunet.2023.03.021},
  journal      = {Neural Networks},
  pages        = {379-394},
  shortjournal = {Neural Netw.},
  title        = {Adams-based hierarchical features fusion network for image dehazing},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Remix: Towards the transferability of adversarial examples.
<em>NN</em>, <em>163</em>, 367–378. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are susceptible to adversarial examples , which are crafted by deliberately adding some human-imperceptible perturbations on original images. To explore the vulnerability of models of DNNs, transfer-based black-box attacks are attracting increasing attention of researchers credited to their high practicality. The transfer-based approaches can launch attacks against models easily in the black-box setting by resultant adversarial examples , whereas the success rates are not satisfactory. To boost the adversarial transferability, we propose a Remix method with multiple input transformations, which could achieve multiple data augmentation by utilizing gradients from previous iterations and images from other categories in the same iteration. Extensive experiments on the NeurIPS 2017 adversarial dataset and the ILSVRC 2012 validation dataset demonstrate that the proposed approach could drastically enhance the adversarial transferability and maintain similar success rates of white-box attacks on both undefended models and defended models. Furthermore, extended experiments based on LPIPS show that our method could maintain a similar perceived distance compared to other baselines.},
  archive      = {J_NN},
  author       = {Hongzhi Zhao and Lingguang Hao and Kuangrong Hao and Bing Wei and Xin Cai},
  doi          = {10.1016/j.neunet.2023.04.012},
  journal      = {Neural Networks},
  pages        = {367-378},
  shortjournal = {Neural Netw.},
  title        = {Remix: Towards the transferability of adversarial examples},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring personalization via federated representation
learning on non-IID data. <em>NN</em>, <em>163</em>, 354–366. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) can learn a global model across decentralized data over different clients. However, it is susceptible to statistical heterogeneity of client-specific data. Clients focus on optimizing for their individual target distributions , which would yield divergence of the global model due to inconsistent data distributions. Moreover, federated learning approaches adhere to the scheme of collaboratively learning representations and classifiers, further exacerbating such inconsistency and resulting in imbalanced features and biased classifiers. Hence, in this paper, we propose an independent two-stage personalized FL framework, i.e., Fed-RepPer, to separate representation learning from classification in federated learning. First, the client-side feature representation models are learned using supervised contrastive loss, which enables local objectives consistently, i.e., learning robust representations on distinct data distributions. Local representation models are aggregated into the common global representation model. Then, in the second stage, personalization is studied by learning different classifiers for each client based on the global representation model. The proposed two-stage learning scheme is examined in lightweight edge computing that involves devices with constrained computation resources. Experiments on various datasets (CIFAR-10/100, CINIC-10) and heterogeneous data setups show that Fed-RepPer outperforms alternatives by utilizing flexibility and personalization on non-IID data.},
  archive      = {J_NN},
  author       = {Changxing Jing and Yan Huang and Yihong Zhuang and Liyan Sun and Zhenlong Xiao and Yue Huang and Xinghao Ding},
  doi          = {10.1016/j.neunet.2023.04.007},
  journal      = {Neural Networks},
  pages        = {354-366},
  shortjournal = {Neural Netw.},
  title        = {Exploring personalization via federated representation learning on non-IID data},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Dynamic event-triggered controller design for nonlinear
systems: Reinforcement learning strategy. <em>NN</em>, <em>163</em>,
341–353. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current investigation aims at the optimal control problem for discrete-time nonstrict-feedback nonlinear systems by invoking the reinforcement learning-based backstepping technique and neural networks . The dynamic-event-triggered control strategy introduced in this paper can alleviate the communication frequency between the actuator and controller. Based on the reinforcement learning strategy, actor–critic neural networks are employed to implement the n-order backstepping framework. Then, a neural network weight-updated algorithm is developed to minimize the computational burden and avoid the local optimal problem. Furthermore, a novel dynamic-event-triggered strategy is introduced, which can remarkably outperform the previously studied static-event-triggered strategy. Moreover, combined with the Lyapunov stability theory , all signals in the closed-loop system are strictly proven to be semiglobal uniformly ultimately bounded. Finally, the practicality of the offered control algorithms is further elucidated by the numerical simulation examples.},
  archive      = {J_NN},
  author       = {Zichen Wang and Xin Wang and Ning Pang},
  doi          = {10.1016/j.neunet.2023.04.008},
  journal      = {Neural Networks},
  pages        = {341-353},
  shortjournal = {Neural Netw.},
  title        = {Dynamic event-triggered controller design for nonlinear systems: Reinforcement learning strategy},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning task-agnostic and interpretable subsequence-based
representation of time series and its applications in fMRI analysis.
<em>NN</em>, <em>163</em>, 327–340. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent success of sequential learning models, such as deep recurrent neural networks , is largely due to their superior representation-learning capability for learning the informative representation of a targeted time series. The learning of these representations is generally goal-directed, resulting in their task-specific nature, giving rise to excellent performance in completing a single downstream task but hindering between-task generalisation. Meanwhile, with increasingly intricate sequential learning models, learned representation becomes abstract to human knowledge and comprehension. Hence, we propose a unified local predictive model based on the multi-task learning paradigm to learn the task-agnostic and interpretable subsequence-based time series representation, allowing versatile use of learned representations in temporal prediction, smoothing, and classification tasks . The targeted interpretable representation could convey the spectral information of the modelled time series to the level of human comprehension. Through a proof-of-concept evaluation study, we demonstrate the empirical superiority of learned task-agnostic and interpretable representation over task-specific and conventional subsequence-based representation, such as symbolic and recurrent learning-based representation, in solving temporal prediction, smoothing, and classification tasks. These learned task-agnostic representations can also reveal the ground-truth periodicity of the modelled time series. We further propose two applications of our unified local predictive model in functional magnetic resonance imaging (fMRI) analysis to reveal the spectral characterisation of cortical areas at rest and reconstruct more smoothed temporal dynamics of cortical activations in both resting-state and task-evoked fMRI data, giving rise to robust decoding.},
  archive      = {J_NN},
  author       = {Wenjun Bai and Okito Yamashita and Junichiro Yoshimoto},
  doi          = {10.1016/j.neunet.2023.03.038},
  journal      = {Neural Networks},
  pages        = {327-340},
  shortjournal = {Neural Netw.},
  title        = {Learning task-agnostic and interpretable subsequence-based representation of time series and its applications in fMRI analysis},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resilient fixed-time stabilization of switched neural
networks subjected to impulsive deception attacks. <em>NN</em>,
<em>163</em>, 312–326. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the resilient fixed-time stabilization of switched neural networks (SNNs) under impulsive deception attacks. A novel theorem for the fixed-time stability of impulsive systems is established by virtue of the comparison principle. Existing fixed-time stability theorems for impulsive systems assume that the impulsive strength is not greater than 1, while the proposed theorem removes this assumption. SNNs subjected to impulsive deception attacks are modeled as impulsive systems. Some sufficient criteria are derived to ensure the stabilization of SNNs in fixed time. The estimation of the upper bound for the settling time is also given. The influence of impulsive attacks on the convergence time is discussed. A numerical example and an application to Chua’s circuit system are given to demonstrate the effectiveness of the theoretical results.},
  archive      = {J_NN},
  author       = {Yuangui Bao and Yijun Zhang and Baoyong Zhang},
  doi          = {10.1016/j.neunet.2023.04.003},
  journal      = {Neural Networks},
  pages        = {312-326},
  shortjournal = {Neural Netw.},
  title        = {Resilient fixed-time stabilization of switched neural networks subjected to impulsive deception attacks},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning long-term motor timing/patterns on an orthogonal
basis in random neural networks. <em>NN</em>, <em>163</em>, 298–311. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of the brain to generate complex spatiotemporal patterns with specific timings is essential for motor learning and temporal processing. An approach that can model this function, using the spontaneous activity of a random neural network (RNN), is associated with orbital instability. We propose a simple system that learns an arbitrary time series as the linear sum of stable trajectories produced by several small network modules. New finding in computer experiments is that the trajectories of the module outputs are orthogonal to each other. They created a dynamic orthogonal basis acquiring a high representational capacity , which enabled the system to learn the timing of extremely long intervals, such as tens of seconds for a millisecond computation unit, and also the complex time series of Lorenz attractors. This self-sustained system satisfies the stability and orthogonality requirements and thus provides a new neurocomputing framework and perspective for the neural mechanisms of motor learning.},
  archive      = {J_NN},
  author       = {Yuji Kawai and Jihoon Park and Ichiro Tsuda and Minoru Asada},
  doi          = {10.1016/j.neunet.2023.04.006},
  journal      = {Neural Networks},
  pages        = {298-311},
  shortjournal = {Neural Netw.},
  title        = {Learning long-term motor timing/patterns on an orthogonal basis in random neural networks},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust fall detection in video surveillance based on weakly
supervised learning. <em>NN</em>, <em>163</em>, 286–297. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall event detection has been a research hotspot in recent years in the fields of medicine and health. Currently, vision-based fall detection methods have been considered the most promising methods due to their advantages of a non-contact characteristic and easy deployment. However, the existing vision-based fall detection methods mainly use supervised learning in model training and require much time and energy for data annotations. To address these limitations, this work proposes a detection method that uses a weakly supervised learning-based dual-modal network. The proposed method adopts a deep multiple instance learning framework to learn the fall events using weak labels. As a result, the proposed method does not require time-consuming fine-grained annotations. The final detection result of each video is obtained by integrating the information obtained from two streams of the dual-modal network using the proposed dual-modal fusion strategy. Experimental results on two public benchmark datasets and a proposed dataset demonstrate the superiority of the proposed method over the current state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Lian Wu and Chao Huang and Shuping Zhao and Jinkai Li and Jianchuan Zhao and Zhongwei Cui and Zhen Yu and Yong Xu and Min Zhang},
  doi          = {10.1016/j.neunet.2023.03.042},
  journal      = {Neural Networks},
  pages        = {286-297},
  shortjournal = {Neural Netw.},
  title        = {Robust fall detection in video surveillance based on weakly supervised learning},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Functional connectivity learning via siamese-based SPD
matrix representation of brain imaging data. <em>NN</em>, <em>163</em>,
272–285. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement of brain functional connectivity has become a dominant approach to explore the interaction dynamics between brain regions of subjects under examination. Conventional functional connectivity measures largely originate from deterministic models on empirical analysis, usually demanding application-specific settings (e.g., Pearson’s Correlation and Mutual Information). To bridge the technical gap, this study proposes a Siamese-based Symmetric Positive Definite (SPD) Matrix Representation framework ( SiameseSPD-MR ) to derive the functional connectivity of brain imaging data (BID) such as Electroencephalography (EEG), thus the alternative application-independent measure (in the form of SPD matrix) can be automatically learnt: (1) SiameseSPD-MR first exploits graph convolution to extract the representative features of BID with the adjacency matrix computed considering the anatomical structure; (2) Adaptive Gaussian kernel function then applies to obtain the functional connectivity representations from the deep features followed by SPD matrix transformation to address the intrinsic functional characteristics; and (3) Two-branch (Siamese) networks are combined via an element-wise product followed by a dense layer to derive the similarity between the pairwise inputs. Experimental results on two EEG datasets (autism spectrum disorder, emotion) indicate that (1) SiameseSPD-MR can capture more significant differences in functional connectivity between neural states than the state-of-the-art counterparts do, and these findings properly highlight the typical EEG characteristics of ASD subjects, and (2) the obtained functional connectivity representations conforming to the proposed measure can act as meaningful markers for brain network analysis and ASD discrimination.},
  archive      = {J_NN},
  author       = {Yunbo Tang and Dan Chen and Jia Wu and Weiping Tu and Jessica J.M. Monaghan and Paul Sowman and David Mcalpine},
  doi          = {10.1016/j.neunet.2023.04.004},
  journal      = {Neural Networks},
  pages        = {272-285},
  shortjournal = {Neural Netw.},
  title        = {Functional connectivity learning via siamese-based SPD matrix representation of brain imaging data},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differential evolution based dual adversarial camouflage:
Fooling human eyes and object detectors. <em>NN</em>, <em>163</em>,
256–271. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network-based object detectors are vulnerable to adversarial examples . Among existing works to fool object detectors, the camouflage-based method is more often adopted due to its adaptation to multi-view scenarios and non-planar objects. However, most of them can still be easily observed by human eyes, which limits their application in the real world. To fool human eyes and object detectors simultaneously, we propose a differential evolution based dual adversarial camouflage method. Specifically, we try to obtain the camouflage texture by the two-stage training, which can be wrapped over the surface of the object. In the first stage, we optimize the global texture to minimize the discrepancy between the rendered object and the scene background, making human eyes difficult to distinguish. In the second stage, we design three loss functions to optimize the local texture, which is selected from the global texture, making object detectors ineffective. In addition, we introduce the differential evolution algorithm to search for the near-optimal areas of the object to attack, improving the adversarial performance under certain attack area limitations. Experimental results show that our proposed method can obtain a good trade-off between fooling human eyes and object detectors under multiple specific scenes and objects.},
  archive      = {J_NN},
  author       = {Jialiang Sun and Wen Yao and Tingsong Jiang and Donghua Wang and Xiaoqian Chen},
  doi          = {10.1016/j.neunet.2023.03.041},
  journal      = {Neural Networks},
  pages        = {256-271},
  shortjournal = {Neural Netw.},
  title        = {Differential evolution based dual adversarial camouflage: Fooling human eyes and object detectors},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the value of label and semantic information in domain
generalization. <em>NN</em>, <em>163</em>, 244–255. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we tackle the domain generalization (DG) problem aiming to learn a universal predictor on several source domains and deploy it on an unseen target domain. Many existing DG approaches were mainly motivated by domain adaptation techniques to align the marginal feature distribution but ignored conditional relations and labeling information in the source domains, which are critical to ensure successful knowledge transfer. Although some recent advances started to take advantage of conditional semantic distributions, theoretical justifications were still missing. To this end, we investigate the theoretical guarantee for a successful generalization process by focusing on how to control the target domain error. Our results reveal that to control the target risk, one should jointly control the source errors that are weighted according to label information and align the semantic conditional distributions between different source domains. The theoretical analysis then leads to an efficient algorithm to control the label distributions as well as match the semantic conditional distributions . To verify the effectiveness of our method, we evaluate it against recent baseline algorithms on several benchmarks. We also conducted experiments to verify the performance under label distribution shift to demonstrate the necessity of leveraging the labeling and semantic information. Empirical results show that the proposed method outperforms most of the baseline methods and shows state-of-the-art performances.},
  archive      = {J_NN},
  author       = {Fan Zhou and Yuyi Chen and Shichun Yang and Boyu Wang and Brahim Chaib-draa},
  doi          = {10.1016/j.neunet.2023.03.023},
  journal      = {Neural Networks},
  pages        = {244-255},
  shortjournal = {Neural Netw.},
  title        = {On the value of label and semantic information in domain generalization},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incomplete multi-view clustering network via nonlinear
manifold embedding and probability-induced loss. <em>NN</em>,
<em>163</em>, 233–243. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering, which included missing data in different views, is more challenging than multi-view clustering. For the purpose of eliminating the negative influence of incomplete data, researchers have proposed a series of solutions. However, the present incomplete multi-view clustering methods still confront three major issues: (1) The interference of redundant features hinders these methods to learn the most discriminative features . (2) The importance role of local structure is not considered during clustering. (3) These methods fail to utilize data distribution information to guide models update to decrease the effects of outliers and noise. To address above issues, a novel deep clustering network which exerted on incomplete multi-view data was proposed in this paper. We combine multi-view autoencoders with nonlinear manifold embedding method UMAP to extract latent consistent features of incomplete multi-view data. In the clustering method , we introduce Gaussian Mixture Model (GMM) to fit the complex distribution of data and deal with the interference of outliers. In addition, we reasonably utilize the probability distribution information generated by GMM, using probability-induced loss function to integrate feature learning and clustering as a joint framework. In experiments conducted on multiple benchmark datasets, our method captures incomplete multi-view data features effectively and perform excellent.},
  archive      = {J_NN},
  author       = {Cheng Huang and Jinrong Cui and Yulu Fu and Dong Huang and Min Zhao and Lusi Li},
  doi          = {10.1016/j.neunet.2023.03.013},
  journal      = {Neural Networks},
  pages        = {233-243},
  shortjournal = {Neural Netw.},
  title        = {Incomplete multi-view clustering network via nonlinear manifold embedding and probability-induced loss},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust data hiding for JPEG images with invertible neural
network. <em>NN</em>, <em>163</em>, 219–232. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {JPEG compression will cause severe distortion to the shared compressed image, which brings great challenges to extracting messages correctly from the stego image . To address such challenges, we propose a novel end-to-end robust data hiding scheme for JPEG images. The embedding and extracting secret messages on the quantized discrete cosine transform (DCT) coefficients are implemented by the bi-directional process of the invertible neural network (INN), which can provide intrinsic robustness against lossy JPEG compression. We design a JPEG compression attack module to simulate the JPEG compression process , which helps the network automatically learn how to recover the secret message from JPEG compressed image. Experimental results have demonstrated that our method achieves strong robustness against lossy JPEG compression, and also significantly improves the security compared with the existing data hiding methods on the premise of ensuring image quality and high capacity. For example, the detection error of our method against XuNet has been increased by 3.45\% over the existing data hiding methods.},
  archive      = {J_NN},
  author       = {Fei Shang and Yuhang Lan and Jianhua Yang and Enping Li and Xiangui Kang},
  doi          = {10.1016/j.neunet.2023.03.037},
  journal      = {Neural Networks},
  pages        = {219-232},
  shortjournal = {Neural Netw.},
  title        = {Robust data hiding for JPEG images with invertible neural network},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative-guided spectral abundance learning with
bilinear mixing model for hyperspectral subpixel target detection.
<em>NN</em>, <em>163</em>, 205–218. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting subpixel targets is a considerably challenging issue in hyperspectral image processing and interpretation. Most of the existing hyperspectral subpixel target detection methods construct detectors based on the linear mixing model which regards a pixel as a linear combination of different spectral signatures . However, due to the multiple scattering, the linear mixing model cannot​ illustrate the multiple materials interactions that are nonlinear and widespread in real-world hyperspectral images , which could result in unsatisfactory performance in detecting subpixel targets. To alleviate this problem, this work presents a novel collaborative-guided spectral abundance learning model (denoted as CGSAL) for subpixel target detection based on the bilinear mixing model in hyperspectral images . The proposed CGSAL detects subpixel targets by learning a spectral abundance of the target signature in each pixel. In CGSAL, virtual endmembers and their abundance help to achieve good accuracy for modeling nonlinear scattering accounts for multiple materials interactions according to the bilinear mixing model. Besides, we impose a collaborative term to the spectral abundance learning model to emphasize the collaborative relationships between different endmembers , which contributes to accurate spectral abundance learning and further help to detect subpixel targets. Plentiful experiments and analyses are conducted on three real-world and one synthetic hyperspectral datasets to evaluate the effectiveness of the CGSAL in subpixel target detection. The experiment results demonstrate that the CGSAL achieves competitive performance in detecting subpixel targets and outperforms other state-of-the-art hyperspectral subpixel target detectors.},
  archive      = {J_NN},
  author       = {Dehui Zhu and Bo Du and Meiqi Hu and Yanni Dong and Liangpei Zhang},
  doi          = {10.1016/j.neunet.2023.02.002},
  journal      = {Neural Networks},
  pages        = {205-218},
  shortjournal = {Neural Netw.},
  title        = {Collaborative-guided spectral abundance learning with bilinear mixing model for hyperspectral subpixel target detection},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A novel semi-supervised meta learning method for
subject-transfer brain–computer interface. <em>NN</em>, <em>163</em>,
195–204. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain–computer interface (BCI) provides a direct communication pathway between the human brain and external devices. However, the models trained for existing subjects perform poorly on new subjects, which is termed the subject calibration problem. In this paper, we propose a semi-supervised meta learning (SSML) method for subject-transfer calibration. The proposed SSML learns a model-agnostic meta learner with existing subjects and then fine-tunes the meta learner in a semi-supervised learning manner, i.e. using a few labelled samples and many unlabelled samples of the target subject for calibration. It is significant for BCI applications in which labelled data are scarce or expensive while unlabelled data are readily available. Three different BCI paradigms are tested: event-related potential detection, emotion recognition and sleep staging. The SSML achieved classification accuracies of 0.95, 0.89 and 0.83 in the benchmark datasets of three paradigms. The runtime complexity of SSML grows linearly as the number of samples of target subject increases so that is possible to apply it in real-time systems. This study is the first attempt to apply semi-supervised model-agnostic meta learning methodology for subject calibration. The experimental results demonstrated the effectiveness and potential of the SSML method for subject-transfer BCI applications.},
  archive      = {J_NN},
  author       = {Jingcong Li and Fei Wang and Haiyun Huang and Feifei Qi and Jiahui Pan},
  doi          = {10.1016/j.neunet.2023.03.039},
  journal      = {Neural Networks},
  pages        = {195-204},
  shortjournal = {Neural Netw.},
  title        = {A novel semi-supervised meta learning method for subject-transfer brain–computer interface},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Amortized bayesian inference on generative dynamical network
models of epilepsy using deep neural density estimators. <em>NN</em>,
<em>163</em>, 178–194. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whole-brain modeling of epilepsy combines personalized anatomical data with dynamical models of abnormal activities to generate spatio-temporal seizure patterns as observed in brain imaging data. Such a parametric simulator is equipped with a stochastic generative process , which itself provides the basis for inference and prediction of the local and global brain dynamics affected by disorders. However, the calculation of likelihood function at whole-brain scale is often intractable. Thus, likelihood-free algorithms are required to efficiently estimate the parameters pertaining to the hypothetical areas, ideally including the uncertainty. In this study, we introduce the simulation-based inference for the virtual epileptic patient model (SBI-VEP), enabling us to amortize the approximate posterior of the generative process from a low-dimensional representation of whole-brain epileptic patterns. The state-of-the-art deep learning algorithms for conditional density estimation are used to readily retrieve the statistical relationships between parameters and observations through a sequence of invertible transformations . We show that the SBI-VEP is able to efficiently estimate the posterior distribution of parameters linked to the extent of the epileptogenic and propagation zones from sparse intracranial electroencephalography recordings. The presented Bayesian methodology can deal with non-linear latent dynamics and parameter degeneracy, paving the way for fast and reliable inference on brain disorders from neuroimaging modalities.},
  archive      = {J_NN},
  author       = {Meysam Hashemi and Anirudh N. Vattikonda and Jayant Jha and Viktor Sip and Marmaduke M. Woodman and Fabrice Bartolomei and Viktor K. Jirsa},
  doi          = {10.1016/j.neunet.2023.03.040},
  journal      = {Neural Networks},
  pages        = {178-194},
  shortjournal = {Neural Netw.},
  title        = {Amortized bayesian inference on generative dynamical network models of epilepsy using deep neural density estimators},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifelong learning with shared and private latent
representations learned through synaptic intelligence. <em>NN</em>,
<em>163</em>, 165–177. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a novel lifelong learning method with Shared and Private Latent Representations (SPLR), which are learned through synaptic intelligence. To solve a sequence of tasks, by considering the entire parameter learning trajectory , SPLR can learn task-invariant representation which changes little, and task-specific features that change greatly along the entire parameter updating trajectory. Therefore, in the lifelong learning scenarios, our model can obtain a task-invariant structure shared by all tasks and also contain some private properties that are task-specific to each task. To reduce the parameter quantity, a ℓ 1 ℓ1 regularization to promote sparsity is employed in the weights. We use multiple datasets under lifelong learning scenes to verify our SPLR, on these datasets it can get comparable performance compared with existing lifelong learning approaches, and learn a sparse network which means fewer parameters while requiring less model training time.},
  archive      = {J_NN},
  author       = {Yang Yang and Jie Huang and Dexiu Hu},
  doi          = {10.1016/j.neunet.2023.04.005},
  journal      = {Neural Networks},
  pages        = {165-177},
  shortjournal = {Neural Netw.},
  title        = {Lifelong learning with shared and private latent representations learned through synaptic intelligence},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph contrastive learning with implicit augmentations.
<em>NN</em>, <em>163</em>, 156–164. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing graph contrastive learning methods rely on augmentation techniques based on random perturbations (e.g., randomly adding or dropping edges and nodes). Nevertheless, altering certain edges or nodes can unexpectedly change the graph characteristics, and choosing the optimal perturbing ratio for each dataset requires onerous manual tuning. In this paper, we introduce Implicit Graph Contrastive Learning (iGCL), which utilizes augmentations in the latent space learned from a Variational Graph Auto-Encoder by reconstructing graph topological structure . Importantly, instead of explicitly sampling augmentations from latent distributions, we further propose an upper bound for the expected contrastive loss to improve the efficiency of our learning algorithm. Thus, graph semantics can be preserved within the augmentations in an intelligent way without arbitrary manual design or prior human knowledge. Experimental results on both graph-level and node-level show that the proposed method achieves state-of-the-art accuracy on downstream classification tasks compared to other graph contrastive baselines, where ablation studies in the end demonstrate the effectiveness of modules in iGCL.},
  archive      = {J_NN},
  author       = {Huidong Liang and Xingjian Du and Bilei Zhu and Zejun Ma and Ke Chen and Junbin Gao},
  doi          = {10.1016/j.neunet.2023.04.001},
  journal      = {Neural Networks},
  pages        = {156-164},
  shortjournal = {Neural Netw.},
  title        = {Graph contrastive learning with implicit augmentations},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online continual learning with declarative memory.
<em>NN</em>, <em>163</em>, 146–155. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are enjoying unprecedented attention and success in recent years. However, catastrophic forgetting undermines the performance of deep models when the training data are arrived sequentially in an online multi-task learning fashion. To address this issue, we propose a novel method named continual learning with declarative memory (CLDM) in this paper. Specifically, our idea is inspired by the structure of human memory. Declarative memory is a major component of long-term memory which helps human beings memorize past experiences and facts. In this paper, we propose to formulate declarative memory as task memory and instance memory in neural networks to overcome catastrophic forgetting. Intuitively, the instance memory recalls the input–output relations (fact) in previous tasks, which is implemented by jointly rehearsing previous samples and learning current tasks as replaying-based methods act. In addition, the task memory aims to capture long-term task correlation information across task sequences to regularize the learning of the current task, thus preserving task-specific weight realizations (experience) in high task-specific layers. In this work, we implement a concrete instantiation of the proposed task memory by leveraging a recurrent unit. Extensive experiments on seven continual learning benchmarks verify that our proposed method is able to outperform previous approaches with tremendous improvements by retaining the information of both samples and tasks.},
  archive      = {J_NN},
  author       = {Zhe Xiao and Zhekai Du and Ruijin Wang and Ruimeng Gan and Jingjing Li},
  doi          = {10.1016/j.neunet.2023.03.025},
  journal      = {Neural Networks},
  pages        = {146-155},
  shortjournal = {Neural Netw.},
  title        = {Online continual learning with declarative memory},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot remote sensing image scene classification based on
multiscale covariance metric network (MCMNet). <em>NN</em>,
<em>163</em>, 132–145. (<a
href="https://doi.org/10.1016/j.neunet.2023.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) is a paradigm that simulates the fast learning ability of human beings, which can learn the feature differences between two groups of small-scale samples with common label space, and the label space of the training set and the test set is not repeated. By this way, it can quickly identify the categories of the unseen image in the test set. This method is widely used in image scene recognition, and it is expected to overcome difficulties of scarce annotated samples in remote sensing (RS). However, among most existing FSL methods, images were embed into Euclidean space , and the similarity between features at the last layer of deep network were measured by Euclidean distance . It is difficult to measure the inter-class similarity and intra-class difference of RS images . In this paper, we propose a multi-scale covariance network (MCMNet) for the application of remote sensing scene classification (RSSC). Taking Conv64F as the backbone, we mapped the features of the 1, 2, and 4 layers of the network to the manifold space by constructing a regional covariance matrix to form a covariance network with different scales. For each layer of features, we introduce the center in manifold space as a prototype for different categories of features. We simultaneously measure the similarity of three prototypes on the manifold space with different scales to form three loss functions and optimize the whole network by episodic training strategy. We conducted comparative experiments on three public datasets. The results show that the classification accuracy (CA) of our proposed method is from 1.35\% to 2.36\% higher than that of the most excellent method, which demonstrates that the performance of MCMNet outperforms other methods.},
  archive      = {J_NN},
  author       = {Xiliang Chen and Guobin Zhu and Mingqing Liu and Zhaotong Chen},
  doi          = {10.1016/j.neunet.2023.04.002},
  journal      = {Neural Networks},
  pages        = {132-145},
  shortjournal = {Neural Netw.},
  title        = {Few-shot remote sensing image scene classification based on multiscale covariance metric network (MCMNet)},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot molecular property prediction via hierarchically
structured learning on relation graphs. <em>NN</em>, <em>163</em>,
122–131. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies few-shot molecular property prediction, which is a fundamental problem in cheminformatics and drug discovery. More recently, graph neural network based model has gradually become the theme of molecular property prediction. However, there is a natural deficiency for existing methods, that is, the scarcity of molecules with desired properties, which makes it hard to build an effective predictive model. In this paper, we propose a novel framework called Hierarchically Structured Learning on Relation Graphs (HSL-RG) for molecular property prediction, which explores the structural semantics of a molecule from both global-level and local-level granularities. Technically, we first leverage graph kernels to construct relation graphs to globally communicate molecular structural knowledge from neighboring molecules and then design self-supervised learning signals of structure optimization to locally learn transformation-invariant representations from molecules themselves. Moreover, we propose a task-adaptive meta-learning algorithm to provide meta knowledge customization for different tasks in few-shot scenarios. Experiments on multiple real-life benchmark datasets show that HSL-RG is superior to existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Wei Ju and Zequn Liu and Yifang Qin and Bin Feng and Chen Wang and Zhihui Guo and Xiao Luo and Ming Zhang},
  doi          = {10.1016/j.neunet.2023.03.034},
  journal      = {Neural Networks},
  pages        = {122-131},
  shortjournal = {Neural Netw.},
  title        = {Few-shot molecular property prediction via hierarchically structured learning on relation graphs},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An octonion-based nonlinear echo state network for speech
emotion recognition in metaverse. <em>NN</em>, <em>163</em>, 108–121.
(<a href="https://doi.org/10.1016/j.neunet.2023.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the Metaverse is becoming a popular trend and drawing much attention from academia, society, and businesses, processing cores used in its infrastructures need to be improved, particularly in terms of signal processing and pattern recognition. Accordingly, the speech emotion recognition (SER) method plays a crucial role in creating the Metaverse platforms more usable​ and enjoyable for its users. However, existing SER methods continue to be plagued by two significant problems in the online environment. The shortage of adequate engagement and customization between avatars and users is recognized as the first issue and the second problem is related to the complexity of SER problems in the Metaverse as we face people and their digital twins or avatars. This is why developing efficient machine learning (ML) techniques specified for hypercomplex signal processing is essential to enhance the impressiveness and tangibility of the Metaverse platforms. As a solution, echo state networks (ESNs), which are an ML powerful tool for SER, can be an appropriate technique to enhance the Metaverse’s foundations in this area. Nevertheless, ESNs have some technical issues restricting them from a precise and reliable analysis, especially in the aspect of high-dimensional data. The most significant limitation of these networks is the high memory consumption caused by their reservoir structure in face of high-dimensional signals. To solve all problems associated with ESNs and their application in the Metaverse, we have come up with a novel structure for ESNs empowered by octonion algebra called NO2GESNet. Octonion numbers have eight dimensions, compactly display high-dimensional data, and improve the network precision and performance in comparison to conventional ESNs. The proposed network also solves the weaknesses of the ESNs in the presentation of the higher-order statistics to the output layer by equipping it with a multidimensional bilinear filter. Three comprehensive scenarios to use the proposed network in the Metaverse have been designed and analyzed, not only do they show the accuracy and performance of the proposed approach, but also the ways how SER can be employed in the Metaverse platforms.},
  archive      = {J_NN},
  author       = {Fatemeh Daneshfar and Mohammad (Behdad) Jamshidi},
  doi          = {10.1016/j.neunet.2023.03.026},
  journal      = {Neural Networks},
  pages        = {108-121},
  shortjournal = {Neural Netw.},
  title        = {An octonion-based nonlinear echo state network for speech emotion recognition in metaverse},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explainable artificial intelligence approach to spatial
navigation based on hippocampal circuitry. <em>NN</em>, <em>163</em>,
97–107. (<a href="https://doi.org/10.1016/j.neunet.2023.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to navigate a complex environment is not a difficult task for a mammal. For example, finding the correct way to exit a maze following a sequence of cues, does not need a long training session. Just a single or a few runs through a new environment is, in most cases, sufficient to learn an exit path starting from anywhere in the maze. This ability is in striking contrast with the well-known difficulty that any deep learning algorithm has in learning a trajectory through a sequence of objects. Being able to learn an arbitrarily long sequence of objects to reach a specific place could take, in general, prohibitively long training sessions. This is a clear indication that current artificial intelligence methods are essentially unable to capture the way in which a real brain implements a cognitive function. In previous work, we have proposed a proof-of-principle model demonstrating how, using hippocampal circuitry, it is possible to learn an arbitrary sequence of known objects in a single trial. We called this model SLT (Single Learning Trial). In the current work, we extend this model, which we will call e-STL, to introduce the capability of navigating a classic four-arms maze to learn, in a single trial, the correct path to reach an exit ignoring dead ends. We show the conditions under which the e-SLT network, including cells coding for places, head-direction, and objects, can robustly and efficiently implement a fundamental cognitive function. The results shed light on the possible circuit organization and operation of the hippocampus and may represent the building block of a new generation of artificial intelligence algorithms for spatial navigation.},
  archive      = {J_NN},
  author       = {Simone Coppolino and Michele Migliore},
  doi          = {10.1016/j.neunet.2023.03.030},
  journal      = {Neural Networks},
  pages        = {97-107},
  shortjournal = {Neural Netw.},
  title        = {An explainable artificial intelligence approach to spatial navigation based on hippocampal circuitry},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta attention for off-policy actor-critic. <em>NN</em>,
<em>163</em>, 86–96. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Off-Policy Actor-Critic methods can effectively exploit past experiences and thus they have achieved great success in various reinforcement learning tasks. In many image-based and multi-agent tasks, attention mechanism has been employed in Actor-Critic methods to improve their sampling efficiency. In this paper, we propose a meta attention method for state-based reinforcement learning tasks, which combines attention mechanism and meta-learning based on the Off-Policy Actor-Critic framework. Unlike previous attention-based work, our meta attention method introduces attention in the Actor and the Critic of the typical Actor-Critic framework, rather than in multiple pixels of an image or multiple information sources in specific image-based control tasks or multi-agent systems. In contrast to existing meta-learning methods, the proposed meta-attention approach is able to function in both the gradient-based training phase and the agent’s decision-making process. The experimental results demonstrate the superiority of our meta-attention method in various continuous control tasks, which are based on the Off-Policy Actor-Critic methods including DDPG and TD3.},
  archive      = {J_NN},
  author       = {Jiateng Huang and Wanrong Huang and Long Lan and Dan Wu},
  doi          = {10.1016/j.neunet.2023.03.024},
  journal      = {Neural Networks},
  pages        = {86-96},
  shortjournal = {Neural Netw.},
  title        = {Meta attention for off-policy actor-critic},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time synchronization of delayed memristive neural
networks with impulsive effects via novel fixed-time stability theorem.
<em>NN</em>, <em>163</em>, 75–85. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the fixed-time synchronization (FXTS) of delayed memristive neural networks (MNNs) with hybrid impulsive effects is explored. To investigate the FXTS mechanism , we first propose a novel theorem about the fixed-time stability (FTS) of impulsive dynamical systems , where the coefficients are extended to functions and the derivatives of Lyapunov function (LF) are allowed to be indefinite. After that, we obtain some new sufficient conditions for achieving FXTS of the system within a settling-time using three different controllers. At last, to verify the correctness and effectiveness of our results, a numerical simulation was conducted. Significantly, the impulse strength studied in this paper can take different values at different points, so it can be regarded as a time-varying function, unlike those in previous studies (the impulse strength takes the same value at different points). Hence, the mechanisms in this article are of more practical applicability.},
  archive      = {J_NN},
  author       = {Dongshu Wang and Luke Li},
  doi          = {10.1016/j.neunet.2023.03.036},
  journal      = {Neural Networks},
  pages        = {75-85},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time synchronization of delayed memristive neural networks with impulsive effects via novel fixed-time stability theorem},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DropAGG: Robust graph neural networks via drop aggregation.
<em>NN</em>, <em>163</em>, 65–74. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust learning on graph data is an active research problem in data mining field. Graph Neural Networks (GNNs) have gained great attention in graph data representation and learning tasks. The core of GNNs is the message propagation mechanism across node’s neighbors in GNNs’ layer-wise propagation. Existing GNNs generally adopt the deterministic message propagation mechanism which may (1) perform non-robustly w.r.t structural noises and adversarial attacks and (2) lead to over-smoothing issue. To alleviate these issues, this work rethinks dropout techniques in GNNs and proposes a novel random message propagation mechanism, named Drop Aggregation (DropAGG), for GNNs learning. The core of DropAGG is to randomly select a certain rate of nodes to participate in information aggregation. The proposed DropAGG is a general scheme which can incorporate any specific GNN model to enhance its robustness and mitigate the over-smoothing issue. Using DropAGG, we then design a novel Graph Random Aggregation Network (GRANet) for graph data robust learning. Extensive experiments on several benchmark datasets demonstrate the robustness of GRANet and effectiveness of DropAGG to mitigate the issue of over-smoothing.},
  archive      = {J_NN},
  author       = {Bo Jiang and Yong Chen and Beibei Wang and Haiyun Xu and Bin Luo},
  doi          = {10.1016/j.neunet.2023.03.022},
  journal      = {Neural Networks},
  pages        = {65-74},
  shortjournal = {Neural Netw.},
  title        = {DropAGG: Robust graph neural networks via drop aggregation},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum to “interfering with a memory without erasing
its trace” [neural networks 121 (2020) 339–355]. <em>NN</em>,
<em>163</em>, 64. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Gesa Lange and Mario Senden and Alexandra Radermacher and Peter De Weerd},
  doi          = {10.1016/j.neunet.2023.03.027},
  journal      = {Neural Networks},
  pages        = {64},
  shortjournal = {Neural Netw.},
  title        = {Corrigendum to “Interfering with a memory without erasing its trace” [Neural networks 121 (2020) 339–355]},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed/prescribed-time synchronization of BAM memristive
neural networks with time-varying delays via convex analysis.
<em>NN</em>, <em>163</em>, 53–63. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synchronization problem of bidirectional associative memory memristive neural networks (BAMMNNs) with time-varying delays plays an essential role in the implementation and application of neural networks . Firstly, under the framework of the Filippov’s solution, the discontinuous parameters of the state-dependent switching are transformed by convex analysis method, which is different from most previous approaches. Secondly, based on Lyapunov function and some inequality techniques, several conditions for the fixed-time synchronization (FXTS) of the drive-response systems are obtained by designing special control strategies. Moreover, the settling time (ST) is estimated by the improved fixed-time stability lemma. Thirdly, the driven-response BAMMNNs are investigated to be synchronized within a prescribed time by designing new controllers based on the FXTS results, where ST is irrelevant to the initial values of BAMMNNs and the parameters of controllers. Finally, a numerical simulation is exhibited to verify the correctness of the conclusions.},
  archive      = {J_NN},
  author       = {Jinrong Yang and Guici Chen and Song Zhu and Shiping Wen and Junhao Hu},
  doi          = {10.1016/j.neunet.2023.03.031},
  journal      = {Neural Networks},
  pages        = {53-63},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of BAM memristive neural networks with time-varying delays via convex analysis},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized zero-shot domain adaptation via coupled
conditional variational autoencoders. <em>NN</em>, <em>163</em>, 40–52.
(<a href="https://doi.org/10.1016/j.neunet.2023.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation aims to exploit useful information from the source domain where annotated training data are easier to obtain to address a learning problem in the target domain where only limited or even no annotated data are available. In classification problems, domain adaptation has been studied under the assumption all classes are available in the target domain regardless of the annotations. However, a common situation where only a subset of classes in the target domain are available has not attracted much attention. In this paper, we formulate this particular domain adaptation problem within a generalized zero-shot learning framework by treating the labelled source-domain samples as semantic representations for zero-shot learning. For this novel problem, neither conventional domain adaptation approaches nor zero-shot learning algorithms directly apply. To solve this problem, we present a novel Coupled Conditional Variational Autoencoder (CCVAE) which can generate synthetic target-domain image features for unseen classes from real images in the source domain. Extensive experiments have been conducted on three domain adaptation datasets including a bespoke X-ray security checkpoint dataset to simulate a real-world application in aviation security. The results demonstrate the effectiveness of our proposed approach both against established benchmarks and in terms of real-world applicability.},
  archive      = {J_NN},
  author       = {Qian Wang and Toby P. Breckon},
  doi          = {10.1016/j.neunet.2023.03.033},
  journal      = {Neural Networks},
  pages        = {40-52},
  shortjournal = {Neural Netw.},
  title        = {Generalized zero-shot domain adaptation via coupled conditional variational autoencoders},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive fixed-time output synchronization for complex
dynamical networks with multi-weights. <em>NN</em>, <em>163</em>, 28–39.
(<a href="https://doi.org/10.1016/j.neunet.2023.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses fixed-time output synchronization problems for two types of complex dynamical networks with multi-weights (CDNMWs) by using two types of adaptive control methods. Firstly, complex dynamical networks with multiple state and output couplings are respectively presented. Secondly, several fixed-time output synchronization criteria for these two networks are formulated based on Lyapunov functional and inequality techniques. Thirdly, by employing two types of adaptive control methods, fixed-time output synchronization issues of these two networks are dealt with. At last, the analytical results are verified by two numerical simulations.},
  archive      = {J_NN},
  author       = {Yuting Cao and Linhao Zhao and Qishui Zhong and Shiping Wen and Kaibo Shi and Jianying Xiao and Tingwen Huang},
  doi          = {10.1016/j.neunet.2023.03.032},
  journal      = {Neural Networks},
  pages        = {28-39},
  shortjournal = {Neural Netw.},
  title        = {Adaptive fixed-time output synchronization for complex dynamical networks with multi-weights},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level feature interaction and efficient non-local
information enhanced channel attention for image dehazing. <em>NN</em>,
<em>163</em>, 10–27. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing is a challenging task in computer vision . Currently, most dehazing methods adopt the U-Net architecture that directly fuses the decoding layer with the corresponding scale encoding layer. These methods ignore the effective utilization of different encoding layer information and existing feature information dilute problems, resulting in suboptimal edge details and overall scene aspects of dehazed image restoration. In addition, Squeeze and Excitation (SE) channel attention is widely used in dehazing network. However, the two fully-connected layers of dimensionality reduction operation in SE will negatively affect the weight prediction of feature channels, thus reducing the performance of the dehazing network. To solve the above problems, we propose a Multi-level Feature Interaction and Non-local Information Enhanced Channel Attention (MFINEA) dehazing model. Specifically, a multi-level feature interaction module is proposed to enable the decoding layer to fuse shallow and deep feature information extracted from different encoding layers for better recovery of edge details and the overall scene. Furthermore, an efficient non-local information enhanced channel attention module is proposed to mine more effective feature channel information for the weight assignment of the feature maps. The experimental results on several challenging benchmark datasets show that our MFINEA outperforms the state-of-the-art dehazing methods.},
  archive      = {J_NN},
  author       = {Hang Sun and Bohui Li and Zhiping Dan and Wei Hu and Bo Du and Wen Yang and Jun Wan},
  doi          = {10.1016/j.neunet.2023.03.017},
  journal      = {Neural Networks},
  pages        = {10-27},
  shortjournal = {Neural Netw.},
  title        = {Multi-level feature interaction and efficient non-local information enhanced channel attention for image dehazing},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot human–object interaction video recognition with
transformers. <em>NN</em>, <em>163</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel few-shot learning framework that can recognize human–object interaction (HOI) classes with a few labeled samples. We achieve this by leveraging a meta-learning paradigm where human–object interactions are embedded into compact features for similarity calculation. More specifically, spatial and temporal relationships of HOI in videos are constructed with transformers which boost the performance over the baseline significantly. First, we present a spatial encoder that extracts the spatial context and infers frame-level features of a human and objects in each frame. And then the video-level feature is obtained by encoding a series of frame-level feature vectors with a temporal encoder. Experiments on two datasets, CAD-120 and Something-Else, validate that our approach achieves 7.8\% and 15.2\% accuracy improvement on 1-shot task, 4.7\% and 15.7\% on 5-shot task, which outperforms the state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Qiyue Li and Xuemei Xie and Jin Zhang and Guangming Shi},
  doi          = {10.1016/j.neunet.2023.01.019},
  journal      = {Neural Networks},
  pages        = {1-9},
  shortjournal = {Neural Netw.},
  title        = {Few-shot human–object interaction video recognition with transformers},
  volume       = {163},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>162</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(23)00199-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00199-5},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Current events. <em>NN</em>, <em>162</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(23)00198-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00198-3},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {Current events},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting the fragility of influence functions.
<em>NN</em>, <em>162</em>, 581–588. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, many works have tried to explain the predictions of deep learning models. Few methods, however, have been proposed to verify the accuracy or faithfulness of these explanations. Recently, influence functions, which is a method that approximates the effect that leave-one-out training has on the loss function, has been shown to be fragile. The proposed reason for their fragility remains unclear. Although previous work suggests the use of regularization to increase robustness, this does not hold in all cases. In this work, we seek to investigate the experiments performed in the prior work in an effort to understand the underlying mechanisms of influence function fragility. First, we verify influence functions using procedures from the literature under conditions where the convexity assumptions of influence functions are met. Then, we relax these assumptions and study the effects of non-convexity by using deeper models and more complex datasets. Here, we analyze the key metrics and procedures that are used to validate influence functions. Our results indicate that the validation procedures may cause the observed fragility.},
  archive      = {J_NN},
  author       = {Jacob R. Epifano and Ravi P. Ramachandran and Aaron J. Masino and Ghulam Rasool},
  doi          = {10.1016/j.neunet.2023.03.029},
  journal      = {Neural Networks},
  pages        = {581-588},
  shortjournal = {Neural Netw.},
  title        = {Revisiting the fragility of influence functions},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RAFNet: Restricted attention fusion network for sleep apnea
detection. <em>NN</em>, <em>162</em>, 571–580. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep apnea (SA) is a common sleep-related breathing disorder, which would lead to damage of multiple systemic organs or even sudden death. In clinical practice, portable device is an important tool to monitor sleep conditions and detect SA events by using physiological signals . However, SA detection performance is still limited due to physiological signals with time-variability and complexity. In this paper, we focus on SA detection with single lead ECG signals, which can be easily collected by a portable device. Under this context, we propose a restricted attention fusion network called RAFNet for sleep apnea detection. Specifically, RR intervals (RRI) and R-peak amplitudes (Rpeak) are generated from ECG signals and divided into one-minute-long segments. To alleviate the problem of insufficient feature information of the target segment, we combine the target segment with two pre- and post-adjacent segments in sequence, ( i.e. a five-minute-long segment), as the input. Meanwhile, by leveraging the target segment as the query vector, we propose a new restricted attention mechanism with cascaded morphological and temporal attentions, which can effectively learn the feature information and depress redundant feature information from the adjacent segments with adaptive assigning weight importance. To further improve the SA detection performance, the target and adjacent segment features are fused together with the channel-wise stacking scheme. Experiment results on the public Apnea-ECG dataset and the real clinical FAH-ECG dataset with sleep apnea annotations show that the RAFNet greatly improves SA detection performance and achieves competitive results, which are superior to those achieved by the state-of-the-art baselines.},
  archive      = {J_NN},
  author       = {Ying Chen and Huijun Yue and Ruifeng Zou and Wenbin Lei and Wenjun Ma and Xiaomao Fan},
  doi          = {10.1016/j.neunet.2023.03.019},
  journal      = {Neural Networks},
  pages        = {571-580},
  shortjournal = {Neural Netw.},
  title        = {RAFNet: Restricted attention fusion network for sleep apnea detection},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Restoration and enhancement on low exposure raw images by
joint demosaicing and denoising. <em>NN</em>, <em>162</em>, 557–570. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring high quality images from raw data in low light is challenging due to various noises caused by limited photon count and complicated Image Signal Process (ISP). Although several restoration and enhancement approaches are proposed, they may fail in extreme conditions, such as imaging short exposure raw data. The first path-breaking attempt is to utilize the connection between a pair of short and long exposure raw data and outputs RGB images as the final results. However, the whole pipeline still suffers from some blurs and color distortion. To overcome those difficulties, we propose an end-to-end network that contains two effective subnets to joint demosaic and denoise low exposure raw images. While traditional ISP are difficult to image them in acceptable conditions, the short exposure raw images can be better restored and enhanced by our model. For denoising , the proposed Short2Long raw restoration subnet outputs pseudo long exposure raw data with little noisy points. Then for demosaicing , the proposed Color consistent RGB enhancement subnet generates corresponding RGB images with the desired attributes: sharpness, color vividness, good contrast and little noise. By training the network in an end-to-end manner, our method avoids additional tuning by experts. We conduct experiments to reveal good results on three raw data datasets. We also illustrate the effectiveness of each module and the well generalization ability of this model.},
  archive      = {J_NN},
  author       = {Jiaqi Ma and Guoli Wang and Lefei Zhang and Qian Zhang},
  doi          = {10.1016/j.neunet.2023.03.018},
  journal      = {Neural Networks},
  pages        = {557-570},
  shortjournal = {Neural Netw.},
  title        = {Restoration and enhancement on low exposure raw images by joint demosaicing and denoising},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward a cerebello-thalamo-cortical computational model of
spinocerebellar ataxia. <em>NN</em>, <em>162</em>, 541–556. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational neural network modelling is an emerging approach for optimization of drug treatment of neurological disorders and fine-tuning of rehabilitation strategies. In the current study, we constructed a cerebello-thalamo-cortical computational neural network model to simulate a mouse model of cerebellar ataxia ( pcd 5J pcd5J mice) by manipulating cerebellar bursts through reduction of GABAergic inhibitory input. Cerebellar output neurons were projected to the thalamus and bidirectionally connected with the cortical network . Our results showed that reduction of inhibitory input in the cerebellum orchestrated the cortical local field potential (LFP) dynamics to generate specific motor outputs of oscillations of the theta, alpha, and beta bands in the computational model as well as in mouse motor cortical neurons . The therapeutic potential of deep brain stimulation (DBS) was tested in the computational model by increasing the sensory input to restore cortical output. Ataxia mice showed normalization of the motor cortex LFP after cerebellum DBS. We provide a novel approach to computational modelling to investigate the effect of DBS by mimicking cerebellar ataxia involving degeneration of Purkinje cells . Simulated neural activity coincides with findings from neural recordings of ataxia mice. Our computational model could thus represent cerebellar pathologies and provide insight into how to improve disease symptoms by restoring neuronal electrophysiological properties using DBS.},
  archive      = {J_NN},
  author       = {Gajendra Kumar and Chi Him Eddie Ma},
  doi          = {10.1016/j.neunet.2023.01.045},
  journal      = {Neural Networks},
  pages        = {541-556},
  shortjournal = {Neural Netw.},
  title        = {Toward a cerebello-thalamo-cortical computational model of spinocerebellar ataxia},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CHARLES: A c++ fixed-point library for photonic-aware neural
networks. <em>NN</em>, <em>162</em>, 531–540. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present CHARLES (C++ pHotonic Aware neuRaL nEtworkS), a C++ library aimed at providing a flexible tool to simulate the behavior of Photonic-Aware Neural Network (PANN). PANNs are neural network architectures aware of the constraints due to the underlying photonic hardware, mostly in terms of low equivalent precision of the computations. For this reason, CHARLES exploits fixed-point computations for inference, while it supports both floating-point and fixed-point numerical formats for training. In this way, we can compare the effects due to the quantization in the inference phase when the training phase is performed on a classical floating-point model and on a model exploiting high-precision fixed-point numbers. To validate CHARLES and identify the most suited numerical format for PANN training, we report the simulation results obtained considering three datasets: Iris, MNIST, and Fashion-MNIST. Fixed-training is shown to outperform floating-training when executing inference on bitwidths suitable for photonic implementation. Indeed, performing the training phase in the floating-point domain and then quantizing to lower bitwidths results in a very high accuracy loss. Instead, when fixed-point numbers are exploited in the training phase, the accuracy loss due to quantization to lower bitwidths is significantly reduced. In particular, we show that for Iris dataset, fixed-training achieves a performance similar to floating-training. Fixed-training allows to obtain an accuracy of 90.4\% and 68.1\% with the MNIST and Fashion-MNIST datasets using only 6 bits, while the floating-training reaches an accuracy of just 25.4\% and 50.0\% when exploiting the same bitwidths.},
  archive      = {J_NN},
  author       = {Emilio Paolini and Lorenzo De Marinis and Luca Maggiani and Marco Cococcioni and Nicola Andriolli},
  doi          = {10.1016/j.neunet.2023.03.007},
  journal      = {Neural Networks},
  pages        = {531-540},
  shortjournal = {Neural Netw.},
  title        = {CHARLES: A c++ fixed-point library for photonic-aware neural networks},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decoding self-motion from visual image sequence predicts
distinctive features of reflexive motor responses to visual motion.
<em>NN</em>, <em>162</em>, 516–530. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual motion analysis is crucial for humans to detect external moving objects and self-motion which are informative for planning and executing actions for various interactions with environments. Here we show that the image motion analysis trained to decode the self-motion during human natural movements by a convolutional neural network exhibits similar specificities with the reflexive ocular and manual responses induced by a large-field visual motion, in terms of stimulus spatiotemporal frequency tuning. The spatiotemporal frequency tuning of the decoder peaked at high-temporal and low-spatial frequencies, as observed in the reflexive ocular and manual responses, but differed significantly from the frequency power of the visual image itself and the density distribution of self-motion. Further, artificial manipulations of the learning data sets predicted great changes in the specificity of the spatiotemporal tuning. Interestingly, despite similar spatiotemporal frequency tunings in the vertical-axis rotational direction and in the transversal direction to full-field visual stimuli, the tunings for center-masked stimuli were different between those directions, and the specificity difference is qualitatively similar to the discrepancy between ocular and manual responses, respectively. In addition, the representational analysis demonstrated that head-axis rotation was decoded by relatively simple spatial accumulation over the visual field, while the transversal motion was decoded by more complex spatial interaction of visual information. These synthetic model examinations support the idea that visual motion analyses eliciting the reflexive motor responses, which are critical in interacting with the external world, are acquired for decoding self-motion.},
  archive      = {J_NN},
  author       = {Daiki Nakamura and Hiroaki Gomi},
  doi          = {10.1016/j.neunet.2023.03.020},
  journal      = {Neural Networks},
  pages        = {516-530},
  shortjournal = {Neural Netw.},
  title        = {Decoding self-motion from visual image sequence predicts distinctive features of reflexive motor responses to visual motion},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Miper-MVS: Multi-scale iterative probability estimation with
refinement for efficient multi-view stereo. <em>NN</em>, <em>162</em>,
502–515. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view stereo reconstruction aims to construct 3D scenes from multiple 2D images. In recent years, learning-based multi-view stereo methods have achieved significant results in depth estimation for multi-view stereo reconstruction. However, the current popular multi-stage processing method cannot solve the low-efficiency problem satisfactorily owing to the use of 3D convolution and still involves significant amounts of calculation. Therefore, to further balance the efficiency and generalization performance , this study proposed a multi-scale iterative probability estimation with refinement, which is a highly efficient method for multi-view stereo reconstruction. It comprises three main modules: 1) a high-precision probability estimator, dilated-LSTM that encodes the pixel probability distribution of depth in the hidden state, 2) an efficient interactive multi-scale update module that fully integrates multi-scale information and improves parallelism by interacting information between adjacent scales, and 3) a Pi-error Refinement module that converts the depth error between views into a grayscale error map and refines the edges of objects in the depth map . Simultaneously, we introduced a large amount of high-frequency information to ensure the accuracy of the refined edges. Among the most efficient methods (e.g., runtime and memory), the proposed method achieved the best generalization on the Tanks &amp; Temples benchmarks. Additionally, the performance of the Miper-MVS was highly competitive in DTU benchmark. Our code is available at https://github.com/zhz120/Miper-MVS .},
  archive      = {J_NN},
  author       = {Huizhou Zhou and Haoliang Zhao and Qi Wang and Gefei Hao and Liang Lei},
  doi          = {10.1016/j.neunet.2023.03.012},
  journal      = {Neural Networks},
  pages        = {502-515},
  shortjournal = {Neural Netw.},
  title        = {Miper-MVS: Multi-scale iterative probability estimation with refinement for efficient multi-view stereo},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved disturbance observer-based fixed-time adaptive
neural network consensus tracking for nonlinear multi-agent systems.
<em>NN</em>, <em>162</em>, 490–501. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the problem of fixed-time consensus tracking for a class of nonlinear multi-agent systems subject to unknown disturbances. Firstly, a modified fixed-time disturbance observer is devised to estimate the unknown mismatched disturbance. Secondly, a distributed fixed-time neural network control protocol is designed, in which neural network is employed to approximate the uncertain nonlinear function . Simultaneously, the technique of command filter is applied to fixed-time control, which circumvents the “explosion of complexity” problem. Under the proposed control strategy, all agents are enable to track the desired trajectory in fixed-time, and the consensus tracking error and disturbance estimation error converge to an arbitrarily small neighborhood of the origin, meanwhile, all signals in the closed-loop system remain bounded. Finally, a simulation example is provided to validate the effectiveness of the presented design method.},
  archive      = {J_NN},
  author       = {Na Zhang and Jianwei Xia and Ju H. Park and Jing Zhang and Hao Shen},
  doi          = {10.1016/j.neunet.2023.03.016},
  journal      = {Neural Networks},
  pages        = {490-501},
  shortjournal = {Neural Netw.},
  title        = {Improved disturbance observer-based fixed-time adaptive neural network consensus tracking for nonlinear multi-agent systems},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-accelerated computational framework based on
physics informed neural network for the solution of linear elasticity.
<em>NN</em>, <em>162</em>, 472–489. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents an efficient and robust data-driven deep learning (DL) computational framework developed for linear continuum elasticity problems . The methodology is based on the fundamentals of the Physics Informed Neural Networks (PINNs). For an accurate representation of the field variables, a multi-objective loss function is proposed. It consists of terms corresponding to the residual of the governing partial differential equations (PDE), constitutive relations derived from the governing physics, various boundary conditions, and data-driven physical knowledge fitting terms across randomly selected collocation points in the problem domain. To this end, multiple densely connected independent artificial neural networks (ANNs), each approximating a field variable, are trained to obtain accurate solutions. Several benchmark problems including the Airy solution to elasticity and the Kirchhoff–Love plate problem are solved. Performance in terms of accuracy and robustness illustrates the superiority of the current framework showing excellent agreement with analytical solutions. The present work combines the benefits of the classical methods depending on the physical information available in analytical relations with the superior capabilities of the DL techniques in the data-driven construction of lightweight, yet accurate and robust neural networks. The models developed herein can significantly boost computational speed using minimal network parameters with easy adaptability in different computational platforms.},
  archive      = {J_NN},
  author       = {Arunabha M. Roy and Rikhi Bose and Veera Sundararaghavan and Raymundo Arróyave},
  doi          = {10.1016/j.neunet.2023.03.014},
  journal      = {Neural Networks},
  pages        = {472-489},
  shortjournal = {Neural Netw.},
  title        = {Deep learning-accelerated computational framework based on physics informed neural network for the solution of linear elasticity},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty maximization in partially observable domains: A
cognitive perspective. <em>NN</em>, <em>162</em>, 456–471. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with an ever-increasing complexity of their domains of application, artificial learning agents are now able to scale up in their ability to process an overwhelming amount of data. However, this comes at the cost of encoding and processing an increasing amount of redundant information. This work exploits the possibility of learning systems, applied in partially observable domains, to selectively focus on the specific type of information that is more likely related to the causal interaction among transitioning states. A temporal difference displacement criterion is defined to implement adaptive masking of the observations. It can enable a significant improvement of convergence of temporal difference algorithms applied to partially observable Markov processes , as shown by experiments performed under a variety of machine learning problems, ranging from highly complex visuals as Atari games to simple textbook control problems such as CartPole. The proposed framework can be added to most RL algorithms since it only affects the observation process, selecting the parts more promising to explain the dynamics of the environment and reducing the dimension of the observation space.},
  archive      = {J_NN},
  author       = {Mirza Ramicic and Andrea Bonarini},
  doi          = {10.1016/j.neunet.2023.02.044},
  journal      = {Neural Networks},
  pages        = {456-471},
  shortjournal = {Neural Netw.},
  title        = {Uncertainty maximization in partially observable domains: A cognitive perspective},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COM: Contrastive masked-attention model for incomplete
multimodal learning. <em>NN</em>, <em>162</em>, 443–455. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most multimodal learning methods assume that all modalities are always available in data. However, in real-world applications, the assumption is often violated due to privacy protection, sensor failure etc. Previous works for incomplete multimodal learning often suffer from one of the following drawbacks: introducing noise, lacking flexibility to missing patterns and failing to capture interactions between modalities. To overcome these challenges, we propose a CO ntrastive M asked-attention model (COM). The framework performs cross-modal contrastive learning with GAN-based augmentation to reduce modality gap, and employs a masked-attention model to capture interactions between modalities. The augmentation adapts cross-modal contrastive learning to suit incomplete case by a two-player game, improving the effectiveness of multimodal representations. Interactions between modalities are modeled by stacking self-attention blocks, and attention masks limit them on the observed modalities to avoid extra noise. All kinds of modality combinations share a unified architecture, so the model is flexible to different missing patterns. Extensive experiments on six datasets demonstrate the effectiveness and robustness of the proposed method for incomplete multimodal learning.},
  archive      = {J_NN},
  author       = {Shuwei Qian and Chongjun Wang},
  doi          = {10.1016/j.neunet.2023.03.003},
  journal      = {Neural Networks},
  pages        = {443-455},
  shortjournal = {Neural Netw.},
  title        = {COM: Contrastive masked-attention model for incomplete multimodal learning},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Framework for segmented threshold ℓ0 gradient approximation
based network for sparse signal recovery. <em>NN</em>, <em>162</em>,
425–442. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signal reconstruction from compressed sensed data need iterative methods since the sparse measurement matrix is analytically non invertible. The iterative thresholding and ℓ 0 ℓ0 function minimization are of special interest as these two operations provide sparse solution . However these methods need an inverse operation corresponding to the measurement matrix for estimating the reconstruction error. The pseudo-inverse of the measurement matrix is used in general for this purpose. Here a sparse signal recovery framework using an approximate inverse matrix Q Q and iterative segment thresholding of ℓ 0 ℓ0 and ℓ 1 ℓ1 norm with residue addition is presented. Two recovery algorithms are developed using this framework. The ℓ 0 ℓ0 based method is later developed to a basis function dictionary based network for sparse signal recovery. The proposed framework enables the users experiment with different inverse matrix to achieve better efficiency in sparse signal recovery and implement the algorithm in computationally efficient way.},
  archive      = {J_NN},
  author       = {Vivekanand V. and Deepak Mishra},
  doi          = {10.1016/j.neunet.2023.03.005},
  journal      = {Neural Networks},
  pages        = {425-442},
  shortjournal = {Neural Netw.},
  title        = {Framework for segmented threshold ℓ0 gradient approximation based network for sparse signal recovery},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A learnable sampling method for scalable graph neural
networks. <em>NN</em>, <em>162</em>, 412–424. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of graph neural networks , how to handle large-scale graph data has become an increasingly important topic. Currently, most graph neural network models which can be extended to large-scale graphs are based on random sampling methods. However, the sampling process in these models is detached from the forward propagation of neural networks . Moreover, quite a few works design sampling based on statistical estimation methods for graph convolutional networks and the weights of message passing in GCNs nodes are fixed, making these sampling methods not scalable to message passing networks with variable weights, such as graph attention networks . Noting the end-to-end learning capability of neural networks, we propose a learnable sampling method. It solves the problem that random sampling operations cannot calculate gradients and samples nodes with an unfixed probability . In this way, the sampling process is dynamically combined with the forward propagation process of the features, allowing for better training of the networks. And it can be generalized to all message passing models. In addition, we apply the learnable sampling method to GNNs and propose two models. Our method can be flexibly combined with different graph neural network models and achieves excellent accuracy on benchmark datasets with large graphs. Meanwhile, loss function converges to smaller values at a faster rate during training than past methods.},
  archive      = {J_NN},
  author       = {Weichen Zhao and Tiande Guo and Xiaoxi Yu and Congying Han},
  doi          = {10.1016/j.neunet.2023.03.015},
  journal      = {Neural Networks},
  pages        = {412-424},
  shortjournal = {Neural Netw.},
  title        = {A learnable sampling method for scalable graph neural networks},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nested relation extraction via self-contrastive learning
guided by structure and semantic similarity. <em>NN</em>, <em>162</em>,
393–411. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional Relation Extraction (RE) task involves identifying whether relations exist between two entities in a given sentence and determining their relation types. However, the complexity of practical application scenarios and the flexibility of natural language demand the ability to extract nested relations, i.e., the recognized relation triples may be components of the higher-level relations. Previous studies have highlighted several challenges that affect the nested RE task, including the lack of abundant labeled data, inappropriate neural networks , and underutilization of the nested relation structures. To address these issues, we formalize the nested RE task and propose a hierarchical neural network to iteratively identify the nested relations between entities and relation triples in a layer by layer manner. Moreover, a novel self-contrastive learning optimization strategy is presented to adapt our method to low-data settings by fully exploiting the constraints due to the nested structure and semantic similarity between paired input sentences. Our method outperformed the state-of-the-art baseline methods in extensive experiments, and ablation experiments verified the effectiveness of the proposed self-contrastive learning optimization strategy .},
  archive      = {J_NN},
  author       = {Chengcheng Mai and Kaiwen Luo and Yuxiang Wang and Ziyan Peng and Yu Chen and Chunfeng Yuan and Yihua Huang},
  doi          = {10.1016/j.neunet.2023.03.001},
  journal      = {Neural Networks},
  pages        = {393-411},
  shortjournal = {Neural Netw.},
  title        = {Nested relation extraction via self-contrastive learning guided by structure and semantic similarity},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interpretive constrained linear model for ResNet and
MgNet. <em>NN</em>, <em>162</em>, 384–392. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a constrained linear data-feature-mapping model as an interpretable mathematical model for image classification using a convolutional neural network (CNN). From this viewpoint, we establish detailed connections between the traditional iterative schemes for linear systems and the architectures of the basic blocks of ResNet- and MgNet-type models. Using these connections, we present some modified ResNet models that, compared with the original models, have fewer parameters but can produce more accurate results, thereby demonstrating the validity of this constrained learning data-feature-mapping assumption. Based on this assumption, we further propose a general data-feature iterative scheme to demonstrate the rationality of MgNet. We also provide a systematic numerical study on MgNet to show its success and advantages in image classification problems, particularly in comparison with established networks.},
  archive      = {J_NN},
  author       = {Juncai He and Jinchao Xu and Lian Zhang and Jianqing Zhu},
  doi          = {10.1016/j.neunet.2023.03.011},
  journal      = {Neural Networks},
  pages        = {384-392},
  shortjournal = {Neural Netw.},
  title        = {An interpretive constrained linear model for ResNet and MgNet},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative negative replay for continual learning.
<em>NN</em>, <em>162</em>, 369–383. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning continually is a key aspect of intelligence and a necessary ability to solve many real-life problems. One of the most effective strategies to control catastrophic forgetting, the Achilles’ heel of continual learning, is storing part of the old data and replaying them interleaved with new experiences (also known as the replay approach). Generative replay, which is using generative models to provide replay patterns on demand, is particularly intriguing, however, it was shown to be effective mainly under simplified assumptions, such as simple scenarios and low-dimensional data. In this paper, we show that, while the generated data are usually not able to improve the classification accuracy for the old classes, they can be effective as negative examples (or antagonists) to better learn the new classes, especially when the learning experiences are small and contain examples of just one or few classes. The proposed approach is validated on complex class-incremental and data-incremental continual learning scenarios (CORe50 and ImageNet-1000) composed of high-dimensional data and a large number of training experiences: a setup where existing generative replay approaches usually fail.},
  archive      = {J_NN},
  author       = {Gabriele Graffieti and Davide Maltoni and Lorenzo Pellegrini and Vincenzo Lomonaco},
  doi          = {10.1016/j.neunet.2023.03.006},
  journal      = {Neural Networks},
  pages        = {369-383},
  shortjournal = {Neural Netw.},
  title        = {Generative negative replay for continual learning},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical attention master–slave for heterogeneous
multi-agent reinforcement learning. <em>NN</em>, <em>162</em>, 359–368.
(<a href="https://doi.org/10.1016/j.neunet.2023.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most multi-agent reinforcement learning (MARL) approaches optimize strategy by improving itself, while ignoring the limitations of homogeneous agents that may have single function. However, in reality, the complex tasks tend to coordinate various types of agents and leverage advantages from one another. Therefore, it is a vital research issue how to establish appropriate communication among them and optimize decision. To this end, we propose a Hierarchical Attention Master–Slave (HAMS) MARL, where the Hierarchical Attention balances the weight allocation within and among clusters, and the Master–Slave architecture endows agents independent reasoning and individual guidance. By the offered design, information fusion, especially among clusters, is implemented effectively, and excessive communication is avoided, moreover, selective composed action optimizes decision. We evaluate the HAMS on both small and large scale heterogeneous StarCraft II micromanagement tasks. The proposed algorithm achieves the exceptional performance with more than 80\% win rates in all evaluation scenarios, which obtains an impressive win rate of over 90\% in the largest map. The experiments demonstrate a maximum improvement in win rate of 47\% over the best known algorithm. The results show that our proposal outperforms recent state-of-the-art approaches, which provides a novel idea for heterogeneous multi-agent policy optimization .},
  archive      = {J_NN},
  author       = {Jiao Wang and Mingrui Yuan and Yun Li and Zihui Zhao},
  doi          = {10.1016/j.neunet.2023.02.037},
  journal      = {Neural Networks},
  pages        = {359-368},
  shortjournal = {Neural Netw.},
  title        = {Hierarchical attention Master–Slave for heterogeneous multi-agent reinforcement learning},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vertex points are not enough: Monocular 3D object detection
via intra- and inter-plane constraints. <em>NN</em>, <em>162</em>,
350–358. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existed methods for 3D object detection in monocular images focus mainly on the class of rigid bodies like cars, while more challenging detection like the cyclist is less studied. Therefore, we propose a novel 3D monocular object detection method to improve the accuracy of detection objects with large differences in deformation by introducing the geometric constraints of the object 3D bounding box plane. Considering the map relationship of projection plane and the keypoint , we firstly introduce the geometric constraints of the object 3D bounding box plane, adding the intra-plane constraint while regressing the position and offset of the keypoint itself, so that the position and offset error of the keypoint are always within the error range of the projection plane. For the inter-plane geometry relationship of the 3D bounding box, the prior knowledge is incorporated to optimize the keypoint regression allowing for improved the accuracy of depth location prediction. Experimental results show that the proposed method outperforms some other state-of-the-art methods on cyclist class, and obtains competitive results in the field of real-time monocular detection.},
  archive      = {J_NN},
  author       = {Hongdou Yao and Jun Chen and Zheng Wang and Xiao Wang and Xiaoyu Chai and Yansheng Qiu and Pengfei Han},
  doi          = {10.1016/j.neunet.2023.02.038},
  journal      = {Neural Networks},
  pages        = {350-358},
  shortjournal = {Neural Netw.},
  title        = {Vertex points are not enough: Monocular 3D object detection via intra- and inter-plane constraints},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic forecasting with graph spatial–temporal position
recurrent network. <em>NN</em>, <em>162</em>, 340–349. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of social economy and smart technology, the explosive growth of vehicles has caused traffic forecasting to become a daunting challenge, especially for smart cities. Recent methods exploit graph spatial–temporal characteristics, including constructing the shared patterns of traffic data, and modeling the topological space of traffic data. However, existing methods fail to consider the spatial position information and only utilize little spatial neighborhood information. To tackle above limitation, we design a Graph Spatial–Temporal Position Recurrent Network (GSTPRN) architecture for traffic forecasting. We first construct a position graph convolution module based on self-attention and calculate the dependence strengths among the nodes to capture the spatial dependence relationship. Next, we develop approximate personalized propagation that extends the propagation range of spatial dimension information to obtain more spatial neighborhood information. Finally, we systematically integrate the position graph convolution , approximate personalized propagation and adaptive graph learning into a recurrent network (i.e. Gated Recurrent Units). Experimental evaluation on two benchmark traffic datasets demonstrates that GSTPRN is superior to the state-of-art methods.},
  archive      = {J_NN},
  author       = {Yibi Chen and Kenli Li and Chai Kiat Yeo and Keqin Li},
  doi          = {10.1016/j.neunet.2023.03.009},
  journal      = {Neural Networks},
  pages        = {340-349},
  shortjournal = {Neural Netw.},
  title        = {Traffic forecasting with graph spatial–temporal position recurrent network},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SuperstarGAN: Generative adversarial networks for
image-to-image translation in large-scale domains. <em>NN</em>,
<em>162</em>, 330–339. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-to-image translation with generative adversarial networks (GANs) has been extensively studied in recent years. Among the models, StarGAN has achieved image-to-image translation for multiple domains with a single generator, whereas conventional models require multiple generators. However, StarGAN has several limitations, including the lack of capacity to learn mappings among large-scale domains; furthermore, StarGAN can barely express small feature changes. To address the limitations, we propose an improved StarGAN, namely SuperstarGAN. We adopted the idea, first proposed in controllable GAN (ControlGAN), of training an independent classifier with the data augmentation techniques to handle the overfitting problem in the classification of StarGAN structures. Since the generator with a well-trained classifier can express small features belonging to the target domain, SuperstarGAN achieves image-to-image translation in large-scale domains. Evaluated with a face image dataset, SuperstarGAN demonstrated improved performance in terms of Fréchet Inception distance (FID) and learned perceptual image patch similarity (LPIPS). Specifically, compared to StarGAN, SuperstarGAN exhibited decreased FID and LPIPS by 18.1\% and 42.5\%, respectively. Furthermore, we conducted an additional experiment with interpolated and extrapolated label values, indicating the ability of SuperstarGAN to control the degree of expression of the target domain features in generated images. Additionally, SuperstarGAN was successfully adapted to an animal face dataset and a painting dataset, where it can translate styles of animal faces (i.e., a cat to a tiger) and styles of painters (i.e., Hassam to Picasso), respectively, which explains the generality of SuperstarGAN regardless of datasets.},
  archive      = {J_NN},
  author       = {Kanghyeok Ko and Taesun Yeom and Minhyeok Lee},
  doi          = {10.1016/j.neunet.2023.02.042},
  journal      = {Neural Networks},
  pages        = {330-339},
  shortjournal = {Neural Netw.},
  title        = {SuperstarGAN: Generative adversarial networks for image-to-image translation in large-scale domains},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LCM-captioner: A lightweight text-based image captioning
method with collaborative mechanism between vision and text.
<em>NN</em>, <em>162</em>, 318–329. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based image captioning (TextCap) aims to remedy the shortcomings of existing image captioning tasks that ignore text content when describing images. Instead, it requires models to recognize and describe images from both visual and textual content to achieve a deeper level of comprehension of the images. However, existing methods tend to use numerous complex network architectures to improve performance, which still fails to adequately model the relationship between vision and text on the one side, while on the other side this leads to long running times, high memory consumption, and other unfavorable deployment problems. To solve the above issues, we have developed a lightweight captioning method with a collaborative mechanism, LCM-Captioner, which balances high efficiency with high performance. First, we propose a feature-lightening transformation for the TextCap task, named TextLighT, which is able to learn rich multimodal representations while mapping features to lower dimensions, thereby reducing memory costs. Next, we present a collaborative attention module for visual and text information, VTCAM , to facilitate the semantic alignment of multimodal information to uncover important visual objects and textual content. Finally, the conducted extensive experiments on the TextCaps dataset demonstrate the effectiveness of our method. Code is available at https://github.com/DengHY258/LCM-Captioner .},
  archive      = {J_NN},
  author       = {Qi Wang and Hongyu Deng and Xue Wu and Zhenguo Yang and Yun Liu and Yazhou Wang and Gefei Hao},
  doi          = {10.1016/j.neunet.2023.03.010},
  journal      = {Neural Networks},
  pages        = {318-329},
  shortjournal = {Neural Netw.},
  title        = {LCM-captioner: A lightweight text-based image captioning method with collaborative mechanism between vision and text},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global synchronization of complex-valued neural networks
with unbounded time-varying delays. <em>NN</em>, <em>162</em>, 309–317.
(<a href="https://doi.org/10.1016/j.neunet.2023.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates global synchronization of complex-valued neural networks (CVNNs) with unbounded time-varying delays. By applying analytical method and inequality techniques, an algebraic criterion is established to ensure global synchronization of the CVNNs via a devised feedback controller , which generalizes some existing outcomes. Finally, two numerical simulations and one application in image encryption are provided to verify the effectiveness of the theoretical results.},
  archive      = {J_NN},
  author       = {Yin Sheng and Haoyu Gong and Zhigang Zeng},
  doi          = {10.1016/j.neunet.2023.02.041},
  journal      = {Neural Networks},
  pages        = {309-317},
  shortjournal = {Neural Netw.},
  title        = {Global synchronization of complex-valued neural networks with unbounded time-varying delays},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual adaptive learning multi-task multi-view for graph
network representation learning. <em>NN</em>, <em>162</em>, 297–308. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph network analysis , which achieves widely application, is to explore and mine the graph structure data . However, existing graph network analysis methods with graph representation learning technique ignore the correlation between multiple graph network analysis tasks, and they need massive repeated calculation to obtain each graph network analysis results. Or they cannot adaptively balance the relative importance of multiple graph network analysis tasks, that lead to weak model fitting. Besides, most of existing methods ignore multiplex views semantic information and global graph information , which fail to learn robust node embeddings resulting in unsatisfied graph analysis results. To solve these issues, we propose a m ulti-task m ulti-view a daptive g raph network representation l earning model, called M 2 2 agl. The highlights of M 2 2 agl are as follows: (1) Graph convolutional network with the linear combination of the adjacency matrix and PPMI (positive point-wise mutual information) matrix is utilized as encoder to extract the local and global intra-view graph feature information of the multiplex graph network. Each intra-view graph information of the multiplex graph network can adaptively learn the parameters of graph encoder. (2) We use regularization to capture the interaction information among different graph views, and the importance of different graph views are learned by view attention mechanism for further inter-view graph network fusion. (3) The model is trained oriented by multiple graph network analysis tasks. The relative importance of multiple graph network analysis tasks are adjusted adaptively with the homoscedastic uncertainty. The regularization can be considered as an auxiliary task to further boost the performance. Experiments on real-worlds attributed multiplex graph networks demonstrate the effectiveness of M 2 2 agl in comparison with other competing approaches.},
  archive      = {J_NN},
  author       = {Beibei Han and Yingmei Wei and Qingyong Wang and Shanshan Wan},
  doi          = {10.1016/j.neunet.2023.02.026},
  journal      = {Neural Networks},
  pages        = {297-308},
  shortjournal = {Neural Netw.},
  title        = {Dual adaptive learning multi-task multi-view for graph network representation learning},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bounded synchronization for uncertain master–slave neural
networks: An adaptive impulsive control approach. <em>NN</em>,
<em>162</em>, 288–296. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the bounded synchronization of the discrete-time master–slave neural networks (MSNNs) with uncertainty. To deal with the unknown parameter in the MSNNs, a parameter adaptive law combined with the impulsive mechanism is proposed to improve the estimation efficiency. Meanwhile, the impulsive method also is applied to the controller design for saving the energy. In addition, a novel time-varying Lyapunov functional candidate is employed to depict the impulsive dynamical characteristic of the MSNNs, wherein a convex function related to the impulsive interval is used to obtain a sufficient condition for bounded synchronization of the MSNNs. Based on the above condition, the controller gain is calculated utilizing an unitary matrix . An algorithm is proposed to reduce the boundary of the synchronization error by optimizing its parameters. Finally, a numerical example is provided to illustrate the correctness and the superiority of the developed results.},
  archive      = {J_NN},
  author       = {Yuru Guo and Chang Liu and Yonghua Liu and Yong Xu and Renquan Lu and Tingwen Huang},
  doi          = {10.1016/j.neunet.2023.03.002},
  journal      = {Neural Networks},
  pages        = {288-296},
  shortjournal = {Neural Netw.},
  title        = {Bounded synchronization for uncertain master–slave neural networks: An adaptive impulsive control approach},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HARDC: A novel ECG-based heartbeat classification method to
detect arrhythmia using hierarchical attention based dual structured RNN
with dilated CNN. <em>NN</em>, <em>162</em>, 271–287. (<a
href="https://doi.org/10.1016/j.neunet.2023.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based models have achieved significant success in detecting cardiac arrhythmia by analyzing ECG signals to categorize patient heartbeats. To improve the performance of such models, we have developed a novel hybrid hierarchical attention-based bidirectional recurrent neural network with dilated CNN (HARDC) method for arrhythmia classification. This solves problems that arise when traditional dilated convolutional neural network (CNN) models disregard the correlation between contexts and gradient dispersion. The proposed HARDC fully exploits the dilated CNN and bidirectional recurrent neural network unit (BiGRU–BiLSTM) architecture to generate fusion features . As a result of incorporating both local and global feature information and an attention mechanism , the model’s performance for prediction is improved. By combining the fusion features with a dilated CNN and a hierarchical attention mechanism , the trained HARDC model showed significantly improved classification results and interpretability of feature extraction on the PhysioNet 2017 challenge dataset. Sequential Z-Score normalization, filtering, denoising , and segmentation are used to prepare the raw data for analysis. CGAN (Conditional Generative Adversarial Network) is then used to generate synthetic signals from the processed data. The experimental results demonstrate that the proposed HARDC model significantly outperforms other existing models, achieving an accuracy of 99.60\%, F1 score of 98.21\%, a precision of 97.66\%, and recall of 99.60\% using MIT-BIH generated ECG. In addition, this approach significantly reduces run time when using dilated CNN compared to normal convolution . Overall, this hybrid model demonstrates an innovative and cost-effective strategy for ECG signal compression and high-performance ECG recognition. Our results indicate that an automated and highly computed method to classify multiple types of arrhythmia signals holds considerable promise.},
  archive      = {J_NN},
  author       = {Md Shofiqul Islam and Khondokar Fida Hasan and Sunjida Sultana and Shahadat Uddin and Pietro Lio’ and Julian M.W. Quinn and Mohammad Ali Moni},
  doi          = {10.1016/j.neunet.2023.03.004},
  journal      = {Neural Networks},
  pages        = {271-287},
  shortjournal = {Neural Netw.},
  title        = {HARDC: A novel ECG-based heartbeat classification method to detect arrhythmia using hierarchical attention based dual structured RNN with dilated CNN},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A meta-framework for multi-label active learning based on
deep reinforcement learning. <em>NN</em>, <em>162</em>, 258–270. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label Active Learning (MLAL) is an effective method to improve the performance of the classifier on multi-label problems with less annotation effort by allowing the learning system to actively select high-quality examples (example-label pairs) for labeling. Existing MLAL algorithms mainly focus on designing reasonable algorithms to evaluate the potential values (as previously mentioned quality) of the unlabeled data . These manually designed methods may show totally different results on various types of datasets due to the defect of the methods or the particularity of the datasets. In this paper, instead of manually designing an evaluation method, we propose a deep reinforcement learning (DRL) model to explore a general evaluation method on several seen datasets and eventually apply it to unseen datasets based on a meta framework. In addition, a self-attention mechanism along with a reward function is integrated into the DRL structure to address the label correlation and data imbalanced problems in MLAL. Comprehensive experiments show that our proposed DRL-based MLAL method is able to produce comparable results as compared with other methods reported in the literature.},
  archive      = {J_NN},
  author       = {Shuyue Chen and Ran Wang and Jian Lu},
  doi          = {10.1016/j.neunet.2023.02.045},
  journal      = {Neural Networks},
  pages        = {258-270},
  shortjournal = {Neural Netw.},
  title        = {A meta-framework for multi-label active learning based on deep reinforcement learning},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Genetic hyperparameter optimization with modified
scalable-neighbourhood component analysis for breast cancer
prognostication. <em>NN</em>, <em>162</em>, 240–257. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is common among women resulting in mortality when left untreated. Early detection is vital so that suitable treatment could assist cancer from spreading further and save people’s life. The traditional way of detection is a time-consuming process. With the evolvement of DM (Data Mining), the healthcare industry could be benefitted in predicting the disease as it permits the physicians to determine the significant attributes for diagnosis. Though, conventional techniques have used DM-based methods to identify breast cancer, they lacked in terms of prediction rate. Moreover, parametric-Softmax classifiers have been a general option by conventional works with fixed classes, particularly when huge labelled data are present during training. Nevertheless, this turns into an issue for open set cases where new classes are encountered along with few instances to learn a generalized parametric classifier. Thus, the present study aims to implement a non-parametric strategy by optimizing the embedding of a feature rather than parametric classifiers. This research utilizes Deep CNN (Deep Convolutional Neural Network) and Inception V3 for learning visual features which preserve neighbourhood outline in semantic space relying on NCA (Neighbourhood Component Analysis) criteria. Delimited by its bottleneck, the study proposes MS-NCA (Modified Scalable-Neighbourhood Component Analysis) that relies on a non-linear objective function to perform feature fusion by optimizing the distance-learning objective due to which it gains the capability of computing inner feature products without performing mapping which increases the scalability of MS-NCA. Finally, G-HPO (Genetic-Hyper-parameter Optimization) is proposed. In this case, the new stage in the algorithm simply denotes the enhancement in the length of chromosome bringing several hyperparameters into subsequent XGBoost , NB and RF models having numerous layers for identifying the normal and affected cases of breast cancer for which optimized hyper-parameter values of RF (Random Forest), NB (Naïve Bayes), and XGBoost (eXtreme Gradient Boosting) are determined. This process helps in improvising the classification rate which is confirmed through analytical results.},
  archive      = {J_NN},
  author       = {Shtwai Alsubai and Abdullah Alqahtani and Mohemmed Sha},
  doi          = {10.1016/j.neunet.2023.02.035},
  journal      = {Neural Networks},
  pages        = {240-257},
  shortjournal = {Neural Netw.},
  title        = {Genetic hyperparameter optimization with modified scalable-neighbourhood component analysis for breast cancer prognostication},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disturbance rejection for multi-weighted complex dynamical
networks with actuator saturation and deception attacks via
hybrid-triggered mechanism. <em>NN</em>, <em>162</em>, 225–239. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address hybrid-driven-based robust synchronization problem for multi-weighted complex dynamical networks with actuator saturation and deception attacks. The hybrid-triggered mechanism, which combines a switch between the event-triggered scheme and the time-triggered scheme, is often used to reduce the data transmission and the alleviate network burden. Further, the equivalent-input-disturbance technique is applied to eliminate the unknown disturbance effect of the addressed system. Moreover, a memory controller is designed under actuator saturation to ensure that the resultant augmented system is asymptotically synchronized even in the presence of deception attacks. Finally, three numerical examples are given to show the validity of the obtained theoretical results.},
  archive      = {J_NN},
  author       = {R. Sakthivel and O.M. Kwon and M.J. Park and S.M. Lee and R. Sakthivel},
  doi          = {10.1016/j.neunet.2023.02.031},
  journal      = {Neural Networks},
  pages        = {225-239},
  shortjournal = {Neural Netw.},
  title        = {Disturbance rejection for multi-weighted complex dynamical networks with actuator saturation and deception attacks via hybrid-triggered mechanism},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge computing on TPU for brain implant signal analysis.
<em>NN</em>, <em>162</em>, 212–224. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing number of recording sites of silicon-based probes imposes a great challenge for detecting and evaluating single-unit activities in an accurate and efficient manner. Currently separate solutions are available for high precision offline evaluation and separate solutions for embedded systems where computational resources are more limited. We propose a deep learning-based spike sorting system, that utilizes both unsupervised and supervised paradigms to learn a general feature embedding space and detect neural activity in raw data as well as predict the feature vectors for sorting. The unsupervised component uses contrastive learning to extract features from individual waveforms, while the supervised component is based on the MobileNetV2 architecture. One of the key advantages of our system is that it can be trained on multiple, diverse datasets simultaneously, resulting in greater generalizability than previous deep learning-based models. We demonstrate that the proposed model does not only reaches the accuracy of current state-of-art offline spike sorting methods but has the unique potential to run on edge Tensor Processing Units (TPUs), specialized chips designed for artificial intelligence and edge computing . We compare our model performance with state of art solutions on paired datasets as well as on hybrid recordings as well. The herein demonstrated system paves the way to the integration of deep learning-based spike sorting algorithms into wearable electronic devices, which will be a crucial element of high-end brain–computer interfaces.},
  archive      = {J_NN},
  author       = {János Rokai and István Ulbert and Gergely Márton},
  doi          = {10.1016/j.neunet.2023.02.036},
  journal      = {Neural Networks},
  pages        = {212-224},
  shortjournal = {Neural Netw.},
  title        = {Edge computing on TPU for brain implant signal analysis},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Successes and critical failures of neural networks in
capturing human-like speech recognition. <em>NN</em>, <em>162</em>,
199–211. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural and artificial audition can in principle acquire different solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would potentially enrich artificial hearing systems and process models of the mind and brain. Speech recognition — an area ripe for such exploration — is inherently robust in humans to a number transformations at various spectrotemporal granularities . To what extent are these robustness profiles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimulus-computable, optimized observers. In a series of experiments, we (1) clarify how influential speech manipulations in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-distribution robustness, reproducing classical perceptual phenomena in humans, (3) identify the specific conditions where model predictions of human performance differ, and (4) demonstrate a crucial failure of all artificial systems to perceptually recover where humans do, suggesting alternative directions for theory and model building. These findings encourage a tighter synergy between the cognitive science and engineering of audition.},
  archive      = {J_NN},
  author       = {Federico Adolfi and Jeffrey S. Bowers and David Poeppel},
  doi          = {10.1016/j.neunet.2023.02.032},
  journal      = {Neural Networks},
  pages        = {199-211},
  shortjournal = {Neural Netw.},
  title        = {Successes and critical failures of neural networks in capturing human-like speech recognition},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general framework for robust stability analysis of neural
networks with discrete time delays. <em>NN</em>, <em>162</em>, 186–198.
(<a href="https://doi.org/10.1016/j.neunet.2023.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust stability of different types of dynamical neural network models including time delay parameters have been extensively studied, and many different sets of sufficient conditions ensuring robust stability of these types of dynamical neural network models have been presented in past decades. In conducting stability analysis of dynamical neural systems, some basic properties of the employed activation functions and the forms of delay terms included in the mathematical representations of dynamical neural networks are of crucial importance in obtaining global stability criteria for dynamical neural systems. Therefore, this research article will examine a class of neural networks expressed by a mathematical model that involves the discrete time delay terms, the Lipschitz activation functions and possesses the intervalized parameter uncertainties. This paper will first present a new and alternative upper bound value of the second norm of the class of interval matrices, which will have an important impact on obtaining the desired results for establishing robust stability of these neural network models. Then, by exploiting wellknown Homeomorphism mapping theory and basic Lyapunov stability theory , we will state a new general framework for determining some novel robust stability conditions for dynamical neural networks possessing discrete time delay terms. This paper will also make a comprehensive review of some previously published robust stability results and show that the existing robust stability results can be easily derived from the results given in this paper.},
  archive      = {J_NN},
  author       = {Melike Solak and Ozlem Faydasicok and Sabri Arik},
  doi          = {10.1016/j.neunet.2023.02.040},
  journal      = {Neural Networks},
  pages        = {186-198},
  shortjournal = {Neural Netw.},
  title        = {A general framework for robust stability analysis of neural networks with discrete time delays},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Mittag-leffler stability of fractional-order
quaternion-valued memristive neural networks with generalized piecewise
constant argument. <em>NN</em>, <em>162</em>, 175–185. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the global Mittag-Leffler (M-L) stability problem for fractional-order quaternion-valued memristive neural networks (FQVMNNs) with generalized piecewise constant argument (GPCA). First, a novel lemma is established, which is used to investigate the dynamic behaviors of quaternion-valued memristive neural networks (QVMNNs). Second, by using the theories of differential inclusion , set-valued mapping, and Banach fixed point, several sufficient criteria are derived to ensure the existence and uniqueness (EU) of the solution and equilibrium point for the associated systems. Then, by constructing Lyapunov functions and employing some inequality techniques, a set of criteria are proposed to ensure the global M-L stability of the considered systems. The obtained results in this paper not only extends previous works, but also provides new algebraic criteria with a larger feasible range. Finally, two numerical examples are introduced to illustrate the effectiveness of the obtained results.},
  archive      = {J_NN},
  author       = {Jingjing Wang and Song Zhu and Xiaoyang Liu and Shiping Wen},
  doi          = {10.1016/j.neunet.2023.02.030},
  journal      = {Neural Networks},
  pages        = {175-185},
  shortjournal = {Neural Netw.},
  title        = {Mittag-leffler stability of fractional-order quaternion-valued memristive neural networks with generalized piecewise constant argument},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifelong text-audio sentiment analysis learning.
<em>NN</em>, <em>162</em>, 162–174. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis refers to the mining of textual context, which is conducted with the aim of identifying and extracting subjective opinions in textual materials. However, most existing methods neglect other important modalities, e.g., the audio modality, which can provide intrinsic complementary knowledge for sentiment analysis. Furthermore, much work on sentiment analysis cannot continuously learn new sentiment analysis tasks or discover potential correlations among distinct modalities. To address these concerns, we propose a novel Lifelong Text-Audio Sentiment Analysis (LTASA) model to continuously learn text-audio sentiment analysis tasks, which effectively explores intrinsic semantic relationships from both intra-modality and inter-modality perspectives. More specifically, a modality-specific knowledge dictionary is developed for each modality to obtain shared intra-modality representations among various text-audio sentiment analysis tasks. Additionally, based on information dependence between text and audio knowledge dictionaries, a complementarity-aware subspace is developed to capture the latent nonlinear inter-modality complementary knowledge. To sequentially learn text-audio sentiment analysis tasks, a new online multi-task optimization pipeline is designed. Finally, we verify our model on three common datasets to show its superiority. Compared with some baseline representative methods, the capability of the LTASA model is significantly boosted in terms of five measurement indicators.},
  archive      = {J_NN},
  author       = {Yuting Lin and Peng Ji and Xiuyi Chen and Zhongshi He},
  doi          = {10.1016/j.neunet.2023.02.008},
  journal      = {Neural Networks},
  pages        = {162-174},
  shortjournal = {Neural Netw.},
  title        = {Lifelong text-audio sentiment analysis learning},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WDMNet: Modeling diverse variations of regional wind speed
for multi-step predictions. <em>NN</em>, <em>162</em>, 147–161. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regional wind speed prediction plays an important role in the development of wind power, which is usually recorded in the form of two orthogonal components , namely U-wind and V-wind. The regional wind speed has the characteristics of diverse variations, which are reflected in three aspects: (1) The spatially diverse variations of regional wind speed indicate that wind speed has different dynamic patterns at different positions; (2) The distinct variations between U-wind and V-wind denote that U-wind and V-wind at the same position exhibit different dynamic patterns; (3) The non-stationary variations of wind speed represent that the intermittent and chaotic nature of wind speed. In this paper, we propose a novel framework named Wind Dynamics Modeling Network (WDMNet) to model the diverse variations of regional wind speed and make accurate multi-step predictions. To jointly capture the spatially diverse variations and the distinct variations between U-wind and V-wind, WDMNet leverages a new neural block called Involution Gated Recurrent Unit Partial Differential Equation (Inv-GRU-PDE) as its key component. The block adopts involution to model spatially diverse variations and separately constructs hidden driven PDEs of U-wind and V-wind. The construction of PDEs in this block is achieved by a new Involution PDE (InvPDE) layers. Besides, a deep data-driven model is also introduced in Inv-GRU-PDE block as the complement to the constructed hidden PDEs for sufficiently modeling regional wind dynamics. Finally, to effectively capture the non-stationary variations of wind speed, WDMNet follows a time-variant structure for multi-step predictions. Comprehensive experiments have been conducted on two real-world datasets. Experimental results demonstrate the effectiveness and superiority of the proposed method over state-of-the-art techniques.},
  archive      = {J_NN},
  author       = {Rui Ye and Shanshan Feng and Xutao Li and Yunming Ye and Baoquan Zhang and Yan Zhu and Yao Sun and Yaowei Wang},
  doi          = {10.1016/j.neunet.2023.02.024},
  journal      = {Neural Networks},
  pages        = {147-161},
  shortjournal = {Neural Netw.},
  title        = {WDMNet: Modeling diverse variations of regional wind speed for multi-step predictions},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effects of parity, frustration, and stochastic fluctuations
on integrated conceptual information for networks with two small-sized
loops. <em>NN</em>, <em>162</em>, 131–146. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an evaluation of the system-level integrated conceptual information of a major complex for a small-scale network containing two loops in accordance with the integrated information theory 3.0 framework. We focus on the following parameters characterizing the system model: (1) number of nodes in the loop, (2) frustration of the loop, and (3) temperature controlling the stochastic fluctuation of the state transition. Effects of these parameters on the integrated conceptual information and conditions for major complexes formed by a single loop, rather than the entire network, are investigated. Our first finding is that parity of the number of nodes forming a loop has a strong effect on the integrated conceptual information. For loops with an even number of nodes, the number of concepts tends to decrease, and the integrated conceptual information becomes smaller. Our second finding is that a major complex is more likely to be formed by a small number of nodes under small stochastic fluctuations. On the other hand, the entire network can easily become a major complex under larger stochastic fluctuations, and this tendency can be reinforced by frustration. It is also shown that, although counterintuitive, the integrated conceptual information can be maximized in the presence of stochastic fluctuations. These results suggest that even when several small subnetworks are connected by only a few connections, such as a bridge, the entire network may become a major complex by introducing some stochastic fluctuations and by frustrating loops with an even number of nodes.},
  archive      = {J_NN},
  author       = {Tadaaki Hosaka},
  doi          = {10.1016/j.neunet.2023.02.034},
  journal      = {Neural Networks},
  pages        = {131-146},
  shortjournal = {Neural Netw.},
  title        = {Effects of parity, frustration, and stochastic fluctuations on integrated conceptual information for networks with two small-sized loops},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NLS: An accurate and yet easy-to-interpret prediction
method. <em>NN</em>, <em>162</em>, 117–130. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last years, the predictive power of supervised machine learning (ML) has undergone impressive advances, achieving the status of state of the art and super-human level in some applications. However, the employment rate of ML models in real-life applications is much slower than one would expect. One of the downsides of using ML solution-based technologies is the lack of user trust in the produced model, which is related to the black-box nature of these models. To leverage the application of ML models, the generated predictions should be easy to interpret while maintaining a high accuracy. In this context, we develop the Neural Local Smoother (NLS), a neural network architecture that yields accurate predictions with easy-to-obtain explanations. The key idea of NLS is to add a smooth local linear layer to a standard network. We show experiments that indicate that NLS leads to a predictive power that is comparable to state-of-the-art machine learning models, but that at the same time is easier to interpret.},
  archive      = {J_NN},
  author       = {Victor Coscrato and Marco H.A. Inácio and Tiago Botari and Rafael Izbicki},
  doi          = {10.1016/j.neunet.2023.02.043},
  journal      = {Neural Networks},
  pages        = {117-130},
  shortjournal = {Neural Netw.},
  title        = {NLS: An accurate and yet easy-to-interpret prediction method},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-guided deep learning with ante-hoc explainability by
convolutional network from non-image data for pregnancy prognostication.
<em>NN</em>, <em>162</em>, 99–116. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is applied in medicine mostly due to its state-of-the-art performance for diagnostic imaging. Supervisory authorities also require the model to be explainable, but most explain the model after development (post hoc) instead of incorporating explanation into the design (ante hoc). This study aimed to demonstrate a human-guided deep learning with ante-hoc explainability by convolutional network from non-image data to develop, validate, and deploy a prognostic prediction model for PROM and an estimator of time of delivery using a nationwide health insurance database. To guide modeling, we constructed and verified association diagrams respectively from literatures and electronic health records . Non-image data were transformed into meaningful images utilizing predictor-to-predictor similarities, harnessing the power of convolutional neural network mostly used for diagnostic imaging. The network architecture was also inferred from the similarities. This resulted the best model for prelabor rupture of membranes ( n = 883 n=883 , 376) with the area under curves 0.73 (95\% CI 0.72 to 0.75) and 0.70 (95\% CI 0.69 to 0.71) respectively by internal and external validations, and outperformed previous models found by systematic review. It was explainable by knowledge-based diagrams and model representation. This allows prognostication with actionable insights for preventive medicine.},
  archive      = {J_NN},
  author       = {Herdiantri Sufriyana and Yu-Wei Wu and Emily Chia-Yu Su},
  doi          = {10.1016/j.neunet.2023.02.020},
  journal      = {Neural Networks},
  pages        = {99-116},
  shortjournal = {Neural Netw.},
  title        = {Human-guided deep learning with ante-hoc explainability by convolutional network from non-image data for pregnancy prognostication},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective knowledge graph entity alignment model based on
multiple information. <em>NN</em>, <em>162</em>, 83–98. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment refers to matching entities with the same realistic meaning in different knowledge graphs. The structure of a knowledge graph provides the global signal for entity alignment. But in the real world, a knowledge graph provides insufficient structural information in general. Moreover, the problem of knowledge graph heterogeneity is common. The semantic and string information can alleviate the problems caused by the sparse and heterogeneous nature of knowledge graphs, yet both of them have not been fully utilized by most existing work. Therefore, we propose an e ntity a lignment model based on m ultiple i nformation (EAMI), which employs structural, semantic and string information. EAMI learns the structural representation of a knowledge graph by using multi-layer graph convolutional networks . To acquire more accurate entity vector representation , we incorporate the attribute semantic representation into the structural representation. In addition, to further improve entity alignment, we study the entity name string information. There is no training required to calculate the similarity of entity names. Our model is tested on publicly available cross-lingual datasets and cross-resource datasets, and the experimental results demonstrate the effectiveness of our model.},
  archive      = {J_NN},
  author       = {Beibei Zhu and Tie Bao and Ridong Han and Hai Cui and Jiayu Han and Lu Liu and Tao Peng},
  doi          = {10.1016/j.neunet.2023.02.029},
  journal      = {Neural Networks},
  pages        = {83-98},
  shortjournal = {Neural Netw.},
  title        = {An effective knowledge graph entity alignment model based on multiple information},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based open set multi-source domain adaptation
with complementary transferability metric for mechanical fault
diagnosis. <em>NN</em>, <em>162</em>, 69–82. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis aims to build robust mechanical condition recognition models with limited dataset. At this stage, fault diagnosis faces two practical challenges: (1) the variability of mechanical working conditions makes the collected data distribution inconsistent, which brings about the domain shift; (2) some unpredictable unknown fault modes that do not observe in the training dataset may occur in the testing scenario, leading to a category gap. In order to cope with these two entangled challenges, an open set multi-source domain adaptation approach is developed in this study. Specifically, a complementary transferability metric defined on multiple classifiers is introduced to quantify the similarity of each target sample to known classes to weight the adversarial mechanism. By applying an unknown mode detector, unknown faults can be automatically identified. Moreover, a multi-source mutual-supervised strategy is further adopted to mine relevant information between different sources to enhance the model performance. Extensive experiments are conducted on three rotating machinery datasets, and the results show that the proposed method is superior to traditional domain adaptation approaches in the mechanical diagnosis issues that new fault modes occur.},
  archive      = {J_NN},
  author       = {Jinghui Tian and Dongying Han and Hamid Reza Karimi and Yu Zhang and Peiming Shi},
  doi          = {10.1016/j.neunet.2023.02.025},
  journal      = {Neural Networks},
  pages        = {69-82},
  shortjournal = {Neural Netw.},
  title        = {Deep learning-based open set multi-source domain adaptation with complementary transferability metric for mechanical fault diagnosis},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamical model of visual motion processing for arbitrary
stimuli including type II plaids. <em>NN</em>, <em>162</em>, 46–68. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explore the operating principle of visual motion processing in the brain underlying perception and eye movements, we model the information processing of velocity estimate of the visual stimulus at the algorithmic level using the dynamical system approach . In this study, we formulate the model as an optimization process of an appropriately defined objective function. The model is applicable to arbitrary visual stimuli. We find that our theoretical predictions qualitatively agree with time evolution of eye movement reported by previous works across various types of stimulus. Our results suggest that the brain implements the present framework as the internal model of motion vision. We anticipate our model to be a promising building block for more profound understanding of visual motion processing as well as for the development of robotics.},
  archive      = {J_NN},
  author       = {Yusuke Korai and Kenichiro Miura},
  doi          = {10.1016/j.neunet.2023.02.039},
  journal      = {Neural Networks},
  pages        = {46-68},
  shortjournal = {Neural Netw.},
  title        = {A dynamical model of visual motion processing for arbitrary stimuli including type II plaids},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Episodic task agnostic contrastive training for multi-task
learning. <em>NN</em>, <em>162</em>, 34–45. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning knowledge from different tasks to improve the general learning performance is crucial for designing an efficient algorithm. In this work, we tackle the Multi-task Learning (MTL) problem, where the learner extracts the knowledge from different tasks simultaneously with limited data. Previous works have been designing the MTL models by taking advantage of the transfer learning techniques, requiring the knowledge of the task index, which is not realistic in many practical scenarios. In contrast, we consider the scenario that the task index is not explicitly known, under which the features extracted by the neural networks are task agnostic. To learn the task agnostic invariant features, we implement model agnostic meta-learning by leveraging the episodic training scheme to capture the common features across tasks. Apart from the episodic training scheme, we further implemented a contrastive learning objective to improve the feature compactness for a better prediction boundary in the embedding space. We conduct extensive experiments on several benchmarks compared with several recent strong baselines to demonstrate the effectiveness of the proposed method. The results showed that our method provides a practical solution for real-world scenarios, where the task index is agnostic to the learner and can outperform several strong baselines, achieving state-of-the-art performances.},
  archive      = {J_NN},
  author       = {Fan Zhou and Yuyi Chen and Jun Wen and Qiuhao Zeng and Changjian Shui and Charles X. Ling and Shichun Yang and Boyu Wang},
  doi          = {10.1016/j.neunet.2023.02.023},
  journal      = {Neural Networks},
  pages        = {34-45},
  shortjournal = {Neural Netw.},
  title        = {Episodic task agnostic contrastive training for multi-task learning},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-UAV autonomous collision avoidance based on PPO-GIC
algorithm with CNN–LSTM fusion network. <em>NN</em>, <em>162</em>,
21–33. (<a href="https://doi.org/10.1016/j.neunet.2023.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the autonomous effective collision avoidance strategy for multiple unmanned aerial vehicles (multi-UAV) in limited airspace under the framework of proximal policy optimization (PPO) algorithm. An end-to-end deep reinforcement learning (DRL) control strategy and a potential-based reward function are designed. Next, the CNN-LSTM (CL) fusion network is constructed by fusing the convolutional neural network (CNN) and the long short-term memory network (LSTM), which realizes the feature interaction among the information of multi-UAV. Then, a generalized integral compensator (GIC) is introduced into the actor-critic structure, and the CLPPO-GIC algorithm is proposed by combining CL and GIC. Finally, we validate the learned policy in various simulation environments by performance evaluation. The simulation results show that the introduction of the LSTM network and GIC can further improve the efficiency of collision avoidance , and the robustness and accuracy of the algorithm are verified in different environments.},
  archive      = {J_NN},
  author       = {Chengqing Liang and Lei Liu and Chen Liu},
  doi          = {10.1016/j.neunet.2023.02.027},
  journal      = {Neural Networks},
  pages        = {21-33},
  shortjournal = {Neural Netw.},
  title        = {Multi-UAV autonomous collision avoidance based on PPO-GIC algorithm with CNN–LSTM fusion network},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ProMask: Probability mask representation for skeleton
detection. <em>NN</em>, <em>162</em>, 11–20. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting object skeletons in natural images presents challenges due to varied object scales and complex backgrounds. The skeleton is a highly compressing shape representation, which can bring some essential advantages but cause difficulties in detection. This skeleton line occupies a small part of the image and is overly sensitive to spatial position . Inspired by these issues, we propose the ProMask, which is a novel skeleton detection model. The ProMask includes the probability mask representation and vector router. This skeleton probability mask describes the gradual formation process of skeleton points , which can achieve high detection performance and robustness. Moreover, the vector router module possesses two sets of orthogonal basis vectors in a two-dimensional space, which can dynamically adjust the predicted skeleton position. Experiments show that our approach realizes better performance, efficiency, and robustness than state-of-the-art methods. We consider that our proposed skeleton probability representation will serve as a standard configuration for future skeleton detection, since it is reasonable, simple, and very effective.},
  archive      = {J_NN},
  author       = {Xiuxiu Bai and Lele Ye and Zhe Liu and Bin Liu},
  doi          = {10.1016/j.neunet.2023.02.033},
  journal      = {Neural Networks},
  pages        = {11-20},
  shortjournal = {Neural Netw.},
  title        = {ProMask: Probability mask representation for skeleton detection},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized image outpainting with u-transformer.
<em>NN</em>, <em>162</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel transformer-based generative adversarial neural network called U-Transformer for generalized image outpainting problems. Different from most present image outpainting methods conducting horizontal extrapolation, our generalized image outpainting could extrapolate visual context all-side around a given image with plausible structure and details even for complicated scenery, building, and art images. Specifically, we design a generator as an encoder-to-decoder structure embedded with the popular Swin Transformer blocks. As such, our novel neural network can better cope with image long-range dependencies which are crucially important for generalized image outpainting. We propose additionally a U-shaped structure and multi-view Temporal Spatial Predictor (TSP) module to reinforce image self-reconstruction as well as unknown-part prediction smoothly and realistically. By adjusting the predicting step in the TSP module in the testing stage, we can generate arbitrary outpainting size given the input sub-image. We experimentally demonstrate that our proposed method could produce visually appealing results for generalized image outpainting against the state-of-the-art image outpainting approaches.},
  archive      = {J_NN},
  author       = {Penglei Gao and Xi Yang and Rui Zhang and John Y. Goulermas and Yujie Geng and Yuyao Yan and Kaizhu Huang},
  doi          = {10.1016/j.neunet.2023.02.021},
  journal      = {Neural Networks},
  pages        = {1-10},
  shortjournal = {Neural Netw.},
  title        = {Generalized image outpainting with U-transformer},
  volume       = {162},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>161</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(23)00153-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00153-3},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). CURRENT EVENTS. <em>NN</em>, <em>161</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(23)00152-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00152-1},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {CURRENT EVENTS},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MonkeyNet: A robust deep convolutional neural network for
monkeypox disease detection and classification. <em>NN</em>,
<em>161</em>, 757–775. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The monkeypox virus poses a new pandemic threat while we are still recovering from COVID-19. Despite the fact that monkeypox is not as lethal and contagious as COVID-19, new patient cases are recorded every day. If preparations are not made, a global pandemic is likely. Deep learning (DL) techniques are now showing promise in medical imaging for figuring out what diseases a person has. The monkeypox virus-infected human skin and the region of the skin can be used to diagnose the monkeypox early because an image has been used to learn more about the disease. But there is still no reliable Monkeypox database that is available to the public that can be used to train and test DL models. As a result, it is essential to collect images of monkeypox patients. The “ MSID ” dataset, short form of “ Monkeypox Skin Images Dataset ”, which was developed for this research, is free to use and can be downloaded from the Mendeley Data database by anyone who wants to use it. DL models can be built and used with more confidence using the images in this dataset. These images come from a variety of open-source and online sources and can be used for research purposes without any restrictions. Furthermore, we proposed and evaluated a modified DenseNet-201 deep learning-based CNN model named MonkeyNet. Using the original and augmented datasets, this study suggested a deep convolutional neural network that was able to correctly identify monkeypox disease with an accuracy of 93.19\% and 98.91\% respectively. This implementation also shows the Grad-CAM which indicates the level of the model’s effectiveness and identifies the infected regions in each class image, which will help the clinicians. The proposed model will also help doctors make accurate early diagnoses of monkeypox disease and protect against the spread of the disease.},
  archive      = {J_NN},
  author       = {Diponkor Bala and Md. Shamim Hossain and Mohammad Alamgir Hossain and Md. Ibrahim Abdullah and Md. Mizanur Rahman and Balachandran Manavalan and Naijie Gu and Mohammad S. Islam and Zhangjin Huang},
  doi          = {10.1016/j.neunet.2023.02.022},
  journal      = {Neural Networks},
  pages        = {757-775},
  shortjournal = {Neural Netw.},
  title        = {MonkeyNet: A robust deep convolutional neural network for monkeypox disease detection and classification},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to generate tips from song reviews. <em>NN</em>,
<em>161</em>, 746–756. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reviews of songs play an important role in online music service platforms. Prior research shows that users can make quicker and more informed decisions when presented with meaningful song reviews. However, reviews of songs are generally long in length and most of them are non-informative for users. It is difficult for users to efficiently grasp meaningful messages for making decisions. To solve this problem, one practical strategy is to provide tips , i.e., short, concise, empathetic, and self-contained descriptions about songs. Tips are produced from song reviews and should express non-trivial insights about the songs. To the best of our knowledge, no prior studies have explored the tip generation task in music domain. In this paper, we create a dataset named MTips for the task and propose a learning-to-generate framework named GenTMS for automatically generating tips from song reviews. The dataset involves 8,003 Chinese tips/non-tips from 128 songs which are distributed in five different song genres. Experimental results show that GenTMS achieves top-10 precision at 85.56\%, outperforming the baseline models by at least 3.34\%. Besides, to simulate the practical usage of our proposed framework, we also experiment with previously-unseen songs, during which GenTMS also achieves the best performance with top-10 precision at 78.89\% on average. The results demonstrate the effectiveness of the proposed framework in tip generation of the music domain.},
  archive      = {J_NN},
  author       = {Jingya Zang and Cuiyun Gao and Yupan Chen and Ruifeng Xu and Lanjun Zhou and Xuan Wang},
  doi          = {10.1016/j.neunet.2023.01.049},
  journal      = {Neural Networks},
  pages        = {746-756},
  shortjournal = {Neural Netw.},
  title        = {Learning to generate tips from song reviews},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy scheduling for DoS attack over multi-hop networks:
Deep reinforcement learning approach. <em>NN</em>, <em>161</em>,
735–745. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the energy scheduling for Denial-of-Service (DoS) attack against remote state estimation over multi-hop networks. A smart sensor observes a dynamic system, and transmits its local state estimate to a remote estimator. Due to the limited communication range of the sensor, some relay nodes are employed to deliver data packets from the sensor to the remote estimator, which constitutes a multi-hop network. To maximize the estimation error covariance with energy constraint, a DoS attacker needs to determine the energy level implemented on each channel. This problem is formulated as an associated Markov decision process (MDP), and the existence of an optimal deterministic and stationary policy (DSP) is proved for the attacker. Besides, a simple threshold structure of the optimal policy is obtained, which significantly reduces the computational complexity . Furthermore, an up-to-date deep reinforcement learning (DRL) algorithm, dueling double Q Q -network (D3QN), is introduced to approximate the optimal policy . Finally, a simulation example illustrates the developed results and verifies the effectiveness of D3QN for optimal DoS attack energy scheduling.},
  archive      = {J_NN},
  author       = {Lixin Yang and Jie Tao and Yong-Hua Liu and Yong Xu and Chun-Yi Su},
  doi          = {10.1016/j.neunet.2023.02.028},
  journal      = {Neural Networks},
  pages        = {735-745},
  shortjournal = {Neural Netw.},
  title        = {Energy scheduling for DoS attack over multi-hop networks: Deep reinforcement learning approach},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partial label learning: Taxonomy, analysis and outlook.
<em>NN</em>, <em>161</em>, 708–734. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning (PLL) is an emerging framework in weakly supervised machine learning with broad application prospects. It handles the case in which each training example corresponds to a candidate label set and only one label concealed in the set is the ground-truth label. In this paper, we propose a novel taxonomy framework for PLL including four categories: disambiguation strategy, transformation strategy, theory-oriented strategy and extensions. We analyze and evaluate methods in each category and sort out synthetic and real-world PLL datasets which are all hyperlinked to the source data. Future work of PLL is profoundly discussed in this article based on the proposed taxonomy framework.},
  archive      = {J_NN},
  author       = {Yingjie Tian and Xiaotong Yu and Saiji Fu},
  doi          = {10.1016/j.neunet.2023.02.019},
  journal      = {Neural Networks},
  pages        = {708-734},
  shortjournal = {Neural Netw.},
  title        = {Partial label learning: Taxonomy, analysis and outlook},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A neurodynamic approach for nonsmooth optimal power
consumption of intelligent and connected vehicles. <em>NN</em>,
<em>161</em>, 693–707. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a class of power consumption minimization and equalization for intelligent and connected vehicles cooperative system . Accordingly, a distributed optimization problem model related to power consumption and data rate of intelligent and connected vehicles is presented, where the power consumption cost function of each intelligent and connected vehicle may be nonsmooth, and the corresponding control variable is subject to the constraints generated by data acquisition, compression coding, transmission and reception. We propose a distributed subgradient-based neurodynamic approach with projection operator to achieve the optimal power consumption of intelligent and connected vehicles. By differential inclusion and nonsmooth analysis, it is confirmed that the state solution of neurodynamic system converges to the optimal solution of the distributed optimization problem . With the help of the algorithm, all intelligent and connected vehicles asymptotically reach a consensus on an optimal power consumption. Simulation results show that the proposed neurodynamic approach is capable of effectively solving the problem of power consumption optimal control for intelligent and connected vehicles cooperative system .},
  archive      = {J_NN},
  author       = {Jingxin Liu and Xiaofeng Liao and Jin-song Dong and Amin Mansoori},
  doi          = {10.1016/j.neunet.2023.02.011},
  journal      = {Neural Networks},
  pages        = {693-707},
  shortjournal = {Neural Netw.},
  title        = {A neurodynamic approach for nonsmooth optimal power consumption of intelligent and connected vehicles},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature alignment by uncertainty and self-training for
source-free unsupervised domain adaptation. <em>NN</em>, <em>161</em>,
682–692. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most unsupervised domain adaptation (UDA) methods assume that labeled source images are available during model adaptation. However, this assumption is often infeasible owing to confidentiality issues or memory constraints on mobile devices . Some recently developed approaches do not require source images during adaptation, but they show limited performance on perturbed images. To address these problems, we propose a novel source-free UDA method that uses only a pre-trained source model and unlabeled target images. Our method captures the aleatoric uncertainty by incorporating data augmentation and trains the feature generator with two consistency objectives. The feature generator is encouraged to learn consistent visual features away from the decision boundaries of the head classifier. Thus, the adapted model becomes more robust to image perturbations. Inspired by self-supervised learning, our method promotes inter-space alignment between the prediction space and the feature space while incorporating intra-space consistency within the feature space to reduce the domain gap between the source and target domains. We also consider epistemic uncertainty to boost the model adaptation performance. Extensive experiments on popular UDA benchmark datasets demonstrate that the proposed source-free method is comparable or even superior to vanilla UDA methods. Moreover, the adapted models show more robust results when input images are perturbed.},
  archive      = {J_NN},
  author       = {JoonHo Lee and Gyemin Lee},
  doi          = {10.1016/j.neunet.2023.02.009},
  journal      = {Neural Networks},
  pages        = {682-692},
  shortjournal = {Neural Netw.},
  title        = {Feature alignment by uncertainty and self-training for source-free unsupervised domain adaptation},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TL-ADA: Transferable loss-based active domain adaptation.
<em>NN</em>, <em>161</em>, 670–681. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Active Domain Adaptation (ADA) has been investigating ways to close the performance gap between supervised and unsupervised learning settings. Previous ADA research has primarily focused on query selection, but there has been little examination of how to effectively train newly labeled target samples using both labeled source samples and unlabeled target samples. In this study, we present a novel Transferable Loss-based ADA (TL-ADA) framework. Our approach is inspired by loss-based query selection, which has shown promising results in active learning. However, directly applying loss-based query selection to the ADA scenario leads to a buildup of high-loss samples that do not contribute to the model due to transferability issues and low diversity. To address these challenges, we propose a transferable doubly nested loss, which incorporates target pseudo labels and a domain adversarial loss. Our TL-ADA framework trains the model sequentially, considering both the domain type (source/target) and the availability of labels (labeled/unlabeled). Additionally, we encourage the pseudo labels to have low self-entropy and diverse class distributions to improve their reliability. Experiments on several benchmark datasets demonstrate that our TL-ADA model outperforms previous ADA methods, and in-depth analysis supports the effectiveness of our proposed approach.},
  archive      = {J_NN},
  author       = {Kyeongtak Han and Youngeun Kim and Dongyoon Han and Hojun Lee and Sungeun Hong},
  doi          = {10.1016/j.neunet.2023.02.004},
  journal      = {Neural Networks},
  pages        = {670-681},
  shortjournal = {Neural Netw.},
  title        = {TL-ADA: Transferable loss-based active domain adaptation},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLAD: A realistic continual learning benchmark for
autonomous driving. <em>NN</em>, <em>161</em>, 659–669. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we describe the design and the ideas motivating a new Continual Learning benchmark for Autonomous Driving (CLAD), that focuses on the problems of object classification and object detection. The benchmark utilises SODA10M, a recently released large-scale dataset that concerns autonomous driving related problems. First, we review and discuss existing continual learning benchmarks, how they are related, and show that most are extreme cases of continual learning. To this end, we survey the benchmarks used in continual learning papers at three highly ranked computer vision conferences. Next, we introduce CLAD-C, an online classification benchmark realised through a chronological data stream that poses both class and domain incremental challenges; and CLAD-D, a domain incremental continual object detection benchmark. We examine the inherent difficulties and challenges posed by the benchmark, through a survey of the techniques and methods used by the top-3 participants in a CLAD-challenge workshop at ICCV 2021. We conclude with possible pathways to improve the current continual learning state of the art, and which directions we deem promising for future research.},
  archive      = {J_NN},
  author       = {Eli Verwimp and Kuo Yang and Sarah Parisot and Lanqing Hong and Steven McDonagh and Eduardo Pérez-Pellitero and Matthias De Lange and Tinne Tuytelaars},
  doi          = {10.1016/j.neunet.2023.02.001},
  journal      = {Neural Networks},
  pages        = {659-669},
  shortjournal = {Neural Netw.},
  title        = {CLAD: A realistic continual learning benchmark for autonomous driving},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonconvex low-rank tensor approximation with graph and
consistent regularizations for multi-view subspace learning.
<em>NN</em>, <em>161</em>, 638–658. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is widely used to improve clustering performance. Recently, the subspace clustering tensor learning method based on Markov chain is a crucial branch of multi-view clustering. Tensor learning is commonly used to apply tensor low-rank approximation to represent the relationships between data samples. However, most of the current tensor learning methods have the following shortcomings: the information of the local graph is not taken into account, the relationships between different views are not shown, and the existing tensor low-rank representation takes a biased tensor rank function for estimation. Therefore, a nonconvex low-rank tensor approximation with graph and consistent regularizations (NLRTGC) model is proposed for multi-view subspace learning. NLRTGC retains the local manifold information through graph regularization, and adopts a consistent regularization between multi-views to keep the diagonal block structure of representation matrices . Furthermore, a nonnegative nonconvex low-rank tensor kernel function is used to replace the existing classical tensor nuclear norm via tensor-singular value decomposition (t-SVD), so as to reduce the deviation from rank. Then, an alternating direction method of multipliers (ADMM) which makes the objective function monotonically non-increasing is proposed to solve NLRTGC. Finally, the effectiveness and superiority of the NLRTGC are shown through abundant comparative experiments with various state-of-the-art algorithms on noisy datasets and real world datasets.},
  archive      = {J_NN},
  author       = {Baicheng Pan and Chuandong Li and Hangjun Che},
  doi          = {10.1016/j.neunet.2023.02.016},
  journal      = {Neural Networks},
  pages        = {638-658},
  shortjournal = {Neural Netw.},
  title        = {Nonconvex low-rank tensor approximation with graph and consistent regularizations for multi-view subspace learning},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UDRN: Unified dimensional reduction neural network for
feature selection and feature projection. <em>NN</em>, <em>161</em>,
626–637. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensional reduction (DR) maps high-dimensional data into a lower dimensions latent space with minimized defined optimization objectives . The two independent branches of DR are feature selection (FS) and feature projection (FP). FS focuses on selecting a critical subset of dimensions but risks destroying the data distribution (structure). On the other hand, FP combines all the input features into lower dimensions space, aiming to maintain the data structure , but lacks interpretability and sparsity . Moreover, FS and FP are traditionally incompatible categories and have not been unified into an amicable framework. Therefore, we consider that the ideal DR approach combines both FS and FP into a unified end-to-end manifold learning framework, simultaneously performing fundamental feature discovery while maintaining the intrinsic relationships between data samples in the latent space. This paper proposes a unified framework named Unified Dimensional Reduction Network (UDRN) to integrate FS and FP in an end-to-end way. Furthermore, a novel network framework is designed to implement FS and FP tasks separately using a stacked feature selection network and feature projection network . In addition, a stronger manifold assumption and a novel loss function are proposed. Furthermore, the loss function can leverage the priors of data augmentation to enhance the generalization ability of the proposed UDRN. Finally, comprehensive experimental results on four image and four biological datasets, including very high-dimensional data, demonstrate the advantages of DRN over existing methods (FS, FP, and FS&amp;FP pipeline), especially in downstream tasks such as classification and visualization.},
  archive      = {J_NN},
  author       = {Zelin Zang and Yongjie Xu and Linyan Lu and Yulan Geng and Senqiao Yang and Stan Z. Li},
  doi          = {10.1016/j.neunet.2023.02.018},
  journal      = {Neural Networks},
  pages        = {626-637},
  shortjournal = {Neural Netw.},
  title        = {UDRN: Unified dimensional reduction neural network for feature selection and feature projection},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data augmentation with norm-AE and selective
pseudo-labelling for unsupervised domain adaptation. <em>NN</em>,
<em>161</em>, 614–625. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the Unsupervised Domain Adaptation (UDA) problem in image classification from a new perspective. In contrast to most existing works which either align the data distributions or learn domain-invariant features, we directly learn a unified classifier for both the source and target domains in the high-dimensional homogeneous feature space without explicit domain alignment. To this end, we employ the effective Selective Pseudo-Labelling (SPL) technique to take advantage of the unlabelled samples in the target domain. Surprisingly, data distribution discrepancy across the source and target domains can be well handled by a computationally simple classifier (e.g., a shallow Multi-Layer Perceptron) trained in the original feature space. Besides, we propose a novel generative model norm-AE to generate synthetic features for the target domain as a data augmentation strategy to enhance the classifier training. Experimental results on several benchmark datasets demonstrate the pseudo-labelling strategy itself can lead to comparable performance to many state-of-the-art methods whilst the use of norm-AE for feature augmentation can further improve the performance in most cases. As a result, our proposed methods (i.e. naive-SPL and norm-AE-SPL ) can achieve comparable performance with state-of-the-art methods with the average accuracy of 93.4\% and 90.4\% on Office-Caltech and ImageCLEF-DA datasets, and achieve competitive performance on Digits, Office31 and Office-Home datasets with the average accuracy of 97.2\%, 87.6\% and 68.6\% respectively.},
  archive      = {J_NN},
  author       = {Qian Wang and Fanlin Meng and Toby P. Breckon},
  doi          = {10.1016/j.neunet.2023.02.006},
  journal      = {Neural Networks},
  pages        = {614-625},
  shortjournal = {Neural Netw.},
  title        = {Data augmentation with norm-AE and selective pseudo-labelling for unsupervised domain adaptation},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature flow regularization: Improving structured sparsity
in deep neural networks. <em>NN</em>, <em>161</em>, 598–613. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning is a model compression method that removes redundant parameters and accelerates the inference speed of deep neural networks (DNNs) while maintaining accuracy. Most available pruning methods impose various conditions on parameters or features directly. In this paper, we propose a simple and effective regularization strategy to improve the structured sparsity and structured pruning in DNNs from a new perspective of evolution of features. In particular, we consider the trajectories connecting features of adjacent hidden layers, namely feature flow. We propose feature flow regularization (FFR) to penalize the length and the total absolute curvature of the trajectories, which implicitly increases the structured sparsity of the parameters. The principle behind FFR is that short and straight trajectories will lead to an efficient network that avoids redundant parameters. Experiments on CIFAR-10 and ImageNet datasets show that FFR improves structured sparsity and achieves pruning results comparable to or even better than those state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Yue Wu and Yuan Lan and Luchan Zhang and Yang Xiang},
  doi          = {10.1016/j.neunet.2023.02.013},
  journal      = {Neural Networks},
  pages        = {598-613},
  shortjournal = {Neural Netw.},
  title        = {Feature flow regularization: Improving structured sparsity in deep neural networks},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memory-efficient transformer-based network model for
traveling salesman problem. <em>NN</em>, <em>161</em>, 589–597. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization problems such as Traveling Salesman Problem (TSP) have a wide range of real-world applications in transportation, logistics, manufacturing. It has always been a difficult problem to solve large-scale TSP problems quickly because of memory usage limitations. Recent research shows that the Transformer model is a promising approach. However, the Transformer has several severe problems that prevent it from quickly solving TSP combinatorial optimization problems, such as quadratic time complexity , especially quadratic space complexity, and the inherent limitations of the encoder and decoder itself. To address these issues, we developed a memory-efficient Transformer-based network model for TSP combinatorial optimization problems, termed Tspformer, with two distinctive characteristics: (1) a sampled scaled dot-product attention mechanism with O ( L log ( L ) ) O(Llog(L)) (L is the length of input sequences) time and space complexity, which is the most different between our work and other works. (2) due to the reduced space complexity, GPU/CPU memory usage is significantly reduced. Extensive experiments demonstrate that Tspformer significantly outperforms existing methods and provides a new solution to the TSP combinatorial optimization problems. Our Pytorch code will be publicly available on GitHub https://github.com/yhnju/tspFormer .},
  archive      = {J_NN},
  author       = {Hua Yang and Minghao Zhao and Lei Yuan and Yang Yu and Zhenhua Li and Ming Gu},
  doi          = {10.1016/j.neunet.2023.02.014},
  journal      = {Neural Networks},
  pages        = {589-597},
  shortjournal = {Neural Netw.},
  title        = {Memory-efficient transformer-based network model for traveling salesman problem},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eigen value based loss function for training attractors in
iterated autoencoders. <em>NN</em>, <em>161</em>, 575–588. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The way that the human brain handles the input variations has been one of the most interesting areas of research for neuroscientists. There are some evidences that the human brain acts like an attractor when trying to memorize or retrieve some information. Based on this fact, in this research, a new method is presented for creating attractors during training of an iterated autoencoder . In this method a new loss function is presented which decreases the absolute real of Eigen values while preserving the reconstruction error during training. A fully connected structure is chosen for constructing the iterated autoencoder in this research which mostly faces with local minima especially when they are deep. For getting through this issue, a layer-by-layer pre-training approach is taken to train the network. Using the evaluation on MNIST dataset, it is shown that the proposed model can retrieve 59.98\% of test samples which shows a considerable improvement over Dense Associative Memory (DAM) when trained on 100 similar MNIST test samples. The performance of the proposed model is compared to overparameterized autoencoder (OAE) model which was recently presented and showed promising results in constructing associative memories. The results show that the proposed model outperforms OAE in terms of the number of attractors learned by the network in a similar number of network parameters. Finally, the performance of the proposed model is evaluated with corrupted version of training samples, revealing significant robustness when compared to the baseline autoencoder.},
  archive      = {J_NN},
  author       = {Ali Nouri and Seyyed Ali Seyyedsalehi},
  doi          = {10.1016/j.neunet.2023.02.003},
  journal      = {Neural Networks},
  pages        = {575-588},
  shortjournal = {Neural Netw.},
  title        = {Eigen value based loss function for training attractors in iterated autoencoders},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Regularizing transformers with deep probabilistic layers.
<em>NN</em>, <em>161</em>, 565–574. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language models (LM) have grown non-stop in the last decade, from sequence-to-sequence architectures to attention-based Transformers. However, regularization is not deeply studied in those structures. In this work, we use a Gaussian Mixture Variational Autoencoder (GMVAE) as a regularizer layer. We study its advantages regarding the depth where it is placed and prove its effectiveness in several scenarios. Experimental result demonstrates that the inclusion of deep generative models within Transformer-based architectures such as BERT , RoBERTa, or XLM-R can bring more versatile models, able to generalize better and achieve improved imputation score in tasks such as SST-2 and TREC or even impute missing/noisy words with richer text.},
  archive      = {J_NN},
  author       = {Aurora Cobo Aguilera and Pablo M. Olmos and Antonio Artés-Rodríguez and Fernando Pérez-Cruz},
  doi          = {10.1016/j.neunet.2023.01.032},
  journal      = {Neural Networks},
  pages        = {565-574},
  shortjournal = {Neural Netw.},
  title        = {Regularizing transformers with deep probabilistic layers},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network model for imprecise regression with interval
dependent variables. <em>NN</em>, <em>161</em>, 550–564. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a computationally feasible method to compute rigorous bounds on the interval-generalization of regression analysis to account for epistemic uncertainty in the output variables. The new iterative method uses machine learning algorithms to fit an imprecise regression model to data that consist of intervals rather than point values. The method is based on a single-layer interval neural network which can be trained to produce an interval prediction. It seeks parameters for the optimal model that minimizes the mean squared error between the actual and predicted interval values of the dependent variable using a first-order gradient-based optimization and interval analysis computations to model the measurement imprecision of the data. An additional extension to a multi-layer neural network is also presented. We consider the explanatory variables to be precise point values, but the measured dependent values are characterized by interval bounds without any probabilistic information. The proposed iterative method estimates the lower and upper bounds of the expectation region, which is an envelope of all possible precise regression lines obtained by ordinary regression analysis based on any configuration of real-valued points from the respective y y -intervals and their x x -values.},
  archive      = {J_NN},
  author       = {Krasymyr Tretiak and Georg Schollmeyer and Scott Ferson},
  doi          = {10.1016/j.neunet.2023.02.005},
  journal      = {Neural Networks},
  pages        = {550-564},
  shortjournal = {Neural Netw.},
  title        = {Neural network model for imprecise regression with interval dependent variables},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical neural network with efficient selection
inference. <em>NN</em>, <em>161</em>, 535–549. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image classification precision is vastly enhanced with the growing complexity of convolutional neural network (CNN) structures. However, the uneven visual separability between categories leads to various difficulties in classification. The hierarchical structure of categories can be leveraged to deal with it, but a few CNNs pay attention to the character of data. Besides, a network model with a hierarchical structure is promising to extract more specific features from the data than current CNNs, since, for the latter, all categories have the same fixed number of layers for feed-forward computation. In this paper, we propose to use category hierarchies to integrate ResNet-style modules to form a hierarchical network model in a top-down manner. To extract abundant discriminative features and improve the computation efficiency, we adopt residual block selection based on coarse categories to allocate different computation paths. Each residual block works as a switch to determine the JUMP or JOIN mode for an individual coarse category. Interestingly, since some categories need less feed-forward computation than others by jumping layers, the average inference time cost is reduced. Extensive experiments show that our hierarchical network achieves higher prediction accuracy with similar FLOPs on CIFAR-10 and CIFAR-100, SVHM, and Tiny-ImageNet datasets compared to original residual networks and other existing selection inference methods.},
  archive      = {J_NN},
  author       = {Jian-Xun Mi and Nuo Li and Ke-Yang Huang and Weisheng Li and Lifang Zhou},
  doi          = {10.1016/j.neunet.2023.02.015},
  journal      = {Neural Networks},
  pages        = {535-549},
  shortjournal = {Neural Netw.},
  title        = {Hierarchical neural network with efficient selection inference},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MixGradient: A gradient-based re-weighting scheme with mixup
for imbalanced data streams. <em>NN</em>, <em>161</em>, 525–534. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A challenge for contemporary deep neural networks in real-world problems is learning from an imbalanced data stream, where data tends to be received chunk by chunk over time, and the prior class distribution is severely imbalanced. Although many sophisticated algorithms have been derived, most of them overlook the importance of gradient information . From this perspective, the difficulty of learning from imbalanced data streams lies in the fact that the gradient estimated on an uneven class distribution is not informative enough to reflect the critical pattern of each class. To this end, we propose to assign higher weights on the training samples whose gradients are close to the gradient of corresponding typical samples, thus highlighting the important samples in minority classes and suppressing the noisy samples in majority classes. Such an idea can be combined with Mixup, which exploits the interpolation information of data to further compensate for the information of sample space that the typical samples do not provide and expand the role of the proposed re-weighting scheme. Experiments on artificially induced long-tailed CIFAR data streams and long-tailed MiniPlaces data stream show that the resulting method, termed MixGradient, boosts the generalization performance of DNNs under different imbalance ratios and achieves up to 10\% accuracy improvement.},
  archive      = {J_NN},
  author       = {Xinyu Peng and Fei-Yue Wang and Li Li},
  doi          = {10.1016/j.neunet.2023.02.017},
  journal      = {Neural Networks},
  pages        = {525-534},
  shortjournal = {Neural Netw.},
  title        = {MixGradient: A gradient-based re-weighting scheme with mixup for imbalanced data streams},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The role of capacity constraints in convolutional neural
networks for learning random versus natural data. <em>NN</em>,
<em>161</em>, 515–524. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are often described as promising models of human vision, yet they show many differences from human abilities. We focus on a superhuman capacity of top-performing CNNs, namely, their ability to learn very large datasets of random patterns. We verify that human learning on such tasks is extremely limited, even with few stimuli. We argue that the performance difference is due to CNNs’ overcapacity and introduce biologically inspired mechanisms to constrain it, while retaining the good test set generalisation to structured images as characteristic of CNNs. We investigate the efficacy of adding noise to hidden units’ activations, restricting early convolutional layers with a bottleneck, and using a bounded activation function . Internal noise was the most potent intervention and the only one which, by itself, could reduce random data performance in the tested models to chance levels. We also investigated whether networks with biologically inspired capacity constraints show improved generalisation to out-of-distribution stimuli, however little benefit was observed. Our results suggest that constraining networks with biologically motivated mechanisms paves the way for closer correspondence between network and human performance, but the few manipulations we have tested are only a small step towards that goal.},
  archive      = {J_NN},
  author       = {Christian Tsvetkov and Gaurav Malhotra and Benjamin D. Evans and Jeffrey S. Bowers},
  doi          = {10.1016/j.neunet.2023.01.011},
  journal      = {Neural Networks},
  pages        = {515-524},
  shortjournal = {Neural Netw.},
  title        = {The role of capacity constraints in convolutional neural networks for learning random versus natural data},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SP-GNN: Learning structure and position information from
graphs. <em>NN</em>, <em>161</em>, 505–514. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) is a powerful model for learning from graph data. However, existing GNNs may have limited expressive power , especially in terms of capturing adequate structural and positional information of input graphs. Structure properties and node position information are unique to graph-structured data, but few GNNs are capable of capturing them. This paper proposes Structure- and Position-aware Graph Neural Networks (SP-GNN) , a new class of GNNs offering generic and expressive power of graph data. SP-GNN enhances the expressive power of GNN architectures by incorporating a near-isometric proximity-aware position encoder and a scalable structure encoder. Further, given a GNN learning task, SP-GNN can be used to analyze positional and structural awareness of GNN tasks using the corresponding embeddings computed by the encoders. The awareness scores can guide fusion strategies of the extracted positional and structural information with raw features for better performance of GNNs on downstream tasks. We conduct extensive experiments using SP-GNN on various graph datasets and observe significant improvement in classification over existing GNN models.},
  archive      = {J_NN},
  author       = {Yangrui Chen and Jiaxuan You and Jun He and Yuan Lin and Yanghua Peng and Chuan Wu and Yibo Zhu},
  doi          = {10.1016/j.neunet.2023.01.051},
  journal      = {Neural Networks},
  pages        = {505-514},
  shortjournal = {Neural Netw.},
  title        = {SP-GNN: Learning structure and position information from graphs},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emphasizing unseen words: New vocabulary acquisition for
end-to-end speech recognition. <em>NN</em>, <em>161</em>, 494–504. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the dynamic nature of human language, automatic speech recognition (ASR) systems need to continuously acquire new vocabulary. Out-Of-Vocabulary (OOV) words, such as trending words and new named entities, pose problems to modern ASR systems that require long training times to adapt their large numbers of parameters. Different from most previous research focusing on language model post-processing, we tackle this problem on an earlier processing level and eliminate the bias in acoustic modeling to recognize OOV words acoustically. We propose to generate OOV words using text-to-speech systems and to rescale losses to encourage neural networks to pay more attention to OOV words. Specifically, we enlarge the classification loss used for training neural networks’ parameters of utterances containing OOV words (sentence-level), or rescale the gradient used for back-propagation for OOV words (word-level), when fine-tuning a previously trained model on synthetic audio. To overcome catastrophic forgetting, we also explore the combination of loss rescaling and model regularization , i.e. L2 regularization and elastic weight consolidation (EWC). Compared with previous methods that just fine-tune synthetic audio with EWC, the experimental results on the LibriSpeech benchmark reveal that our proposed loss rescaling approach can achieve significant improvement on the recall rate with only a slight decrease on word error rate. Moreover, word-level rescaling is more stable than utterance-level rescaling and leads to higher recall rates and precision rates on OOV word recognition. Furthermore, our proposed combined loss rescaling and weight consolidation methods can support continual learning of an ASR system.},
  archive      = {J_NN},
  author       = {Leyuan Qu and Cornelius Weber and Stefan Wermter},
  doi          = {10.1016/j.neunet.2023.01.027},
  journal      = {Neural Networks},
  pages        = {494-504},
  shortjournal = {Neural Netw.},
  title        = {Emphasizing unseen words: New vocabulary acquisition for end-to-end speech recognition},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual object detection: A review of definitions,
strategies, and challenges. <em>NN</em>, <em>161</em>, 476–493. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Continual Learning investigates the ability to learn consecutive tasks without losing performance on those previously learned. The efforts of researchers have been mainly focused on incremental classification tasks . Yet, we believe that continual object detection deserves even more attention due to its vast range of applications in robotics and autonomous vehicles. This scenario is also more complex than conventional classification, given the occurrence of instances of classes that are unknown at the time but can appear in subsequent tasks as a new class to be learned, resulting in missing annotations and conflicts with the background label. In this review, we analyze the current strategies proposed to tackle the problem of class-incremental object detection. Our main contributions are: (1) a short and systematic review of the methods that propose solutions to traditional incremental object detection scenarios; (2) A comprehensive evaluation of the existing approaches using a new metric to quantify the stability and plasticity of each technique in a standard way; (3) an overview of the current trends within continual object detection and a discussion of possible future research directions.},
  archive      = {J_NN},
  author       = {Angelo G. Menezes and Gustavo de Moura and Cézanne Alves and André C.P.L.F. de Carvalho},
  doi          = {10.1016/j.neunet.2023.01.041},
  journal      = {Neural Networks},
  pages        = {476-493},
  shortjournal = {Neural Netw.},
  title        = {Continual object detection: A review of definitions, strategies, and challenges},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid distributed finite-time neurodynamic optimization of
electric vehicle charging schemes management in microgrid considering
time-varying factors. <em>NN</em>, <em>161</em>, 466–475. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two distributed finite-time neurodynamic algorithms are proposed to collaboratively manage the charging scheme of electric vehicles (EVs) in the microgrid scenario. First, the upper level model is constructed to optimize the disorderly charging problem of EV users under private charging posts , and explore the optimal charging scheme under charging constraints and time-varying conditions to ensure the benefits of users. The lower layer model explores the optimal public charging scheme under the system operation constraint and the supply–demand balance constraint with the objective of minimizing the overall microgrid operation cost. The optimal solution of the upper model, i.e., the load of EV users under the private charging post, is considered as a parameter of the lower model. In this context, two finite-time neurodynamics with fast convergence rate, executed in a distributed manner, are proposed to track the optimal solution of the problem in real time. Furthermore, the stability and convergence in finite time of the two proposed algorithms are proved using Lyapunov theorem and finite time theorem. Numerical case studies of small-scale and large-scale power systems demonstrate the effectiveness, robustness, and real-time performance of the two proposed algorithms.},
  archive      = {J_NN},
  author       = {Haohao Qin and Gui Zhao and Yue Li and Hui Wang},
  doi          = {10.1016/j.neunet.2023.02.012},
  journal      = {Neural Networks},
  pages        = {466-475},
  shortjournal = {Neural Netw.},
  title        = {Hybrid distributed finite-time neurodynamic optimization of electric vehicle charging schemes management in microgrid considering time-varying factors},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving transparency and representational generalizability
through parallel continual learning. <em>NN</em>, <em>161</em>, 449–465.
(<a href="https://doi.org/10.1016/j.neunet.2023.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper takes a parallel learning approach in continual learning scenarios. We define parallel continual learning as learning a sequence of tasks where the data for the previous tasks, whose distribution may have shifted over time, are also available while learning new tasks. We propose a parallel continual learning method by assigning subnetworks to each task, and simultaneously training only the assigned subnetworks on their corresponding tasks. In doing so, some parts of the network will be shared across multiple tasks. This is unlike the existing literature in continual learning which aims at learning incoming tasks sequentially, with the assumption that the data for the previous tasks have a fixed distribution. Our proposed method offers promises in: (1) Transparency in the network and in the relationship across tasks by enabling examination of the learned representations by independent and shared subnetworks, (2) Representation generalizability through sharing and training subnetworks on multiple tasks simultaneously. Our analysis shows that compared to many competing approaches such as continual learning, neural architecture search, and multi-task learning, parallel continual learning is capable of learning more generalizable representations. Also, (3) Parallel continual learning overcomes the common issue of catastrophic forgetting in continual learning algorithms. This is the first effort to train a neural network on multiple tasks and input domains simultaneously in a continual learning scenario. Our code is available at https://github.com/yours-anonym/PaRT .},
  archive      = {J_NN},
  author       = {Mahsa Paknezhad and Hamsawardhini Rengarajan and Chenghao Yuan and Sujanya Suresh and Manas Gupta and Savitha Ramasamy and Hwee Kuan Lee},
  doi          = {10.1016/j.neunet.2023.02.007},
  journal      = {Neural Networks},
  pages        = {449-465},
  shortjournal = {Neural Netw.},
  title        = {Improving transparency and representational generalizability through parallel continual learning},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bat algorithm based control to decrease the control energy
consumption and modified bat algorithm based control to increase the
trajectory tracking accuracy in robots. <em>NN</em>, <em>161</em>,
437–448. (<a
href="https://doi.org/10.1016/j.neunet.2023.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the control theory , the best control gain produces a balance between the trajectory tracking accuracy and control energy consumption. The random search of the bat algorithm is one alternative to find the best control gain. In this paper, (1) a bat algorithm based control is proposed to decrease the control energy consumption in robots, where a bat algorithm is used to find the best control gain; and (2) a modified bat algorithm based control is proposed to increase the trajectory tracking accuracy in robots, where a modified bat algorithm is used to find the best control gain. The comparison between the two proposed controls and the simplex based control is illustrated for the trajectory tracking accuracy and control energy consumption in two robots.},
  archive      = {J_NN},
  author       = {José de Jesús Rubio},
  doi          = {10.1016/j.neunet.2023.02.010},
  journal      = {Neural Networks},
  pages        = {437-448},
  shortjournal = {Neural Netw.},
  title        = {Bat algorithm based control to decrease the control energy consumption and modified bat algorithm based control to increase the trajectory tracking accuracy in robots},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SuperFormer: Continual learning superposition method for
text classification. <em>NN</em>, <em>161</em>, 418–436. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the biggest challenges in continual learning domains is the tendency of machine learning models to forget previously learned information over time. While overcoming this issue, the existing approaches often exploit large amounts of additional memory and apply model forgetting mitigation mechanisms which substantially prolong the training process. Therefore, we propose a novel SuperFormer method that alleviates model forgetting, while spending negligible additional memory and time. We tackle the continual learning challenges in a learning scenario, where we learn different tasks in a sequential order. We compare our method against several prominent continual learning methods, i.e., EWC, SI, MAS, GEM , PSP , etc. on a set of text classification tasks . We achieve the best average performance in terms of AUROC and AUPRC (0.7\% and 0.9\% gain on average, respectively) and the lowest training time among all the methods of comparison. On average, our method reduces the total training time by a factor of 5.4-8.5 in comparison to similarly performing methods. In terms of the additional memory, our method is on par with the most memory-efficient approaches.},
  archive      = {J_NN},
  author       = {Marko Zeman and Jana Faganeli Pucer and Igor Kononenko and Zoran Bosnić},
  doi          = {10.1016/j.neunet.2023.01.040},
  journal      = {Neural Networks},
  pages        = {418-436},
  shortjournal = {Neural Netw.},
  title        = {SuperFormer: Continual learning superposition method for text classification},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPGE and RootRank: A sufficient root cause characterization
and quantification framework for industrial process faults. <em>NN</em>,
<em>161</em>, 397–417. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Root cause diagnosis can locate abnormalities of industrial processes, ensuring production safety and manufacturing efficiency. However, existing root cause diagnosis models only consider pairwise direct causality and ignore the multi-level fault propagation, which may lead to incomplete root cause descriptions and ambiguous root cause candidates. To address the above issue, a novel framework, named multi-level predictive graph extraction (MPGE) and RootRank scoring, is proposed and applied to the root cause diagnosis for industrial processes. In this framework, both direct and indirect Granger causalities are characterized by multi-level predictive relationships to provide a sufficient characterization of root cause variables. First, a predictive graph structure with a sparse constrained adjacency matrix is constructed to describe the information transmission between variables. The information of variables is deeply fused according to the adjacency matrix to consider multi-level fault propagation. Then, a hierarchical adjacency pruning (HAP) mechanism is designed to automatically capture vital predictive relationships through adjacency redistribution. In this way, the multi-level causalities between variables are extracted to fully describe both direct and indirect fault propagation and highlight the root cause. Further, a RootRank scoring algorithm is proposed to analyze the predictive graph and quantify the fault propagation contribution of each variable, thereby giving definite root cause identification results. Three examples are adopted to verify the diagnostic performance of the proposed framework, including a numerical example, the Tennessee Eastman benchmark process, and a real cut-made process of cigarette. Both theoretical analysis and experimental verification show the high interpretability and reliability of the proposed framework.},
  archive      = {J_NN},
  author       = {Pengyu Song and Chunhui Zhao and Biao Huang},
  doi          = {10.1016/j.neunet.2023.01.030},
  journal      = {Neural Networks},
  pages        = {397-417},
  shortjournal = {Neural Netw.},
  title        = {MPGE and RootRank: A sufficient root cause characterization and quantification framework for industrial process faults},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). U-SPDNet: An SPD manifold learning-based neural network for
visual classification. <em>NN</em>, <em>161</em>, 382–396. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of neural networking techniques, several architectures for symmetric positive definite (SPD) matrix learning have recently been put forward in the computer vision and pattern recognition (CV&amp;PR) community for mining fine-grained geometric features . However, the degradation of structural information during multi-stage feature transformation limits their capacity. To cope with this issue, this paper develops a U-shaped neural network on the SPD manifolds (U-SPDNet) for visual classification. The designed U-SPDNet contains two subsystems, one of which is a shrinking path (encoder) making up of a prevailing SPD manifold neural network (SPDNet (Huang and Van Gool, 2017)) for capturing compact representations from the input data. Another is a constructed symmetric expanding path (decoder) to upsample the encoded features, trained by a reconstruction error term. With this design, the degradation problem will be gradually alleviated during training. To enhance the representational capacity of U-SPDNet, we also append skip connections from encoder to decoder, realized by manifold-valued geometric operations, namely Riemannian barycenter and Riemannian optimization. On the MDSD, Virus, FPHA, and UAV-Human datasets, the accuracy achieved by our method is respectively 6.92\%, 8.67\%, 1.57\%, and 1.08\% higher than SPDNet, certifying its effectiveness.},
  archive      = {J_NN},
  author       = {Rui Wang and Xiao-Jun Wu and Tianyang Xu and Cong Hu and Josef Kittler},
  doi          = {10.1016/j.neunet.2022.11.030},
  journal      = {Neural Networks},
  pages        = {382-396},
  shortjournal = {Neural Netw.},
  title        = {U-SPDNet: An SPD manifold learning-based neural network for visual classification},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot link prediction for temporal knowledge graphs based
on time-aware translation and attention mechanism. <em>NN</em>,
<em>161</em>, 371–381. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot knowledge graph completion (KGC) is an important and common task in real applications, which aims to predict unseen facts when only few samples are available for each relation in the knowledge graph (KG). Previous methods on few-shot KGC mainly focus on static KG, however, many KG in real-world applications are dynamic and develop over time. In this work, we consider few-shot KGC in temporal knowledge graphs (TKGs), where the fact may only hold for a specific timestamp. We propose a Few-Shot Completion model in TKG (TFSC), which compare the input query to the given few-shot references to make predictions. Specifically, in order to enhance the representation of entities in the case of few samples, we use the attention mechanism to model the neighbor entities of the task entity with timestamp information , and generate expressive time-aware entity pair representations through the Transformer encoder. A comprehensive set of experiments is finally carried out to demonstrate the effectiveness a of our proposed model TFSC.},
  archive      = {J_NN},
  author       = {Han Zhang and Luyi Bai},
  doi          = {10.1016/j.neunet.2023.01.043},
  journal      = {Neural Networks},
  pages        = {371-381},
  shortjournal = {Neural Netw.},
  title        = {Few-shot link prediction for temporal knowledge graphs based on time-aware translation and attention mechanism},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video summarization for event-centric videos. <em>NN</em>,
<em>161</em>, 359–370. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization has long been used to ease video browsing and plays a more crucial role with the explosion of online videos. In the context of event-centric videos, we aim to extract the corresponding clips of more important events in the video. To tackle the dilemma between the detection precision and the clip completeness faced by previous methods, we present an efficient B oundary- A ware framework for S ummary clip E xtraction ( BASE ) to extract summary clips with more precise boundaries while maintaining their completeness. Specifically, we propose a new distance-based importance signal to reflect the progress information in each video. The signal can not only help us to detect boundaries with higher precision, but also make it possible to preserve the clip completeness. For the feature presentation part, we also explore new information types to facilitate video summarization. Our approach outperforms current state-of-the-art video summarization models in terms of more precise clip boundaries and more complete summary clips. Note that we even yield comparable results to manual annotations.},
  archive      = {J_NN},
  author       = {Qingwen Li and Jianni Chen and Qiqin Xie and Xiao Han},
  doi          = {10.1016/j.neunet.2023.01.047},
  journal      = {Neural Networks},
  pages        = {359-370},
  shortjournal = {Neural Netw.},
  title        = {Video summarization for event-centric videos},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-relational graph convolutional networks:
Generalization guarantees and experiments. <em>NN</em>, <em>161</em>,
343–358. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class of multi-relational graph convolutional networks (MRGCNs) is a recent extension of standard graph convolutional networks (GCNs) to handle heterogenous graphs with multiple types of relationships. MRGCNs have been shown to yield results superior than traditional GCNs in various machine learning tasks. The key idea is to introduce a new kind of convolution operated on tensors that can effectively exploit correlations exhibited in multiple relationships. The main objective of this paper is to analyze the algorithmic stability and generalization guarantees of MRGCNs to confirm the usefulness of MRGCNs. Our contributions are of three folds. First, we develop a matrix representation of various tensor operations underneath MRGCNs to simplify the analysis significantly. Next, we prove the uniform stability of MRGCNs and deduce the convergence of the generalization gap to support the usefulness of MRGCNs. The analysis sheds lights on the design of MRGCNs, for instance, how the data should be scaled to achieve the uniform stability of the learning process. Finally, we provide experimental results to demonstrate the stability results.},
  archive      = {J_NN},
  author       = {Xutao Li and Michael K. Ng and Guangning Xu and Andy Yip},
  doi          = {10.1016/j.neunet.2023.01.044},
  journal      = {Neural Networks},
  pages        = {343-358},
  shortjournal = {Neural Netw.},
  title        = {Multi-relational graph convolutional networks: Generalization guarantees and experiments},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximating nash equilibrium for anti-UAV jamming markov
game using a novel event-triggered multi-agent reinforcement learning.
<em>NN</em>, <em>161</em>, 330–342. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the downlink communication, it is currently challenging for ground users to cope with the uncertain interference from aerial intelligent jammers . The cooperation and competition between ground users and unmanned aerial vehicle (UAV) jammers leads to a Markov game problem of anti-UAV jamming. Therefore, a model-free method is adopted based on multi-agent reinforcement learning (MARL) to handle the Markov game. However, the benchmark MARL strategies suffer from dimension explosion and local optimal convergence. To solve these issues, a novel event-triggered multi-agent proximal policy optimization algorithm with Beta strategy (ETMAPPO) is proposed in this paper, which aims to reduce the dimension of information transmission and improve the efficiency of policy convergence. In this event-triggering mechanism, agents can learn to obtain appropriate observation in different moment, thereby reducing the transmission of valueless information. Beta operator is used to optimize the action search. It expands the search scope of policy space. Ablation simulations show that the proposed strategy achieves better global benefits with fewer dimension of information than benchmark algorithms. In addition, the convergence performance verifies that the well-trained ETMAPPO has the capability to achieve stable jamming strategies and stable anti-jamming strategies. This approximately constitutes the Nash equilibrium of the anti-jamming Markov game.},
  archive      = {J_NN},
  author       = {Zikai Feng and Mengxing Huang and Yuanyuan Wu and Di Wu and Jinde Cao and Iakov Korovin and Sergey Gorbachev and Nadezhda Gorbacheva},
  doi          = {10.1016/j.neunet.2022.12.022},
  journal      = {Neural Networks},
  pages        = {330-342},
  shortjournal = {Neural Netw.},
  title        = {Approximating nash equilibrium for anti-UAV jamming markov game using a novel event-triggered multi-agent reinforcement learning},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CrimeNet: Neural structured learning using vision
transformer for violence detection. <em>NN</em>, <em>161</em>, 318–329.
(<a href="https://doi.org/10.1016/j.neunet.2023.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state of the art in violence detection in videos has improved in recent years thanks to deep learning models, but it is still below 90\% of average precision in the most complex datasets, which may pose a problem of frequent false alarms in video surveillance environments and may cause security guards to disable the artificial intelligence system. In this study, we propose a new neural network based on Vision Transformer (ViT) and Neural Structured Learning (NSL) with adversarial training . This network, called CrimeNet, outperforms previous works by a large margin and reduces practically to zero the false positives . Our tests on the four most challenging violence-related datasets (binary and multi-class) show the effectiveness of CrimeNet, improving the state of the art from 9.4 to 22.17 percentage points in ROC AUC depending on the dataset. In addition, we present a generalisation study on our model by training and testing it on different datasets. The obtained results show that CrimeNet improves over competing methods with a gain of between 12.39 and 25.22 percentage points, showing remarkable robustness.},
  archive      = {J_NN},
  author       = {Fernando J. Rendón-Segador and Juan A. Álvarez-García and Jose L. Salazar-González and Tatiana Tommasi},
  doi          = {10.1016/j.neunet.2023.01.048},
  journal      = {Neural Networks},
  pages        = {318-329},
  shortjournal = {Neural Netw.},
  title        = {CrimeNet: Neural structured learning using vision transformer for violence detection},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature relocation network for fine-grained image
classification. <em>NN</em>, <em>161</em>, 306–317. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fine-grained image classification , there are only very subtle differences between classes. It is challenging to learn local discriminative features and remove distractive features in fine-grained image classification . Existing fine-grained image classification methods learn discriminative feature mainly via manual part annotation or attention mechanisms . However, due to the large intraclass variance and interclass similarity, the discriminative information and distractive information still are not distinguished effectively. To address this problem, we propose a feature relocation network (FRe-Net) which takes advantage of the different natures of features learned from different stages of the network. Our network consists of a distractive feature learning module and a relocated high-level feature learning module. In the distractive feature learning module, we propose to exploit the difference between low-level features and high-level features to design a distractive loss L d i s t r a c t i v e Ldistractive , which guides the attention to locate distractive regions more accurately. In the relocated high-level feature learning module, we enhance the representing capacity of the middle-level feature via the attention module and subtract the distractive feature learned from the distractive feature learning module in order to learn more local discriminative features . In end-to-end model training, the distractive feature learning module and the relocated high-level feature learning module are beneficial to each other via joint optimization. We conducted comprehensive experiments on three benchmark datasets widely used in fine-grained image classification. The experimental results show that FRe-Net achieves state-of-the-art performance, which validates the effectiveness of FRe-Net.},
  archive      = {J_NN},
  author       = {Peng Zhao and Yi Li and Baowei Tang and Huiting Liu and Sheng Yao},
  doi          = {10.1016/j.neunet.2023.01.050},
  journal      = {Neural Networks},
  pages        = {306-317},
  shortjournal = {Neural Netw.},
  title        = {Feature relocation network for fine-grained image classification},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BalanceHRNet: An effective network for bottom-up human pose
estimation. <em>NN</em>, <em>161</em>, 297–305. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study of human pose estimation, which is widely used in safety and sports scenes, the performance of deep learning methods is greatly reduced in high overlap rate and crowded scenes. Therefore, we propose a bottom-up model, called BalanceHRNet, which is based on balanced high-resolution module and a new branch attention module. BalanceHRNet draws on the multi-branch structure and fusion method of a popular model HigherHRNet. And our model overcomes the shortcoming of HigherHRNet that cannot obtain a large enough receptive field. Specifically, through the connecting structure in balanced high-resolution module, we can connect almost all convolutional layers and obtain a sufficiently large receptive field. At the same time, the multi-resolution representation can be maintained due to the use of balanced high-resolution module, which enable our model to recognize objects with richer scales and obtain more complex semantics information. And for branch fusion method, we design branch attention to obtain the importance of different branches at different stages. Finally, our model improves the accuracy while ensuring a smaller amount of computation than HigherHRNet. The CrowdPose dataset is used as test dataset , and HigherHRNet, AlphaPose, OpenPose and so on are taken as comparison models. The AP measured by BalanceHRNet is 63.0\%, increased by 3.1\% compared to best model — HigherHRNet. We also demonstrate the effectiveness of our network through the COCO(2017) keypoint detection dataset. Compared with HigherHRNet-w32, the AP of our model is improved by 1.6\%.},
  archive      = {J_NN},
  author       = {Yaoping Li and Shuangcheng Jia and Qian Li},
  doi          = {10.1016/j.neunet.2023.01.036},
  journal      = {Neural Networks},
  pages        = {297-305},
  shortjournal = {Neural Netw.},
  title        = {BalanceHRNet: An effective network for bottom-up human pose estimation},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative modular reinforcement learning for large
discrete action space problem. <em>NN</em>, <em>161</em>, 281–296. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has achieved remarkable results on high-dimension state tasks. However, it suffers in hard convergence and low sample efficiency when solving large discrete action space problems. To meet these challenges, we develop a cooperative modular reinforcement learning (CMRL) method to distributedly solve the problems with a large discrete action space. A general yet effective task decomposition method is proposed to decompose the complex decision task in a large action space into multiple decision sub-tasks in small action subsets, using a rule-based action division method. The CMRL method consisting of multiple Critic networks is proposed to settle the multiple sub-tasks, where each Critic network learns a decomposed value function to obtain the local optimal action in a sub-task. The global optimal action is cooperatively chosen by all local optimal actions. Moreover, we propose a new parallel training mechanism, which trains multiple Critic networks with different models and multi-data in parallel. Mathematical properties are proposed to analyze the rationality and superiority of CMRL. Four different simulation experiments are conducted to verify the generality and effectiveness of CMRL for large action space problems. The results show that CMRL has superior performance on training efficiency compared with classical and latest DRL methods while maintaining the accuracy of the solution.},
  archive      = {J_NN},
  author       = {Fangzhu Ming and Feng Gao and Kun Liu and Chengmei Zhao},
  doi          = {10.1016/j.neunet.2023.01.046},
  journal      = {Neural Networks},
  pages        = {281-296},
  shortjournal = {Neural Netw.},
  title        = {Cooperative modular reinforcement learning for large discrete action space problem},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IASA: An IoU-aware tracker with adaptive sample assignment.
<em>NN</em>, <em>161</em>, 267–280. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of existing trackers develop tracking in a tracking head network, which is composed of classification branch and regression branch. However, they lack a meaningful exploration of how to define positive and negative samples during training, which can significantly affect tracking performance. Furthermore, they cannot provide a reliable ranking by using classification scores or a combination of classification and regression scores to obtain candidate locations. To address these issues, we propose an intersection over union (IoU) aware tracker with adaptive sample assignment (IASA). The IASA introduces an IoU-aware classification score to achieve a more accurate ranking for candidate tracking locations . We also propose a new loss function, IoU-focal loss , to train the anchor-free tracker IASA to predict the classification scores and introduce a star-shaped box feature representation to refine classification features. To explore the actual content of the training samples, we develop an adaptive sample assignment (ASA) strategy to divide the positive and negative samples according to the statistical characteristics of the sample IoUs. By combining these two proposed components, the IASA tracker treats the tracking task as a classification and a regression problem . It directly finds the candidate tracking location in the classification branch and then regresses the four distances from the location to the four sides of the tracking box. Experimental results show that the proposed IASA can achieve state-of-the-art performance on seven public datasets.},
  archive      = {J_NN},
  author       = {Kai Yang and Haijun Zhang and Dongliang Zhou and Li Dong and Jianghong Ma},
  doi          = {10.1016/j.neunet.2023.01.038},
  journal      = {Neural Networks},
  pages        = {267-280},
  shortjournal = {Neural Netw.},
  title        = {IASA: An IoU-aware tracker with adaptive sample assignment},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning matrix factorization with scalable distance metric
and regularizer. <em>NN</em>, <em>161</em>, 254–266. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization has always been an encouraging field, which attempts to extract discriminative features from high-dimensional data. However, it suffers from negative generalization ability and high computational complexity when handling large-scale data. In this paper, we propose a learnable deep matrix factorization via the projected gradient descent method , which learns multi-layer low-rank factors from scalable metric distances and flexible regularizers. Accordingly, solving a constrained matrix factorization problem is equivalently transformed into training a neural network with an appropriate activation function induced from the projection onto a feasible set. Distinct from other neural networks, the proposed method activates the connected weights not just the hidden layers. As a result, it is proved that the proposed method can learn several existing well-known matrix factorizations, including singular value decomposition, convex, nonnegative and semi-nonnegative matrix factorizations. Finally, comprehensive experiments demonstrate the superiority of the proposed method against other state-of-the-arts.},
  archive      = {J_NN},
  author       = {Shiping Wang and Yunhe Zhang and Xincan Lin and Lichao Su and Guobao Xiao and William Zhu and Yiqing Shi},
  doi          = {10.1016/j.neunet.2023.01.034},
  journal      = {Neural Networks},
  pages        = {254-266},
  shortjournal = {Neural Netw.},
  title        = {Learning matrix factorization with scalable distance metric and regularizer},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simultaneous approximation of a smooth function and its
derivatives by deep neural networks with piecewise-polynomial
activations. <em>NN</em>, <em>161</em>, 242–253. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the approximation properties of deep neural networks with piecewise-polynomial activation functions . We derive the required depth, width, and sparsity of a deep neural network to approximate any Hölder smooth function up to a given approximation error in Hölder norms in such a way that all weights of this neural network are bounded by 1. The latter feature is essential to control generalization errors in many statistical and machine learning applications.},
  archive      = {J_NN},
  author       = {Denis Belomestny and Alexey Naumov and Nikita Puchkin and Sergey Samsonov},
  doi          = {10.1016/j.neunet.2023.01.035},
  journal      = {Neural Networks},
  pages        = {242-253},
  shortjournal = {Neural Netw.},
  title        = {Simultaneous approximation of a smooth function and its derivatives by deep neural networks with piecewise-polynomial activations},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving efficient interpretability of reinforcement
learning via policy distillation and selective input gradient
regularization. <em>NN</em>, <em>161</em>, 228–241. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep Reinforcement Learning (RL) has proven successful in a wide range of tasks, one challenge it faces is interpretability when applied to real-world problems. Saliency maps are frequently used to provide interpretability for deep neural networks . However, in the RL domain, existing saliency map approaches are either computationally expensive and thus cannot satisfy the real-time requirement of real-world scenarios or cannot produce interpretable saliency maps for RL policies. In this work, we propose an approach of Distillation with selective Input Gradient Regularization (DIGR) which uses policy distillation and input gradient regularization to produce new policies that achieve both high interpretability and computation efficiency in generating saliency maps. Our approach is also found to improve the robustness of RL policies to multiple adversarial attacks . We conduct experiments on three tasks, MiniGrid (Fetch Object), Atari (Breakout) and CARLA Autonomous Driving , to demonstrate the importance and effectiveness of our approach.},
  archive      = {J_NN},
  author       = {Jinwei Xing and Takashi Nagata and Xinyun Zou and Emre Neftci and Jeffrey L. Krichmar},
  doi          = {10.1016/j.neunet.2023.01.025},
  journal      = {Neural Networks},
  pages        = {228-241},
  shortjournal = {Neural Netw.},
  title        = {Achieving efficient interpretability of reinforcement learning via policy distillation and selective input gradient regularization},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain adaptive object detection with model-agnostic
knowledge transferring. <em>NN</em>, <em>161</em>, 213–227. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of deep learning techniques has greatly benefited CNN-based object detectors, leading to unprecedented progress in recent years. However, the distribution variance between training and testing domains causes significant performance degradation . Labeling data for new scenarios is costly and time-consuming, so most existing domain adaptation methods perform feature alignment through adversarial training . While this can improve the accuracy of detectors in unlabeled target domains, the unconstrained domain alignment also negatively transfers the feature distribution, which compromises the recognition ability of the model. To address this problem, we propose the Knowledge Transfer Network (KTNet), which consists of object intrinsic knowledge mining and category relational knowledge constraint modules. Specifically, a binary classifier shared by the source and target domains is designed to extract common attribute knowledge of objects, which can align foreground and background features from different data domains adaptively. Then, we construct relational knowledge graphs to explicitly constrain the category correlations in the source, target, and cross-domain settings. These two modules guide the detector to learn object-related and domain-invariant representations, enabling the proposed KTNet to perform well in four commonly-used cross-domain scenarios. Furthermore, the ablation experiments show that our method is scalable to more complex backbone networks and different detection architectures.},
  archive      = {J_NN},
  author       = {Kun Tian and Chenghao Zhang and Ying Wang and Shiming Xiang},
  doi          = {10.1016/j.neunet.2023.01.028},
  journal      = {Neural Networks},
  pages        = {213-227},
  shortjournal = {Neural Netw.},
  title        = {Domain adaptive object detection with model-agnostic knowledge transferring},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging joint incremental learning objective with data
ensemble for class incremental learning. <em>NN</em>, <em>161</em>,
202–212. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class-incremental learning problem is characterized by training data becoming available in a phase-by-phase manner. Deep learning models suffer from catastrophic forgetting of the classes in the older phases as they get trained on the classes introduced in the new phase. In this work, we show that the change in orientation of an image has a considerable effect on the model prediction accuracy, which in turn demonstrates the different rates of catastrophic forgetting for the different orientations of the same image, which is a novel finding. Based on this, we propose a data-ensemble approach that combines the predictions for the different orientations of the image to help the model retain information regarding the previously seen classes and thereby reduce the rate of forgetting in the model predictions. However, we cannot directly use the data-ensemble approach if the model is trained using traditional techniques. Therefore, we also propose a novel training approach using a joint-incremental learning objective (JILO) that involves jointly training the network with two incremental learning objectives, i.e., the class-incremental learning objective and our proposed data-incremental learning objective. We empirically demonstrate that JILO is vital to the data-ensemble approach. We apply our proposed approach to state-of-the-art class-incremental learning methods and empirically show that our approach significantly improves the performance of these methods. Our proposed approach significantly improves the performance of the state-of-the-art method (AANets) on the CIFAR-100 dataset by absolute margins of 3.30\%, 4.28\%, 3.55\%, 4.03\%, for the number of phases P = = 50, 25, 10, and 5, respectively, which establishes the efficacy of the proposed work.},
  archive      = {J_NN},
  author       = {Pratik Mazumder and Mohammed Asad Karim and Indu Joshi and Pravendra Singh},
  doi          = {10.1016/j.neunet.2023.01.017},
  journal      = {Neural Networks},
  pages        = {202-212},
  shortjournal = {Neural Netw.},
  title        = {Leveraging joint incremental learning objective with data ensemble for class incremental learning},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating gradient descent and adam via fractional
gradients. <em>NN</em>, <em>161</em>, 185–201. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a class of novel fractional-order optimization algorithms . We define a fractional-order gradient via the Caputo fractional derivatives that generalizes integer-order gradient. We refer it to as the Caputo fractional-based gradient, and develop an efficient implementation to compute it. A general class of fractional-order optimization methods is then obtained by replacing integer-order gradients with the Caputo fractional-based gradients. To give concrete algorithms, we consider gradient descent (GD) and Adam, and extend them to the Caputo fractional GD ( CfGD ) and the Caputo fractional Adam ( CfAdam ). We demonstrate the superiority of CfGD and CfAdam on several large scale optimization problems that arise from scientific machine learning applications, such as ill-conditioned least squares problem on real-world data and the training of neural networks involving non-convex objective functions. Numerical examples show that both CfGD and CfAdam result in acceleration over GD and Adam, respectively. We also derive error bounds of CfGD for quadratic functions , which further indicate that CfGD could mitigate the dependence on the condition number in the rate of convergence and results in significant acceleration over GD.},
  archive      = {J_NN},
  author       = {Yeonjong Shin and Jérôme Darbon and George Em Karniadakis},
  doi          = {10.1016/j.neunet.2023.01.002},
  journal      = {Neural Networks},
  pages        = {185-201},
  shortjournal = {Neural Netw.},
  title        = {Accelerating gradient descent and adam via fractional gradients},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VISAL—a novel learning strategy to address class imbalance.
<em>NN</em>, <em>161</em>, 178–184. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the imbalance data scenarios, Deep Neural Networks (DNNs) fail to generalize well on minority classes. In this letter, we propose a simple and effective learning function i.e, Visually Interpretable Space Adjustment Learning (VISAL) to handle the imbalanced data classification task . VISAL’s objective is to create more room for the generalization of minority class samples by bringing in both the angular and euclidean margins into the cross-entropy learning strategy. When evaluated on the imbalanced versions of CIFAR, Tiny ImageNet, COVIDx and IMDB reviews datasets, our proposed method outperforms the state of the art works by a significant margin.},
  archive      = {J_NN},
  author       = {Sree Rama Vamsidhar S. and Arun Kumar Sivapuram and Vaishnavi Ravi and Gowtham Senthil and Rama Krishna Gorthi},
  doi          = {10.1016/j.neunet.2023.01.015},
  journal      = {Neural Networks},
  pages        = {178-184},
  shortjournal = {Neural Netw.},
  title        = {VISAL—A novel learning strategy to address class imbalance},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective low-rank compression with a joint rank
selection followed by a compression-friendly training. <em>NN</em>,
<em>161</em>, 165–177. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank compression of a neural network is one of the popular compression techniques , where it has been known to have two main challenges. The first challenge is determining the optimal rank of all the layers and the second is training the neural network into a compression-friendly form. To overcome the two challenges, we propose BSR (Beam-search and Stable Rank), a low-rank compression algorithm that embodies an efficient rank-selection method and a unique compression-friendly training method. For the rank selection, BSR employs a modified beam search that can perform a joint optimization of the rank allocations over all the layers in contrast to the previously used heuristic methods . For the compression-friendly training, BSR adopts a regularization loss derived from a modified stable rank, which can control the rank while incurring almost no harm in performance. Experiment results confirm that BSR is effective and superior when compared to the existing low-rank compression methods . For CIFAR10 on ResNet56, BSR not only achieves compression but also provides a performance improvement over the baseline model’s performance for the compression ratio of up to 0.82. For CIFAR100 on ResNet56 and ImageNet on AlexNet, BSR outperforms the previous SOTA method, LC, by 4.7\% and by 6.7\% on the average, respectively. BSR is also effective for EfficientNet-B0 and MobileNetV2 that are known for their efficient design in terms of parameters and computational cost. We also show that BSR provides a competitive performance when compared with the recent pruning compression algorithms. As with pruning, BSR can be easily combined with quantization for an additional compression.},
  archive      = {J_NN},
  author       = {Moonjung Eo and Suhyun Kang and Wonjong Rhee},
  doi          = {10.1016/j.neunet.2023.01.024},
  journal      = {Neural Networks},
  pages        = {165-177},
  shortjournal = {Neural Netw.},
  title        = {An effective low-rank compression with a joint rank selection followed by a compression-friendly training},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A feedforward unitary equivariant neural network.
<em>NN</em>, <em>161</em>, 154–164. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise a new type of feedforward neural network . It is equivariant with respect to the unitary group U ( n ) U(n) . The input and output can be vectors in ℂ n ℂn with arbitrary dimension n n . No convolution layer is required in our implementation. We avoid errors due to truncated higher order terms in Fourier-like transformation. The implementation of each layer can be done efficiently using simple calculations. As a proof of concept , we have given empirical results on the prediction of the dynamics of atomic motion to demonstrate the practicality of our approach.},
  archive      = {J_NN},
  author       = {Pui-Wai Ma and T.-H. Hubert Chan},
  doi          = {10.1016/j.neunet.2023.01.042},
  journal      = {Neural Networks},
  pages        = {154-164},
  shortjournal = {Neural Netw.},
  title        = {A feedforward unitary equivariant neural network},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fractional derivative based weighted skip connections for
satellite image road segmentation. <em>NN</em>, <em>161</em>, 142–153.
(<a href="https://doi.org/10.1016/j.neunet.2023.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of a road portion from a satellite image is challenging due to its complex background, occlusion, shadows, clouds, and other optical artifacts. One must combine both local and global cues for an accurate and continuous/connected road network extraction. This paper proposes a model using fractional derivative-based weighted skip connections on a densely connected convolutional neural network for road segmentation. Weights corresponding to the skip connections are determined using Grunwald–Letnikov fractional derivative . Fractional derivatives being non-local in nature incorporates memory into the system and thereby combine both local and global features. Experiments have been performed on two open source widely used benchmark databases v i z viz . Massachusetts Road database (MRD) and Ottawa Road database (ORD). Both these datasets represent different road topography and network structure including varying road widths and complexities. Result reveals that the proposed system demonstrated better performance than the other state-of-the-art methods by achieving an F1-score of 0.748 and the mIoU of 0.787 at fractional order 0.4 on the MRD and a mIoU of 0.9062 at fractional order 0.5 on the ORD.},
  archive      = {J_NN},
  author       = {Sugandha Arora and Harsh Kumar Suman and Trilok Mathur and Hari Mohan Pandey and Kamlesh Tiwari},
  doi          = {10.1016/j.neunet.2023.01.031},
  journal      = {Neural Networks},
  pages        = {142-153},
  shortjournal = {Neural Netw.},
  title        = {Fractional derivative based weighted skip connections for satellite image road segmentation},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximation bounds for convolutional neural networks in
operator learning. <em>NN</em>, <em>161</em>, 129–141. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep Convolutional Neural Networks (CNNs) have proven to be successful when employed in areas such as reduced order modeling of parametrized PDEs . Despite their accuracy and efficiency, the approaches available in the literature still lack a rigorous justification on their mathematical foundations. Motivated by this fact, in this paper we derive rigorous error bounds for the approximation of nonlinear operators by means of CNN models. More precisely, we address the case in which an operator maps a finite dimensional input μ ∈ R p μ∈Rp onto a functional output u μ : [ 0 , 1 ] d → R uμ:[0,1]d→R , and a neural network model is used to approximate a discretized version of the input-to-output map. The resulting error estimates provide a clear interpretation of the hyperparameters defining the neural network architecture. All the proofs are constructive, and they ultimately reveal a deep connection between CNNs and the Fourier transform . Finally, we complement the derived error bounds by numerical experiments that illustrate their application.},
  archive      = {J_NN},
  author       = {Nicola Rares Franco and Stefania Fresca and Andrea Manzoni and Paolo Zunino},
  doi          = {10.1016/j.neunet.2023.01.029},
  journal      = {Neural Networks},
  pages        = {129-141},
  shortjournal = {Neural Netw.},
  title        = {Approximation bounds for convolutional neural networks in operator learning},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rapid learning of spatial representations for goal-directed
navigation based on a novel model of hippocampal place fields.
<em>NN</em>, <em>161</em>, 116–128. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of place cells and other spatially modulated neurons in the hippocampal complex of rodents has been crucial to elucidating the neural basis of spatial cognition. More recently, the replay of neural sequences encoding previously experienced trajectories has been observed during consummatory behavior—potentially with implications for rapid learning, quick memory consolidation, and behavioral planning. Several promising models for robotic navigation and reinforcement learning have been proposed based on these and previous findings. Most of these models, however, use carefully engineered neural networks , and sometimes require long learning periods. In this paper, we present a self-organizing model incorporating place cells and replay, and demonstrate its utility for rapid one-shot learning in non-trivial environments with obstacles.},
  archive      = {J_NN},
  author       = {Adedapo Alabi and Dieter Vanderelst and Ali A. Minai},
  doi          = {10.1016/j.neunet.2023.01.010},
  journal      = {Neural Networks},
  pages        = {116-128},
  shortjournal = {Neural Netw.},
  title        = {Rapid learning of spatial representations for goal-directed navigation based on a novel model of hippocampal place fields},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-preserving continual person re-identification
using graph attention network. <em>NN</em>, <em>161</em>, 105–115. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID), considered as a sub-problem of image retrieval , is critical for intelligent security. The general practice is to train a deep model on images from a particular scenario (also known as a domain) and perform retrieval tests on images from the same domain. Thus, the model has to be retrained to ensure good performance on unseen domains. Unfortunately, retraining will introduce the so called catastrophic forgetting problem existing in deep learning models. To address this problem, we propose a Continual person re-identification model via a Knowledge-Preserving (CKP) mechanism. The proposed model is able to accumulate knowledge from continuously changing scenarios. The knowledge is updated via a graph attention network from the human cognitive-inspired perspective as the scenario changes. The accumulated knowledge is used to guide the learning process of the proposed model on image samples from new-coming domains. We finally evaluate and compare CKP with fine-tuning, continual learning in image classification and person re-identification, and joint training. Experiments on representative benchmark datasets (Market1501, DukeMTMC, CUHK03, CUHK-SYSU, and MSMT17, which arrive in different orders) demonstrate the advantages of the proposed model in preventing forgetting, and experiments on other benchmark datasets (GRID, SenseReID, CUHK01, CUHK02, VIPER, iLIDS, and PRID, which are not available during training) demonstrate the generalization ability of the proposed model. The CKP outperforms the best comparative model by 0.58\% and 0.65\% on seen domains (datasets available during training), and by 0.95\% and 1.02\% on never seen domains (datasets not available during training) in terms of mAP and Rank1, respectively. Arrival order of the training datasets, guidance of accumulated knowledge for learning new knowledge and parameter settings are also discussed.},
  archive      = {J_NN},
  author       = {Zhaoshuo Liu and Chaolu Feng and Shuaizheng Chen and Jun Hu},
  doi          = {10.1016/j.neunet.2023.01.033},
  journal      = {Neural Networks},
  pages        = {105-115},
  shortjournal = {Neural Netw.},
  title        = {Knowledge-preserving continual person re-identification using graph attention network},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced tensor low-rank representation learning for
multi-view clustering. <em>NN</em>, <em>161</em>, 93–104. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MSC), assuming the multi-view data are generated from a latent subspace, has attracted considerable attention in multi-view clustering. To recover the underlying subspace structure, a successful approach adopted recently is subspace clustering based on tensor nuclear norm (TNN). But there are some limitations to this approach that the existing TNN-based methods usually fail to exploit the intrinsic cluster structure and high-order correlations well, which leads to limited clustering performance. To address this problem, the main purpose of this paper is to propose a novel tensor low-rank representation (TLRR) learning method to perform multi-view clustering. First, we construct a 3rd-order tensor by organizing the features from all views, and then use the t-product in the tensor space to obtain the self-representation tensor of the tensorial data. Second, we use the ℓ 1 , 2 ℓ1,2 norm to constrain the self-representation tensor to make it capture the class-specificity distribution, that is important for depicting the intrinsic cluster structure. And simultaneously, we rotate the self-representation tensor, and use the tensor singular value decomposition-based weighted TNN as a tighter tensor rank approximation to constrain the rotated tensor. For the challenged mathematical optimization problem, we present an effective optimization algorithm with a theoretical convergence guarantee and relatively low computation complexity. The constructed convergent sequence to the Karush–Kuhn–Tucker (KKT) critical point solution is mathematically validated in detail. We perform extensive experiments on four datasets and demonstrate that TLRR outperforms state-of-the-art multi-view subspace clustering methods .},
  archive      = {J_NN},
  author       = {Deyan Xie and Quanxue Gao and Ming Yang},
  doi          = {10.1016/j.neunet.2023.01.037},
  journal      = {Neural Networks},
  pages        = {93-104},
  shortjournal = {Neural Netw.},
  title        = {Enhanced tensor low-rank representation learning for multi-view clustering},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum to “functional connectivity inference from fMRI
data using multivariate information measures” [neural networks 146
(2022) 85–97]. <em>NN</em>, <em>161</em>, 92. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Qiang Li},
  doi          = {10.1016/j.neunet.2023.01.021},
  journal      = {Neural Networks},
  pages        = {92},
  shortjournal = {Neural Netw.},
  title        = {Corrigendum to “Functional connectivity inference from fMRI data using multivariate information measures” [Neural networks 146 (2022) 85–97]},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DEFAEK: Domain effective fast adaptive network for face
anti-spoofing. <em>NN</em>, <em>161</em>, 83–91. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep learning based face anti-spoofing (FAS) or deepfake detection approaches usually rely on large-scale datasets and powerful networks with significant amount of parameters to achieve satisfactory performance. However, these make them resource-heavy and unsuitable for handheld devices. Moreover, they are limited by the types of spoof in the dataset they train on and require considerable training time. To produce a robust FAS model, they need large datasets covering the widest variety of predefined presentation attacks possible. Testing on new or unseen attacks or environments generally results in poor performance. Ideally, the FAS model should learn discriminative features that can generalize well even on unseen spoof types. In this paper, we propose a fast learning approach called Domain Effective Fast Adaptive nEt-worK (DEFAEK), a face anti-spoofing approach based on the optimization-based meta-learning paradigm that effectively and quickly adapts to new tasks. DEFAEK treats differences in an environment as domains and simulates multiple domain shifts during training. To further improve the effectiveness and efficiency of meta-learning, we adopt the metric learning in the inner loop update with careful sample selection. With extensive experiments on the challenging CelebA-Spoof and FaceForensics++ datasets, the evaluation results show that DEFAEK can learn cues independent of the environment with good generalization capability. In addition, the resulting model is lightweight following the design principle of modern lightweight network architecture and still generalizes well on unseen classes. In addition, we also demonstrate our model’s capabilities by comparing the numbers of parameters, FLOPS , and model performance with other state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Jiun-Da Lin and Yue-Hua Han and Po-Han Huang and Julianne Tan and Jun-Cheng Chen and M. Tanveer and Kai-Lung Hua},
  doi          = {10.1016/j.neunet.2023.01.018},
  journal      = {Neural Networks},
  pages        = {83-91},
  shortjournal = {Neural Netw.},
  title        = {DEFAEK: Domain effective fast adaptive network for face anti-spoofing},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal guiding and reweighting network for multi-modal
RSVP-based target detection. <em>NN</em>, <em>161</em>, 65–82. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid Serial Visual Presentation (RSVP) based Brain–Computer Interface (BCI) facilities the high-throughput detection of rare target images by detecting evoked event-related potentials (ERPs). At present, the decoding accuracy of the RSVP-based BCI system limits its practical applications. This study introduces eye movements (gaze and pupil information), referred to as EYE modality, as another useful source of information to combine with EEG-based BCI and forms a novel target detection system to detect target images in RSVP tasks. We performed an RSVP experiment, recorded the EEG signals and eye movements simultaneously during a target detection task, and constructed a multi-modal dataset including 20 subjects. Also, we proposed a cross-modal guiding and fusion network to fully utilize EEG and EYE modalities and fuse them for better RSVP decoding performance. In this network, a two-branch backbone was built to extract features from these two modalities. A Cross-Modal Feature Guiding (CMFG) module was proposed to guide EYE modality features to complement the EEG modality for better feature extraction. A Multi-scale Multi-modal Reweighting (MMR) module was proposed to enhance the multi-modal features by exploring intra- and inter-modal interactions. And, a Dual Activation Fusion (DAF) was proposed to modulate the enhanced multi-modal features for effective fusion. Our proposed network achieved a balanced accuracy of 88.00\% (±2.29) on the collected dataset. The ablation studies and visualizations revealed the effectiveness of the proposed modules. This work implies the effectiveness of introducing the EYE modality in RSVP tasks. And, our proposed network is a promising method for RSVP decoding and further improves the performance of RSVP-based target detection systems.},
  archive      = {J_NN},
  author       = {Jiayu Mao and Shuang Qiu and Wei Wei and Huiguang He},
  doi          = {10.1016/j.neunet.2023.01.009},
  journal      = {Neural Networks},
  pages        = {65-82},
  shortjournal = {Neural Netw.},
  title        = {Cross-modal guiding and reweighting network for multi-modal RSVP-based target detection},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asynchronous dissipative stabilization for stochastic
markov-switching neural networks with completely- and incompletely-known
transition rates. <em>NN</em>, <em>161</em>, 55–64. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The asynchronous dissipative stabilization for stochastic Markov-switching neural networks (SMSNNs) is investigated. The aim is to design an output-feedback controller with inconsistent mode switching to ensure that the SMSNN is stochastically stable with extended dissipativity. Two situations, which involve completely- and incompletely-known transition rates (TRs), are taken into account. The situation that all TRs are exactly known is considered first. By applying a mode-dependent Lyapunov–Krasovskii functional, Dynkin’s formula, and several matrix inequalities, a criterion for the desired performance of the closed-loop SMSNN is derived and a design method for determining the asynchronous controller is developed. Then, the study is generalized to the situation where some TRs are allowed to be uncertain or even fully unknown. An inequality is established for judging the upper bound of the product of the TRs with the Lyapunov matrix by making full use of accessible information on the incompletely-known TRs. Based on the inequality, performance analysis and control synthesis are presented without imposing the zero-sum hypothesis of the uncertainties in the TR matrix . Finally, an example with numerical calculation and simulation is provided to verify the validity of the stabilizing approaches.},
  archive      = {J_NN},
  author       = {Weipeng Tai and Xinling Li and Jianping Zhou and Sabri Arik},
  doi          = {10.1016/j.neunet.2023.01.039},
  journal      = {Neural Networks},
  pages        = {55-64},
  shortjournal = {Neural Netw.},
  title        = {Asynchronous dissipative stabilization for stochastic markov-switching neural networks with completely- and incompletely-known transition rates},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced robust spatial feature selection and correlation
filter learning for UAV tracking. <em>NN</em>, <em>161</em>, 39–54. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial boundary effect can significantly reduce the performance of a learned discriminative correlation filter (DCF) model. A commonly used method to relieve this effect is to extract appearance features from a wider region of a target. However, this way would introduce unexpected features from background pixels and noises, which will lead to a decrease of the filter’s discrimination power. To address this shortcoming, this paper proposes an innovative method called enhanced robust spatial feature selection and correlation filter Learning (EFSCF), which performs jointly sparse feature learning to handle boundary effects effectively while suppressing the influence of background pixels and noises. Unlike the ℓ 2 ℓ2 -norm-based tracking approaches that are prone to non-Gaussian noises, the proposed method imposes the ℓ 2 , 1 ℓ2,1 -norm on the loss term to enhance the robustness against the training outliers. To enhance the discrimination further, a jointly sparse feature selection scheme based on the ℓ 2 , 1 ℓ2,1 -norm is designed to regularize the filter in rows and columns simultaneously. To the best of the authors’ knowledge, this has been the first work exploring the structural sparsity in rows and columns of a learned filter simultaneously. The proposed model can be efficiently solved by an alternating direction multiplier method. The proposed EFSCF is verified by experiments on four challenging unmanned aerial vehicle datasets under severe noise and appearance changes, and the results show that the proposed method can achieve better tracking performance than the state-of-the-art trackers.},
  archive      = {J_NN},
  author       = {Jiajun Wen and Honglin Chu and Zhihui Lai and Tianyang Xu and Linlin Shen},
  doi          = {10.1016/j.neunet.2023.01.003},
  journal      = {Neural Networks},
  pages        = {39-54},
  shortjournal = {Neural Netw.},
  title        = {Enhanced robust spatial feature selection and correlation filter learning for UAV tracking},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable local flow attention for multi-step traffic
flow prediction. <em>NN</em>, <em>161</em>, 25–38. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction (TFP) has attracted increasing attention with the development of smart city. In the past few years, neural network-based methods have shown impressive performance for TFP. However, most of previous studies fail to explicitly and effectively model the relationship between inflows and outflows. Consequently, these methods are usually uninterpretable and inaccurate. In this paper, we propose an interpretable local flow attention (LFA) mechanism for TFP, which yields three advantages. (1) LFA is flow-aware. Different from existing works, which blend inflows and outflows in the channel dimension, we explicitly exploit the correlations between flows with a novel attention mechanism . (2) LFA is interpretable. It is formulated by the truisms of traffic flow, and the learned attention weights can well explain the flow correlations. (3) LFA is efficient. Instead of using global spatial attention as in previous studies, LFA leverages the local mode. The attention query is only performed on the local related regions. This not only reduces computational cost but also avoids false attention. Based on LFA, we further develop a novel spatiotemporal cell, named LFA-ConvLSTM (LFA-based convolutional long short-term memory), to capture the complex dynamics in traffic data. Specifically, LFA-ConvLSTM consists of three parts. (1) A ConvLSTM module is utilized to learn flow-specific features. (2) An LFA module accounts for modeling the correlations between flows. (3) A feature aggregation module fuses the above two to obtain a comprehensive feature. Extensive experiments on two real-world datasets show that our method achieves a better prediction performance. We improve the RMSE metric by 3.2\%–4.6\%, and the MAPE metric by 6.2\%–6.7\%. Our LFA-ConvLSTM is also almost 32\% faster than global self-attention ConvLSTM in terms of prediction time. Furthermore, we also present some visual results to analyze the learned flow correlations.},
  archive      = {J_NN},
  author       = {Xu Huang and Bowen Zhang and Shanshan Feng and Yunming Ye and Xutao Li},
  doi          = {10.1016/j.neunet.2023.01.023},
  journal      = {Neural Networks},
  pages        = {25-38},
  shortjournal = {Neural Netw.},
  title        = {Interpretable local flow attention for multi-step traffic flow prediction},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPIDE: A purely spike-based method for training feedback
spiking neural networks. <em>NN</em>, <em>161</em>, 9–24. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) with event-based computation are promising brain-inspired models for energy-efficient applications on neuromorphic hardware. However, most supervised SNN training methods, such as conversion from artificial neural networks or direct training with surrogate gradients, require complex computation rather than spike-based operations of spiking neurons during training. In this paper, we study spike-based implicit differentiation on the equilibrium state (SPIDE) that extends the recently proposed training method, implicit differentiation on the equilibrium state (IDE), for supervised learning with purely spike-based computation, which demonstrates the potential for energy-efficient training of SNNs. Specifically, we introduce ternary spiking neuron couples and prove that implicit differentiation can be solved by spikes based on this design, so the whole training procedure, including both forward and backward passes, is made as event-driven spike computation, and weights are updated locally with two-stage average firing rates. Then we propose to modify the reset membrane potential to reduce the approximation error of spikes. With these key components, we can train SNNs with flexible structures in a small number of time steps and with firing sparsity during training, and the theoretical estimation of energy costs demonstrates the potential for high efficiency. Meanwhile, experiments show that even with these constraints, our trained models can still achieve competitive results on MNIST, CIFAR-10, CIFAR-100, and CIFAR10-DVS.},
  archive      = {J_NN},
  author       = {Mingqing Xiao and Qingyan Meng and Zongpeng Zhang and Yisen Wang and Zhouchen Lin},
  doi          = {10.1016/j.neunet.2023.01.026},
  journal      = {Neural Networks},
  pages        = {9-24},
  shortjournal = {Neural Netw.},
  title        = {SPIDE: A purely spike-based method for training feedback spiking neural networks},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quasi-synchronization of drive–response systems with
parameter mismatch via event-triggered impulsive control. <em>NN</em>,
<em>161</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an event-triggered impulsive control method is proposed to investigate the quasi-synchronization of drive–response systems with parameter mismatch, which integrates the event-triggered control and impulsive control together. The impulsive instants are event-triggered and determined by a certain state-dependent triggering law. Sufficient conditions for achieving quasi-synchronization are achieved. The synchronization error is shown to be no more than a nonzero bound. Furthermore, Zeno-behavior of impulsive instants is excluded. Finally, a numerical example is presented to verify the validity of the theoretical results.},
  archive      = {J_NN},
  author       = {Huannan Zheng and Nanxiang Yu and Wei Zhu},
  doi          = {10.1016/j.neunet.2023.01.020},
  journal      = {Neural Networks},
  pages        = {1-8},
  shortjournal = {Neural Netw.},
  title        = {Quasi-synchronization of drive–response systems with parameter mismatch via event-triggered impulsive control},
  volume       = {161},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023f). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>160</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(23)00106-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00106-5},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Current events. <em>NN</em>, <em>160</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(23)00105-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(23)00105-3},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {Current events},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A wholistic view of continual learning with deep neural
networks: Forgotten lessons and the bridge to active and open world
learning. <em>NN</em>, <em>160</em>, 306–336. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep learning methods are regarded as favorable if they empirically perform well on dedicated test sets. This mentality is seamlessly reflected in the resurfacing area of continual learning, where consecutively arriving data is investigated. The core challenge is framed as protecting previously acquired representations from being catastrophically forgotten. However, comparison of individual methods is nevertheless performed in isolation from the real world by monitoring accumulated benchmark test set performance. The closed world assumption remains predominant, i.e. models are evaluated on data that is guaranteed to originate from the same distribution as used for training. This poses a massive challenge as neural networks are well known to provide overconfident false predictions on unknown and corrupted instances. In this work we critically survey the literature and argue that notable lessons from open set recognition , identifying unknown examples outside of the observed set, and the adjacent field of active learning, querying data to maximize the expected performance gain, are frequently overlooked in the deep learning era. Hence, we propose a consolidated view to bridge continual learning, active learning and open set recognition in deep neural networks. Finally, the established synergies are supported empirically, showing joint improvement in alleviating catastrophic forgetting, querying data, selecting task orders, while exhibiting robust open world application.},
  archive      = {J_NN},
  author       = {Martin Mundt and Yongwon Hong and Iuliia Pliushch and Visvanathan Ramesh},
  doi          = {10.1016/j.neunet.2023.01.014},
  journal      = {Neural Networks},
  pages        = {306-336},
  shortjournal = {Neural Netw.},
  title        = {A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-free forecasting of partially observable
spatiotemporally chaotic systems. <em>NN</em>, <em>160</em>, 297–305.
(<a href="https://doi.org/10.1016/j.neunet.2023.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir computing is a powerful tool for forecasting turbulence because its simple architecture has the computational efficiency to handle high-dimensional systems. Its implementation, however, often requires full state-vector measurements and knowledge of the system nonlinearities . We use nonlinear projector functions to expand the system measurements to a high dimensional space and then feed them to a reservoir to obtain forecasts. We demonstrate the application of such reservoir computing networks on spatiotemporally chaotic systems, which model several features of turbulence. We show that using radial basis functions as nonlinear projectors enables complex system nonlinearities to be captured robustly even with only partial observations and without knowing the governing equations. Finally, we show that when measurements are sparse or incomplete and noisy, such that even the governing equations become inaccurate, our networks can still produce reasonably accurate forecasts, thus paving the way towards model-free forecasting of practical turbulent systems.},
  archive      = {J_NN},
  author       = {Vikrant Gupta and Larry K.B. Li and Shiyi Chen and Minping Wan},
  doi          = {10.1016/j.neunet.2023.01.013},
  journal      = {Neural Networks},
  pages        = {297-305},
  shortjournal = {Neural Netw.},
  title        = {Model-free forecasting of partially observable spatiotemporally chaotic systems},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A domain-agnostic approach for characterization of lifelong
learning systems. <em>NN</em>, <em>160</em>, 274–296. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the advancement of machine learning techniques in recent years, state-of-the-art systems lack robustness to “real world” events, where the input distributions and tasks encountered by the deployed systems will not be limited to the original training context, and systems will instead need to adapt to novel distributions and tasks while deployed. This critical gap may be addressed through the development of “Lifelong Learning” systems that are capable of (1) Continuous Learning , (2) Transfer and Adaptation , and (3) Scalability . Unfortunately, efforts to improve these capabilities are typically treated as distinct areas of research that are assessed independently, without regard to the impact of each separate capability on other aspects of the system. We instead propose a holistic approach, using a suite of metrics and an evaluation framework to assess Lifelong Learning in a principled way that is agnostic to specific domains or system techniques. Through five case studies, we show that this suite of metrics can inform the development of varied and complex Lifelong Learning systems. We highlight how the proposed suite of metrics quantifies performance trade-offs present during Lifelong Learning system development — both the widely discussed Stability-Plasticity dilemma and the newly proposed relationship between Sample Efficient and Robust Learning. Further, we make recommendations for the formulation and use of metrics to guide the continuing development of Lifelong Learning systems and assess their progress in the future.},
  archive      = {J_NN},
  author       = {Megan M. Baker and Alexander New and Mario Aguilar-Simon and Ziad Al-Halah and Sébastien M.R. Arnold and Ese Ben-Iwhiwhu and Andrew P. Brna and Ethan Brooks and Ryan C. Brown and Zachary Daniels and Anurag Daram and Fabien Delattre and Ryan Dellana and Eric Eaton and Haotian Fu and Kristen Grauman and Jesse Hostetler and Shariq Iqbal and Cassandra Kent and Nicholas Ketz and Soheil Kolouri and George Konidaris and Dhireesha Kudithipudi and Erik Learned-Miller and Seungwon Lee and Michael L. Littman and Sandeep Madireddy and Jorge A. Mendez and Eric Q. Nguyen and Christine Piatko and Praveen K. Pilly and Aswin Raghavan and Abrar Rahman and Santhosh Kumar Ramakrishnan and Neale Ratzlaff and Andrea Soltoggio and Peter Stone and Indranil Sur and Zhipeng Tang and Saket Tiwari and Kyle Vedder and Felix Wang and Zifan Xu and Angel Yanguas-Gil and Harel Yedidsion and Shangqun Yu and Gautam K. Vallabha},
  doi          = {10.1016/j.neunet.2023.01.007},
  journal      = {Neural Networks},
  pages        = {274-296},
  shortjournal = {Neural Netw.},
  title        = {A domain-agnostic approach for characterization of lifelong learning systems},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A subgradient-based neurodynamic algorithm to constrained
nonsmooth nonconvex interval-valued optimization. <em>NN</em>,
<em>160</em>, 259–273. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a subgradient-based neurodynamic algorithm is presented to solve the nonsmooth nonconvex interval-valued optimization problem with both partial order and linear equality constraints, where the interval-valued objective function is nonconvex, and interval-valued partial order constraint functions are convex. The designed neurodynamic system is constructed by a differential inclusion with upper semicontinuous right-hand side, whose calculation load is reduced by relieving penalty parameters estimation and complex matrix inversion. Based on nonsmooth analysis and the extension theorem of the solution of differential inclusion , it is obtained that the global existence and boundedness of state solution of neurodynamic system, as well as the asymptotic convergence of state solution to the feasible region and the set of L U LU -critical points of interval-valued nonconvex optimization problem . Several numerical experiments and the applications to emergency supplies distribution and nondeterministic fractional continuous static games are solved to illustrate the applicability of the proposed neurodynamic algorithm.},
  archive      = {J_NN},
  author       = {Jingxin Liu and Xiaofeng Liao and Jin-song Dong and Amin Mansoori},
  doi          = {10.1016/j.neunet.2023.01.012},
  journal      = {Neural Networks},
  pages        = {259-273},
  shortjournal = {Neural Netw.},
  title        = {A subgradient-based neurodynamic algorithm to constrained nonsmooth nonconvex interval-valued optimization},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiclass skin lesion localization and classification using
deep learning based features fusion and selection framework for smart
healthcare. <em>NN</em>, <em>160</em>, 238–258. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The idea of smart healthcare has gradually gained attention as a result of the information technology industry’s rapid development. Smart healthcare uses next-generation technologies i.e., artificial intelligence (AI) and Internet of Things (IoT), to intelligently transform current medical methods to make them more efficient, dependable and individualized. One of the most prominent uses of telemedicine and e-health in medical image analysis is teledermatology. Telecommunications technologies are used in this industry to send medical information to professionals. Teledermatology is a useful method for the identification of skin lesions, particularly in rural locations, because the skin is visually perceptible. One of the most recent tools for diagnosing skin cancer is dermoscopy. To classify skin malignancies, numerous computational approaches have been proposed in the literature. However, difficulties still exist i.e., lesions with low contrast, imbalanced datasets, high level of memory complexity, and the extraction of redundant features. In this work, a unified CAD model is proposed based on a deep learning framework for skin lesion segmentation and classification. In the proposed approach, the source dermoscopic images are initially pre-processed using a contrast enhancement based modified bio-inspired multiple exposure fusion approach. In the second stage, a custom 26-layered convolutional neural network (CNN) architecture is designed to segment the skin lesion regions. In the third stage, four pre-trained CNN models (Xception, ResNet-50, ResNet-101 and VGG16) are modified and trained using transfer learning on the segmented lesion images. In the fourth stage, the deep features vectors are extracted from all the CNN models and fused using the convolutional sparse image decomposition fusion approach. In the fifth stage, the univariate measurement and Poisson distribution feature selection approach is used for the best features selection for classification. Finally, the selected features are fed to the multi-class support vector machine (MC-SVM) for the final classification. The proposed approach employed to the HAM10000, ISIC2018, ISIC2019, and PH2 datasets and achieved an accuracy of 98.57\%, 98.62\%, 93.47\%, and 98.98\% respectively which are better than previous works. When compared to renowned state-of-the-art methods, experimental results show that the proposed skin lesion detection and classification approach achieved higher performance in terms of both visually and enhanced quantitative evaluation with enhanced accuracy.},
  archive      = {J_NN},
  author       = {Sarmad Maqsood and Robertas Damaševičius},
  doi          = {10.1016/j.neunet.2023.01.022},
  journal      = {Neural Networks},
  pages        = {238-258},
  shortjournal = {Neural Netw.},
  title        = {Multiclass skin lesion localization and classification using deep learning based features fusion and selection framework for smart healthcare},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust exponential stability of discrete-time uncertain
impulsive stochastic neural networks with delayed impulses. <em>NN</em>,
<em>160</em>, 227–237. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of the robust exponential stability (RES) of discrete-time uncertain impulsive stochastic neural networks (DTUISNNs) with delayed impulses. Using Lyapunov function methods and Razumikhin techniques, a number of sufficient conditions for mean square (RES-ms) robust exponential stability are derived. The obtained results show that the hybrid dynamic is RES-ms with regard to lower boundary of impulse interval if the discrete-time stochastic neural networks (DTSNNs) is RES-ms and that the impulsive effects are instable. Conversely, if DTSNNs is not RES-ms, impulsive effects can induce unstable neural networks (NNs) to stabilize again concerning an upper bound of the impulsive interval. The results obtained in this study have a broader scope of application than some previously existing findings. Two numerical examples were presented to verify the availability and advantages of the results.},
  archive      = {J_NN},
  author       = {Ting Cai and Pei Cheng and Fengqi Yao and Mingang Hua},
  doi          = {10.1016/j.neunet.2023.01.016},
  journal      = {Neural Networks},
  pages        = {227-237},
  shortjournal = {Neural Netw.},
  title        = {Robust exponential stability of discrete-time uncertain impulsive stochastic neural networks with delayed impulses},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DF-UDetector: An effective method towards robust deepfake
detection via feature restoration. <em>NN</em>, <em>160</em>, 216–226.
(<a href="https://doi.org/10.1016/j.neunet.2023.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abuse of deepfakes , a rising face swap technique, causes severe concerns about the authenticity of visual content and the dissemination of misinformation . To alleviate the threats imposed by deepfakes , a vast body of data-centric detectors has been deployed. However, the performance of these methods can be easily defected by degradations on deepfakes. To improve the performance of degradation deepfake detection, we creatively explore the recovery method in the feature space to preserve the artifacts for detection instead of directly in the image domain. In this paper, we propose a method, namely DF-UDetector, against degradation deepfakes by modeling the degraded images and transforming the extracted features to a high-quality level. To be specific, the whole model consists of three key components: an image feature extractor to capture image features, a feature transforming module to map the degradation features into a higher quality, and a discriminator to determine whether the feature map is of high quality enough. Extensive experiments on multiple video datasets show that our proposed model performs comparably or even better than state-of-the-art counterparts. Moreover, DF-UDetector outperforms by a small margin when detecting deepfakes in the wild.},
  archive      = {J_NN},
  author       = {Jianpeng Ke and Lina Wang},
  doi          = {10.1016/j.neunet.2023.01.001},
  journal      = {Neural Networks},
  pages        = {216-226},
  shortjournal = {Neural Netw.},
  title        = {DF-UDetector: An effective method towards robust deepfake detection via feature restoration},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance estimation for the memristor-based
computing-in-memory implementation of extremely factorized network for
real-time and low-power semantic segmentation. <em>NN</em>,
<em>160</em>, 202–215. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays many semantic segmentation algorithms have achieved satisfactory accuracy on von Neumann platforms (e.g., GPU), but the speed and energy consumption have not meet the high requirements of certain edge applications like autonomous driving . To tackle this issue, it is of necessity to design an efficient lightweight semantic segmentation algorithm and then implement it on emerging hardware platforms with high speed and energy efficiency. Here, we first propose an extremely factorized network (EFNet) which can learn multi-scale context information while preserving rich spatial information with reduced model complexity. Experimental results on the Cityscapes dataset show that EFNet achieves an accuracy of 68.0\% mean intersection over union (mIoU) with only 0.18M parameters, at a speed of 99 frames per second (FPS) on a single RTX 3090 GPU . Then, to further improve the speed and energy efficiency, we design a memristor-based computing-in-memory (CIM) accelerator for the hardware implementation of EFNet. It is shown by the simulation in DNN+NeuroSim V2.0 that the memristor-based CIM accelerator is ∼ ∼ 63 × × ( ∼ ∼ 4.6 × × ) smaller in area, at most ∼ ∼ 9.2 × × ( ∼ ∼ 1000 × × ) faster, and ∼ ∼ 470 × × ( ∼ ∼ 2400 × × ) more energy-efficient than the RTX 3090 GPU (the Jetson Nano embedded development board), although its accuracy slightly decreases by 1.7\% mIoU. Therefore, the memristor-based CIM accelerator has great potential to be deployed at the edge to implement lightweight semantic segmentation models like EFNet. This study showcases an algorithm-hardware co-design to realize real-time and low-power semantic segmentation at the edge.},
  archive      = {J_NN},
  author       = {Shuai Dong and Zhen Fan and Yihong Chen and Kaihui Chen and Minghui Qin and Min Zeng and Xubing Lu and Guofu Zhou and Xingsen Gao and Jun-Ming Liu},
  doi          = {10.1016/j.neunet.2023.01.008},
  journal      = {Neural Networks},
  pages        = {202-215},
  shortjournal = {Neural Netw.},
  title        = {Performance estimation for the memristor-based computing-in-memory implementation of extremely factorized network for real-time and low-power semantic segmentation},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive pseudo-siamese policy network for temporal
knowledge prediction. <em>NN</em>, <em>160</em>, 192–201. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge prediction is a crucial task for early event warning, which has gained increasing attention recently. It aims to predict future facts based on relevant historical facts using temporal knowledge graphs. There are two main difficulties associated with the prediction task: from the perspective of historical facts, modeling the evolutionary patterns of facts to accurately predict the query and from the query perspective, handling the two cases where the query contains seen and unseen entities in a unified framework. Driven by these two problems, we propose a novel adaptive pseudo-Siamese policy network for temporal knowledge prediction based on reinforcement learning . Specifically, we design the policy network in our model as a pseudo-Siamese network consisting of two sub-policy networks. In the sub-policy network I, the agent searches for the answer to the query along the entity-relation paths to capture static evolutionary patterns. In sub-policy network II, the agent searches for the answer to the query along relation-time paths to deal with unseen entities. Moreover, we develop a temporal relation encoder to capture the temporal evolutionary patterns. Finally, we design a gating mechanism to adaptively integrate the results of the two sub-policy networks to help the agent focus on the destination answer. To assess the performance of our model, we conduct link prediction on four benchmark datasets, and extensive experimental results demonstrate that our method achieves considerable performance compared with existing methods.},
  archive      = {J_NN},
  author       = {Pengpeng Shao and Tong Liu and Feihu Che and Dawei Zhang and Jianhua Tao},
  doi          = {10.1016/j.neunet.2023.01.004},
  journal      = {Neural Networks},
  pages        = {192-201},
  shortjournal = {Neural Netw.},
  title        = {Adaptive pseudo-siamese policy network for temporal knowledge prediction},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deterministic learning-based neural network control with
adaptive phase compensation. <em>NN</em>, <em>160</em>, 175–191. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the persistent excitation (PE) condition, the real dynamics of the nonlinear system can be obtained through the deterministic learning-based radial basis function neural network (RBFNN) control. However, in this scheme, the learning speed and accuracy are limited by the tradeoff between the PE levels and the approximation capabilities of the neural network (NN). Inspired by the frequency domain phase compensation of linear time-invariant (LTI) systems, this paper presents an adaptive phase compensator employing the pure time delay to improve the performance of the deterministic learning-based adaptive feedforward control with the reference input known a priori. When the adaptive phase compensation is applied to the hidden layer of the RBFNN, the nonlinear approximation capability of the RBFNN is effectively improved such that both the learning performance (learning speed and accuracy) and the control performance of the deterministic learning-based control scheme are improved. Theoretical analysis is conducted to prove the stability of the proposed learning control scheme for a class of systems which are affine in the control. Simulation studies demonstrate the effectiveness of the proposed phase compensation method.},
  archive      = {J_NN},
  author       = {Yiming Fei and Dongyu Li and Yanan Li and Jiangang Li},
  doi          = {10.1016/j.neunet.2023.01.005},
  journal      = {Neural Networks},
  pages        = {175-191},
  shortjournal = {Neural Netw.},
  title        = {Deterministic learning-based neural network control with adaptive phase compensation},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-attention learning network for face super-resolution.
<em>NN</em>, <em>160</em>, 164–174. (<a
href="https://doi.org/10.1016/j.neunet.2023.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing face super-resolution methods depend on deep convolutional networks (DCN) to recover high-quality reconstructed images. They either acquire information in a single space by designing complex models for direct reconstruction, or employ additional networks to extract multiple prior information to enhance the representation of features. However, existing methods are still challenging to perform well due to the inability to learn complete and uniform representations. To this end, we propose a self-attention learning network (SLNet) for three-stage face super-resolution, which fully explores the interdependence of low- and high-level spaces to achieve compensation of the information used for reconstruction. Firstly, SLNet uses a hierarchical feature learning framework to obtain shallow information in the low-level space. Then, the shallow information with cumulative errors due to DCN is improved under high-resolution (HR) supervision, while bringing an intermediate reconstruction result and a powerful intermediate benchmark. Finally, the improved feature representation is further enhanced in high-level space by a multi-scale context-aware encoder–decoder for facial reconstruction. The features in both spaces are explored progressively from coarse to fine reconstruction information. The experimental results show that SLNet has a competitive performance compared to the state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Kangli Zeng and Zhongyuan Wang and Tao Lu and Jianyu Chen and Jiaming Wang and Zixiang Xiong},
  doi          = {10.1016/j.neunet.2023.01.006},
  journal      = {Neural Networks},
  pages        = {164-174},
  shortjournal = {Neural Netw.},
  title        = {Self-attention learning network for face super-resolution},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning in random neural fields: Numerical experiments
via neural tangent kernel. <em>NN</em>, <em>160</em>, 148–163. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A biological neural network in the cortex forms a neural field. Neurons in the field have their own receptive fields, and connection weights between two neurons are random but highly correlated when they are in close proximity in receptive fields. In this paper, we investigate such neural fields in a multilayer architecture to investigate the supervised learning of the fields. We empirically compare the performances of our field model with those of randomly connected deep networks. The behavior of a randomly connected network is investigated on the basis of the key idea of the neural tangent kernel regime, a recent development in the machine learning theory of over-parameterized networks; for most randomly connected neural networks, it is shown that global minima always exist in their small neighborhoods. We numerically show that this claim also holds for our neural fields. In more detail, our model has two structures: (i) each neuron in a field has a continuously distributed receptive field, and (ii) the initial connection weights are random but not independent, having correlations when the positions of neurons are close in each layer. We show that such a multilayer neural field is more robust than conventional models when input patterns are deformed by noise disturbances. Moreover, its generalization ability can be slightly superior to that of conventional models.},
  archive      = {J_NN},
  author       = {Kaito Watanabe and Kotaro Sakamoto and Ryo Karakida and Sho Sonoda and Shun-ichi Amari},
  doi          = {10.1016/j.neunet.2022.12.020},
  journal      = {Neural Networks},
  pages        = {148-163},
  shortjournal = {Neural Netw.},
  title        = {Deep learning in random neural fields: Numerical experiments via neural tangent kernel},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coexistence and local stability of multiple equilibrium
points for fractional-order state-dependent switched competitive neural
networks with time-varying delays. <em>NN</em>, <em>160</em>, 132–147.
(<a href="https://doi.org/10.1016/j.neunet.2022.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the coexistence and local stability of multiple equilibrium points for a class of competitive neural networks with sigmoidal activation functions and time-varying delays, in which fractional-order derivative and state-dependent switching are involved at the same time. Some novel criteria are established to ensure that such n n -neuron neural networks can have 5 m 1 ⋅ 3 m 2 5m1⋅3m2 total equilibrium points and 3 m 1 ⋅ 2 m 2 3m1⋅2m2 locally stable equilibrium points with m 1 + m 2 = n m1+m2=n , based on the fixed-point theorem, the definition of equilibrium point in the sense of Filippov, the theory of fractional-order differential equation and Lyapunov function method. The investigation implies that the competitive neural networks with switching can possess greater storage capacity than the ones without switching. Moreover, the obtained results include the multistability results of both fractional-order switched Hopfield neural networks and integer-order switched Hopfield neural networks as special cases, thus generalizing and improving some existing works. Finally, four numerical examples are presented to substantiate the effectiveness of the theoretical analysis.},
  archive      = {J_NN},
  author       = {Zhongwen Wu and Xiaobing Nie and Boqiang Cao},
  doi          = {10.1016/j.neunet.2022.12.013},
  journal      = {Neural Networks},
  pages        = {132-147},
  shortjournal = {Neural Netw.},
  title        = {Coexistence and local stability of multiple equilibrium points for fractional-order state-dependent switched competitive neural networks with time-varying delays},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial lagrangian integrated contrastive embedding for
limited size datasets. <em>NN</em>, <em>160</em>, 122–131. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Certain datasets contain a limited number of samples with highly various styles and complex structures. This study presents a novel adversarial Lagrangian integrated contrastive embedding (ALICE) method for small-sized datasets. First, the accuracy improvement and training convergence of the proposed pre-trained adversarial transfer are shown on various subsets of datasets with few samples. Second, a novel adversarial integrated contrastive model using various augmentation techniques is investigated. The proposed structure considers the input samples with different appearances and generates a superior representation with adversarial transfer contrastive training. Finally, multi-objective augmented Lagrangian multipliers encourage the low-rank and sparsity of the presented adversarial contrastive embedding to adaptively estimate the coefficients of the regularizers automatically to the optimum weights. The sparsity constraint suppresses less representative elements in the feature space. The low-rank constraint eliminates trivial and redundant components and enables superior generalization. The performance of the proposed model is verified by conducting ablation studies by using benchmark datasets for scenarios with small data samples.},
  archive      = {J_NN},
  author       = {Amin Jalali and Minho Lee},
  doi          = {10.1016/j.neunet.2022.12.023},
  journal      = {Neural Networks},
  pages        = {122-131},
  shortjournal = {Neural Netw.},
  title        = {Adversarial lagrangian integrated contrastive embedding for limited size datasets},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-time and prescribed-time synchronization of
quaternion-valued neural networks: A control strategy involving lyapunov
functions. <em>NN</em>, <em>160</em>, 108–121. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A control strategy containing Lyapunov functions is proposed in this paper. Based on this strategy, the fixed-time synchronization of a time-delay quaternion-valued neural network (QVNN) is analyzed. This strategy is extended to the prescribed-time synchronization of the QVNN. Furthermore, an improved two-step switching control strategy is also proposed based on this flexible control strategy. Compared with some existing methods, the main method of this paper is a non-decomposition one, does not contain a sign function in the controller, and has better synchronization accuracy. Two numerical examples verify the above advantages.},
  archive      = {J_NN},
  author       = {Tao Peng and Yanqiu Wu and Zhengwen Tu and A.S. Alofi and Jianquan Lu},
  doi          = {10.1016/j.neunet.2022.12.014},
  journal      = {Neural Networks},
  pages        = {108-121},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time and prescribed-time synchronization of quaternion-valued neural networks: A control strategy involving lyapunov functions},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predefined-time synchronization of coupled neural networks
with switching parameters and disturbed by brownian motion. <em>NN</em>,
<em>160</em>, 97–107. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on predefined time synchronization problem for a class of signal switching neural networks with time-varying delays. In the network models, we not only consider the coupling characteristics in the following networks, but also consider the disturbance with standard Brownian motion . In the design of the controller, the control gain is designed as ɛ 1 ɛ + T p − t 1ɛ+Tp−t ( t ∈ [ T 0 , T p ) t∈[T0,Tp) , ɛ ɛ ɛ is an optional smaller positive number), which avoids the infinite gain (the control gain is designed as 1 T p − t 1Tp−t in other reference). In order to get the predefined time control law, a power function is multiplied to the Lyapunov functional , from which it can get an exponential upper bound function via the derivative and mathematical expectation operation. Utilizing the martingale theory and the method of Laplace matrix, some novel predefined time synchronization criteria are obtained for the leader-following neural networks , meanwhile the following networks can maintain the leader network after achieved synchronization. Based on the special network of the main system, five corollaries separately develop the predefined time synchronization results from different perspectives. An example with some simulation figures and computing results fully exhibits the effectiveness of the achieved synchronization scheme. In this case, although the error signal is disturbed by Brownian motion, the trace signal can still stably converge to zero by this control scheme, meanwhile the predefined-time control effect is achieved.},
  archive      = {J_NN},
  author       = {Xianghui Zhou and Jinde Cao and Xin Wang},
  doi          = {10.1016/j.neunet.2022.12.024},
  journal      = {Neural Networks},
  pages        = {97-107},
  shortjournal = {Neural Netw.},
  title        = {Predefined-time synchronization of coupled neural networks with switching parameters and disturbed by brownian motion},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Origin of the efficiency of spike timing-based neural
computation for processing temporal information. <em>NN</em>,
<em>160</em>, 84–96. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the advantage of spike timing-based over rate-based network computation has been recognized, the underlying mechanism remains unclear. Using Tempotron and Perceptron as elementary neural models , we examined the intrinsic difference between spike timing-based and rate-based computations. For more direct comparison, we modified Tempotron computation into rate-based computation with the retention of some temporal information. Previous studies have shown that spike timing-based computation are computationally more powerful than rate-based computation in terms of the number of computational units required and the capability in classifying random patterns. Our study showed that spike timing-based and rate-based Tempotron computations provided similar capability in classifying random spike patterns, as well as in text sentiment classification and spam text detection. However, spike timing-based computation is superior in performing a task involving discriminating forward vs. reverse sequence of events, i.e., information mainly temporal in nature. Further studies revealed that this superiority required the asymmetry in the profile of the postsynaptic potential (PSP), and that temporal sequence information was converted to biased spatial distribution of synaptic weight modifications during learning. Thus, the intrinsic PSP asymmetry is a mechanistic basis for the high efficiency of spike timing-based computation for processing temporal information.},
  archive      = {J_NN},
  author       = {Zhiwei Jiang and Jiaming Xu and Tielin Zhang and Mu-ming Poo and Bo Xu},
  doi          = {10.1016/j.neunet.2022.12.017},
  journal      = {Neural Networks},
  pages        = {84-96},
  shortjournal = {Neural Netw.},
  title        = {Origin of the efficiency of spike timing-based neural computation for processing temporal information},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tucker network: Expressive power and comparison.
<em>NN</em>, <em>160</em>, 63–83. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have achieved great success in solving many machine learning and computer vision problems. In this paper, we propose a deep neural network called the Tucker network derived from the Tucker format and analyze its expressive power . The results demonstrate that the Tucker network has exponentially higher expressive power than the shallow network. In other words, a shallow network with an exponential width is required to realize the same score function as that computed by the Tucker network. Moreover, we discuss the expressive power between the hierarchical Tucker tensor network (HT network) and the proposed Tucker network. To generalize the Tucker network into a deep version, we combine the hierarchical Tucker format and Tucker format to propose a deep Tucker tensor decomposition . Its corresponding deep Tucker network is presented. Experiments are conducted on three datasets: MNIST, CIFAR-10 and CIFAR-100. The results experimentally validate the theoretical results and show that the Tucker network and deep Tucker network have better performance than the shallow network and HT network.},
  archive      = {J_NN},
  author       = {Ye Liu and Junjun Pan and Michael K. Ng},
  doi          = {10.1016/j.neunet.2022.12.016},
  journal      = {Neural Networks},
  pages        = {63-83},
  shortjournal = {Neural Netw.},
  title        = {Tucker network: Expressive power and comparison},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 2DHeadPose: A simple and effective annotation method for the
head pose in RGB images and its dataset. <em>NN</em>, <em>160</em>,
50–62. (<a href="https://doi.org/10.1016/j.neunet.2022.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Head pose estimation is one of the essential tasks in computer vision , which predicts the Euler angles of the head in an image. In recent years, CNN-based methods for head pose estimation have achieved excellent performance. Their training relies on RGB images providing facial landmarks or depth images from RGBD cameras. However, labeling facial landmarks is complex for large angular head poses in RGB images, and RGBD cameras are unsuitable for outdoor scenes. We propose a simple and effective annotation method for the head pose in RGB images. The novelty method uses a 3D virtual human head to simulate the head pose in the RGB image. The Euler angle can be calculated from the change in coordinates of the 3D virtual head. We then create a dataset using our annotation method: 2DHeadPose dataset, which contains a rich set of attributes, dimensions, and angles. Finally, we propose Gaussian label smoothing to suppress annotation noises and reflect inter-class relationships. A baseline approach is established using Gaussian label smoothing. Experiments demonstrate that our annotation method, datasets, and Gaussian label smoothing are very effective. Our baseline approach surpasses most current state-of-the-art methods. The annotation tool, dataset, and source code are publicly available at https://github.com/youngnuaa/2DHeadPose .},
  archive      = {J_NN},
  author       = {Yang Wang and Wanlin Zhou and Jiakai Zhou},
  doi          = {10.1016/j.neunet.2022.12.021},
  journal      = {Neural Networks},
  pages        = {50-62},
  shortjournal = {Neural Netw.},
  title        = {2DHeadPose: A simple and effective annotation method for the head pose in RGB images and its dataset},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topological biclustering ARTMAP for identifying within
bicluster relationships. <em>NN</em>, <em>160</em>, 34–49. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biclustering is a powerful tool for exploratory data analysis in domains such as social networking , data reduction, and differential gene expression studies. Topological learning identifies connected regions that are difficult to find using other traditional clustering methods and produces a graphical representation . Therefore, to improve the quality of biclustering and module extraction, this work combines the adaptive resonance theory (ART)-based methods of biclustering ARTMAP (BARTMAP) and topological ART (TopoART), to produce TopoBARTMAP. The latter inherits the ability to detect topological associations while performing data reduction. The capabilities of TopoBARTMAP were benchmarked using 35 real world cancer datasets and contrasted with other (bi)clustering methods, where it showed a statistically significant improvement over the other assessed methods on ordered and shuffled data experiments. In experiments with 12 synthetic datasets , the method was observed to perform better at identifying constant, scale, shift, and shift scale type biclusters. The produced graphical representation was refined to represent gene bicluster associations and was assessed on the NCBI GSE89116 dataset containing expression levels of 39,326 probes sampled over 38 observations.},
  archive      = {J_NN},
  author       = {Raghu Yelugam and Leonardo Enzo Brito da Silva and Donald C. Wunsch II},
  doi          = {10.1016/j.neunet.2022.12.010},
  journal      = {Neural Networks},
  pages        = {34-49},
  shortjournal = {Neural Netw.},
  title        = {Topological biclustering ARTMAP for identifying within bicluster relationships},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-granularity graph pooling for video-based person
re-identification. <em>NN</em>, <em>160</em>, 22–33. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video-based person re-identification (ReID) aims to identify the given pedestrian video sequence across multiple non-overlapping cameras. To aggregate the temporal and spatial features of the video samples, the graph neural networks (GNNs) are introduced. However, existing graph-based models, like STGCN, perform the mean / max pooling on node features to obtain the graph representation , which neglect the graph topology and node importance. In this paper, we propose the graph pooling network (GPNet) to learn the multi-granularity graph representation for the video retrieval, where the graph pooling layer is implemented to downsample the graph. We construct a multi-granular graph by using node features learned from backbone, then implement multiple graph convolutional layers to perform the spatial and temporal aggregation on nodes. To downsample the graph, we propose a multi-head full attention graph pooling (MHFAPool) layer, which integrates the advantages of existing node clustering and node selection pooling methods. Specifically, MHFAPool first learns a full attention matrix for each pooled node, then obtains the principal eigenvector of the attention matrix via the power iteration algorithm , finally takes the softmax of the principal eigenvector as the aggregation coefficients. Extensive experiments demonstrate that our GPNet achieves the competitive results on four widely-used datasets, i.e., MARS, DukeMTMC-VideoReID, iLIDS-VID and PRID-2011.},
  archive      = {J_NN},
  author       = {Honghu Pan and Yongyong Chen and Zhenyu He},
  doi          = {10.1016/j.neunet.2022.12.015},
  journal      = {Neural Networks},
  pages        = {22-33},
  shortjournal = {Neural Netw.},
  title        = {Multi-granularity graph pooling for video-based person re-identification},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On joint parameterizations of linear and nonlinear
functionals in neural networks. <em>NN</em>, <em>160</em>, 12–21. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a new class of nonlinear operators and a dual learning paradigm where optimization jointly concerns both linear convolutional weights and the parameters of these nonlinear operators . The nonlinear class proposed to perform a rich functional representation is composed by functions called rectified parametric sigmoid units. This class is constructed to benefit from the advantages of both sigmoid and rectified linear unit functions, while rejecting their respective drawbacks. Moreover, the analytic form of this new neural class involves scale, shift and shape parameters to obtain a wide range of activation shapes, including the standard rectified linear unit as a limit case. Parameters of this neural transfer class are considered as learnable for the sake of discovering the complex shapes that can contribute to solving machine learning issues. Performance achieved by the joint learning of convolutional and rectified parametric sigmoid learnable parameters are shown to be outstanding in both shallow and deep learning frameworks. This class opens new prospects with respect to machine learning in the sense that main learnable parameters are attached not only to linear transformations , but also to a wide range of nonlinear operators.},
  archive      = {J_NN},
  author       = {Abdourrahmane Mahamane Atto and Sylvie Galichet and Dominique Pastor and Nicolas Méger},
  doi          = {10.1016/j.neunet.2022.12.019},
  journal      = {Neural Networks},
  pages        = {12-21},
  shortjournal = {Neural Netw.},
  title        = {On joint parameterizations of linear and nonlinear functionals in neural networks},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STACoRe: Spatio-temporal and action-based contrastive
representations for reinforcement learning in atari. <em>NN</em>,
<em>160</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of deep learning technology, deep reinforcement learning (DRL) has successfully built intelligent agents in sequential decision-making problems through interaction with image-based environments. However, learning from unlimited interaction is impractical and sample inefficient because training an agent requires many trial and error and numerous samples. One response to this problem is sample-efficient DRL, a research area that encourages learning effective state representations in limited interactions with image-based environments. Previous methods could effectively surpass human performance by training an RL agent using self-supervised learning and data augmentation to learn good state representations from a given interaction. However, most of the existing methods only consider similarity of image observations so that they are hard to capture semantic representations . To address these challenges, we propose spatio-temporal and action-based contrastive representation (STACoRe) learning for sample-efficient DRL. STACoRe performs two contrastive learning to learn proper state representations. One uses the agent’s actions as pseudo labels, and the other uses spatio-temporal information. In particular, when performing the action-based contrastive learning , we propose a method that automatically selects data augmentation techniques suitable for each environment for stable model training. We train the model by simultaneously optimizing an action-based contrastive loss function and spatio-temporal contrastive loss functions in an end-to-end manner. This leads to improving sample efficiency for DRL. We use 26 benchmark games in Atari 2600 whose environment interaction is limited to only 100k steps. The experimental results confirm that our method is more sample efficient than existing methods. The code is available at https://github.com/dudwojae/STACoRe .},
  archive      = {J_NN},
  author       = {Young Jae Lee and Jaehoon Kim and Mingu Kwak and Young Joon Park and Seoung Bum Kim},
  doi          = {10.1016/j.neunet.2022.12.018},
  journal      = {Neural Networks},
  pages        = {1-11},
  shortjournal = {Neural Netw.},
  title        = {STACoRe: Spatio-temporal and action-based contrastive representations for reinforcement learning in atari},
  volume       = {160},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). S3NN: Time step reduction of spiking surrogate gradients for
training energy efficient single-step spiking neural networks.
<em>NN</em>, <em>159</em>, 208–219. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the scales of neural networks increase, techniques that enable them to run with low computational cost and energy efficiency are required. From such demands, various efficient neural network paradigms, such as spiking neural networks (SNNs) or binary neural networks (BNNs), have been proposed. However, they have sticky drawbacks, such as degraded inference accuracy and latency. To solve these problems, we propose a single-step spiking neural network (S 3 3 NN), an energy-efficient neural network with low computational cost and high precision. The proposed S 3 3 NN processes the information between hidden layers by spikes as SNNs. Nevertheless, it has no temporal dimension so that there is no latency within training and inference phases as BNNs. Thus, the proposed S 3 3 NN has a lower computational cost than SNNs that require time-series processing. However, S 3 3 NN cannot adopt naïve backpropagation algorithms due to the non-differentiability nature of spikes. We deduce a suitable neuron model by reducing the surrogate gradient for multi-time step SNNs to a single-time step. We experimentally demonstrated that the obtained surrogate gradient allows S 3 3 NN to be trained appropriately. We also showed that the proposed S 3 3 NN could achieve comparable accuracy to full-precision networks while being highly energy-efficient.},
  archive      = {J_NN},
  author       = {Kazuma Suetake and Shin-ichi Ikegawa and Ryuji Saiin and Yoshihide Sawada},
  doi          = {10.1016/j.neunet.2022.12.008},
  journal      = {Neural Networks},
  pages        = {208-219},
  shortjournal = {Neural Netw.},
  title        = {S3NN: Time step reduction of spiking surrogate gradients for training energy efficient single-step spiking neural networks},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving fine-tuning of self-supervised models with
contrastive initialization. <em>NN</em>, <em>159</em>, 198–207. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has achieved remarkable performance in pre-training the models that can be further used in downstream tasks via fine-tuning. However, these self-supervised models may not capture meaningful semantic information since the images belonging to the same class are often regarded as negative pairs in the contrastive loss . Consequently, the images of the same class are often located far away from each other in the learned feature space, which would inevitably hamper the fine-tuning process. To address this issue, we seek to explicitly enhance the semantic relation among instances on the targeted downstream task and provide a better initialization for the subsequent fine-tuning. To this end, we propose a Contrastive Initialization (COIN) method that breaks the standard fine-tuning pipeline by introducing an extra class-aware initialization stage before fine-tuning. Specifically, we exploit a supervised contrastive loss to increase inter-class discrepancy and intra-class compactness of features on the target dataset. In this way, self-supervised models can be easily trained to discriminate instances of different classes during the final fine-tuning stage. Extensive experiments show that, with the enriched semantics, our COIN significantly outperforms existing methods without introducing extra training cost and sets new state-of-the-arts on multiple downstream tasks. For example, compared with the baseline method , our COIN improves the accuracy by 5\% on ImageNet-20 and 2.57\% on CIFAR100, respectively.},
  archive      = {J_NN},
  author       = {Haolin Pan and Yong Guo and Qinyi Deng and Haomin Yang and Jian Chen and Yiqun Chen},
  doi          = {10.1016/j.neunet.2022.12.012},
  journal      = {Neural Networks},
  pages        = {198-207},
  shortjournal = {Neural Netw.},
  title        = {Improving fine-tuning of self-supervised models with contrastive initialization},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explainable autoencoder with multi-paradigm fMRI fusion
for identifying differences in dynamic functional connectivity during
brain development. <em>NN</em>, <em>159</em>, 185–197. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-paradigm deep learning models show great potential for dynamic functional connectivity (dFC) analysis by integrating complementary information. However, many of them cannot use information from different paradigms effectively and have poor explainability , that is, the ability to identify significant features that contribute to decision making. In this paper, we propose a multi-paradigm fusion-based explainable deep sparse autoencoder (MF-EDSAE) to address these issues. Considering explainability , the MF-EDSAE is constructed based on a deep sparse autoencoder (DSAE). For integrating information effectively, the MF-EDASE contains the nonlinear fusion layer and multi-paradigm hypergraph regularization . We apply the model to the Philadelphia Neurodevelopmental Cohort and demonstrate it achieves better performance in detecting dynamic FC (dFC) that differ significantly during brain development than the single-paradigm DSAE. The experimental results show that children have more dispersive dFC patterns than adults. The function of the brain transits from undifferentiated systems to specialized networks during brain development. Meanwhile, adults have stronger connectivities between task-related functional networks for a given task than children. As the brain develops, the patterns of the global dFC change more quickly when stimulated by a task.},
  archive      = {J_NN},
  author       = {Faming Xu and Chen Qiao and Huiyu Zhou and Vince D. Calhoun and Julia M. Stephen and Tony W. Wilson and Yuping Wang},
  doi          = {10.1016/j.neunet.2022.12.007},
  journal      = {Neural Networks},
  pages        = {185-197},
  shortjournal = {Neural Netw.},
  title        = {An explainable autoencoder with multi-paradigm fMRI fusion for identifying differences in dynamic functional connectivity during brain development},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proposed algorithm for smart grid DDoS detection based on
deep learning. <em>NN</em>, <em>159</em>, 175–184. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Smart Grid’s objective is to increase the electric grid’s dependability , security, and efficiency through extensive digital information and control technology deployment. As a result, it is necessary to apply real-time analysis and state estimation-based techniques to ensure efficient controls are implemented correctly. These systems are vulnerable to cyber-attacks, posing significant risks to the Smart Grid’s overall availability due to their reliance on communication technology. Therefore, effective intrusion detection algorithms are required to mitigate such attacks. In dealing with these uncertainties, we propose a hybrid deep learning algorithm that focuses on Distributed Denial of Service attacks on the communication infrastructure of the Smart Grid. The proposed algorithm is hybridized by the Convolutional Neural Network and the Gated Recurrent Unit algorithms. Simulations are done using a benchmark cyber security dataset of the Canadian Institute of Cybersecurity Intrusion Detection System . According to the simulation results, the proposed algorithm outperforms the current intrusion detection algorithms, with an overall accuracy rate of 99.7\%.},
  archive      = {J_NN},
  author       = {Sayawu Yakubu Diaba and Mohammed Elmusrati},
  doi          = {10.1016/j.neunet.2022.12.011},
  journal      = {Neural Networks},
  pages        = {175-184},
  shortjournal = {Neural Netw.},
  title        = {Proposed algorithm for smart grid DDoS detection based on deep learning},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Observer-based dynamical pattern recognition via
deterministic learning. <em>NN</em>, <em>159</em>, 161–174. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, based on the sampled-data observer and the deterministic learning theory, a rapid dynamical pattern recognition approach is proposed for univariate time series composed of the output signals of the dynamical systems . Specifically, locally-accurate identification of inherent dynamics of univariate time series is first achieved by using the sampled-data observer and the radial basis function (RBF) networks. The dynamical estimators embedded with the learned knowledge are then designed by resorting to the sampled-data observer. It is proved that generated estimator residuals can reflect the difference between the system dynamics of the training and test univariate time series. Finally, a recognition decision-making scheme is proposed based on the residual norms of the dynamical estimators. Through rigorous analysis , recognition conditions are given to guarantee the accurate recognition of the dynamical pattern of the test univariate time series. The significance of this paper lies in that the difficult problems of dynamical modeling and rapid recognition for univariate time series are solved by incorporating the sampled-data observer design and the deterministic learning theory. The effectiveness of the proposed approach is confirmed by a numerical example and compressor stall warning experiments.},
  archive      = {J_NN},
  author       = {Jingtao Hu and Weiming Wu and Fukai Zhang and Tianrui Chen and Cong Wang},
  doi          = {10.1016/j.neunet.2022.12.004},
  journal      = {Neural Networks},
  pages        = {161-174},
  shortjournal = {Neural Netw.},
  title        = {Observer-based dynamical pattern recognition via deterministic learning},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Path reliability-based graph attention networks.
<em>NN</em>, <em>159</em>, 153–160. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-attention mechanism has been successfully introduced in Graph Neural Networks (GNNs) for graph representation learning and achieved state-of-the-art performances in tasks such as node classification and node attacks. In most existing attention-based GNNs, attention score is only computed between two directly connected nodes with their representation at a single layer. However, this attention score computation method cannot account for its multi-hop neighbors, which supply graph structure information and have influence on many tasks such as link prediction, knowledge graph completion, and adversarial attack as well. In order to address this problem, in this paper, we propose Path Reliability-based Graph Attention Networks (PRGATs), a novel method to incorporate multi-hop neighboring context into attention score computation, enabling to capture longer-range dependencies and large-scale structural information within a single layer. Moreover, path reliability-based attention layer, a core layer of PRGATs, uses a resource-constrain allocation algorithm to compute the reliable path and its attention scores from neighboring nodes to non-neighboring nodes, increasing the receptive field for every message-passing layer. Experimental results on real-world datasets show that, as compared with baselines, our model outperforms existing methods up to 3\% on standard node classification and 12\% on graph universal adversarial attack .},
  archive      = {J_NN},
  author       = {Yayang Li and Shuqing Liang and Yuncheng Jiang},
  doi          = {10.1016/j.neunet.2022.11.021},
  journal      = {Neural Networks},
  pages        = {153-160},
  shortjournal = {Neural Netw.},
  title        = {Path reliability-based graph attention networks},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Representation learning for continuous action spaces is
beneficial for efficient policy learning. <em>NN</em>, <em>159</em>,
137–152. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) breaks through the bottlenecks of traditional reinforcement learning (RL) with the help of the perception capability of deep learning and has been widely applied in real-world problems. While model-free RL, as a class of efficient DRL methods, performs the learning of state representations simultaneously with policy learning in an end-to-end manner when facing large-scale continuous state and action spaces. However, training such a large policy model requires a large number of trajectory samples and training time. On the other hand, the learned policy often fails to generalize to large-scale action spaces, especially for the continuous action spaces. To address this issue, in this paper we propose an efficient policy learning method in latent state and action spaces. More specifically, we extend the idea of state representations to action representations for better policy generalization capability. Meanwhile, we divide the whole learning task into learning with the large-scale representation models in an unsupervised manner and learning with the small-scale policy model in the RL manner. The small policy model facilitates policy learning, while not sacrificing generalization and expressiveness via the large representation model. Finally, the effectiveness of the proposed method is demonstrated by MountainCar, CarRacing and Cheetah experiments.},
  archive      = {J_NN},
  author       = {Tingting Zhao and Ying Wang and Wei Sun and Yarui Chen and Gang Niu and Masashi Sugiyama},
  doi          = {10.1016/j.neunet.2022.12.009},
  journal      = {Neural Networks},
  pages        = {137-152},
  shortjournal = {Neural Netw.},
  title        = {Representation learning for continuous action spaces is beneficial for efficient policy learning},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable three-term conjugate gradient method for training
artificial neural networks. <em>NN</em>, <em>159</em>, 125–136. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have been widely adopted as general computational tools both in computer science as well as many other engineering fields. Stochastic gradient descent (SGD) and adaptive methods such as Adam are popular as robust optimization algorithms used to train the ANNs. However, the effectiveness of these algorithms is limited because they calculate a search direction based on a first-order gradient. Although higher-order gradient methods such as Newton’s method have been proposed, they require the Hessian matrix to be semi-definite, and its inversion incurs a high computational cost. Therefore, in this paper, we propose a variable three-term conjugate gradient (VTTCG) method that approximates the Hessian matrix to enhance search direction and uses a variable step size to achieve improved convergence stability. To evaluate the performance of the VTTCG method, we train different ANNs on benchmark image classification and generation datasets. We also conduct a similar experiment in which a grasp generation and selection convolutional neural network (GGS-CNN) is trained to perform intelligent robotic grasping. After considering a simulated environment, we also test the GGS-CNN with a physical grasping robot. The experimental results show that the performance of the VTTCG method is superior to that of four conventional methods, including SGD , Adam, AMSGrad, and AdaBelief.},
  archive      = {J_NN},
  author       = {Hansu Kim and Chuxuan Wang and Hyoseok Byun and Weifei Hu and Sanghyuk Kim and Qing Jiao and Tae Hee Lee},
  doi          = {10.1016/j.neunet.2022.12.001},
  journal      = {Neural Networks},
  pages        = {125-136},
  shortjournal = {Neural Netw.},
  title        = {Variable three-term conjugate gradient method for training artificial neural networks},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Early stopping by correlating online indicators in neural
networks. <em>NN</em>, <em>159</em>, 109–124. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to minimize the generalization error in neural networks , a novel technique to identify overfitting phenomena when training the learner is formally introduced. This enables support of a reliable and trustworthy early stopping condition, thus improving the predictive power of that type of modeling. Our proposal exploits the correlation over time in a collection of online indicators, namely characteristic functions for indicating if a set of hypotheses are met, associated with a range of independent stopping conditions built from a canary judgment to evaluate the presence of overfitting. That way, we provide a formal basis for decision making in terms of interrupting the learning process. As opposed to previous approaches focused on a single criterion, we take advantage of subsidiarities between independent assessments, thus seeking both a wider operating range and greater diagnostic reliability. With a view to illustrating the effectiveness of the halting condition described, we choose to work in the sphere of natural language processing , an operational continuum increasingly based on machine learning . As a case study, we focus on parser generation, one of the most demanding and complex tasks in the domain. The selection of cross-validation as a canary function enables an actual comparison with the most representative early stopping conditions based on overfitting identification, pointing to a promising start toward an optimal bias and variance control.},
  archive      = {J_NN},
  author       = {Manuel Vilares Ferro and Yerai Doval Mosquera and Francisco J. Ribadas Pena and Víctor M. Darriba Bilbao},
  doi          = {10.1016/j.neunet.2022.11.035},
  journal      = {Neural Networks},
  pages        = {109-124},
  shortjournal = {Neural Netw.},
  title        = {Early stopping by correlating online indicators in neural networks},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accuracy of a deep learning method for heart sound analysis
is unrealistic. <em>NN</em>, <em>159</em>, 107–108. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Arash Gharehbaghi and Elaheh Partovi},
  doi          = {10.1016/j.neunet.2022.12.006},
  journal      = {Neural Networks},
  pages        = {107-108},
  shortjournal = {Neural Netw.},
  title        = {Accuracy of a deep learning method for heart sound analysis is unrealistic},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient perturbation inference and expandable network for
continual learning. <em>NN</em>, <em>159</em>, 97–106. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although humans are capable of learning new tasks without forgetting previous ones, most neural networks fail to do so because learning new tasks could override the knowledge acquired from previous data. In this work, we alleviate this issue by proposing a novel Efficient Perturbation Inference and Expandable Network (EPIE-Net), which dynamically expands lightweight task-specific decoders for new classes and utilizes a mixed-label uncertainty strategy to improve the robustness. Moreover, we calculate the average probability of perturbed samples at inference, which can generally improve the performance of the model. Experimental results show that our method consistently outperforms other methods with fewer parameters in class incremental learning benchmarks. For example, on the CIFAR-100 10 steps setup, our method achieves an average accuracy of 76.33\% and the last accuracy of 65.93\% within only 3.46M average parameters.},
  archive      = {J_NN},
  author       = {Fei Du and Yun Yang and Ziyuan Zhao and Zeng Zeng},
  doi          = {10.1016/j.neunet.2022.10.030},
  journal      = {Neural Networks},
  pages        = {97-106},
  shortjournal = {Neural Netw.},
  title        = {Efficient perturbation inference and expandable network for continual learning},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Factorizing time-heterogeneous markov transition for
temporal recommendation. <em>NN</em>, <em>159</em>, 84–96. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal recommendation which recommends items to users with consideration of time information has been of wide interest in recent years. But huge event space, highly sparse user activities and time-heterogeneous dependency of temporal behaviors make it really challenging to learn the temporal patterns for high-quality recommendation. In this paper, aiming to handle these challenges, especially the time-heterogeneous characteristic of user’s temporal behaviors , we proposed the Neural-based Time-heterogenous Markov Transition (NeuralTMT) model. Firstly, users’ temporal behaviors are mathematically simplified as the third-order Markov transition tensors. And then a linear co-factorization model which learns the time-evolving user/item factors from these tensors is proposed. Furthermore, the model is extended to the neural-based learning framework (NeuralTMT), which is more flexible and able to capture time-heterogeneous temporal patterns via nonlinear neural network mappings and attention techniques. Extensive experiments on four datasets demonstrate that NeuralTMT performs significantly better than the state-of-the-art baselines. And the proposed method is fundamentally inspired by factorization techniques, which may also provide some interesting ideas on the connection of tensor factorization and neural-based sequential recommendation methods.},
  archive      = {J_NN},
  author       = {Wen Wen and Wencui Wang and Zhifeng Hao and Ruichu Cai},
  doi          = {10.1016/j.neunet.2022.11.032},
  journal      = {Neural Networks},
  pages        = {84-96},
  shortjournal = {Neural Netw.},
  title        = {Factorizing time-heterogeneous markov transition for temporal recommendation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-fragile output-feedback synchronization for delayed
discrete-time complex-valued neural networks with randomly occurring
uncertainties. <em>NN</em>, <em>159</em>, 70–83. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is step forward to establish an exponential synchronization criterion for discrete-time complex-valued neural networks (CVNNs) having time-varying delays subject to randomly occurring uncertain weighting parameters, in order to overcome the fluctuation when the output-feedback controller imposes on its dynamics. To achieve this, Jensen’s weighted summation inequalities (WSIs) and an extended reciprocal convex matrix inequality (ERCMI) are extended into the domain of complex field. By introducing some augmented vectors, a Lyapunov–Krasovskii functional (LKF) is constructed to attain an improved delay-dependent linear matrix inequalities (LMIs) constraint for the exponential synchronization phenomenon of the desired master–slave neuronal system model. For instance, the upper bound of the quadratic summation terms occurred in the finite difference of the LKF have been obtained from its linearization that has been made by the developed complex-valued WSIs and complex-valued ERCMI. The proposed results are less restrictive with the minimum number of decision variables than those obtained using existing inequalities. The designed output-feedback control gain has been determined by solving a set of complex-valued LMIs and it has been enforced with a prescribed exponential decay rate . Finally, in sight of MATLAB software, the established results have been examined via a numerical example supported by the simulation results.},
  archive      = {J_NN},
  author       = {G. Soundararajan and G. Nagamani},
  doi          = {10.1016/j.neunet.2022.12.002},
  journal      = {Neural Networks},
  pages        = {70-83},
  shortjournal = {Neural Netw.},
  title        = {Non-fragile output-feedback synchronization for delayed discrete-time complex-valued neural networks with randomly occurring uncertainties},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DroneAttention: Sparse weighted temporal attention for
drone-camera based activity recognition. <em>NN</em>, <em>159</em>,
57–69. (<a href="https://doi.org/10.1016/j.neunet.2022.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) using drone-mounted cameras has attracted considerable interest from the computer vision research community in recent years. A robust and efficient HAR system has a pivotal role in fields like video surveillance, crowd behavior analysis, sports analysis, and human–computer interaction. What makes it challenging are the complex poses, understanding different viewpoints, and the environmental scenarios where the action is taking place. To address such complexities, in this paper, we propose a novel Sparse Weighted Temporal Attention (SWTA) module to utilize sparsely sampled video frames for obtaining global weighted temporal attention. The proposed SWTA is comprised of two parts. First, temporal segment network that sparsely samples a given set of frames. Second, weighted temporal attention, which incorporates a fusion of attention maps derived from optical flow, with raw RGB images. This is followed by a basenet network, which comprises a convolutional neural network (CNN) module along with fully connected layers that provide us with activity recognition. The SWTA network can be used as a plug-in module to the existing deep CNN architectures, for optimizing them to learn temporal information by eliminating the need for a separate temporal stream. It has been evaluated on three publicly available benchmark datasets, namely Okutama, MOD20, and Drone-Action. The proposed model has received an accuracy of 72.76\%, 92.56\%, and 78.86\% on the respective datasets thereby surpassing the previous state-of-the-art performances by a margin of 25.26\%, 18.56\%, and 2.94\%, respectively.},
  archive      = {J_NN},
  author       = {Santosh Kumar Yadav and Achleshwar Luthra and Esha Pahwa and Kamlesh Tiwari and Heena Rathore and Hari Mohan Pandey and Peter Corcoran},
  doi          = {10.1016/j.neunet.2022.12.005},
  journal      = {Neural Networks},
  pages        = {57-69},
  shortjournal = {Neural Netw.},
  title        = {DroneAttention: Sparse weighted temporal attention for drone-camera based activity recognition},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Graph spring network and informative anchor selection for
session-based recommendation. <em>NN</em>, <em>159</em>, 43–56. (<a
href="https://doi.org/10.1016/j.neunet.2022.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) aims at predicting the next item for an ongoing anonymous session. The major challenge of SBR is how to capture richer relations in between items and learn ID-based item embeddings to capture such relations. Recent studies propose to first construct an item graph from sessions and employ a Graph Neural Network (GNN) to encode item embedding from the graph. Although such graph-based approaches have achieved performance improvements, their GNNs are not suitable for ID-based embedding learning for the SBR task. In this paper, we argue that the objective of such ID-based embedding learning is to capture a kind of neighborhood affinity in that the embedding of a node is similar to that of its neighbors’ in the embedding space. We propose a new graph neural network, called Graph Spring Network (GSN), for learning ID-based item embedding on an item graph to optimize neighborhood affinity in the embedding space. Furthermore, we argue that even stacking multiple GNN layers may not be enough to encode potential relations for two item nodes far-apart in a graph. In this paper, we propose a strategy that first selects some informative item anchors and then encode items’ potential relations to such anchors. In summary, we propose a GSN-IAS model ( G raph S pring N etwork and I nformative A nchor S election) for the SBR task. We first construct an item graph to describe items’ co-occurrences in all sessions. We design the GSN for ID-based item embedding learning and propose an item entropy measure to select informative anchors. We then design an unsupervised learning mechanism to encode items’ relations to anchors. We next employ a shared gated recurrent unit (GRU) network to learn two session representations and make two next item predictions. Finally, we design an adaptive decision fusion strategy to fuse two predictions to make the final recommendation. Extensive experiments on three public datasets demonstrate the superiority of our GSN-IAS model over the state-of-the-art models.},
  archive      = {J_NN},
  author       = {Zizhuo Zhang and Bang Wang},
  doi          = {10.1016/j.neunet.2022.12.003},
  journal      = {Neural Networks},
  pages        = {43-56},
  shortjournal = {Neural Netw.},
  title        = {Graph spring network and informative anchor selection for session-based recommendation},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Depth map guided triplet network for deepfake face
detection. <em>NN</em>, <em>159</em>, 34–42. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread dissemination of facial forgery technology has brought many ethical issues and aroused widespread concern in society. Most research today treats deepfake detection as a fine grained classification task , which however makes it difficult to enable the feature extractor to express the features related to the real and fake attributes. This paper proposes a depth map guided triplet network, which mainly consists of a depth prediction network and a triplet feature extraction network . The depth map predicted by the depth prediction network can effectively reflect the differences between real and fake faces in discontinuity, inconsistent illumination, and blurring, thus in favor of deepfake detection. Regardless of the facial appearance changes induced by deepfake, we argue that real and fake faces should correspond to their respective latent feature spaces. Particularly, the pair of real faces (original–target) remain close in the latent feature space, while the two pairs of real–fake faces (original–fake, target–fake) instead keep faraway. Following this paradigm, we suggest a triplet loss supervision network to extract the sufficiently discriminative deep features, which minimizes the distance of the original–target pair and maximize the distance of the original–fake (also target–fake) pair. The extensive results on public FaceForensics++ and Celeb-DF datasets validate the superiority of our method over competitors.},
  archive      = {J_NN},
  author       = {Buyun Liang and Zhongyuan Wang and Baojin Huang and Qin Zou and Qian Wang and Jingjing Liang},
  doi          = {10.1016/j.neunet.2022.11.031},
  journal      = {Neural Networks},
  pages        = {34-42},
  shortjournal = {Neural Netw.},
  title        = {Depth map guided triplet network for deepfake face detection},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SGORNN: Combining scalar gates and orthogonal constraints in
recurrent networks. <em>NN</em>, <em>159</em>, 25–33. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent Neural Network (RNN) models have been applied in different domains, producing high accuracies on time-dependent data. However, RNNs have long suffered from exploding gradients during training, mainly due to their recurrent process. In this context, we propose a variant of the scalar gated FastRNN architecture, called Scalar Gated Orthogonal Recurrent Neural Networks (SGORNN). SGORNN utilizes orthogonal matrices at the recurrent step. Our experiments evaluate SGORNN using two recently proposed orthogonal parametrizations for the recurrent weights of an RNN. We present a constraint on the scalar gates of SGORNN, which is easily enforced at training time to provide a probabilistic generalization gap which grows linearly with the length of sequences processed. Next, we provide bounds on the gradients of SGORNN to show the impossibility of exponentially exploding gradients through time. Our experimental results on the addition problem confirm that our combination of orthogonal and scalar gated RNNs are able to outperform other orthogonal RNNs and LSTM on long sequences. We further evaluate SGORNN on the HAR-2 classification task , where it improves upon the accuracy of several models using far fewer parameters than standard RNNs. Finally, we evaluate SGORNN on the Penn Treebank word-level language modeling task, where it again outperforms its related architectures and shows comparable performance to LSTM using far less parameters. Overall, SGORNN shows higher representation capacity than the other orthogonal RNNs tested, suffers from less overfitting than other models in our experiments, benefits from a decrease in parameter count, and alleviates exploding gradients during backpropagation through time.},
  archive      = {J_NN},
  author       = {Will Taylor-Melanson and Martha Dais Ferreira and Stan Matwin},
  doi          = {10.1016/j.neunet.2022.11.028},
  journal      = {Neural Networks},
  pages        = {25-33},
  shortjournal = {Neural Netw.},
  title        = {SGORNN: Combining scalar gates and orthogonal constraints in recurrent networks},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monte carlo ensemble neural network for the diagnosis of
alzheimer’s disease. <em>NN</em>, <em>159</em>, 14–24. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been increasingly used in the computer-aided diagnosis of Alzheimer’s Disease (AD). This study takes the advantage of the 2D-slice CNN fast computation and ensemble approaches to develop a Monte Carlo Ensemble Neural Network (MCENN) by introducing Monte Carlo sampling and an ensemble neural network in the integration with ResNet50 . Our goals are to improve the 2D-slice CNN performance and to design the MCENN model insensitive to image resolution. Unlike traditional ensemble approaches with multiple base learners, our MCENN model incorporates one neural network learner and generates a large number of possible classification decisions via Monte Carlo sampling of feature importance within the combined slices. This can overcome the main weakness of the lack of 3D brain anatomical information in 2D-slice CNNs and develop a neural network to learn the 3D relevance of the features across multiple slices. Brain images from Alzheimer’s Disease Neuroimaging Initiative (ADNI, 7199 scans), the Open Access Series of Imaging Studies-3 (OASIS-3, 1992 scans), and a clinical sample (239 scans) are used to evaluate the performance of the MCENN model for the classification of cognitively normal (CN), patients with mild cognitive impairment (MCI) and AD. Our MCENN with a small number of slices and minimal image processing (rigid transformation, intensity normalization, skull stripping) achieves the AD classification accuracy of 90\%, better than existing 2D-slice CNNs (accuracy: 63\% ∼ 84\% 63\%∼84\% ) and 3D CNNs (accuracy: 74\% ∼ 88\% 74\%∼88\% ). Furthermore, the MCENN is robust to be trained in the ADNI dataset and applied to the OASIS-3 dataset and the clinical sample. Our experiments show that the AD classification accuracy of the MCENN model is comparable when using high- and low-resolution brain images, suggesting the insensitivity of the MCENN to image resolution. Hence, the MCENN does not require high-resolution 3D brain structural images and comprehensive image processing , which supports its potential use in a clinical setting.},
  archive      = {J_NN},
  author       = {Chaoqiang Liu and Fei Huang and Anqi Qiu and Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.neunet.2022.10.032},
  journal      = {Neural Networks},
  pages        = {14-24},
  shortjournal = {Neural Netw.},
  title        = {Monte carlo ensemble neural network for the diagnosis of alzheimer’s disease},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronization of hybrid switching diffusions delayed
networks via stochastic event-triggered control. <em>NN</em>,
<em>159</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization problem of stochastic complex networks with time delays and hybrid switching diffusions (SCNTH) is concerned based on event-triggered control. Therein, a new class of event-triggered function is proposed for the control design. Particularly, different from the existing work, the triggered instant generated by event-triggered control in this paper is a stochastic sequence instead of a number sequence to be more realistic for stochastic systems , which is a breakthrough. Furthermore, some sufficient conditions are derived to guarantee asymptotical synchronization in mean square , exponential synchronization in mean square and almost surely exponential synchronization of SCNTH based on sampled-data control, event-driven control theory and stability analysis. Meanwhile, the Zeno phenomenon can be avoided. Then, the synchronization of single-link robot arms is investigated in detail as a practical application of the obtained results. Ultimately, a numerical example is given for demonstration.},
  archive      = {J_NN},
  author       = {Hui Zhou and Shufan Li and Chunmei Zhang},
  doi          = {10.1016/j.neunet.2022.11.034},
  journal      = {Neural Networks},
  pages        = {1-13},
  shortjournal = {Neural Netw.},
  title        = {Synchronization of hybrid switching diffusions delayed networks via stochastic event-triggered control},
  volume       = {159},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023g). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>158</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(22)00520-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(22)00520-2},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Current events. <em>NN</em>, <em>158</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(22)00519-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(22)00519-6},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {Current events},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CT-loc: Cross-domain visual localization with a channel-wise
transformer. <em>NN</em>, <em>158</em>, 369–383. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle the cross-domain visual localization problem of estimating camera position and orientation from real images without three-dimensional (3D) spatial mapping or modeling. Recent studies have shown suboptimal performance in this task owing to the photometric and geometric differences between synthetic and real images. In this study, we present a deep learning approach that uses a channel-wise transformer localization (CT-Loc) framework. Inspired by the human behavior of looking for structural landmarks to estimate one’s location, CT-Loc encodes the most salient features of task-relevant objects in target scenes. To evaluate the efficacy of the proposed method in a real-world application, we built a complex and large-scale dataset of the interior of the mechanical room during operations and conducted extensive performance comparisons with the publicly available state-of-the-art University of Melbourne Corridor and Virtual KITTI 2 datasets. Compared with the otherwise best-performing BIM-PoseNet indoor camera localization model, our method significantly reduces position and orientation errors through the application of attention weights and saliency maps while also learning only the visual structural patterns (e.g., floors and doors) that are most relevant to localization tasks. Our model successfully ignores uninformative objects. This approach yields higher-level robust camera-pose regression localization results without requiring prebuilt maps. The code is available at https://github.com/kdaeho27/CT-Loc .},
  archive      = {J_NN},
  author       = {Daeho Kim and Jaeil Kim},
  doi          = {10.1016/j.neunet.2022.11.014},
  journal      = {Neural Networks},
  pages        = {369-383},
  shortjournal = {Neural Netw.},
  title        = {CT-loc: Cross-domain visual localization with a channel-wise transformer},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised graph-level representation learning with
hierarchical contrasts. <em>NN</em>, <em>158</em>, 359–368. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised graph-level representation learning has recently shown great potential in a variety of domains, ranging from bioinformatics to social networks. Plenty of graph contrastive learning methods have been proposed to generate discriminative graph-level representations recently. They typically design multiple types of graph augmentations and enforce a graph to have consistent representations under different views. However, these techniques mostly neglect the intrinsic hierarchical structure of the graph, resulting in a limited exploration of semantic information for graph representation . Moreover, they often rely on a large number of negative samples to prevent collapsing into trivial solutions , while a great need for negative samples may lead to memory issues during optimization in graph domains. To address the two issues, this paper develops an unsupervised graph-level representation learning framework named H ierarchical G raph C ontrastive L earning (HGCL), which investigates the hierarchical structural semantics of a graph at both node and graph levels. Specifically, our HGCL consists of three parts, i.e., node-level contrastive learning , graph-level contrastive learning, and mutual contrastive learning to capture graph semantics hierarchically. Furthermore, the Siamese network and momentum update are further involved to release the demand for excessive negative samples. Finally, the experimental results on both benchmark datasets for graph classification and large-scale OGB datasets for transfer learning demonstrate that our proposed HGCL significantly outperforms a broad range of state-of-the-art baselines.},
  archive      = {J_NN},
  author       = {Wei Ju and Yiyang Gu and Xiao Luo and Yifan Wang and Haochen Yuan and Huasong Zhong and Ming Zhang},
  doi          = {10.1016/j.neunet.2022.11.019},
  journal      = {Neural Networks},
  pages        = {359-368},
  shortjournal = {Neural Netw.},
  title        = {Unsupervised graph-level representation learning with hierarchical contrasts},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A singular riemannian geometry approach to deep neural
networks II. Reconstruction of 1-d equivalence classes. <em>NN</em>,
<em>158</em>, 344–358. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We proposed in a previous work a geometric framework to study a deep neural network , seen as sequence of maps between manifolds, employing singular Riemannian geometry . In this paper, we present an application of this framework, proposing a way to build the class of equivalence of an input point: such class is defined as the set of the points on the input manifold mapped to the same output by the neural network . In other words, we build the preimage of a point in the output manifold in the input space. In particular. We focus for simplicity on the case of neural networks maps from n n –dimensional real spaces to ( n − 1 n−1 )–dimensional real spaces, we propose an algorithm allowing to build the set of points lying on the same class of equivalence. This approach leads to two main applications: the generation of new synthetic data and it may provides some insights on how a classifier can be confused by small perturbation on the input data ( e.g. a penguin image classified as an image containing a chihuahua). In addition, for neural networks from 2D to 1D real spaces, we also discuss how to find the preimages of closed intervals of the real line. We also present some numerical experiments with several neural networks trained to perform non-linear regression tasks, including the case of a binary classifier .},
  archive      = {J_NN},
  author       = {Alessandro Benfenati and Alessio Marta},
  doi          = {10.1016/j.neunet.2022.11.026},
  journal      = {Neural Networks},
  pages        = {344-358},
  shortjournal = {Neural Netw.},
  title        = {A singular riemannian geometry approach to deep neural networks II. reconstruction of 1-D equivalence classes},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A singular riemannian geometry approach to deep neural
networks i. Theoretical foundations. <em>NN</em>, <em>158</em>, 331–343.
(<a href="https://doi.org/10.1016/j.neunet.2022.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks are widely used for solving complex problems in several scientific areas, such as speech recognition, machine translation, image analysis. The strategies employed to investigate their theoretical properties mainly rely on Euclidean geometry , but in the last years new approaches based on Riemannian geometry have been developed. Motivated by some open problems, we study a particular sequence of maps between manifolds, with the last manifold of the sequence equipped with a Riemannian metric. We investigate the structures induced through pullbacks on the other manifolds of the sequence and on some related quotients. In particular, we show that the pullbacks of the final Riemannian metric to any manifolds of the sequence is a degenerate Riemannian metric inducing a structure of pseudometric space. We prove that the Kolmogorov quotient of this pseudometric space yields a smooth manifold, which is the base space of a particular vertical bundle. We investigate the theoretical properties of the maps of such sequence, eventually we focus on the case of maps between manifolds implementing neural networks of practical interest and we present some applications of the geometric framework we introduced in the first part of the paper.},
  archive      = {J_NN},
  author       = {Alessandro Benfenati and Alessio Marta},
  doi          = {10.1016/j.neunet.2022.11.022},
  journal      = {Neural Networks},
  pages        = {331-343},
  shortjournal = {Neural Netw.},
  title        = {A singular riemannian geometry approach to deep neural networks i. theoretical foundations},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guest editorial: Special issue on advances in deep learning
based speech processing. <em>NN</em>, <em>158</em>, 328–330. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Xiao-Lei Zhang and Lei Xie and Eric Fosler-Lussier and Emmanuel Vincent},
  doi          = {10.1016/j.neunet.2022.11.033},
  journal      = {Neural Networks},
  pages        = {328-330},
  shortjournal = {Neural Netw.},
  title        = {Guest editorial: Special issue on advances in deep learning based speech processing},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep MCANC: A deep learning approach to multi-channel
active noise control. <em>NN</em>, <em>158</em>, 318–327. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional multi-channel active noise control (MCANC) is based on adaptive filtering and usually uses a separate control unit for each channel. This paper introduces a deep learning based approach for multi-channel active noise control (ANC). The proposed approach, called deep MCANC, encodes optimal control parameters corresponding to different noises and environments, and jointly computes the multiple canceling signals to cancel or attenuate the primary noises captured at error microphones. A convolutional recurrent network (CRN) is employed for complex spectral mapping where the summated power of error signals is used as the loss function for CRN training. Deep MCANC is a fixed-parameter ANC approach and large-scale multi-condition training is employed to achieve robustness against a variety of noises. We explore the performance of deep MCANC with different setups and investigate the impact of factors such as the number of loudspeakers and microphones, and the position of a secondary source, on ANC performance. Experimental results show that deep MCANC is effective for wideband noise reduction and generalizes well to untrained noises. Moreover, the proposed approach is robust against variations in reference signals and works well in the presence of nonlinear distortions .},
  archive      = {J_NN},
  author       = {Hao Zhang and DeLiang Wang},
  doi          = {10.1016/j.neunet.2022.11.029},
  journal      = {Neural Networks},
  pages        = {318-327},
  shortjournal = {Neural Netw.},
  title        = {Deep MCANC: A deep learning approach to multi-channel active noise control},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-graph fusion graph convolutional networks with
pseudo-label supervision. <em>NN</em>, <em>158</em>, 305–317. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have become a popular tool for learning unstructured graph data due to their powerful learning ability. Many researchers have been interested in fusing topological structures and node features to extract the correlation information for classification tasks . However, it is inadequate to integrate the embedding from topology and feature spaces to gain the most correlated information. At the same time, most GCN-based methods assume that the topology graph or feature graph is compatible with the properties of GCNs, but this is usually not satisfied since meaningless, missing, or even unreal edges are very common in actual graphs. To obtain a more robust and accurate graph structure, we intend to construct an adaptive graph with topology and feature graphs. We propose Multi-graph Fusion Graph Convolutional Networks with pseudo-label supervision (MFGCN), which learn a connected embedding by fusing the multi-graphs and node features. We can obtain the final node embedding for semi-supervised node classification by propagating node features over multi-graphs. Furthermore, to alleviate the problem of labels missing in semi-supervised classification, a pseudo-label generation mechanism is proposed to generate more reliable pseudo-labels based on the similarity of node features. Extensive experiments on six benchmark datasets demonstrate the superiority of MFGCN over state-of-the-art classification methods.},
  archive      = {J_NN},
  author       = {Yachao Yang and Yanfeng Sun and Fujiao Ju and Shaofan Wang and Junbin Gao and Baocai Yin},
  doi          = {10.1016/j.neunet.2022.11.027},
  journal      = {Neural Networks},
  pages        = {305-317},
  shortjournal = {Neural Netw.},
  title        = {Multi-graph fusion graph convolutional networks with pseudo-label supervision},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forgetting memristor based STDP learning circuit for neural
networks. <em>NN</em>, <em>158</em>, 293–304. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The circuit implementation of STDP based on memristor is of great significance for the application of neural network . However, recent research shows that the research on the pure circuit implementation of forgetting memristor and STDP is still rare. This paper proposes a new STDP learning rule implementation circuit based on the forgetting memristor. This kind of forgetting memory resistance synapse makes the neural network have the function of time-division multiplexing, but the instability of short-term memory will affect the learning ability of the neural network. This paper analyzes and discusses the influence of synapses with long-term and short-term memory on the learning characteristics of neural network STDP, which lays a foundation for the construction of time-division multiplexing neural network with long-term and short-term memory synapses. Through this circuit, it is found that the volatile memristor has different behaviors to the stimulus signal in different initial states, and the resulting LTP phenomenon is more in line with the forgetting effect in biology. This circuit has multiple adjustable parameters, which can fit the STDP learning rules under different conditions. The application of neural network proves the availability of this circuit.},
  archive      = {J_NN},
  author       = {Wenhao Zhou and Shiping Wen and Yi Liu and Lu Liu and Xin Liu and Ling Chen},
  doi          = {10.1016/j.neunet.2022.11.023},
  journal      = {Neural Networks},
  pages        = {293-304},
  shortjournal = {Neural Netw.},
  title        = {Forgetting memristor based STDP learning circuit for neural networks},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IA-FaceS: A bidirectional method for semantic face editing.
<em>NN</em>, <em>158</em>, 272–292. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic face editing has achieved substantial progress in recent years. However, existing face editing methods, which often encode the entire image into a single code, still have difficulty in enabling flexible editing while keeping high-fidelity reconstruction. The one-code scheme also brings entangled face manipulations and limited flexibility in editing face components. In this paper, we present IA-FaceS, a bidirectional method for disentangled face attribute manipulation as well as flexible, controllable component editing. We propose to embed images onto two branches: one branch computes high-dimensional component-invariant content embedding for capturing face details, and the other provides low-dimensional component-specific embeddings for component manipulations. The two-branch scheme naturally enables high-quality facial component-level editing while keeping faithful reconstruction with details. Moreover, we devise a component adaptive modulation (CAM) module, which integrates component-specific guidance into the decoder and successfully disentangles highly-correlated face components. The single-eye editing is developed for the first time without editing face masks or sketches. According to the experimental results, IA-FaceS establishes a good balance between maintaining image details and performing flexible face manipulation. Both quantitative and qualitative results indicate that the proposed method outperforms the existing methods in reconstruction, face attribute manipulation, and component transfer. We release the code and weights at: https://github.com/CMACH508/IA-FaceS .},
  archive      = {J_NN},
  author       = {Wenjing Huang and Shikui Tu and Lei Xu},
  doi          = {10.1016/j.neunet.2022.11.016},
  journal      = {Neural Networks},
  pages        = {272-292},
  shortjournal = {Neural Netw.},
  title        = {IA-FaceS: A bidirectional method for semantic face editing},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strictly intermittent quantized control for
fixed/predefined-time cluster lag synchronization of stochastic
multi-weighted complex networks. <em>NN</em>, <em>158</em>, 258–271. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the fixed-time (F-T) and predefined-time (P-T) cluster lag synchronization of stochastic multi-weighted complex networks (SMWCNs) via strictly intermittent quantized control (SIQC). Firstly, by exploiting mathematical induction and reduction to absurdity, a novel F-T stability lemma is proved and an accurate estimation of settling time (ST) is obtained. Subsequently, by virtue of the proposed F-T stability, some simple conditions that ensure the F-T cluster lag synchronization of SMWCNs are derived by developing a SIQC strategy. Furthermore, the P-T cluster lag synchronization is also explored based on a SIQC design, where the ST can be predefined by an adjustable constant of the controller. Note that the designed controllers here are simpler and more economical than the traditional design whose the linear part is still activated during the rest interval. Finally, two numerical examples are provided to verify the effectiveness of the theoretical results.},
  archive      = {J_NN},
  author       = {Xuejiao Qin and Haijun Jiang and Jianlong Qiu and Cheng Hu and Yue Ren},
  doi          = {10.1016/j.neunet.2022.10.033},
  journal      = {Neural Networks},
  pages        = {258-271},
  shortjournal = {Neural Netw.},
  title        = {Strictly intermittent quantized control for fixed/predefined-time cluster lag synchronization of stochastic multi-weighted complex networks},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale multi-reception attention network for bone age
assessment in x-ray images. <em>NN</em>, <em>158</em>, 249–257. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone age assessment plays a significant role in estimating bone maturity. However, radiograph/X-ray images of hand bones contain a large amount of redundant information. Some detection or segmentation based methods have recently been proposed to solve this issue. These network structures are often of high complexity and might require extra annotations, which make them less applicable in practice. In this paper, we present a Multi-scale Multi-reception Attention Net (MMANet), which combines a novel Multi-scale Multi-reception Complement Attention (MMCA) network and a graph attention module with a ResNet backbone to enhance the feature representation of key regions and suppress the influence of background regions to achieve significant performance improvement. Experimental results show our MMANet is able to accurately detect key regions and achieves 3.88 mean absolute error (MAE) on the RSNA 2017 Paediatric Bone Age Challenge dataset. Our method, without explicit modelling of anatomical information, outperforms the current state-of-the-art method (MAE=3.91) by 0.03 (months) which requires extra annotations. Code is available at https://github.com/yzc1122333/BoneAgeAss .},
  archive      = {J_NN},
  author       = {Zhichao Yang and Cong Cong and Maurice Pagnucco and Yang Song},
  doi          = {10.1016/j.neunet.2022.11.002},
  journal      = {Neural Networks},
  pages        = {249-257},
  shortjournal = {Neural Netw.},
  title        = {Multi-scale multi-reception attention network for bone age assessment in X-ray images},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pavlovian-based neurofeedback enhances meta-awareness of
mind-wandering. <em>NN</em>, <em>158</em>, 239–248. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Absorption in mind-wandering (MW) may worsen our mood and can cause psychological disorders. Researchers indicate the possibility that meta-awareness of MW prevents these mal-effects and enhances favorable consequences of MW, such as boosting creativity; thus, meta-awareness has attracted psychological and clinical attention. However, few studies have investigated the nature of meta-awareness of MW, because there has been no method to isolate and operate this ability. Therefore, we propose a new approach to manipulate the ability of meta-awareness. We used Pavlovian conditioning, tying to it an occurrence of MW and a neutral tone sound inducing the meta-awareness of MW. To perform paired presentations of the unconditioned stimulus (neutral tone) and the conditioned stimulus (perception accompanying MW), we detected participants’ natural occurrence of MW via electroencephalogram and a machine-learning estimation method. The double-blinded randomized controlled trial with 37 participants found that a single 20-min conditioning session significantly increased the meta-awareness of MW as assessed by behavioral and neuroscientific measures. The core protocol of the proposed method is real-time feedback on participants’ neural information, and in that sense, we can refer to it as neurofeedback . However, there are some differences from typical neurofeedback protocols, and we discuss them in this paper. Our novel classical conditioning is expected to contribute to future research on the modulation effect of meta-awareness on MW.},
  archive      = {J_NN},
  author       = {Issaku Kawashima and Toru Nagahama and Hiroaki Kumano and Keiko Momose and Saori C. Tanaka},
  doi          = {10.1016/j.neunet.2022.11.024},
  journal      = {Neural Networks},
  pages        = {239-248},
  shortjournal = {Neural Netw.},
  title        = {Pavlovian-based neurofeedback enhances meta-awareness of mind-wandering},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SSA-ICL: Multi-domain adaptive attention with intra-dataset
continual learning for facial expression recognition. <em>NN</em>,
<em>158</em>, 228–238. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) is a kind of affective computing that identifies the emotional state represented in facial photographs. Various methods have been developed for completing this critical task. In spite of this progress, three significant obstacles, the interaction between spatial action units, the inadequacy of semantic information about spectral expressions and the unbalanced data distribution, are not well addressed. In this work, we propose SSA-ICL, a novel approach for FER, and solve these three difficulties inside a coherent framework. To address the first two challenges, we develop a Spectral and Spatial Attention (SSA) module that integrates spectral semantics with spatial locations to improve the performance of the model. We provide an Intra-dataset Continual Learning (ICL) module to combat the issue of long-tail distribution in FER datasets. By subdividing a single long-tail dataset into multiple sub-datasets, ICL repeatedly trains well-balanced representations from each subset and finally develop a independent classifier. We performed extensive experiments on two publicly available datasets, AffectNet and RAFDB. In comparison to existing attention modules, our SSA achieves an accuracy improvement of 3 . 8\% ∼ 6 . 7\% 3.8\%∼6.7\% , as evidenced by testing results. In the meanwhile, our proposed SSA-ICL can achieve superior or comparable performance to state-of-the-art FER methods (65.78\% on AffectNet and 89.44\% on RAFDB).},
  archive      = {J_NN},
  author       = {Hongxiang Gao and Min Wu and Zhenghua Chen and Yuwen Li and Xingyao Wang and Shan An and Jianqing Li and Chengyu Liu},
  doi          = {10.1016/j.neunet.2022.11.025},
  journal      = {Neural Networks},
  pages        = {228-238},
  shortjournal = {Neural Netw.},
  title        = {SSA-ICL: Multi-domain adaptive attention with intra-dataset continual learning for facial expression recognition},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural speech enhancement with unsupervised pre-training and
mixture training. <em>NN</em>, <em>158</em>, 216–227. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised neural speech enhancement methods always require a large scale of paired noisy and clean speech data. Since collecting adequate paired data from real-world applications is infeasible, simulated data is always adopted in supervised learning methods. However, the mismatch between the simulated data and in-the-wild data always causes performance inconsistency when the system is deployed in real-world applications. Unsupervised speech enhancement methods are studied to address the mismatch problem by directly using the in-the-wild noisy data without access to the corresponding clean speech. Therefore, the simulated paired data is not necessary. However, the performance of the unsupervised speech enhancement method is not on par with the supervised learning method. To address the aforementioned problems, this work proposes an unsupervised pre-training and mixture training algorithm by leveraging the advantages of supervised and unsupervised learning methods. Specifically, the proposed speech enhancement approach employs large volumes of unpaired noisy and clean speech to conduct unsupervised pre-training. The noisy data and a small amount of simulated paired data are then used for mixture training to optimize the pre-trained model. Experimental results show that the proposed method achieves better performances than other state-of-the-art supervised and unsupervised learning methods.},
  archive      = {J_NN},
  author       = {Xiang Hao and Chenglin Xu and Lei Xie},
  doi          = {10.1016/j.neunet.2022.11.013},
  journal      = {Neural Networks},
  pages        = {216-227},
  shortjournal = {Neural Netw.},
  title        = {Neural speech enhancement with unsupervised pre-training and mixture training},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating reinforcement learning with case-based
model-assisted experience augmentation for process control. <em>NN</em>,
<em>158</em>, 197–215. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of intelligent manufacturing in the process industry, traditional model-based optimization control methods cannot adapt to the situation of drastic changes in working conditions or operating modes. Reinforcement learning (RL) directly achieves the control objective by interacting with the environment, and has significant advantages in the presence of uncertainty since it does not require an explicit model of the operating plant. However, most RL algorithms fail to retain transfer learning capabilities in the presence of mode variation , which becomes a practical obstacle to industrial process control applications. To address these issues, we design a framework that uses local data augmentation to improve the training efficiency and transfer learning (adaptability) performance. Therefore, this paper proposes a novel RL control algorithm, CBR-MA-DDPG, organically integrating case-based reasoning (CBR), model-assisted (MA) experience augmentation, and deep deterministic policy gradient (DDPG). When the operating mode changes, CBR-MA-DDPG can quickly adapt to the varying environment and achieve the desired control performance within several training episodes. Experimental analyses on a continuous stirred tank reactor (CSTR) and an organic Rankine cycle (ORC) demonstrate the superiority of the proposed method in terms of both adaptability and control performance/robustness. The results show that the control performance of the CBR-MA-DDPG agent outperforms the conventional PI and MPC control schemes, and that it has higher training efficiency than the state-of-the-art DDPG, TD3, and PPO algorithms in transfer learning scenarios with mode shift situations.},
  archive      = {J_NN},
  author       = {Runze Lin and Junghui Chen and Lei Xie and Hongye Su},
  doi          = {10.1016/j.neunet.2022.10.016},
  journal      = {Neural Networks},
  pages        = {197-215},
  shortjournal = {Neural Netw.},
  title        = {Accelerating reinforcement learning with case-based model-assisted experience augmentation for process control},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified deep semi-supervised graph learning scheme based
on nodes re-weighting and manifold regularization. <em>NN</em>,
<em>158</em>, 188–196. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, semi-supervised learning on graphs has gained importance in many fields and applications. The goal is to use both partially labeled data (labeled examples) and a large amount of unlabeled data to build more effective predictive models . Deep Graph Neural Networks (GNNs) are very useful in both unsupervised and semi-supervised learning problems. As a special class of GNNs, Graph Convolutional Networks (GCNs) aim to obtain data representation through graph-based node smoothing and layer-wise neural network transformations. However, GCNs have some weaknesses when applied to semi-supervised graph learning: (1) it ignores the manifold structure implicitly encoded by the graph; (2) it uses a fixed neighborhood graph and focuses only on the convolution of a graph, but pays little attention to graph construction ; (3) it rarely considers the problem of topological imbalance. To overcome the above shortcomings, in this paper, we propose a novel semi-supervised learning method called Re-weight Nodes and Graph Learning Convolutional Network with Manifold Regularization (ReNode-GLCNMR). Our proposed method simultaneously integrates graph learning and graph convolution into a unified network architecture , which also enforces label smoothing through an unsupervised loss term. At the same time, it addresses the problem of imbalance in graph topology by adaptively reweighting the influence of labeled nodes based on their distances to the class boundaries. Experiments on 8 benchmark datasets show that ReNode-GLCNMR significantly outperforms the state-of-the-art semi-supervised GNN methods. 1},
  archive      = {J_NN},
  author       = {Fadi Dornaika and Jingjun Bi and Chongsheng Zhang},
  doi          = {10.1016/j.neunet.2022.11.017},
  journal      = {Neural Networks},
  pages        = {188-196},
  shortjournal = {Neural Netw.},
  title        = {A unified deep semi-supervised graph learning scheme based on nodes re-weighting and manifold regularization},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual learning with attentive recurrent neural networks
for temporal data classification. <em>NN</em>, <em>158</em>, 171–187.
(<a href="https://doi.org/10.1016/j.neunet.2022.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning is an emerging research branch of deep learning , which aims to learn a model for a series of tasks continually without forgetting knowledge obtained from previous tasks. Despite receiving a lot of attention in the research community, temporal-based continual learning techniques are still underutilized. In this paper, we address the problem of temporal-based continual learning by allowing a model to continuously learn on temporal data. To solve the catastrophic forgetting problem of learning temporal data in task incremental scenarios , in this research, we propose a novel method based on attentive recurrent neural networks , called Temporal Teacher Distillation (TTD). TTD solves the catastrophic forgetting problem in an attentive recurrent neural network based on three hypotheses, namely Rotation Hypothesis, Redundant Hypothesis, and Recover Hypothesis. Rotation Hypothesis and Redundant hypotheses could cause the attention shift phenomenon, which degrades the model performance on the learned tasks. Moreover, not considering the Recover Hypothesis increases extra memory usage in continuously training different tasks. Therefore, the proposed TTD based on the above hypotheses complements the inadequacy of the existing methods for temporal-based continual learning. For evaluating the performance of our proposed method in task incremental setting, we use a public dataset, WIreless Sensor Data Mining (WISDM) , and a synthetic dataset , Split-QuickDraw-100 . According to experimental results, the proposed TTD significantly outperforms state-of-the-art methods by up to 14.6\% and 45.1\% in terms of accuracy and forgetting measures, respectively. To the best of our knowledge, this is the first work that studies continual learning in real-world incremental categories for temporal data classification with attentive recurrent neural networks and provides the proper application-oriented scenario.},
  archive      = {J_NN},
  author       = {Shao-Yu Yin and Yu Huang and Tien-Yu Chang and Shih-Fang Chang and Vincent S. Tseng},
  doi          = {10.1016/j.neunet.2022.10.031},
  journal      = {Neural Networks},
  pages        = {171-187},
  shortjournal = {Neural Netw.},
  title        = {Continual learning with attentive recurrent neural networks for temporal data classification},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fractional gradient descent algorithm robust to the
initial weights of multilayer perceptron. <em>NN</em>, <em>158</em>,
154–170. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multilayer perceptron (MLP), the initial weights will significantly influence its performance. Based on the enhanced fractional derivative extend from convex optimization , this paper proposes a fractional gradient descent (RFGD) algorithm robust to the initial weights of MLP. We analyze the effectiveness of the RFGD algorithm. The convergence of the RFGD algorithm is also analyzed. The computational complexity of the RFGD algorithm is generally larger than that of the gradient descent (GD) algorithm but smaller than that of the Adam, Padam, AdaBelief, and AdaDiff algorithms. Numerical experiments show that the RFGD algorithm has strong robustness to the order of fractional calculus which is the only added parameter compared to the GD algorithm. More importantly, compared to the GD, Adam, Padam, AdaBelief, and AdaDiff algorithms, the experimental results show that the RFGD algorithm has the best robust performance for the initial weights of MLP. Meanwhile, the correctness of the theoretical analysis is verified.},
  archive      = {J_NN},
  author       = {Xuetao Xie and Yi-Fei Pu and Jian Wang},
  doi          = {10.1016/j.neunet.2022.11.018},
  journal      = {Neural Networks},
  pages        = {154-170},
  shortjournal = {Neural Netw.},
  title        = {A fractional gradient descent algorithm robust to the initial weights of multilayer perceptron},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UniSKGRep: A unified representation learning framework of
social network and knowledge graph. <em>NN</em>, <em>158</em>, 142–153.
(<a href="https://doi.org/10.1016/j.neunet.2022.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human-oriented applications aim to exploit behaviors of people, which impose challenges on user modeling of integrating social network (SN) with knowledge graph (KG), and jointly analyzing two types of graph data. However, existing graph representation learning methods merely represent one of two graphs alone, and hence are unable to comprehensively consider features of both SN and KG with profiling the correlation between them, resulting in unsatisfied performance in downstream tasks. Considering the diverse gap of features and the difficulty of associating of the two graph data, we introduce a Uni fied S ocial K nowledge G raph Rep resentation learning framework (UniSKGRep), with the goal to leverage the multi-view information inherent in the SN and KG for improving the downstream tasks of user modeling. To the best of our knowledge, we are the first to present a unified representation learning framework for SN and KG. Concretely, the SN and KG are organized as the Social Knowledge Graph (SKG), a unified representation of SN and KG. For the representation learning of SKG, first, two separate encoders in the Intra-graph model capture both the social-view and knowledge-view in two embedding spaces, respectively. Then the Inter-graph model is learned to associate the two separate spaces via bridging the semantics of overlapping node pairs. In addition, the overlapping node enhancement module is designed to effectively align two spaces with the consideration of a relatively small number of overlapping nodes. The two spaces are gradually unified by continuously iterating the joint training procedure. Extensive experiments on two real-world SKG datasets have proved the effectiveness of UniSKGRep in yielding general and substantial performance improvement compared with the strong baselines in various downstream tasks.},
  archive      = {J_NN},
  author       = {Yinghan Shen and Xuhui Jiang and Zijian Li and Yuanzhuo Wang and Chengjin Xu and Huawei Shen and Xueqi Cheng},
  doi          = {10.1016/j.neunet.2022.11.010},
  journal      = {Neural Networks},
  pages        = {142-153},
  shortjournal = {Neural Netw.},
  title        = {UniSKGRep: A unified representation learning framework of social network and knowledge graph},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning for robust stabilization of nonlinear
systems with asymmetric saturating actuators. <em>NN</em>, <em>158</em>,
132–141. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the robust stabilization problem of a class of nonlinear systems with asymmetric saturating actuators and mismatched disturbances. Initially, we convert such a robust stabilization problem into a nonlinear-constrained optimal control problem by constructing a discounted cost function for the auxiliary system. Then, for the purpose of solving the nonlinear-constrained optimal control problem , we develop a simultaneous policy iteration (PI) in the reinforcement learning framework. The implementation of the simultaneous PI relies on an actor–critic architecture, which employs actor and critic neural networks (NNs) to separately approximate the control policy and the value function. To determine the actor and critic NNs’ weights, we use the approach of weighted residuals together with the typical Monte-Carlo integration technique. Finally, we perform simulations of two nonlinear plants to validate the established theoretical claims.},
  archive      = {J_NN},
  author       = {Xiong Yang and Yingjiang Zhou and Zhongke Gao},
  doi          = {10.1016/j.neunet.2022.11.012},
  journal      = {Neural Networks},
  pages        = {132-141},
  shortjournal = {Neural Netw.},
  title        = {Reinforcement learning for robust stabilization of nonlinear systems with asymmetric saturating actuators},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DANet: Semi-supervised differentiated auxiliaries guided
network for video action recognition. <em>NN</em>, <em>158</em>,
121–131. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video Action Recognition (ViAR) aims to identify the category of the human action observed in a given video. With the advent of Deep Learning (DL) techniques, noticeable performance breakthroughs have been achieved in this study. However, the success of most existing DL-based ViAR methods heavily relies on the existence of a large amount of annotated data, i.e. , videos with corresponding action categories. In practice, obtaining such a desired number of annotations is often difficult due to expensive labeling costs, which may lead to significant performance degradation for these methods. To address this issue, we propose an end-to-end semi-supervised Differentiated Auxiliary guided Network (DANet) to best use a few annotated videos. Except for the common supervised learning on a few annotated videos, the DANet also involves the knowledge of multiple pre-trained auxiliary networks to optimize the ViAR network in a self-supervised way on the unannotated data by removing the annotations. Considering the tight connection between video action recognition and classical static image-based visual tasks, the abundant knowledge from the pre-trained static image-based models can be used for training the ViAR model. Specifically, the DANet is a two-branch architecture, which includes a target branch of the ViAR network, and an auxiliary branch of multiple auxiliary networks ( i.e. , referring to diverse off-the-shelf models of relevant image tasks). Given a limited number of annotated videos, we train the target ViAR network end-to-end in a semi-supervised way, namely, with both the supervised cross-entropy loss on annotated videos, and the per-auxiliary weighted self-supervised contrastive losses on the same videos but without using annotations. Besides, we further explore different weighted guidance of the auxiliary networks to the ViAR network to better reflect different relationships between the image-based models and the ViAR model. Finally, we conduct extensive experiments on several popular action recognition benchmarks in comparison with existing state-of-the-art methods, and the experimental results demonstrate the superiority of DANet over most of the compared methods. In particular, the DANet obviously suppresses state-of-the-art ViAR methods even with very fewer annotated videos .},
  archive      = {J_NN},
  author       = {Guangyu Gao and Ziming Liu and Guangjun Zhang and Jinyang Li and A.K. Qin},
  doi          = {10.1016/j.neunet.2022.11.009},
  journal      = {Neural Networks},
  pages        = {121-131},
  shortjournal = {Neural Netw.},
  title        = {DANet: Semi-supervised differentiated auxiliaries guided network for video action recognition},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An architecture entropy regularizer for differentiable
neural architecture search. <em>NN</em>, <em>158</em>, 111–120. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiable architecture search (DARTS) is one of the prevailing paradigms of neural architecture search (NAS) due to allowing efficient gradient-based optimization during the search phase. However, its poor stability and generalizability are intolerable. We argue that the crux is the locally optimal architecture parameter caused by a dilemma, which is that the solutions to the Matthew effect and discretization discrepancy are inconsistent. To escape from the dilemma, we propose an architecture entropy to measure the discrepancy of the architecture parameters of different candidate operations and use it as a regularizer to control the learning of architecture parameters. Extensive experiments show that an architecture entropy regularizer with a negative or positive coefficient can effectively solve one side of the contradiction respectively, and the regularizer with a variable coefficient can relieve DARTS from the dilemma. Experimental results demonstrate that our architecture entropy regularizer can significantly improve different differentiable NAS algorithms on different datasets and different search spaces. Furthermore, we also achieve more accurate and more robust results on CIFAR-10 and ImageNet. The code is publicly available at https://github.com/kunjing96/DARTS-AER.},
  archive      = {J_NN},
  author       = {Kun Jing and Luoyu Chen and Jungang Xu},
  doi          = {10.1016/j.neunet.2022.11.015},
  journal      = {Neural Networks},
  pages        = {111-120},
  shortjournal = {Neural Netw.},
  title        = {An architecture entropy regularizer for differentiable neural architecture search},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizing functional brain networks via spatio-temporal
attention 4D convolutional neural networks (STA-4DCNNs). <em>NN</em>,
<em>158</em>, 99–110. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterizing individualized spatio-temporal patterns of functional brain networks (FBNs) via functional magnetic resonance imaging (fMRI) provides a foundation for understanding complex brain function. Although previous studies have achieved promising performances based on either shallow or deep learning models, there is still much space to improve the accuracy of spatio-temporal pattern characterization of FBNs by optimally integrating the four-dimensional (4D) features of fMRI. In this study, we introduce a novel Spatio-Temporal Attention 4D Convolutional Neural Network (STA-4DCNN) model to characterize individualized spatio-temporal patterns of FBNs. Particularly, STA-4DCNN is composed of two subnetworks , in which the first Spatial Attention 4D CNN (SA-4DCNN) models the spatio-temporal features of 4D fMRI data and then characterizes the spatial pattern of FBNs, and the second Temporal Guided Attention Network (T-GANet) further characterizes the temporal pattern of FBNs under the guidance of the spatial pattern together with 4D fMRI data. We evaluate the proposed STA-4DCNN on seven different task fMRI and one resting state fMRI datasets from the publicly released Human Connectome Project. The experimental results demonstrate that STA-4DCNN has superior ability and generalizability in characterizing individualized spatio-temporal patterns of FBNs when compared to other state-of-the-art models. We further apply STA-4DCNN on another independent ABIDE I resting state fMRI dataset including both autism spectrum disorder (ASD) and typical developing (TD) subjects, and successfully identify abnormal spatio-temporal patterns of FBNs in ASD compared to TD. In general, STA-4DCNN provides a powerful tool for FBN characterization and for clinical applications on brain disease characterization at the individual level.},
  archive      = {J_NN},
  author       = {Xi Jiang and Jiadong Yan and Yu Zhao and Mingxin Jiang and Yuzhong Chen and Jingchao Zhou and Zhenxiang Xiao and Zifan Wang and Rong Zhang and Benjamin Becker and Dajiang Zhu and Keith M. Kendrick and Tianming Liu},
  doi          = {10.1016/j.neunet.2022.11.004},
  journal      = {Neural Networks},
  pages        = {99-110},
  shortjournal = {Neural Netw.},
  title        = {Characterizing functional brain networks via spatio-temporal attention 4D convolutional neural networks (STA-4DCNNs)},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LAC-GAN: Lesion attention conditional GAN for
ultra-widefield image synthesis. <em>NN</em>, <em>158</em>, 89–98. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of retinal diseases based on deep learning technology and Ultra-widefield (UWF) images plays an important role in clinical practices in recent years. However, due to small lesions and limited data samples, it is not easy to train a detection-accurate model with strong generalization ability . In this paper, we propose a lesion attention conditional generative adversarial network (LAC-GAN) to synthesize retinal images with realistic lesion details to improve the training of the disease detection model. Specifically, the generator takes the vessel mask and class label as the conditional inputs, and processes the random Gaussian noise by a series of residual block to generate the synthetic images . To focus on pathological information, we propose a lesion feature attention mechanism based on random forest (RF) method, which constructs its reverse activation network to activate the lesion features. For discriminator , a weight-sharing multi-discriminator is designed to improve the performance of model by affine transformations. Experimental results on multi-center UWF image datasets demonstrate that the proposed method can generate retinal images with reasonable details, which helps to enhance the performance of the disease detection model.},
  archive      = {J_NN},
  author       = {Haijun Lei and Zhihui Tian and Hai Xie and Benjian Zhao and Xianlu Zeng and Jiuwen Cao and Weixin Liu and Jiantao Wang and Guoming Zhang and Shuqiang Wang and Baiying Lei},
  doi          = {10.1016/j.neunet.2022.11.005},
  journal      = {Neural Networks},
  pages        = {89-98},
  shortjournal = {Neural Netw.},
  title        = {LAC-GAN: Lesion attention conditional GAN for ultra-widefield image synthesis},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A class of doubly stochastic shift operators for random
graph signals and their boundedness. <em>NN</em>, <em>158</em>, 83–88.
(<a href="https://doi.org/10.1016/j.neunet.2022.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of doubly stochastic graph shift operators (GSO) is proposed, which is shown to exhibit: (i) lower and upper L 2 L2 -boundedness for locally stationary random graph signals, (ii) L 2 L2 -isometry for i.i.d. random graph signals with the asymptotic increase in the incoming neighbourhood size of vertices, and (iii) preservation of the mean of any graph signal – all prerequisites for reliable graph neural networks . These properties are obtained through a statistical consistency analysis of the proposed graph shift operator, and by exploiting the dual role of the doubly stochastic GSO as a Markov (diffusion) matrix and as an unbiased expectation operator. For generality, we consider directed graphs which exhibit asymmetric connectivity matrices . The proposed approach is validated through an example on the estimation of a vector field.},
  archive      = {J_NN},
  author       = {Bruno Scalzo and Ljubiša Stanković and Miloš Daković and Anthony G. Constantinides and Danilo P. Mandic},
  doi          = {10.1016/j.neunet.2022.10.035},
  journal      = {Neural Networks},
  pages        = {83-88},
  shortjournal = {Neural Netw.},
  title        = {A class of doubly stochastic shift operators for random graph signals and their boundedness},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EvoPruneDeepTL: An evolutionary pruning model for transfer
learning based deep neural networks. <em>NN</em>, <em>158</em>, 59–82.
(<a href="https://doi.org/10.1016/j.neunet.2022.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Deep Learning models have shown a great performance in complex optimization problems . They generally require large training datasets, which is a limitation in most practical cases. Transfer learning allows importing the first layers of a pre-trained architecture and connecting them to fully-connected layers to adapt them to a new problem. Consequently, the configuration of the these layers becomes crucial for the performance of the model. Unfortunately, the optimization of these models is usually a computationally demanding task. One strategy to optimize Deep Learning models is the pruning scheme. Pruning methods are focused on reducing the complexity of the network, assuming an expected performance penalty of the model once pruned. However, the pruning could potentially be used to improve the performance, using an optimization algorithm to identify and eventually remove unnecessary connections among neurons. This work proposes EvoPruneDeepTL, an evolutionary pruning model for Transfer Learning based Deep Neural Networks which replaces the last fully-connected layers with sparse layers optimized by a genetic algorithm . Depending on its solution encoding strategy, our proposed model can either perform optimized pruning or feature selection over the densely connected part of the neural network. We carry out different experiments with several datasets to assess the benefits of our proposal. Results show the contribution of EvoPruneDeepTL and feature selection to the overall computational efficiency of the network as a result of the optimization process. In particular, the accuracy is improved, reducing at the same time the number of active neurons in the final layers.},
  archive      = {J_NN},
  author       = {Javier Poyatos and Daniel Molina and Aritz D. Martinez and Javier Del Ser and Francisco Herrera},
  doi          = {10.1016/j.neunet.2022.10.011},
  journal      = {Neural Networks},
  pages        = {59-82},
  shortjournal = {Neural Netw.},
  title        = {EvoPruneDeepTL: An evolutionary pruning model for transfer learning based deep neural networks},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian disturbance injection: Robust imitation learning of
flexible policies for robot manipulation. <em>NN</em>, <em>158</em>,
42–58. (<a href="https://doi.org/10.1016/j.neunet.2022.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans demonstrate a variety of interesting behavioral characteristics when performing tasks, such as selecting between seemingly equivalent optimal actions, performing recovery actions when deviating from the optimal trajectory, or moderating actions in response to sensed risks. However, imitation learning, which attempts to teach robots to perform these same tasks from observations of human demonstrations, often fails to capture such behavior . Specifically, commonly used learning algorithms embody inherent contradictions between the learning assumptions ( e.g., single optimal action) and actual human behavior ( e.g., multiple optimal actions), thereby limiting robot generalizability , applicability, and demonstration feasibility. To address this, this paper proposes designing imitation learning algorithms with a focus on utilizing human behavioral characteristics, thereby embodying principles for capturing and exploiting actual demonstrator behavioral characteristics. This paper presents the first imitation learning framework, Bayesian Disturbance Injection (BDI), that typifies human behavioral characteristics by incorporating model flexibility, robustification, and risk sensitivity. Bayesian inference is used to learn flexible non-parametric multi-action policies, while simultaneously robustifying policies by injecting risk-sensitive disturbances to induce human recovery action and ensuring demonstration feasibility. Our method is evaluated through risk-sensitive simulations and real-robot experiments ( e.g., table-sweep task, shaft-reach task and shaft-insertion task) using the UR5e 6-DOF robotic arm , to demonstrate the improved characterization of behavior . Results show significant improvement in task performance, through improved flexibility, robustness as well as demonstration feasibility.},
  archive      = {J_NN},
  author       = {Hanbit Oh and Hikaru Sasaki and Brendan Michael and Takamitsu Matsubara},
  doi          = {10.1016/j.neunet.2022.11.008},
  journal      = {Neural Networks},
  pages        = {42-58},
  shortjournal = {Neural Netw.},
  title        = {Bayesian disturbance injection: Robust imitation learning of flexible policies for robot manipulation},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LSTMED: An uneven dynamic process monitoring method based on
LSTM and autoencoder neural network. <em>NN</em>, <em>158</em>, 30–41.
(<a href="https://doi.org/10.1016/j.neunet.2022.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complicated production mechanism in multivariate industrial processes, different dynamic features of variables raise challenges to traditional data-driven process monitoring methods which assume the process data is static or dynamically consistent. To tackle this issue, this paper proposes a novel process monitoring method based on the long short-term memory (LSTM) and Autoencoder neural network (called LSTMED) for multivariate process monitoring with uneven dynamic features. First, the LSTM units are arranged in the encoder–decoder form to construct an end-to-end model. Then, the constructed model is trained in an unsupervised manner to capture long-term time dependency within variables and dominant representation of high dimensional process data. Afterward, the kernel density estimation (KDE) method is performed to determine the control limit only based on the reconstruction error from historical normal data. Finally, effective online monitoring for uneven dynamic process can be achieved. The performance and advantage of the process monitoring method proposed are explained through typical cases, including the numerical simulation and Tennessee Eastman (TE) benchmark process, and comparative experimental analysis with state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Wenfeng Deng and Yuxuan Li and Keke Huang and Dehao Wu and Chunhua Yang and Weihua Gui},
  doi          = {10.1016/j.neunet.2022.11.001},
  journal      = {Neural Networks},
  pages        = {30-41},
  shortjournal = {Neural Netw.},
  title        = {LSTMED: An uneven dynamic process monitoring method based on LSTM and autoencoder neural network},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Representation based regression for object distance
estimation. <em>NN</em>, <em>158</em>, 15–29. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a novel approach to predict the distances of the detected objects in an observed scene. The proposed approach modifies the recently proposed Convolutional Support Estimator Networks (CSENs). CSENs are designed to compute a direct mapping for the Support Estimation (SE) task in a representation-based classification problem. We further propose and demonstrate that representation-based methods (sparse or collaborative representation) can be used in well-designed regression problems especially over scarce data. To the best of our knowledge, this is the first representation-based method proposed for performing a regression task by utilizing the modified CSENs; and hence, we name this novel approach as Representation-based Regression (RbR) . The initial version of CSENs has a proxy mapping stage (i.e., a coarse estimation for the support set) that is required for the input. In this study, we improve the CSEN model by proposing Compressive Learning CSEN (CL-CSEN) that has the ability to jointly optimize the so-called proxy mapping stage along with convolutional layers . The experimental evaluations using the KITTI 3D Object Detection distance estimation dataset show that the proposed method can achieve a significantly improved distance estimation performance over all competing methods. Finally, the software implementations of the methods are publicly shared at https://github.com/meteahishali/CSENDistance .},
  archive      = {J_NN},
  author       = {Mete Ahishali and Mehmet Yamac and Serkan Kiranyaz and Moncef Gabbouj},
  doi          = {10.1016/j.neunet.2022.11.011},
  journal      = {Neural Networks},
  pages        = {15-29},
  shortjournal = {Neural Netw.},
  title        = {Representation based regression for object distance estimation},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving small-batch accuracy with large-batch scalability
via hessian-aware learning rate adjustment. <em>NN</em>, <em>158</em>,
1–14. (<a href="https://doi.org/10.1016/j.neunet.2022.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider synchronous data-parallel neural network training with a fixed large batch size. While the large batch size provides a high degree of parallelism , it degrades the generalization performance due to the low gradient noise scale. We propose a general learning rate adjustment framework and three critical heuristics that tackle the poor generalization issue. The key idea is to adjust the learning rate based on geometric information of loss landscape and encourage the model to converge into a flat minimum that is known to better generalize to the unknown data. Our empirical study demonstrates that the Hessian-aware learning rate schedule remarkably improves the generalization performance in large-batch training. For CIFAR-10 classification with ResNet20, our method achieves 92.31\% accuracy using 16,384 batch size, which is close to 92.83\% achieved using 128 batch size, at a negligible extra computational cost.},
  archive      = {J_NN},
  author       = {Sunwoo Lee and Chaoyang He and Salman Avestimehr},
  doi          = {10.1016/j.neunet.2022.11.007},
  journal      = {Neural Networks},
  pages        = {1-14},
  shortjournal = {Neural Netw.},
  title        = {Achieving small-batch accuracy with large-batch scalability via hessian-aware learning rate adjustment},
  volume       = {158},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Announcement of the neural networks best paper award.
<em>NN</em>, <em>157</em>, xli. (<a
href="https://doi.org/10.1016/S0893-6080(22)00490-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Taro Toyoizumi ( Co-Editors-in-Chief, Neural Networks ) and DeLiang Wang},
  doi          = {10.1016/S0893-6080(22)00490-7},
  journal      = {Neural Networks},
  pages        = {xli},
  shortjournal = {Neural Netw.},
  title        = {Announcement of the neural networks best paper award},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural networks referees in 2022. <em>NN</em>, <em>157</em>,
xii–xl. (<a
href="https://doi.org/10.1016/S0893-6080(22)00489-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(22)00489-0},
  journal      = {Neural Networks},
  pages        = {xii-xl},
  shortjournal = {Neural Netw.},
  title        = {Neural networks referees in 2022},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023h). INN/ENNS/JNNS - membership applic. form. <em>NN</em>,
<em>157</em>, II. (<a
href="https://doi.org/10.1016/S0893-6080(22)00486-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(22)00486-5},
  journal      = {Neural Networks},
  pages        = {II},
  shortjournal = {Neural Netw.},
  title        = {INN/ENNS/JNNS - membership applic. form},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). Current events. <em>NN</em>, <em>157</em>, I. (<a
href="https://doi.org/10.1016/S0893-6080(22)00485-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  doi          = {10.1016/S0893-6080(22)00485-3},
  journal      = {Neural Networks},
  pages        = {I},
  shortjournal = {Neural Netw.},
  title        = {Current events},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Another bumper year. <em>NN</em>, <em>157</em>, 471–472. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Taro Toyoizumi ( Co-Editors-in-Chief ) and DeLiang Wang},
  doi          = {10.1016/j.neunet.2022.11.020},
  journal      = {Neural Networks},
  pages        = {471-472},
  shortjournal = {Neural Netw.},
  title        = {Another bumper year},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BASeg: Boundary aware semantic segmentation for autonomous
driving. <em>NN</em>, <em>157</em>, 460–470. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a critical component for street understanding task in autonomous driving field. Existing various methods either focus on constructing the object’s inner consistency by aggregating global or multi-scale context information, or simply combine semantic features with boundary features to refine object details. Despite impressive, most of them neglect the long-range dependences between the inner objects and boundaries. To this end, we present a Boundary Aware Network (BASeg) for semantic segmentation by exploiting boundary information as a significant cue to guide context aggregation. Specifically, a Boundary Refined Module (BRM) is proposed in the BASeg to refine coarse low-level boundary features from a Canny detector by high-level multi-scale semantic features from the backbone, and based on which, the Context Aggregation Module (CAM) is further proposed to capture long-range dependences between the boundary regions and the object inner pixels, achieving mutual gains and enhancing the intra-class consistency. Moreover, our method can be plugged into other CNN backbones for higher performance with a minor computation budget, and obtains 45.72\%, 81.2\%, and 77.3\% of mIoU on the datasets ADE20K, Cityscapes, and CamVid, respectively. Compared with some state-of-the-art ResNet101-based segmentation methods , extensive experiments demonstrate the effectiveness of our method. Our code is available at https://github.com/Lature-Yang/BASeg .},
  archive      = {J_NN},
  author       = {Xiaoyang Xiao and Yuqian Zhao and Fan Zhang and Biao Luo and Lingli Yu and Baifan Chen and Chunhua Yang},
  doi          = {10.1016/j.neunet.2022.10.034},
  journal      = {Neural Networks},
  pages        = {460-470},
  shortjournal = {Neural Netw.},
  title        = {BASeg: Boundary aware semantic segmentation for autonomous driving},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting graph neural networks from hybrid regularized
graph signal reconstruction. <em>NN</em>, <em>157</em>, 444–459. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown strong graph-structured data processing capabilities. However, most of them are generated based on the message-passing mechanism and lack of the systematic approach to guide their developments. Meanwhile, a unified point of view is hard to explain the design concepts of different GNN models. This paper presents a unified optimization framework from hybrid regularized graph signal reconstruction to establish the connection between the aggregation operations of different GNNs, showing that exploring the optimal solution is the process of GNN information aggregation. We use this new framework to mathematically explain several classic GNN models and summarizes their commonalities and differences from a macro perspective. The proposed framework not only provides convenience to understand GNNs, but also has a guiding significance for the proposal of new GNNs. Moreover, we design a model-driven fixed-point iteration method and a data-driven dictionary learning network according to the corresponding optimization objective and sparse representation . Then the new model, GNN based on model-driven and data-driven (GNN-MD), is established by using alternating iteration methods . We also theoretically analyze its convergence. Numerous node classification experiments on multiple datasets illustrate that the proposed GNN-MD has excellent performance and outperforms all baselines on high-feature-dimension datasets.},
  archive      = {J_NN},
  author       = {Jiaxing Miao and Feilong Cao and Hailiang Ye and Ming Li and Bing Yang},
  doi          = {10.1016/j.neunet.2022.11.003},
  journal      = {Neural Networks},
  pages        = {444-459},
  shortjournal = {Neural Netw.},
  title        = {Revisiting graph neural networks from hybrid regularized graph signal reconstruction},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-enabled gated spiking neural p model for
aspect-level sentiment classification. <em>NN</em>, <em>157</em>,
437–443. (<a
href="https://doi.org/10.1016/j.neunet.2022.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gated spiking neural P (GSNP) model is a recently developed recurrent-like network, which is abstracted by nonlinear spiking mechanism of nonlinear spiking neural P systems . In this study, a modification of GSNP is combined with attention mechanism to develop a novel model for sentiment classification, called attention-enabled GSNP model or termed as AGSNP model. The AGSNP model has two channels that process content words and aspect item respectively, where two modified GSNPs are used to obtain dependencies between content words and between aspect words. Moreover, two attention components are used to establish semantic correlation between content words and aspect item. Comparative experiments on three real data sets and several baseline models are conducted to verify the effectiveness of the AGSNP model. The comparison results demonstrate that the AGSNP model is competent for aspect-level sentiment classification tasks .},
  archive      = {J_NN},
  author       = {Yanping Huang and Hong Peng and Qian Liu and Qian Yang and Jun Wang and David Orellana-Martín and Mario J. Pérez-Jiménez},
  doi          = {10.1016/j.neunet.2022.11.006},
  journal      = {Neural Networks},
  pages        = {437-443},
  shortjournal = {Neural Netw.},
  title        = {Attention-enabled gated spiking neural p model for aspect-level sentiment classification},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Free energy model of emotional valence in dual-process
perceptions. <em>NN</em>, <em>157</em>, 422–436. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An appropriate level of arousal induces positive emotions, and a high arousal potential may provoke negative emotions. To explain the effect of arousal on emotional valence, we propose a novel mathematical framework of arousal potential variations in the dual process of human cognition : automatic and controlled. A suitable mathematical formulation to explain the emotions in the dual process is still absent. Our model associates free energy with arousal potential and its variations to explain emotional valence. Decreasing and increasing free energy consequently induce positive and negative emotions, respectively. We formalize a transition from the automatic to the controlled process in the dual process as a change of Bayesian prior. Further, we model emotional valence using free energy increase (FI) when one tries changing one’s Bayesian prior and its reduction (FR) when one succeeds in recognizing the same stimuli with a changed prior and define three emotions: “interest,” “confusion,” and “boredom” using the variations. The results of our mathematical analysis comparing various Gaussian model parameters reveals the following: (1) prediction error (PR) increases FR (representing “interest”) when the first prior variance is greater than the second prior variance, (2) PR decreases FR when the first prior variance is less than the second prior variance, and (3) the distance between priors’ means always increases FR. We also discuss the association of the outcomes with emotions in the controlled process. The proposed mathematical model provides a general framework for predicting and controlling emotional valence in the dual process that varies with viewpoint and stimuli, as well as for understanding the contradictions in the effects of arousal on the valence.},
  archive      = {J_NN},
  author       = {Hideyoshi Yanagisawa and Xiaoxiang Wu and Kazutaka Ueda and Takeo Kato},
  doi          = {10.1016/j.neunet.2022.10.027},
  journal      = {Neural Networks},
  pages        = {422-436},
  shortjournal = {Neural Netw.},
  title        = {Free energy model of emotional valence in dual-process perceptions},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurodynamics-driven portfolio optimization with targeted
performance criteria. <em>NN</em>, <em>157</em>, 404–421. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses portfolio selection with targeted performance criteria via neurodynamic optimization. Five portfolio optimization problems are formulated with a variable weight to maximize five risk-adjusted performance criteria in Markowitz’s mean–variance framework and reformulated as iteratively weighted convex optimization problems to facilitate subsequent problem-solving solution procedures. In addition, distributed portfolio optimization problems with separable performance criteria are also formulated. Three neurodynamic approaches are developed based on two globally convergent recurrent neural networks to solve the formulated and reformulated problems. Extensive experimental results on 13 datasets of world stock markets are elaborated to demonstrate the superior performance of the neurodynamic approaches against the baselines in terms of five given evaluation criteria and two investment returns.},
  archive      = {J_NN},
  author       = {Jun Wang and Xin Gan},
  doi          = {10.1016/j.neunet.2022.10.018},
  journal      = {Neural Networks},
  pages        = {404-421},
  shortjournal = {Neural Netw.},
  title        = {Neurodynamics-driven portfolio optimization with targeted performance criteria},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temperature guided network for 3D joint segmentation of the
pancreas and tumors. <em>NN</em>, <em>157</em>, 387–403. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and automatic segmentation of pancreatic tumors and organs from medical images is important for clinical diagnoses and making treatment plans for patients with pancreatic cancer. Although deep learning methods have been widely adopted for this task, the segmentation accuracy , especially for pancreatic tumors, still needs to be further improved because (1) phenotypic differences, such as volumes, tend to make the models focus on pancreatic learning, resulting in insufficient tumor feature selection; (2) deep learning models may fall into local optima, leading to unsatisfactory segmentation results for tumors and pancreas. To alleviate the above issues, in this paper, we propose a 3D fully convolutional neural network with three temperature guided modules, namely, balance temperature loss, rigid temperature optimizer and soft temperature indictor, to realize joint segmentation of the pancreas and tumors. Specifically, balance temperature loss is designed to dynamically adjust the learning points between tumors and the pancreas to balance the selected features, and it is aimed at improving the accuracy of tumor segmentation without losing pancreas information. Rigid temperature optimizer is proposed to accept nonimproving moves probabilistically to adaptively avoid local optima. To further refine the segmentation results, we propose the soft temperature indictor to guide the network into a fine-tuning state automatically when the model tends to stability. Our experimental results are more accurate than the fourteen top-ranking methods in pancreas and tumors segmentation on the MSD pancreas dataset and six top-ranking methods in brain tumors segmentation. Ablation studies verify the effectiveness of the three temperature guided modules.},
  archive      = {J_NN},
  author       = {Qi Li and Xiyu Liu and Yiming He and Dengwang Li and Jie Xue},
  doi          = {10.1016/j.neunet.2022.10.026},
  journal      = {Neural Networks},
  pages        = {387-403},
  shortjournal = {Neural Netw.},
  title        = {Temperature guided network for 3D joint segmentation of the pancreas and tumors},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurodynamics-driven holistic approaches to semi-supervised
feature selection. <em>NN</em>, <em>157</em>, 377–386. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a crucial part of machine learning and pattern recognition, which aims at selecting a subset of informative features from the original dataset. Because of label information, supervised feature selection performs better than unsupervised feature selection without label information. However, in the presence of a small number of labeled data and a large number of unlabeled data , it is challenging for supervised feature selection methods to select relevant features. In this paper, we propose three neurodynamics-driven holistic approaches to semi-supervised feature selection via semi-supervised feature redundancy minimization and semi-supervised feature relevancy maximization. We first define information-theoretic semi-supervised similarity coefficient matrix and semi-supervised feature relevancy vector based on multi-information, unsupervised symmetric uncertainty, and entropy to measure feature redundancy and relevancy. We then formulate a fractional programming problem and an iteratively weighted quadratic programming problem based on the semi-supervised similarity coefficient matrix and semi-supervised feature relevancy vector for semi-supervised feature selection. To solve the formulated problems, we delineate three neurodynamic optimization approaches based on two projection neural networks . We elaborate on the experimental results on six benchmark datasets to demonstrate the superior classification performance of the proposed neurodynamic approaches against six existing supervised and semi-supervised feature selection methods.},
  archive      = {J_NN},
  author       = {Yadi Wang and Jun Wang},
  doi          = {10.1016/j.neunet.2022.10.029},
  journal      = {Neural Networks},
  pages        = {377-386},
  shortjournal = {Neural Netw.},
  title        = {Neurodynamics-driven holistic approaches to semi-supervised feature selection},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discriminative and geometry-preserving adaptive graph
embedding for dimensionality reduction. <em>NN</em>, <em>157</em>,
364–376. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning graph embeddings for high-dimensional data is an important technology for dimensionality reduction. The learning process is expected to preserve the discriminative and geometric information of high-dimensional data in a new low-dimensional subspace via either manual or automatic graph construction . Although both manual and automatic graph constructions can capture the geometry and discrimination of data to a certain degree, they working alone cannot fully explore the underlying data structure . To learn and preserve more discriminative and geometric information of the high-dimensional data in the low-dimensional subspace as much as possible, we develop a novel D iscriminative and G eometry- P reserving A daptive G raph E mbedding (DGPAGE). It systematically integrates manual and adaptive graph constructions in one unified graph embedding framework, which is able to effectively inject the essential information of data involved in predefined graphs into the learning of an adaptive graph, in order to achieve both adaptability and specificity of data. Learning the adaptive graph jointly with the optimized projections, DGPAGE can generate an embedded subspace that has better pattern discrimination for image classification . Results derived from extensive experiments on image data sets have shown that DGPAGE outperforms the state-of-the-art graph-based dimensionality reduction methods. The ablation studies show that it is beneficial to have an integrated framework, like DGPAGE, that brings together the advantages of manual/adaptive graph construction .},
  archive      = {J_NN},
  author       = {Jianping Gou and Xia Yuan and Ya Xue and Lan Du and Jiali Yu and Shuyin Xia and Yi Zhang},
  doi          = {10.1016/j.neunet.2022.10.024},
  journal      = {Neural Networks},
  pages        = {364-376},
  shortjournal = {Neural Netw.},
  title        = {Discriminative and geometry-preserving adaptive graph embedding for dimensionality reduction},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite-time consensus control for multi-agent systems with
full-state constraints and actuator failures. <em>NN</em>, <em>157</em>,
350–363. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at a class of uncertain nonlinear multi-agent systems (MASs) with full-state constraints and actuator failures , a finite-time consensus control method is developed. Full-state constraints and actuator failures are ubiquitous in practical engineering applications . Violation of constraints would drastically affect the performance of MASs, even arise security problems. It is challenging to guarantee the performance of the MASs when undergoing actuator failures. To tackle these problems, an adaptive consensus control method is established by applying the Backstepping technique and Barrier Lyapunov functions (BLFs) to ensure the performance of the MASs with full-state constraints no matter actuator failures occur. Simultaneously, for the uncertain nonlinear MASs, a finite-time neural network (NN) consensus control scheme is established to ensure system’s signals are synchronized in finite time. Moreover, an event-triggered control strategy is constructed to relieve the communication pressure of each agent. Finally, numerical and practical examples are employed to verify the effectiveness of the proposed control strategy.},
  archive      = {J_NN},
  author       = {Jianhui Wang and Yancheng Yan and Zhi Liu and C.L. Philip Chen and Chunliang Zhang and Kairui Chen},
  doi          = {10.1016/j.neunet.2022.10.028},
  journal      = {Neural Networks},
  pages        = {350-363},
  shortjournal = {Neural Netw.},
  title        = {Finite-time consensus control for multi-agent systems with full-state constraints and actuator failures},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered adaptive dynamic programming for
decentralized tracking control of input constrained unknown nonlinear
interconnected systems. <em>NN</em>, <em>157</em>, 336–349. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses decentralized tracking control (DTC) problems for input constrained unknown nonlinear interconnected systems via event-triggered adaptive dynamic programming. To reconstruct the system dynamics , a neural-network-based local observer is established by using local input–output data and the desired trajectories of all other subsystems. By employing a nonquadratic value function, the DTC problem of the input constrained nonlinear interconnected system is transformed into an optimal control problem . By using the observer-critic architecture, the DTC policy is obtained by solving the local Hamilton–Jacobi–Bellman equation through the local critic neural network , whose weights are tuned by the experience replay technique to relax the persistence of excitation condition . Under the event-triggering mechanism, the DTC policy is updated at the event-triggering instants only. Then, the computational resource and the communication bandwidth are saved. The stability of the closed-loop system is guaranteed by implementing event-triggered DTC policy via Lyapunov’s direct method. Finally, simulation examples are provided to demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_NN},
  author       = {Qiuye Wu and Bo Zhao and Derong Liu and Marios M. Polycarpou},
  doi          = {10.1016/j.neunet.2022.10.025},
  journal      = {Neural Networks},
  pages        = {336-349},
  shortjournal = {Neural Netw.},
  title        = {Event-triggered adaptive dynamic programming for decentralized tracking control of input constrained unknown nonlinear interconnected systems},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stacked attention hourglass network based robust facial
landmark detection. <em>NN</em>, <em>157</em>, 323–335. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning based facial landmark detection (FLD) has made rapid progress. However, the accuracy and robustness of FLD algorithms are degraded heavily when the face is subject to diverse expressions, posture deflection, partial occlusion and other uncertain circumstances. To learn more discriminative representations and reduce the negative effect caused by outliers, a stacked attention hourglass network (SAHN) is proposed for FLD, where new attention mechanism is introduced. Basically, in the design of SAHN, a spatial attention residual (SAR) unit is constructed such that relevant areas of facial landmarks are specially emphasized and essential features of different scales can be well extracted, and a channel attention branch (CAB) is introduced to better guide the next-level hourglass network for feature extraction. Due to the introduction of SAR and CAB, only two hourglass networks are stacked as the proposed SAHN with fewer parameters, which is different from traditional SHNs stacked by four hourglass networks. Furthermore, a variable robustness (VR) loss function is introduced for the training of SAHN. The robustness of the proposed model for FLD is guaranteed with the help of the VR loss by adaptively adjusting a continuous parameter. Extensive experimental results on three public datasets including 300W, WFLW and COFW confirm that our method is superior to some previous ones.},
  archive      = {J_NN},
  author       = {Ying Huang and He Huang},
  doi          = {10.1016/j.neunet.2022.10.021},
  journal      = {Neural Networks},
  pages        = {323-335},
  shortjournal = {Neural Netw.},
  title        = {Stacked attention hourglass network based robust facial landmark detection},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved residual network based on norm-preservation for
visual recognition. <em>NN</em>, <em>157</em>, 305–322. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residual Network (ResNet) achieves deeper and wider networks with high-performance gains, representing a powerful convolutional neural network architecture. In this paper, we propose architectural refinements to ResNet that address the information flow through several layers of the network, including the input stem, downsampling block, projection shortcut, and identity blocks. We will show that our collective refinements facilitate stable backpropagation by preserving the norm of the error gradient within the residual blocks, which can reduce the optimization difficulties of training very deep networks. Our proposed modifications enhance the learning dynamics, resulting in high accuracy and inference performance by enforcing norm-preservation throughout the network training. The effectiveness of our method is verified by extensive experimental results on five computer vision tasks , including image classification (ImageNet and CIFAR-100), video classification (Kinetics-400), multi-label image recognition (MS-COCO), object detection and semantic segmentation (PASCAL VOC). We also empirically show consistent improvements in generalization performance when applying our modifications over different networks to provide new insights and inspire new architectures. The source code is publicly available at: https://github.com/bharatmahaur/LeNo .},
  archive      = {J_NN},
  author       = {Bharat Mahaur and K.K. Mishra and Navjot Singh},
  doi          = {10.1016/j.neunet.2022.10.023},
  journal      = {Neural Networks},
  pages        = {305-322},
  shortjournal = {Neural Netw.},
  title        = {Improved residual network based on norm-preservation for visual recognition},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning for automatic quadrilateral mesh
generation: A soft actor–critic approach. <em>NN</em>, <em>157</em>,
288–304. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes, implements, and evaluates a reinforcement learning (RL)-based computational framework for automatic mesh generation. Mesh generation plays a fundamental role in numerical simulations in the area of computer aided design and engineering (CAD/E). It is identified as one of the critical issues in the NASA CFD Vision 2030 Study. Existing mesh generation methods suffer from high computational complexity , low mesh quality in complex geometries , and speed limitations. These methods and tools, including commercial software packages , are typically semiautomatic and they need inputs or help from human experts. By formulating the mesh generation as a Markov decision process (MDP) problem, we are able to use a state-of-the-art reinforcement learning (RL) algorithm called “soft actor-critic” to automatically learn from trials the policy of actions for mesh generation. The implementation of this RL algorithm for mesh generation allows us to build a fully automatic mesh generation system without human intervention and any extra clean-up operations, which fills the gap in the existing mesh generation tools. In the experiments to compare with two representative commercial software packages , our system demonstrates promising performance with respect to scalability, generalizability , and effectiveness.},
  archive      = {J_NN},
  author       = {Jie Pan and Jingwei Huang and Gengdong Cheng and Yong Zeng},
  doi          = {10.1016/j.neunet.2022.10.022},
  journal      = {Neural Networks},
  pages        = {288-304},
  shortjournal = {Neural Netw.},
  title        = {Reinforcement learning for automatic quadrilateral mesh generation: A soft actor–critic approach},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the role of feedback in image recognition under noise and
adversarial attacks: A predictive coding perspective. <em>NN</em>,
<em>157</em>, 280–287. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-inspired machine learning is gaining increasing consideration, particularly in computer vision . Several studies investigated the inclusion of top-down feedback connections in convolutional networks ; however, it remains unclear how and when these connections are functionally helpful. Here we address this question in the context of object recognition under noisy conditions. We consider deep convolutional networks (CNNs) as models of feed-forward visual processing and implement Predictive Coding (PC) dynamics through feedback connections (predictive feedback) trained for reconstruction or classification of clean images. First, we show that the accuracy of the network implementing PC dynamics is significantly larger compared to its equivalent forward network. Importantly, to directly assess the computational role of predictive feedback in various experimental situations, we optimize and interpret the hyper-parameters controlling the network’s recurrent dynamics. That is, we let the optimization process determine whether top-down connections and predictive coding dynamics are functionally beneficial. Across different model depths and architectures (3-layer CNN, ResNet18, and EfficientNetB0) and against various types of noise (CIFAR100-C), we find that the network increasingly relies on top-down predictions as the noise level increases; in deeper networks, this effect is most prominent at lower layers. All in all, our results provide novel insights relevant to Neuroscience by confirming the computational role of feedback connections in sensory systems, and to Machine Learning by revealing how these can improve the robustness of current vision models.},
  archive      = {J_NN},
  author       = {Andrea Alamia and Milad Mozafari and Bhavin Choksi and Rufin VanRullen},
  doi          = {10.1016/j.neunet.2022.10.020},
  journal      = {Neural Networks},
  pages        = {280-287},
  shortjournal = {Neural Netw.},
  title        = {On the role of feedback in image recognition under noise and adversarial attacks: A predictive coding perspective},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving malicious email detection through novel designated
deep-learning architectures utilizing entire email. <em>NN</em>,
<em>157</em>, 257–279. (<a
href="https://doi.org/10.1016/j.neunet.2022.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s email dependent world, cyber criminals often target organizations using a variety of social engineering techniques and specially crafted malicious emails. When successful, such attacks can result in significant harm to physical and digital systems and assets, the leakage of sensitive information , reputation damage, and financial loss. Despite the plethora of studies on the detection of phishing attacks and malicious links in emails, there are no solutions capable of effectively, quickly, and accurately coping with more complex email-based attacks, such as malicious email attachments . This paper presents the first fully automated malicious email detection framework using deep ensemble learning to analyze all email segments (body, header, and attachments); this eliminates the need for human expert intervention for feature engineering. In this paper, we also demonstrate how an ensemble framework of deep learning classifiers each of which are trained on specific portions of an email (thereby independently utilizing the entire email) can generalize better than popular email analysis methods that analyze just a specific portion of the email for analysis. The proposed framework is evaluated comprehensively and with an AUC of 0.993, the proposed framework’s results surpass state-of-the-art malicious email detection methods, including human expert feature-based machine learning models by a TPR of 5\%.},
  archive      = {J_NN},
  author       = {Trivikram Muralidharan and Nir Nissim},
  doi          = {10.1016/j.neunet.2022.09.002},
  journal      = {Neural Networks},
  pages        = {257-279},
  shortjournal = {Neural Netw.},
  title        = {Improving malicious email detection through novel designated deep-learning architectures utilizing entire email},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DAFA-BiLSTM: Deep autoregression feature augmented
bidirectional LSTM network for time series prediction. <em>NN</em>,
<em>157</em>, 240–256. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting models that use the past information of exogenous or endogenous sequences to forecast future series play an important role in the real world because most real-world time series datasets are rich in time-dependent information. Most conventional prediction models for time series datasets are time-consuming and fraught with complex limitations because they usually fail to adequately exploit the latent spatial dependence between pairs of variables. As a successful variant of recurrent neural networks , the long short-term memory network (LSTM) has been demonstrated to have stronger nonlinear dynamics to store sequential data than traditional machine learning models. Nevertheless, the common shallow LSTM architecture has limited capacity to fully extract the transient characteristics of long interval sequential datasets. In this study, a novel deep autoregression feature augmented bidirectional LSTM network (DAFA-BiLSTM) is proposed as a new deep BiLSTM architecture for time series prediction . Initially, the input vectors are fed into a vector autoregression (VA) transformation module to represent the time-delayed linear and nonlinear properties of the input signals in an unsupervised way. Then, the learned nonlinear combination vectors of VA are progressively fed into different layers of BiLSTM and the output of the previous BiLSTM module is also concatenated with the time-delayed linear vectors of the VA as an augmented feature to form new additional input signals for the next adjacent BiLSTM layer. Extensive real-world time series applications are addressed to demonstrate the superiority and robustness of the proposed DAFA-BiLSTM. Comparative experimental results and statistical analysis show that the proposed DAFA-BiLSTM has good adaptive performance as well as robustness even in noisy environment .},
  archive      = {J_NN},
  author       = {Heshan Wang and Yiping Zhang and Jing Liang and Lili Liu},
  doi          = {10.1016/j.neunet.2022.10.009},
  journal      = {Neural Networks},
  pages        = {240-256},
  shortjournal = {Neural Netw.},
  title        = {DAFA-BiLSTM: Deep autoregression feature augmented bidirectional LSTM network for time series prediction},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gateway identity and spatial remapping in a combined grid
and place cell attractor. <em>NN</em>, <em>157</em>, 226–239. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatial specificities of hippocampal place cells, i.e., their firing fields, are subject to change if the rat enters a new compartment in the experimental maze. This effect is known as remapping. It cannot be explained from path integration (grid cell activity) and local sensory cues alone but requires additional knowledge of the different compartments in the form of context recognition at the gateways between them. Here we present a model for the hippocampal–entorhinal interplay in which the activity of place and grid cells follows a joint attractor dynamic. Place cells depend on the current grid cell activity but can also reset the grid cell activity in the remapping process. Remapping is triggered by the passage through a gateway. When this happens, a previously stored pattern of place cell activity associated with the gateway is reactivated from a “gateway database”. The joint attractor will then reinstate the grid cell pattern that was active when the gateway had first been learned and path integration can proceed from there. The model is tested with various mazes used in the experimental literature and reproduces the published results, and we make predictions for remapping in a new maze type. We propose the involvement of memory in the form of “gate cells” that drive the place cells and with them the joint hippocampal–entorhinal loop into the corresponding attractor whenever a compartment is entered.},
  archive      = {J_NN},
  author       = {Tristan Baumann and Hanspeter A. Mallot},
  doi          = {10.1016/j.neunet.2022.10.019},
  journal      = {Neural Networks},
  pages        = {226-239},
  shortjournal = {Neural Netw.},
  title        = {Gateway identity and spatial remapping in a combined grid and place cell attractor},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial style discrepancy minimization for unsupervised
domain adaptation. <em>NN</em>, <em>157</em>, 216–225. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mainstream unsupervised domain adaptation (UDA) methods align feature distributions across different domains via adversarial learning. However, most of them focus on global distribution alignment, ignoring the fine-grained domain discrepancy. Besides, they generally require auxiliary models, bringing extra computation costs. To tackle these issues, this study proposes an UDA method that differentiates individual samples without the help of extra models. To this end, we introduce a novel discrepancy metric, termed style discrepancy, to distinguish different target samples. We also propose a paradigm for adversarial style discrepancy minimization (ASDM). Specifically, we fix the parameters of the feature extractor and maximize style discrepancy to update the classifier, which helps detect more hard samples. Adversely, we fix the parameters of the classifier and minimize the style discrepancy to update the feature extractor, pushing those hard samples near the support of the source distribution. Such adversary helps to progressively detect and adapt more hard samples, leading to fine-grained domain adaptation. Experiments on different UDA tasks validate the effectiveness of ASDM. Overall, without any extra models, ASDM reaches a 46.9\% mIoU in the GTA5 to Cityscapes benchmark and an 84.7\% accuracy in the VisDA-2017 benchmark, outperforming many existing adversarial-learning-based methods.},
  archive      = {J_NN},
  author       = {Xin Luo and Wei Chen and Zhengfa Liang and Chen Li and Yusong Tan},
  doi          = {10.1016/j.neunet.2022.10.015},
  journal      = {Neural Networks},
  pages        = {216-225},
  shortjournal = {Neural Netw.},
  title        = {Adversarial style discrepancy minimization for unsupervised domain adaptation},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ExpGCN: Review-aware graph convolution network for
explainable recommendation. <em>NN</em>, <em>157</em>, 202–215. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing works in recommender system have widely explored extracting reviews as explanations beyond user–item interactions, and formulated the explanation generation as a ranking task to enhance item recommendation performance. To associate explanations with users and items, graph neural networks (GNN) are usually employed to learn node representations on the heterogeneous user–item–explanation interaction graph. However, modeling heterogeneous graph convolution poses limitations in both message passing styles and computational efficiency, resulting in sub-optimal recommendation performance. To address the limitations, we propose an Explanation-aware Graph Convolution Network (ExpGCN). In particular, the heterogeneous interaction graph is divided to subgraphs regard to the edge types in ExpGCN. By aggregating information from distinct subgraphs, ExpGCN is capable of generating node representations for explanation ranking task and item recommendation task respectively. Task-oriented graph convolution can not only reduce the complexity of heterogeneous node aggregation , but also alleviate the performance degeneration caused by the conflicts between task learning objectives, which has been neglected in current studies. Extensive experiments on four public datasets show that ExpGCN significantly outperforms state-of-the-art baselines with high efficiency, demonstrating the effectiveness of ExpGCN in explainable recommendations.},
  archive      = {J_NN},
  author       = {Tianjun Wei and Tommy W.S. Chow and Jianghong Ma and Mingbo Zhao},
  doi          = {10.1016/j.neunet.2022.10.014},
  journal      = {Neural Networks},
  pages        = {202-215},
  shortjournal = {Neural Netw.},
  title        = {ExpGCN: Review-aware graph convolution network for explainable recommendation},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). More refined superbag: Distantly supervised relation
extraction with deep clustering. <em>NN</em>, <em>157</em>, 193–201. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distant supervision (DS) can automatically generate annotated data for relation extraction (RE) with knowledge bases and corpora. The existing DS methods that train on bags selected by attention mechanism are susceptible to noisy bags and neglect useful information in noisy bags. In this paper, we propose DCSR, a novel DS method which utilizes deep clustering to obtain refined superbag representations for solving the wrong labeling problem. we substitute deep clustering for selective attention to construct superbags, capturing helpful information between spatially-close bags, including noisy bags. Moreover, we implement data augmentation on the input sentences to handle the long-tail problem. Experiments on the NYT2010 and NYT-H datasets show that our method can effectively improve RE and significantly outperforms state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Suizhu Yang and Yanxia Liu and Yuantong Jiang and Zhiqiang Liu},
  doi          = {10.1016/j.neunet.2022.10.008},
  journal      = {Neural Networks},
  pages        = {193-201},
  shortjournal = {Neural Netw.},
  title        = {More refined superbag: Distantly supervised relation extraction with deep clustering},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pairwise learning problems with regularization networks and
nyström subsampling approach. <em>NN</em>, <em>157</em>, 176–192. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pairwise learning usually refers to the learning problem that works with pairs of training samples, such as ranking, similarity and metric learning, and AUC maximization. To overcome the challenge of pairwise learning in the large scale computation, this paper introduces Nyström sampling approach to the coefficient-based regularized pairwise algorithm in the context of kernel networks. Our theorems establish that the obtained Nyström estimator achieves the minimax error over all estimators using the whole data provided that the subsampling level is not too small. We derive the function relation between the subsampling level and regularization parameter that guarantees computation cost reduction and asymptotic behaviors’ optimality simultaneously. The Nyström coefficient-based pairwise learning method does not require the kernel to be symmetric or positive semi-definite, which provides more flexibility and adaptivity in the learning process. We apply the method to the bipartite ranking problem, which improves the state-of-the-art theoretical results in previous works. By developing probability inequalities for U-statistics on Hilbert–Schmidt operators, we provide new mathematical tools for handling pairs of examples involved in pairwise learning.},
  archive      = {J_NN},
  author       = {Cheng Wang and Ting Hu and Siyang Jiang},
  doi          = {10.1016/j.neunet.2022.10.007},
  journal      = {Neural Networks},
  pages        = {176-192},
  shortjournal = {Neural Netw.},
  title        = {Pairwise learning problems with regularization networks and nyström subsampling approach},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inferring the location of neurons within an artificial
network from their activity. <em>NN</em>, <em>157</em>, 160–175. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring the connectivity of biological neural networks from neural activation data is an open problem. We propose that the analogous problem in artificial neural networks is more amenable to study and may illuminate the biological case. Here, we study the specific problem of assigning artificial neurons to locations in a network of known architecture, specifically the LeNet image classifier. We evaluate a supervised learning approach based on features derived from the eigenvectors of the activation correlation matrix . Experiments highlighted that for an image dataset to be effective for accurate localisation , it should fully activate the network and contain minimal confounding correlations. No single image dataset was found that resulted in perfect assignment, however perfect assignment was achieved using a concatenation of features from multiple image datasets.},
  archive      = {J_NN},
  author       = {Alexander J. Dyer and Lewis D. Griffin},
  doi          = {10.1016/j.neunet.2022.10.012},
  journal      = {Neural Networks},
  pages        = {160-175},
  shortjournal = {Neural Netw.},
  title        = {Inferring the location of neurons within an artificial network from their activity},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximum decentral projection margin classifier for high
dimension and low sample size problems. <em>NN</em>, <em>157</em>,
147–159. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with relatively easy feature creation or generation in data analysis, manual data labeling needs a lot of time and effort in most cases. Even if automated data labeling​ seems to make it better in some cases, the labeling results still need to be checked and verified by manual. The High Dimension and Low Sample Size (HDLSS) data are therefore very common in data mining and machine learning . For classification problems with the HDLSS data, due to data piling and approximate equidistance between any two input points in high-dimension space, some traditional classifiers often give poor predictive performance . In this paper, we propose a Maximum Decentral Projection Margin Classifier (MDPMC) in the framework of a Support Vector Classifier (SVC). In the MDPMC model , the constraints of maximizing the projection distance between decentralized input points and their supporting hyperplane are integrated into the SVC model in addition to maximizing the margin of two supporting hyperplanes. On ten real HDLSS datasets, the experiment results show that the proposed MDPMC approach can deal well with data piling and approximate equidistance problems. Compared with SVC with Linear Kernel (SVC-LK) and Radial Basis Function Kernel (SVC-RBFK), Distance Weighted Discrimination (DWD), weighted DWD (wDWD), Distance-Weighted Support Vector Machine (DWSVM), Population-Guided Large Margin Classifier (PGLMC), and Data Maximum Dispersion Classifier (DMDC), MDPMC obtains better predictive accuracy and lower classification errors than the other seven classifiers on the HDLSS data.},
  archive      = {J_NN},
  author       = {Zhiwang Zhang and Jing He and Jie Cao and Shuqing Li},
  doi          = {10.1016/j.neunet.2022.10.017},
  journal      = {Neural Networks},
  pages        = {147-159},
  shortjournal = {Neural Netw.},
  title        = {Maximum decentral projection margin classifier for high dimension and low sample size problems},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification-based prediction of network connectivity
robustness. <em>NN</em>, <em>157</em>, 136–146. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, there is an increasing concern about malicious attacks on various networks in society and industry, against which the network robustness is critical. Network connectivity robustness, in particular, is of fundamental importance, which is generally measured by a sequence of calculated values that indicate the connectedness of the remaining network after a sequence of attacks by means of node- or edge-removal. It is computationally time-consuming, however, to measure and evaluate the network connectivity robustness using the conventional attack simulations, especially for large-scale networked systems. In the present paper, an efficient robustness predictor based on multiple convolutional neural networks (mCNN-RP) is proposed for predicting the network connectivity robustness, which is an natural extension of the single CNN-based predictor. In mCNN-RP, one CNN works as the classifier, while each of the rest CNNs works as an estimator for predicting the connectivity robustness of every classified network category. The network categories are classified according to the available prior knowledge. A data-based filter is installed for predictive data refinement. Extensive experimental studies on both synthetic and real-world networks, including directed and undirected as well as weighted and unweighted topologies, verify the effectiveness of mCNN-RP. The results demonstrate that the average prediction error is lower than the standard deviation of the tested data, which outperforms the single CNN-based framework. The runtime in assessing network connectivity robustness is significantly reduced by using the CNN-based technique. The proposed mCNN-RP not only can accurately predict the connectivity robustness of various complex networks, but also provides an excellent indicator for the connectivity robustness, better than other existing prediction measures.},
  archive      = {J_NN},
  author       = {Yang Lou and Ruizi Wu and Junli Li and Lin Wang and Chang-Bing Tang and Guanrong Chen},
  doi          = {10.1016/j.neunet.2022.10.013},
  journal      = {Neural Networks},
  pages        = {136-146},
  shortjournal = {Neural Netw.},
  title        = {Classification-based prediction of network connectivity robustness},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inverse free reduced universum twin support vector machine
for imbalanced data classification. <em>NN</em>, <em>157</em>, 125–135.
(<a href="https://doi.org/10.1016/j.neunet.2022.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced datasets are prominent in real-world problems. In such problems, the data samples in one class are significantly higher than in the other classes, even though the other classes might be more important. The standard classification algorithms may classify all the data into the majority class, and this is a significant drawback of most standard learning algorithms, so imbalanced datasets need to be handled carefully. One of the traditional algorithms, twin support vector machines (TSVM), performed well on balanced data classification but poorly on imbalanced datasets classification. In order to improve the TSVM algorithm’s classification ability for imbalanced datasets, recently, driven by the universum twin support vector machine (UTSVM), a reduced universum twin support vector machine for class imbalance learning (RUTSVM) was proposed. The dual problem and finding classifiers involve matrix inverse computation, which is one of RUTSVM’s key drawbacks. In this paper, we improve the RUTSVM and propose an improved reduced universum twin support vector machine for class imbalance learning (IRUTSVM). We offer alternative Lagrangian functions to tackle the primal problems of RUTSVM in the suggested IRUTSVM approach by inserting one of the terms in the objective function into the constraints. As a result, we obtain new dual formulation for each optimization problem so that we need not compute inverse matrices neither in the training process nor in finding the classifiers. Moreover, the smaller size of the rectangular kernel matrices is used to reduce the computational time. Extensive testing is carried out on a variety of synthetic and real-world imbalanced datasets, and the findings show that the IRUTSVM algorithm outperforms the TSVM, UTSVM, and RUTSVM algorithms in terms of generalization performance .},
  archive      = {J_NN},
  author       = {Hossein Moosaei and M.A. Ganaie and Milan Hladík and M. Tanveer},
  doi          = {10.1016/j.neunet.2022.10.003},
  journal      = {Neural Networks},
  pages        = {125-135},
  shortjournal = {Neural Netw.},
  title        = {Inverse free reduced universum twin support vector machine for imbalanced data classification},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robustness meets accuracy in adversarial training for graph
autoencoder. <em>NN</em>, <em>157</em>, 114–124. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph autoencoder (GAE) is an effective deep method for graph embedding , while it is vulnerable to the graph adversarial attacks . Adversarial training, which generates adversarial examples in the adversarial scope(neighborhood of natural examples), is effective to improve the robustness of GAE. However, it may lead to degradation of natural accuracy (accuracy on natural examples) due to the extra training examples generated in the adversarial scope (the reasonable scope of adversarial examples). Therefore, considering robustness and natural accuracy is crucial to GAE. In this paper, an improved GAE model is formulated by combining the Structure and Feature encoders, and a novel Adversarial Training strategy (GAE-SFAT) is proposed based on improved GAE. GAE-SFAT has a smaller but more reasonable adversarial scope for adversarial training, which keeps the robustness and reduces the degradation of natural accuracy compared with ordinary adversarial training. In addition, a novel algorithm considering the robustness and accuracy is designed to optimize the GAE-SFAT. We conduct experiments both on the natural graphs as well as perturbed graphs for three datasets. The results show that GAE-SFAT can perform better than state of arts adversarial training model under different kinds of perturbations.},
  archive      = {J_NN},
  author       = {Xianchen Zhou and Kun Hu and Hongxia Wang},
  doi          = {10.1016/j.neunet.2022.10.010},
  journal      = {Neural Networks},
  pages        = {114-124},
  shortjournal = {Neural Netw.},
  title        = {Robustness meets accuracy in adversarial training for graph autoencoder},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforcement meta-learning framework of executive
function and information demand. <em>NN</em>, <em>157</em>, 103–113. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gathering information is crucial for maximizing fitness, but requires diverting resources from searching directly for primary rewards to actively exploring the environment. Optimal decision-making thus maximizes information while reducing effort costs, but little is known about the neuro-computational implementation of this tradeoff. We present a Reinforcement Meta-Learning (RML) computational model that solves the trade-off between the value and costs of gathering information. We implement the RML in a biologically plausible architecture that links catecholaminergic neuromodulators , the medial prefrontal cortex and topographically organized visual maps and show that it accounts for neural and behavioral findings on information demand motivated by instrumental incentives and intrinsic utility. Moreover, the utility function used by the RML, encoded by dopamine, is an approximation of variational free energy. Thus, the RML presents a biologically plausible mechanism for coordinating motivational, executive and sensory systems generate visual information gathering policies that minimize free energy.},
  archive      = {J_NN},
  author       = {Massimo Silvetti and Stefano Lasaponara and Nabil Daddaoua and Mattias Horan and Jacqueline Gottlieb},
  doi          = {10.1016/j.neunet.2022.10.004},
  journal      = {Neural Networks},
  pages        = {103-113},
  shortjournal = {Neural Netw.},
  title        = {A reinforcement meta-learning framework of executive function and information demand},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-aspect enhanced graph neural networks for
recommendation. <em>NN</em>, <em>157</em>, 90–102. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved remarkable performance in personalized recommendation, for their powerful data representation capabilities. However, these methods still face several challenging problems: (1) the majority of user–item interaction graphs only utilize the interaction information, which cannot reflect the users’ specific preferences for different aspects, making it difficult to capture user preferences in a fine-grained manner. (2) there is no effective way to integrate multi-aspect preferences into a unified model to capture the comprehensive user interests. To address these challenges, we propose a Multi-Aspect enhanced Graph Neural Networks (MA-GNNs) model for item recommendation. Specifically, we learn the aspect-based sentiments from reviews and use them to construct multiple aspect-aware user–item graphs, thus giving the edge practical meaning. And aspect semantic features are introduced into the information aggregation process to adjust users’ preferences for different items. Furthermore, we design a routing-based fusion mechanism, which adaptively allocates weights to different aspects to realize the dynamic fusion of aspect preferences. We conduct experiments on four publicly available datasets, and the experimental results show that the proposed MA-GNNs model outperforms state-of-the-art methods. Further analysis proves that fine-grained interest modeling can improve the interpretability of recommendations.},
  archive      = {J_NN},
  author       = {Chenyan Zhang and Shan Xue and Jing Li and Jia Wu and Bo Du and Donghua Liu and Jun Chang},
  doi          = {10.1016/j.neunet.2022.10.001},
  journal      = {Neural Networks},
  pages        = {90-102},
  shortjournal = {Neural Netw.},
  title        = {Multi-aspect enhanced graph neural networks for recommendation},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tropical support vector machines: Evaluations and extension
to function spaces. <em>NN</em>, <em>157</em>, 77–89. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support Vector Machines (SVMs) are one of the most popular supervised learning models to classify using a hyperplane in an Euclidean space . Similar to SVMs, tropical SVMs classify data points using a tropical hyperplane under the tropical metric with the max-plus algebra. In this paper, first we show generalization error bounds of tropical SVMs over the tropical projective torus. While the generalization error bounds attained via Vapnik–Chervonenkis (VC) dimensions in a distribution-free manner still depend on the dimension, we also show numerically and theoretically by extreme value statistics that the tropical SVMs for classifying data points from two Gaussian distributions as well as empirical data sets of different neuron types are fairly robust against the curse of dimensionality . Extreme value statistics also underlie the anomalous scaling behaviors of the tropical distance between random vectors with additional noise dimensions. Finally, we define tropical SVMs over a function space with the tropical metric.},
  archive      = {J_NN},
  author       = {Ruriko Yoshida and Misaki Takamori and Hideyuki Matsumoto and Keiji Miura},
  doi          = {10.1016/j.neunet.2022.10.002},
  journal      = {Neural Networks},
  pages        = {77-89},
  shortjournal = {Neural Netw.},
  title        = {Tropical support vector machines: Evaluations and extension to function spaces},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-HGT: Metapath-aware HyperGraph transformer for
heterogeneous information network embedding. <em>NN</em>, <em>157</em>,
65–76. (<a href="https://doi.org/10.1016/j.neunet.2022.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information network embedding aims to learn low-dimensional node vectors in heterogeneous information networks (HINs), concerning not only structural information but also heterogeneity of diverse node and relation types. Most existing HIN embedding models mainly rely on metapath to define composite relations between node pairs and thus extract substructures from the original HIN. However, due to the pairwise structure of metapath, these models fail to capture the high-order relations (such as “ Multiple authors co-authoring a paper ”) implicitly contained in HINs. To tackle the limitation, this paper proposes a Metapath-aware HyperGraph Transformer (Meta-HGT) for node embedding in HINs. Meta-HGT first extends metapath to guide the high-order relation extraction from original HIN and constructs multiple metapath based hypergraphs with diverse composite semantics. Then, Meta-HGT learns the latent node and hyperedge embeddings in each metapath based hypergraph through Meta-HGT layers. Each layer consists of two types of components, i.e., intra-hyperedge aggregation and inter-hyperedge aggregation, in which a novel type-dependent attention mechanism is proposed for node and hyperedge feature aggregation. Finally, it fuses multiple node embeddings learned from different metapath based hypergraphs via a semantic attention layer and generates the final node embeddings. Extensive experiments have been conducted on three HIN benchmarks for node classification . The results demonstrate that Meta-HGT achieves state-of-the-art performance on all three datasets.},
  archive      = {J_NN},
  author       = {Jie Liu and Lingyun Song and Guangtao Wang and Xuequn Shang},
  doi          = {10.1016/j.neunet.2022.08.028},
  journal      = {Neural Networks},
  pages        = {65-76},
  shortjournal = {Neural Netw.},
  title        = {Meta-HGT: Metapath-aware HyperGraph transformer for heterogeneous information network embedding},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Practical synchronization of neural networks with delayed
impulses and external disturbance via hybrid control. <em>NN</em>,
<em>157</em>, 54–64. (<a
href="https://doi.org/10.1016/j.neunet.2022.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of practical synchronization for delayed neural networks via hybrid-driven impulsive control in which delayed impulses and external disturbance are taken into account. Firstly, a switching method which establishes the relationship between error signals and a threshold function is introduced, which determines whether time-driven control or event-driven control is activated. Secondly, the effects of delayed impulses and external disturbance on impulsive systems are considered, and the corresponding comparison lemma is proposed. Thirdly, whenever the norm of the initial value of the error system state is less than or greater than the initial value of the threshold function, under the proposed hybrid-driven impulsive control scheme, the practical synchronization of the delayed neural networks with delayed impulses and external disturbance can be achieved by synchronizing impulses. Moreover, the Zeno behavior can be excluded under the proposed hybrid-driven impulsive control. Finally, two numerical examples are presented to verify the effectiveness of the theoretical results.},
  archive      = {J_NN},
  author       = {Shiyu Dong and Xinzhi Liu and Shouming Zhong and Kaibo Shi and Hong Zhu},
  doi          = {10.1016/j.neunet.2022.09.025},
  journal      = {Neural Networks},
  pages        = {54-64},
  shortjournal = {Neural Netw.},
  title        = {Practical synchronization of neural networks with delayed impulses and external disturbance via hybrid control},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image-based time series forecasting: A deep convolutional
neural network approach. <em>NN</em>, <em>157</em>, 39–53. (<a
href="https://doi.org/10.1016/j.neunet.2022.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the successful use of deep learning in computer vision , in this paper we introduce ForCNN , a novel deep learning method for univariate time series forecasting that mixes convolutional and dense layers in a single neural network . Instead of using conventional, numeric representations of time series data as input to the network, the proposed method considers visual representations of it in the form of images to directly produce point forecasts. Three variants of deep convolutional neural networks are examined to process the images, the first based on VGG-19, the second on ResNet-50, while the third on a self-designed architecture. The performance of the proposed approach is evaluated using time series of the M3 and M4 forecasting competitions. Our results suggest that image-based time series forecasting methods can outperform both standard and state-of-the-art forecasting models .},
  archive      = {J_NN},
  author       = {Artemios-Anargyros Semenoglou and Evangelos Spiliotis and Vassilios Assimakopoulos},
  doi          = {10.1016/j.neunet.2022.10.006},
  journal      = {Neural Networks},
  pages        = {39-53},
  shortjournal = {Neural Netw.},
  title        = {Image-based time series forecasting: A deep convolutional neural network approach},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rutting prediction and analysis of influence factors based
on multivariate transfer entropy and graph neural networks. <em>NN</em>,
<em>157</em>, 26–38. (<a
href="https://doi.org/10.1016/j.neunet.2022.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Rutting prediction model is an essential element of efficient pavement management systems . Accuracy of commonly used predictive model necessitates knowledge of the input parameters that was incorporated and local calibration of the model coefficients . In this paper, a novel rutting prediction model based on multivariate transfer entropy and graph neural networks is proposed for incorporating a limited number of observable inputs, which can accommodate with sufficient prediction performance and generalization to a variety of complex pavement design structure data . The multivariate transfer entropy based graph representation is able to find the significant causality between variables and rutting. The influence factor analysis results confirm the high influence of temperature and vehicle axle load . Several experiments are set up on the Research Institute of Highway Ministry of Transport track (RIOHTrack) dataset for the comparison between the proposed model and the state-of-art prediction models. The result demonstrates that the proposed model is more accurate and robust compared to existing methods on the rutting prediction task.},
  archive      = {J_NN},
  author       = {Jinren Zhang and Jinde Cao and Wei Huang and Xinli Shi and Xingye Zhou},
  doi          = {10.1016/j.neunet.2022.08.030},
  journal      = {Neural Networks},
  pages        = {26-38},
  shortjournal = {Neural Netw.},
  title        = {Rutting prediction and analysis of influence factors based on multivariate transfer entropy and graph neural networks},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple asymptotical ω-periodicity of fractional-order
delayed neural networks under state-dependent switching. <em>NN</em>,
<em>157</em>, 11–25. (<a
href="https://doi.org/10.1016/j.neunet.2022.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents theoretical results on multiple asymptotical ω ω -periodicity of a state-dependent switching fractional-order neural network with time delays and sigmoidal activation functions . Firstly, by combining the geometrical properties of activation functions with the range of switching threshold, a partition of state space is given. Then, the conditions guaranteeing that the solutions can approach each other infinitely in each positive invariant set are derived. Furthermore, the S S -asymptotical ω ω -periodicity and the convergence of solutions in positive invariant sets are discussed. It is worth noting that the number of attractors increases to 3 n 3n from 2 n 2n in a neural network without switching. Finally, three numerical examples are given to substantiate the theoretical results.},
  archive      = {J_NN},
  author       = {Jingxuan Ci and Zhenyuan Guo and Han Long and Shiping Wen and Tingwen Huang},
  doi          = {10.1016/j.neunet.2022.09.034},
  journal      = {Neural Networks},
  pages        = {11-25},
  shortjournal = {Neural Netw.},
  title        = {Multiple asymptotical ω-periodicity of fractional-order delayed neural networks under state-dependent switching},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pinning synchronization of stochastic neutral memristive
neural networks with reaction–diffusion terms. <em>NN</em>,
<em>157</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neunet.2022.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms. Firstly, two novel pinning controllers, which contain both current state and past state, are designed. Subsequently, in terms of Green’s theorem, inequality technology, stochastic analysis theory and pinning control technology, two easy-to-test sufficient conditions based on algebraic inequalities are obtained to ensure the mean-square asymptotic synchronization of stochastic memristive neural networks with neutral delays and reaction–diffusion terms by providing a new Lyapunov–Krasovskii functional. In addition, some existing results can be regarded as special cases of our work. Finally, illustrative examples further verify the correctness and validity of the derived results.},
  archive      = {J_NN},
  author       = {Xiang Wu and Shutang Liu and Huiyu Wang},
  doi          = {10.1016/j.neunet.2022.09.032},
  journal      = {Neural Networks},
  pages        = {1-10},
  shortjournal = {Neural Netw.},
  title        = {Pinning synchronization of stochastic neutral memristive neural networks with reaction–diffusion terms},
  volume       = {157},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
