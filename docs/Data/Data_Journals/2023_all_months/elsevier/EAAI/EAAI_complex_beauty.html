<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai---1559">EAAI - 1559</h2>
<ul>
<li><details>
<summary>
(2023). Using machine learning techniques to predict ammonium
concentration in membrane contactors for nitrogen recovery as a valuable
resource. <em>EAAI</em>, <em>126</em>, 107330. (<a
href="https://doi.org/10.1016/j.engappai.2023.107330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of real-time measurements of primary quality water variables is one of the key challenges in the wastewater treatment industry. However, due to the cost and maintenance requirements of sensors and probes for on-line measurement of primary quality variables, the prediction of these variables via data-driven approaches using as inputs easy-to-measure process variables has attracted research interest. In this paper, different machine learning techniques: feed-forward artificial neural network, random forest, support vector machine, gaussian process regression and partial least squares were used to predict in real-time the total ammonium nitrogen concentration during the operation of a hollow fibre membrane contactor. This recently developed technology allows the recovery of nitrogen from nitrogen rich streams (i.e. supernatant of anaerobic digesters in wastewater treatment plants) as ammonium sulphate (a marketable fertilizer). These contactors are usually operated in batch mode, pumping the high nitrogen concentration feed from the storage tank, where the total ammonium nitrogen concentration decreases progressively as the fertilizer is produced. Knowing the real-time concentration of total ammonium nitrogen in the storage tank would enable the optimization of the process operation, avoiding its operation with conservative fixed-time batch duration. The pH is an easy-to-measure process variable usually available in wastewater treatment plants that was used as input of the tested data-driven models, together with two extracted features from this variable (its derivative and increments after each reagent dosing). The number of total ammonium nitrogen measurements in the collected database is 2350 data points (corresponding to 8 complete batches, which were divided into 6 for training the data-driven models and 2 for testing them), ranging from 987 to 2.5 mg NH 4 + -N/L which covers almost the complete range of total ammonium nitrogen concentration values in the membrane contactor. The predictive ability of the developed predictive models was evaluated on the test data set by four indices, namely: the root-mean-square error, the slope and the intercept of the linear fit between the measured and predicted concentrations and the determination coefficient. The results showed a strong predictive ability of the fitted ANN that outperformed the other approaches exhibiting a determination coefficient of 0.99 and the lowest root-mean-square error (19.87 mg/L) in the test set. Permutation variable importance demonstrated that all machine learning techniques depended mainly on the two variables extracted from the pH: its derivative and increments, which resulted to be more important than the pH itself to predict the total ammonium nitrogen concentration.},
  archive      = {J_EAAI},
  author       = {D. Aguado and G. Noriega-Hevia and J. Serralta and A. Seco},
  doi          = {10.1016/j.engappai.2023.107330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Using machine learning techniques to predict ammonium concentration in membrane contactors for nitrogen recovery as a valuable resource},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Time-energy-jerk optimal trajectory planning for high-speed
parallel manipulator based on quantum-behaved particle swarm
optimization algorithm and quintic b-spline. <em>EAAI</em>,
<em>126</em>, 107223. (<a
href="https://doi.org/10.1016/j.engappai.2023.107223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a technique for multi-node trajectory planning for high-speed parallel manipulators that optimizes the execution time, energy consumption and jerk (the time derivative of the acceleration of the manipulator joints) to improve working efficiency, decrease energy consumption, dampen vibration and ensure mechanism protection. Initially, an improved quintic B-spline interpolation model is proposed, incorporating additional jerk boundary constraints to dampen residual vibrations at the start and end of the trajectory. Subsequently, the time-energy-jerk optimization model is formulated, with the maximum angular velocity, acceleration, and jerk serving as constraints. The normalized parameter of the B-spline curve is considered to divide the whole model into two submodels. In the first submodel, the satisfaction function is proposed to convert energy and jerk indices into one comprehensive objective for optimization with the quantum-behaved particle swarm optimization (QPSO) algorithm. Time parameters are to be decided as decision variables, regardless of kinematic constraints and execution time. In the second submodel, the optimal time parameters obtained in the first submodel are used as input arguments, and the optimal execution time is determined with respect to the kinematic constraints. The simulation results on a planar parallel manipulator show that the proposed method achieves an efficient trajectory, which is energy-saving and possesses reduced vibration. Application of the comprehensive trajectory generated by the proposed method, rather than the classical method, enhances the maximum productivity of the fast pick-and-place operation to 155 picks per minute from 97 picks/min. This improvement is accomplished by using less energy and reducing vibration.},
  archive      = {J_EAAI},
  author       = {Weihua Chen and Heng Wang and Zhanhao Liu and Kejian Jiang},
  doi          = {10.1016/j.engappai.2023.107223},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107223},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time-energy-jerk optimal trajectory planning for high-speed parallel manipulator based on quantum-behaved particle swarm optimization algorithm and quintic B-spline},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integration of distributed generations and static var
compensators with static synchronous compensators to reduce power
losses. <em>EAAI</em>, <em>126</em>, 107208. (<a
href="https://doi.org/10.1016/j.engappai.2023.107208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The necessity of power is growing in response to today&#39;s growing population. In order to reduce both real and reactive power losses, three devices have been combined in this research. The distributed generations (DGs) and static var compensator (SVC) with static synchronous compensator (STATCOM) play important role for reduction of power losses (both real and reactive power) and improvement of voltage profile. The research outcome presented here outlines that presents genetic algorithm (GA) may be utilised to improve power system performance and voltage profile (VP) of distribution networks by integrating DG, SVC and STATCOM planning properly. On a 37-bus distribution network, the proposed methodology has been applied. The results of this study are helpful to those focusing on the functionality of viable and upcoming electrical grids, as well as those working in the disciplines of DG, SVC and STATCOM integration for improved system performance.},
  archive      = {J_EAAI},
  author       = {Vipul Shukla and V. Mukherjee and Bindeshwar Singh},
  doi          = {10.1016/j.engappai.2023.107208},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107208},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integration of distributed generations and static var compensators with static synchronous compensators to reduce power losses},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart filter aided domain adversarial neural network for
fault diagnosis in noisy industrial scenarios. <em>EAAI</em>,
<em>126</em>, 107202. (<a
href="https://doi.org/10.1016/j.engappai.2023.107202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of unsupervised domain adaptation (UDA)-based fault diagnosis methods has shown significant efficacy in industrial settings, facilitating the transfer of operational experience and fault signatures between different operating conditions, different units of a fleet or between simulated and real data. However, in real industrial scenarios, unknown levels and types of noise can amplify the difficulty of domain alignment, thus severely affecting the diagnostic performance of deep learning models. To address this issue, we propose an UDA method called Smart Filter-Aided Domain Adversarial Neural Network (SFDANN) for fault diagnosis in noisy industrial scenarios. The proposed methodology comprises two steps. In the first step, we develop a smart filter that dynamically enforces similarity between the source and target domain data in the time-frequency domain. This is achieved by combining a learnable wavelet packet transform network (LWPT) and a traditional wavelet packet transform module. In the second step, we input the data reconstructed by the smart filter into a domain adversarial neural network (DANN). To learn domain-invariant and discriminative features, the learnable modules of SFDANN are trained in a unified manner with three objectives: time-frequency feature proximity, domain alignment, and fault classification. We validate the effectiveness of the proposed SFDANN method based on two fault diagnosis cases: one involving fault diagnosis of bearings in noisy environments and another involving fault diagnosis of slab tracks in a train-track-bridge coupling vibration system, where the transfer task involves transferring from numerical simulations to field measurements. Results show that compared to other representative state of the art UDA methods, SFDANN exhibits superior performance and remarkable stability.},
  archive      = {J_EAAI},
  author       = {Baorui Dai and Gaëtan Frusque and Tianfu Li and Qi Li and Olga Fink},
  doi          = {10.1016/j.engappai.2023.107202},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107202},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Smart filter aided domain adversarial neural network for fault diagnosis in noisy industrial scenarios},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A chebyshev polynomial approach to approximate solution of
differential equations using differential evolution. <em>EAAI</em>,
<em>126</em>, 107197. (<a
href="https://doi.org/10.1016/j.engappai.2023.107197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the problems associated with physical, biological and engineering systems are complex and are usually modeled with the help of linear as well as non-linear differential equations. In general, the exact solutions of non-linear differential equations may not be obtained by analytical methods and thus, in this paper, a numerical method is proposed to find approximate solutions of differential equations using Chebyshev polynomials and metaheuristic optimization algorithms. In this paper, Ordinary differential equations (ODEs) are modeled as optimization problems to determine their approximate solutions by considering Chebyshev polynomials as the base approximation function, taking initial and/or boundary conditions as constraints. The unknown coefficients of the polynomials are calculated using Differential Evolution (DE) in order to get the approximate solution with minimal error. The proposed method is applied to find the approximate solution to both Initial and Boundary Value Problems. For all test problems considered in this paper, the algorithms have been programmed using MATLAB software to run on computer. The effectiveness of the method is demonstrated by graphical comparison of the computed approximate solutions with that of the exact ones. Further, the performance of the method proposed in this paper is shown by finding out the Root Mean Square Error (RMSE) between the exact and approximate solution, which is found to be better than that of the related existing papers.},
  archive      = {J_EAAI},
  author       = {Ratika Rastogi and O.P. Misra and Rajshree Mishra},
  doi          = {10.1016/j.engappai.2023.107197},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107197},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A chebyshev polynomial approach to approximate solution of differential equations using differential evolution},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analyzing system reliability using conflicting bifuzzy
failure rates of the components. <em>EAAI</em>, <em>126</em>, 107195.
(<a href="https://doi.org/10.1016/j.engappai.2023.107195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since uncertainty and ambiguity are common in real-world problems, numerous methods based on different kinds of fuzzy sets have been widely used in the evaluation of system reliability over the years. However, these methods are unable to deal with conflict uncertainty, particularly when it comes to the uncertain failure rates of the system&#39;s components. This paper introduces the idea of the triangular conflicting bifuzzy set (TCBFS), which is a novel paradigm for dealing with conflicting uncertainty. A novel method is devised to determine the membership and non-membership functions for the system&#39;s reliability when subsystems/components exhibit conflicting bifuzzy failure rates. In order to generate the membership and non-membership functions for various system configurations, including series, parallel, series-parallel, and parallel-series systems, non-linear programming is used to derive a number of functions based on conflicting bifuzzy numbers. The validity of the suggested method in modeling and evaluating system reliability with different conflicting bifuzzy failure rates is demonstrated through illustrated scenarios. This novel approach improves the precision and resilience of reliability estimations for systems by providing a more precise representation of uncertainties.},
  archive      = {J_EAAI},
  author       = {Shshank Chaube},
  doi          = {10.1016/j.engappai.2023.107195},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107195},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analyzing system reliability using conflicting bifuzzy failure rates of the components},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent framework for estimating grade and quantity
of tropical fruits in a multi-modal latent representation network.
<em>EAAI</em>, <em>126</em>, 107193. (<a
href="https://doi.org/10.1016/j.engappai.2023.107193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research addresses the crucial aspects of ensuring the quality and origin of fruits in the supply chain, as well as estimating their quantity measures. A novel interwoven deep neural framework is proposed, incorporating an Object Detection Network (ODN) and a Multi-modal Regressive Convolution Neural Network (MRCNN). Two distinct datasets, Annotated FruitNet and FruitBox, were compiled to support the framework’s tasks. The FruitNet360 dataset was re-clustered based on geographical origin, enabling robust fruit quality detection and localization with a mean Average Precision (mAP) score of 95.70% using YOLOv7. Leveraging the representation learning capability of Residual Networks, the framework accurately predicted quantitative weight measures of fruit boxes, achieving a marginal Mean Squared Error (MSE) rate of 0.034. Furthermore, the origin of fruits was identified with an impressive accuracy of 98.67%. The proposed framework, with its combined regression and classification model, captured the latent representations of source data effectively, surpassing the limitations of conventional approaches and reducing manual system overhead. The automation framework holds potential for integration into smart devices, offering valuable assistance to both vendors and consumers in fruit analysis and selection.},
  archive      = {J_EAAI},
  author       = {Misaj Sharafudeen and Vinod Chandra S.S.},
  doi          = {10.1016/j.engappai.2023.107193},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107193},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intelligent framework for estimating grade and quantity of tropical fruits in a multi-modal latent representation network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intuitionistic fuzzy-based model for performance
evaluation of EcoPorts. <em>EAAI</em>, <em>126</em>, 107192. (<a
href="https://doi.org/10.1016/j.engappai.2023.107192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The EcoPort performance level serves as a basic indicator to determine the environmental status of a port and its achievement of certification standards. The European Sea Ports Organization has defined ten essential EcoPort criteria that contribute significantly to the assessment of EcoPort performance. The primary motivation for this study is to determine the importance of the criteria from the perspective of academics and chief officers, as well as to evaluate the EcoPort performance of six port authorities that comply with three basic certification standards for environmental management systems. The research methodology and application are conducted in four phases. In the first phase, experts, criteria, and alternative ports are identified. In the second phase, the importance levels of experts are determined using neutrosophic sets, while the criteria are weighted using the intuitionistic fuzzy weighting averaging operator. In the third phase, the alternative ranking order method accounting for two-step normalization (AROMAN) based on the intuitionistic fuzzy sets is introduced to evaluate the EcoPort performance of the ports. In the fourth phase, the results are supported by sensitivity analysis scenarios. The research results identified air pollution as the most critical criterion, while the Valencia Port Authority secured the highest rank in terms of EcoPort performance. Ultimately, this research contributes to the literature by developing and applying the new IF-AROMAN method for EcoPort performance evaluation.},
  archive      = {J_EAAI},
  author       = {Galip Cihan Yalçın and Karahan Kara and Arda Toygar and Vladimir Simic and Dragan Pamucar and Nilay Köleoğlu},
  doi          = {10.1016/j.engappai.2023.107192},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107192},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intuitionistic fuzzy-based model for performance evaluation of EcoPorts},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction-based peer-to-peer energy transaction market
design for smart grids. <em>EAAI</em>, <em>126</em>, 107190. (<a
href="https://doi.org/10.1016/j.engappai.2023.107190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting energy costs and energy generation in traditional power grids is a complex endeavour, primarily due to the imperative of maintaining supply–demand equilibrium for upholding the stability of the power system. Predicting energy costs and generation includes the highly variable nature of energy prices and the need to analyze large amounts of data from various sources. We propose an auto-executable blockchain-based peer-to-peer(P2P) energy transaction market with a Long short-term memory (LSTM) neural network to address challenges in the energy sector. LSTM can handle non-linear relationships and can effectively model and predict the complex patterns that arise in energy markets. Our energy market enables accurate energy consumption and production prediction, facilitates decentralized and sustainable energy trading, and balances supply and demand via smart contracts. A secure and efficient blockchain-based P2P energy transaction market is designed to facilitate transactions in smart grids. The integrated system is a novel contribution that can improve energy systems’ efficiency, reliability, and sustainability. Our experiments show that our proposed energy market can reduce the electricity buying budget by 17.68% compared to the traditional market and 41.36% compared to the open loop look ahead dispatch method for 30 microgrids and the utility.},
  archive      = {J_EAAI},
  author       = {I. Chien and P. Karthikeyan and Pao-Ann Hsiung},
  doi          = {10.1016/j.engappai.2023.107190},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107190},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction-based peer-to-peer energy transaction market design for smart grids},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid metaheuristic with learning for a real supply chain
scheduling problem. <em>EAAI</em>, <em>126</em>, 107188. (<a
href="https://doi.org/10.1016/j.engappai.2023.107188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, research on supply chain management (SCM) has enabled companies to improve their environmental, social, and economic performance. This paper presents an industrial application of logistics that can be classified as an inventory-route problem. The problem consists of assigning orders to the available warehouses. The orders are composed of items that must be loaded within a week. The warehouses provide an inventory of the number of items available for each day of the week, so the objective is to minimize the total transportation costs and the costs of producing extra stock to satisfy the weekly demand. To solve this problem a formal mathematical model is proposed. Then a hybrid approach that involves two metaheuristics: a greedy randomized adaptive search procedure (GRASP) and a genetic algorithm (GA) is proposed. Additionally, a meta-learning tuning method is incorporated into our hybridized approach, which yields better results but with a longer computation time. Thus, the trade-off of using it is analyzed. An extensive evaluation was carried out over realistic instances provided by an industrial partner. The proposed technique was evaluated and compared with several complete and incomplete solvers from the state of the art (CP Optimizer, Yuck, OR-Tools, etc.). The results showed that our hybrid metaheuristic outperformed the behavior of these well-known solvers, mainly in large-scale instances (2000 orders per week). This hybrid algorithm provides the company with a powerful tool to solve its supply chain management problem, delivering significant economic benefits every week.},
  archive      = {J_EAAI},
  author       = {Christian Pérez and Laura Climent and Giancarlo Nicoló and Alejandro Arbelaez and Miguel A. Salido},
  doi          = {10.1016/j.engappai.2023.107188},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107188},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid metaheuristic with learning for a real supply chain scheduling problem},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning model for efficient end-to-end
stratification of thrombotic risk in left atrial appendage.
<em>EAAI</em>, <em>126</em>, 107187. (<a
href="https://doi.org/10.1016/j.engappai.2023.107187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clot formation in the left atrial appendage (LAA) poses a high risk of ischemic strokes and systemic embolism to patients with atrial fibrillation (AF), the most common type of sustained heart arrhythmia that affects more than 35 million people worldwide. Hemodynamic metrics evaluated using computational fluid dynamics (CFD) have been employed to assess the risk of thrombosis in LAA, but its utilization in clinical settings is limited due to their cumbersome operations and high computational cost. To this end, we propose UDGCNN (U: U-net, DGCNN: Dynamic Graph Convolutional Neural Network) that can utilize data from the point cloud of patient-specific LAA geometries as inputs and predict multiple hemodynamic indexes for systematic assessment of the thrombotic risk. The novelty of the proposed model lies in introducing edge convolution layers to the PointNet structure to improve the model’s capacity to learn local features, which is essential for training and predicting complex patient-specific geometries. Moreover, the network structure of UDGCNN is optimized by integrating the Encoder-Decoder structure and skip-connection to extract hierarchical features from the point cloud. The accuracy and efficiency of the UDGCNN is examined by training and testing on 371 LAA geometries from patients with AF, the largest patient-specific dataset in the literature. Using mean absolute error and model inference time as metrics, we demonstrate that UDGCNN can provide an assessment of multiple hemodynamic metrics in 3D patient-specific geometries with prediction error ∼ 30% lower than those of the state-of-art PointNet model, whereas the inference time is 500-fold shorter compared to computational time CFD simulation. It is noted that UDGCNN is a general computational framework that can be extended to study various cardiovascular diseases. In summary, this study presents a new computational tool that enables end-to-end stratification of thrombotic risk in LAA based on bioimaging, thereby advancing the current screening approach in clinical practice.},
  archive      = {J_EAAI},
  author       = {Qi Gao and Hongtao Lin and Jianghong Qian and Xingli Liu and Shengze Cai and He Li and Hongguang Fan and Zhe Zheng},
  doi          = {10.1016/j.engappai.2023.107187},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107187},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning model for efficient end-to-end stratification of thrombotic risk in left atrial appendage},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Screening out potentially defective products in
micro-transformer production by intelligently integrating mechanical and
electronic signals. <em>EAAI</em>, <em>126</em>, 107186. (<a
href="https://doi.org/10.1016/j.engappai.2023.107186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with unstable mechanical status, the critical uncertainty of micro-transformer at electronic specification boundary leads to potentially defective products (PDPs) in qualified products. Hence, an intelligent prediction of PDPs is proposed by integrating mechanical and electronic signals and tracing defective product information. The objective is to screen out the PDPs by the relationship between critical state of normal test equipment and the defective ex-factory products in actual production. On the base of time and frequency domain eigenvalues, Artificial Neural Network (ANN) and Naïve Bayes (NB) were firstly employed to process the vibration signal of equipment testing probe for network training and prior probability, respectively. Then, the various electronic signals related to quality performance parameters were categorized to screen out the PDPs by K-Nearest Neighbor (KNN) and Support Vector Machine (SVM) along with spatial distance and hyperplane databases, respectively. Finally, the screen-out threshold was introduced to evaluate the reasonableness with reference to the phase-out divergence. It is shown that the NB more precisely recognizes the equipment status by timely updating small and incomplete samples than the ANN. Compared to the SVM, the KNN validly screens out the PDPs due to its superior processing capability of electronic signals. As a result, the screen-out threshold is set as 5–6% to balance the screen-out number and precision.},
  archive      = {J_EAAI},
  author       = {Lei Li and Jin Xie and Xingqiu Zhao and Quanpeng He and Risen Wang},
  doi          = {10.1016/j.engappai.2023.107186},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107186},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Screening out potentially defective products in micro-transformer production by intelligently integrating mechanical and electronic signals},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Augmented physics-informed neural networks (APINNs): A
gating network-based soft domain decomposition methodology.
<em>EAAI</em>, <em>126</em>, 107183. (<a
href="https://doi.org/10.1016/j.engappai.2023.107183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) and extended PINNs (XPINNs) have emerged as a promising approach in computational science and engineering for solving partial differential equations (PDEs) by combining the power of artificial intelligence (AI) with the underlying physics to accurately model and predict the solutions to complex problems in science and engineering. In this work, we propose the augmented physics-informed neural network (APINN), which adopts soft and trainable domain decomposition and flexible parameter sharing to further improve the extended PINN (XPINN) as well as the vanilla PINN methods. Concretely, a trainable gate network is employed to mimic the hard decomposition of XPINN, which can be flexibly fine-tuned for discovering a potentially better partition. The gate network satisfying the partition-of-unity property, weighted averages several sub-networks as the final output. APINN does not require complex interface conditions, whose sub-nets can utilize all training samples rather than just part of the training data in their subdomains. Lastly, each sub-net shares part of the common parameters to capture the similar components in each decomposed function. Furthermore, following the PINN generalization theory (Hu et al., 2022), APINN is shown to improve generalization by proper gate network initialization and general domain &amp; function decomposition. Extensive experiments on different partial differential equations (PDEs) demonstrate how APINN improves PINN and XPINN. Specifically, we present examples where XPINN performs similarly to or worse than PINN, so that APINN can significantly improve both. We also show cases where XPINN is already better than PINN, so APINN can still slightly improve XPINN. Furthermore, we visualize the optimized gating networks and their optimization trajectories, and connect them with their performance, which helps discover the possibly optimal decomposition. Interestingly, if initialized by different decomposition, the performances of corresponding APINNs can differ drastically. This, in turn, shows the potential to design an optimal domain decomposition for the PDE under consideration.},
  archive      = {J_EAAI},
  author       = {Zheyuan Hu and Ameya D. Jagtap and George Em Karniadakis and Kenji Kawaguchi},
  doi          = {10.1016/j.engappai.2023.107183},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107183},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Augmented physics-informed neural networks (APINNs): A gating network-based soft domain decomposition methodology},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lightweight privacy-preserving scheme using pixel block
mixing for facial image classification in deep learning. <em>EAAI</em>,
<em>126</em>, 107180. (<a
href="https://doi.org/10.1016/j.engappai.2023.107180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The training of state-of-the-art deep learning models generally requires significant high-quality data, including personal and sensitive data. To ensure privacy of the sensitive data used in training deep learning models, many methods have been designed by the research community. However, it has been observed that many privacy-preserving approaches for image-based deep learning model training incur significant time in the processing of images and/or have low accuracy on trained models when a large number of images is used for classification tasks. Hence, in this paper, we propose a lightweight and efficient approach to preserve image privacy while maintaining the availability of the training set. Specifically, we design the pixel block mixing algorithm for facial image classification privacy preservation in deep learning. Experimental findings show that the models trained by the mixed training set generated by the proposed algorithm maintain their availability. The comparison results of the structural similarity index measure between images in the new training set and the original training set show that our scheme preserves image privacy. Our evaluations also reveal that the data augmentation can be applied to the mixed training set to improve the training effectiveness. We also demonstrate it is computationally challenging for attackers to restore the mixed training set to the original one.},
  archive      = {J_EAAI},
  author       = {Yuexin Xiang and Tiantian Li and Wei Ren and Tianqing Zhu and Kim-Kwang Raymond Choo},
  doi          = {10.1016/j.engappai.2023.107180},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107180},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight privacy-preserving scheme using pixel block mixing for facial image classification in deep learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep convolution multi-adversarial adaptation network with
correlation alignment for fault diagnosis of rotating machinery under
different working conditions. <em>EAAI</em>, <em>126</em>, 107179. (<a
href="https://doi.org/10.1016/j.engappai.2023.107179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation (DA) approaches have been extensively applied to the diagnosis of rotating machinery faults under different working conditions. However, most DA-based methods perform poorly in practical situations since they generally only consider the global distribution or subdomain distribution of the source and target domains. Thus, we propose a novel Deep Convolution Multi-Adversarial adaptation network with Correlation Alignment (DCMACA). DCMACA consists of an improved deep convolutional feature extractor, a domain adaptation module, and a label classifier. The improved deep convolutional feature extractor comprises ordinary convolutional layers, depthwise convolution layers, Squeeze and Excitation modules, skip connection operations, an average pooling layer, and a fully connected layer. The domain adaptation module introduces multiple domain discriminators and Coral distance to align the subdomain distribution and global distribution of features extracted by the feature extractor, respectively. The softmax function is employed as the label classifier. Based on DCMACA, we presented a new approach for identifying faults in rotating machinery under different operating conditions. First, the original vibration signals are converted into the time-frequency maps of size 64 × 64 via the continuous wavelet transform and bilinear interpolation technologies. Subsequently, the time-frequency maps are input to DCMACA to complete the extraction of transferable features and fault identification. The proposed DCMACA fault identification approach was evaluated through two experiments, where it achieved an average accuracy of 98.84% in 18 migration diagnostic tasks. The comprehensive results reveal that the presented approach can realize higher diagnostic accuracies, robustness, and superior generalization capability compared to the existing mainstream DA approaches.},
  archive      = {J_EAAI},
  author       = {Li Jiang and Wei Lei and Shuaiyu Wang and Shunsheng Guo and Yibing Li},
  doi          = {10.1016/j.engappai.2023.107179},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107179},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep convolution multi-adversarial adaptation network with correlation alignment for fault diagnosis of rotating machinery under different working conditions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of natural language processing in residential
building defects analysis: Australian stakeholders’ perceptions, causes
and types. <em>EAAI</em>, <em>126</em>, 107178. (<a
href="https://doi.org/10.1016/j.engappai.2023.107178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of defects in residential buildings has been reported to impact the performance of the architecture, engineering, and construction (AEC) industry. Defects can increase the construction cost, significantly contribute to the increment of construction waste and cause stress to home occupants. To minimise these effects the first step is to understand the main causes of building defects (Building defects). To date, the research specific to building defects in the Australian context is scant. Limited research considered the perceptions of all the possible stakeholders that are responsible for the generation and management of defects. Hence, this study aims to explore the causes of building defects by considering the perceptions of various stakeholders using the machine learning method. The research employed a mixed approach that involve qualitative content analysis and natural language processing (NLP) of court cases obtained from the Victorian Civil and Administrative Tribunal, the legal entity that deals with building-related disputes. NLP resulted in extracting defect sentences based on defect keywords using the KeyBERT algorithm and pre-trained deep learning embedding models including BERT-Base, RoBERTa-Base, and fastText. The content analysis showed that the top three reasons for building defects are related to workmanship, design, and materials. The three main stakeholder groups involved in building defect management were builders, owners and sub-contractors. Drawing on these findings, a proactive defect prevention framework was developed to guide building defect risk management.},
  archive      = {J_EAAI},
  author       = {Salman Shooshtarian and Argaw Tarekegn Gurmu and Abdul-Manan Sadick},
  doi          = {10.1016/j.engappai.2023.107178},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107178},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of natural language processing in residential building defects analysis: Australian stakeholders&#39; perceptions, causes and types},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting concrete strength through packing density using
machine learning models. <em>EAAI</em>, <em>126</em>, 107177. (<a
href="https://doi.org/10.1016/j.engappai.2023.107177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an innovative approach to predict concrete compressive strength using particle packing theories through machine learning techniques. The existing challenge in concrete engineering lies in the accurate estimation of concrete strength, a critical factor in construction. The adoption of particle packing theories, which hold great promise for enhancing concrete performance, has been limited due to the complexity and time-consuming nature of the required calculations. An approach encompassing particle packing models (JD Dewar Model, Compressible Packing Model, and Modified Toufar Model) with machine learning is the novelty of the work. These models optimize the packing density of aggregate proportions while minimizing the void ratio, essential for achieving desired compressive strength criteria. To train the model, a comprehensive dataset comprising 479 concrete mixtures, each associated with known compressive strength values relative to packing density, is utilized. A significant advancement in predicting concrete compressive strength is demonstrated by the results. The approach outperforms traditional empirical models, offering precise and reliable predictions based on packing density. Importantly, this innovation eliminates the need for time-consuming and costly trial-and-error procedures in concrete mix design. The strong performance of various models in predicting concrete strength using particle packing theories is underscored by the study, with R^2 values ranging from 0.664 to 0.999. By combining concepts of particle packing theories and machine learning, a more efficient and reliable method for predicting concrete compressive strength is achieved. This innovation has the potential to revolutionize concrete mix design, leading to more durable and cost-effective construction practices.},
  archive      = {J_EAAI},
  author       = {Swamy Naga Ratna Giri Pallapothu and Rathish Kumar Pancharathi and Rakesh Janib},
  doi          = {10.1016/j.engappai.2023.107177},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107177},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting concrete strength through packing density using machine learning models},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sports video retrieval and classification using focus u-net
based squeeze excitation and residual mapping deep learning model.
<em>EAAI</em>, <em>126</em>, 107176. (<a
href="https://doi.org/10.1016/j.engappai.2023.107176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports videos are widely used by athletes and coaches for training and match analysis purposes outside the mainstream audience. Sports videos should be effectively classified into different genres to easily retrieve and index them from large video datasets. Manual labelling classification methods may cause errors and have low accuracy. Classification based on video content analysis is challenging for computer vision-based techniques. This work introduces an improved focus-net deep learning (DL) model called the Convolutional squeeze U-Net based encoder-decoder for sports video retrieval and classification. First, the keyframes are extracted from the input sports video using a clustering and optical flow analysis method. In the next stage, the frames are pre-processed using a smoothed shock filtering technique to remove the noise. The process of image segmentation is carried out using a Convolutional squeeze U-Net based encoder-decoder model. Finally, the sports video can be classified using the softmax classifier. A CNN (convolutional neural network) is utilized at the encoder section for extracting the features and fed to the decoder for video classification. The experiments are performed in the UCF101 dataset, and the proposed model achieved an overall accuracy of 99.68%. Hence, it is proven that the proposed focus-net model can be efficiently utilized in sports video classification.},
  archive      = {J_EAAI},
  author       = {G. Srilakshmi and I.R. Praveen Joe},
  doi          = {10.1016/j.engappai.2023.107176},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107176},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sports video retrieval and classification using focus u-net based squeeze excitation and residual mapping deep learning model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial neural networks for inverse kinematics problem in
articulated robots. <em>EAAI</em>, <em>126</em>, 107175. (<a
href="https://doi.org/10.1016/j.engappai.2023.107175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse kinematics problem in articulated robots implies to obtain joint rotation angles using the robot end effector position and orientation tool. Unlike the problem of direct kinematics, in inverse kinematics there are no systematic methods for solving the problem. Moreover, solving the inverse kinematics problem is particularly complicated for certain morphologies of articulated robots. Machine learning techniques and, more specifically, artificial neural networks (ANNs) have been proposed in the scientific literature to solve this problem. However, there are some limitations in the performance of ANNs. In this study, different techniques that involve ANNs are proposed and analyzed. The results show that the proposed original bootstrap sampling and hybrid methods can substantially improve the performance of approaches that use only one ANN. Although all of these improvements do not solve completely the inverse kinematics problem in articulated robots, they do lay the foundations for the design and development of future more effective and efficient controllers. Therefore, the source code and documentation of this research are also publicly available to practitioners interested in adapting and improving these methods to any industrial robot or articulated robot.},
  archive      = {J_EAAI},
  author       = {Daniel Cagigas-Muñiz},
  doi          = {10.1016/j.engappai.2023.107175},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107175},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural networks for inverse kinematics problem in articulated robots},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian process regression for forward and inverse
kinematics of a soft robotic arm. <em>EAAI</em>, <em>126</em>, 107174.
(<a href="https://doi.org/10.1016/j.engappai.2023.107174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of soft robotics to perform tasks and interact with the environment requires good system identification. Data-driven methods offer a promising alternative where traditional analytical model-based techniques have proven insufficient. However, their use has been limited and under-explored in soft robotics. The novelty of this research lies in the application of Gaussian processes to soft robotics and the exploration of approximate Gaussian processes (AGP) and deep Gaussian processes (DGP) methods. It highlights the advantages of Gaussian processes in modeling uncertainty, incorporating prior knowledge, and handling complex systems. This is achieved through the identification of the forward and inverse kinematics of a two-degree-of-freedom soft robotic arm actuated by three tendons. A comparison is made between different configurations using Gaussian processes and the results are also compared with those obtained from the analytical model of the kinematics and an artificial neural network (ANN). The research contributes to the development of more efficient and accurate techniques for system identification, kinematics modeling, and control in soft robotics.},
  archive      = {J_EAAI},
  author       = {Carlos Relaño and Javier Muñoz and Concepción A. Monje},
  doi          = {10.1016/j.engappai.2023.107174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gaussian process regression for forward and inverse kinematics of a soft robotic arm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid approach for artwork recommendation. <em>EAAI</em>,
<em>126</em>, 107173. (<a
href="https://doi.org/10.1016/j.engappai.2023.107173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Museums usually exhibit thousands of artworks, and nowadays, they often have their collections online for visitors. In these collections, the curators are responsible for organizing the artworks seeking a delicate balance between emotion and reason. Given an initial artwork, however, a visitor is likely to select and admire a set of related artworks that match her interests. This setting can be seen as a recommendation problem in the art domain. Although image recommendation systems have been previously developed, considering the artwork nature is a fundamental aspect when designing a recommender system in this domain. Thus, we propose a hybrid recommendation approach that combines deep autoencoders with a social influence graph in order to capture the visual aspects and context of artworks (represented by images). These mechanisms inform the generation of rankings of related artworks. In this context, we report on a case-study with a group of art experts who assessed the rankings of artworks recommended by our approach. Although preliminary, the results showed a better precision than traditional strategies based solely on image features or metadata. Furthermore, the recommendations exhibited diversity properties, avoiding typical over-specialization problems of content-based techniques.},
  archive      = {J_EAAI},
  author       = {Ignacio Gatti and J. Andres Diaz-Pace and Silvia Schiaffino},
  doi          = {10.1016/j.engappai.2023.107173},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107173},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid approach for artwork recommendation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Searching natural neighbors in an accelerated way.
<em>EAAI</em>, <em>126</em>, 107172. (<a
href="https://doi.org/10.1016/j.engappai.2023.107172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural neighbor (NaN) is an adaptive neighbor concept for automatically determining k value for k -nearest neighbors, which has been proved effective in clustering analysis, classification, and outlier detection. However, the existing algorithms for searching NaN employ the global search strategy, which increases unnecessary consumption of time on non-critical points. To solve this problem, we propose a novel accelerated algorithm by utilizing a local search strategy, called ASNN. ASNN is based on the fact that if remote points have reverse nearest neighbors, others are likely to have reverse nearest neighbors. Firstly, it extracts the remote points by defining remote radius. Secondly, only the neighbors of remote points are searched, so that ASNN can quickly obtain the natural neighbor eigenvalue (NaNE). Compared to existing algorithms for searching NaNs, ASNN drastically reduces the number of query points and time consumption. The efficiency and effectiveness of ASNN are proved on synthetic and real datasets.},
  archive      = {J_EAAI},
  author       = {Dongdong Cheng and Jiangmei Luo and Jinlong Huang and Sulan Zhang},
  doi          = {10.1016/j.engappai.2023.107172},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107172},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Searching natural neighbors in an accelerated way},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual hesitant fuzzy correlation coefficient-based
decision-making algorithm and its applications to engineering cost
management problems. <em>EAAI</em>, <em>126</em>, 107170. (<a
href="https://doi.org/10.1016/j.engappai.2023.107170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering management plays a significant part in project construction, and it is a process involved with making decision under uncertainty. When decision makers are hesitant to assess investment projects, fuzzy set theory offers an effective tool for dealing with uncertainty. In this paper, a decision-making method is put forward for handling engineering management problems, where dual hesitant fuzzy set is adopted to model the uncertainty. Firstly, we raise an improved dual hesitant fuzzy correlation coefficient and its weighted form. Compared with the current dual hesitant fuzzy correlation coefficients, the presented one has more desirable properties. It not only can manifest the positive or negative correlation between dual hesitant fuzzy sets, but also can guarantee the dual hesitant fuzzy correlation coefficient is 1 (−1) if and only if the two dual hesitant fuzzy sets are identical (complementary). Secondly, a mathematical programming model, which integrates within-attribute and between-attribute variation information, is designed to derive the attribute weights. More importantly, it can fully utilize the decision information. Finally, the weighted correlation coefficients are calculated, and an illustrative example concerning engineering management is offered to demonstrate the rationality of the proposed technique.},
  archive      = {J_EAAI},
  author       = {Harish Garg and Yukun Sun and Xiaodi Liu},
  doi          = {10.1016/j.engappai.2023.107170},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107170},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual hesitant fuzzy correlation coefficient-based decision-making algorithm and its applications to engineering cost management problems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SeNet-i: An approach for detecting network intrusions
through serialized network traffic images. <em>EAAI</em>, <em>126</em>,
107169. (<a
href="https://doi.org/10.1016/j.engappai.2023.107169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of the internet and inter-connectivity has resulted in an extensive increase in network size and the corresponding data, which has led to numerous novel attacks that pose significant challenges to network security. However, conventional network security approaches predominantly rely on the metadata of network traffic, utilized in numeric form, which is becoming ineffective against new attacks that hide within the content of the traffic. Therefore, it raises the need for security systems to adapt to the changing dynamics of network attacks. To address this issue, we propose a new approach called SeNet-I that leverages computer vision capabilities to combine low-level features and develop a more abstract and high-level representation of network traffic without requiring feature engineering. The proposed approach utilizes the raw network traffic information and transforms it into serialized three-channel images, which are employed as input to a proposed deep concatenated convolutional neural network model. Additionally, SeNet-I can easily incorporate packet level information, which is often challenging for conventional approaches due to its high dimensionality. To demonstrate the effectiveness of the proposed approach, we tested SeNet-I on both packet-based and flow-based network traffic, comparing it with current state-of-the-art methods and different image-based approaches. With F1 scores of 96% and 83% achieved in the multi-class classification of flow-based and packet-based network intrusion detection, our proposed approach outperformed other existing methods in the literature. Lastly, we discussed the advantages and limitations of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yasir Ali Farrukh and Syed Wali and Irfan Khan and Nathaniel D. Bastian},
  doi          = {10.1016/j.engappai.2023.107169},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107169},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SeNet-I: An approach for detecting network intrusions through serialized network traffic images},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection using a sinusoidal sequence combined with
mutual information. <em>EAAI</em>, <em>126</em>, 107168. (<a
href="https://doi.org/10.1016/j.engappai.2023.107168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data classification is the most common task in machine learning, and feature selection is the key step in the classification task. Common feature selection methods mainly analyze the maximum correlation and minimum redundancy between feature factors and tags while ignoring the impact of the number of key features, which will inevitably lead to waste in subsequent classification training. To solve this problem, a feature selection algorithm (SSMI) based on the combination of sinusoidal sequences and mutual information is proposed. First, the mutual information between each feature and tag is calculated, and the interference information in high-dimensional data is removed according to the mutual information value. Second, a sine function is constructed, and sine ordering is carried out according to the mutual information value and feature mean value between different categories of the same feature. By adjusting the period and phase value of the sequence, the feature set with the largest difference is found, and the subset of key features is obtained. Finally, three machine learning classifiers (KNN, RF, SVM) are used to classify key feature subsets, and several feature selection algorithms (JMI, mRMR, CMIM, SFS, etc.) are compared to verify the advantages and disadvantages of different algorithms. Compared with other feature selection methods, the SSMI algorithm obtains the least number of key features, with an average reduction of 15 features. The average classification accuracy has been improved by 3% on the KNN classifier. On the HBV and SDHR datasets, the SSMI algorithm achieved classification accuracy of 81.26% and 83.12%, with sensitivity and specificity results of 76.28%, 87.39% and 68.14%, 86.11%, respectively. This shows that the SSMI algorithm can achieve higher classification accuracy with a smaller feature subset.},
  archive      = {J_EAAI},
  author       = {Gaoteng Yuan and Lu Lu and Xiaofeng Zhou},
  doi          = {10.1016/j.engappai.2023.107168},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107168},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature selection using a sinusoidal sequence combined with mutual information},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy correlational analysis for dynamic consolidation of
virtual machines in cloud computing environment. <em>EAAI</em>,
<em>126</em>, 107167. (<a
href="https://doi.org/10.1016/j.engappai.2023.107167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This theoretical research in fuzzy correlation analysis integrates data uncertainty analysis by measuring the strength of the linear relationship restricted to two fuzzy sets. As the relevant contribution to this research area, this paper presents the axiomatic definition of the n-dimensional generalized fuzzy correlation coefficient ( nGCC ), assigning to n input fuzzy sets an output value in the interval [−1,1]. Thus, the properties of general overlap functions and fuzzy negations are studied, discussing binary non-normed restricted dissimilarity functions, and the n-dimensional non-normed conjunctive functions. This study provides new methods for the n-dimensional generalized fuzzy correlation coefficient analysis, regarding their applications in solving multi-criteria and decision-making problems founded on fuzzy logic extensions. The n-dimensional non-normed conjunctive aggregation functions are also introduced, as range domain extensions from [0,1] to [−1.1], covering the interpretation of negative to positive variable associations. The proposal correlation analysis promotes a better evaluation and data selection even when more than one algorithm is applied to evaluate the reduction methods in the defuzzification process based on Interval-valued Fuzzy Logic. We also investigate the relevance to determine a reliable result from the fuzzy inference system based on the nGCC methodology. This correlation methodology applied to the Interval Fuzzy Load Balancing for Cloud Computing (Int-FLBCC) model contributes as a flexible approach for virtual machines dynamic consolidation enabling improvements in resource usage and power efficiency, improving the computational system’s energy efficiency. So, the nGCC methodology extends the Int-FLBCC model by adding other degrees of reliability to the results obtained with diverse evaluations through n-dimensional generalized fuzzy correlation coefficient expressions, exploring average aggregations as arithmetic and exponential means and the median operator.},
  archive      = {J_EAAI},
  author       = {Alex Bertei and Luciana Foss and Benjamín Bedregal and Renata Reiser},
  doi          = {10.1016/j.engappai.2023.107167},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107167},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy correlational analysis for dynamic consolidation of virtual machines in cloud computing environment},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Feature selections based on three improved condition
entropies and one new similarity degree in interval-valued decision
systems. <em>EAAI</em>, <em>126</em>, 107165. (<a
href="https://doi.org/10.1016/j.engappai.2023.107165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selections facilitate classification learning in various data environments. Aiming at interval-valued decision systems (IVDSs), feature selections rely on information measures and similarity degrees, whereas current selection algorithms on credibility-based condition entropy and classical similarity degree are accompanied with some measurement limitations and advancement space. In this paper based on IVDSs, three coverage-credibility-based condition entropies and one geometry-probabilistic similarity degree are proposed across two dimensions of informationization and granulation, and they improve the existing condition entropy and similarity degree; accordingly, 4 × 2 feature selections emerge for optimization and applicability, and they systematically contain one initial selection algorithm and seven new/robuster algorithms. At first, three-way granular measures (i.e., credibility, coverage, and integrated coverage-credibility) are formulated in IVDSs, and three novel condition entropies are established by implementing three information structures on coverage-credibility. These condition entropies acquire in-depth improvements, hierarchical algorithms, size relationships, maximum/minimum conditions, and granulation non-monotonicity. Then, the probabilistic similarity degree is defined by a six-piecewise function with quadratic factors, and this new measure gains the geometry-probability mechanism and high-quality improvement. Furthermore, feature selections are determined by preserving condition entropies and by mining feature significances, so eight selection algorithms are obtained by combining condition entropies and similarity degrees. Finally, data experiments are performed to validate relevant uncertainty measures and feature selections, and seven constructional selection algorithms outperform three contrastive algorithms to achieve better classification performances.},
  archive      = {J_EAAI},
  author       = {Benwei Chen and Xianyong Zhang and Jilin Yang},
  doi          = {10.1016/j.engappai.2023.107165},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107165},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature selections based on three improved condition entropies and one new similarity degree in interval-valued decision systems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image-based preliminary emergency assessment of damaged
buildings after earthquake: Taiwan case studies. <em>EAAI</em>,
<em>126</em>, 107164. (<a
href="https://doi.org/10.1016/j.engappai.2023.107164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural collapses that occur during earthquake disasters and subsequent aftershock periods often result in high numbers of fatalities. Rapid preliminary building evaluations are necessary to determine whether buildings are safe for continued occupation. Currently, structural damage is evaluated manually in on-site, expert inspections that are time-intensive, uncertain, inconsistent, and heavily reliant on the experience of the expert team. Therefore, TL-EfficientNet, which combines EfficientNet and Transfer Learning, was used in this research to create an image recognition system for use in an Emergency Assessment Damaged Building Model (EADBM). The integration of hybrid models and building safety assessments presents a pioneering approach to replace manual damage assessments. This system classifies images of structural members into four damage levels based on Taiwan&#39;s emergency assessment code, then calculates a structural damage index (SDI) based on the assessed level of damage to columns and structural walls. The accuracy and overall F1 score obtained by the proposed model were both high, with the accuracy of validation results reaching 97% and 91% for columns and structural walls, respectively. Furthermore, the model was applied to two actual damaged building case studies, with the highest accuracy and overall F1 score for columns reaching 90% and 95%, respectively. The SDI value indicates that the first case study was correctly classified as dangerous, while the second case study was categorized as restricted. This model has been proven to overcome subjective and inconsistent results associated with manual assessment, achieving rapid and accurate preliminary assessment in post-earthquake building inspections and safety evaluations.},
  archive      = {J_EAAI},
  author       = {Min-Yuan Cheng and Riqi Radian Khasani and Richard Jordan Citra},
  doi          = {10.1016/j.engappai.2023.107164},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107164},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image-based preliminary emergency assessment of damaged buildings after earthquake: Taiwan case studies},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on the mechanism and countermeasures of
low-frequency swaying of high-speed trains caused by aerodynamic loads.
<em>EAAI</em>, <em>126</em>, 107162. (<a
href="https://doi.org/10.1016/j.engappai.2023.107162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The carbody abnormal vibration has significant impacts on the comfort and safety of high-speed train. Field measurements were conducted to study the low-frequency swaying of the carbody on a high-speed train operating on a railway line. According to the test results, the tail vehicle of the train swayed laterally in various places along the line. The lateral stability index of vehicle clearly exceeded the limit value when the carbody swayed. The predominant frequency of the lateral acceleration of the carbody was between 1.4 and 1.5 Hz. Through the simulation of computational fluid dynamics, it is confirmed that the yaw moment and lift force of the tail vehicle are greater than those of the middle and the head vehicles. Furthermore, the dynamics simulation show that aerodynamics disturbances may be the intensified cause of the abnormal swaying of the tail vehicle. Therefore, the study proposes the installation of inter-vehicle dampers. and optimizes the damping values of dampers based on GA-BP optimization algorithm, so as to weaken the abnormal swaying motion. The relevant simulation results offer a solution to address the abnormal swaying phenomenon in practical situations.},
  archive      = {J_EAAI},
  author       = {Chao Chang and Xin Ding and Zhuang Sun and Yizheng Yu and Lei Zhang},
  doi          = {10.1016/j.engappai.2023.107162},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107162},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A survey on the mechanism and countermeasures of low-frequency swaying of high-speed trains caused by aerodynamic loads},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weight prediction and recognition of latent subject terms
based on the fusion of explicit &amp; implicit information about
keyword. <em>EAAI</em>, <em>126</em>, 107161. (<a
href="https://doi.org/10.1016/j.engappai.2023.107161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight prediction and recognition of subject term in documents is widely used in application fields such as literature recommendation and keyword retrieval. Unlike traditional methods which only focus on searching for subject terms from existing keywords in documents, this paper proposes a recognition method of latent subject term outside documents based on a one-class collaborative filtering algorithm that fuses explicit and implicit information. A matrix factorization model based on the analysis of document activity and subject term popularity is constructed to measure the correlation probability between documents and subject terms that do not appear in the current document. After these subject terms being divided into Latent Subject Terms (LST) and Irrelevant Subject Terms (IST), two methods for predicting the weight of these types of subject terms is introduced, which include Hybrid Filling with Preference Coefficients (HFPC), and Zero Filling. In order to verify the effectiveness of subject term recognition, many collaborative filtering recommendation algorithms are conducted with the filled document keyword matrix. On the basis of not changing these algorithms, MAE and FCP can be improved by 28.01% and 22.79% at most, while P@N and NDCG@N can be improved by 22.37% and 27.06%, respectively.},
  archive      = {J_EAAI},
  author       = {Shuqing Li and Mingfeng Jiang and Weiwei Jiang and Jingwang Huang and Hu Zhang and Zhiwang Zhang},
  doi          = {10.1016/j.engappai.2023.107161},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107161},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weight prediction and recognition of latent subject terms based on the fusion of explicit &amp; implicit information about keyword},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven based method for damage detection of combining
joints and elements of frame structures using noisy incomplete data.
<em>EAAI</em>, <em>126</em>, 107160. (<a
href="https://doi.org/10.1016/j.engappai.2023.107160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most previous studies on damage detection in civil engineering structures have focused on either element damage detection or joint damage detection, separately. However, in practice, both elements and joints may be prone to damage, simultaneously. In addition, the development of effective numerical approaches to detect and quantify these damages in real time within structures is essential to ensure their integrity and reliable operation. Therefore, to deal with these problems, this study proposes an effective data-driven approach by using an attention based convolutional gated recurrent unit network (ACGRU) for real time damage detection of combining joint and element in frame structures using incomplete data. In the proposed approach, the convolutional layers in the network are utilized to extract critical features from the raw input data. Then, these extracted features are fed into the gated recurrent unit layers to learn to predict the desired output data. In addition, by introducing the attention mechanisms into the network, the important information can be effectively learned. The performance and applicability of the ACGRU are validated through two different numerical examples using incomplete data in both noise-free condition and noisy condition. Moreover, the effect of the numbers and placements of sensors on the damage detection results is also investigated. The damage detection results achieved by the proposed approach are compared with those of other state-of-the-art methods to inspect the reliability of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Tam T. Truong and Jaehong Lee and T. Nguyen-Thoi},
  doi          = {10.1016/j.engappai.2023.107160},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107160},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven based method for damage detection of combining joints and elements of frame structures using noisy incomplete data},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Thermal analysis of PCM magnesium chloride hexahydrate using
various machine learning and deep learning models. <em>EAAI</em>,
<em>126</em>, 107159. (<a
href="https://doi.org/10.1016/j.engappai.2023.107159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heat storage through Phase change material (PCM) is important for sustainable development. Previously a set of experiments were carried out on 14.5 kg of PCM, Magnesium chloride hexa hydrate in a shell and tube heat exchanger. The results are used to build machine learning and deep learning models such as Support vector machine, Random forest, Extreme gradient boost, Catboost and Artificial neural network to replicate the experiment virtually. The input variables are heat transfer fluid’s inlet and outlet temperature and time elapsed while PCM’s temperature is predicted in both charging and discharging cycles. The hyperparameter tuning is done using hyperband. Catboost model outperformed all other models with highest variance in both the cycles (0.9945 and 0.9299) and highest score: 0.993 and 0.9466. It has got the lowest MAPE (0.2% and 0.1 %). Hence this model can be recommended over these other models for doing system simulation of problems involving both charging and discharging cycles of the PCM.},
  archive      = {J_EAAI},
  author       = {Vignes Karthic Venkatraman Balakrishnan and Kannan Kumaresan},
  doi          = {10.1016/j.engappai.2023.107159},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107159},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal analysis of PCM magnesium chloride hexahydrate using various machine learning and deep learning models},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vibration optimization of cantilevered bistable composite
shells based on machine learning. <em>EAAI</em>, <em>126</em>, 107158.
(<a href="https://doi.org/10.1016/j.engappai.2023.107158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bistable composite shells with high storage efficiency have great potential applications in deployable space structures. This paper proposes a constrained vibration optimization approach for improving the bending-mode frequency of cantilevered bistable reeled composite shells (BRCS) with respect to fiber orientation angles using a machine learning (ML) method. First, the bistability and a specific coiled diameter are considered as constraints to classify the input data. The data set of the support vector regression (SVR) model is constructed based on the finite element (FE) simulation results, followed by constricted particle swarm optimization (PSO) to improve the bending-mode vibration frequency of a cantilevered BRCS. A 15.5% improvement of the vibration frequency with respect to the benchmark is achieved at α = 59 . 3 ° and β = 32 . 2 ° , which maintains great consistency with published results. Additionally, the optimization approach based on ML is further utilized to improve the vibration frequency of BRCS subjected to constraints of constant arc length and coiled diameter. The vibration frequency is improved by 85.3% with respect to the benchmark shell with optimized parameters of R = 16 mm, γ = 358 ° , and the stacking laminate sequence of [ 60 / 80 / 0 / − 80 / − 60 ] . Evaluation and validation analyses of the ML model demonstrate that vibration optimization using ML yields high computing efficiency and accuracy. This optimization approach has great potential in real-life engineering applications.},
  archive      = {J_EAAI},
  author       = {Chenchen Wu and Ruming Zhang and Fengzhen Tang and Mengling Fan},
  doi          = {10.1016/j.engappai.2023.107158},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107158},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vibration optimization of cantilevered bistable composite shells based on machine learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structural reliability analysis based on neural networks
with physics-informed training samples. <em>EAAI</em>, <em>126</em>,
107157. (<a
href="https://doi.org/10.1016/j.engappai.2023.107157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to develop high-fidelity and high-efficiency machine learning (ML) models in reliability engineering, a novel ML approach based on Neural Networks (NN) with Physics-Informed Training Samples (PITS) is established, which is abbreviated as NN-PITS. The proposed NN-PITS framework uses data augmentation techniques to improve the training samples based on the properties of the failure surface, so that the physical information is embedded into the NN. Two approaches for embedding physical information are introduced. When the limit state equation (LSE) can be solved analytically, the training samples are extended to the failure surface based on the LSE, and then the physics-informed loss function is constructed. When the LSE is implicit or unsolvable analytically, a novel sampling method based on pseudo-probability distribution to generate the samples of required distribution is proposed, so as to obtain the PITS that are near the failure surface. Compared with the common data-driven NN model, the proposed NN-PITS framework can effectively utilize the physical information in reliability problem, so as to reduce the dependence on label samples. The proposed NN-PITS can be combined with finite element analysis (FEA) and applied to reliability engineering problems. Three engineering examples, including two static problems and one time-varying problem, are given to illustrate the good applicability and capability of the proposed methods for structural reliability analysis.},
  archive      = {J_EAAI},
  author       = {Zhiwei Bai and Shufang Song},
  doi          = {10.1016/j.engappai.2023.107157},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107157},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Structural reliability analysis based on neural networks with physics-informed training samples},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel framework based on ensemble classification and secure
feature extraction for COVID-19 critical health prediction.
<em>EAAI</em>, <em>126</em>, 107156. (<a
href="https://doi.org/10.1016/j.engappai.2023.107156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Covid outbreak necessitated the use of an automated method for treating patients with critical symptoms. Increasing use of the Internet of Things (IoT) and smart devices requires access to real-time data over robust and secure network infrastructures. During the lifetime of healthcare applications, the data must be transferred in a controlled manner. In this context, this study proposes, an IoT-based decision support system for the analysis of Covid-related data in healthcare systems. Through in-vehicle monitoring, it is intended to safely send important data and patient updates to attending physicians. The suggested approach uses feature extraction methods to identify patients&#39; crucial states while protecting their private information. To improve feature extraction, two techniques are combined: ensemble classification and cipher substitution for secure Json Web Tokens (JWTs). By incorporating the Secure Hashing Algorithm-2 (SHA-2) methods into the Feature Extraction based Logistic Regression (FELR), security protections are substantially reinforced. The system uses the Message Queuing Telemetry Transport (MQTT) protocol to provide secure communication between devices and access to the extracted characteristics from rescue vehicles. The system analyzes passengers, traffic data, and medical issues, which are continually updated with cloud-based security, by using vehicle-based communication networks. The secure movement of patient data inside the hospital network is ensured by this cloud-based system. By using sophisticated regression analysis and ensemble learning approaches, our suggested methodology has shown significant advantages compared to traditional models such as Logistic Regression (LR) and Mixed Regression (MR). Our technique demonstrates exceptional performance with an accuracy rate of 96%, a recall rate of 91%, and an F-measure of 91%. We also precisely compared the performance of our proposed FELR algorithm with hybrid prediction model using deep learning, the extra tree convolutional neural network-based ensemble model, ensemble-based random forest, ensemble transformation learning, and machine learning with regression. Significantly, FELR algorithm has demonstrated exceptional superiority by consistently surpassing the predictive capabilities of all these algorithms. The system has exceptional performance and exhibits improved efficiency and secure transmission capabilities. The unique model that we propose offers a feasible and effective approach for detecting crucial states in patients within healthcare facilities. The success of our framework is shown via a well-planned approach that includes important processes such as data preprocessing, feature extraction, ensemble model construction, and evaluation. The proposed framework offers a promising avenue for aiding healthcare professionals in making informed decisions regarding the critical health trajectories of COVID-19 patients.},
  archive      = {J_EAAI},
  author       = {R. Priyadarshini and Abdul Quadir Md and Senthilkumar Mohan and Abdullah Alghamdi and Mesfer Alrizq and Ummul Hanan Mohamad and Ali Ahmadian},
  doi          = {10.1016/j.engappai.2023.107156},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107156},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel framework based on ensemble classification and secure feature extraction for COVID-19 critical health prediction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification of maintenance significant items for machine
tools by integrating DEMATEL and MABAC with spherical fuzzy sets.
<em>EAAI</em>, <em>126</em>, 107155. (<a
href="https://doi.org/10.1016/j.engappai.2023.107155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of maintenance significant items (MSIs), which is a multi-criteria decision-making (MCDM) process, is the primary phase of reliability centered maintenance. The identification process is typically vague and uncertain as a result of the structural complexity and functional diversity of machine tools. Therefore, there are limited effective methods for identifying MSIs in machine tools. In this study, we propose a novel MSI identification method that integrates two MCDM methods, namely the decision-making trial and evaluation laboratory (DEMATEL) and multi-attributive border approximation area comparison (MABAC). A novel extension of the fuzzy theory called the spherical fuzzy (SF) set concept is combined with the integrated DEMATEL-MABAC method. SF-DEMATEL is used to evaluate the criteria weights of machine tools. Then, based on the judgement information regarding alternatives under each criterion, SF-MABAC is used to identify and rank MSIs. The proposed integration method was applied to a CNC lathe with six criteria and 11 alternatives. Robustness analysis was conducted to verify the stability and effectiveness of the proposed method. The results demonstrate that the integration of DEMATEL and MABAC under the SF concept is a reasonable and applicable method for MSI identification. The results support engineers into reasonably identifying the significant maintenance items for machine tools.},
  archive      = {J_EAAI},
  author       = {Xiao Zhu and Yan Ran and Genbao Zhang and Jingjie Chen and Liu Heli},
  doi          = {10.1016/j.engappai.2023.107155},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107155},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of maintenance significant items for machine tools by integrating DEMATEL and MABAC with spherical fuzzy sets},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised contrastive learning for wafer map pattern
classification. <em>EAAI</em>, <em>126</em>, 107154. (<a
href="https://doi.org/10.1016/j.engappai.2023.107154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the semiconductor manufacturing process, analyzing the defect patterns on a wafer map is crucial for identifying the causes of the defects. The advent of convolutional neural networks (CNNs) has significantly increased the accuracy of automated wafer map pattern classification. Generally, the use of a larger training dataset results in higher classification accuracy. However, collecting a large number of wafer maps and labeling them with their defect categories is expensive and time-consuming. In this paper, we present an improved training method under data insufficiency for wafer map pattern classification. We apply supervised contrastive learning to train a CNN by exploiting the rotational-invariant characteristic of wafer map labeling. The CNN is trained by simultaneously minimizing two loss functions: classification loss and contrastive loss. The first loss function is to classify the rotational variants of wafer maps accurately. The second loss function is to align the representation vectors for the rotational variants of wafer maps with similar labels to be close to each other. Using two benchmark datasets, WM-811K and MixedWM38, we demonstrate that the proposed method enhances classification accuracy compared with existing methods, particularly when the training dataset is small.},
  archive      = {J_EAAI},
  author       = {Youngjae Bae and Seokho Kang},
  doi          = {10.1016/j.engappai.2023.107154},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107154},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Supervised contrastive learning for wafer map pattern classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Algorithms for decision-making process using complex
pythagorean fuzzy set and its application to hospital siting for
COVID-19 patients. <em>EAAI</em>, <em>126</em>, 107153. (<a
href="https://doi.org/10.1016/j.engappai.2023.107153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the start of COVID-19, a fair amount of work has been undertaken by scholars around the world to model its progression. It became clear from the start of pandemic that its progression is affected by various factors within different communities. Subsequently, the necessary means and the range of measures used to effectively control the virus would vary from place to place. And we have been witness to different approaches adopted around the world to maintain the virus under check both in the short term and the long term. So, in this unexpected situation, it is a great challenge for the world health organization (WHO) to save the lives of COVID-19 patients. For this, several mathematical models have been made for better understanding the coronavirus contagion. Mostly, these models are based on classical integer-order derivative using real numbers which cannot capture the fading memory. Thus, in this unexpected situation, fuzzy sets (FSs) are considered due to their inherent capability to deal with uncertainty. Fuzzy sets (FSs) theory has the ability to manage uncertain situations. Thus, the goal of this research is to present newly mathematical methods based on complex Pythagorean fuzzy sets (CPyFSs) and their operators, namely complex Pythagorean fuzzy Einstein weighted geometric operator, and induced complex Pythagorean fuzzy Einstein hybrid geometric operator to reduce the spreading rate of COVID-19. At the end of the paper an illustrative example is constructed to show the effectiveness, reliability of the new techniques.},
  archive      = {J_EAAI},
  author       = {Khaista Rahman and Harish Garg and Rifaqat Ali and Suleman H. Alfalqi and Tarik Lamoudan},
  doi          = {10.1016/j.engappai.2023.107153},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107153},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Algorithms for decision-making process using complex pythagorean fuzzy set and its application to hospital siting for COVID-19 patients},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applying human-in-the-loop to construct a dataset for
determining content reliability to combat fake news. <em>EAAI</em>,
<em>126</em>, 107152. (<a
href="https://doi.org/10.1016/j.engappai.2023.107152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Annotated corpora are indispensable tools to train computational models in Natural Language Processing. However, in the case of more complex semantic annotation processes, it is a costly, arduous, and time-consuming task, resulting in a shortage of resources to train Machine Learning and Deep Learning algorithms. In consideration, this work proposes a methodology, based on the human-in-the-loop paradigm, for semi-automatic annotation of complex tasks. This methodology is applied in the construction of a reliability dataset of Spanish news so as to combat disinformation and fake news. We obtain a high quality resource by implementing the proposed methodology for semi-automatic annotation, increasing annotator efficacy and speed, with fewer examples. The methodology consists of three incremental phases and results in the construction of the RUN dataset. The annotation quality of the resource was evaluated through time-reduction (annotation time reduction of almost 64% with respect to the fully manual annotation), annotation quality (measuring consistency of annotation and inter-annotator agreement), and performance by training a model with RUN semi-automatic dataset (Accuracy 95% F1 95%), validating the suitability of the proposal.},
  archive      = {J_EAAI},
  author       = {Alba Bonet-Jover and Robiert Sepúlveda-Torres and Estela Saquete and Patricio Martínez-Barco and Alejandro Piad-Morffis and Suilan Estevez-Velarde},
  doi          = {10.1016/j.engappai.2023.107152},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107152},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Applying human-in-the-loop to construct a dataset for determining content reliability to combat fake news},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FeatsFlow: Traceable representation learning based on
normalizing flows. <em>EAAI</em>, <em>126</em>, 107151. (<a
href="https://doi.org/10.1016/j.engappai.2023.107151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies effective traceable feature representation learning in the view of distribution transformation, termed FeatsFlow , by proposing a distribution-aware learning framework combining the discriminating model with a normalizing flow-based model. The process can be regarded as a series of feature distribution transformations, from the input images to the expected results. Focusing on the learned representation of the target model, we take full advantage of the invertible nature of normalizing flows and learn the practical and traceable feature representation for target goals. Considering that it is difficult to model the traceable process for feature extraction, we propose an effective model by combining a general discriminating model with normalizing flows for traceable feature extraction. The normalizing flows module is added to the original model in a plug-in mode, which is convenient to make it available for effective and traceable feature learning. Thus we can obtain an effective and traceable representation distribution. Extensive experiments are conducted on our proposed representation learning model for the image classification task, and the experimental results illustrate that our proposed model is adequate for traceable representation learning. The most important is that we present a distribution-aware representation learning approach, which makes it possible to conduct and understand feature representation learning at the feature level.},
  archive      = {J_EAAI},
  author       = {Wenwen Zhang and Zhao Pei and Fei-Yue Wang},
  doi          = {10.1016/j.engappai.2023.107151},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107151},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FeatsFlow: Traceable representation learning based on normalizing flows},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel deep learning-driven approach for predicting the
pelvis soft-tissue deformations toward a real-time interactive
childbirth simulation. <em>EAAI</em>, <em>126</em>, 107150. (<a
href="https://doi.org/10.1016/j.engappai.2023.107150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and objective Soft-tissue dynamics plays an essential role in the mechanical functions of the human body. Numerical approaches using finite element modeling and mass-spring framework have been currently used to estimate the biological soft tissue dynamics. However, these approaches still have important computational cost due to the use of a mesh configuration in the formulation of the dynamic equilibrium equation and unstable convergence issue. Methods We present in this study a novel approach based on the deep learning framework to predict the deformation of soft-tissues. In particular, the Long Short-term Memory (LSTM) neural network and deep neural network (DNN) were used to deal with high-frequency oscillation signals. Different learning strategies (with and without data dimension reduction) were also applied. A simulation-based database was generated using our HyperMSM model for training and testing purposes. The application of the proposed approach on the childbirth simulation was addressed. Results Using the root mean square error, the LSTM- and DNN-derived deformation deviation range from 0.139 mm to 1.062 mm (0.266%–2.028%) for both training and testing processes. The Pearson correlation coefficient of 0.994–0.999 demonstrates the strong similarity between predicted outputs and ground truth data. Conclusions This present work showed the capacity of the deep learning neural networks to predict complex physiological signals of the human body functions. As a perspective, this approach will be coupled with the Hololens device toward a novel interactive childbirth training tool with real-time feedback on the soft tissue deformations.},
  archive      = {J_EAAI},
  author       = {Duyen Hien Nguyen-Le and Abbass Ballit and Tien-Tuan Dao},
  doi          = {10.1016/j.engappai.2023.107150},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107150},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep learning-driven approach for predicting the pelvis soft-tissue deformations toward a real-time interactive childbirth simulation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparison of edge computing methods in internet of things
architectures for efficient estimation of indoor environmental
parameters with machine learning. <em>EAAI</em>, <em>126</em>, 107149.
(<a href="https://doi.org/10.1016/j.engappai.2023.107149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large increase in the number of Internet of Things (IoT) devices have revolutionised the way data is processed, which added to the current trend from cloud to edge computing has resulted in the need for efficient and reliable data processing near the data sources using energy-efficient devices. Two methods based on low-cost edge-IoT architectures are proposed to implement lightweight Machine Learning (ML) models that estimate indoor environmental quality (IEQ) parameters, such as Artificial Neural Networks of Multilayer Perceptron type. Their implementation is based on centralised and distributed parallel IoT architectures, connected via wireless, which share commercial off-the-self modules for data acquisition and sensing, such as sensors for temperature, humidity, illuminance, CO 2 , and other gases. The centralised method uses a Graphics Processing Unit and the Message Queuing Telemetry Transport protocol, but the distributed method utilises low-performance ARM-based devices and the Message Passing Interface protocol. Although multiple IEQ parameters are measured, the training and testing of ML models is accomplished with experiments focused on small temperature and illuminance datasets to reduce data processing load, obtained from sudden spikes, square profiles and sawteeth test cases. The results show a high estimation performance with F-score and Accuracy values close to 0.95, and an almost theorical Speedup with a reduction in power consumption close to 37% in the distributed parallel approach. In addition, similar or slightly better performance is achieved compared to equivalent IoT architectures from related research, but error reduction of 35–76% is accomplished with an adequate balance between performance and energy efficiency.},
  archive      = {J_EAAI},
  author       = {Jose-Carlos Gamazo-Real and Raúl Torres Fernández and Adrián Murillo Armas},
  doi          = {10.1016/j.engappai.2023.107149},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107149},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparison of edge computing methods in internet of things architectures for efficient estimation of indoor environmental parameters with machine learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved pairs trading strategy using two-level
reinforcement learning framework. <em>EAAI</em>, <em>126</em>, 107148.
(<a href="https://doi.org/10.1016/j.engappai.2023.107148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pairs trading is a popular classic neutral trading strategy in financial market. Deep reinforcement learning (DRL) has been widely used to improve the performance of this strategy. However, most works primarily focused on setting trading signals, but ignored selecting appropriate trading pairs. In this paper, a novel two-level reinforcement learning framework is proposed, where both pair selection and trading thresholds setting are involved. For pair selection, an Extended Option-Critic (EOC) method is utilized, which allows the agent to select trading pair on non-fixed length of time intervals. For trading thresholds setting, a three-agent Multi-Agent Deep Deterministic Policy Gradient (MADDPG) method is used for setting the opening and stop-loss thresholds as well as decide whether to trade. The simulation results in the Chinese futures market demonstrate that our proposed method achieves higher returns compared to traditional methods and popular reinforcement learning approaches.},
  archive      = {J_EAAI},
  author       = {Zhizhao Xu and Chao Luo},
  doi          = {10.1016/j.engappai.2023.107148},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107148},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved pairs trading strategy using two-level reinforcement learning framework},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved heterogeneous graph convolutional network for
job recommendation. <em>EAAI</em>, <em>126</em>, 107147. (<a
href="https://doi.org/10.1016/j.engappai.2023.107147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Job recommendation is crucial in online recruitment platforms due to the overwhelming number of job postings. Job seekers spend considerable time and effort searching for suitable employment. With millions of job seekers browsing job postings daily, the demand for accurate and effective job recommendations is more pressing than ever. To address this challenge, we propose IHGCN, an improved semi-supervised heterogeneous graph convolutional network model for job recommendation. IHGCN aims to provide job recommendations for early job seekers based on their resumes. Firstly, we introduce a novel labeling classification standard specifically tailored to early job seeker resumes. Secondly, we construct a heterogeneous resume graph where each resume is represented as a node. Job recommendation is treated as a multi-classification problem. Thirdly, our IHGCN model learns a node representation from the graph to perform effective job recommendations. To evaluate our model, we conduct experiments using a real-world resume dataset obtained from LinkedIn. The results demonstrate that IHGCN outperforms the baselines by around 10%. This study highlights the benefits of leveraging meta-paths within the Graph Convolutional Network model to address the sparsity problem caused by the one-hot representation of nodes.},
  archive      = {J_EAAI},
  author       = {Hao Wang and Wenchuan Yang and Jichao Li and Junwei Ou and Yanjie Song and Yingwu Chen},
  doi          = {10.1016/j.engappai.2023.107147},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107147},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved heterogeneous graph convolutional network for job recommendation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Agent-based hybrid tabu-search heuristic for dynamic
scheduling. <em>EAAI</em>, <em>126</em>, 107146. (<a
href="https://doi.org/10.1016/j.engappai.2023.107146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic scheduling has received widespread attention from academia and industry due to the increasing complexity in manufacturing systems. Highly dynamic and adaptable behaviours are necessary for an improved production efficiency in unstable and constantly changing environments. This paper proposes an agent-based hybrid tabu-search heuristic (AB-TSH) to solve dynamic flexible job-shop scheduling problems. The solution is fully implemented and tested in an industrial environment for seven distinct dynamic scenarios derived from a static scenario using the benchmark of AIP-PRIMECA Flexible Manufacturing System. The scheduling plan is obtained by exploitation using a greedy heuristic on tabu search solution points. The hybrid tabu-search heuristic is supported by a multi-agent system that react and re-optimize the scheduling plan in case of disturbances and unpredicted events. The proposed solution demonstrated superior performance in terms of makespan in the majority of dynamic scenarios tested when compared to previous studies in the literature. This improved performance is attributed to the solution’s ability to combine the scheduling plan both statically and dynamically.},
  archive      = {J_EAAI},
  author       = {Bernardo Firme and João Figueiredo and João M.C. Sousa and Susana M. Vieira},
  doi          = {10.1016/j.engappai.2023.107146},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107146},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Agent-based hybrid tabu-search heuristic for dynamic scheduling},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AITIA-PM: Discovering the true causes of events in a process
mining context. <em>EAAI</em>, <em>126</em>, 107145. (<a
href="https://doi.org/10.1016/j.engappai.2023.107145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining is a research area that enables businesses to analyze and improve their processes by deriving knowledge from event logs. While pinpointing the causes of, for instance, a negative case outcome can provide valuable insights for business users, only a limited amount of research has been done to uncover causal relations within the process mining field while actively distinguishing between correlation and causality. The AITIA-PM algorithm is one of these research projects. This article updates the AITIA-PM method, which uses causality theory to measure cause-and-effect relationships in event logs. The system uses probabilistic temporal logic (PTL) to formulate hypotheses explicitly and then automatically checks them for causality using available data. More precisely, AITIA-PM is designed for process mining since it operates directly on event logs, giving users access to the information stored there, and increasing the scope for meaningful causal analysis in a process mining setting. With this addition, PTL is emphasized more as a crucial algorithmic component, and the method to control for false discovery rates (FDR) is adjusted for increased practical use. The case study shows that after the domain expert provides the search space of hypotheses, the AITIA-PM algorithm can extract valuable cause–effect insights from an event log. The search space can be flexibly defined, making AITIA-PM a powerful tool for business users. An evaluation on artificial data proves AITIA-PM is capable of extracting the causal relationships, while a demonstration on the Road Traffic Fines Management dataset shows the applicability of the algorithm on real data.},
  archive      = {J_EAAI},
  author       = {Greg Van Houdt and Niels Martin and Benoît Depaire},
  doi          = {10.1016/j.engappai.2023.107145},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107145},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AITIA-PM: Discovering the true causes of events in a process mining context},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Sparse q-laplace kernel online prediction for indoor
localization in the internet of things. <em>EAAI</em>, <em>126</em>,
107144. (<a
href="https://doi.org/10.1016/j.engappai.2023.107144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important component of IoT-oriented applications, the indoor positioning estimation is getting increasing concern with IoT’s rapid development. However, the performance of indoor positioning is heavily relied on the complexity of the environment, which is always full of noises, such as Gaussian noise mixed with impulsive noise. These noises can deteriorate the precision performance of indoor positioning identification systems. In order to attack this problem, we propose a new kernel called generalized q -Laplace kernel to produce a new q -Laplace kernel adaptive filtering algorithm ( q LaKAF), which is combined with the recently proposed kernel mean p -power error criterion (KMPE). The proposed q LaKAF has two vital features. Firstly, the q -Laplace kernel is employed to combat the Gaussian noise together with abrupt noise in real-world scenarios. Besides, the KMPE is utilized to obtain higher-order information in addition to second-order information which facilitates to suppress mixed noise. Furthermore, a Strengthened Surprise Criterion (SSC) is applied to q LaKAF to reduce the size of neural networks. The q LaKAF algorithm assisted by SSC is called Strengthened Surprise Criterion q -Laplace kernel adaptive filtering algorithm (SSC- q LaKAF). Three experiments are carried out on two real-world scenarios to validate the effectiveness and accuracy performance. The experimental results demonstrate that the accuracy has been improved by at least 3.6%; meanwhile, the SSC- q LaKAF neural network size can be reduced by up to 12.5%, without much loss of accuracy performance compared to q LaKAF.},
  archive      = {J_EAAI},
  author       = {Chang Liu and Xifeng Li and Dongjie Bi and Libiao Peng and Yongle Xie},
  doi          = {10.1016/j.engappai.2023.107144},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107144},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse q-laplace kernel online prediction for indoor localization in the internet of things},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentimental analysis &amp; hate speech detection on english
and german text collected from social media platforms using optimal
feature extraction and hybrid diagonal gated recurrent neural network.
<em>EAAI</em>, <em>126</em>, 107143. (<a
href="https://doi.org/10.1016/j.engappai.2023.107143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networking platforms allow users to ask questions, exchange information, opinions, ideas, and promote companies. Social media&#39;s massive user-generated text is useful for study, translation, and analysis. Due of their quick spread and detrimental impact, offensive remarks, hate speech, and harassment must be discovered and deleted immediately. In non-English main language environments, code-mixed text makes hate speech detection difficult. Hate speech&#39;s thematic emphasis and target-oriented orientation are typically ignored in binary categorization methods. These methods also fail in code-mixing multilingual contexts. In this study, we propose an optimal feature extraction and hybrid diagonal gated recurrent neural network (FE-DGRNN) for hate speech detection and sentiment analysis on code-mixed texts in multiple languages. Our FE-DGRNN technique consists of three processes: preprocessing, improved seagull optimization (ISO) for feature extraction, and hybrid diagonal gated recurrent neural network (Hyb-DGRNN) for hate speech detection and sentiment analysis. We evaluate the performance of our proposed technique using the HASOC 2019 dataset, focusing on English and German. The results demonstrate high accuracy of 95%, 96%, and 92% for English tasks, with Precision and F-measure of 94%, 96%, and 91%. For German tasks, the accuracy is 92% and 93%, with Precision and F-measure of 90% and 91%.},
  archive      = {J_EAAI},
  author       = {Purbani Kar and Swapan Debbarma},
  doi          = {10.1016/j.engappai.2023.107143},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107143},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sentimental analysis &amp; hate speech detection on english and german text collected from social media platforms using optimal feature extraction and hybrid diagonal gated recurrent neural network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Power transformer fault diagnosis based on a
self-strengthening offline pre-training model. <em>EAAI</em>,
<em>126</em>, 107142. (<a
href="https://doi.org/10.1016/j.engappai.2023.107142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate transformer fault diagnosis is crucial for maintaining the power system stability. Due the complex operation condition of the transformer, its faults are with the characteristic of multi-class faults, class-imbalance, and limited diagnosis data of availability. Additionally, some fault samples are only with overheating or discharge labels when collected, it is a challenge that how to how to use these samples. To address these issues, in this paper, a novel transformer fault diagnosis method based on a hybrid model of Res-Variational-Auto-Encoder (ResVAE) and ensemble learning (EL) model is proposed. Through a self-strengthening strategy, fault characteristics are extracted category-by-category by using a residual convolutional neural network, and low dimensional characteristics are mapped into characteristic fusion samples by VAE. Based on this strategy, an offline pre-training model is built based on ResVAE and EL. The hybrid model can obtain more information from offline source domain, enabling the EL to diagnose multiple fault types as well as undetermined faults. Considering 11 categories of imbalanced classification scenarios with limited sample sizes, the comparison is made between eight expansion and six diagnosis algorithms. The results show that the offline pre-training EL model increased the diagnostic accuracy up to 11.224% compared with tradition ratios method. The ResVAE-EL model achieves the highest diagnostic accuracy of 91.011%, which is 10.112% higher than that of the single offline pre-training model.},
  archive      = {J_EAAI},
  author       = {Mingwei Zhong and Siqi Yi and Jingmin Fan and Yikang Zhang and Guanglin He and Yunfei Cao and Lutao Feng and Zhichao Tan and Wenjun Mo},
  doi          = {10.1016/j.engappai.2023.107142},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107142},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Power transformer fault diagnosis based on a self-strengthening offline pre-training model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive technique for physical human–robot interaction
handling using proprioceptive sensors. <em>EAAI</em>, <em>126</em>,
107141. (<a
href="https://doi.org/10.1016/j.engappai.2023.107141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work focuses on the development of an adaptive technique for the physical interaction handling between a human and a robot, as well as its experimental validation. The proposed technique is based on the deep residual neural network and dedicated finite state machine, where the states are the robot behavior modes and transitions are the switchings between the states that depend on the interaction parameters and characteristics. It ensures the human operator safety and improves the human–robot collaboration performance by implementing various scenarios. In the scope of this technique, the parameters of human–robot interaction are used to select an appropriate robot reaction strategy using data from internal robot sensors only, i.e. proprioceptive sensors. These parameters define the interaction force vector and its application point on the robot surface, which allow to classify the interaction within the set of predefined categories. This classification distinguishes interactions applied at the tool or intermediate link (Tool/Link), having soft or hard nature (Soft/Hard), as well as having different intention (Intl/Accd) or duration (Short/Long). Based on identified category and the current robot state, the algorithm chooses an appropriate robot reaction. To confirm the efficiency the developed technique, an experimental study was conducted, which involved the collaboration between the real industrial manipulator KUKA LBR iiwa and the human operator.},
  archive      = {J_EAAI},
  author       = {Dmitry Popov and Anatol Pashkevich and Alexandr Klimchik},
  doi          = {10.1016/j.engappai.2023.107141},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107141},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive technique for physical human–robot interaction handling using proprioceptive sensors},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simplified probabilistic linguistic preference relation in
decision making. <em>EAAI</em>, <em>126</em>, 107140. (<a
href="https://doi.org/10.1016/j.engappai.2023.107140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic linguistic preference relation (PLPR), whose elements are denoted in probabilistic linguistic term sets, provides a flexible tool for experts to express linguistic preferences in pairwise comparisons of objects. However, missing elements in PLPRs often occur owing to the difficulty of providing pairwise comparison values, especially when the number of objects is large. This study introduces a simplified PLPR based on reference objects, which allows for the incompleteness of probabilistic linguistic term sets when deriving the priorities of objects. We also introduce a consistency measure to check the reliability of a simplified PLPR. An illustrative example is provided to demonstrate the efficiency and validity of the simplified PLPR in decision making.},
  archive      = {J_EAAI},
  author       = {Xiaomei Mi and Huchang Liao and Xiao-Jun Zeng and Abdullah Al-Barakati},
  doi          = {10.1016/j.engappai.2023.107140},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107140},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simplified probabilistic linguistic preference relation in decision making},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual cross-attention for medical image segmentation.
<em>EAAI</em>, <em>126</em>, 107139. (<a
href="https://doi.org/10.1016/j.engappai.2023.107139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Dual Cross-Attention (DCA), a simple yet effective attention module that enhances skip-connections in U-Net-based architectures for medical image segmentation. The plain and simple skip-connection scheme in U-Net-based architectures struggles with capturing the multi-scale context, resulting in a semantic gap between encoder and decoder features. Such a semantic gap causes redundancy between low and high-level features which ultimately limits the segmentation performance. In this paper, we address this issue by sequentially capturing channel and spatial dependencies across multi-scale encoder features that adaptively combine low and high-level features in various scales to effectively bridge the semantic gap. First, the Channel Cross-Attention (CCA) extracts global channel-wise dependencies by utilizing cross-attention across channel tokens of multi-scale encoder features. Then, the Spatial Cross-Attention (SCA) module performs cross-attention to capture spatial dependencies across spatial tokens. Finally, these fine-grained encoder features are up-sampled and connected to their corresponding decoder parts to form the skip-connection scheme. Our proposed DCA module can be integrated into any encoder–decoder architecture with skip-connections such as U-Net and its variants as well as advanced architectures based on vision transformers. The experimental results using six medical image segmentation datasets demonstrate that our DCA module can consistently improve the overall segmentation performance at a slight parameter increase. Our codes are available at: https://github.com/gorkemcanates/Dual-Cross-Attention .},
  archive      = {J_EAAI},
  author       = {Gorkem Can Ates and Prasoon Mohan and Emrah Celik},
  doi          = {10.1016/j.engappai.2023.107139},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107139},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual cross-attention for medical image segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). P2CA-GAM-ID: Coupling of probabilistic principal components
analysis with generalised additive model to predict the k−barriers for
intrusion detection. <em>EAAI</em>, <em>126</em>, 107137. (<a
href="https://doi.org/10.1016/j.engappai.2023.107137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drastic advancement in computing technology and the dramatic increase in the usage of explainable machine learning algorithms provide a promising platform for developing robust intrusion detection algorithms. However, the development of these algorithms is constrained by their applicability over specific scenarios of Wireless Sensor Networks (WSNs). We introduced a hybrid framework by combining Probabilistic Principal Component Analysis (P 2 CA) and Generalised Additive Model (GAM), which is performing well for all the scenarios of WSNs. To demonstrate our framework’s broad applicability, we evaluated its performance over three publicly available intrusion detection datasets ( i.e., LT-FS-ID, AutoML-ID, and FF-ANN-ID), each from different scenarios. Our findings highlight that the presented framework can accurately predict the number of k − barriers for all three datasets. Furthermore, we conducted a comprehensive performance comparison between our proposed framework and benchmark algorithms, which revealed that our approach outperforms all of them. Additionally, we evaluated the framework’s versatility by testing its performance on datasets unrelated to intrusion detection, specifically ALE datasets. Notably, our approach accurately predicted the response variable in these datasets and exceeded the performance of its primary algorithm, further demonstrating its robustness and adaptability. The implications of this research are substantial. By developing a robust intrusion detection framework that performs well across diverse WSN scenarios, we address a critical need for reliable network security in various domains, including industrial IoT, smart cities, and environmental monitoring. Our findings not only enhance the understanding of intrusion detection in WSNs but also pave the way for developing more sophisticated and adaptable systems to safeguard sensitive data and critical infrastructure.},
  archive      = {J_EAAI},
  author       = {Abhilash Singh and Jaiprakash Nagar and J. Amutha and Sandeep Sharma},
  doi          = {10.1016/j.engappai.2023.107137},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107137},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {P2CA-GAM-ID: Coupling of probabilistic principal components analysis with generalised additive model to predict the k−barriers for intrusion detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A tutorial-based survey on feature selection: Recent
advancements on feature selection. <em>EAAI</em>, <em>126</em>, 107136.
(<a href="https://doi.org/10.1016/j.engappai.2023.107136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curse of dimensionality is known as big challenges in data mining, pattern recognition, computer vison and machine learning in recent years. Feature selection and feature extraction are two main approaches to circumvent this challenge. The main objective in feature selection is to remove the redundant features and preserve the relevant features in order to improve the learning algorithm performance. This survey provides a comprehensive overview of state-of-art feature selection techniques including mathematical formulas and fundamental algorithm to facilitate understanding. This survey encompasses different approaches of feature selection which can be categorized to five domains including: A) subspace learning which involves matrix factorization and matrix projection, B) sparse representation learning which includes compressed sensing and dictionary learning, C) information theory which covers multi-label neighborhood entropy, symmetrical uncertainty, Monte Carlo and Markov blanket, D) evolutionary computational algorithms including Genetic algorithm (GA), particle swarm optimization (PSO), Ant colony (AC) and Grey wolf optimization (GWO), and E) reinforcement learning techniques. This survey can be helpful for researchers to acquire deep understanding of feature selection techniques and choose a proper feature selection technique. Moreover, researcher can choose one of the A, B, C, D and E domains to become deep in this field for future study. A potential avenue for future research could involve exploring methods to reduce computational complexity while simultaneously maintaining performance efficiency. This would involve investigating ways to achieve a more efficient balance between computational resources and overall performance. For matrix-based techniques, the main limitation of these techniques lies in the need to tune the coefficients of the regularization terms, as this process can be challenging and time-consuming. For evolutionary computational techniques, getting stuck in local minimum and finding an appropriate objective function are two main limitations.},
  archive      = {J_EAAI},
  author       = {Amir Moslemi},
  doi          = {10.1016/j.engappai.2023.107136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A tutorial-based survey on feature selection: Recent advancements on feature selection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised spectral feature learning for fine-grained
classification in small data set. <em>EAAI</em>, <em>126</em>, 107135.
(<a href="https://doi.org/10.1016/j.engappai.2023.107135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image classification is a challenging task due to the small inter-class variance, the large intra-class difference, and the small training data. Traditional methods typically rely on large-scale training samples with annotated part annotations, making them costly and severely limiting their application area. In this paper, we propose an effective and weakly supervised fine-grained classification framework. In this framework, a discriminative class-specific spectral feature is learned by intra-class spectral coupling and inter-class spectral decoupling under the weak supervision of image-level category labels, and then the new input images are classified based on the learned class-specific spectral feature. Different from existing strong supervised methods, the proposed technique creatively combines weak supervision of the image-level category labels with unsupervised spectral graph decomposition, not relying on large-scale training samples with dense part annotations, which are heavily labor-consuming. The performance of the proposed methods has been verified on four kinds of typical datasets: the JAFFE dataset, the Yale database, the UCI-CMU face database, and the neural foramina dataset. The satisfactory classification results have been achieved by the proposed method in expression recognition on the JAFFE dataset (with a mean accuracy of 95.31%), face recognition on the Yale database (with a mean accuracy of 98.79%), object recognition on the UCI-CMU face database (with a mean accuracy of 96.96%), and disease grading on the neural foramina dataset (with a mean accuracy of 92.09%). Compared with most state-of-the-art methods, the proposed method has superior classification performance in the small data set.},
  archive      = {J_EAAI},
  author       = {Xiaoxu He},
  doi          = {10.1016/j.engappai.2023.107135},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107135},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Supervised spectral feature learning for fine-grained classification in small data set},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ICA-net: Industrial defect detection network based on
convolutional attention guidance and aggregation of multiscale features.
<em>EAAI</em>, <em>126</em>, 107134. (<a
href="https://doi.org/10.1016/j.engappai.2023.107134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting surface defects in the industry is essential for improving the quality of industrial products and maintaining product safety. However, problems such as the similarity of defects, significant variation in the scale of the target object, and the balance between detection speed and accuracy in industrial inspection scenarios have been considerable research topics in this field. This paper proposes an industrial defect detection network based on convolutional attention-guided and aggregated multiscale features to address these issues (ICA-Net). Firstly, for similarity defects in complex backgrounds, this paper proposes a backbone network with a combination of lightweight convolutional blocks and self-attentive modules to fully extract images’ local and global information and enhance the network’s expressiveness. Secondly, to make full use of the shallow fine-grained features and deep semantic features of the backbone network to improve the detection capability of defects with significant scale changes, this paper designs a cross-layer multiscale feature fusion network (CEF-Net), which fully fuses the features of adjacent layers and cross-layers through a reweighting feature strategy to enrich the network feature transfer path and ensure the efficient fusion of different scale features in the network. At the same time, the fine-grained feature fusion module (FFM) is used to fuse elements from multiple layers to extract more contextual information, enhance the extraction of fine-grained features and improve the detection capability of complex small targets. Finally, to address the problems of inaccurate regression localization and low detection accuracy of defects in existing industrial algorithms, a new IoU loss function (G-IOU) is proposed for regressing the intersection part of the predicted frame and the actual structure according to the aspect ratio of the real frame during the model regression to improve the accuracy and stability of detection. The experimental results show that 94.1%, 98.6%, 99.4%, 98.8% and 96.5% of mAP@.5 are obtained on steel, PCB, aluminium, automobile and Xsteel steel metal surface defect datasets, respectively, and 48 FPS is achieved, which is superior to the current mainstream detectors and meets the needs of practical industrial production.},
  archive      = {J_EAAI},
  author       = {ShiLong Zhao and Gang Li and MingLe Zhou and Min Li},
  doi          = {10.1016/j.engappai.2023.107134},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107134},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ICA-net: Industrial defect detection network based on convolutional attention guidance and aggregation of multiscale features},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A feature enhanced RetinaNet-based for instance-level ship
recognition. <em>EAAI</em>, <em>126</em>, 107133. (<a
href="https://doi.org/10.1016/j.engappai.2023.107133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance-level ship recognition (ISR) has important applications in civil and military fields such as target acquisition, maritime surveillance, and ship situational awareness. Due to the special peculiarities of the marine environment and the rigidity of ships, the changes of viewpoint and scale lead to significant differences in the appearance of ships, which poses a challenge to ISR. Meanwhile, the lack of public datasets for ISR further increases the difficulty of recognition. Considerable work has been conducted on coarse- or fine-grained classification, and little research has been done on ISR. Therefore, a feature enhanced RetinaNet-based for ISR (FERISR) is proposed. First, an attention-aware pyramid network (APN) is designed to enhance the salience features of ship instances and integrate attention-guided features to maximize the use of multilayer information while reducing information redundancy. On this basis, a detail information enhancement module (DFEM) is proposed to refine the fused multi-scale feature maps to improve model performance in scale variations by further enhancing the ship features. At the same time, foggy environment at sea is simulated and the images of foggy and low-light scenario are tested to cope with the impacts caused by low visibility scenes. The ReidDataset is further divided into instance level to make a dataset for ISR(DISR), which is used to discuss the performance of FFRISR on ISR. The generalizability of FFRISR in different scenarios is also discussed. The experimental results demonstrate that FERISR can effectively improve recognition accuracy in viewpoint change, scale change and low visibility scenarios, as well as improve the detection speed. Finally, the effectiveness of APN and DFEM is further verified by ablation experiments.},
  archive      = {J_EAAI},
  author       = {Jing Cheng and Rongjie Wang and Anhui Lin and Desong Jiang and Yichun Wang},
  doi          = {10.1016/j.engappai.2023.107133},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107133},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A feature enhanced RetinaNet-based for instance-level ship recognition},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SIA-net: Structural information awareness network based on
normal samples for surface defect detection. <em>EAAI</em>,
<em>126</em>, 107131. (<a
href="https://doi.org/10.1016/j.engappai.2023.107131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection is a challenging task in industrial manufacturing, and the detection method based on deep learning has become the mainstream trend in the industry. However, this method requires a large number of labeled datasets for network training, and it cannot detect new types of defects randomly generated in the actual production process, making it difficult to transfer to actual production. To address this problem, we propose a structural information awareness network (SIA-Net). It is constructed by the adaptive generative adjunctive network (AGAN) module, which can simulate the background style of defect-free samples to randomly embed more reasonable defects. Then, the model is trained to recover the defect embedded area and the defect area is inferred according to the difference between before and after image restoration. Furthermore, in order to avoid blurring the image structure information during feature extraction, the self-attention encoder (SE) and spatial awareness decoder (SD) modules are designed to aggregate the image structure information to generate the final prediction results. We selected four public datasets and specially developed a box defect dataset to verify its detection effect. Experimental results (mIoU/mPA) (Kolektor: 88.91%/89.55%, AITEX defect: 89.61%/91.46%, RSDDs: 86.89%/87.88%, MT defect: 88.36%/90.32%, box defect: 89.71%/90.57%) show that our proposed method clearly outperforms the current unsupervised detection methods.},
  archive      = {J_EAAI},
  author       = {Qiurui Ma and Erhu Zhang and Yajun Chen and Jinghong Duan and Linhao Shao},
  doi          = {10.1016/j.engappai.2023.107131},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107131},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SIA-net: Structural information awareness network based on normal samples for surface defect detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Hierarchical reinforcement learning with adaptive
scheduling for robot control. <em>EAAI</em>, <em>126</em>, 107130. (<a
href="https://doi.org/10.1016/j.engappai.2023.107130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional hierarchical reinforcement learning (HRL) relies on discrete options to represent explicitly distinguishable knowledge, which may lead to severe performance bottlenecks. It is possible to represent richer knowledge through continuous options, but reliable scheduling methods are lacking. To design an available scheduling method for continuous options, in this paper, the hierarchical reinforcement learning with adaptive scheduling (HAS) algorithm is proposed. Its low-level controller learns diverse options, while the high-level controller schedules options to learn solutions. It achieves an adaptive balance between exploration and exploitation during the frequent scheduling of continuous options, maximizing the representation potential of continuous options. It builds on multi-step static scheduling and makes switching decisions according to the relative advantages of the previous and the estimated continuous options, enabling the agent to focus on different behaviors at different phases of the task. The expected t -step distance is applied to demonstrate the superiority of adaptive scheduling in terms of exploration. Furthermore, an interruption incentive based on annealing is proposed to alleviate excessive exploration during the early training phase, accelerating the convergence rate. Finally, we apply HAS to robot control with sparse rewards in continuous spaces, and develop a comprehensive experimental analysis scheme. The experimental results not only demonstrate the high performance and robustness of HAS, but also provide evidence that the adaptive scheduling method has a positive effect both on the representation and option policies.},
  archive      = {J_EAAI},
  author       = {Zhigang Huang and Quan Liu and Fei Zhu},
  doi          = {10.1016/j.engappai.2023.107130},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107130},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical reinforcement learning with adaptive scheduling for robot control},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lazy deep q networks for unified rotor angle stability
framework with unified time-scale of power systems with mass distributed
energy storage. <em>EAAI</em>, <em>126</em>, 107129. (<a
href="https://doi.org/10.1016/j.engappai.2023.107129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The addition of increasing numbers of new energy sources can lead to challenges to the security and stability of power systems. The combined rotor angle stability (RAS) framework of power systems with multiple time-scales could lead to uncoordinated stability control commands for numerous stability control devices of power systems. To mitigate this deficiency, this study proposes a unified RAS framework to replace the RAS with three time-scales, which consist of small-disturbance, large-disturbance, and long-term RASs. This study proposes lazy deep Q networks for the unified RAS framework of power systems. The lazy deep Q networks approach, which is based on the Markov decision process, contains lazy learning, deep Q networks, a state-buffer, a selector operation, and a limiter operation. The unified stability framework and the conventional combined stability framework of power systems are compared under four cases, i.e., the power system with four generators, the power system based on IEEE 39-bus system, the European high voltage 89-bus system, and the European high voltage 1354-bus system. These four case studies verify that the unified stability framework based on the lazy deep Q networks approach is more stable than the conventional combined stability framework based on the combination of optimization algorithm of long-term dynamic stability, control method of middle-term transient stability, and control method of short-term static stability. The error indices for the proposed lazy deep Q networks algorithm are as follows: the AAE is at least 4.7% lower than the other compared algorithms; the IAE is at least 4.8% lower than the other compared algorithms; the ISE is at least 3.9% lower than the other compared algorithms; the ITAE is 2.3% lower than the other compared algorithms.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Nan Mo and Yuejiang Lu},
  doi          = {10.1016/j.engappai.2023.107129},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107129},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lazy deep q networks for unified rotor angle stability framework with unified time-scale of power systems with mass distributed energy storage},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-hop question answering using sparse graphs.
<em>EAAI</em>, <em>126</em>, 107128. (<a
href="https://doi.org/10.1016/j.engappai.2023.107128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop question answering (QA) across multiple documents requires a deep understanding of relationships between entities in documents, questions, and answer candidates. Graph Neural Networks (GNNs) have emerged as a promising tool for multi-hop QA tasks. These models often suffer from increasing computational and model complexity, which makes them inefficient for real-world applications with limited resources. In this paper, we propose a graph-based approach called Sparse Graph-based Multi-hop Question Answering system (SG-MQA), which provides a throughout examination of the mentioned challenges and presents appropriate measures to address them. We propose a novel approach based on the Relational Graph Convolutional Network (R-GCN) that reduces the model complexity and improves its performance. We have utilized various strategies and conducted multiple experiments to achieve this goal. We show the efficacy of the proposed approach by examining the results of experiments on two QA datasets, namely WikiHop and HotpotQA. The SG-MQA model outperforms all the state-of-the-art (SOTA) methods on WikiHop and increases the accuracy of the best previous approach from 74.4% to 78.3%. Additionally, it achieves acceptable performance on HotpotQA. Although, according to the F1 measure, the performance of SG-MQA is inferior to that of the SOTA model, it is comparable to that of all other approaches. On the other hand, based on the Exact Match (EM) measure, SG-MQA shows comparable performance to that of the SOTA model and outperforms all other approaches.},
  archive      = {J_EAAI},
  author       = {Nima Hemmati and Gholamreza Ghassem-Sani},
  doi          = {10.1016/j.engappai.2023.107128},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107128},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-hop question answering using sparse graphs},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning model based on bayesian optimization for
predicting the infinite dilution activity coefficients of ionic
liquid-solute systems. <em>EAAI</em>, <em>126</em>, 107127. (<a
href="https://doi.org/10.1016/j.engappai.2023.107127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The infinite dilution activity coefficient (γ ∞ ) is a crucial thermodynamic property that provides a measure of the affinity between the solute and the solvent. In this work, three deep learning models (deep neural network, convolution neural network, and convolution deep neural network) were proposed to predict the γ ∞ for ionic liquid-solute systems. 52 ionic liquids and 114 organic solutes (7783 data points in total) contained in the γ ∞ database over the temperature from 293.15 to 428.15 K were collected to construct the model. Molecular descriptor was generated using the RDKit. The Bayesian optimization algorithm was employed to determine the parameters for each model, and the stability of the model was increased by 10-fold cross validation. Finally, the method of SHapley Additive exPlanations was employed to explain our proposed model. The coefficient of determination, mean absolute error, mean square error, root mean square error, error, sum of squared error, relative root mean square error and the Wilcoxon signed-rank test were used to assess the model. The results indicated that the experimental values were in satisfactory agreement with the values predicted for convolution deep neural network. These predictive models can be used to predict the γ ∞ for ionic liquid-solute systems to solve problems in phase equilibrium and process design.},
  archive      = {J_EAAI},
  author       = {Dingchao Fan and Wenguang Zhu and Yusen Chen and Ke Xue and Tianxiong Liu and Peizhe Cui and Jianguang Qi and Zhaoyou Zhu and Yinglong Wang},
  doi          = {10.1016/j.engappai.2023.107127},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107127},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning model based on bayesian optimization for predicting the infinite dilution activity coefficients of ionic liquid-solute systems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review on prognostics and health management in smart
factory: From conventional to deep learning perspectives. <em>EAAI</em>,
<em>126</em>, 107126. (<a
href="https://doi.org/10.1016/j.engappai.2023.107126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the fourth industrial revolution is pushing factories toward an intelligent, interconnected grid of machinery, communication systems, and computational resources. Smart factories (SF) and smart manufacturing (SM) incorporate a cyber-physical system that employs advanced technologies such as artificial intelligence (AI) for data analysis, automated process driving, and continuous data handling. Smart factories operate by combining machines, humans, and massive amounts of data into a single, digitally interconnected ecosystem. Prognostics and health management (PHM) has become a critical requirement of smart factories to meet production needs. PHM of components/machines in the smart factory is crucial for securing uninterrupted operation and ensuring safety standards. The growing availability of computational capacity has increased the use of deep learning in PHM strategies. Deep learning supports comprehensive PHM solutions, thus reducing the need for manual feature development. This review presents an extensive study of the PHM strategies employed in the smart factory ranging from the conventional perspective to the deep learning perspective. This includes consideration of the conventional methodologies used for health management along with latest trends in the PHM domain in the smart factory.},
  archive      = {J_EAAI},
  author       = {Prashant Kumar and Izaz Raouf and Heung Soo Kim},
  doi          = {10.1016/j.engappai.2023.107126},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107126},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review on prognostics and health management in smart factory: From conventional to deep learning perspectives},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive federated few-shot feature learning with prototype
rectification. <em>EAAI</em>, <em>126</em>, 107125. (<a
href="https://doi.org/10.1016/j.engappai.2023.107125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Targeting to produce new features from limited data, few-shot feature generation approaches have attracted extensive attention and successfully mitigated the high cost of acquiring sufficient data. However, two main challenges remain underexplored among existing few-shot feature generation methods, namely the distribution gaps between base and novel classes, and the gradual tightening of data privacy. In order to ameliorate the performance drop induced by the distribution gap and alleviate the laborious cost of collecting massive data, in this paper, we propose a novel few-shot feature generation model that integrates domain alignment, prototype rectification, and federated learning into a unified framework. Concretely, the distance between across different classes is explicitly shrunk via domain alignment, facilitating more precise and reliable feature generation. Additionally, we develop prototype correction to reduce the intra-class discrepancy and make samples from the same class more clustered. Such that, the negative effects of the boundary samples are eliminated and thus boost the model performance. Finally, we combine our few-shot feature generation with the federated framework to protect data privacy and propose an adaptive federated scheme to provide customized services for individual clients. Extensive experiments are performed on three standard benchmark datasets to evaluate the effectiveness and superiority of our proposed method. The results consistently demonstrate that our proposed model gains substantial performance boosts and achieves state-of-the-art performance on the few-shot tasks.},
  archive      = {J_EAAI},
  author       = {Mengping Yang and Xu Chu and Jingwen Zhu and Yonghui Xi and Saisai Niu and Zhe Wang},
  doi          = {10.1016/j.engappai.2023.107125},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107125},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive federated few-shot feature learning with prototype rectification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive GLNPSO method for inventory replenishment supply
chain problem with multiple-warehouse policy and budget consideration.
<em>EAAI</em>, <em>126</em>, 107124. (<a
href="https://doi.org/10.1016/j.engappai.2023.107124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an efficient computation tool for a multiple-warehouse inventory replenishment lot-sizing problem with supplier selection, quantity discounts, and budget constraint. The cost model of the considered inventory replenishment issue is formulated as a mixed-integer nonlinear programming (MINLP) problem. With the proposed MINLP problem being an NP-hard problem, the MINLP cost model was optimized by using a novel global–local neighbor particle swarm optimization algorithm (TPAGLNPSO), inspired by two-phase self-adaptive inertia weight and improved constraint-handling technique. Apart from introducing the velocity index to switch the search scheme from exploration to exploitation, the constraint-handling technique was utilized to guide and guarantee the particle search toward undiscovered regions in the solution space. The stability analysis for the proposed novel TPAGLNPSO was also conducted using the stochastic process theorem. The corresponding parameter selection ranges were obtained based on the convergent conditions. Finally, eight industry cases were provided as examples to evaluate the performance of the proposed TPAGLNPSO method, after which a sensitivity analysis for the MINLP cost model was performed. The results demonstrate the competitive performance of the proposed TPAGLNPSO optimizer in terms of solution quality (with near-optimal results) than the optimal solutions obtained from Lingo software and computational effort (CPU time). Such findings can provide practitioners marginal insights into the effective management of the supply chain inventory replenishment problem.},
  archive      = {J_EAAI},
  author       = {Yen-Deng Huang and Tsung-Hui Chen and Mingchang Chih and Wen-Jung Chang and Chun-Chi Lien},
  doi          = {10.1016/j.engappai.2023.107124},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107124},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive GLNPSO method for inventory replenishment supply chain problem with multiple-warehouse policy and budget consideration},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal-ViT: Robust vision transformer by causal
intervention. <em>EAAI</em>, <em>126</em>, 107123. (<a
href="https://doi.org/10.1016/j.engappai.2023.107123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence based on deep learning is better at improving the representation ability of models from data. However, due to the limitation of fixed receptive field, these agents are not able to provide a correct response outside the fixed receptive field. To address this problem, this paper provides a new perspective with improving the Image Recognition tasks. This study firstly constructs two extended receptive fields using structural causal model. Then, an approximate intervention method that changes the traditional likelihood prediction to predict the result of causal intervention is proposed. Finally, this study formulates the objective function to adapt the proxy training, which makes the whole model work well. Above all of these, a new Vision Transformer variant named Causal-ViT is proposed. Furthermore, rich experimental results of different tasks are reported. These results show that the proposed perspective makes a significant improvement in Image Recognition tasks. By simply plugging Causal-ViT to different sub-tasks, all of them bring the new benchmarks of themselves field, which proves our method is flexible.},
  archive      = {J_EAAI},
  author       = {Wei Li and Zhixin Li and Xiwei Yang and Huifang Ma},
  doi          = {10.1016/j.engappai.2023.107123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal-ViT: Robust vision transformer by causal intervention},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilize DBN and DBSCAN to detect selective forwarding
attacks in event-driven wireless sensors networks. <em>EAAI</em>,
<em>126</em>, 107122. (<a
href="https://doi.org/10.1016/j.engappai.2023.107122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious nodes launching selective forwarding attacks jeopardize network reliability in event-driven wireless sensor networks. Swift detection and exclusion of these nodes are vital, especially in harsh environments where normal nodes also suffer from decreased forwarding rates due to poor channel conditions. To solve this problem, this paper proposes a deep belief network (DBN) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN) based detection scheme against selective forwarding attacks under harsh environments. The DBN algorithm extracts and analyzes behavior features of nodes, while the DBSCAN clustering algorithm effectively distinguishes between malicious and normal nodes during selective forwarding attacks. Simulation results demonstrate the scheme’s effectiveness with a missed detection rate (MDR) of approximately 2% and a false detection rate (FDR) below 5% in harsh environments, providing a robust solution for ensuring the integrity and efficiency of data transmission in event-driven wireless sensor networks.},
  archive      = {J_EAAI},
  author       = {Quanbing Li and Yilun Ma and Yuanming Wu},
  doi          = {10.1016/j.engappai.2023.107122},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107122},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Utilize DBN and DBSCAN to detect selective forwarding attacks in event-driven wireless sensors networks},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CB-SAGE: A novel centrality based graph neural network for
floor plan classification. <em>EAAI</em>, <em>126</em>, 107121. (<a
href="https://doi.org/10.1016/j.engappai.2023.107121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have emerged as one of the most prominent research areas in accomplishing machine learning tasks over graphical networks. GNNs are prominently used in performing tasks like semi-supervised node classification, link prediction, and community detection. GraphSAGE is one of the most recent GNN models which is being used to accomplish these tasks. A floor plan is an architectural design of a building that represents various floor compartments. In this paper, we represent floor plan(s) as graph(s). We characterize floor room (compartment) classification as a node classification problem. We propose a variation of the traditional GraphSAGE (sample and aggregation) algorithm: Centrality based GraphSAGE (CB-SAGE), which captures the structural properties of the network. We use the average clustering coefficient and average betweenness centrality to capture structure properties. We compute CB scores for all the floor plan graphs. Top 70% nodes (based on CB scores) are selected for the training. During the training, we append the betweenness centrality score of each node as an additional feature in the feature matrix for the embedding process. We conduct experiments on the House-GAN dataset, which contains 1,43,184 vectorized floor plan images. The proposed method outperforms the current state-of-art models in accomplishing the task of floor plan classification. We compare our results with the traditional machine learning approach (MLP) and other GNN-based methods. Our approach achieves an accuracy of 96.70%, which is significantly (approximately 16%) higher than other state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Atul Kumar Verma and Mahipal Jadeja},
  doi          = {10.1016/j.engappai.2023.107121},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107121},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CB-SAGE: A novel centrality based graph neural network for floor plan classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automated voice command classification model based on an
attention-deep convolutional neural network for industrial automation
system. <em>EAAI</em>, <em>126</em>, 107120. (<a
href="https://doi.org/10.1016/j.engappai.2023.107120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a method was developed for utilizing voice commands with programmable logic controllers (PLCs) and supervisory control and data acquisition (SCADA) systems, which are commonly utilized in industrial automation. This approach incorporates artificial intelligence to enable human–machine interaction, aligning with the trends of Industry 4.0. A deep neural network was specifically designed for speech recognition, eliminating the need for reliance on any pre-existing speech-to-text engines. The objective was to create a model that is accurate and compact in size, making it suitable for embedded systems within industrial systems. To train the deep learning network, 21,600 sound files were generated. These files combined real factory noise with a synthetic dataset of human speech, forming a dataset comprising 60 different classes of voice commands. These commands encompassed actions like starting, stopping, and operating at various speeds for 10 motors controlled by the automation system. After applying the Mel-frequency cepstral coefficient (MFCC) to the voice commands, the resulting data was directly fed into the proposed network. The network achieved an impressive accuracy rate of 99.73%. Notably, the proposed network outperformed even networks several times its size.},
  archive      = {J_EAAI},
  author       = {Omur Aydogmus and Mustafa Can Bingol and Gullu Boztas and Turker Tuncer},
  doi          = {10.1016/j.engappai.2023.107120},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107120},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An automated voice command classification model based on an attention-deep convolutional neural network for industrial automation system},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A social network analysis-based model for failure mode and
effect analysis under linguistic preference relation environment.
<em>EAAI</em>, <em>126</em>, 107119. (<a
href="https://doi.org/10.1016/j.engappai.2023.107119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effect analysis (FMEA) is a proactive risk analysis technique widely used to improve the reliability and safety of complex systems in various industries. Generally, FMEA is a multidisciplinary team activity in which the trust relationships among experts have an influence on the risk assessment process and the risk priority of failure items. Furthermore, it is significant to obtain the risk ranking result of failure items with a high consistency degree in the group FMEA. Therefore, in this study, we aim to develop a new FMEA model based on double hierarchy hesitant linguistic preference relations to derive the risk priority of failure items considering experts&#39; social network. First, the risk assessments of experts are described by using the double hierarchy hesitant linguistic preference relations via pairwise comparisons of failure items. Second, the relative weights of FMEA experts are derived based on their trust relationships in social network and the consistency of failure risk evaluations. Third, consistency checking and repairing algorithm are performed to address experts’ self-contradictory opinions, and the risk priority of failure items is determined in line with their risk degrees. Finally, a practical risk evaluation case is provided to demonstrate the applicability of the proposed FMEA model, and a comparative analysis is conducted to illustrate its effectiveness and advantages.},
  archive      = {J_EAAI},
  author       = {Jia Huang and Wei Guo and Hua Shi and Hu-Chen Liu},
  doi          = {10.1016/j.engappai.2023.107119},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107119},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A social network analysis-based model for failure mode and effect analysis under linguistic preference relation environment},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart vibratory peening: An approach towards digitalisation
and integration of vibratory special process into smart factories.
<em>EAAI</em>, <em>126</em>, 107118. (<a
href="https://doi.org/10.1016/j.engappai.2023.107118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shot peening is a widely used technique in aerospace to enhance the fatigue life of a part. However, it leads to an increased surface roughness, which necessitates an additional Vibropolishing technique to improve the fatigue life and aerodynamic efficiency. Alternatively vibratory peening, a relatively new technology, can replace both Shot peening and Vibropolishing and achieve similar fatigue life and aerodynamic efficiency. This paper reports the development of a novel smart vibratory peening system, using which several experimental investigations are conducted to characterize the part and validate them using the conventional Almen strips. Data from the experimental investigations are used to train a machine learning model and predict the characteristics of the given part and hence eliminating the use of Almen strips. With the help of the feature redundancy removal technique, 79% of the redundant features were removed to retain 94% of the process information. The results show that out of various established machine learning models, the Kernel Ridge model demonstrated the best performance with an RMSE of 0.0443. With the introduction of the smart vibratory peening system, the overall process time has been significantly reduced by 76%.},
  archive      = {J_EAAI},
  author       = {Abhay Gopinath and Jeng Wei Teoh and Piyush Tagade and Gary Lee Kee Khoon and Thomas Haubold and A. Senthil Kumar},
  doi          = {10.1016/j.engappai.2023.107118},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107118},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Smart vibratory peening: An approach towards digitalisation and integration of vibratory special process into smart factories},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-invariant feature fusion networks for semi-supervised
generalization fault diagnosis. <em>EAAI</em>, <em>126</em>, 107117. (<a
href="https://doi.org/10.1016/j.engappai.2023.107117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machinery fault diagnosis based on deep learning methods is cost-effective to guarantee safety and reliability of mechanical systems. Due to the variability of machinery working condition and difficulty of data obtaining under different health states, it is desirable to enhance the generalization capability to unseen working conditions for the fault diagnosis models trained by available data sets under limited number of working conditions. Considering that labeling industrial data is also a laborious work, this paper proposes a novel semi-supervised domain generalization model, termed domain-invariant feature fusion networks (DIFFN) for intelligent fault diagnosis under unseen target working conditions. The main contributions are that, intra-domain-invariant features are considered to capture the intrinsic semantic information within the domain and are fused with inter-domain-invariant features to enhance the discrimination and generalization abilities in fault diagnosis. First, a domain-invariant representation learning method is established to learn the inter- and intra-domain-invariant features using two network branches and fuse them via a fusion module. Second, a mutual learning strategy is designed to enable the network branches and the fusion module to learn from each other, thereby improving the discrimination of the extracted features for accurate fault diagnosis. Lastly, a feature divergence maximization strategy is embedded between the two network branches to improve the generalization ability of the fault diagnosis model. Experiments on two bearing data sets demonstrate that the proposed model has better diagnostic accuracy and stability over state-of-the-art semi-supervised domain generalization methods, indicating its great potential for application in generalization fault diagnosis of machinery under unseen target working conditions.},
  archive      = {J_EAAI},
  author       = {He Ren and Jun Wang and Weiguo Huang and Xingxing Jiang and Zhongkui Zhu},
  doi          = {10.1016/j.engappai.2023.107117},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107117},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Domain-invariant feature fusion networks for semi-supervised generalization fault diagnosis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective optimisation of sustainable closed-loop
supply chain networks in the tire industry. <em>EAAI</em>, <em>126</em>,
107116. (<a
href="https://doi.org/10.1016/j.engappai.2023.107116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As environmental concerns and social legislation continue to gain importance, supply chain decision-makers are increasingly required to consider economic and ecological objectives. A potential strategy for mitigating sustainability issues entails the utilisation of discarded tyres through the process of recycling. Nevertheless, the establishment of a closed-loop supply chain that is both sustainable and profitable presents a noteworthy challenge. This study proposes a novel multi-objective mixed-integer linear programming model to design a sustainable closed-loop supply chain network in the tire industry. The objective of the model is to optimize the overall cost of the network, taking into account the environmental consequences related to the establishment of facilities, tire processing, and transportation. While metaheuristic algorithms have been extensively employed to solve network design problems, they are not very effective in handling large-scale networks. To overcome this limitation, our study introduces six new multi-objective evolutionary algorithms based on decomposition (MOEA/D) variants. The present study introduces a prospective methodology for devising supply chain networks that are sustainable in nature, while simultaneously ensuring a harmonious equilibrium between economic and environmental considerations. The efficacy of the proposed multi-objective mixed-integer linear programming model and its MOEA/D variants in addressing large-scale networks has been demonstrated through the obtained results. As such, this study contributes to sustainable supply chain management, which is becoming increasingly important in the current environment.},
  archive      = {J_EAAI},
  author       = {Reza Kiani Mavi and Seyed Ashkan Hosseini Shekarabi and Neda Kiani Mavi and Sobhan Arisian and Reza Moghdani},
  doi          = {10.1016/j.engappai.2023.107116},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107116},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective optimisation of sustainable closed-loop supply chain networks in the tire industry},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grey-box and ANN-based building models for multistep-ahead
prediction of indoor temperature to implement model predictive control.
<em>EAAI</em>, <em>126</em>, 107115. (<a
href="https://doi.org/10.1016/j.engappai.2023.107115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based predictive control (MPC) strategies for heating, ventilation, and air-conditioning (HVAC) systems present an opportunity to lower building energy consumption and operational costs. Such approaches rely on the development of a model to precisely forecast building thermal dynamics, such as room air temperature or heating/cooling rate, and make control-related decisions. The control-oriented modeling of building energy systems should be accurate in predicting indoor conditions and present low computational complexity. These features are the key challenge of implementing advanced control methods such as MPC. Extant studies on building modeling for MPC have focused on step-ahead forecasting techniques to forecast building thermal dynamics, while multistep-ahead forecasting is essential. Moreover, machine learning model suitable in case of the domain-based engineering expertise are also not available. To this aim, we perform a comparative analysis of the grey-box model based on a resistance-capacitance (RC) thermal network and a machine learning model composed of an artificial neural network (ANN) for multistep-ahead prediction of building thermal dynamics using current and historical data. Actual experimental data obtained from the Flexible Research Platform (FRP) in Oak Ridge National Laboratory (US) are used for estimation and validation purposes. The average root mean squared error (RMSE) of the grey-box and ANN models are 0.89 °C and 1.02 °C, respectively. The results indicate that the grey-box model outperforms the ANN model in the considered validation periods in terms of accuracy and prediction stability.},
  archive      = {J_EAAI},
  author       = {Abu Talib and Semi Park and Piljae Im and Jaewan Joe},
  doi          = {10.1016/j.engappai.2023.107115},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107115},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Grey-box and ANN-based building models for multistep-ahead prediction of indoor temperature to implement model predictive control},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust key parameter identification of dedicated hybrid
engine performance indicators via k-fold filter collaborated feature
selection. <em>EAAI</em>, <em>126</em>, 107114. (<a
href="https://doi.org/10.1016/j.engappai.2023.107114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dedicated hybrid engine technology using auxiliary electronic components has been proven as an energy-saving solution to public concerns about energy consumption and carbon emissions. This paper proposes a generic approach of K-fold filter-collaborated feature selection (KFFC-FS) to robustly identify the key parameters of three engine performance indicators, i.e., volumetric efficiency, thermal efficiency, and fuel consumption. By using this approach, five filters are collaborated to provide a robust rank of feature importance and avoid the feature overestimation caused by the single filter. Meanwhile, the K-fold cross validation method is introduced to avoid random precision issues and overfitting, further enhancing the robustness of key parameter identification for the independent engine performance indicators. In this research, the modelling data is collected from an experimental test bench with a BYD 1.5L gasoline engine. Under the basics of the studied three engine performance indicators by using a multiple-layer perceptron network, the proposed approach further reduces by at least 10.3% root-mean-square error (RMSE) and at least 30% reduction of the model inputs.},
  archive      = {J_EAAI},
  author       = {Xu He and Ji Li and Quan Zhou and Guoxiang Lu and Hongming Xu},
  doi          = {10.1016/j.engappai.2023.107114},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107114},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust key parameter identification of dedicated hybrid engine performance indicators via K-fold filter collaborated feature selection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A double-adaptive general variable neighborhood search for
an unmanned electric vehicle routing and scheduling problem in green
manufacturing systems. <em>EAAI</em>, <em>126</em>, 107113. (<a
href="https://doi.org/10.1016/j.engappai.2023.107113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more and more manufacturing factories have employed unmanned electric vehicles (UEVs) to perform the materials delivery, and efficient routing and scheduling approaches are required to improve the delivery efficiency. However, most of existing papers studied the routing problem of fuel vehicles or the drones. This paper investigates the optimization of UEVs delivery routes and charging strategies. Due to the limited payload capacity and battery capacity, the UEV must return to the depot multiple times to load the materials and go to the recharging station during the route to charge, and thus the problem is modeled as a multi-trip UEV routing and scheduling problem, which assigns the recharging station to the UEV’s route and optimizes a set of UEV’s trips. The investigated problem is firstly formulated as a mixed integer programming model. Then, considering the routing and scheduling challenges, we develop an efficient double-adaptive variable neighborhood search (DA-GVNS), which incorporates the general variable neighborhood search with a new adaptive mechanism, for this problem. The experimental results on the test and benchmark instances highlight that the DA-GVNS outperforms other existing algorithms. Furthermore, sensitivity analyses are conducted to study the impact of model’s characteristics on the optimality and complexity of solutions. Finally, a case study is proposed to present how the developed approach works for a manufacturing factory. This paper can offer decision-makers a valuable approach to construct a high-quality routing and scheduling scheme for the UEV delivery while providing potential managerial insights for implementing efficient green manufacturing systems.},
  archive      = {J_EAAI},
  author       = {Wenheng Liu and Mahjoub Dridi and Jintong Ren and Amir Hajjam El Hassani and Shuying Li},
  doi          = {10.1016/j.engappai.2023.107113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A double-adaptive general variable neighborhood search for an unmanned electric vehicle routing and scheduling problem in green manufacturing systems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating the blockchain-based healthcare supply chain
using interval-valued pythagorean fuzzy entropy-based decision support
system. <em>EAAI</em>, <em>126</em>, 107112. (<a
href="https://doi.org/10.1016/j.engappai.2023.107112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era, blockchain technology has emerged as a novel technique to maintain the operations of healthcare management systems. The global COVID-19 disease has led to increase in the utilization of technology for healthcare supply chain, patient data management, and claims settlement. Data management in healthcare industry is a complex procedure where multiple organizations offer appropriate supply chain facilities in everyday life. Inadequate data handling disrupts the supply chain, which has a longstanding impact on the healthcare region. Blockchain-based solutions are renowned for their ability to produce safe and traceable results and effective in the health sector for secure data retrieval and storage, resulting in more effectual product creation and tracking. These technologies can deliver data provenance, sponsors candid healthcare industry demands, and certifies the immutability of multi direction transactions. Due to involvement of multiple factors/criteria, the selection of an effective blockchain platform-based healthcare supply chain can be treated as a decision support system ( DSS ) problem. Thus, the objective of this paper is to present a novel interval-valued Pythagorean fuzzy DSS for evaluating the blockchain platforms for healthcare supply chain and selecting a suitable one with respect to multiple criteria and uncertainty. The proposed DSS framework is divided into three stages. First, some fairly aggregation operators are presented to combine the individual’s information and also discussed their desirable characteristics on interval-valued Pythagorean fuzzy sets (IVPFSs). Second, an integrated weighting tool is developed using entropy-based tool for objective weight of criteria and pivot pairwise relative criteria importance assessment (PIPRECIA) model for subjective weight of criteria with IVPFSs. For this purpose, new entropy is presented on IVPFSs. Third, the multi-attribute ideal-real comparative analysis (MAIRCA) model is developed with the combination of fairly aggregation operators, entropy-based weighting tool and PIPRECIA model with interval-valued Pythagorean fuzzy information. Further, the proposed DSS is used on a case study of blockchain platforms for healthcare supply chain evaluation, which confirms its applicability and usefulness. Sensitivity and comparative assessments are carried out to check the consistency, robustness and efficiency of the presented method.},
  archive      = {J_EAAI},
  author       = {Arunodaya Raj Mishra and Pratibha Rani and Adel Fahad Alrasheedi and Rajeev Dwivedi},
  doi          = {10.1016/j.engappai.2023.107112},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107112},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating the blockchain-based healthcare supply chain using interval-valued pythagorean fuzzy entropy-based decision support system},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient mining of concise and informative representations
of frequent high utility itemsets. <em>EAAI</em>, <em>126</em>, 107111.
(<a href="https://doi.org/10.1016/j.engappai.2023.107111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of frequent closed high utility itemsets (FCHUIs) and frequent generators of high utility itemsets (FGHUIs) is significant because they serve as important and concise representations of frequent high utility itemsets (FHUIs), offering a brief but essential summary that can be considerably smaller. Besides, they facilitate the generation of nonredundant high utility association rules that are crucial for decision-makers. However, the challenge lies in the difficulty of mining these representations due to scalability issues, high memory usage, and long runtimes, particularly when dealing with dense and large datasets. To address this issue, this paper proposes a novel approach for efficiently mining FCHUIs and FGHUIs using a novel weak lower bound named w l b u on the utility. The approach includes effective pruning strategies for early eliminating non-closed and/or non-generator high utility branches in the prefix search tree based on w l b u . These pruning strategies allow faster execution with lower memory usage. In addition, the paper presents two novel algorithms, FCGHUI-Miner and FGHUI-Miner, which can simultaneously discover both FGHUIs and FCHUIs or solely mine FGHUIs, respectively. The experimental results demonstrate that the proposed algorithms outperform state-of-the-art algorithms in terms of efficiency and effectiveness.},
  archive      = {J_EAAI},
  author       = {Thong Tran and Hai Duong and Tin Truong and Bac Le},
  doi          = {10.1016/j.engappai.2023.107111},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107111},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient mining of concise and informative representations of frequent high utility itemsets},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid path planning based on adaptive visibility graph
initialization and edge computing for mobile robots. <em>EAAI</em>,
<em>126</em>, 107110. (<a
href="https://doi.org/10.1016/j.engappai.2023.107110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new initialization method that combines adaptive visibility graphs and the A* algorithm to improve the exploration, accuracy, and computing efficiency of hybrid path planning for mobile robots. First, segments/links in the full visibility graphs are removed randomly in an iterative and adaptive manner, yielding adaptive visibility graphs. Then the A* algorithm is applied to find the shortest paths in these adaptive visibility graphs. Next, high-quality paths featuring low fitness values are chosen to initialize the subsequent heuristic optimization in hybrid path planning. Specifically, in the present study, the genetic algorithm (GA) is implemented on a CPU/GPU edge computing device (Jetson AGX Xavier) to exploit its massively parallel processing threads, and the strategy for judicious CPU/GPU resource utilization is also developed. Numerical experiments are conducted to determine proper hyperparameters and configure GA with balanced performance. Various optimal paths with differential consideration of practical factors for robot path planning are obtained by the proposed method. Compared to the other benchmark methods, ours significantly improves the diversity of initial path and exploration, optimization accuracy, and computing speed (within 5 s with most less than 2 s). Furthermore, real-time experiments are carried out to demonstrate the effectiveness and application of the proposed algorithm on mobile robots.},
  archive      = {J_EAAI},
  author       = {Junlin Ou and Seong Hyeon Hong and Ge Song and Yi Wang},
  doi          = {10.1016/j.engappai.2023.107110},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107110},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid path planning based on adaptive visibility graph initialization and edge computing for mobile robots},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving collaborative recommender system using hybrid
clustering and optimized singular value decomposition. <em>EAAI</em>,
<em>126</em>, 107109. (<a
href="https://doi.org/10.1016/j.engappai.2023.107109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of internet and big data, recommender systems are necessary to filter out useless information. Collaborative filtering ( CF ) is one of the most successful technique used in recommender systems, this technique suffers from a large number of users and items, or the scalability issue. In this paper, a new hybrid method based on K-means clustering ( KM ) and Singular Value Decomposition (SVD) which uses evolutionary algorithms is proposed to deal with scalability issue. On the one hand, KM optimized by Particle Swarm Optimization ( PSO ) and denoising by Density-Based Spatial Clustering of Applications with Noise ( DBSCAN ) is used to cluster users and reduce the number of comparisons between the target user and other users. On the other hand, SVD optimized by Genetic Algorithm ( GA ) is used to reduce the number of items. The proposed method is assessed on three standard datasets and the results are compared with basic CF and other extended versions that use clustering algorithms, evolutionary algorithms and dimensionality reduction techniques. The results show that our proposed method performed better than other methods in terms of precision , recall and MAE , and the scalability problem was improved by reducing the time complexity. Also, the combined clustering method was optimized in terms of Davies-Bouldin and the Dunn&#39;s index compared to the basic clustering methods.},
  archive      = {J_EAAI},
  author       = {Zahra Movafegh and Abdoreza Rezapour},
  doi          = {10.1016/j.engappai.2023.107109},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107109},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving collaborative recommender system using hybrid clustering and optimized singular value decomposition},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved unified domain adversarial category-wise
alignment network for unsupervised cross-domain sentiment
classification. <em>EAAI</em>, <em>126</em>, 107108. (<a
href="https://doi.org/10.1016/j.engappai.2023.107108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain sentiment analysis (CDSA) aims to learn transferable knowledge from the source domain to facilitate the sentiment polarity classification on the target domain of lacking labeled data. Currently, two types of unsupervised domain adaptation (UDA) methods are widely used in CDSA tasks. One employs the domain adversarial strategy to extract domain-invariant features, and the other utilizes the distance metric strategy to reduce domain distribution discrepancy. However, the fine-grained domain-specific information related to categories aligned between domains is not preserved, which suppresses the performance of target-domain classification. To overcome the mentioned problem, a unified Domain Adversarial Category-wise Alignment Network (DACAN) was proposed in this paper. An integrated network was constructed with progressive multi-level feature learning. Specifically, a feature extraction module was constructed with parameter sharing between two domains at low-level text feature extraction layers. The domain adversarial module was added to enable shared knowledge transfer by extracting domain-invariant information and by updating the shared parameters at the feature extraction layers. A category-wise alignment module was built to achieve local distribution alignment at the high dimension-level semantic layers guided by fine-grained category structure information. Meanwhile, joint constraint was established with domain-invariant constraint based on domain adversarial, and domain-consistency constraint based on category-wise alignment. Comprehensive experiments were conducted on two standard Amazon review datasets. The results show that DACAN outperforms other state-of-the-art UDA methods by 0.7% and 1.1% on the two- and three-category CDSA tasks, respectively. Also, better performance results are achieved with a synergistic UDA scheme compared with a single UDA scheme.},
  archive      = {J_EAAI},
  author       = {Xibin Jia and Chen Li and Meng Zeng and Luo Wang and Qing Mi},
  doi          = {10.1016/j.engappai.2023.107108},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107108},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved unified domain adversarial category-wise alignment network for unsupervised cross-domain sentiment classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New players in intelligent transportation: Autonomous segway
in a dynamic environment. <em>EAAI</em>, <em>126</em>, 107107. (<a
href="https://doi.org/10.1016/j.engappai.2023.107107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper heralds a mathematical treatment of Segways as autonomous robots for personal transportation and deliveries and courier services in constrained dynamic environments from a bird’s-eye view. New velocity-based stabilizing controllers of an autonomous nonholonomic two-wheeled self-balancing personalized Segway robot are extracted from a total potential developed by employing the Lyapunov-based Control Scheme (LbCS) for navigation in a partially known environment. Velocity controllers’ cost and time effectiveness and efficiency result from the interaction of the three prominent pillars of LbCS: smoothest, shortest, and safest path for motion planning. Furthermore, the autonomous personal transporter has an obstacle avoidance sensor with a limited detection range ideal for fast navigation in dynamic environments with narrow corridors, tracks, and pathways. This also successfully facilitates navigation in a partially known environment where the sensors only receive and avoid static and dynamic obstacles in a limited range. The results are numerically validated, and the efficacy of the new controllers is exemplified via computer simulations, which illustrate the forward, backward, and zero-turn radius maneuvers of the Segway robot. Introducing the particular autonomous personal transporter would contribute to transportation systems of smart cities.},
  archive      = {J_EAAI},
  author       = {Sandeep A. Kumar and Bibhya Sharma and Jito Vanualailai and Avinesh Prasad and Ravinesh Chand},
  doi          = {10.1016/j.engappai.2023.107107},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107107},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {New players in intelligent transportation: Autonomous segway in a dynamic environment},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Thermographic image-based diagnosis of failures in
electrical motors using deep transfer learning. <em>EAAI</em>,
<em>126</em>, 107106. (<a
href="https://doi.org/10.1016/j.engappai.2023.107106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosing faults in electric motors is a task of great importance for the Industrial Sector since stopping these types of equipment can cause several invaluable losses for industries. To address the problems associated with quality and quantify motor data available in the literature, an intelligent fault diagnosis model for electric motors using Deep Transfer Learning (DTL), and InfraRed Thermal (IRT) images were studied. For that end, publicly available dataset containing 11 fault conditions were balanced and fed into a Convolutional Neural Network (CNN) pre-trained with the ImageNet dataset. Then, a cropping layer is added to the network to delimit the regions of interest and finally a hyperparameter optimization is obtained using Random Search (RS). The proposal was evaluated on four CNN architectures: InceptionV3, MobileNetV2, EfficientNetSV2, and RegNetX002. The research presented good results for fault classification, reaching 98.18% accuracy for the RegNetX002 model in 3245 s. All the experiments based on deep transfer learning presented great potential adaptation in the classification of problems when applied to the diagnosis of failures of machinery using data InfraRed Thermal.},
  archive      = {J_EAAI},
  author       = {Luiz Fillipe Dahmer dos Santos and Jorge Luiz dos Santos Canuto and Rodrigo Clemente Thom de Souza and Linnyer Beatrys Ruiz Aylon},
  doi          = {10.1016/j.engappai.2023.107106},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107106},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermographic image-based diagnosis of failures in electrical motors using deep transfer learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AFcIHNet: Attention feature-constrained network for single
image information hiding. <em>EAAI</em>, <em>126</em>, 107105. (<a
href="https://doi.org/10.1016/j.engappai.2023.107105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image information hiding aims to obtain a stegano image by hiding a secret image within a cover image. Recently, deep neural network (DNN) based information hiding methods have been advanced extensively. However, it is difficult for them to preserve the spatial information at different scales on each channel feature map in the stegano image, largely because of a lack of effective features and feature fusion. In this paper, a bi-channel attention feature-constrained pixel-shuffle information hiding network (AFcIHNet) is proposed to efficiently enhance the detailed spatial information in the stegano image. First, the invertible neural network (INN) is employed for the information hiding task, which is adaptively constrained by the proposed bi-channel attention module (Bi-AM). The capability of the Bi-AM module is further enhanced by the introduction of a novel attention loss function. In addition, to take full advantage of the attention based feature fusion mechanism that combines the global and local contexts of the features, we used the Squeeze and Concat (SPC) module with adaptive branching factors, the model can hierarchically approach the input feature map from local to global. Extensive experiments on the DIV2K and COCO datasets show that the proposed method can produce competitive stegano images when compared with some state-of-the-art methods. Finally, we can get a secret image that is closer to the original image. Peak signal-to-noise ratio (PSNR), structural similarity (SSIM) and average pixel difference (APD) were used to evaluate the experimental effects of cover and stegano images as well as secret and recovered secret images. The experimental results show that the obtained stegano and cover images are more indistinguishable, and the recovered secret image is closer to the original image. Overall, the overall performance is improved by nearly 0.8% compared to the existing baseline model.},
  archive      = {J_EAAI},
  author       = {Xingwang Jia and Huamei Xin and Lingchen Gu and Hao Wang and Jiande Sun and Wenbo Wan},
  doi          = {10.1016/j.engappai.2023.107105},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107105},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AFcIHNet: Attention feature-constrained network for single image information hiding},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Highly imbalanced fault classification of wind turbines
using data resampling and hybrid ensemble method approach.
<em>EAAI</em>, <em>126</em>, 107104. (<a
href="https://doi.org/10.1016/j.engappai.2023.107104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based incipient fault diagnostic techniques have achieved surprisingly well in wind turbines. Due to component failures, wind turbines must undergo active maintenance, substantially influencing revenue and power generation. Unfortunately, there are consistently uneven data distributions between samples with faults and those without faults, resulting in incorrect fault classification. Wind turbine fault classification has a significant data imbalance problem, compromising learning attention for majority and minority classes. Machine learning methodologies based on Generative Adversarial Networks (GAN), over-sampling, and under-sampling techniques for generating synthetic data have been widely employed to address the imbalance data problem. However, the traditional synthetic minority oversampling technique (SMOTE) accomplishes oversampling using linear interpolation between close minority class samples, which could be confusing, subpar, and indistinguishable from the majority class. This study suggests combining over and under-sampling using adaptive SMOTE and edited nearest neighbors (ASMOTE-ENN) that incorporate over-sampling with adaptive SMOTE and under-sampling with ENN to improve the quality of the generated samples. With this resampling technique, noise in an imbalanced dataset is reduced on three levels by using an adaptive nearest neighbor selection algorithm to find the nearest neighbors that are visible. Then use SMOTE to create samples that precisely fall into the minority class, and later use the ENN technique to eliminate instances that contribute to noise afterwards. Resampling data created by combining over- and under-sampling approaches to match the data distribution over all classes is the foundation of the suggested method’s efficacy. A hybrid ensemble method is used for effective classification, including boosting, bagging, and stacking techniques. The original unbalanced and balanced data using the ASMOTE-ENN algorithm were classified using the proposed hybrid ensemble method. The classification results show that the proposed strategy is more accurate than a few imbalanced fault diagnosis techniques.},
  archive      = {J_EAAI},
  author       = {Subhajit Chatterjee and Yung-Cheol Byun},
  doi          = {10.1016/j.engappai.2023.107104},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107104},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Highly imbalanced fault classification of wind turbines using data resampling and hybrid ensemble method approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel noise-robustness and rotation-invariant LADAR point
cloud target classification method. <em>EAAI</em>, <em>126</em>, 107103.
(<a href="https://doi.org/10.1016/j.engappai.2023.107103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying targets of LAser Detection And Ranging (LADAR) point clouds that are affected by noise and different poses throws a significant challenge. This paper proposes a novel LADAR point cloud target classification method that is both noise-robust and rotation-invariant. Specifically, the proposed method transforms the point cloud target into a slice image that is resilient to noise and holds rotation-invariance. Next, a designed 2D Convolutional Neural Network (CNN) is utilized to classify the corresponding point cloud target based on the slice image. To overcome the challenge of lacking prior knowledge about the discriminative features of the slice image, the 2D CNN is designed with the Local Importance-based Pooling (LIP) layer. This layer extracts the discriminative feature in a data-driven manner, thereby improving the accuracy of the classification process. The proposed method is evaluated through multiple experiments on the public ModelNet40 dataset. The experimental results demonstrate that the designed LIP-CNN can better learn the discriminative features of the slice image, achieving high classification accuracy. Moreover, the proposed slice-image-based method is capable of accurately classifying the target, even in the presence of noise and different poses.},
  archive      = {J_EAAI},
  author       = {Shangwei Guo and Jun Li and Zhengchao Lai and Shaokun Han},
  doi          = {10.1016/j.engappai.2023.107103},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107103},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel noise-robustness and rotation-invariant LADAR point cloud target classification method},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metaheuristics in circular supply chain intelligent systems:
A review of applications journey and forging a path to the future.
<em>EAAI</em>, <em>126</em>, 107102. (<a
href="https://doi.org/10.1016/j.engappai.2023.107102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics have become increasingly popular due to the complex and extensive optimization models that have emerged in the circular supply chain field. This study aims to fill a gap in the literature by conducting a comprehensive analysis of the role of metaheuristics in reverse logistics and circular supply chains. The methodology involves a meticulous review of 77 meticulously selected research articles published until 2023. The findings of our analysis indicate a significant increase in the number of publications in recent times. Through descriptive and content analyses, key themes emerge, including types of metaheuristics used, addressed supply chain issues, and circularity aspects. This study presents a novel approach to analyzing the application of metaheuristics from a circularity perspective. It also introduces a conceptual framework and suggests cluster-based future research directions. The results of the study hold valuable implications for researchers and other stakeholders in terms of understanding and advancement of the field.},
  archive      = {J_EAAI},
  author       = {Pankaj Kumar Detwal and Rajat Agrawal and Ashutosh Samadhiya and Anil Kumar},
  doi          = {10.1016/j.engappai.2023.107102},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107102},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Metaheuristics in circular supply chain intelligent systems: A review of applications journey and forging a path to the future},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A theoretical analysis of continuous firing condition for
pulse-coupled neural networks with its applications. <em>EAAI</em>,
<em>126</em>, 107101. (<a
href="https://doi.org/10.1016/j.engappai.2023.107101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pulse-coupled neural network (PCNN) has become a popular biology-inspired model because of its remarkable performance, such as image fusion, segmentation, and recognition. Although the PCNN is an unsupervised neural network model, its parameters are often manually adjusted, which leads to the shortcomings of being time-consuming, verbose, and with bad consistency. Researchers have conducted work on the PCNN&#39;s neurodynamic analysis and parameter settings. However, most of these works were proposed for specific application areas, and there are no widely recognized and accepted methods or theories for PCNN parameter setting at present. Thus, how to reduce the difficulty of parameter setting based on neurodynamic analysis is a very important research area for applying PCNN. In this work, we proposed a general formulae of a continuous firing condition based on the dynamic analysis of PCNN neurons to avoid constructing an invalid model and to learn the neurons&#39; firing characteristics. The results obtained from the proposed formulae were used to explore the usability of the PCNN parameter setting theory. We first utilized the pre-existing theory of the PCNN firing period to examine the rationality of our theory, and then we also introduce an image fusion method using our theory and whale optimization algorithm to verify our method and theory, besides, numerical tests and experiments on common images were also performed to verify our theory. Experimental results show that our method and theory is effective.},
  archive      = {J_EAAI},
  author       = {Xin Jin and Pingfan Zhang and Youwei He and Qian Jiang and Puming Wang and Jingyu Hou and Wei Zhou and Shaowen Yao},
  doi          = {10.1016/j.engappai.2023.107101},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107101},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A theoretical analysis of continuous firing condition for pulse-coupled neural networks with its applications},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crossing points detection in plain weave for old paintings
with deep learning. <em>EAAI</em>, <em>126</em>, 107100. (<a
href="https://doi.org/10.1016/j.engappai.2023.107100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the forensic studies of painting masterpieces, the analysis of the support is of major importance. For plain weave fabrics, the densities of vertical and horizontal threads are used as main features, while angle deviations from the vertical and horizontal axis are also of help. These features can be studied locally through the canvas. In this work, deep learning is proposed as a tool to perform these local densities and angle studies. We trained the model with samples from 36 paintings by Velázquez, Rubens or Ribera, among others. The data preparation and augmentation are dealt with at a first stage of the pipeline. We then focus on the supervised segmentation of crossing points between threads. The U-Net with inception and Dice loss are presented as good choices for this task. Densities and angles are then estimated based on the segmented crossing points. We report test results of the analysis of a few canvases and a comparison with methods in the frequency domain, widely used in this problem. We concluded that this new approach successes in some cases where the frequency analysis tools fail, while improves the results in others. Besides, our proposal does not need the labeling of part of the to be processed image. As case studies, we apply this novel algorithm to the analysis of two pairs of canvases by Velázquez and Murillo, to conclude that the fabrics used came from the same roll.},
  archive      = {J_EAAI},
  author       = {A. Delgado and Laura Alba-Carcelén and Juan J. Murillo-Fuentes},
  doi          = {10.1016/j.engappai.2023.107100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Crossing points detection in plain weave for old paintings with deep learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep deterministic policy gradient based multi-UAV control
for moving convoy tracking. <em>EAAI</em>, <em>126</em>, 107099. (<a
href="https://doi.org/10.1016/j.engappai.2023.107099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of multiple unmanned aerial vehicles (UAV) involve complex control dynamics for accomplishing any task. This paper employs a multi-UAV system for continuous tracking and end-to-end coverage of a moving convoy of vehicles to provide security and surveillance cover. The coverage is achieved by maintaining the moving convoy within the overlapping Field-of-Views (FoVs) of the UAVs. To learn the controls of the autonomous multi-UAV system, we propose a deep reinforcement learning based multi-agent actor-critic method called GPR-MADDPG. The proposed method makes use of Gaussian Process Regression (GPR) to estimate an unbiased and stable target value of the critic. Further, the kernel function of the GPR model has been adapted to keep the high variance in the convoy trajectory in check. The rewards for training the multi-UAV system are formulated to maximize the end-to-end convoy coverage by optimizing the overlaps between the FoVs along with minimizing the tracking error. Experiments were performed on real-world road trajectories of varying complexities along with varying convoy speeds and the number of UAVs. Further tests were performed using a simulator with a real-world physics engine. The experiments show that the proposed GPR-MADDPG model results in the least amount of overlapping error and accumulates maximum reward as compared to other prevalent approaches in the literature.},
  archive      = {J_EAAI},
  author       = {Armaan Garg and Shashi Shekhar Jha},
  doi          = {10.1016/j.engappai.2023.107099},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107099},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep deterministic policy gradient based multi-UAV control for moving convoy tracking},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel shape-based averaging algorithm for time series.
<em>EAAI</em>, <em>126</em>, 107098. (<a
href="https://doi.org/10.1016/j.engappai.2023.107098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series averaging is one of the essential subroutines in time series analysis. DTW Barycenter Averaging (DBA) has proven to be an effective and popular DTW-based time series averaging algorithm. However, DBA lacks the ability to average time series in the time domain, making it sensitive to initialization. In this research, we propose a novel shape-based time series averaging algorithm, called Shape DTW Weighted Averaging (ShapeDWA), to address the shortcomings of DBA. The proposed ShapeDWA algorithm combines the advantages of the DBA and the Cubic-spline DTW (CDTW) averaging methods. The concepts of time index averaging and re-sampling in the CDTW algorithm are incorporated into the DBA algorithm, giving ShapeDWA the ability to average a set of time series in both the amplitude and time domains. Moreover, ShapeDWA utilizes a weighed average instead of the barycenter average in DBA, which effectively attenuate the effects of noise, outliers, and local amplitude differences between the time series. To qualitatively evaluate and compare the proposed time series averaging algorithm, two metrics have been developed: average discrepancy distance and average time distortion. Extensive experimental results on the UCR time series database illustrate the superior performance of ShapeDWA over DBA and SSG, with an average reduction of 23.42% and 24.89% for average discrepancy distance, and 18.76% and 19.81% for average time distortion. Furthermore, the template matching-based classification experiment shows that ShapeDWA combined with these two developed metrics improves the classification rate by 17.07% and 16.42% compared to DBA and SSG, respectively.},
  archive      = {J_EAAI},
  author       = {Yutao Liu and Yong-An Zhang and Ming Zeng and Jie Zhao},
  doi          = {10.1016/j.engappai.2023.107098},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107098},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel shape-based averaging algorithm for time series},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent approach for predicting overbreak in
underground blasting operation based on an optimized XGBoost model.
<em>EAAI</em>, <em>126</em>, 107097. (<a
href="https://doi.org/10.1016/j.engappai.2023.107097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The occurrence of overbreak in tunnels excavated with the drill-and-blast technique is a common phenomenon that has significant impacts on structure safety and construction costs. Accurate prediction of overbreak is crucial for optimizing the construction schedule and diminishing damages. This study proposed a data-driven method that integrated extreme gradient boosting (XGBoost) and Bayesian optimization (BO) algorithms to predict overbreak extent. Firstly, 250 overbreak samples were collected from three underground mines, and eight independent factors that may affect overbreak were identified. Subsequently, the BO–XGBoost prediction model was established, and Spearman correlation analysis and sensitivity analysis were conducted to analyze the relation between overbreak and influencing factors. Finally, the proposed BO–XGBoost model was employed to forecast the overbreak in another two underground mines. The experimental results indicated that the proposed BO–XGBoost model outperformed other models, including Random Forests (RF), Support Vector Machine (SVM), BO–RF, BO–SVM, and XGBoost models, with root mean square error ( RMSE ), mean absolute error ( MAE ), and determination coefficient ( R 2 ) values of 0.888, 0.619 and 0.935, respectively. Additionally, statistical analysis using Friedman Test (FT) and Wilcoxon Signed-Rank Test (WSRT) demonstrated the efficacy of the proposed model. The results suggested that tunnel diameter ( D ) was the most significant factor affecting overbreak, followed by RMR , periphery hole burden ( SP ) and uniaxial compressive strength ( UCS ). The proposed method accurately forecasted overbreak extents at different mines, with errors between the predicted and observed overbreaks of less than 6%. In summary, the proposed BO–XGBoost model can provide valuable guidance for predicting blast-induced overbreak in mining and tunneling operations.},
  archive      = {J_EAAI},
  author       = {Zhixian Hong and Ming Tao and Leilei Liu and Mingsheng Zhao and Chengqing Wu},
  doi          = {10.1016/j.engappai.2023.107097},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107097},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intelligent approach for predicting overbreak in underground blasting operation based on an optimized XGBoost model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CFFR-net: A channel-wise features fusion and recalibration
network for surgical instruments segmentation. <em>EAAI</em>,
<em>126</em>, 107096. (<a
href="https://doi.org/10.1016/j.engappai.2023.107096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical instrument segmentation plays a crucial role in robot-assisted surgery by furnishing essential information about instrument location and orientation. This information not only enhances surgical planning but also augments the precision and safety of procedures. Despite promising strides in recent research on surgical instrument segmentation, accuracy still faces obstacles due to local feature processing limitations, surgical environment complexity, and instrument morphological variability. To address these challenges, we introduced the channel-wise features fusion and recalibration network (CFFR-Net). This network utilizes a dual-stream mechanism, combining a context-guided block and dense block for feature extraction. The context-guided block captures a variety of contextual information by using different dilation rates. Additionally, CFFR-Net employs a fusion mechanism that harmonizes context-guided and dense streams. This integration, along with the inclusion of Squeeze-and-Excitation attention, enhances both the precision and robustness of semantic instrument segmentation. We performed experiments using two publicly available datasets for surgical instrument segmentation: the Kvasir-instrument and Endovis2017 datasets. The results of these experiments were highly encouraging, as our proposed model exhibited remarkable performance on both datasets compared to the state-of-the-art methods. On the Kvasir-instrument set, our model achieved a Dice score of 95.84% and mean intersection over union (mIOU) value of 92.40%. Similarly, on the Endovis2017 set, it obtained a Dice score of 95.47% and mIOU value of 93.02%.},
  archive      = {J_EAAI},
  author       = {Tahir Mahmood and Jin Seong Hong and Nadeem Ullah and Sung Jae Lee and Abdul Wahid and Kang Ryoung Park},
  doi          = {10.1016/j.engappai.2023.107096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CFFR-net: A channel-wise features fusion and recalibration network for surgical instruments segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on decision-level fusion method based on structural
causal model in system-level fault detection and diagnosis.
<em>EAAI</em>, <em>126</em>, 107095. (<a
href="https://doi.org/10.1016/j.engappai.2023.107095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, system-level fault detection and diagnosis (FDD) research often uses correlation-based machine learning methods combined with multiple heterogeneous diagnosis methods to improve the fault detection rate (FDR), that is, decision-level fusion. Since it does not take into account the causal direction of the decision relationship, it will affect the realization of the fusion objectives, and lead to the reduction of the fusion range and the decrease of the global decision on FDR. In this regard, the structural causal model (SCM), a commonly used causal model in causal science, can use the causal graph to ensure causal direction of fusion, and the structural equation can be used to achieve fusion objectives to increase FDR, which can improve this problem. In this paper, we propose seven fusion objectives according to the diagnostic advantage interval of each preliminary method, and use SCM to construct causal graph and structural equation to achieve decision-level fusion according to the proposed seven fusion objectives, thereby improving FDR. The proposed method is validated through the simulation platform Tennessee Eastman process. We choose to combine the prediction results of Linear Discriminant Analysis method and Gaussian Naive Bayes method to achieve decision-level fusion. The results show that compared with the single method and the Bayesian network decision-level fusion method, the proposed method can achieve the best results in the FDR of each single system state and average FDR, and the above indicators are significantly improved.},
  archive      = {J_EAAI},
  author       = {Haoyuan Pu and Zhi Chen and Jie Liu and Xiaohua Yang and Changan Ren and Hua Liu and Yifan Jian},
  doi          = {10.1016/j.engappai.2023.107095},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107095},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on decision-level fusion method based on structural causal model in system-level fault detection and diagnosis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). U-SMR: U-SwinT &amp; multi-residual network for fabric
defect detection. <em>EAAI</em>, <em>126</em>, 107094. (<a
href="https://doi.org/10.1016/j.engappai.2023.107094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabric defect detection methods based on deep networks are widely used in the textile industry, but they often suffer from poor model generalization and blurry edge detection. To resolve these challenges, we propose a novel network called “U-SMR Net”, which integrates global contextual features, defect detail features, and high-level semantic features through the combination of ResNet-50 and Swin Transformer modules. Our U-SMR network includes a lightweight multiscale feature extraction module, the dual-branch pyramid Module (DBPM), which is nested to preserve high-resolution, shallow semantic information. We propose a recursive multi-level residual decoding block for multiscale fusion to refine, filter, and enhance input characteristics, generating prediction maps at multiple stages, and by employing an improved binary cross entropy loss function to supervise saliency mapping. The experimental results based on four groups from ZJU-Leaper dataset demonstrate the superior performance of our approach compared to other competitive methods by achieving an average f m e a s u r e score of 75.33%, and finally testing results from both ZJU-Leaper-Total dataset and the HKU-Fabric dataset further support our U-SMR Net’s validity and generalization ability.},
  archive      = {J_EAAI},
  author       = {Hao Qu and Lan Di and Jiuzhen Liang and Hao Liu},
  doi          = {10.1016/j.engappai.2023.107094},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107094},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {U-SMR: U-SwinT &amp; multi-residual network for fabric defect detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosting fish counting in sonar images with global attention
and point supervision. <em>EAAI</em>, <em>126</em>, 107093. (<a
href="https://doi.org/10.1016/j.engappai.2023.107093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically counting fish in sonar images has been attracting increasing attention in recent years because extreme efforts are needed in manual counting. Density map regression provides a promising approach in the counting field, but two obstacles are placed in front of fish counting in low resolution sonar images: the difficulty in distinguishing fish from the similar background noise and the inconsistency between the strip-shaped fishes in input images and dot-shaped ground truth density map. To address these issues, we present GPNet, a novel encoder-decoder network with global attention and point supervision, to boost sonar image-based fish counting accuracy. To alleviate the impact of background noise, we incorporate a segmentation module (SM) with global self-attention to the neck of the network to identify the fish region and space out background noise. Furthermore, feature enhancement modules (FEM) with a global receptive field are introduced to the encoder to enhance the feature representation and discrimination. To break down the performance upper bound resulting from target shape inconsistency between input and ground truth, we leverage fish center coordinates instead of the Gaussian density map to supervise the network training directly. Extensive experiments on a challenging public sonar image-based fish counting dataset, the ARIS dataset, demonstrate that GPNet achieves state-of-the-art performance both in counting accuracy and noise removal.},
  archive      = {J_EAAI},
  author       = {Yunhong Duan and Shubin Zhang and Yang Liu and Jincun Liu and Dong An and Yaoguang Wei},
  doi          = {10.1016/j.engappai.2023.107093},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107093},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Boosting fish counting in sonar images with global attention and point supervision},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Self-supervised temporal autoencoder for egocentric action
segmentation. <em>EAAI</em>, <em>126</em>, 107092. (<a
href="https://doi.org/10.1016/j.engappai.2023.107092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an egocentric video, action temporal segmentation aims to temporally segment the video into basic units, each depicting an action. As the camera is constantly moving, some important objects may disappear in some consecutive frames and cause an abrupt change in the visual content. Recently works fail to deal with this condition in the absence of manually annotating abundant frames. In this study, we propose a temporal-aware clustering method for egocentric action temporal segmentation: a self-supervised temporal autoencoder (SSTAE). Instead of directly learning visual features, the SSTAE is implemented by encoding the preceding target frame and predicting subsequent frames in the temporal relationship domain, which takes into account the local temporal consistency. Our proposed algorithm is guided by the reconstruction and predicted losses. Consequently, local temporal contexts are naturally integrated into the feature representation, and a clustering step is performed. Experiments on three egocentric datasets demonstrate the our proposed approach outperforms the state-of-the-art methods by clustering Accuracy(ACC) 7.57%, Normalized Mutual Information(NMI) 8.17%, Adjusted Rand Index(ARI) 8.6%.},
  archive      = {J_EAAI},
  author       = {Mingming Zhang and Dong Liu and Shizhe Hu and Xiaoqiang Yan and Zhongchuan Sun and Yangdong Ye},
  doi          = {10.1016/j.engappai.2023.107092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised temporal autoencoder for egocentric action segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A structurally re-parameterized convolution neural
network-based method for gearbox fault diagnosis in edge computing
scenarios. <em>EAAI</em>, <em>126</em>, 107091. (<a
href="https://doi.org/10.1016/j.engappai.2023.107091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gearboxes operate in harsh environments. Cloud-based techniques have been previously adopted for fault diagnosis in Gearboxes. Cloud-based fault diagnosis methods are prone to time delays and loss of information. Therefore, edge computing-based fault diagnosis becomes an option. However, with limited hardware resources for edge devices, balancing the diagnostic capabilities of the model with operating performance becomes a challenge. This paper proposes a lightweight convolutional neural network for gearbox fault diagnosis in edge computing scenarios to achieve an accurate diagnosis and lightweight deployment of models. By constructing the Mel-Frequency Cepstral Coefficients (MFCC) feature matrix of input data, the methodology can suppress noise interference and improve diagnostic accuracy. Based on the structural re-parameterization, the model structure transforms from multiple branches at training time to a single branch at inference time. This improves the inference speed of the model and reduces the hardware cost when the model is deployed while ensuring that the diagnostic capability of the model remains unchanged. Validation experiments were conducted on a public dataset and a custom experimental device, using the NVIDIA Jetson Xavier NX kit as the edge computing platform. According to the experiment result, after extracting the MFCC feature matrix, the average diagnostic accuracy rate in the noisy environment of the presented methodology is improved by 12.22% and 9.44%, respectively. After structural re-parameterization, the Memory of the model decreases by 52.58%, and the inference speed is increased by 38.83%.},
  archive      = {J_EAAI},
  author       = {Yanzhi Wang and Jinhong Wu and Ziyang Yu and Jiexiang Hu and Qi Zhou},
  doi          = {10.1016/j.engappai.2023.107091},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107091},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A structurally re-parameterized convolution neural network-based method for gearbox fault diagnosis in edge computing scenarios},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CrowdDCNN: Deep convolution neural network for real-time
crowd counting on IoT edge. <em>EAAI</em>, <em>126</em>, 107089. (<a
href="https://doi.org/10.1016/j.engappai.2023.107089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety and security of crowded places is a major concern for both the government and the public. Accurately and quickly estimating the number of people in a crowd is crucial for public safety, urban planning, and traffic monitoring. The existing methods have a minimum mean square error of 0.89 and require high storage space, making them inappropriate for crowd counting using low-computation and small-storage devices like single-board computers. Furthermore, these methods suffer from prediction time lag and are not suitable for live streaming. To tackle these challenges, this paper proposes a Deep Convolution Neural Network-based ‘CrowdDCNN’ model for crowd counting. This model reduces the value of mean square error by 0.29 and the size of the model by 80.01%. Additionally, the prediction time was decreased to 700 ms. Further, the ‘NoLag’ algorithm introduced in this paper is efficient in live crowd counting. Its O(1) time and space complexity make it appropriate for all devices, including single-board computers, laptops, and GPUs. The reported 0-p value during statistical analysis using Wilcoxon test, Friedman rank test, and paired t-test validates the superiority of the proposed model.},
  archive      = {J_EAAI},
  author       = {Rugved Chavan and Aravind kanamarlapudi and Geeta Rani and Priyam Thakkar and Vijaypal Singh Dhaka},
  doi          = {10.1016/j.engappai.2023.107089},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107089},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CrowdDCNN: Deep convolution neural network for real-time crowd counting on IoT edge},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UACNet: A universal automatic classification network for
microseismic signals regardless of waveform size and sampling rate.
<em>EAAI</em>, <em>126</em>, 107088. (<a
href="https://doi.org/10.1016/j.engappai.2023.107088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In microseismic monitoring, various types of vibration events are often collected. Realizing the automatic identification of microseismic events in many suspected events is the basis of monitoring timeliness. However, due to the different sampling methods of microseismic data provided by different products, the data often contains different waveform sizes and sampling frequencies. This makes it difficult for existing approaches to be widely used in different projects without data preprocessing. In this paper, we propose the Universal Automatic Classification Network (UACNet), a deep learning approach that automatically identifies microseismic data in engineering without preprocessing. The UACNet model includes multiple convolution layers, adaptive average pooling layers, fully connected layers, and UAC blocks. UAC block is a residual structure with multiple convolutional layers and reset and update gates. The adaptive average pooling layer unifies the input size, and the UAC block functions as a feature extraction network to mine sufficient features from data. We test the proposed UACNet on engineering data and compare it with existing common and advanced methods. As a result, UACNet passed the ablation study, and the classification accuracy of UACNet is 95.62%, which is higher than 89.14% of CNN, 91.24% of ResNet, 91.04% of CapsNet, and 86.16% of RTFN, respectively. Moreover, the influence of waveform size, sampling rate, signal-to-noise ratios, and amplitude on the accuracy of UACNet is analyzed. The results show that UACNet can overcome the influence of these factors and truly realize automatic real-time classification of microseismic signals without preprocessing.},
  archive      = {J_EAAI},
  author       = {Zhengxiang He and Mingtao Jia and Liguan Wang},
  doi          = {10.1016/j.engappai.2023.107088},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107088},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {UACNet: A universal automatic classification network for microseismic signals regardless of waveform size and sampling rate},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal fusion for sensorimotor control in steering angle
prediction. <em>EAAI</em>, <em>126</em>, 107087. (<a
href="https://doi.org/10.1016/j.engappai.2023.107087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient reasoning about the spatial and temporal structure of the environment is crucial for perception in autonomous driving, particularly in an end-to-end approach. Although different sensor modalities are employed to capture the complex nature of the environment, they each have their limitations. For example, frame-based RGB cameras are susceptible to variations in illumination conditions. However, these limitations at the sensor level can be addressed by complementing them with sensor fusion techniques, enabling the learning of efficient feature representations for end-to-end autonomous perception. In this study, we address the end-to-end perception problem by fusing a frame-based RGB camera with an event camera to improve the learned representation for predicting lateral control. To achieve this, we propose a convolutional encoder–decoder architecture called DRFuser. DRFuser encodes the features from both sensor modalities and leverages self-attention to fuse the frame-based RGB and event camera features in the encoder part. The decoder component unrolls the learned features to predict lateral control, specifically in the form of a steering angle. We extensively evaluate the proposed method on three datasets: our collected Dataset, Davis Driving dataset, and the EventScape dataset for simulation. The results demonstrate the generalization capability of our method on both real-world and simulated datasets. We observe qualitative and quantitative improvements in the performance of the proposed method for predicting lateral control by incorporating the event camera in fusion with the frame-based RGB camera. Notably, our method outperforms state-of-the-art techniques on the Davis Driving Dataset, achieving a 5.6% improvement in the root mean square error (RMSE) score.},
  archive      = {J_EAAI},
  author       = {Farzeen Munir and Shoaib Azam and Kin-Choong Yow and Byung-Geun Lee and Moongu Jeon},
  doi          = {10.1016/j.engappai.2023.107087},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107087},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal fusion for sensorimotor control in steering angle prediction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Block attention network: A lightweight deep network for
real-time semantic segmentation of road scenes in resource-constrained
devices. <em>EAAI</em>, <em>126</em>, 107086. (<a
href="https://doi.org/10.1016/j.engappai.2023.107086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning-based semantic segmentation networks typically incorporate object classification networks in their backbone. This leads to a loss of context because classification networks have a smaller field of view. The architecture has been extended to recover context with additional downsampling feature maps, a parallel context branch, or pyramid pooling modules after the backbone. However, these extensions increase multiply–accumulate operations and memory requirements, thus, making them unsuitable for resource-constrained devices. To overcome this limitation, a novel convolutional building block with attention-based context guidance is proposed. The block is repeated to build an efficient encoder–decoder network. Our network runs in real-time, has a lightweight design with only 0.72 Million parameters, and achieves 70.1%, and 66.3% mean intersection-over-union scores on the highly competitive Cityscapes and CamVid datasets, respectively. An efficient decoder is also designed to replace other semantic segmentation network decoders with minimal performance loss. The performance measures on mobile platforms show that our network suits resource-constrained devices. Further, experimental results show that the proposed method can optimally balance the model size-inference speed and segmentation accuracy.},
  archive      = {J_EAAI},
  author       = {Saquib Mazhar and Nadeem Atif and M.K. Bhuyan and Shaik Rafi Ahamed},
  doi          = {10.1016/j.engappai.2023.107086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Block attention network: A lightweight deep network for real-time semantic segmentation of road scenes in resource-constrained devices},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning algorithm for real-time automatic crack
detection, segmentation, qualification. <em>EAAI</em>, <em>126</em>,
107085. (<a
href="https://doi.org/10.1016/j.engappai.2023.107085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracking is one of the typical damages in concrete structures, and it is crucial to detect and quantify cracks in a timely and efficient manner. However, current research primarily focuses on either single-task recognition or dual-task recognition based on multi-step sequential approaches. Less attention has been devoted to the multi-task integration of cracks. To address the challenges of inefficient and multi-step detection in traditional concrete crack detection methods, a novel deep learning-based model, called YOLOv5-IDS, is proposed based on You Only Look Once network v5 (version 6.2) with the combination of bilateral segmentation network while introducing a dilated convolution, pyramid pooling module, and attention refinement module. Moreover, crack parameter measurement algorithms based on the micro-element method are proposed to improve accuracy and efficiency. The method proposed in this study can not only detect and segment cracks with high accuracy and efficiency, but also quickly measure crack parameters, thus developing a complete method for the process from real-time crack detection and segmentation to crack parameter measurement. The experimental results for the YOLOv5-IDS model reveal the following performance metrics. For crack detection, the mean average precision with an intersection of union threshold of 0.5 ( mAP@0.5 ) is 84.33%, and the frames per second (FPS) is 159 f/s . For crack segmentation, the mean intersection over union (mIoU) is 94.78%, and the FPS is 8 f/s , respectively. Compared to existing methods, the proposed approach exhibits improvements in both accuracy and efficiency. Moreover, the calculation of crack parameters proves to be both precise and rapid.},
  archive      = {J_EAAI},
  author       = {Gang Xu and Qingrui Yue and Xiaogang Liu},
  doi          = {10.1016/j.engappai.2023.107085},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107085},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning algorithm for real-time automatic crack detection, segmentation, qualification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSCMOT: Multi-object tracking based on channel spatial
cooperative attention mechanism. <em>EAAI</em>, <em>126</em>, 107084.
(<a href="https://doi.org/10.1016/j.engappai.2023.107084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking has made good progress in recent years. Most mainstream methods use the fusion method of detection and Re-ID to complete the multi-target tracking technology. However, the current multi-tracking algorithm is slow and cannot meet the real-time requirements, which makes it difficult to implement in actual scenarios. In addition, the current mainstream multi-target tracking technology often has the problem of identity information jumping. Such frequent identity information hopping can lead to serious problems in some demanding practical applications, resulting in poor tracking performance. To solve these problems, we propose a simple framework CSCMOT. A non-parametric attention mechanism is adopted to focus on some feature points of the target without increasing the amount of computation, so as to reduce the amount of computation and improve the real-time performance of the algorithm. In addition, the jumping problem of identity information can be reduced by random simulation occlusion to improve tracking performance. Experiments show that the real-time performance of the proposed CSCMOT framework reaches 32.5 FPS, which exceeds most of the mainstream methods. In addition, the ID-switch was reduced to 2493 on the MOT17 dataset. Made a great breakthrough, better to solve the problem of identity information jump. The tracking accuracy is also 71.5, a competitive result that exceeds most of the mainstream methods. Effective data show that the framework improves the real-time performance of the algorithm, solves the problem of identity jump between targets, and is more conducive to experiment landing, which is easy to combine with the mobile robot platform.},
  archive      = {J_EAAI},
  author       = {Fei Wang and Hao Yan and Libo Zhang and Ke Gao},
  doi          = {10.1016/j.engappai.2023.107084},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107084},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CSCMOT: Multi-object tracking based on channel spatial cooperative attention mechanism},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation performance of the novel hybrid estimator based
on machine learning and extended kalman filter proposed for
speed-sensorless direct torque control of brushless direct current
motor. <em>EAAI</em>, <em>126</em>, 107083. (<a
href="https://doi.org/10.1016/j.engappai.2023.107083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, machine learning (ML) based methods are used to estimate rotor mechanical speed of brushless direct current (BLDC) motors. Training performances of approaches such as Artificial Neural Network, k-Nearest Neighbor, and Random Forest in the ML-based speed estimator are tested using the datas obtained from the direct torque control (DTC) drive system of BLDC motor in simulation and it is seen that the ANN approach has the highest accuracy. In addition, a novel extended Kalman filter (EKF)-based estimator is proposed for the estimation of back-EMFs of BLDC motor. A hybrid estimation method is proposed by using the developed ML-based speed estimator with the proposed EKF-based estimator and its estimation performance is tested in simulation on DTC drive system.},
  archive      = {J_EAAI},
  author       = {Remzi İnan and Bekir Aksoy and Osamah Khaled Musleh Salman},
  doi          = {10.1016/j.engappai.2023.107083},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107083},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Estimation performance of the novel hybrid estimator based on machine learning and extended kalman filter proposed for speed-sensorless direct torque control of brushless direct current motor},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive manifold partial domain adaptation for fault
transfer diagnosis of rotating machinery. <em>EAAI</em>, <em>126</em>,
107082. (<a
href="https://doi.org/10.1016/j.engappai.2023.107082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the source domain has more fault types than the target domain, the traditional domain adaptation (DA) performance will degrade. Therefore, exploring partial domain adaptation to improve the accuracy of cross-domain fault diagnosis is significant. This work develops a novel adaptive manifold partial domain adaptation (AMPDA) approach for implementing the partial transfer fault diagnosis by decreasing the distribution discrepancy and adaptively learning global geometrical structures. Specifically, AMPDA first proposes the extraction method of the global geometrical structure by an affinity matrix. Then, the two domains are aligned by decreasing the maximum mean discrepancy (MMD) between two classes. AMPDA applies the manifold regularization to the objective function of partial domain adaptation, adaptively changing the weight of the geometrical structure according to the feature mapping within the process aligning two domains. AMPDA can adaptively learn the global geometrical structure to reduce the man-made interference in the K-nearest neighbor and restrain negative transfer learning caused by forcing to keep the structure. AMPDA is successfully applied to partial transfer fault diagnosis of rolling bearings and planetary gearboxes with unlabeled target domain samples. The experimental results demonstrate that the AMPDA performs better than typical DA methods based on machine learning.},
  archive      = {J_EAAI},
  author       = {Yi Qin and Quan Qian and Zhengyi Wang and Yongfang Mao},
  doi          = {10.1016/j.engappai.2023.107082},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107082},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive manifold partial domain adaptation for fault transfer diagnosis of rotating machinery},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A two-phase multi-criteria decision-making with
interval-valued pythagorean normal fuzzy information and its application
for module hospital site selection in combating COVID-19. <em>EAAI</em>,
<em>126</em>, 107081. (<a
href="https://doi.org/10.1016/j.engappai.2023.107081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the fight against COVID-19, module hospital saved tens of thousands of lives and families. Therefore, how to effectively select the site of module hospital is a critical issue. The site selection of module hospital is a multi-criteria decision-making (MCDM) problem. Recently, interval-valued Pythagorean normal fuzzy (IPNF) number has become an effective and powerful tool for handling ambiguity in decision-making. However, the weights of experts in existing IPNF decision-making are often directly given, lacking objectivity and persuasiveness. Moreover, the current research on aggregation operators in IPNFN only involves simple weighted average and geometry, while ignoring the interaction among fuzzy information. Motivated by these issues, this paper aims to develop a two-phase IPNF MCDM approach and apply it to the site selection of module hospital. Firstly, IPNF Einstein weighted averaging (IPNFEWA) operator, IPNF Einstein order weighted averaging (IPNFEOWA) operator, IPNF Einstein weighted geometric (IPNFEWG) operator, and IPNF Einstein order weighted geometric (IPNFEOWG) operator are proposed. Moreover, numerical and theoretical proofs of the proposed operators are carried out. Secondly, an algorithm for determining experts’ weights is developed using the proposed IPNF social network in the first phase, and the decision-making process is conducted in the second phase. Finally, a numerical example on the site selection of module hospital is provided to demonstrate the feasibility of the proposed method. The numerical results of comparisons and sensitivity analysis are further analyzed to confirm the advantages of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yuan Xu},
  doi          = {10.1016/j.engappai.2023.107081},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107081},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-phase multi-criteria decision-making with interval-valued pythagorean normal fuzzy information and its application for module hospital site selection in combating COVID-19},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive scalable spatio-temporal graph convolutional
network for PM2.5 prediction. <em>EAAI</em>, <em>126</em>, 107080. (<a
href="https://doi.org/10.1016/j.engappai.2023.107080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PM2.5 Prediction is a complex task of large-scale spatio-temporal analysis, which not only needs comprehension of static geospatial knowledge and relative features but also needs to analyze the real-time situation. This paper discusses the characteristics of the static graph and the dynamic graph in spatio-temporal series tasks. An Adaptive Scalable Spatio-temporal Graph Convolutional Network(ASGCN) model is proposed to predict PM2.5. To capture and analyze the characteristics of the time series period of PM2.5, a time convolution network based on the strategies of inception and gating is proposed and used as a temporal module. A dynamic graph idea is adopted to distinguish the spatio-temporal similarity of different periods. And an adaptive weighted multilayer graph convolution network is used to process static and dynamic graphs, aiming to analyze the spatial relationship of PM2.5 stations. The convolution network with the inception and gating improves the time-series feature capture ability, and adaptive static and dynamic graphs enhance the spatial relationship analysis ability. The temporal and spatial modules of the model are relatively independent, which benefits obtaining the potential information of datasets to improve the prediction accuracy. At the same time, these modules cooperate to make the model adaptable to various data. We choose a great number of comparative models and design a thorough experimental scheme including single-step prediction, multi-step prediction, hyperparameter experiments, and ablation experiments on two real PM2.5 datasets collected in China. Finally, the model achieves performance close to or better than the current state-of-the-art models selected for comparison in prediction tasks.},
  archive      = {J_EAAI},
  author       = {Qingjian Ni and Yuhui Wang and Jiayi Yuan},
  doi          = {10.1016/j.engappai.2023.107080},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107080},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive scalable spatio-temporal graph convolutional network for PM2.5 prediction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MCA: Multidimensional collaborative attention in deep
convolutional neural networks for image recognition. <em>EAAI</em>,
<em>126</em>, 107079. (<a
href="https://doi.org/10.1016/j.engappai.2023.107079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A broad range of prior research has demonstrated that attention mechanisms offer great potential in advancing the performance of deep convolutional neural networks (CNNs). However, most existing approaches either ignore modeling attention in both channel and spatial dimensions or introduce higher model complexity and heavier computational burden. To alleviate this dilemma, in this paper, we propose a lightweight and efficient multidimensional collaborative attention, MCA, a novel method for simultaneously inferring attention in channel, height, and width dimensions with almost free additional overhead by using a three-branch architecture. For the essential components of MCA, we not only develop an adaptive combination mechanism for merging dual cross-dimension feature responses in squeeze transformation , enhancing the informativeness and discriminability of feature descriptors but also design a gating mechanism in excitation transformation that adaptively determines the coverage of interaction to capture local feature interactions, overcoming the paradox of performance and computational overhead trade-off. Our MCA is simple yet general and can be easily plugged into various classic CNNs as a plug-and-play module and trained along with the vanilla networks in an end-to-end manner. Extensive experimental results for image recognition on CIFAR and ImageNet-1K datasets demonstrate the superiority of our method over other state-of-the-art (SOTA) counterparts. In addition, we also provide insight into the practical benefits of MCA by visually inspecting the GradCAM++ visualization results. The code is available at https://github.com/ndsclark/MCANet .},
  archive      = {J_EAAI},
  author       = {Yang Yu and Yi Zhang and Zeyu Cheng and Zhe Song and Chengkai Tang},
  doi          = {10.1016/j.engappai.2023.107079},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107079},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MCA: Multidimensional collaborative attention in deep convolutional neural networks for image recognition},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot learning for image-based bridge damage detection.
<em>EAAI</em>, <em>126</em>, 107078. (<a
href="https://doi.org/10.1016/j.engappai.2023.107078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous bridge visual inspection is a real-world challenge due to various materials, surface coatings, and changing light and weather conditions. Traditional supervised learning relies on massive annotated data to establish a robust model, which requires a time-consuming data acquisition process. This work proposes a few-shot learning (FSL) approach based on improved ProtoNet for damage detection with just a few labeled examples. Feature embedding is achieved through cross-domain transfer learning from ImageNet instead of episodic training. The ProtoNet is improved with embedding normalization to enhance transduction performance based on Euclidean distance and a linear classifier for classification. The approach is explored on a public dataset through different ablation experiments and achieves over 94% mean accuracy for 2-way 5-shot classification via the pre-trained GoogleNet after fine-tuning. Moreover, the proposed fine-tuning methods based on a fully connected layer (FCN) and Hadamard product are demonstrated with better performance than the previous method. Finally, the approach is validated using real bridge inspection images, demonstrating its capability of fast implementation for practical damage inspection with weakly supervised information.},
  archive      = {J_EAAI},
  author       = {Yan Gao and Haijiang Li and Weiqi Fu},
  doi          = {10.1016/j.engappai.2023.107078},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107078},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Few-shot learning for image-based bridge damage detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Koopman-operator-based learning control of air-breathing
hypersonic vehicles with nonminimum phase properties. <em>EAAI</em>,
<em>126</em>, 107077. (<a
href="https://doi.org/10.1016/j.engappai.2023.107077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a prescribed learning controller is developed for nonminimum phase air-breathing hypersonic vehicles (AHVs) in the presence of parametric uncertainties and external disturbances. In comparison with the current state of the art, the most significant feature of our control design lies in introducing the Koopman operator to construct an intelligent output redefinition to overcome the nonminimum phase behavior. To evaluate the current control behavior and enhance the learning ability, an improved continuous-time performance index is developed under the actor–critic learning structure. Furthermore, combined with a nonlinear disturbance observer, prescribed learning control is proposed to design control commands, while compensating for lumped disturbances, including neural approximation errors and external disturbances. Numerical simulations have been performed to highlight the superiority of the proposed learning control.},
  archive      = {J_EAAI},
  author       = {Guan Wang and Hongwei Xia},
  doi          = {10.1016/j.engappai.2023.107077},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107077},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Koopman-operator-based learning control of air-breathing hypersonic vehicles with nonminimum phase properties},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep hierarchical distillation proxy-oil modeling for
heterogeneous carbonate reservoirs. <em>EAAI</em>, <em>126</em>, 107076.
(<a href="https://doi.org/10.1016/j.engappai.2023.107076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel few-shot proxy modeling approach for the oil and gas industry to reduce reliance on numerical simulators for reservoir analysis. The strategy introduces a regression framework leveraging deep hierarchical self-distillation to construct a meta-model based on ensemble learning. The proposed method employs a cascade training scheme, which uses predictions derived from a superior hierarchical level to distill knowledge into the next predictor. The pivotal idea of self-distillation is to generate “soft targets” rather than hard ones. Soft targets represent probability distributions over potential output curves rather than a correct answer. This smoothing information provides additional guidance to the model during training, helping it generalize better. This architecture utilizes three-dimensional (3D) maps in proxy modeling to forecast cumulative fluid production and generate risk curves indispensable for effective field decisions. The study employed data acquired from a complex oil field characterized by a substantial degree of uncertainty. The hierarchical self-distillation technique outperforms alternative methods, achieving a symmetric mean absolute percentage error (SMAPE) below 2%. It reduces computational overhead by 84% for a probabilistic model with 900 simulations and 62% for a model with 200 simulations. The developed proxy model delivers valuable insights for decision-making in oil field management, offering the potential to decrease expenses and enhance efficiency in field exploration endeavors.},
  archive      = {J_EAAI},
  author       = {Gabriel Cirac and Jeanfranco Farfan and Guilherme Daniel Avansi and Denis José Schiozer and Anderson Rocha},
  doi          = {10.1016/j.engappai.2023.107076},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107076},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep hierarchical distillation proxy-oil modeling for heterogeneous carbonate reservoirs},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review helpfulness prediction on e-commerce websites: A
comprehensive survey. <em>EAAI</em>, <em>126</em>, 107075. (<a
href="https://doi.org/10.1016/j.engappai.2023.107075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This comprehensive survey investigates methodologies and factors utilized for predicting review helpfulness on e-commerce websites. Analyzing 132 research publications from the past 17 years, four primary determinants come to light: textual contents, non-textual contents, reviewer-related factors, and product-related factors. Review length, readability, entropy, sentiments, review rating, product description features, and customer question-answer features emerge as influential indicators. The study revealed a shift from statistical processes to machine learning and neural learning approaches in recent years due to their superior performance in predicting review helpfulness. The survey findings open up promising avenues for future research. Key directions include addressing the challenges posed by duplicate reviews, ensuring review-rating consistency, and leveraging helpful reviews in the development of chatbot systems for e-commerce websites. Additionally, exploring the impact of social media sentiment on product recommendations presents intriguing possibilities. This survey provides valuable insights for researchers and practitioners in the realm of review helpfulness prediction on e-commerce websites.},
  archive      = {J_EAAI},
  author       = {Sunil Saumya and Pradeep Kumar Roy and Jyoti Prakash Singh},
  doi          = {10.1016/j.engappai.2023.107075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review helpfulness prediction on e-commerce websites: A comprehensive survey},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scheduling operations in a large hospital by multiple
agents. <em>EAAI</em>, <em>126</em>, 107074. (<a
href="https://doi.org/10.1016/j.engappai.2023.107074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scheduling of operations in a large hospital is performed jointly by several groups of people, each with its own objective and constraints. It is a two-phase process, starting with the allocation of operating rooms to wards, and followed by the scheduling of operations in each operating room of the hospital on each day. The final schedule must satisfy all inter-ward hard constraints, such as the allocation of anesthetists, nurses, and equipment to operations that are taking place in parallel, and ideally, it should also address soft constraints such as taking the urgency and complexity of operations into consideration. This study contributes to the ongoing effort of adapting multi-agent optimization models and algorithms to real-world applications by modeling the problems in both phases as distributed constraint optimization problems (DCOPs), with different properties. The first phase includes partially cooperative ward-representing agents, allocating operating rooms for daily usage among themselves. In the second phase, ward-representing agents interact with agents representing constraining elements, in order to generate daily operation schedules for each operating room, thus forming a unique bipartite constraint graph. On one side are the ward representatives, while on the other are the agents representing the constraining resources. Each agent has a non-trivial local problem to solve, and its solution serves as the proposed assignment in the distributed algorithm. The study begins by discussing the properties required of the algorithms needed to solve the two phases. It then proposes adjustments to existing distributed partially cooperative algorithms and local search algorithms to solve these problems, and compares the results of different variants of these algorithms. The results obtained for both phases emphasize that successful collaboration is predicated on two requirements: that agents hold consistent information regarding their peers’ states and that the degree of exploration undertaken by the algorithm is restricted in order to produce high-quality solutions.},
  archive      = {J_EAAI},
  author       = {Noam Gaon and Yuval Gabai Schlosberg and Roie Zivan},
  doi          = {10.1016/j.engappai.2023.107074},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107074},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scheduling operations in a large hospital by multiple agents},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attentional ensemble model for accurate discharge and water
level prediction with training data enhancement. <em>EAAI</em>,
<em>126</em>, 107073. (<a
href="https://doi.org/10.1016/j.engappai.2023.107073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discharge is water flow from a higher to a lower elevation resulting from precipitation or surface runoff. It is an essential resource for human society, including drinking water and irrigation. Forecasting discharge and water level are crucial in establishing plans to secure water sources and predict floods. Deep learning has recently emerged as a potential solution for forecasting discharge and water levels. However, it faces three challenges: training data shortage, noise existence, and underestimation tendency. This research offers a novel deep learning-based method addressing the abovementioned shortcomings. To overcome data scarcity and improve prediction accuracy, we leverage the strengths of the one-dimensional Convolutional Neural Network (1D-CNN), Long short-term memory (LSTM), and Ensemble learning technique. Specifically, 1D-CNN uses a kernel moving in one direction and executing the convolution operations to extract the correlations between the features. LSTM helps to capture temporal relationships inside the data, while ensemble learning exploits multiple learning models for better predictive performance. Besides, Singular-Spectrum Analysis (SSA) technique is applied to decompose the input data into several components and eliminate noise-like ones while retaining essential parts. Besides, the attention mechanism is leveraged to assign higher weights for more essential features, further enhancing the accuracy. Finally, we utilize the Linear Exponential (LINEX) loss to prevent under- and overestimation. The experiments show that our proposal outperforms existing approaches regarding all metrics. Notably, our method improves the Nash–Sutcliffe model Efficiency coefficient (NSE) (the most critical metric) by up to 40% and 34% concerning one-step-ahead and multistep-ahead, respectively, compared to existing approaches.},
  archive      = {J_EAAI},
  author       = {Anh Duy Nguyen and Viet Hung Vu and Duc Viet Hoang and Thuy Dung Nguyen and Kien Nguyen and Phi Le Nguyen and Yusheng Ji},
  doi          = {10.1016/j.engappai.2023.107073},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107073},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attentional ensemble model for accurate discharge and water level prediction with training data enhancement},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLformer: Constraint-based locality enhanced transformer for
anomaly detection of ancient building structures. <em>EAAI</em>,
<em>126</em>, 107072. (<a
href="https://doi.org/10.1016/j.engappai.2023.107072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ancient buildings are valuable heritage and non-renewable resources. Existing warning mechanisms typically rely on degradation causation analysis. However, it has limitations of complex research, poor generalization, and inadequate warnings. To address these challenges, we propose a novel algorithm, the core component is the constraint-based locality enhanced transformer (CLformer), leveraging multi-scale causal convolution (MSCC) to enhance the local features extraction. Utilizing a generative prediction to reduce error accumulation and improve accuracy. Additionally, a block recurrent prediction strategy is introduced to further optimize the model, reducing the time complexity to O ( L k ∙ k 2 ) and the space complexity to O ( k 2 ) , accelerating the inference speed and run efficiency. Then, CLformer is compared with five other models using two ancient building cases. The results show that the root mean square error (RMSE) and mean absolute error (MAE) of CLformer have significantly improved, and the area under the receiver operating characteristic curve (AUC) value is the largest, which proves its superiority and effectiveness. The generalization and robustness are validated through ablation experiments and six additional real cases. Finally, the algorithm is implemented in engineering and employed in practice, providing valuable guidelines and applications for the conservation of ancient buildings worldwide.},
  archive      = {J_EAAI},
  author       = {Yuhan Wu and Yabo Dong and Wentao Zhu and Junru Zhang and Shijie Liu and Dongming Lu and Nan Zeng and Yinhui Li},
  doi          = {10.1016/j.engappai.2023.107072},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107072},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CLformer: Constraint-based locality enhanced transformer for anomaly detection of ancient building structures},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph neural network-based data cleaning method to prevent
intelligent fault diagnosis from data contamination. <em>EAAI</em>,
<em>126</em>, 107071. (<a
href="https://doi.org/10.1016/j.engappai.2023.107071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of deep learning (DL) based-mechanical fault diagnosis hinges on the high quality of training data. However, it is difficult to acquire high-quality mechanical monitoring data due to data contamination: 1) Monitoring device irregularities, such as sensor malfunction and signal transmission disruption, bring anomalies into the training data; 2) human labour-based data annotation inevitably produces incorrectly labeled data. These two types of data contamination degrade the performance of DL models. To address the aforementioned issue, this paper proposes a graph neural network-based data-cleaning method. In the first stage, a group anomaly detector is designed to identify the presence of anomalous data. This detector incorporates affinity graphs for depicting data groups and subsequently calculates the group anomaly score to determine the abnormal group. In the second stage, a graph clustering model is developed to relabel the mislabeled data. This model takes advantage of the graph neural network&#39;s proficiency in handling affinity graphs to prepare clean labels for subsequent network training. Experimental results, conducted on a pump and an industrial robot joint reducer, show the proposed method&#39;s ability to effectively detect anomalous data and rectify incorrect labeling, surpassing the performance of baseline methods in mechanical fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Shuhui Wang and Yaguo Lei and Bin Yang and Xiang Li and Yue Shu and Na Lu},
  doi          = {10.1016/j.engappai.2023.107071},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107071},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A graph neural network-based data cleaning method to prevent intelligent fault diagnosis from data contamination},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Swin transformer with multiscale 3D atrous convolution for
hyperspectral image classification. <em>EAAI</em>, <em>126</em>, 107070.
(<a href="https://doi.org/10.1016/j.engappai.2023.107070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) classification has attracted significant interest among researchers owing to its diverse practical applications. Convolutional neural networks (CNNs) have been extensively utilized for HSI classification. However, the effectiveness of CNN-based approaches is constrained by the fixed size and structure of the convolutional kernels, as well as their incapacity to capture global features. Moreover, these networks are inadequate in modeling the sequential characteristics of data. Recently, a promising approach, window-based multi-head self-attention has emerged to address the limitations of CNNs and incorporate efficient sequence modeling capabilities. This paper introduces a novel method, multiscale 3D atrous convolution with a lightweight swin transformer (MACLST), that effectively combines the strengths of two networks to capture both local and global features at different scales in HSI classification. The MACLST is designed to process HSI cubes as input and employs a spectral–spatial features extraction module based on multiscale 3D atrous convolution. This module involves parallel branches of 3D layers with varying atrous rates, enabling the extraction of features at multiple scales and resolutions. The extracted spectral–spatial features are fused and passed to the lightweight Swin transformer module as linear embeddings. This module captures long-range dependencies and learns effective feature representations of HSI. To reduce computational complexity, the swin transformer module is simplified and consists of only two stages, offering a more efficient version of the original swin transformer. The proposed MACLST model is extensively evaluated on five widely used benchmark HSI datasets, and the experimental results validate its superiority over state-of-the-art approaches with an overall accuracy of 99.00%, 99.59%, 99.95%, 98.71%, and 94.98% on the Indian Pines, University of Pavia, Salinas Valley, Houston University 2013, and Houston University 2018 datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Ghulam Farooque and Qichao Liu and Allah Bux Sargano and Liang Xiao},
  doi          = {10.1016/j.engappai.2023.107070},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107070},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Swin transformer with multiscale 3D atrous convolution for hyperspectral image classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Window-based transformer generative adversarial network for
autonomous underwater image enhancement. <em>EAAI</em>, <em>126</em>,
107069. (<a
href="https://doi.org/10.1016/j.engappai.2023.107069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The estimation of high-quality underwater images is an important step towards the development of computer vision systems in marine environments. This fundamental step contains numerous computer vision and robotics applications including marine exploration, robotics manipulation, navigation, object detection, tracking, and sea life monitoring. However, this pre-processing step becomes more challenging in the presence of back-scattering of underwater particles and attenuation issues, which lead to the formation of hazy underwater images. Vision transformers have recently demonstrated outstanding performance in many computer vision applications. Window-based Transformers (WT) show promising enhancement performance by computing self-attention within non-overlapping local windows. WT has been identified as an essential component in improving representation capabilities; however, it has received less attention in improving the performance of Underwater Image Enhancement (UIE). Therefore, we propose a novel end-to-end Underwater window-based Transformer Generative Adversarial Network (UwTGAN). Our proposed algorithm consists of two main components, including a transformer generator that generates a restored underwater image and a transformer discriminator that classifies the generated underwater image. Both components are equipped with Window-based Self-Attention Blocks (WSABs), which maximize efficiency by limiting self-attention computation to non-overlapping local windows and provide relatively low computational costs. WSAB-based transformer generators and discriminators are trained end-to-end. We formulated an efficient loss function to ensure that the variables are closely integrated. Extensive experimental evaluations are performed on four independent underwater image datasets. Our results demonstrate that the proposed UwTGAN algorithm has outperformed several state-of-the-art UIE methods in terms of both quantitative and qualitative metrics by a significant margin.},
  archive      = {J_EAAI},
  author       = {Mehnaz Ummar and Fayaz Ali Dharejo and Basit Alawode and Taslim Mahbub and Md. Jalil Piran and Sajid Javed},
  doi          = {10.1016/j.engappai.2023.107069},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107069},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Window-based transformer generative adversarial network for autonomous underwater image enhancement},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel grey prediction model based on tensor higher-order
singular value decomposition and its application in short-term traffic
flow. <em>EAAI</em>, <em>126</em>, 107068. (<a
href="https://doi.org/10.1016/j.engappai.2023.107068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term traffic flow prediction is the key to traffic guidance and control and can directly affect the performance of intelligent transportation systems. Traffic flow data has the characteristics of volatility, chaos, and randomness, which affect the accuracy of the prediction model. Based on the multi-dimensional spatio-temporal data characteristics of traffic flow data, this paper combines the tensor higher-order singular value decomposition theory and the modeling mechanism of the classical grey model GM(1,1) model and establishes the grey GM(1,1) model with tensor higher-order singular values. The tensor higher-order singular value decomposition reflects the periodic, multi-modal, and holistic nature of traffic flow data, which can mitigate the volatility and randomness of traffic flow data and improve the accuracy of the model. Then, the new model is applied to highway short-time traffic flow prediction, analyzing the spatio-temporal nature of traffic flow data, giving the detailed steps of model modeling, and analyzing the correlation between the original traffic flow data and tensor approximation data using grey correlation degrees. There are three cases to illustrate the effectiveness of the model. Case 1 shows that the results of MAPE from nine modeling objects are stable at about 5%, which indicates that the new model has some stability; Case 2 shows that the new model is more adaptable to short-time traffic flow prediction based on the results of three different modeling and prediction objects; Case 3 uses the new model to compare it with two traditional grey forecasting models and two optimization models, and the results indicate that the new model has a total MAPE value of 5.172%, which is better than the other four grey forecasting models. Finally, the new model is applied to short-time traffic flow prediction, and its prediction results are consistent with the trend of the original traffic flow data, indicating that it can reveal the real-time characteristics of the traffic system to a certain extent and provide a reliable theoretical basis for traffic planning, control, and optimization.},
  archive      = {J_EAAI},
  author       = {Derong Xie and Sihao Chen and Haotong Duan and Xinwei Li and Caotong Luo and Yuxuan Ji and Huiming Duan},
  doi          = {10.1016/j.engappai.2023.107068},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107068},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel grey prediction model based on tensor higher-order singular value decomposition and its application in short-term traffic flow},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ink painting style transfer using asymmetric
cycle-consistent GAN. <em>EAAI</em>, <em>126</em>, 107067. (<a
href="https://doi.org/10.1016/j.engappai.2023.107067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese ink painting, an artistic and cultural treasure, necessitates automatic generation for its preservation and evolution. We&#39;ve innovatively observed and validated that the domain information between photographs and ink paintings, is asymmetrical, which has been overlooked by current style transfer algorithms. We propose an innovative generative adversarial network featuring an asymmetric cyclic consistency structure to address this in ink painting style transfer. This structure uses generators of differing capabilities to align with the asymmetry in transformation directions, improving image quality and model optimization speed. Additionally, we introduce two unique loss functions within the network. The salient edge loss intensifies the subject in the real photo and enhances the edge stroke of the drawn subject, a distinct attribute of ink painting. The feature-wise cycle consistency loss is designed to speed up model optimization. We&#39;ve also built a Chinese bird ink painting dataset to validate effectiveness of the model. Extensive experiments on this and a public dataset demonstrate that our algorithm can comprehensively learn various stylistic features of ink painting, especially regarding brushstroke style, ink diffusion, and detail preservation. Furthermore, the quantitative results indicate our approach achieves superior results in generation quality and model efficiency compared to existing methods. For instance, compared to the most recent style transfer method, our method achieves an average decrease of 9.44% and 25.32% for FID and KID metrics across three datasets and reduces training and inference time costs by 46.81% and 22.71% respectively.},
  archive      = {J_EAAI},
  author       = {Weining Wang and Yifan Li and Huan Ye and Fenghua Ye and Xiangmin Xu},
  doi          = {10.1016/j.engappai.2023.107067},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107067},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ink painting style transfer using asymmetric cycle-consistent GAN},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The reconciliation mechanism by cooperative intention index
for managing non-cooperative behaviors in social network group decision
making. <em>EAAI</em>, <em>126</em>, 107066. (<a
href="https://doi.org/10.1016/j.engappai.2023.107066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social network group consensus is a hybrid cooperative and non-cooperative problem, with the management of non-cooperative behavior as a key topic. In response, this study investigates the reconciliation mechanism to manage non-cooperative behaviors based on a cooperative intention index ( C I I ). First, a C I I index driven by preference similarity and trust relationships is constructed, which predicts the compromise domain of decision makers (DMs). Subsequently, this study recognizes three types of non-cooperative behaviors from the group and individual proposal perspectives in turn: (i)Type-1 cooperation with the group; (ii)Type-2 non-cooperation with the group but cooperation with the individual; and (iii)Type-3 non-cooperation with both the group and the individual. Then, reconciliation mechanisms applicable to different types of mediation are proposed. Then, group-orientated, individual-orientated and compulsory reconciliation mechanisms are proposed for different types. Finally, a demonstration example and discussions are provided to illustrate the efficacy of the proposed model.},
  archive      = {J_EAAI},
  author       = {Jiayao Shen and Sha Wang and Feixia Ji and Tiantian Gai and Jian Wu},
  doi          = {10.1016/j.engappai.2023.107066},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107066},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The reconciliation mechanism by cooperative intention index for managing non-cooperative behaviors in social network group decision making},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal operational self-learning control for multi-time
scale industrial processes with signal compensations. <em>EAAI</em>,
<em>126</em>, 107065. (<a
href="https://doi.org/10.1016/j.engappai.2023.107065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the multi-time scales and strong nonlinearity are objectively existed in the practical industrial processes, it is extremely challenging to design control policy for optimizing the industrial operation. Therefore, this paper focuses on the multi-time scale optimal operational control (OOC) problem with unmodeled dynamics. Under the framework of reinforcement learning (RL) technology, a self-learning model-free method by integrating zero-sum game and singular perturbation (SP) theories is proposed in this paper, such that composite controllers with signal compensation can be found under which the suboptimal operation of the whole process can be achieved using only measured data. The remarkable highlight in this paper is the novel design method of the composite controllers with signal compensations for unknown nonlinear systems with multi-rate operations. Finally, the effectiveness of the proposed method is verified by a practical example and a numerical example.},
  archive      = {J_EAAI},
  author       = {Jinna Li and Mingwei Yang and Frank L. Lewis},
  doi          = {10.1016/j.engappai.2023.107065},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107065},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal operational self-learning control for multi-time scale industrial processes with signal compensations},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Urban traffic volume estimation using intelligent
transportation system crowdsourced data. <em>EAAI</em>, <em>126</em>,
107064. (<a
href="https://doi.org/10.1016/j.engappai.2023.107064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic volume is a crucial information for many different fields, such as city planner, logistic planning and more. However, installing sensors on each road to collect traffic volume data for the whole traffic network is impractical due to high cost and human labour. Most recent studies implement machine learning, mathematical and statistical methods to learn the behaviour of traffic volume. However, the randomness of traffic volume can hardly be defined by equations or statistical models which leads to the proposed machine learning model. This paper proposed a novel spatial prediction to fill up the traffic volume of a whole network with an estimated 10% of ground truth data. To make up for the lack of data, a spatial-temporal weightage is assigned to each road before fitting the training sample into a tree ensemble model to perform a prediction of the connecting roads. The weightage is first computed using the 10% ground truth data and then the weightage is spread to connecting roads via an innovative repetitive breadth-first search (BFS) method that capture the spatial correlation of a traffic network. Various experiments were conducted to assess the significance of spatial weighting and it was observed that incorporating the weighting resulted in a 1.69% improvement in the Mean Absolute Percentage Error (MAPE). The temporal relationship can be learnt from the trend of hourly traffic data for every day of the week. The proposed model achieved an average percentage error of 2.63% with reduced average percentage error by 95% compared to existing methods.},
  archive      = {J_EAAI},
  author       = {Liangyu Tay and Joanne Mun-Yee Lim and Shiuan-Ni Liang and Chua Kah Keong and Yong Haur Tay},
  doi          = {10.1016/j.engappai.2023.107064},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107064},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Urban traffic volume estimation using intelligent transportation system crowdsourced data},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent fault diagnosis of bearings under small samples:
A mechanism-data fusion approach. <em>EAAI</em>, <em>126</em>, 107063.
(<a href="https://doi.org/10.1016/j.engappai.2023.107063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been extensively applied to bearing fault diagnosis with remarkable achievements. However, in real industrial scenarios, the primary challenge in developing an effective intelligent diagnosis model is the scarcity of fault samples required for training due to shutting down operations during failure behavior. Simulation data-driven and data augmentation-based small sample diagnosis methods have their own limitations, including insufficient diagnostic performance and low data quality. In view of these, a novel mechanism-data fusion diagnosis scheme with bearing dynamic model and multi-agent diverse generative adversarial network (MAD-GAN) is proposed in this study. Specifically, the bearing dynamic model addresses the scarcity of failure samples by simulating vibration signals across various operating conditions. Besides, A simulation-real transformation model based on MAD-GAN is developed to achieve the conversion between simulated domain and real domain, which shares the diagnostic knowledge between two domains. Finally, the domain adversarial based comprehensive generalization network is improved by maximum mean discrepancy and metric learning to further generalize diagnosis knowledge from simulation domain to real domain. Two bearing experimental datasets are applicated and case studies are conducted under small sample, validating the effectiveness and superiority of the proposed method. Experimental results show the potential application of this method in real industrial scenarios.},
  archive      = {J_EAAI},
  author       = {Kun Xu and Xianguang Kong and Qibin Wang and Bing Han and Liqiang Sun},
  doi          = {10.1016/j.engappai.2023.107063},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107063},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent fault diagnosis of bearings under small samples: A mechanism-data fusion approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ship trajectory prediction based on machine learning and
deep learning: A systematic review and methods analysis. <em>EAAI</em>,
<em>126</em>, 107062. (<a
href="https://doi.org/10.1016/j.engappai.2023.107062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ship trajectory prediction based on Automatic Identification System (AIS) data has attracted increasing interest as it helps prevent collision accidents and eliminate potential navigational conflicts. Therefore, it is necessary and urgent to conduct a systematic analysis of all the prediction methods to help reveal their advantages to ensure safety at sea in different scenarios. It is particularly important and significant within the context of unmanned ships forming a new hybrid maritime traffic together with manned ships in the future. This paper aims to conduct a comparative analysis of the up-to-date ship trajectory prediction algorithms based on machine learning and deep learning methods. To do so, five classical machine learning methods (i.e., Kalman Filter, Gaussian Process Regression, Support Vector Regression, Random Forest, and Back Propagation Network) and eight deep learning methods (i.e., Recurrent Neural Networks, Long Short-Term Memory, Bi-directional Long Short-Term Memory, Gate Recurrent Unit, Bi-directional Gate Recurrent Unit, Sequence to Sequence, Spatio-Temporal Graph Convolutional Network, and Transformer) are thoroughly analysed and compared from the algorithm essence and applications to excavate their features and adaptability for manned and unmanned ships. The findings reveal the characteristics of various prediction methods and provide valuable implications for different stakeholders to guide the best-fit choice of a particular method as the solution under a specific circumstance. It also makes contributions to the extraction of the research difficulties of ship trajectory prediction and the corresponding solutions that are put forward to guide the development of future research.},
  archive      = {J_EAAI},
  author       = {Huanhuan Li and Hang Jiao and Zaili Yang},
  doi          = {10.1016/j.engappai.2023.107062},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107062},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ship trajectory prediction based on machine learning and deep learning: A systematic review and methods analysis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributional prediction of short-term traffic using neural
networks. <em>EAAI</em>, <em>126</em>, 107061. (<a
href="https://doi.org/10.1016/j.engappai.2023.107061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network (NN)-based models have recently achieved outstanding results in short-term traffic prediction. However, most of these are based on the regression approach and trained to generate a single data point as a predicted value for future timesteps, which does not provide information on prediction uncertainty and limits its performance under different traffic conditions. To solve this problem, this study proposes a novel, high-dimensional distributional prediction (HDP) framework. This method has been validated by a series of experiments using the Caltrans Performance Measurement System dataset and four widely used NN models. The results suggest that the proposed HDP scheme can help existing NN structures to (1) generate adaptive distributional predictions for quantifying the uncertainty of multiple targets, and (2) gain better point prediction in terms of accuracy and robustness. Furthermore, we demonstrate that predicted speed distributions can be used for travel time estimation, outperforming other traditional methods in unexpected traffic conditions such as traffic incidents.},
  archive      = {J_EAAI},
  author       = {Bo Wang and Hai L. Vu and Inhi Kim and Chen Cai},
  doi          = {10.1016/j.engappai.2023.107061},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107061},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributional prediction of short-term traffic using neural networks},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel multi-label pest image classifier using the modified
swin transformer and soft binary cross entropy loss. <em>EAAI</em>,
<em>126</em>, 107060. (<a
href="https://doi.org/10.1016/j.engappai.2023.107060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As pests can cause heavy crop losses, integrated pest management is a vital aspect of agriculture. In general, pest recognition is essential to the integrated pest management. Many studies have explored how to achieve automatic pest recognition using computer vision and artificial intelligence techniques. However, most existing methods did not consider the class ambiguity problem. That is, a pest image may belong to multiple possibly true categories, but only one possible class label is assigned to the pest image. To close the above gap, this study converted the conventional one-label pest classification task into a multi-label one. In detail, the state-of-the-art deep network, Swin Transformer, was first modified to enable the predicted scores of possible classes to approximate one simultaneously by replacing the fully connected soft-max layer with a sigmoid activation layer. Then, a two-stage supervised learning algorithm using the binary cross entropy loss and the novel soft binary cross entropy loss was designed to train the Swin-Transformer-based multi-label classification model with single-label images. Experiments on the IP102 image dataset showed that the proposed method obtained the highest F 1 -score value of 60.83%. It outperformed the second-best one by a margin of 7.52%. In conclusion, the proposed method can tackle the pest class ambiguity problem on IP102 better.},
  archive      = {J_EAAI},
  author       = {Qingwen Guo and Chuntao Wang and Deqin Xiao and Qiong Huang},
  doi          = {10.1016/j.engappai.2023.107060},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107060},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multi-label pest image classifier using the modified swin transformer and soft binary cross entropy loss},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Ultrathin optically transparent and flexible wideband
absorber based on ANN and DGCNN. <em>EAAI</em>, <em>126</em>, 107059.
(<a href="https://doi.org/10.1016/j.engappai.2023.107059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optically transparent and structurally flexible metamaterial absorbers (MMAs) are widely used in many practical applications. However, the realization of such MMAs requires both thickness reduction and bandwidth enhancement, which remains a challenge task. As a multi-objective optimization problem, it is a time-consuming and resource-demanding process. Guided by prior-knowledge, two degrees of freedom are taken into account in the design, namely the structure of unit-cells and their spatial arrangement. In this way, the multi-objective optimization problem is simplified into a two-step problem. A general procedure based on machine-learning (ML) method is proposed to solve this problem. First, an artificial neural network (ANN) is used to map the configuration parameters of a type of meta-atom onto its reflection coefficients; then, a dynamic graph convolutional neural network (DGCNN) is trained to realize the synthesis of quasi-periodic distributed MMA array; finally, combined with the differential evolution (DE) algorithm, the optimized configuration of the meta-atoms and their optimum distribution are obtained. Based on the proposed procedure, an ultrathin optically transparent and flexible MMA is designed, fabricated and further verified by experiments. The designed MMA realizes 87% absorption bandwidth covering 6.22 GHz–19.42 GHz (103% relative bandwidth) with the thickness only 3 . 3 mm ( 0 . 068 λ L ) , which approaches the theoretical limit 1 / 17 λ L . And its averaged transparency is about 63% at the wavelength range 500 – 800 mm . The whole design process is achieved 50 times faster than the conventional full-wave simulation, which convincingly demonstrates the superiority of the proposed method.},
  archive      = {J_EAAI},
  author       = {Xiaolu Yang and Zhenguo Liu and Zhe Zhang and Wei Xiang and Mingyang Geng and Hao Chen and Xiaochun Liu and Weibing Lu},
  doi          = {10.1016/j.engappai.2023.107059},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107059},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ultrathin optically transparent and flexible wideband absorber based on ANN and DGCNN},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Construction of bearing health indicator under time-varying
operating conditions based on isolation forest. <em>EAAI</em>,
<em>126</em>, 107058. (<a
href="https://doi.org/10.1016/j.engappai.2023.107058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While there have been extensive studies in the health assessment of the bearings using the vibration signal, most have focused on the constant operating conditions. The field, however, operates often under time-varying conditions as is the case of the automotive wheel bearing. In this study, a novel health indicator (HI) is proposed to address this problem based on the Isolation Forest algorithm, which was originally developed for anomaly detection. The method is advantageous in two aspects: the HI is not influenced by the type of operating conditions whether it is constant or time-varying. Only the data under normal condition are used to construct the HI without the need of run-to-failure data. The method is demonstrated by the three cases with different types of bearing and operating conditions ranging from constant to the highly variable conditions. As a result, monotonic trends are obtained for the HI in all cases, which may be useful for the prognostic monitoring. Furthermore, in comparison with the HI constructed by the run-to-failure data in the previous literature, it is found that the trends of HI agree reasonably well with each other, which supports the validity of the method.},
  archive      = {J_EAAI},
  author       = {Jinwoo Sim and Jinhong Min and Seokgoo Kim and Seok Woo Lee and Joo-Ho Choi},
  doi          = {10.1016/j.engappai.2023.107058},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107058},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Construction of bearing health indicator under time-varying operating conditions based on isolation forest},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video anomaly detection based on cross-frame prediction
mechanism and spatio-temporal memory-enhanced pseudo-3D encoder.
<em>EAAI</em>, <em>126</em>, 107057. (<a
href="https://doi.org/10.1016/j.engappai.2023.107057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent video anomaly detection (VAD) methods play a crucial role in conserving human resources, reducing the financial burden on governments, and promptly and accurately identifying abnormal behaviors. Frame prediction, which performs VAD by reasonably predicting normal video and distorting predicted anomalous video, is a popular and efficient method. Although Auto-Encoders (AE) show excellent performance in video frame prediction methods, the ability of these methods to use temporal information and poorly reconstruct anomalous videos is insufficient. To improve the shortcomings of AE in VAD, we propose a VAD method based on the cross-frame prediction mechanism and the spatio-temporal memory-enhanced pseudo-3D encoder. This method significantly enhances the recognition capability of abnormal activities in surveillance videos. Firstly, we use the prediction mechanism that uses multiple past frames with intervals to predict future frames. It can broaden the extra information and limit the memory consumption. Then we design the pseudo-3D encoder to encode the spatio-temporal information in videos, avoiding the problems that the 2D encoder cannot obtain the temporal dimensional information and the 3D encoder has complicated structure and overmuch parameters. Finally, we design the spatio-temporal memory block with three loss functions to store the spatio-temporal information of normal videos, which can expand the predicted differences between normal and abnormal examples. Experiments on UCSD Ped2, CUHK Avenue and ShanghaiTech datasets experimentally show that the proposed method achieves 99.4%, 90.5% and 74.3% of the AUC values. Our method shows excellent performance among single-stage semi-supervised anomaly detection methods.},
  archive      = {J_EAAI},
  author       = {Xiaopeng Wen and Huicheng Lai and Guxue Gao and Yang Xiao and Tongguan Wang and Zhenhong Jia and Liejun Wang},
  doi          = {10.1016/j.engappai.2023.107057},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107057},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Video anomaly detection based on cross-frame prediction mechanism and spatio-temporal memory-enhanced pseudo-3D encoder},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A face recognition taxonomy and review framework towards
dimensionality, modality and feature quality. <em>EAAI</em>,
<em>126</em>, 107056. (<a
href="https://doi.org/10.1016/j.engappai.2023.107056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive review of Automatic Facial Recognition Systems using integrative and systematic mapping approach. The review is grounded on criteria-attribute scheme formulated in proposed Face Recognition framework. The proposed framework provides a unified platform to identify, categorize and understand wholesome Face Recognition taxonomy based on different criteria (Modality, Dimensionality and Feature Quality) and their corresponding attributes (Unimodal-Multimodal, 2D-3D and Physiological-Behavioral). The framework facilitates a user to understand and select attributes across different criteria. The user selection of criteria-attribute is assisted through several selection parameters (Dataset Availability, Application, User Preference, System Complexity and Time Complexity). Depending on the user selection, a criteria-attribute scheme based model is formulated for Face Recognition. This paper also provides critical mathematical insights to understand each attribute extensively. Existing works are analyzed and compared comprehensively and quantitatively based on popular datasets and proposed criteria-attribute framework.},
  archive      = {J_EAAI},
  author       = {Ipsita Pattnaik and Amita Dev and A.K. Mohapatra},
  doi          = {10.1016/j.engappai.2023.107056},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107056},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A face recognition taxonomy and review framework towards dimensionality, modality and feature quality},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast fractional-order polar linear canonical transform:
Theory and application. <em>EAAI</em>, <em>126</em>, 107055. (<a
href="https://doi.org/10.1016/j.engappai.2023.107055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-watermarking is a promising technology for image copyright protection due to its excellent imperceptibility and robustness. Compared with deep learning (DL)-based zero-watermarking schemes which are time-consuming and unable to respond in real-time, the moment-based zero-watermarking schemes do not have the aforementioned drawbacks and have drawn great attention with their strong description ability and geometric invariance. However, most existing moment-based zero-watermarking methods bear a number of drawbacks, in particular: (i) Direct computation of image moments is inefficient and inaccurate; (ii) They have difficulty obtaining the favorable trade-off between robustness and discriminability; (iii) Generating pseudo-random numbers based on traditional logistic map results in their lower security performance. To deal with those issues, this paper introduces a new image zero-watermarking method that relies on fast fractional-order polar linear canonical transform (FFrPLCT) features and asymmetric tent map. Firstly , we propose a novel computation strategy called fast polar linear Canonical transform (FPLCT), to save the calculation time of moments. Secondly, we define the fast fractional-order polar linear Canonical transform (FFrPLCT), which is characterized by the generic nature and time-frequency analysis capability. Thirdly, we present the FFrPLCT mixed low-order features by fully exploiting the time-frequency property of FFrPLCT, to improve both the robustness and discriminability of image representation. Finally, we develop a new image zero-watermarking method using FFrPLCT domain mixed low-order features and asymmetric tent map. Experimental results and comparison with well-known existing methods demonstrate the efficacy and superiority of the proposed image zero-watermarking scheme.},
  archive      = {J_EAAI},
  author       = {Xiangyang Wang and Jialin Tian and Panpan Niu and Hongying Yang},
  doi          = {10.1016/j.engappai.2023.107055},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107055},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast fractional-order polar linear canonical transform: Theory and application},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention gate guided multiscale recursive fusion strategy
for deep neural network-based fault diagnosis. <em>EAAI</em>,
<em>126</em>, 107052. (<a
href="https://doi.org/10.1016/j.engappai.2023.107052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearings are crucial for ensuring the safe and stable operation of electromechanical systems. Although deep learning has been widely used in fault diagnosis of rolling bearings, it is unable to accurately diagnose faults when the system operates under multiple working conditions. Therefore, it is essential to conduct research on fault diagnosis of rolling bearings under multiple working conditions to ensure the reliable operation of electromechanical systems. The potential features related to working conditions may be reflected in the different layers of the deep neural network (DNN). However, information loss during the process of layer-by-layer feature extraction may result in the loss of potential features related to changes in working conditions, which in turn affects the fault diagnosis results. This study focused on developing a multiscale recursive fusion strategy for a DNN by designing a new attention model with a lower computational burden. The proposed multiscale recursive fusion strategy guided by the attention mechanism can help correctly characterize the potential features related to variations in working conditions by allocating more attention to useful information and less attention to useless information on the adjacent layers of the DNN. Experimental tests for fault diagnosis of rolling bearings verified that the proposed method is superior to existing methods for fault diagnosis when the system is operated under multiple working conditions.},
  archive      = {J_EAAI},
  author       = {Zhiqiang Zhang and Funa Zhou and Hamid Reza Karimi and Hamido Fujita and Xiong Hu and Chenglin Wen and Tianzhen Wang},
  doi          = {10.1016/j.engappai.2023.107052},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107052},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention gate guided multiscale recursive fusion strategy for deep neural network-based fault diagnosis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised transfer learning for intelligent health status
identification of bearing in adaptive input length selection.
<em>EAAI</em>, <em>126</em>, 107051. (<a
href="https://doi.org/10.1016/j.engappai.2023.107051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input length (IL) is an important element in transfer learning (TL) network for intelligent health status identification of bearing (IHSIB). However, fixed IL are used in most studies. In this paper, a TL network via adaptive IL selection module for IHSIB (AILTLN) is proposed, which includes adaptive IL module, feature extractor module, health status identification module, and domain discriminator module. Firstly, an adaptive IL selection module based on envelope spectrum analysis is proposed. The module varies with bearing structure, motor speed, and sampling frequency. Secondly, group convolution, transposed convolution, and instant normalization are constructed in feature extractor. Thirdly, softmax cross-entropy loss function and maximum mean discrepancy are used for health status identification and domain alignment. The TL results of open bearing dataset and high-speed train bearing experiment show that AILTLN is better than the other existing methods in the TL of IHSIB. The ablation study shows the reuse of low-dimensional features and the adaptive IL help to improve to the accuracy of the proposed method.},
  archive      = {J_EAAI},
  author       = {Guiting Tang and Lei Liu and Yirong Liu and Cai Yi and Yongxu Hu and Du Xu and Qiuyang Zhou and Jianhui Lin},
  doi          = {10.1016/j.engappai.2023.107051},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107051},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised transfer learning for intelligent health status identification of bearing in adaptive input length selection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightning risk assessment of offshore wind farms by
semi-supervised learning. <em>EAAI</em>, <em>126</em>, 107050. (<a
href="https://doi.org/10.1016/j.engappai.2023.107050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wind turbine has rapidly developed worldwide with increasing height and scale, resulting in the increased risk of lightning strikes. When wind turbines were stroke by the lightning, they will be damaged, causing economic loss and outage. Lightning risk assessment can guide the improvement of lightning protection and the design of the wind farms to efficiently prevent lightning damages. The traditional lightning risk assessment methods rely on subjective features to some extent. The existing lightning risk assessment methods based on machine learning demand abundant labeled data. It is extremely difficult to label and acquire the data. This paper proposed a lightning risk assessment method based on semi-supervised learning to address the challenges of labeling negative samples and limited labeled data. The semi-supervised K-means algorithm is proposed to divide all data into three parts. The Laplacian support vector machine (LapSVM) with hyperparameters optimized by the particle swarm optimization (PSO) is used to assess the lightning risk. The proposed method has better performance than the standard SVM and neural network (NN). Moreover, previous researches did not consider lightning protection ability. This paper introduces the receptor number into lightning risk assessment. The assessment results suggest that there is higher lightning risk in areas with a great number of wind turbines, high lightning density, and strong lightning strength. The ocean area is more likely to have low lightning risk. The results are valuable for lightning protection optimization of existing wind farms and can give guidance for the plan of new wind farms.},
  archive      = {J_EAAI},
  author       = {Qibin Zhou and Jingjie Ye and Guohua Yang and Ruanming Huang and Yang Zhao and Yudan Gu and Xiaoyan Bian},
  doi          = {10.1016/j.engappai.2023.107050},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107050},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightning risk assessment of offshore wind farms by semi-supervised learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auto-pore segmentation of digital microscopic leather images
for species identification. <em>EAAI</em>, <em>126</em>, 107049. (<a
href="https://doi.org/10.1016/j.engappai.2023.107049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In leather images, precise pore segmentation is a necessary medium for accurate species prediction. However, due to foreground color, texture, size, and boundary variability, traditional methods encounter false segmentation. This paper proposes a deep learning-based novel auto-pore segmentation network (ApSnet). It aims to automatically segment the species-definite pores from novel digital microscopic leather image data. The ApSnet learns the pore regions from raw and the corresponding ground-truth images. The images undergo patch-based image augmentation to fasten the learning process. The depth and the concatenations of the existing Unet are reduced to design the simple and shallow ApSnet. The weighted average loss function strengthens the image understanding to segment the accurate pore pixels. The experimental analysis affirms the superior performance of the proposed ApSnet against Unet, Unet++, and I-Unet. The study also validates ApSnet with KDSB18 and KVasir-SEG datasets for medical image segmentation. It also tests the robustness of ApSnet on the leather images with fuzzy textures. Finally, the k-nearest neighbor (KNN) model learns and classifies the features from the ApSnet segmented images with 97.4% accuracy. Thus, the analysis proves that precise pore segmentation is indispensable in interpreting species-distinct pore features. Therefore, the present work develops a human–computer interactive platform for accurate leather species prediction by designing a computationally efficient ApSnet-based segmentation model.},
  archive      = {J_EAAI},
  author       = {Anjli Varghese and Sahil Jain and Malathy Jawahar and A. Amalin Prince},
  doi          = {10.1016/j.engappai.2023.107049},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107049},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Auto-pore segmentation of digital microscopic leather images for species identification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fractal belief jensen–shannon divergence-based multi-source
information fusion for pattern classification. <em>EAAI</em>,
<em>126</em>, 107048. (<a
href="https://doi.org/10.1016/j.engappai.2023.107048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source information fusion is an effective method to handle pattern classification problems. Dempster–Shafer evidence theory (DSET) plays an important role in handling uncertainty problems in multi-source information fusion. However, highly conflicting evidence in DSET may cause counter-intuitive fusion results. Belief divergence theory is one of the solutions to conflict management, which is also beneficial for the improvement of accuracies of pattern classification. In this paper, a novel belief divergence measurement method, fractal belief Jensen–Shannon ( F B J S ) divergence is proposed to better measure the discrepancy between Basic probability assignments (BPAs) and address the problem of highly conflicting evidence in DSET. The proposed F B J S divergence is the first belief divergence that incorporates the belief divergence theory and the concept of fractal. In addition, it has the properties of non-negativeness and symmetry. Then, based on F B J S divergence, a novel multi-source information fusion algorithm is proposed. Ultimately, the proposed algorithm is effectively applied to solve a pattern classification problem with a higher classification accuracy.},
  archive      = {J_EAAI},
  author       = {Yingcheng Huang and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2023.107048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fractal belief Jensen–Shannon divergence-based multi-source information fusion for pattern classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Targeted mining of top-k high utility itemsets.
<em>EAAI</em>, <em>126</em>, 107047. (<a
href="https://doi.org/10.1016/j.engappai.2023.107047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding high-importance patterns in data is an emerging data mining task known as High-utility itemset mining (HUIM). Given a minimum utility threshold, a HUIM algorithm extracts all the high-utility itemsets (HUIs) whose utility values are not less than the threshold. This can reveal a wealth of useful information, but the precise needs of users are not well taken into account. In particular, users often want to focus on patterns that have some specific items rather than find all patterns. To overcome that difficulty, targeted mining has emerged, focusing on user preferences, but only preliminary work has been conducted. For example, the targeted high-utility itemset querying algorithm (TargetUM) was proposed, which uses a lexicographic tree to query itemsets containing a target pattern. However, selecting the minimum utility threshold is difficult when the user is not familiar with the processed database. As a solution, this paper formulates the task of targeted mining of the top- k high-utility itemsets and proposes an efficient algorithm called TMKU based on the TargetUM algorithm to discover the top- k target high-utility itemsets (top- k THUIs). At the same time, several pruning strategies are used to reduce memory consumption and execution time. Extensive experiments show that the proposed TMKU algorithm has good performance on real and synthetic datasets.},
  archive      = {J_EAAI},
  author       = {Shan Huang and Wensheng Gan and Jinbao Miao and Xuming Han and Philippe Fournier-Viger},
  doi          = {10.1016/j.engappai.2023.107047},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107047},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Targeted mining of top-k high utility itemsets},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic viscosity prediction using artificial intelligence
for an antifreeze containing MWCNT–alumina hybrid nanopowders.
<em>EAAI</em>, <em>126</em>, 107046. (<a
href="https://doi.org/10.1016/j.engappai.2023.107046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of Solid Volume Fraction (SVF) and temperature on the dynamic viscosity of a hybrid antifreeze composed of MWCNTs and aluminum oxide in a mixture of water (80%) and ethylene-glycol (20%). An Artificial Neural Network (ANN) is used to predict the viscosity of the nanofluid, which was generated at different SVFs ranging from 0.25% to 1% and temperatures ranging from 25 °C to 50 °C. This study aims to establish a correlation between viscosity and input parameters in the antifreeze. Results demonstrate that Shear Rate (SR) and SVF have opposite effects on the viscosity of the nanofluid. Increasing SVF leads to a strong increase in viscosity deviation and higher mean values of viscosity while increasing SR results in a sharp decline in both the mean value and variation of the viscosity. The temperature has a smaller impact on viscosity variance than SR and SVF. The proposed ANN model with a two-layer network and 13 neurons having nonlinear activation functions in the hidden layer shows an accurate prediction of viscosity versus inputs. The proposed methodology offers an improvement of up to 10 times in predicting viscosity accuracy as compared to GMDH and decision tree techniques. The findings of this study can have important implications for the design of heat exchangers using nanofluids especially in portable devices.},
  archive      = {J_EAAI},
  author       = {Suqin Hua and Dheyaa J. Jasim and As&#39;ad Alizadeh and S. Ali Eftekhari and Navid Nasajpour-Esfahani and Mahmoud Shamsborhan and Davood Toghraie},
  doi          = {10.1016/j.engappai.2023.107046},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107046},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic viscosity prediction using artificial intelligence for an antifreeze containing MWCNT–alumina hybrid nanopowders},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Investigating the influence of dimensionality reduction on
force estimation in robotic-assisted surgery using recurrent and
convolutional networks. <em>EAAI</em>, <em>126</em>, 107045. (<a
href="https://doi.org/10.1016/j.engappai.2023.107045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large data computing is a research problem and a major challenge in order to successfully mine, process, and evaluate massive datasets, as they represent a useful source of knowledge across multiple and intersecting domains. This paper explores the impact of Dimensionality Reduction (DR) on estimating the force in robotic-assisted surgery using recurrent and recurrent convolutional neural networks. This work collects an extensive dataset from three ex vivo porcine samples and one ex vivo artificial skin, as well as from various sensors, surgical tools, and manipulators, to research the impact of dimensionality reduction. Three neural networks were considered to analyze and validate the results of this work: Recurrent Neural Networks (RNN-LSTM), Recurrent Convolutional Neural Networks (RCNN), and Modified Inception ResNet V2. The statistical analysis of the estimated force quality shows a 17.33% improvement in Ince. ResNet V2 networks, a 10.08% improvement in CNN+LSTM networks, and a 3.88% improvement in RNN-LSTM networks with and without dimensionality reduction in the average of all the force components in all three datasets. The analysis also shows a reduction in training time of 8.21% in LSTM-RNN, 14.91% in CNN-LSTM, and 21.01% in Ince. ResNet V2 with and without DR. Additionally, networks with DR outperform those without DR in terms of execution time per step and force prediction time, resulting in notable reductions in each aspect. Sensitivity analysis reveals that Torque, Position, Deformation, Stiffness, Tool diameter, Rotation, and Orientation features have significant impacts on the predicted force after DR. It was also observed that the predicted force quality was superior when performing feature selection and dimensionality reduction on collected features from tool, manipulator, tissue, and vision data when processed simultaneously in all three architectures. The findings have significant implications for various fields and applications beyond the specific domain of surgical robotics.},
  archive      = {J_EAAI},
  author       = {P.V. Sabique and Ganesh Pasupathy and Sivaramakrishnan Ramachandran and G. Shanmugasundar},
  doi          = {10.1016/j.engappai.2023.107045},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107045},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Investigating the influence of dimensionality reduction on force estimation in robotic-assisted surgery using recurrent and convolutional networks},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scaling-up medical vision-and-language representation
learning with federated learning. <em>EAAI</em>, <em>126</em>, 107037.
(<a href="https://doi.org/10.1016/j.engappai.2023.107037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical Vision-and-Language Pre-training (MedVLP), which learns generic vision-language representations from medical images and texts to benefit various downstream medical tasks, has drawn remarkable attention in both artificial intelligence and clinical medicine. However, existing works ignore the privacy issues and the heavy computation burden in MedVLP. In this study, we propose a FedMedVLP model, which adopts federated learning to unify the datasets from different clients, e.g., centers and hospitals, to form a large-scale pre-training dataset. As a result, the unified large-scale pre-training dataset can be used to pre-train the MedVLP to achieve strong performance. Overall, our FedMedVLP can improve the performance of MedVLP while preventing data leakage. Extensive experiments prove that the proposed model sets new state-of-the-art results on five benchmark datasets across three medical mainstream tasks, i.e., medical image–text retrieval, medical text-image retrieval, and medical visual question answering tasks. Besides, we further evaluate our method on our curated well-balanced medical dataset COVID-Fed.},
  archive      = {J_EAAI},
  author       = {Siyu Lu and Zheng Liu and Tianlin Liu and Wangchunshu Zhou},
  doi          = {10.1016/j.engappai.2023.107037},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107037},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scaling-up medical vision-and-language representation learning with federated learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Yaw system restart strategy optimization of wind turbines in
mountain wind farms based on operational data mining and multi-objective
optimization. <em>EAAI</em>, <em>126</em>, 107036. (<a
href="https://doi.org/10.1016/j.engappai.2023.107036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wind resources of mountain wind farms are affected by more complex terrain than are found at flat wind farms. Wind turbine (WT) failures caused by frequent operation of the yaw system occur often in mountain wind farms, resulting in significantly reduced economic benefits over the WT life cycle. Considering the problem of frequent yaw motions of WTs in mountain wind farms, this study introduces multi-objective optimization theory into the yaw system restart strategy optimization of WTs for the first time and proposes an optimized yaw system restart strategy with wind speed segmentation in the wind speed region below the rated wind speed. The yaw behavior of mountain wind farms in southern China is analyzed from multiple perspectives; a segmentation scheme of wind speed intervals for yaw control was determined from the results. The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is used to optimize the control parameters for each sub-interval with the goals of minimizing yaw operation time and maximizing energy generation. A set of Pareto solutions is obtained and evaluated with the Technique for Order of Preference by Similarity to an Ideal Solution (TOPSIS) method to produce the optimal solution. The simulation results indicated that after the WT adopts the optimized yaw system restart strategy in the wind speed region below the rated wind speed, the number of yaw motions is decreased by 82.9%, with only a slight decrease in energy generation. The optimization method proposed in this study can significantly reduce yaw operation time with minimal loss of energy generation, which provides a new approach to balancing the relationship between reducing the WT failure rate and ensuring power generation efficiency and is expected to significantly improve the economic benefits to wind farms.},
  archive      = {J_EAAI},
  author       = {Jialu Han and Xian Wang and Xuebing Yang and Qihui Ling and Wei Liu},
  doi          = {10.1016/j.engappai.2023.107036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Yaw system restart strategy optimization of wind turbines in mountain wind farms based on operational data mining and multi-objective optimization},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing the drilling efficiency through the application of
machine learning and optimization algorithm. <em>EAAI</em>,
<em>126</em>, 107035. (<a
href="https://doi.org/10.1016/j.engappai.2023.107035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel Artificial Intelligence (AI) workflow to enhance drilling performance by mitigating the adverse impact of drill-string vibrations on drilling efficiency. The study employs three supervised machine learning (ML) algorithms, namely the Multi-Layer Perceptron (MLP), Support Vector Regression (SVR), and Regression Decision Tree (DTR), to train models for bit rotation (Bit RPM), rate of penetration (ROP), and torque. These models combine to form a digital twin for a drilling system and are validated through extensive cross-validation procedures against actual drilling parameters using field data. The combined SVR - Bit RPM model is then used to categorize torsional vibrations and constrain optimized parameter selection using the Particle Swarm Optimization block (PSO). The SVR-ROP model is integrated with a PSO under two constraints: Stick Slip Index (SSI&lt;0.05) and Depth of Cut (DOC&lt;5 mm) to further improve torsional stability. Simulations predict a 43% increase in ROP and torsional stability on average when the optimized parameters WOB and RPM are applied. This would avoid the need to trip in/out to change the bit, and the drilling time can be reduced from 66 to 31 h. The findings of this study illustrate the system&#39;s competency in determining optimal drilling parameters and boosting drilling efficiency. Integrating AI techniques offers valuable insights and practical solutions for drilling optimization, particularly in terms of saving drilling time and improving the ROP, which increases potential savings.},
  archive      = {J_EAAI},
  author       = {Farouk Said Boukredera and Mohamed Riad Youcefi and Ahmed Hadjadj and Chinedu Pascal Ezenkwu and Vahid Vaziri and Sumeet S. Aphale},
  doi          = {10.1016/j.engappai.2023.107035},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107035},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing the drilling efficiency through the application of machine learning and optimization algorithm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic prediction of wind speed using an integrated
deep belief network optimized by a hybrid multi-objective particle swarm
algorithm. <em>EAAI</em>, <em>126</em>, 107034. (<a
href="https://doi.org/10.1016/j.engappai.2023.107034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improvement in wind speed prediction is highly necessary for estimating the accuracy as well as stability of wind power. In this work, we proposed probabilistic forecasts of wind speed for predicting the short-term wind speed intervals. The optimal model has been designed by considering three different modules such as data decomposition, prediction, and optimization. Variational-Mode-Decomposition (VMD) is utilized for decomposing the primary time series data into a suitable number of modes followed by the Deep Belief Network (DBN) for probabilistic wind sped prediction. Here the Gauss-Bernoulli restricted Boltzmann machine (GBRBM) and Bernoulli-Bernoulli RBM (BBRBM) are combined in the DBN where the GBRBM is utilized as the initial RBM to convert the continuity feature of the source data into a binomial distribution feature. Multi-kernel-random-vector-functional-link-network (MKRVFLN) is employed here as supervised learning in DBN to avoid long execution time and get the model into local optima. In the model optimization, a hybrid multi-objective Sine-Cosine particle-swarm-optimization (MOSCPSO)is used to optimize the DBN parameters for obtaining high accuracy and strong stability output simultaneously. It determines the wind speed at 95%, 90%, 85%, and 80% prediction interval nominal confidence (PINC). To validate the proposed model and comparing with other benchmark prediction techniques, the data are taken from the wind farm located at Sotavento, Spain, at different time horizons (30 min–1 h) in different seasons. The results obtained demonstrate that the proposed technique outperforms the further existing model on the basis of prediction accuracy and stability.},
  archive      = {J_EAAI},
  author       = {Snigdha Sarangi and Pradipta Kishore Dash and Ranjeeta Bisoi},
  doi          = {10.1016/j.engappai.2023.107034},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107034},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic prediction of wind speed using an integrated deep belief network optimized by a hybrid multi-objective particle swarm algorithm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based 3D multigrid topology optimization of
manufacturable designs. <em>EAAI</em>, <em>126</em>, 107033. (<a
href="https://doi.org/10.1016/j.engappai.2023.107033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural topology optimization is a compute-intensive process due to several iterations of simulations required to evaluate the performance of the component during optimization. Deep learning (DL) based approaches can address this challenge, but these methods were demonstrated mainly using 2D shapes and, at best, in low-resolution 3D geometries (typically 3 2 3 ). Further, due to non-manufacturable geometric features, the predicted optimal geometries from DL may not be manufacturable, even using additive manufacturing. In this paper, we develop a DL framework using a multigrid convolutional neural network (CNN) to generate high-resolution topology-optimized 3D geometries with additional checks on the manufacturability of the predicted shapes. Our framework predicts the final optimal topology using the initial strain energy (objective function of structural topology optimization) and target volume fraction (material fraction to be preserved after optimization) as input. We train the network using a multigrid approach, which enables topology optimization at 12 8 3 resolution, which was previously computationally challenging. We first train the multigrid CNN at a lower resolution and then transfer the learned network to continue training at higher resolutions. We use a distributed deep learning framework on a GPU supercomputing cluster to further speed up the training time. Distributed DL significantly speeds up the training time by more than 4 × while achieving similar model performance. Finally, we check the optimal geometries for manufacturability using fused deposition modeling (FDM)-specific manufacturability constraints. The large training dataset ( &gt; 60,000 high-resolution topology optimization examples) will be released with the paper to enable further research on this topic.},
  archive      = {J_EAAI},
  author       = {Jaydeep Rade and Anushrut Jignasu and Ethan Herron and Ashton Corpuz and Baskar Ganapathysubramanian and Soumik Sarkar and Aditya Balu and Adarsh Krishnamurthy},
  doi          = {10.1016/j.engappai.2023.107033},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107033},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based 3D multigrid topology optimization of manufacturable designs},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic contour correction of pectus excavatum using
computer-aided diagnosis and convolutional neural network.
<em>EAAI</em>, <em>126</em>, 107032. (<a
href="https://doi.org/10.1016/j.engappai.2023.107032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pectus excavatum (PE) is a common congenital sternal malformation disease that significantly impacts the physical and psychological well-being of affected individuals. Traditional methods for diagnosing and correcting PE rely heavily on physician expertise, leading to potential uncertainties and errors. While current research has primarily focused on automatic indices extraction and deformity evaluation, there is a lack of emphasis on generating corrective solutions for patients with PE. To address these limitations, we present a novel convolutional neural network (CNN)-based computer-aided diagnosis (CAD) approach for automatically generating recommended corrections for patients with PE. Specifically, our approach involves training a CNN model using sternum contours from normal individuals to predict corrected sternum contours for patients. Through block-wise fine-tuning using transfer learning, we optimize the regression performance for three PE indices. The complete contours of patients are then depicted based on the predicted indices using our CAD method. To validate our approach, we collected a dataset comprising 11,755 chest CT images from 40 PE patients and 40 healthy individuals. The results suggest there is no significant difference between the predicted contours generated by our model and the actual postoperative contours by skilled surgeons, underscoring the promising efficacy of our model. In summary, our novel approach goes beyond the limitations of existing techniques and offers a significant advancement in the diagnosis and correction of PE.},
  archive      = {J_EAAI},
  author       = {Siqi Cai and Yizhi Liao and Lixuan Lai and Haiyu Zhou and Longhan Xie},
  doi          = {10.1016/j.engappai.2023.107032},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107032},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic contour correction of pectus excavatum using computer-aided diagnosis and convolutional neural network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). C-ECAFormer: A new lightweight fault diagnosis framework
towards heavy noise and small samples. <em>EAAI</em>, <em>126</em>,
107031. (<a
href="https://doi.org/10.1016/j.engappai.2023.107031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In engineering practice, small-sample fault diagnosis of mechanical equipment towards heavy noise interference poses great challenges for the existing Transformer based intelligent models. To address these challenges, this paper proposes a new lightweight model called C-ECAFormer. Firstly, inverted residual block is used to establish signal correlations and inductive bias capability and to extract richer local feature information by varying the input channel dimensions. Secondly, ECAFormer module is designed to enhance the relationship awareness between different channels in the input signal features, thereby improving the model&#39;s attention to important channels. Finally, collaborative self-attention block is developed to facilitate spatial interaction between window local and grid global in vibration signals, reducing the number of parameters and computational complexity of the model. The results of two experiments demonstrate that the proposed approach accommodates advantages of lightweight and robustness in small-sample fault diagnosis tasks, compared to the existing mainstream Transformer and CNN fault diagnosis frameworks.},
  archive      = {J_EAAI},
  author       = {Jie Wang and Haidong Shao and Shen Yan and Bin Liu},
  doi          = {10.1016/j.engappai.2023.107031},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107031},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {C-ECAFormer: A new lightweight fault diagnosis framework towards heavy noise and small samples},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-population co-evolutionary algorithm for green
integrated process planning and scheduling considering logistics system.
<em>EAAI</em>, <em>126</em>, 107030. (<a
href="https://doi.org/10.1016/j.engappai.2023.107030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, green manufacturing is an increasingly significant theme in the worldwide industry fields. System integration can fully exploit the potential of subsystems to achieve satisfying green and low-carbon manufacturing. In particular, integrated process planning and scheduling (IPPS) can obtain better process routes and scheduling schemes to realize more efficient and less energy-consuming production by utilizing the complementary attributes of the process and scheduling subsystems. Additional consideration of the shop logistics system including task assignment of automated guided vehicles (AGVs) can improve shop productivity while ensuring the smooth running of the whole manufacturing system. Taking into account AGV transportation, this paper studies a green multi-objective IPPS problem considering logistics system (MO_IPPS_LS) to minimize the maximum completion time and energy consumption simultaneously. A multi-population co-evolutionary algorithm (MPCEA) is proposed with a novel integrated encoding method. The co-evolutionary framework can ensure the diversity of the populations through a backtracking mechanism and different evolutionary operators including modified critical-path based local searching. The proposed MPCEA is tested on the open benchmarks with different proportions of transport resources. The comparative experimental results show the effectiveness and superiority of MPCEA for solving MO_IPPS_LS problem.},
  archive      = {J_EAAI},
  author       = {Qihao Liu and Cuiyu Wang and Xinyu Li and Liang Gao},
  doi          = {10.1016/j.engappai.2023.107030},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107030},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-population co-evolutionary algorithm for green integrated process planning and scheduling considering logistics system},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based black box checking for k-safety
hyperproperties. <em>EAAI</em>, <em>126</em>, 107029. (<a
href="https://doi.org/10.1016/j.engappai.2023.107029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The L ∗ algorithm proposed by Angluin is a standard approach to automata learning of unknown systems that generate regular languages. Black box checking (BBC) based on the L ∗ algorithm is a promising formal verification of unknown systems. On the other hand, a k -safety hyperproperty is a hyperproperty that proscribes “bad things”. For example, it can express safety policies for safety-critical and safety-related systems. However, conventional BBC methods based on the L ∗ algorithm focuses only on properties, not on hyperproperties. Therefore, this paper proposes an algorithm that checks whether a black box system satisfies a regular k -safety hyperproperty based on the Angluin’s L ∗ algorithm. In the proposed algorithm, k -bad prefix automata that violate the regular k -safety hyperproperty are generated from the regular k -safety hyperproperty described as a HyperLTL formula. Because the generated k -bad prefix automata are finite automata, the verification of the k -safety hyperproperty for black box systems can be conducted by automata-theoretic model checking. It is demonstrated that the proposed algorithm can verify noninterference, described as a 2-safety hyperproperty, with an illustrative example.},
  archive      = {J_EAAI},
  author       = {Naomi Kuze and Keiichiro Seno and Toshimitsu Ushio},
  doi          = {10.1016/j.engappai.2023.107029},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107029},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning-based black box checking for k-safety hyperproperties},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trace encoding in process mining: A survey and benchmarking.
<em>EAAI</em>, <em>126</em>, 107028. (<a
href="https://doi.org/10.1016/j.engappai.2023.107028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encoding methods are employed across several process mining tasks, including predictive process monitoring, anomalous case detection, trace clustering, etc. These methods are usually performed as preprocessing steps and are responsible for mapping complex event data information into a numerical feature space. Most papers choose existing encoding methods arbitrarily or employ a strategy based on expert domain knowledge. Moreover, existing methods are employed by using their default parameters without evaluating other options. This practice can lead to several drawbacks, such as suboptimal performance and unfair comparisons with the state-of-the-art. Therefore, this work aims at providing a comprehensive survey and benchmark on event log encoding by comparing 27 methods, from different natures, in terms of expressivity, scalability, correlation, and domain agnosticism. To the best of our knowledge, this is the most comprehensive study so far focusing on trace encoding in process mining. It contributes to maturing awareness about the role of trace encoding in process mining pipelines and sheds light on issues, concerns, and future research directions regarding the use of encoding methods to bridge the gap between machine learning models and process mining.},
  archive      = {J_EAAI},
  author       = {Gabriel M. Tavares and Rafael S. Oyamada and Sylvio Barbon Junior and Paolo Ceravolo},
  doi          = {10.1016/j.engappai.2023.107028},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107028},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trace encoding in process mining: A survey and benchmarking},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep generative learning for exploration in large
electrochemical impedance dataset. <em>EAAI</em>, <em>126</em>, 107027.
(<a href="https://doi.org/10.1016/j.engappai.2023.107027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fields of energy storage, photocatalysis, and sensors have undergone substantial technological advancements, which have led to the generation of vast amounts of data on electrochemical impedance (EIS). The interpretation of large amounts of EIS data is a challenging task since the analysis of EIS data requires multiple steps to get a suitable equivalent circuit. Recently, some progress has been made in the machine learning (ML) model for EIS classification. However, most of the ML models are performed as a “black box” model, which provides only the classification result and lacks physical descriptor representation. Here, we apply variational autoencoders (VAE) to EIS data analysis, which includes classification, parameter prediction, and the visualization of physical descriptors. The VAE model performed well in the classification task, with an accuracy of 82.0%–92.4%. In the prediction task, VAE shows a high R-squared value on the Randles circuit. Additionally, the VAE model can map physical descriptors to the latent space, allowing the latent space to transform into a property space, which plays an important role in the optimization and exploration of novel materials research.},
  archive      = {J_EAAI},
  author       = {Dulyawat Doonyapisut and Byeongkyu Kim and Jung Kyu Kim and Eunseok Lee and Chan-Hwa Chung},
  doi          = {10.1016/j.engappai.2023.107027},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107027},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep generative learning for exploration in large electrochemical impedance dataset},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Superposition of populations in multi-objective evolutionary
optimization of car suspensions. <em>EAAI</em>, <em>126</em>, 107026.
(<a href="https://doi.org/10.1016/j.engappai.2023.107026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of the suspension model of road cars is extremely important for both driver comfort and safety. Road traffic injuries are currently the eighth leading cause of death worldwide and are predicted to become the seventh leading cause of death by 2030, according to the World Health Organization (WHO). Among other factors, road infrastructure is one of the most important factors to consider when designing the suspension model, especially as autonomous driving becomes more popular. In addition, there is a growing need to test and study the impact of road roughness and pavement type on autonomous vehicles (AVs). This work provides the following contributions: a platform for suspension system optimization–flexible, highly parameterizable and rich in applications. Our solution implements, tests and optimises the 2, 3 and 4 degrees of freedom (DOF) quarter-car models (QCM) with linear seat suspension and the 5 DOF half-car model (HCM), respectively, based on random road profiles generated according to ISO 8608 standards. In addition, many multi-objective optimization (MOO) algorithms have been implemented and applied in isolation to see their comparative performance (in terms of Pareto fronts, hypervolume, coverage, spread, and epsilon), but most importantly we have also introduced a meta-optimization technique by super-positioning Non-dominated Sorting Genetic Algorithm II and Strength Pareto Evolutionary Algorithm 2, where each of the algorithms, running concurrently, produces a percentage of the total number of individuals in a generation, percentage that is calculated according to the solution quality of the individuals in the previous generation. The experimental results were obtained by simulating the optimal configurations generated by the MOO heuristic algorithms on different categories of cars (small/medium). Finally, the Taguchi method and regression analysis were used to evaluate the effects of specific parameters on system responses such as sprung mass acceleration and displacement. The Taguchi simulation was performed to experimentally validate the results obtained by metaheuristic optimization methods.},
  archive      = {J_EAAI},
  author       = {Adrian Florea and Ioana Cofaru and Andrei Patrausanu and Nicolae Cofaru and Ugo Fiore},
  doi          = {10.1016/j.engappai.2023.107026},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107026},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Superposition of populations in multi-objective evolutionary optimization of car suspensions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using the numerical simulation and artificial neural network
(ANN) to evaluate temperature distribution in pulsed laser welding of
different alloys. <em>EAAI</em>, <em>126</em>, 107025. (<a
href="https://doi.org/10.1016/j.engappai.2023.107025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The temperature field during laser welding process plays an important role on determining the quality and quantity of the weld bead size, microstructure characterizations and mechanical properties of the welding interface in the thermal engineering applications. In this study, using the numerical simulation, the influence of pulse duration and frequency on the temperature distribution and velocity field in distinctive laser welding of stainless steel 420 (S.S 420)/stainless steel 304 (S.S 304), and Bohler 303 (B 303)/stainless steel 304 (S.S 304) was examined. The results of numerical modeling illustrated that shear stress of Marangoni and buoyancy force are the most curtail aspects in the formation of the flow of liquid metal. A novel artificial intelligence method is proposed to optimally predict the melting ratio, and maximum temperature of the materials. To this end, a combination of ANN and Particle Swarm Optimization (PSO) algorithms are employed. The PSO algorithm is used to optimize the architecture and training algorithm of the ANN, while the ANN is employed for the regression problem. Based on the results, a three-layer feed-forward architecture with sigmoid transfer functions having 17 and 8 neurons in the hidden layers combined with the scaled conjugate gradient backpropagation training scheme is recognized by the PSO as the optimal configuration. Application of optimal ANN to the regression problem results in an acceptable level of error for the training, validation, and test datasets. Finally, the optimized ANN can be utilized to anticipate the melting ratio and thereby the resultant temperature.},
  archive      = {J_EAAI},
  author       = {Muhyaddin J.H. Rawa and Mohammad Hossein Razavi Dehkordi and Mohammad Javad Kholoud and Nidal H. Abu-Hamdeh and Hamidreza Azimy},
  doi          = {10.1016/j.engappai.2023.107025},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107025},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Using the numerical simulation and artificial neural network (ANN) to evaluate temperature distribution in pulsed laser welding of different alloys},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic borehole fracture detection and characterization
with tailored faster r-CNN and simplified hough transform.
<em>EAAI</em>, <em>126</em>, 107024. (<a
href="https://doi.org/10.1016/j.engappai.2023.107024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the geological information of fractures from borehole images is essential for conducting a thorough geological analysis in engineering. Recently, the convolutional neural network (CNN) has been employed to extract high-level features of fractures from images. We propose an improved Faster R-CNN (region-based CNN) model for fracture detection, which is suitably equipped with a tailored region proposal network f -RPN for borehole fractures. The anchors generated by f -RPN are specifically designed with a fixed width and varying heights, and only the anchors with the maximum intersection-over-union values are labeled as positive. By taking advantage of the cyclic feature of borehole images, the images are expanded in four orientations to increase the amount and diversity of the model input. The detection results of the model can further be utilized to simplify the Hough transform for characterizing dip angles and dip directions of fractures. The proposed method is validated with borehole images from multiple projects in hydraulic engineering. Experiments reveal that the average detection accuracy is approximately 91.5%, which exhibits an improvement of 11.06% compared to the original Faster R-CNN. Further analysis indicates that both f -RPN and the multi-orientation expansion contribute to improving the prediction accuracy. It is also shown that this method demonstrates robustness against blurred image background and outperforms traditional image processing methods in the presence of noise. The fracture characterization by the simplified Hough transform turns out to be computationally efficient and accurate, with the absolute errors less than 5° compared to the manual identification results.},
  archive      = {J_EAAI},
  author       = {Shuyang Han and Xiao Xiao and Benyang Song and Tao Guan and Yichi Zhang and Mingming Lyu},
  doi          = {10.1016/j.engappai.2023.107024},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107024},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic borehole fracture detection and characterization with tailored faster R-CNN and simplified hough transform},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online surface defect segmentation on aluminum strip
production line using a lightweight and efficient model. <em>EAAI</em>,
<em>126</em>, 107023. (<a
href="https://doi.org/10.1016/j.engappai.2023.107023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant challenge in automated defect inspection (ADI) of aluminum strip surfaces is improving segmentation speed to satisfy the online inspection requirements of the production line while maintaining the precision of defect identification. This study proposes a lightweight and efficient defect segmentation model that can be applied in aluminum processing enterprises for fast and precise segmentation of aluminum strip surface defects. A novel fusion attention (FA) mechanism is first established to enhance the focus on critical characteristics along the spatial and channel dimensions. This mechanism adopts continuous dilated convolutions with appropriate dilation rates to effectively increase the range of the receptive field and improve defect localization accuracy. Subsequently, a lightweight MobileViTv2 with an embedded FA mechanism is employed as a multi-scale feature extractor to learn comprehensive representations from defect images. Next, a novel feature fusion method, named large-scale feature pyramid network (LSFPN), is introduced to enhance the focus on details within large-scale features. LSFPN establishes four progressively shallower top-down pathways with fast normalized fusion weights and incorporates lightweight aggregation nodes based on the MoblieNetv2 block. Surface images of straightened aluminum strips with five universal defects were collected, whereby a new dataset was established. The experimental outcomes demonstrate the proposed model outperforms other state-of-the-art techniques synthetically, achieving a mean Intersection over Union (mIoU) of 87.01%, a segmentation speed of 61.67 fps, and a model size of 16.23 MB. This model may serve as a valuable theoretical foundation for the online segmentation of aluminum strip surface defects in embedded devices.},
  archive      = {J_EAAI},
  author       = {Zehua Lv and Yibo Li and Siying Qian and Liuqing Wu},
  doi          = {10.1016/j.engappai.2023.107023},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107023},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online surface defect segmentation on aluminum strip production line using a lightweight and efficient model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal transaction information-aware ponzi scheme
detection for ethereum smart contracts. <em>EAAI</em>, <em>126</em>,
107022. (<a
href="https://doi.org/10.1016/j.engappai.2023.107022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the frenetic advances of blockchain techniques have promoted the large-scale application of cryptocurrency and attracted significant attention in the mushrooming applications of decentralized finance (DeFi). To guarantee the health of a DeFi ecosystem, it is critical to reduce the transaction risks in a DeFi system. In particular, as a representative DeFi ecosystem platform, Ethereum’s transaction process is mainly carried out with the help of smart contracts. Due to (pseudo)anonymity, the transaction process of Ethereum users is challenged by severe fraud threats. Ponzi scheme is the typical one. Previous studies have used machine learning methods to build Ponzi scheme detection models based on learning from the identified static smart contract samples feature data. However, in the early stage of smart contract deployment, the Ponzi scheme is difficult to detect. With the progress of transactions, Ponzi scheme will gradually show its characteristics. The existing methods are still falling short in capturing the temporal features of smart contracts for detecting Ponzi schemes in the big data environment. The recognition rate of the current approaches needs to be further improved. In this paper, we propose TTPS, a Long Short-Term Memory (LSTM) Ponzi scheme detection method considering time series transaction information of smart contracts. TTPS considers both temporal account features and code features of smart contracts. Adaptive synthetic sampling (ADASYN) is employed to effectively extend the feature data of minority class Ponzi scheme small samples. LSTM is utilized to learn from the temporal feature data of Ponzi scheme samples for TTPS model training. Experimental results verify and demonstrate the effectiveness and efficiency of TTPS.},
  archive      = {J_EAAI},
  author       = {Lei Wang and Hao Cheng and Zibin Zheng and Aijun Yang and Ming Xu},
  doi          = {10.1016/j.engappai.2023.107022},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107022},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Temporal transaction information-aware ponzi scheme detection for ethereum smart contracts},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer for object detection: Review and benchmark.
<em>EAAI</em>, <em>126</em>, 107021. (<a
href="https://doi.org/10.1016/j.engappai.2023.107021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a crucial task in computer vision (CV). With the rapid advancement of Transformer-based models in natural language processing (NLP) and various visual tasks, Transformer structures are becoming increasingly prevalent in CV tasks. In recent years, numerous Transformer-based object detectors have been proposed, achieving performance comparable to mainstream convolutional neural network-based (CNN-based) approaches. To provide researchers with a comprehensive understanding of the development, advantages, disadvantages, and future potential of Transformer-based object detectors in Artificial Intelligence (AI), this paper systematically reviews the mainstream methods and analyzes the limitations and challenges encountered in their current applications, while also offering insights into future research directions. We have reviewed a large number of papers, selected the most prominent Transformer detection methods, and divided them into Transformer Neck and Transformer Backbone categories for introduction and comparative analysis. Furthermore, we have constructed a benchmark using the COCO2017 dataset to evaluate different object detection algorithms. Finally, we summarize the challenges and prospects in this field.},
  archive      = {J_EAAI},
  author       = {Yong Li and Naipeng Miao and Liangdi Ma and Feng Shuang and Xingwen Huang},
  doi          = {10.1016/j.engappai.2023.107021},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107021},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer for object detection: Review and benchmark},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Application of quantum particle swarm optimization for task
scheduling in device-edge-cloud cooperative computing. <em>EAAI</em>,
<em>126</em>, 107020. (<a
href="https://doi.org/10.1016/j.engappai.2023.107020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence and evolutionary algorithms (SI&amp;EAs) have been widely applied to various fields. In this paper, we make the first attempt, to our best knowledge, to apply an SI&amp;EA, Quantum Particle Swarm Optimization (QPSO), for addressing the task scheduling problem in Device-Edge-Cloud Cooperative Computing (DE3C) which is one of the most widespread and new computing paradigms. We first formulate the problem and propose a QPSO based method to solve the problem with a reasonable time. Then we summarize the existing variants of QPSO, which exploit various improvement schemes for QPSO. At last, we conduct simulated experiments to evaluate the performance of QPSO and its variants on solving the task scheduling problem of DE3C, and have the following findings. (1) QPSO outperforms several up-to-date heuristics and SI&amp;EAs in both the user satisfaction and the resource efficiency. (2) Existing improvement methods have no appreciable effect on QPSO for solving large-scale problems. (3) The performance of an improvement for QPSO depends mostly on randomness of the offset added to particle movements.},
  archive      = {J_EAAI},
  author       = {Bo Wang and Zhifeng Zhang and Ying Song and Ming Chen and Yangyang Chu},
  doi          = {10.1016/j.engappai.2023.107020},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107020},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of quantum particle swarm optimization for task scheduling in device-edge-cloud cooperative computing},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning with multimodal advantage function
for accurate advantage estimation in robot learning. <em>EAAI</em>,
<em>126</em>, 107019. (<a
href="https://doi.org/10.1016/j.engappai.2023.107019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a reinforcement learning (RL) framework that uses a multimodal advantage function (MAF) to come close to the true advantage function, thereby achieving high returns. The MAF, which is constructed as a logarithm of a mixture of Gaussians policy (MoG-P) and trained by globally collected past experiences, directly assesses the complex true advantage function with its multi-modality and is expected to enhance the sample-efficiency of RL. To realize the expected enhanced learning performance with the proposed RL framework, two practical techniques are developed that include mode selection and rounding off of actions during the policy update process. Mode selection is conducted to sample the action around the most influential or weighted mode for efficient environment exploration. For fast policy updates, past actions are rounded off to discretized action values when calculating the multimodal advantage function. The proposed RL framework was validated using simulation environments and a real inverted pendulum system. The findings showed that the proposed framework can achieve a more sample-efficient performance or higher returns than other advantage-based RL benchmarks.},
  archive      = {J_EAAI},
  author       = {Jonghyeok Park and Soohee Han},
  doi          = {10.1016/j.engappai.2023.107019},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107019},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning with multimodal advantage function for accurate advantage estimation in robot learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hydrogen prediction in poultry litter gasification process
based on hybrid data-driven deep learning with multilevel factorial
design and process simulation: A surrogate model. <em>EAAI</em>,
<em>126</em>, 107018. (<a
href="https://doi.org/10.1016/j.engappai.2023.107018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gasification is one of the recommended processes for poultry litter valorization, and its success is largely dependent on process input parameters for syngas production. The quality of syngas, characterized by a higher heating value (HHV) and lower heating value (LHV), is significantly influenced by hydrogen. In this research, integration of Aspen Plus simulation and Convolutional Neural Network (CNN) have been done to estimate the hydrogen content in syngas. The gasification process has been optimized using the response surface method, and the results have been supported by the particle swarm optimization (PSO) technique. The statistical analysis of the response surface model revealed that the optimal process parameters are around 408 °C, 2.0 (biomass to air ratio) BMR, and 2.0 bars. Interestingly, PSO led to nearly identical optimum values (400 °C, 2.0 BMR, and 2.0 bars), resulting in high-quality syngas. Furthermore, CNN exhibited a good predicting performance with a coefficient of determination (R 2 ) exceeding 0.96, coupled with mean square error (MSE) and mean absolute error (MAE) of 0.01 and 0.05, respectively. This solidifies the integration of Aspen Plus simulations and CNN as an accurate surrogate model for predicting hydrogen levels during poultry litter gasification, enabling effective process optimization. Therefore, the proposed model serves as a reliable tool for predicting and optimizing the syngas produced during the gasification process of poultry litter, with potential applications in enhancing energy production and waste management practices.},
  archive      = {J_EAAI},
  author       = {Yousaf Ayub and Yusha Hu and Jingzheng Ren and Weifeng Shen and Carman K.M. Lee},
  doi          = {10.1016/j.engappai.2023.107018},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107018},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hydrogen prediction in poultry litter gasification process based on hybrid data-driven deep learning with multilevel factorial design and process simulation: A surrogate model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A knowledge-driven co-evolutionary algorithm assisted by
cross-regional interactive learning. <em>EAAI</em>, <em>126</em>,
107017. (<a
href="https://doi.org/10.1016/j.engappai.2023.107017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) and Estimation of distribution algorithm (EDA) exhibit complementary superiority in solving complex continuous optimization and engineering problems. The design of appropriate strategies coordinated with the two algorithms to balance exploration and exploitation is conducive to obtaining high-precision solutions. A knowledge-driven co-evolutionary algorithm assisted by a cross-regional interactive learning mechanism (KCACIL) is proposed to achieve a comprehensive collaboration between the algorithms, diverse strategies, and cross-regional individuals. Various elite-guided mutation strategies and a self-feedback strategy based on successful experience in light of implicit knowledge are devoted to fulfilling self-learning and cross-regional interactive learning to accomplish individual collaboration and knowledge transfer in the three regions. Reinforcement learning based on ε − g r e e d y and simulated annealing is employed as feedback on the cross-regional individual information to promote the collaboration between opposition-based learning, interaction learning mechanism, and the revised strategy of inferior solutions with small Q values and high distance density. The dynamic self-adaptive adjustment strategies of multiple parameters are adopted to balance diversity and convergence. KCACIL is verified on the CEC 2014, 2017, 2020 benchmark test suites, and engineering applications. Experimental results indicate KCACIL is superior to the state-of-the-art comparison algorithms.},
  archive      = {J_EAAI},
  author       = {Ningning Zhu and Fuqing Zhao and Jie Cao and Jonrinaldi},
  doi          = {10.1016/j.engappai.2023.107017},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107017},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A knowledge-driven co-evolutionary algorithm assisted by cross-regional interactive learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SUCOLA: Self-adaptive structure refinement unsupervised
contrastive learning framework for food safety risk early warning.
<em>EAAI</em>, <em>126</em>, 107016. (<a
href="https://doi.org/10.1016/j.engappai.2023.107016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food safety is a global issue; risk prevention and control of food physical and chemical testing (PCT) data are critical. However, existing studies have not considered the risk status of qualified products near the detection limit. Therefore, this paper presents a data-driven paradigm to detect the combined risk of multiple indicators across products in real-world food safety datasets for the first time. The following challenges exist to achieve this goal. (1) In real-world scenarios, neighboring samples are somewhat correlated; however, capturing and quantifying the actual testing sample correlation network remains an open problem in food computing. (2) The low-frequency nature of the unqualified samples leads to label imbalance in the data. (3) Labeling dependency limits the application scenarios. This article proposes a novel self-supervised framework (SUCOLA) to address the abovementioned challenges. That jointly learns the optimal graph topology and also inferences the connections between every product node and its well-designed subgraph, helping to resist label imbalance. We applied it to a real-world sterilized PCT dataset from a province in China. Extensive experiments show that SUCOLA performance is outstandingly better than several baselines of the current graph self-supervision field. Meanwhile, we conducted generalizability experiments on five well-known benchmark datasets. The proposed SUCOLA surpasses the current state-of-the-art by a considerable margin (0.39%–8.7% AUC) on public datasets. Thus, our study provides a new idea for early warning research on PCT data in food computing and fills the gap in the study of structural learning under category imbalance.},
  archive      = {J_EAAI},
  author       = {Enguang Zuo and Junyi Yan and Alimjan Aysa and Chen Chen and Cheng Chen and Hongbing Ma and Xiaoyi Lv and Kurban Ubul},
  doi          = {10.1016/j.engappai.2023.107016},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107016},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SUCOLA: Self-adaptive structure refinement unsupervised contrastive learning framework for food safety risk early warning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Customer churn prediction model in cloud environment using
DFE-WUNB: ANN deep feature extraction with weight updated tuned naïve
bayes classification with block-jacobi SVD dimensionality reduction.
<em>EAAI</em>, <em>126</em>, 107015. (<a
href="https://doi.org/10.1016/j.engappai.2023.107015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With progressing competitive market, different organizations were desperate to hold this churn rate as minimum value, hence to achieve this, building an effective (CCP) customer churn prediction model is essential. In order to address those issues in CCP, the study deliberated the churn prediction model using DFE-WUNB (Deep Feature Extraction with Weight Updated Tuned Naïve Bayes classifier) in a cloud-computing environment. Due to the huge non-linear features of the Telco customer churn dataset, the pre-processed features are deeply learned by the subsequent two models of ANN. In ANN, the input feature gets multiplied by the weight value, and the resultant output feature passes to the next dense layer in ANN. The deep feature extraction in ANN models facilitates precise accuracy in determining relevant churn features. However, the higher matrix dimensions of features exhibit complexity in prediction, hence this Block Jacobi SVD algorithm is applied to decrease the dimensions of features, such as to create a sparse dataset projected to get fit to the training model for efficient classification. The dimension-reduced features pass through enhanced weighing Naïve Bayes algorithm gets updated with ANN weights and tunes the parameters having greater and best weights to NB classifier, improvising the classification accuracy performance. The comparative assessment of the proposed DFE-WUNB churn prediction model delineated the efficiency of highly accurate churn prediction, outperforming other conventional churn prediction models.},
  archive      = {J_EAAI},
  author       = {S. Arockia Panimalar and A. Krishnakumar},
  doi          = {10.1016/j.engappai.2023.107015},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107015},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Customer churn prediction model in cloud environment using DFE-WUNB: ANN deep feature extraction with weight updated tuned naïve bayes classification with block-jacobi SVD dimensionality reduction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Chaotic heterogeneous comprehensive learning PSO method for
size and shape optimization of structures. <em>EAAI</em>, <em>126</em>,
107014. (<a
href="https://doi.org/10.1016/j.engappai.2023.107014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel chaotic heterogeneous comprehensive learning particle swarm optimization (CLPSO) method for the simultaneous size and shape design of structures. The heterogeneous CLPSO divides the particles into two explorative and exploitative subpopulations. The exploration performs the global searches for the set of best particles experienced solely within its own subpopulation, whilst the exploitation refines the deep searches learnt from the global best particle over an entire population. In essence, the proposed method maintains a good balance between the global explorative and local exploitative optimization schemes. The global searches within the explorative subpopulation are independent to the exploitative simulations even if the latter scheme prematurely converges to the local swarm position. For both subpopulations, the comprehensive learning approach constructs the particles through a cross-positioning process on the individual variable space and avoids the local optimal pitfall. Moreover, the chaotic logistic map within the exploitative optimization tests the global best particle through the set of diversely generated samples and hence enhances the local search ability. Various enriching techniques, including automatic adaptive (inertial weight and acceleration) parameters with dynamic space reduction, are incorporated to improve the likelihood of finding the optimal solution of practical-scale problems at modest computing efforts. The accuracy and robustness of the proposed method are illustrated through a number of planar and spatial truss design benchmarks subjected to the challenging nonconvex and/or nonsmooth programs.},
  archive      = {J_EAAI},
  author       = {Thu Huynh Van and Sawekchai Tangaramvong and Wei Gao},
  doi          = {10.1016/j.engappai.2023.107014},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107014},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Chaotic heterogeneous comprehensive learning PSO method for size and shape optimization of structures},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CTRAN: CNN-transformer-based network for natural language
understanding. <em>EAAI</em>, <em>126</em>, 107013. (<a
href="https://doi.org/10.1016/j.engappai.2023.107013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intent-detection (ID) and slot-filling (SF) are fundamental tasks for natural language understanding. This study introduces a new encoder–decoder CNN-Transformer-based architecture (CTRAN) designed for ID and SF. The encoder integrates of BERT, followed by several convolutional layers with different kernel sizes. We propose using a kernel size of 1 to preserve the one-to-one correspondence between input tokens and output tags. Subsequently, we rearrange the output of the convolutional layer using the window feature sequence and apply stacked Transformer encoders. The ID decoder leverages self-attention and a linear layer, while the SF decoder employs an aligned Transformer decoder with a zero diagonal mask, facilitating alignment between output tags and input tokens. We evaluate our model on ATIS and SNIPS datasets, achieving 98.46% and 98.30% F1 score for the SF task, respectively. These results surpass the previous state-of-the-art by 0.64% and 0.99%. Moreover, we compare two strategies: using a language model as the encoder or as word embedding. We find out that the latter strategy yields better results.},
  archive      = {J_EAAI},
  author       = {Mehrdad Rafiepour and Javad Salimi Sartakhti},
  doi          = {10.1016/j.engappai.2023.107013},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107013},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CTRAN: CNN-transformer-based network for natural language understanding},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Deep learning-powered vessel traffic flow prediction with
spatial-temporal attributes and similarity grouping. <em>EAAI</em>,
<em>126</em>, 107012. (<a
href="https://doi.org/10.1016/j.engappai.2023.107012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perceiving the future trend of Vessel Traffic Flow (VTF) in advance has great application values in the maritime industry. However, using such big data from the Automatic Identification System (AIS) for accurate VTF prediction remains challenging. Deep training networks can learn valuable features from extensive historical data. This paper proposes a new learning-based prediction network, improved Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) with similarity grouping, including three views. To effectively enable the training network to capture the temporal and periodic (i.e. a spatial attribute) change characteristics of VTF, the CNN and LSTM are employed to compose spatial and temporal views, respectively. Hence, the original one-dimensional data is transformed into a matrix (hour of the day ✕ day) to adapt the input of the proposed methodology. In practical applications, VTF of multiple adjacent target regions need to be predicted simultaneously, and the changes of VTF in different areas may influence each other. To explore their hidden relationships, the similarity grouping view aims to find the target area that exhibits the most similarity with the VTF change trend of the current research area. Furthermore, similar information is combined with the features generated from the other two views to obtain the prediction results. In summary, the new advantage lies in mining the spatiotemporal attributes of data and fusing the similarity information of adjacent regions. Comparative experiments with eleven other methods on realistic VTF datasets show that the proposed method demonstrates superior prediction accuracy and stability performance.},
  archive      = {J_EAAI},
  author       = {Yan Li and Maohan Liang and Huanhuan Li and Zaili Yang and Liang Du and Zhongshuo Chen},
  doi          = {10.1016/j.engappai.2023.107012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-powered vessel traffic flow prediction with spatial-temporal attributes and similarity grouping},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A problem-specific knowledge based artificial bee colony
algorithm for scheduling distributed permutation flowshop problems with
peak power consumption. <em>EAAI</em>, <em>126</em>, 107011. (<a
href="https://doi.org/10.1016/j.engappai.2023.107011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A distributed permutation flowshop scheduling problem (DPFSP) with peak power consumption is addressed in this work. The instantaneous energy consumption of each factory cannot exceed a threshold. First, a mathematical model is developed to describe the concerned problem. Second, an improved artificial bee colony (IABC) algorithm is proposed. Based on problem-specific knowledge, three new solution generation operators, e.g., shift, swap, and speed adjust, are designed for employ bees and onlooker bees. A local search operation is developed to improve the quality of current best-known solution in each iteration. 450 instances are solved to evaluate the performance of IABC via comparing to seven state-of-the-art algorithms. The average relative percentage increase (ARPI) of IABC ranks 1 among all compared algorithms. The results and discussions show that the proposed IABC algorithm has strong competitiveness for solving the DPFSP with peak power consumption.},
  archive      = {J_EAAI},
  author       = {Yuan-Zhen Li and Kaizhou Gao and Lei-Lei Meng and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1016/j.engappai.2023.107011},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107011},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A problem-specific knowledge based artificial bee colony algorithm for scheduling distributed permutation flowshop problems with peak power consumption},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized backpropagation neural network models for the
prediction of nanomaterials concentration for purification industrial
wastewater. <em>EAAI</em>, <em>126</em>, 107010. (<a
href="https://doi.org/10.1016/j.engappai.2023.107010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an optimized backpropagation neural network (BPNN) prediction models have been proposed to estimate the concentration of titanium dioxide (TiO 2 ) nanomaterials required for the removal of Acid Black 24 dye, a type of textile dye, from industrial wastewater. The research gap addressed in this study lies in the investigation of various optimization algorithms for BPNN models and their profound impact on the accuracy of nanomaterial concentration predictions, thus contributing to the advancement of nanotechnology-based wastewater treatment research and its practical applications in industrial settings. Although several studies have predicted the amount of nanomaterial needed to degrade the dyes in industrial wastewater using BPNN, few have investigated the effects of optimized BPNN and how greatly the amount of degradation can vary. Therefore, six different optimization algorithms, including genetic algorithms (GAs), ant colony optimization (ACO), particle swarm optimization (PSO), evaluation strategy (ES), biogeography-based optimization (BBO), and population-based incremental learning algorithm (PBIL), are applied to optimize and evaluate the BPNN models. Experimental data obtained from chemical laboratory experiments are used to train and test the models, with different experiments conducted for various factors like TiO 2 , H 2 SO 4 , NaIO 4 , K 2 S 2 O 8 , dye, and silver nitrate. The performance of the optimized BPNN models is assessed using metrics such as mean squared error (MSE), root means squared error (RMSE), and R-squared (R 2 ). The results demonstrate the effectiveness of the proposed models, with ACO yielding the best outcomes across all models. The R 2 values for the TiO 2 , H 2 SO 4 , NaIO 4 , and K 2 S 2 O 8 models after optimization indicate perfect predictions, whereas the R 2 values before optimization ranged from 0.888 to 0.984. PSO performs well for most models except for K 2 S 2 O 8 , GA improves most models except for the silver nitrate model, ES enhances only the Dye model, and PBIL does not affect the TiO 2 model. Overall, the optimized BPNN models exhibit impressive accuracy in estimating the TiO 2 concentration required for removing Acid Black 24 dye from industrial wastewater.},
  archive      = {J_EAAI},
  author       = {Aboul Ella Hassanien and Lobna M. Abouelmagd and Amira S. Mahmoud and Ashraf Darwish},
  doi          = {10.1016/j.engappai.2023.107010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimized backpropagation neural network models for the prediction of nanomaterials concentration for purification industrial wastewater},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Digital twin framework using agent-based metaheuristic
optimization. <em>EAAI</em>, <em>126</em>, 107009. (<a
href="https://doi.org/10.1016/j.engappai.2023.107009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite advances in instrumentation and measurement techniques, it is still necessary to update numerical models to simulate or predict some structural responses, for example. Thus, this work proposes a metaheuristic framework based on hybrid agents, an approach within the Artificial Intelligence (AI) topics for updating Finite Element (FE) numerical models. This framework aims to provide flexible non-deterministic strategies to guide the updating process, ranging from simple local search procedures to complex learning processes. Two case studies are presented: (i) a free–free aluminium beam tested under laboratory conditions and; (ii) a catamaran tested during a sea trial under real operating conditions. The updating process aimed to optimize the stiffness matrix while maintaining the mass matrix unchanged. The objective function seeks to minimize the differences between numerical and experimental modal parameters, namely, natural frequencies and vibration modes. Results from the digital twin framework showed that the difference in natural frequencies significantly decreased, for example, 9% to 1% for the free–free aluminium beam and 15% to 4% for the catamaran’s main deck, when comparing the experimental with the updated FE model. As for the updated FE vibration modes, the Modal Assurance Criteria (MAC) values decreased slightly in both cases but within the acceptable MAC values (above 0.9), thus showing good consistency with the experimental vibration modes. In the end, the proposed framework was able to update the FE model directly using its respective reduced model, circumventing the”black box” of commercial packages.},
  archive      = {J_EAAI},
  author       = {Brenno Moura Castro and Marcelo de Miranda Reis and Ronaldo Moreira Salles and Ulisses A. Monteiro and Ricardo H.R. Gutiérrez},
  doi          = {10.1016/j.engappai.2023.107009},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107009},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Digital twin framework using agent-based metaheuristic optimization},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive sliding mode controller based on fuzzy rules for a
typical excavator electro-hydraulic position control system.
<em>EAAI</em>, <em>126</em>, 107008. (<a
href="https://doi.org/10.1016/j.engappai.2023.107008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the trajectory tracking accuracy and robustness of a typical heavy electro-hydraulic position system, a fuzzy adaptive sliding mode controller is proposed. A potential-like function is introduced to design a new sliding surface with non-linear integral term. An adaptive controller is designed to approximate the equivalent controller in sliding mode control. Stability of the controller is demonstrated by Lyapunov method, and the chattering phenomenon caused by the nonlinear switching term is reduced by using the fuzzy switching method, 25 fuzzy rules are given to adjust the sliding mode switching controller. Simulations with sinusoidal, ramp and step signals, and experiments with leveling operation at different speeds are carried out. The proposed controller can follow the reference trajectory quickly and smoothly, and has certain anti-interference ability. Compared with the traditional sliding mode controller, the proposed controller has small tracking error, fast response and good tracking performances.},
  archive      = {J_EAAI},
  author       = {Hao Feng and Jinye Jiang and Xiaodan Chang and Chenbo Yin and Donghui Cao and Hongfu Yu and Chunbiao Li and Jiaxue Xie},
  doi          = {10.1016/j.engappai.2023.107008},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107008},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive sliding mode controller based on fuzzy rules for a typical excavator electro-hydraulic position control system},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MLR-net: A multi-layer residual convolutional neural network
for leather defect segmentation. <em>EAAI</em>, <em>126</em>, 107007.
(<a href="https://doi.org/10.1016/j.engappai.2023.107007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is critical to recognize anomalous features in wet-blue leather samples as part of industrial quality control in the leather industry. In industrial settings, manual inspection of leather samples is the present practice. Visual inspection-based leather processing is required to meet current industry requirements that encourage large-scale automation. Visual assessment of uneven surfaces is a difficult subject since irregularities can assume many different shapes and colors. The objective of this research is to develop an automated system that can detect the defects of leather images based on visual surface analysis. A deep learning-based strategy is developed to accomplish this goal, which trains the system to identify uneven and regular leather surfaces and classify leather images based on those surfaces. To address the task of defect segmentation in leather images, we introduce MLR-Net, a multi-layer residual convolutional neural network. Our proposed MLR-Net demonstrates promising performance in this task, achieving competitive results on our curated leather images dataset. The evaluation of MLR-Net reveals average sensitivity of 87.50%, specificity of 99.78%, an accuracy of 95.98%, F 1 -score of 85.90%, and Intersection over Union (IoU) of 78.98% respectively. These metrics indicate the effectiveness of MLR-Net in accurately identifying and segmenting defects in leather images.},
  archive      = {J_EAAI},
  author       = {Shahzaib Iqbal and Tariq M. Khan and Syed S. Naqvi and Geoff Holmes},
  doi          = {10.1016/j.engappai.2023.107007},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107007},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MLR-net: A multi-layer residual convolutional neural network for leather defect segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supplier selection through interval type-2 trapezoidal fuzzy
multi-attribute group decision-making method with logarithmic
information measures. <em>EAAI</em>, <em>126</em>, 107006. (<a
href="https://doi.org/10.1016/j.engappai.2023.107006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supplier selection is a hot issue in logistics and procurement under the new economic situation. For the problems of supplier selection, the uncertainty and complexity of decision-making information often led to the mistakes in the process of group decision-making. In this paper, interval type-2 trapezoidal fuzzy (IT2TrF) information is used to deal with uncertainty and complex decision-making information, and a multi-attribute group decision making (MAGDM) method with IT2TrF information measures is designed for supplier selection problems. Specifically, we first present three axiomatic definitions for IT2TrF information measures. Then, based on logarithmic function, the IT2TrF logarithmic information entropy, the IT2TrF logarithmic similarity and the IT2TrF logarithmic cross-entropy are proposed to measure the fuzziness and similarity of decision-making information. In addition, an attribute weights determination method based on IT2TrF information entropy is established. Finally, a numerical example regarding assess the performance of suppliers is provided, and the comparative analysis demonstrates the applicability and feasibility of the developed MAGDM method.},
  archive      = {J_EAAI},
  author       = {Feifei Jin and Yiqing Zhao and Xiaozeng Zheng and Ligang Zhou},
  doi          = {10.1016/j.engappai.2023.107006},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107006},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Supplier selection through interval type-2 trapezoidal fuzzy multi-attribute group decision-making method with logarithmic information measures},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning for traffic signal control:
Incorporating a virtual mesoscopic model for depicting oversaturated
traffic conditions. <em>EAAI</em>, <em>126</em>, 107005. (<a
href="https://doi.org/10.1016/j.engappai.2023.107005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, with increasing urban traffic congestion, there has been an upsurge in studies on reinforcement learning for traffic signal control (RL-TSC), which enables efficient traffic management. However, most existing RL-TSC research relies on simulation, and instances of real-world application are relatively scarce. Furthermore, existing RL-TSC methods employ a step-based approach, controlling traffic signals every short step. This approach can be inefficient in oversaturated traffic conditions, where large deviations in traffic demand between movements prevent traffic signals from being effectively managed based on the overall traffic situation. In this study, we aim to transform simulation-based RL-TSC into a more practical and applicable model. We have developed a RL-TSC method capable of responding to oversaturated traffic conditions, designing an action space that enables the agent to derive an optimal signal set for every cycle length, thereby understanding the traffic situation across all movements. During each cycle length, our proposed model conducts traffic signal optimization and identifies the optimal signal through an iterative exploration. To facilitate a fast and accurate strategy search process, we developed a kinematic wave-based mesoscopic model. This model estimates the density across the entire link, based on collected traffic data and derives the state and reward values. We have validated the field applicability of the proposed RL-TSC method through a real-world demonstration at a congested intersection in Seoul, Korea. The results indicated a significant improvement in traffic congestion, with the average queue length at the intersection reduced by up to 11.4%.},
  archive      = {J_EAAI},
  author       = {Hyosun Lee and Yohee Han and Youngchan Kim},
  doi          = {10.1016/j.engappai.2023.107005},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107005},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning for traffic signal control: Incorporating a virtual mesoscopic model for depicting oversaturated traffic conditions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An imbalanced classification approach for establishment of
cause-effect relationship between heart-failure and pulmonary embolism
using deep reinforcement learning. <em>EAAI</em>, <em>126</em>, 107004.
(<a href="https://doi.org/10.1016/j.engappai.2023.107004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pulmonary Embolism (PE) — a non-cardiac cause of cardiac arrest is a strenuous job to perform as it is non-specific in presentation and shares various overlapping features with various other clinical disorders like Myocardial Infarction, Pneumonia, etc. This paper delineates a method to identify Pulmonary Embolism (PE) as a reason for Heart Failure using Deep Reinforcement Learning (DRL) algorithm. The methodology has been partitioned into two phases. Phase I acts towards the creation of a novel dataset as there was no data available for this particular problem statement. Phase II deals with the scope and application of the DRL algorithm on the above-invented dataset. The dataset formed is imbalanced in its essence. To effectively tackle the imbalanced dataset challenge, a cutting-edge imbalanced classification algorithm rooted in the power of Deep Reinforcement Learning (DRL) has been embraced. The classification model has been drawn up as a Sequential Decision-Making procedure and is resolved by making use of the DRL algorithm viz Double Deep Q-Network (DDQN). A classification action is performed by an agent on a single sample at each time step. Classification actions are assessed by the environment, based on the assessment, a reward is given to an agent. In order to make the agent more responsive towards the minority class samples, rewards belonging to the minority class are higher. Under the supervision of this reward system, the agent finally learns the optimal classification policy for this imbalanced dataset problem. Comparative analysis of the DDQN algorithm with other Deep Reinforcement Learning algorithms, including Dueling DQN, and Proximal Policy Optimization (PPO) algorithms has been performed in order to arrive at the best learning technique for the dataset. Furthermore, the DDQN algorithm has been evaluated against a selection of Machine Learning (ML) algorithms. From the experimentation, it is demonstrated that the DDQN model outperformed other approaches with an accuracy of 99.99%, G-mean 0.9999, Recall 1.0000, and Specificity 0.9999.},
  archive      = {J_EAAI},
  author       = {Naira Firdous and Nusrat Mohi Ud Din and Assif Assad},
  doi          = {10.1016/j.engappai.2023.107004},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107004},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An imbalanced classification approach for establishment of cause-effect relationship between heart-failure and pulmonary embolism using deep reinforcement learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A semi-supervised network framework for low-light image
enhancement. <em>EAAI</em>, <em>126</em>, 107003. (<a
href="https://doi.org/10.1016/j.engappai.2023.107003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing supervised learning-based low-light image enhancement algorithms treat all degradations as a whole, resulting in limited enhancement performance. It is difficult for fully unsupervised learning to recover more hidden details, making the augmented results unsatisfactory for visual needs. To overwhelm the limitations of supervised and unsupervised learning, we propose a Semi-Supervised Network Framework (SSNF) to enhance low-light images. Specifically, we decouple the low-light image enhancement task into two stages. In the first stage of the SSNF, we employ methods based on information entropy and Retinex to improve the visibility of images. It is worth mentioning that this stage is a lightweight self-supervised network, which only needs to input low-light images and undergo minute-level training to achieve brightness improvement. In the second stage of the SSNF, we utilize U-Net and residual networks to remove problems such as noise and degradation existing in the first-stage enhancement results, thereby improving the visual properties of the enhanced images. It overwhelms the challenge of dealing with low-light images directly. We conduct extensive experiments on datasets such as LOL, synthetic, DICM, etc. The experimental results show that SSNF exhibits better visual effects and outperforms other advanced methods in performance metrics.},
  archive      = {J_EAAI},
  author       = {Jin Chen and Yong Wang and Yujuan Han},
  doi          = {10.1016/j.engappai.2023.107003},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107003},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A semi-supervised network framework for low-light image enhancement},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving combined economic and emission dispatch problems
using reinforcement learning-based adaptive differential evolution
algorithm. <em>EAAI</em>, <em>126</em>, 107002. (<a
href="https://doi.org/10.1016/j.engappai.2023.107002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, economic and environmental concerns in production have become increasingly significant. To address these issues, the Combined Economic and Emission Dispatch (CEED) problem has been introduced to optimize the power generation process by considering fuel cost and emitted substances. However, due to the nonlinearity and nonconvexity of the objective function, the optimization of CEED remains a challenge. In this paper, we develop a Reinforcement Learning-based Adaptive Differential Evolution (RLADE) algorithm to enhance the optimization performance. The mutation strategy and crossover probability of RLADE are optimized using Reinforcement Learning (RL) to respectively ensure better convergence speed and searchability. Additionally, two modifications of RL, namely the adaptive population size-based state division and fitness-ranking-based reward mechanism, are proposed to improve the accuracy of state division and reward calculation in RL. The experiments conducted in this paper consider two objective formulation methods of CEED problems, namely the quadratic and cubic criterion functions. The mean values and standard deviations of the obtained solutions were utilized to assess the performance of RLADE, as well as other comparative algorithms, namely DE algorithm and two RL-based DE variants. The results clearly demonstrate that RLADE surpasses its counterparts with proportion of 100%, 85.7%, and 100% for the 6-unit and 11-unit quadratic CEED problems, as well as cubic criterion functions, in terms of both search accuracy and convergence ability. Furthermore, the significance of RLADE&#39;s superiority is confirmed through the Wilcoxon&#39;s signed rank test.},
  archive      = {J_EAAI},
  author       = {Wenguan Luo and Xiaobing Yu and Yifan Wei},
  doi          = {10.1016/j.engappai.2023.107002},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107002},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving combined economic and emission dispatch problems using reinforcement learning-based adaptive differential evolution algorithm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive differential evolution algorithm based on
deeply-informed mutation strategy and restart mechanism. <em>EAAI</em>,
<em>126</em>, 107001. (<a
href="https://doi.org/10.1016/j.engappai.2023.107001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution is one of the most powerful stochastic real-parameter optimization algorithms currently, and its performance depends heavily on control parameters and mutation strategy. In recent years, methods to select favorable parameters control and mutation strategy when solving various optimization problems have attracted increasing attention. To choose an appropriate mutation strategy and control parameters for a given optimization problem, in this paper, a Adaptive Differential Evolution Algorithm Based on Deeply-Informed Mutation Strategy and Restart Mechanism (ADEDMR) is proposed, and the ADEDMR algorithm has the following characteristics: First, a deeply-informed mutation strategy is proposed, which takes into account the information of suboptimal solutions discarded by selection and inherits the advantages of the powerful “DE/target-pbest/1/bin”, aiming to obtain a better perceptual landscape of the target function and improve the candidate diversity of the trial vector. Second, according to the evolution process, the segmentation method is used to control F , which alleviates the scaling of F in the wrong direction, and makes the newly generated F fit more accurately. Third, a new population restart mechanism is adopted to further enhance population diversity by adaptively enhancing the search ability of hopeless individuals and randomly replacing some inferior individuals with wavelet walks. To evaluate the performance of our proposed algorithm, comparative experiments are conducted on 72 benchmark functions from the CEC2014, CEC2017 and CEC2022 test suites. Experimental results show that the proposed ADEDMR has higher convergence accuracy, better optimization ability when solving high-dimensional complex functions, and is competitive with six recent strong DE variants.},
  archive      = {J_EAAI},
  author       = {Quanbin Zhang and Zhenyu Meng},
  doi          = {10.1016/j.engappai.2023.107001},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107001},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive differential evolution algorithm based on deeply-informed mutation strategy and restart mechanism},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). μMOSM: A hybrid multi-objective micro evolutionary
algorithm. <em>EAAI</em>, <em>126</em>, 107000. (<a
href="https://doi.org/10.1016/j.engappai.2023.107000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-objective optimization problems (MOPs), several mutually conflicting objectives are optimized simultaneously. In such scenarios, there is not a unique solution to the problem; instead, there is a set of solutions known as the Pareto front, representing the trade-off between objectives. Multi-objective evolutionary algorithms (MOEAs) can approximate these solutions in a single run. However, due to their resource-intensive nature, MOEAs are not suitable for solving real-time and engineering MOPs such as the optimization of manufacturing processes and energy consumption in wireless networks, where a fast convergence rate with less computational cost is required. Fortunately, micro versions of MOEAs can meet this requirement by utilizing a tiny population size. However, this can result in a rapid loss of diversity and the algorithm may easily fall into a local optimum. While some approaches such as the restart technique have been proposed to address this issue, hybrid techniques such as integrative, collaborative, and decomposition-based methods have not been effectively considered in the design of micro algorithms, despite hybridization being a widely accepted method for enhancing the diversity of evolutionary algorithms. In this study, we propose a hybrid micro MOEA called μMOSM that can effectively tackle the diversity loss problem and accelerate the convergence rate in approximating Pareto front solutions. Experimental results on benchmark test suites and a real-world MOP demonstrate the advantages of our proposed algorithm and confirm that μMOSM outperforms state-of-the-art MOEAs and micro MOEAs such as MOSM, ADE-MOIA, MMOPSO, NSGA-III, MOEA/D-FRRMAB, μFAME, and ASMiGA.},
  archive      = {J_EAAI},
  author       = {Yousef Abdi and Mohammad Asadpour and Yousef Seyfari},
  doi          = {10.1016/j.engappai.2023.107000},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {107000},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {μMOSM: A hybrid multi-objective micro evolutionary algorithm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment analysis of imbalanced datasets using BERT and
ensemble stacking for deep learning. <em>EAAI</em>, <em>126</em>,
106999. (<a
href="https://doi.org/10.1016/j.engappai.2023.106999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet is a crucial way to share information in both personal and professional areas. Sentiment analysis attracts great interest in marketing, research, and business today. The instability faced by imbalanced datasets on sentiment analysis is examined in this research. Balancing the datasets using techniques based on under-sampling and over-sampling is examined to achieve more efficient classification results as the effects of using BERT as word embedding and ensemble learning methods for classification. The effects of the resampling training set algorithms on different deep learning classifiers were investigated using BERT as a word embedding model and Cohen&#39;s kappa, accuracy, ROC-AUC curve, and MCC as evaluation metrics with k-fold validation on three sentiment analysis datasets containing English, Arabic, and Moroccan Arabic Dialect texts. Also, we did those performance metrics for all models when scaling the dataset for training and testing, and we calculated the memory and the execution time for each model. Finally, we analyzed the National Office of Railways of Morocco (ONCF) customers&#39; Facebook comments in Modern Standard Arabic (MSA) and MD to determine customer satisfaction as positive, negative, and neutral comments.},
  archive      = {J_EAAI},
  author       = {Nassera Habbat and Hicham Nouri and Houda Anoun and Larbi Hassouni},
  doi          = {10.1016/j.engappai.2023.106999},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106999},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sentiment analysis of imbalanced datasets using BERT and ensemble stacking for deep learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep reinforcement learning for the rapid on-demand design
of mechanical metamaterials with targeted nonlinear deformation
responses. <em>EAAI</em>, <em>126</em>, 106998. (<a
href="https://doi.org/10.1016/j.engappai.2023.106998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical metamaterials are artificial materials with unique global properties due to the structural geometry and material composition of their unit cell. Typically, mechanical metamaterial unit cells are designed such that, when tessellated, they exhibit unique mechanical properties such as zero or negative Poisson&#39;s ratio and negative stiffness. Beyond these applications, mechanical metamaterials can be used to achieve tailorable nonlinear deformation responses. Computational methods such as gradient-based topology optimization (TO) and size/shape optimization (SSO) can be implemented to design these metamaterials. However, both methods can lead to suboptimal solutions or a lack of generalizability. Therefore, this research used deep reinforcement learning (DRL), a subset of deep machine learning that teaches an agent to complete tasks through interactive experiences, to design mechanical metamaterials with specific nonlinear deformation responses in compression or tension. The agent learned to design the unit cells by sequentially adding material to a discrete design domain and being rewarded for achieving the desired deformation response. After training, the agent successfully designed unit cells to exhibit desired deformation responses not experienced during training. This work shows the potential of DRL as a high-level design tool for a wide array of engineering applications.},
  archive      = {J_EAAI},
  author       = {Nathan K. Brown and Anthony P. Garland and Georges M. Fadel and Gang Li},
  doi          = {10.1016/j.engappai.2023.106998},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106998},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning for the rapid on-demand design of mechanical metamaterials with targeted nonlinear deformation responses},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TSRes-YOLO: An accurate and fast cascaded detector for waste
collection and transportation supervision. <em>EAAI</em>, <em>126</em>,
106997. (<a
href="https://doi.org/10.1016/j.engappai.2023.106997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of frequently mixed loading in the waste collection and transportation process, which leads to degradation of the waste classification effect. A supervision method based on a cascaded detector combined with ResNet18 and YOLOv5 for waste collection and transportation is proposed. First, the improved YOLOv5s is used to identify the location and states of the garbage cans. By replacing batch normalization in the backbone with representative batch normalization, the specific features are enhanced with a simple and effective feature calibration scheme and produce a more stable feature distribution. Introducing CBAM into the CSP module of YOLOv5 helps the network pay more attention to special regions. The Ghost convolution effectively reduces the number of parameters and faster the speed without affecting the performance of the model. Moreover, the classifier, improved ResNet-18, classifies the color of garbage cans detected by YOLOv5. SE-Net is added at the beginning of the residual structure, and ResNet-D structure is used to improve the accuracy of the network at the same time. Finally, a database for waste classification and collection supervision is constructed based on the images provided by the relevant city department. Then, a series of experiments are performed on the database. The experimental results show that the improved YOLOv5 network reaches an mAP of 98.0%, the accuracy of the improved ResNet18 reaches 98.4% and the accuracy of the cascaded detector reaches 90.93% with a speed of 43.2 ms/it, which meets the requirements for urban garbage collection and transportation supervision.},
  archive      = {J_EAAI},
  author       = {Yanhong He and Junfeng Li},
  doi          = {10.1016/j.engappai.2023.106997},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106997},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TSRes-YOLO: An accurate and fast cascaded detector for waste collection and transportation supervision},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust discriminant latent variable manifold learning for
rotating machinery fault diagnosis. <em>EAAI</em>, <em>126</em>, 106996.
(<a href="https://doi.org/10.1016/j.engappai.2023.106996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is an important technology for performing intelligent manufacturing. To simultaneously maintain high manufacturing quality and low failure rate for manufacturing systems, it is of great value to accurately locate the fault element, evaluate the fault severity and find the fault root cause. In order to effectively perform feature extraction for rotating machinery fault diagnosis, a robust discriminant latent variable manifold learning (RDLVML) algorithm is proposed in this paper. Specifically, RDLVML algorithm could effectively select the features of the high-dimensional fault data, and extract the low-dimensional fault features with better discrimination. Through the idea of discriminative learning, the accuracy of fault diagnosis was improved by increasing the aggregation of the same state feature samples and the difference between different classes of feature samples. A novel weighted neighborhood graph is proposed by constructing the q -Rényi kernel function, which could effectively suppress the interference of outliers and noise, and make the RDLVML algorithm more robust. Moreover, the fault diagnosis method of rotating machinery based on RDLVML is proposed in this paper. Through experimental verifications and comparisons with several classical feature selection algorithms, rotating machinery fault diagnosis could be more accurately performed by this method.},
  archive      = {J_EAAI},
  author       = {Changyuan Yang and Sai Ma and Qinkai Han},
  doi          = {10.1016/j.engappai.2023.106996},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106996},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust discriminant latent variable manifold learning for rotating machinery fault diagnosis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven distributionally newsvendor problem for
edge-cloud collaboration in intelligent manufacturing systems.
<em>EAAI</em>, <em>126</em>, 106995. (<a
href="https://doi.org/10.1016/j.engappai.2023.106995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent manufacturing systems, the industrial informatics has features of multi-source, multi-noise, and time series. It is difficult for small and medium enterprises (SMEs) to directly exploit the enormous amounts of data due to the limited budgets and computing capabilities. Edge intelligence is a key technique to power intelligent manufacturing systems and provide knowledge transferred from the cloud to SMEs at the edges. To address edge-cloud collaboration issue, we propose a refined data-driven distributionally robust newsvendor model based on φ -divergence measures and imprecise Dirichlet models (DRN-IDM). We construct new distributional uncertainty sets by effectively integrating local censored demand data and cloud knowledge, which helps SMEs to make intelligent production decisions and reduce significant decision deviations, even under a small censored data set. In particular, the novel demand uncertainty sets can depict the distance between distributions and probability intervals. Then, we transform the DRN-IDM model into a convex optimization model that is amenable to algorithmic implementation. Additionally, based on the coefficient of variation of limited historical data, we propose an adaptive demand information fusion procedure to achieve excellent synergy effect from cloud knowledge. We also validate the effectiveness of the DRN-IDM model and the practicability of adaptive procedure using extensive numerical studies with both simulated and real-life data. Furthermore, we measure the relative expected value of cloud knowledge and investigate the effect of censored demand samples. Our results verify the effectiveness condition of the DRN-IDM model and indicate that cloud knowledge can improve the precision and robustness of SMEs’ production decisions with small-scale censored data. Interestingly, the verified adaptive procedure can be applied in the learning criteria design of metaheuristics in intelligent manufacturing systems, and the reconstructed uncertainty set can narrow the search space to improve the convergence performance of algorithms.},
  archive      = {J_EAAI},
  author       = {Cheng-hu Yang and Xiao-li Su and Peng Wu},
  doi          = {10.1016/j.engappai.2023.106995},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106995},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven distributionally newsvendor problem for edge-cloud collaboration in intelligent manufacturing systems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-guided and fine-grained feature extraction from
face images for gaze estimation. <em>EAAI</em>, <em>126</em>, 106994.
(<a href="https://doi.org/10.1016/j.engappai.2023.106994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on appearance gaze estimation based on deep learning has achieved considerable results. However, a lack of information in the extracted local blocks reduces the precision of gaze estimation since CNNs do not prioritize the information within the key picture blocks for face image estimation. In this research, fine-grained visual information is extracted from local blocks using a Transformer in Transformer (TNT) model that emphasizes the interactions between local blocks. First, TNT-based gaze estimation models (GTiT-Pure and GTiT-Hybrid) are established with the TNT model to capture both coarse- and fine-grained visual information about the face, which are then combined to provide a feature representation for gaze regression. Then, the performance of the two models are evaluated on four gaze estimation datasets. Experimental results demonstrate that the pre-trained GTiT-Pure has less gaze estimation error than the majority of CNNs and Transformer models, and that the GTiT-Hybrid model performs the best on the EyeDiap and RT-Gene datasets. The GTiT model which combines both coarse- and fine-grained gaze features in face images, can be used to further explore the advantages of the Transformer model in gaze feature extraction.},
  archive      = {J_EAAI},
  author       = {Chenglin Wu and Huanqiang Hu and Kean Lin and Qing Wang and Tianjian Liu and Guannan Chen},
  doi          = {10.1016/j.engappai.2023.106994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention-guided and fine-grained feature extraction from face images for gaze estimation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A lightweight dense relation network with attention for
hyperspectral image few-shot classification. <em>EAAI</em>,
<em>126</em>, 106993. (<a
href="https://doi.org/10.1016/j.engappai.2023.106993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have significantly progressed in hyperspectral image (HSI) classification. However, deep learning relies on large labeled data for training. The cost of labeling samples is enormous. In practical classification tasks, only a few labeled samples are available. A lightweight dense relation network with attention (LDA-RN) was presented for HSI few-shot classification. First, we design a 3D feature embedding module for spectral–spatial feature extraction. A light attention module (CSA), including the channel attention (CA) submodule and spatial attention (SA) submodule, is applied to reinforce essential features. Dense connections are used to fully utilize the feature information in each layer. Second, we propose a 2D relation learning module for classification by comparing the similarity between samples, using global average pooling to reduce the model parameters. Finally, meta-learning and fine-tuning training techniques are employed to enhance the model’s generalization ability and reduce the dependence on the labeled samples. Experimental results on three available HSI datasets suggest that the proposed LDA-RN outperforms existing advanced few-shot learning methods. For example, the experimental results show that the overall accuracy of the proposed method improves by 5.67% on the Univerisity of Pavia data set with only five labeled samples compared to the best method DCFSL.},
  archive      = {J_EAAI},
  author       = {Meilin Shi and Jiansi Ren},
  doi          = {10.1016/j.engappai.2023.106993},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106993},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight dense relation network with attention for hyperspectral image few-shot classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Material handling machine activity recognition by context
ensemble with gated recurrent units. <em>EAAI</em>, <em>126</em>,
106992. (<a
href="https://doi.org/10.1016/j.engappai.2023.106992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on machine activity recognition (MAR) is drawing more attention because MAR can provide productivity monitoring for efficiency optimization, better maintenance scheduling, product design improvement, and potential material savings. A particular challenge of MAR for human-operated machines is the overlap when transiting from one activity to another: during transitions, operators often perform two activities simultaneously, e.g., lifting the fork already while approaching a rack, so the exact time when one activity ends and another begins is uncertain. Machine learning models are often uncertain during such activity transitions, and we propose a novel ensemble-based method adapted to fuzzy transitions in a forklift MAR problem. Unlike traditional ensembles, where models in the ensemble are trained on different subsets of data, or with costs that force them to be diverse in their responses, our approach is to train a single model that predicts several activity labels, each under a different context. These individual predictions are not made by independent networks but are made using a structure that allows for sharing important features, i.e., a context ensemble. The results show that the gated recurrent unit network can provide medium or strong confident context ensembles for 95% of the cases in the test set, and the final forklift MAR result achieves accuracies of 97% for driving and 90% for load-handling activities. This study is the first to highlight the overlapping activity issue in MAR problems and to demonstrate that the recognition results can be significantly improved by designing a machine learning framework that addresses this issue.},
  archive      = {J_EAAI},
  author       = {Kunru Chen and Thorsteinn Rögnvaldsson and Sławomir Nowaczyk and Sepideh Pashami and Jonas Klang and Gustav Sternelöv},
  doi          = {10.1016/j.engappai.2023.106992},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106992},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Material handling machine activity recognition by context ensemble with gated recurrent units},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal hate speech detection via multi-scale visual
kernels and knowledge distillation architecture. <em>EAAI</em>,
<em>126</em>, 106991. (<a
href="https://doi.org/10.1016/j.engappai.2023.106991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People increasingly use social media platforms to express themselves by posting visuals and texts. As a result, hate content is on the rise, necessitating practical visual caption analysis. Thus, the relationship between image and caption modalities is crucial in visual caption analysis. Contrarily, most methods combine features from the image and caption modalities using deep learning architectures with millions of parameters already trained without integrating a specialized attention module, resulting in less desirable outcomes. This paper suggests a novel multi-modal architecture for identifying hateful memetic information in response to the above observation. The proposed architecture contains a novel &quot;multi-scale kernel attentive visual&quot; (MSKAV) module that uses an efficient multi-branch structure to extract discriminative visual features. Additionally, MSKAV utilizes an adaptive receptive field using multi-scale kernels. MSKAV also incorporates a multi-directional visual attention module to highlight spatial regions of importance. The proposed model also contains a novel &quot;knowledge distillation-based attentional caption&quot; (KDAC) module. It uses a transformer-based self-attentive block to extract discriminative features from meme captions. Thorough experimentation on multi-modal hate speech benchmarks MultiOff, Hateful Memes, and MMHS150K datasets achieved accuracy scores of 0.6250, 0.8750, and 0.8078, respectively. It also reaches impressive AUC scores of 0.6557, 0.8363, and 0.7665 on the three datasets, respectively, beating SOTA multi-modal hate speech identification models.},
  archive      = {J_EAAI},
  author       = {Anusha Chhabra and Dinesh Kumar Vishwakarma},
  doi          = {10.1016/j.engappai.2023.106991},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106991},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal hate speech detection via multi-scale visual kernels and knowledge distillation architecture},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DL-AMPUT-EEG: Design and development of the low-cost
prosthesis for rehabilitation of upper limb amputees using
deep-learning-based techniques. <em>EAAI</em>, <em>126</em>, 106990. (<a
href="https://doi.org/10.1016/j.engappai.2023.106990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upper limb amputation is a widespread problem worldwide, leading to massive loss of functionality for the victims. While a few solutions exist, these are often very expensive and involve expensive and dangerous surgical procedures. In this paper, we propose a low-cost, highly functional upper limb prosthesis controlled via Electroencephalogram (EEG) signals captured in real-time, classified into upper limb motion intention using a novel Genetic Algorithm (GA) optimized Long Short-Term Memory (LSTM) deep learning model to rehabilitate amputees. The proposed 3D-printed prosthetic arm has 3 Degrees-of-Freedom (DOF), which allows it to perform complex movements that can accurately emulate an actual human arm. The results discussed later in this paper conclude that our approach, while being low-cost, is highly accurate and functional.},
  archive      = {J_EAAI},
  author       = {Sachin Kansal and Dhruv Garg and Aditya Upadhyay and Snehil Mittal and Guneet Singh Talwar},
  doi          = {10.1016/j.engappai.2023.106990},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106990},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DL-AMPUT-EEG: Design and development of the low-cost prosthesis for rehabilitation of upper limb amputees using deep-learning-based techniques},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HPDE: A dynamic hierarchical population based differential
evolution with novel diversity metric. <em>EAAI</em>, <em>126</em>,
106989. (<a
href="https://doi.org/10.1016/j.engappai.2023.106989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential Evolution (DE) is one of the most effective methods for single-objective numerical optimization, however, the former state-of-the-art DE variants ignore the huge differences among the individuals in the population. To take full advantage of different individuals in the population, in this paper, a dynamic Hierarchical Population based Differential Evolution (HPDE) with novel diversity metric is proposed, and the HPDE algorithm has the following innovations: Firstly, the individuals in the hierarchical population are dynamically divided into two layers, the layer of elites, and the layer of ordinary individuals. Moreover, the ordinary layer individuals are further divided into secondary elites and inferior individuals. The individuals in the two layers employed different mutation strategies and the corresponding parameter control schemes. Secondly, a novel hierarchical population based mutation strategy is firstly proposed in our HPDE algorithm and the individuals in the elite layer employ the novel mutation strategy aiming at scouting the landscape of the objective while the ordinary individuals employ an improved “DE/target- p best/1/bin” strategy aiming at getting a better balance between exploration and exploitation of the solution space. Thirdly, a N ovel P arameter C ontrol technique, namely NPC technique, is employed in the adaptation of control parameters during the evolution. Fourthly, a new metric of population diversity is proposed and premature convergence can be avoided by maintaining better population diversity. To evaluate the performance of our HPDE algorithm, intensive experiments are conducted on 88 benchmark functions from the CEC2013, CEC2014 and CEC2017 test suites, and the results show the competitiveness of our HPDE with six recent state-of-the-art DE variants, e.g. it obtained 28 similar or better performance improvements out of the total 30 benchmarks on 30D optimization in comparison with the winner algorithm, the LSHADE algorithm, of the CEC2014 competition and it also obtained 19 similar or better performance improvements out of the total 30 benchmarks on 30D optimization in comparison with the winner DE variant, the jSO algorithm, of the CEC2017 competition. Furthermore, the novel HPDE algorithm is utilized to estimate the parameters of the photovoltaic model, and the experiment results support its superiority as well.},
  archive      = {J_EAAI},
  author       = {Zhenyu Meng and Quanbin Zhang},
  doi          = {10.1016/j.engappai.2023.106989},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106989},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HPDE: A dynamic hierarchical population based differential evolution with novel diversity metric},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PRAT: Accurate object tracking based on progressive
attention. <em>EAAI</em>, <em>126</em>, 106988. (<a
href="https://doi.org/10.1016/j.engappai.2023.106988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking aims to estimate the position of a given object in subsequent video sequences. One of the research focuses in tracking is feature fusion as the similar response maps generated by feature fusion can significantly affect tracking accuracy. However, traditional naive correlation and depthwise correlation blur the spatial information and do not perform well in low resolution, similar objects, partial occlusion and other scenes. In this paper, we propose a progressive attention tracker called PRAT. It performs sufficient similarity learning between the template and search region to achieve more accurate object tracking. Specifically, PRAT performs self-enhancement on template features, and uses unidirectional cross enhancement and progressive enhancement to fuse template features into search features. Therefore, the search region features have the ability of target perception. In addition, we also design a convolution-based network to replace the FFN in the original Transformer to enhance local semantics. Experiments on six challenging benchmarks show that our PRAT achieves state-of-the-art performance. Particularly, on the challenging UAV123, PRAT sets a new record with 0.703 SUC score. PRAT runs at 63 fps on GPU.},
  archive      = {J_EAAI},
  author       = {Yulin Zeng and Bi Zeng and Huiting Hu and Hong Zhang},
  doi          = {10.1016/j.engappai.2023.106988},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106988},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PRAT: Accurate object tracking based on progressive attention},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-tuning regulatory controller of cyclical disturbances
using data-driven frequency estimator based on fuzzy logic.
<em>EAAI</em>, <em>126</em>, 106987. (<a
href="https://doi.org/10.1016/j.engappai.2023.106987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two learning-type regulatory controllers: adaptive fuzzy iterative learning controller (AF-ILC) and adaptive fuzzy repetitive generalized predictive controller (AFR-GPC). The proposed controllers can reject the cyclical disturbances with small range frequency variations present in many control loops of industrial processes. Moreover, they can estimate the disturbance cycle using fuzzy logic with rules based on the previous values of the integral of the absolute error between the setpoint and output. The estimated period of the disturbance cycle is sent to the regulatory controllers to define the specific control actions required to reduce the oscillations in the process output. The advantage of this technique is that adaptive controllers are automatically adjusted by a frequency estimator, which only depends on process output data. The performance levels of the developed adaptive controllers are compared in the computational simulator of a nonlinear mold level of a continuous casting process employed in the steel industry. This process counteracts the periodic oscillations in the mold level caused by bulging disturbance. The numerical results show that both AF-ILC and AFR-GPC can reduce the oscillations in the output when the disturbance frequency changes by up to 5.2% and 13%, respectively.},
  archive      = {J_EAAI},
  author       = {Rogério P. Pereira and Eduardo J.F. Andrade and José L.F. Salles and Carlos T. Valadão and Ravena S. Monteiro and Gustavo Maia de Almeida and Marco A.S.L. Cuadros and Teodiano F. Bastos-Filho},
  doi          = {10.1016/j.engappai.2023.106987},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106987},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-tuning regulatory controller of cyclical disturbances using data-driven frequency estimator based on fuzzy logic},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A solar radiation intelligent forecasting framework based on
feature selection and multivariable fuzzy time series. <em>EAAI</em>,
<em>126</em>, 106986. (<a
href="https://doi.org/10.1016/j.engappai.2023.106986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate solar radiation forecasting can effectively improve solar energy utilization efficiency and decrease the operational cost of solar photovoltaic power plants. However, some common forecasting methods have certain limitations, such as neglecting data fuzziness, meteorological factors, feature selection, and seasonal adjustment. Therefore, a solar radiation intelligent forecasting framework based on feature selection and multivariable fuzzy time series is proposed. Specifically, a combined fuzzy strategy is used to fuzzy the data, and an improved multi-objective optimization algorithm is proposed to search for the optimal parameters. A seasonal multivariable fuzzy time series is proposed to achieve multivariable inputs and seasonal adjustments. The experimental analysis, statistical test, and robustness analysis all verify the superiority of the proposed forecasting framework compared with competitive models. The MAPE values of the proposed forecasting framework for two regions are about 6% and 4%, respectively, which outperform some common basic models such as BPNN(about 11% and 9%), ELM(about 12% and 10%), LSTM(about 9% and 7%). The comparison analysis further indicates that the vital parts of the forecasting framework containing feature selection, seasonal adjustment, multi-objective optimization, and multivariable inputs can all have a positive influence on forecasting performance.},
  archive      = {J_EAAI},
  author       = {Yuyang Gao and Ping Li and Hufang Yang and Jianzhou Wang},
  doi          = {10.1016/j.engappai.2023.106986},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106986},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A solar radiation intelligent forecasting framework based on feature selection and multivariable fuzzy time series},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-cost, autonomous microscopy using deep learning and
robotics: A crystal morphology case study. <em>EAAI</em>, <em>126</em>,
106985. (<a
href="https://doi.org/10.1016/j.engappai.2023.106985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data availability is a major obstacle to the successful application of artificial intelligence. In chemistry, pharmaceutical and materials science, generating labelled data on scale relies on expensive screening approaches that require major human and/or economic investments. Although industry uses sophisticated autonomous systems for such tasks, tight intellectual property concerns and strict confidentiality agreements limit data accessibility, thus restricting innovation and hindering the concept of ”open science”. Without automation, data collection is laborious and sample characterization often suffers from subjectivity introduced by the operator. This study tackles the challenge of pharmaceutical particle characterization by modifying a 3D printer to enable rapid, autonomous sample characterization using light microscopy. The system uses low-cost hardware and open-source software in a platform that is accessible and reproducible for the scientific community. As well as increasing throughput, this system uses deep learning to assign sample labels in real-time overcoming bias from subjective labelling, which hinders model performance. Different neural architectures were applied, including convolution and attention blocks, to maximize performance and demonstrate the transferability of the system. This autonomous system effectively characterized pharmaceutical crystal morphology, an area where subjective labelling and limited data have hindered applying machine learning models. By releasing this platform, researchers without access to sophisticated automation platforms can carry out larger in-house screening efforts to generate datasets for developing data-driven, intelligent models.},
  archive      = {J_EAAI},
  author       = {Matthew R. Wilkinson and Bernardo Castro-Dominguez and Chick C. Wilson and Uriel Martinez-Hernandez},
  doi          = {10.1016/j.engappai.2023.106985},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106985},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-cost, autonomous microscopy using deep learning and robotics: A crystal morphology case study},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new approach to developing software projects by assigning
teams to projects with interval-valued neutrosophic z numbers.
<em>EAAI</em>, <em>126</em>, 106984. (<a
href="https://doi.org/10.1016/j.engappai.2023.106984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software development projects are becoming increasingly important to achieve successful results in the global digitalization trend that has spread throughout the world at the time of the pandemic. The main software development methodologies (SDM) are waterfall and agile. This study investigates the achievement of success methodology through the evaluation of software development projects, personnel under the scope of SDM&#39;s. Software projects require strong human resources to be successful in terms of on-time completion and success. For software projects that include the human component, it is important to make project team SDM assignments more meaningful and accurate. The power of linguistic variables and the use of expert ratings in such assignments have been the focus of this paper. The reason for the strong representativeness is the conversion of linguistic variables to mathematical fuzzification, Interval Valued Neutrosophic Z-Numbers (NZN) are used to determine which SDM should be used first in projects. The results of the NZN are then incorporated into the NZN-Area model. This replaces the distance measurement equation used to rank alternatives with an area calculation. The NZN-Area Model is the new proposed form of the model. The NZN-Area model produced 22% better results in terms of defect numbers and 25% better results in terms of defect resolution time compared to the NZN method. Additionally, a sensitivity analysis was performed by comparing the NZN method and NZN-Area method with real data. The proposed NZN-Area method was found to be more consistent under variable conditions.},
  archive      = {J_EAAI},
  author       = {İbrahim Yel and Mehmet Emin Baysal and Ahmet Sarucan},
  doi          = {10.1016/j.engappai.2023.106984},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106984},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new approach to developing software projects by assigning teams to projects with interval-valued neutrosophic z numbers},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of classification models in limited data
scenarios with application to additive manufacturing. <em>EAAI</em>,
<em>126</em>, 106983. (<a
href="https://doi.org/10.1016/j.engappai.2023.106983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel framework that enables the generation of unbiased estimates for test loss using fewer labeled samples, effectively evaluating the predictive performance of classification models in data-limited applications. The framework’s key innovation lies in developing an adaptive sampling distribution that iteratively identifies influential testing samples based on interactions between learner and evaluator agents. Notably, the adaptive distribution dynamically adjusts the evaluator agent’s supervisory role by prioritizing inputs with discrepancies between the agents and considering the evaluator’s uncertainty. Comprehensive experimental analyses on synthetic data and two sparse data sets from material extrusion additive manufacturing problems validate the framework’s superiority over uniform and fixed sampling distributions. First, the proposed framework provides unbiased estimates of the test loss across various data sets, sampling ratios, and evaluator models. Second, the introduced adaptive sampling distribution significantly reduces the standard deviation of the test loss estimator compared to uniform sampling, achieving a 50% reduction for a 10% sampling ratio in the filament selection benchmark. Third, the framework demonstrates its efficacy in model selection to determine the optimal number of hidden units with a reduced number of test samples. Overall, this work offers a promising framework for evaluating classification models in applications where acquiring labeled data is time-consuming and resource-intensive, including materials science and engineering.},
  archive      = {J_EAAI},
  author       = {Farhad Pourkamali-Anaraki and Tahamina Nasrin and Robert E. Jensen and Amy M. Peterson and Christopher J. Hansen},
  doi          = {10.1016/j.engappai.2023.106983},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106983},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluation of classification models in limited data scenarios with application to additive manufacturing},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active diversification of head-class features in
bilateral-expert models for enhanced tail-class optimization in
long-tailed classification. <em>EAAI</em>, <em>126</em>, 106982. (<a
href="https://doi.org/10.1016/j.engappai.2023.106982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training deep learning models on long-tailed datasets is a challenging task since the classification performance of tail classes with fewer samples is always unsatisfactory. Currently, many long-tailed methods have achieved success. However, some methods always improve tail-class performance at the expense of head-class performance due to limited model capability. To address this issue, we propose a novel algorithm-level method inspired by information theory to balance the information space of each class and boost tail-class performance while minimizing head-class sacrifice. Our method involves actively eliminating the redundant feature information of head classes to save space for tail classes during training. Specifically, we use a bilateral-expert model and design a duplicate information disentanglement (DID) module that can extract duplicate and redundant information from bilateral-expert features. This allows us to develop a head diversity loss to decrease the extracted duplicate and redundant information of head classes and a tail distillation loss to increase the label information of tail classes. The joint result of these two losses allows our model to fully leverage the information space for improved tail-class performance without compromising head-class performance. The effectiveness and practicability of our method are verified by five datasets with long-tailed distributions for visual recognition or fault diagnosis tasks. Experimental results demonstrate that our method outperforms currently available mainstream methods, which we attribute to the effectiveness of our proposed DID module and the incorporation of two long-tailed losses.},
  archive      = {J_EAAI},
  author       = {Jianting Chen and Ling Ding and Yunxiao Yang and Yang Xiang},
  doi          = {10.1016/j.engappai.2023.106982},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106982},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Active diversification of head-class features in bilateral-expert models for enhanced tail-class optimization in long-tailed classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facial feature fusion convolutional neural network for
driver fatigue detection. <em>EAAI</em>, <em>126</em>, 106981. (<a
href="https://doi.org/10.1016/j.engappai.2023.106981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver fatigue detection is critical for preventing traffic accidents. However, in real driving scenarios, low-quality input situations often occur due to occlusion, large-turn head deformation, and inconsistent eye states, which introduce noise and degrade the performance of single-stream networks. To address this, we propose a multi-stream facial feature fusion convolution neural network (FFF–CNN) that enhances performance on low-quality inputs. The FFF-CNN includes a global face stream and two local eye streams, with feature fusion used for eye state classification. To facilitate feature fusion, we implemented two preprocessing modules, the feature attention module (FAM) and the stream interaction module (SIM). FAM emphasizes important features in the global face stream, while SIM corrects information from the two local eye streams. The proposed FFF-CNN achieved good performance on both our dataset and the public Closed Eyes in the Wild (CEW) dataset. Compared to single-stream networks, the FFF-CNN improved performance by 4.95% and 4.27% on our dataset and the CEW dataset, respectively. Furthermore, it achieved state-of-the-art performance on the CEW dataset with an accuracy of 98.35%. The effectiveness of the proposed FAM and SIM has been verified by experiments. Notably, our experimental results show that the proposed FFF-CNN effectively improved fatigue detection performance on low-quality input, approaching the performance on normal situations.},
  archive      = {J_EAAI},
  author       = {Zhichao Sun and Yinan Miao and Jun Young Jeon and Yeseul Kong and Gyuhae Park},
  doi          = {10.1016/j.engappai.2023.106981},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106981},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Facial feature fusion convolutional neural network for driver fatigue detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). In-situ enhanced anchor-free deep CNN framework for a
high-speed human-machine interaction. <em>EAAI</em>, <em>126</em>,
106980. (<a
href="https://doi.org/10.1016/j.engappai.2023.106980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-Robot Interaction (HRI) constitutes a demanding research field that integrates artificial intelligence, informatics, robotics, engineering, and human-machine interaction. In the present era, there is an increased focus on natural user interfaces, with particular attention to gestural modalities. This leads to the coordination of modern robotic systems, where real-time integration and interpretation of manual gestures play a vital role in facilitating effective manipulation. Hand gesture recognition holds a crucial role in the field of machine vision, perhaps greatly exacerbated with varying lighting conditions and backgrounds. In this paper, first an Enhanced Anchor-free Network (EAF-Net) is proposed to perform hand gesture recognition in real-time. The EAF-Net is deep single-stage Convolutional Neural Network (CNN) based architecture. The Custom Precise Prediction Function (CPPF) is utilized for a continuous recognition of a specific gesture from a video feed. Then, the 6-axis collaborative Robot is manipulated using the predicted gesture. The EAF-Net model utilizes the Enriched Hourglass as a backbone feature extraction network. The proposed EAF-Net model undergoes training and assessment using the MITI HD-II dataset. The performance of the model is also analyzed for the standard benchmark datasets (NUSHP-II and Senz-3D). The evaluation of the EAF-Net model’s performance spans a range of IoU values from 0.5 to 0.95. The EAF-Net model led to higher precision values (AP 0.5 ) as 99.22%, recall values (AR 0.5 ) as 98.20%, and F1-Score 0.5 as 98.64% on the MITI HD-II dataset. The EAF-Net model consumed a prediction time of 259 ms on NVIDIA Jetson Nano Processor and 14 ms on NVIDIA Titan X GPU. It aided in implementing a portable high-speed 6-axis Robot control framework to pick and place operation in 3D space. The robot would be able to imitate human hand activities such as hand rotation, hand tilting, picking and arranging items, and so on in the near future. Further reduction in prediction time of the model on the portable processors (NVIDIA Jetson Nano, Raspberry-Pi) could enhance the speed of the Human Machine Interaction process.},
  archive      = {J_EAAI},
  author       = {S. Rubin Bose and V. Sathiesh Kumar and C. Sreekar},
  doi          = {10.1016/j.engappai.2023.106980},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106980},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {In-situ enhanced anchor-free deep CNN framework for a high-speed human-machine interaction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble learning-based nonlinear time series prediction and
dynamic multi-objective optimization of organic rankine cycle (ORC)
under actual driving cycle. <em>EAAI</em>, <em>126</em>, 106979. (<a
href="https://doi.org/10.1016/j.engappai.2023.106979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complicated road conditions make organic Rankine cycle (ORC) operation characteristics show hysteresis and uncertainty. Under the strong coupling correlation of many operating parameters, how to realize the dynamic optimization of ORC comprehensive performance is the key to obtain practical application potential. Based on ensemble learning mechanism, neural network modeling, ensemble system, unsupervised learning, partial mutual information and optimization algorithm are integrated. This paper presents a nonlinear time series prediction and dynamic multi-objective optimization scheme. The average accuracy increased by at least 59.6%. Taking the thermodynamic performance and environmental impact as optimization objectives, dynamic multi-objective optimization is carried out under road conditions. The optimization scheme can effectively trade off the nonlinear correlation between thermal efficiency and emissions of CO 2 equivalent.},
  archive      = {J_EAAI},
  author       = {Xu Ping and Fubin Yang and Hongguang Zhang and Chengda Xing and Zhuxian Liu and Hailong Yang and Yan Wang},
  doi          = {10.1016/j.engappai.2023.106979},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106979},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble learning-based nonlinear time series prediction and dynamic multi-objective optimization of organic rankine cycle (ORC) under actual driving cycle},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Inference and analysis on the evidential reasoning rule
with time-lagged dependencies. <em>EAAI</em>, <em>126</em>, 106978. (<a
href="https://doi.org/10.1016/j.engappai.2023.106978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidential reasoning rule (ER rule), benefits by the advantage in dealing with various uncertainties, is widely applied for independent evidence aggregation and multi-attribute decision making. In engineering practice, however, time-lagged correlations among multiple attributes from complex systems are often encountered, causing time-lagged dependencies among evidences generated from these attributes. To aggregate multiple pieces of time-lagged dependent evidence, an evidential reasoning rule with time-lagged dependencies, called the ER-TLD, is developed in this paper. Firstly, the calculation algorithm for the relative total time-lagged dependence coefficient (RT-TLDC) and the delay time of each attribute is proposed based on the distance correlation (dCor) method, with which nonlinear time-lagged correlations among multiple attributes can be captured. On this basis, the ER-TLD model is constructed by introducing the RT-TLDCs and delay times into the ER rule, so that multiple pieces of time-lagged dependent evidence can be effectively aggregated. Then, sensitivity analyses are conducted, and the impact of delay time change on the aggregation results is explored. Finally, the effectiveness and potential application of the proposed method are verified by one numerical example and three practical experiments. The aggregation results obtained by the ER-TLD show more rationality according to the comparative studies.},
  archive      = {J_EAAI},
  author       = {Peng Zhang and Zhijie Zhou and Zhichao Feng and Jie Wang and Yijun Zhang},
  doi          = {10.1016/j.engappai.2023.106978},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106978},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inference and analysis on the evidential reasoning rule with time-lagged dependencies},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sentiment induced phrase-based machine translation:
Robustness analysis of PBSMT with senti-module. <em>EAAI</em>,
<em>126</em>, 106977. (<a
href="https://doi.org/10.1016/j.engappai.2023.106977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every type of machine translation system (i.e. neural, statistical, rule-based machine translation system) is equal important to build a sophistical hybrid machine translation system. Keeping this fact in my mind, I concentrate to improve statistical machine translation system with more natural way. In this paper, I try to preserve sentiment after translation to improve the overall accuracy of the machine translation system. So, I introduced senti-model here. A senti-model (sentiment model), translation model, language model, and distortion model are incorporated on the top of the beam search algorithm for decoding. At first, sentiment information is learned and modeled with translation probability by using this algorithm. Thereafter, I decode the source sentences-based on the contextual information. Overall procedure of translation modeling with a sentiment, parameter estimation for it, and senti-translation decoding (decoding with the sentiment model) are presented with empirical evidence. Experiments on a benchmark English–Hindi dataset shows that the proposed model is capable to improve the accuracy (in terms of 4.66 BLEU points, 4.09 LeBleu points, 4.67 NIST points, 5.71 RIBES points) significantly and preserves sentiment 7.79% more than the state-of-the-art technique.},
  archive      = {J_EAAI},
  author       = {Debajyoty Banik},
  doi          = {10.1016/j.engappai.2023.106977},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106977},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sentiment induced phrase-based machine translation: Robustness analysis of PBSMT with senti-module},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seismic fragility analysis of steel moment frames using
machine learning models. <em>EAAI</em>, <em>126</em>, 106976. (<a
href="https://doi.org/10.1016/j.engappai.2023.106976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops machine learning (ML) models for seismic fragility analysis of steel moment frames. Four ML methods – random forest, adaptive boosting, gradient boosting regression tree (GBRT), and extreme gradient boosting (XGBoost) – were employed for this purpose. Probabilistic seismic demand models, each representing the relationship between the seismic response of a type of structure and ground motion intensity, were used to construct the fragility curves based on nonlinear time history analyses of 616 steel moment frames subjected to 240 ground motions. The first three natural periods of steel moment frames and a capacity limit state defined by the maximum interstory drift were selected as input variables for the ML models. Two parameters (median and logarithmic standard deviation) of a fragility function were considered as output variables for the ML models. For each steel frame, the capacity limit state values considered for maximum interstory drift cover a wide range to generalize the fragility curve outcomes. The interquartile range method was used to ensure the quality of the dataset, and consequently 56,479 data points were used for the development of ML models. Based on model performance, the GBRT ( R 2 = 0.9986, for the testing dataset) and XGBoost ( R 2 = 0.9987) models are proposed as the best models for fragility analysis of steel moment frames. Finally, a graphical user interface for fragility analysis of steel moment frames was built based on the two proposed models, for easy access by practicing engineers. This study demonstrates the applicability of ML methods in practical design.},
  archive      = {J_EAAI},
  author       = {Hoang D. Nguyen and Young-Joo Lee and James M. LaFave and Myoungsu Shin},
  doi          = {10.1016/j.engappai.2023.106976},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106976},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Seismic fragility analysis of steel moment frames using machine learning models},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature-wise attention based boosting ensemble method for
fraud detection. <em>EAAI</em>, <em>126</em>, 106975. (<a
href="https://doi.org/10.1016/j.engappai.2023.106975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transaction fraud detection is an essential topic in financial research, protecting customers and financial institutions from suffering significant financial losses. The existing ensemble learning-based fraud detection model improves the accuracy of distinguishing fraudulent transactions by integrating multiple base learners. However, their insufficient optimization of variance leads to the inadequate generalization of the model, which makes them unable to meet the requirements of detecting evolving fraudulent behavior. So, this paper proposes an attention-based boosting ensemble model (AM-Boost) for fraud detection that imparts diversity perturbation to the base learner from the feature dimension. Firstly, the feature-wise attention mechanism is proposed to help the model exploit the highly informative fraud features by learning distributed global feature space. And it is combined with boosting strategy to reduce the variance by lowering the correlation between base learners. Secondly, we propose a feature diversity regularization term in the integration stage to optimize the weighted majority voting strategy with a reasonable trade-off between bias and variance. Finally, we evaluate the proposed method on a public fraud detection dataset and a real-world transaction dataset. Extensive experiment results demonstrate that our method outperforms the baseline methods in both datasets.},
  archive      = {J_EAAI},
  author       = {Ruihao Cao and Junli Wang and Mingze Mao and Guanjun Liu and Changjun Jiang},
  doi          = {10.1016/j.engappai.2023.106975},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106975},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-wise attention based boosting ensemble method for fraud detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A health condition assessment and prediction method of
francis turbine units using heterogeneous signal fusion and graph-driven
health benchmark model. <em>EAAI</em>, <em>126</em>, 106974. (<a
href="https://doi.org/10.1016/j.engappai.2023.106974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the safety and efficiency of hydroelectric power generation, the health condition assessment and prediction (HCAP) of Francis turbine units (FTUs) have been widely concerned. To this end, some data-driven methods based on health benchmark model (HBM) and performance deterioration index (PDI) have been proposed, but there are still some shortcomings: 1) Only one type of signal is used for FTU health monitoring and assessment, which cannot fully represent the deterioration of the system. 2) The establishment of HBM only focuses on the time sequence dependences of signals, while ignoring the inter-correlations between signals. 3) PDI based on linear difference measurement cannot integrate heterogeneous signal representations to fully assess FTU status. In this paper, a HCAP method of FTUs using heterogeneous signal fusion and graph-driven HBM is proposed. First, the multivariate data of health status are transformed into spatial-temporal graphs by establishing connections between similar signals. Furthermore, a hybrid neural network-based HBM is designed to excavate the spatial-temporal dependence relationships existing in these graphs, and learn the mapping relationship between working condition parameters and monitoring signals. Finally, Mahalanobis distance between the heterogeneous signals predicted by HBM and the measured signals in the degraded status is calculated, and the comprehensive PDI for HCAP tasks is obtained by the designed heterogeneous signal fusion function. Verification experiments show that the proposed HCAP method effectively assesses FTU deterioration degree earlier with a higher sensitivity.},
  archive      = {J_EAAI},
  author       = {Fengyuan Zhang and Jie Liu and Yuxin Li and Yujie Liu and Ming-Feng Ge and Xingxing Jiang},
  doi          = {10.1016/j.engappai.2023.106974},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106974},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A health condition assessment and prediction method of francis turbine units using heterogeneous signal fusion and graph-driven health benchmark model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A priori compression of convolutional neural networks for
wave simulators. <em>EAAI</em>, <em>126</em>, 106973. (<a
href="https://doi.org/10.1016/j.engappai.2023.106973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks are now seeing widespread use in a variety of fields, including image classification, facial and object recognition, medical imaging analysis, and many more. In addition, there are applications such as physics-informed simulators in which accurate forecasts in real time with a minimal lag are required. The present neural network designs include millions of parameters, which makes it difficult to install such complex models on devices that have limited memory. Compression techniques might be able to resolve these issues by decreasing the size of CNN models that are created by reducing the number of parameters that contribute to the complexity of the models. We propose a compressed tensor format of convolutional layer, a priori, before the training of the neural network. 3-way kernels or 2-way kernels in convolutional layers are replaced by one-way fiters. The overfitting phenomena will be reduced also. The time needed to make predictions or time required for training using the original Convolutional Neural Networks model would be cut significantly if there were fewer parameters to deal with. In this paper we present a method of a priori compressing convolutional neural networks for finite element (FE) predictions of physical data. Afterwards we validate our a priori compressed models on physical data from a FE model solving a 2D wave equation. We show that the proposed convolutional compression technique achieves equivalent performance in the prediction error as classical convolutional layers with fewer trainable parameters(around 20%) and lower memory footprint.},
  archive      = {J_EAAI},
  author       = {Hamza Boukraichi and Nissrine Akkari and Fabien Casenave and David Ryckelynck},
  doi          = {10.1016/j.engappai.2023.106973},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106973},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A priori compression of convolutional neural networks for wave simulators},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Underwater image enhancement via multi-scale fusion and
adaptive color-gamma correction in low-light conditions. <em>EAAI</em>,
<em>126</em>, 106972. (<a
href="https://doi.org/10.1016/j.engappai.2023.106972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dark underwater areas, existing single-model underwater image enhancement methods have poor enhancement effects. We propose an underwater image enhancement method based on color correction and multi-scale fusion (CCMF). Specifically, we first design a color correction method with red channel compensation, which compensates for the red channel according to light attenuation and removes color bias. We propose a contrast enhancement method based on guided filtering to enhance edge texture details. The image is decomposed into a base layer and a detail layer in the logarithmic domain, with layered enhancement. Secondly, we propose an adaptive gamma correction method that dynamically adjusts correction parameters based on the gray image values. This approach prevents over-enhancement and effectively enhances the exposure in dark areas. We extract weight maps that represent different features from the input images and employ a multi-scale pyramid fusion technique to integrate the aforementioned feature information. This approach enables the mutual complementarity of various features and enhances the overall visual effect. Experimental results show that our method can effectively integrate the advantages of different enhancement methods, and the objective indicators of UCIQE, UIQM, and EG are better than other related state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Dan Zhang and Zongxin He and Xiaohuan Zhang and Zhen Wang and Wenyi Ge and Taian Shi and Yi Lin},
  doi          = {10.1016/j.engappai.2023.106972},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106972},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Underwater image enhancement via multi-scale fusion and adaptive color-gamma correction in low-light conditions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A channel selection method to find the role of the amygdala
in emotion recognition avoiding conflict learning in EEG signals.
<em>EAAI</em>, <em>126</em>, 106971. (<a
href="https://doi.org/10.1016/j.engappai.2023.106971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition using electroencephalogram signals has been widely studied in the last decade, achieving artificial intelligence models that accurately classify primitive or primary emotions. However, most of these models focus on signal processing methods to better recognize multiclass targets, ignoring efficient denoising methods to reduce artifacts in input samples. Therefore, this study proposes two-dimension reduction algorithms derived from machine learning models based on electroencephalogram channel selection and conflict learning. The last two approaches exploit the electroencephalogram signals from the SEED-V dataset as input data. Next, a wavelet noise-estimate frequency decomposition and a 1-D Local Binary Pattern (LBP) are applied to achieve a histogram per signal. After applying a feature extraction method, the targets per sample are adapted to yield the most relevant electroencephalogram channels and obtain a highly competitive machine-learning model that uses only the FCZ and CP4 electrodes. Additionally, relevant findings based on conflict learning yield that samples with “Happy” and “Disgust” targets had numerous artifacts compared with the other studied emotions (“Fear”, “Sad”, and “Neutral) but achieved superior performance than the channel selection method. The proposed framework reached accuracy rates per dimension reduction near 90% accuracy and between 87% and 92.8% using the F1-score metric. Hence, the classification results are highly competitive with state-of-the-art close-related methods.},
  archive      = {J_EAAI},
  author       = {Oscar Almanza-Conejo and Juan Gabriel Avina-Cervantes and Arturo Garcia-Perez and Mario Alberto Ibarra-Manzano},
  doi          = {10.1016/j.engappai.2023.106971},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106971},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A channel selection method to find the role of the amygdala in emotion recognition avoiding conflict learning in EEG signals},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global-and-local aware network for low-light image
enhancement. <em>EAAI</em>, <em>126</em>, 106969. (<a
href="https://doi.org/10.1016/j.engappai.2023.106969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photos taken under nighttime or backlit conditions often suffer from complex and unpredictable degradation, such as low visibility, messy noise, and distorted color. Previous methods mainly focused on global brightness and contrast while ignoring structural and textural details, or they handled the fusion of features without adequately considering their intrinsic association, resulting in incomplete feature representations. To address this issue, we propose a global-and-local aware network (GLAN) by projecting the features into the frequency domain and incorporating them in a knowledge-sharing manner. This method effectively integrates the global modeling capability of the transformer and the local sensitivity of the convolutional neural network to represent structure and texture. First, the global branch, which is comprised of transformer blocks, performs feature extraction under the global receptive field, while the local branch constructs multi-scale features to provide local fine-grained details. Then, we design a novel adaptive multi-scale feature block (AMSFB) that deploys channel split operation to decrease the calculation amount. To better learn the channel and spatial correlations of intermediate features, we introduce a multi-scale channel attention module (MSCAM) and a pixel attention module (PAM) into the AMSFB. Finally, a frequency-aware interaction module (FAIM) is developed for bidirectional information supplementation, which builds feature descriptors simultaneously covering low-frequency and high-frequency information based on the discrete cosine transform (DCT). Through extensive quantitative and qualitative experiments, our method can achieve competitive results compared with over ten state-of-the-art image enhancement methods on eight benchmark datasets.},
  archive      = {J_EAAI},
  author       = {Xufeng He and Zhihua Chen and Lei Dai and Lei Liang and Jianfa Wu and Bin Sheng},
  doi          = {10.1016/j.engappai.2023.106969},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106969},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Global-and-local aware network for low-light image enhancement},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep ensemble learning for high-dimensional subsurface fluid
flow modeling. <em>EAAI</em>, <em>126</em>, 106968. (<a
href="https://doi.org/10.1016/j.engappai.2023.106968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of Deep Learning (DL) algorithms can be improved by combining several deep learners into an ensemble. This avoids the continuous endeavor required to adjust the architecture of individual networks or the nature of the propagation. This study investigates prediction improvements possible using Deep Ensemble Learning (DEL) to determine four distinct multiscale basis functions in the mixed Generalized Multiscale Finite Element Method (GMsFEM), involving the permeability field as the only input. 376,250 samples were initially generated, filtered down to 367,811 after data pre-processing. A standard Convolutional Neural Network (CNN) named SkiplessCNN and three skip connection-based CNNs named FirstSkipCNN, MidSkipCNN, and DualSkipCNN were developed for the base learners. For each basis function, these four CNNs were combined into an ensemble model using linear regression and ridge regression, separately, as part of the stacking technique. A comparison of the coefficient of determination (R 2 ) and Mean Squared Error (MSE) confirms the effectiveness of all three skip connections in enhancing the performance of the standard CNN, with DualSkip being the most effective among them. Additionally, as evaluated on the testing subset, the combined models meaningfully outperform the individual models for all basis functions. The case that applies linear regression delivers R 2 ranging from 0.8456 to 0.9191 and MSE ranging from 0.0092 to 0.0369. The ridge regression case achieves marginally better predictions with R 2 ranging from 0.8539 to 0.922, and MSE ranging from 0.009 to 0.0349 because its solution involves more evenly distributed weights.},
  archive      = {J_EAAI},
  author       = {Abouzar Choubineh and Jie Chen and David A. Wood and Frans Coenen and Fei Ma},
  doi          = {10.1016/j.engappai.2023.106968},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106968},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep ensemble learning for high-dimensional subsurface fluid flow modeling},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prognostic modeling of polydisperse SiO2/aqueous glycerol
nanofluids’ thermophysical profile using an explainable artificial
intelligence (XAI) approach. <em>EAAI</em>, <em>126</em>, 106967. (<a
href="https://doi.org/10.1016/j.engappai.2023.106967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ceramic nanoparticles have become increasingly popular owing to their wide range of engineering applications in the industry. Silica is one of the most promising nanomaterials for heat transfer applications due to its favorable thermophysical characteristics and dispersion stability. This work investigates the thermophysical properties of polydisperse SiO 2 nanoparticles in a glycerol and water mixture. Aqueous glycerol nanofluid comprised 30% glycerol (30 GW) by weight, and SiO 2 with mean particle sizes of 15, 50, and 100 nm were prepared for 0.5 and 1.0% volume concentrations using a two-step method. Measurements of properties are made in the temperature range of 30–100 o C. The nanofluids behaved as a single-phase liquid remaining stable for four weeks. The viscosity and density of the base liquid and nanofluid decreased while the thermal conductivity increased with temperature. The base liquid-specific heat increased slightly while that of nanofluid decreased significantly with temperature. For 0.5% SiO 2 concentration, the thermal conductivity and viscosity varied by 11.1% and 32%, respectively at 60 o C compared to the base liquid. Correlations are developed for the estimation of nanofluid properties. An Explainable Artificial Intelligence (XAI) technique called Bayesian approach optimized Gaussian Process Regression was employed to develop a prognostic model for the thermophysical properties of test nanofluids. In addition, the model&#39;s predictability and explainability are both enhanced by the use of kernel functions, which makes it possible to include historical data in the representation of a phenomenon. The test XAI approaches were shown as robust one because of the high correlation values, which ranged from 99.68% to 99.99%, along with minimal modeling errors.},
  archive      = {J_EAAI},
  author       = {K.V. Sharma and P.H.V. Sesha Talpa Sai and Prabhakar Sharma and Praveen Kumar Kanti and P. Bhramara and Suleiman Akilu},
  doi          = {10.1016/j.engappai.2023.106967},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106967},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prognostic modeling of polydisperse SiO2/Aqueous glycerol nanofluids&#39; thermophysical profile using an explainable artificial intelligence (XAI) approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning human inverse kinematics solutions for redundant
robotic upper-limb rehabilitation. <em>EAAI</em>, <em>126</em>, 106966.
(<a href="https://doi.org/10.1016/j.engappai.2023.106966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a real-time human inverse kinematics approach based on the Gaussian Process (GP) to address the open problem of finding appropriate inverse kinematic solutions for upper-limb rehabilitation using redundant robotic exoskeletons. The proposed approach is validated using recorded data from a Motion Capture (MoCap) system and is shown to achieve accurate and unique upper-limb natural solutions for different rehabilitation exercises. This approach is a computationally tractable alternative to existing solutions, which are not always feasible and unsuitable for real-time rehabilitation tests, as they are based on optimizing discomfort indices online or computationally demanding learning methods. A comparison with existing inverse kinematics solutions confirms the superior performance of the proposed approach. Additionally, a robust Model Predictive Control (MPC) with an Integral Sliding Mode (ISM) combination is proposed for safe trajectory tracking during rehabilitation exercises. Several real-time experiments were conducted on a 7-DoF exoskeleton robot with and without the presence of a healthy subject to verify the effectiveness of the proposed methods.},
  archive      = {J_EAAI},
  author       = {David Bedolla-Martinez and Yassine Kali and Maarouf Saad and Cristobal Ochoa-Luna and Mohammad Habibur Rahman},
  doi          = {10.1016/j.engappai.2023.106966},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106966},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning human inverse kinematics solutions for redundant robotic upper-limb rehabilitation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic global power extraction of partially shaded PV
system using a hybrid MPSO-PID with anti-windup strategy. <em>EAAI</em>,
<em>126</em>, 106965. (<a
href="https://doi.org/10.1016/j.engappai.2023.106965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle Swarm Optimizer (PSO) has three main drawbacks in case of partially shaded photovoltaic systems. First, it converges slowly to the global peak (GP). Second, because PSO is a time invariant, it cannot adhere to a dynamic GP in the presence of various temporal shading patterns and instead, sticks to the first GP. Third, it exhibits high oscillations around GP. To overcome these shortcomings, this paper proposes a novel hybrid modified PSO-PID (MPSO-PID) with anti-windup strategy based maximum power point tracking. The anti-windup strategy aims to guarantee the robustness of the PID controller and eliminate the PID windup outcome. Two anti-windup structures were applied to PID namely: anti-windup using back calculation and anti-windup using conditional integration. For validation purpose, the hybrid MPSO-PID with anti-windup has been compared with conventional PSO and three modified PSO versions namely: PSO with random numbers eliminated (PSO-RNE), PSO with linearly varying parameters (PSO-LVP), and PSO with fixed maximum iterations (PSO-FMI). The obtained simulation and experimental results revealed that the proposed MPSO-PID with anti-windup overcome the previous shortcomings providing outperformance to track dynamic GP with a less convergence time and small oscillations around GP compared to other algorithms. The proposed MPSO-PID technique has a minimum average response time; 0.026 s; to catch the GP under various shading patterns compared to the other PSO versions; CPSO, PSO-LVP, PSO-RNE, and PSO-FMI; where the average response time are 0.026 s, 0.531s, 0.446 s, 0.763 s, and 0.494 s respectively. Finally, the results proved the robustness and effectiveness of PID design for enhancing both the PSO and PV system performance.},
  archive      = {J_EAAI},
  author       = {Ibrahim AL-Wesabi and Fang Zhijian and Hassan M. Hussein Farh and Wei Zhiguo and Khaled Ameur and Abdullrahman A. Al-Shamma&#39;a and Abdullah M. Al-Shaalan},
  doi          = {10.1016/j.engappai.2023.106965},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106965},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic global power extraction of partially shaded PV system using a hybrid MPSO-PID with anti-windup strategy},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel multi-modal neural network approach for dynamic and
generic sports video summarization. <em>EAAI</em>, <em>126</em>, 106964.
(<a href="https://doi.org/10.1016/j.engappai.2023.106964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video Summarization is a video compression/compaction technique to create a shorter yet informative version of original video. Video summarization has offered solutions to plenty of media, user and engineering applications. Though sports video summarization has been an active research topic for some time; there still exists a void for multi-modal, dynamic, generic and domain knowledge based approach for Cricket Sport video summarization. This paper presents a multi-modal video summarization approach to summarize Cricket sport videos. This work captures the domain knowledge acquired from multi-modal (audio-visual) cues. A dual neural network architecture pipeline is proposed to dynamically segment and dynamically summarize Cricket videos for generic target audience. The former Neural Network is grounded on Cricket bowling activity (visual feature) for dynamic video segmentation of Cricket videos. The segments are then forwarded to the latter Neural Network for identification of key segments. The key segment detection module relies on Audio analysis of Cricket video stream to identify exciting, content representative and informative segments as per Cricket domain. Experimental analysis on two novel proposed benchmark datasets, i.e. DPCS (Delivery Play Cricket Sport) image dataset and EXINP (Excited Interval Normal Play) Cricket Dataset (audio based) shows promising results. The results indicate that the proposed multi-modal approach generates exciting, content representative, informative, generic and dynamic summary incorporating domain knowledge of the sport.},
  archive      = {J_EAAI},
  author       = {Pulkit Narwal and Neelam Duhan and Komal Kumar Bhatia},
  doi          = {10.1016/j.engappai.2023.106964},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106964},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multi-modal neural network approach for dynamic and generic sports video summarization},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional neural networks applied to microtomy:
Identifying the trimming-end cutting routine on paraffin-embedded tissue
blocks. <em>EAAI</em>, <em>126</em>, 106963. (<a
href="https://doi.org/10.1016/j.engappai.2023.106963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of histopathology, the microtomy procedure yields thin sections of tissue embedded in paraffin blocks, then to be further processed for diagnostic purposes. Within microtomy, trimming is an initial but critical process in which the excess paraffin covering the tissue of interest is removed by continuous cutting routines, until the tissue is suitably exposed and ready for sectioning. Trimming is currently a time-consuming process that is manually held by technicians. In this paper, we present a method to automatize this process, by analyzing tissue block surface images resulting from each cyclic cutting routine. Two types of Convolutional Neural Networks (CNNs) were fine-tuned: one for binary segmentation, the other for multi-class classification tasks, by exploring and optimizing lightweight architectures to provide fast analytical results on cost-effective edge computing. Two sequential online conditions followed the CNNs to output the current stage of the block surface and rule if the trimming-end cutting routine was reached. We compared the results obtained through our method with the ones obtained by three skilled technicians processing 75 tissue blocks. The proposed method identified the trimming-end cutting routine approximately as accurate as the technicians did, yielding up to 90% of trimmed blocks of optimal quality and evidencing the potential of this tool in future automated trimming instruments. We deployed our method to an Edge TPU hardware accelerator to showcase its capability to provide immediate and objective results at every microtomy station applied with an ad hoc hardware, potentially guaranteeing a throughput 50% higher than manual trimming.},
  archive      = {J_EAAI},
  author       = {Lorena Guachi-Guachi and Jacopo Ruspi and Paola Scarlino and Aliria Poliziani and Sabrina Ciancia and Dario Lunni and Gabriele Baldi and Andrea Cavazzana and Alessandra Zucca and Marco Bellini and Gian Andrea Pedrazzini and Gastone Ciuti and Marco Controzzi and Lorenzo Vannozzi and Leonardo Ricotti},
  doi          = {10.1016/j.engappai.2023.106963},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106963},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Convolutional neural networks applied to microtomy: Identifying the trimming-end cutting routine on paraffin-embedded tissue blocks},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fair consensus adjustment mechanism for large-scale group
decision making in term of gini coefficient. <em>EAAI</em>,
<em>126</em>, 106962. (<a
href="https://doi.org/10.1016/j.engappai.2023.106962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With social media and e-democracy development, decision-making environments and problems have become increasingly complex. Traditional group decision-making, including a small number of decision makers, cannot deal with many practical decision-making problems. Large-scale group decision-making has received extensive attention as an efficient measure to address this issue. This paper proposes a two-stage optimization consensus mechanism for large-scale group decision-making by the Gini coefficient, which considers both the consensus among decision makers’ opinions and the fairness of consensus adjustment. First, we introduce an improved density peak clustering method to cluster decision makers into subgroups that can avoid different clustering centers being too close. Then, we define the subgroups&#39; weights by the silhouette coefficient, the subgroup judgment distance, and their sizes. Respecting the importance of minority opinions, we design a new method to identify and adjust the weights of the minority opinions, which considers more aspects than previous ones. Further, we use the Gini coefficient to measure the equity of consensus adjustment of the group and subgroup. Moreover, we present a two-stage Gini coefficient-based consensus mechanism to obtain the adjusted consensus individual decision matrices, which can ensure the minimization and fairness of consensus adjustment and allocation under the set constraints. Based on these results, we give a new large-scale group decision-making method. Notably, it is the first method that fully considers the opinions of minor subgroups and the fairness of allocation results. These characteristics are essential in decision-making problems such as resource allocation and urban public construction. Finally, we show the utility and validity of the new method through a case study and make the comparative analysis from numerical and principle aspects.},
  archive      = {J_EAAI},
  author       = {Fanyong Meng and Dengyu Zhao and Xumin Zhang},
  doi          = {10.1016/j.engappai.2023.106962},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106962},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fair consensus adjustment mechanism for large-scale group decision making in term of gini coefficient},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel seminar learning framework for weakly supervised
salient object detection. <em>EAAI</em>, <em>126</em>, 106961. (<a
href="https://doi.org/10.1016/j.engappai.2023.106961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised salient object detection (SOD) is a challenging task and has drawn much attention from several research perspectives, it has revealed two problems while driving the rapid development of saliency detection. (1) Large divergence in the characteristics of saliency regions in terms of location, shape and size makes them difficult to recognize. (2) The properties of convolutional neural networks dictate that it is insensitive to various transformations, which will lead to hardly balance the application of various disturbances. To tackle these limitations, this paper proposes a novel seminar learning framework with consistent transformation ensembling (SLF-CT) for scribble supervised SOD. The framework consists of the teacher–student model and the student–student model for segmenting the salient objects. Specifically, we first design a cross attention guided network (CAGNet) as a baseline model for saliency prediction. Then we assign CAGNet to the teacher–student model, where the teacher network is based on the exponential moving average and guides the training of the student network. Moreover, we adopt multiple pseudo labels to transfer the information among students from different conditions. To further enhance the regularization of the network, a consistency transformation mechanism is also incorporated, which encourages the saliency prediction and input image of the network to be consistent. The experimental results demonstrate that the proposed approach performs favorably comparable with the state-of-the-art weakly supervised methods. As far as we know, the proposed approach is the first application of seminar learning in the SOD area.},
  archive      = {J_EAAI},
  author       = {Yan Liu and Yunzhou Zhang and Zhenyu Wang and Fei Yang and Feng Qiu and Sonya Coleman and Dermot Kerr},
  doi          = {10.1016/j.engappai.2023.106961},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106961},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel seminar learning framework for weakly supervised salient object detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint multi-type feature learning for multi-modality FKP
recognition. <em>EAAI</em>, <em>126</em>, 106960. (<a
href="https://doi.org/10.1016/j.engappai.2023.106960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal biometric recognition has attracted intensive attention due to its significant performance improvement for personal authentication by exploiting multiple resources of data. However, most existing multimodal biometric recognition methods tend to fuse completely different biometric traits, making them hard to explore the complementary features of the multimodal data. In this paper, we propose a new multimodal biometric descriptor by jointly learning the multi-type collaborative features of multi-modality finger-knuckle-print (FKP) images. First, we form multi-type feature vectors to capture the texture and direction patterns of the multimodal FKP images. Then, we jointly learn the feature projection to map multi-type vectors into a compact FKP descriptor. Moreover, our method automatically selects the optimal weights for multi-type features during feature learning to make the learned feature codes discriminative. Lastly, we integrate the non-overlapping block-wise histograms of the learned binary codes as the final multimodal FKP feature descriptor. The experimental results conducted on the benchmark PolyU FKP database demonstrate the effectiveness of the proposed method for multimodal FKP recognition.},
  archive      = {J_EAAI},
  author       = {Yeping Yang and Lunke Fei and Adel Homoud Alshehri and Shuping Zhao and Weijun Sun and Shaohua Teng},
  doi          = {10.1016/j.engappai.2023.106960},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106960},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Joint multi-type feature learning for multi-modality FKP recognition},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent optimization: Literature review and
state-of-the-art algorithms (1965–2022). <em>EAAI</em>, <em>126</em>,
106959. (<a
href="https://doi.org/10.1016/j.engappai.2023.106959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, intelligent optimization has become a science that few researchers have not used in dealing with problems in their field. Diversity and flexibility have made the use, efficiency, and usefulness of various nature-inspired optimization methods, such as evolutionary and meta-heuristic algorithms, more evident in such problems. This work first provides a comprehensive overview of all considerations governing various optimization problems with detailed corresponding categories. Then, the most comprehensive review and recent methods (during 1965–2022) are presented in evolution-based, swarm-based, physics-based, human-based, and hybrid-based categories. More than 320 new algorithms have been reviewed. All specifications including authors, year, abbreviation, inspired source, controls, and their application are considered in this regard. Statistical analyzes of papers and publishers, annually and for 57 years, along with their ranking, are also examined in detail. Among the key achievements of the paper include: the most number of algorithms with 47.71% (156 methods) have been from the swarm category, and most of them were published in the five years of 2021 (72, 22.02%), 2020 (39, 11.93%), 2022 (31, 9.48%), 2019 (26, 7.95%), and 2016 (21, 6.42%) respectively; the top five rankings of publishers of reviewed algorithms/papers were also: “Proceedings of the Congress” (33, 10.09%), “Applied Soft Computing” (19, 5.81%), “Expert Systems with Applications” (18, 5.51%), “Knowledge-Based Systems” (12, 3.67%), “Engineering Applications of Artificial Intelligence” (12, 3.67%), “Advances in Engineering Software” (12, 3.67%), &quot; Neural Computing and Applications &quot; (12, 3.67%), and &quot; Information Sciences &quot; (11, 3.36%). The paper&#39;s data is available at: https://github.com/ali-ece .},
  archive      = {J_EAAI},
  author       = {Ali Mohammadi and Farid Sheikholeslam},
  doi          = {10.1016/j.engappai.2023.106959},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106959},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent optimization: Literature review and state-of-the-art algorithms (1965–2022)},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of building energy performance using mathematical
gene-expression programming for a selected region of dry-summer climate.
<em>EAAI</em>, <em>126</em>, 106958. (<a
href="https://doi.org/10.1016/j.engappai.2023.106958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing energy-efficient buildings considering building design parameters can help reduce buildings&#39; energy consumption. The energy efficiency of residential buildings is considered a top priority for the energy policies of a country. Thus, this study utilizes gene-expression programming (GEP) to estimate the energy performance of residential buildings. The energy consumption evaluations were carried out using the Etotect energy simulation software. Eight building parameters with 768 data points were considered to generate the database for the heating load (H L ) and cooling load (C L ), including relative compactness, surface area, wall area, roof area, overall building height, glazing orientation, glazing area, and distribution of glazing area. Different GEP predictive models with varying parameters for building H L and C L were developed, and the best-performing prediction model was selected. In addition, several statistical indices were utilized to measure the accuracy of the proposed GEP models. The results revealed that GEP14 gives the most robust prediction model for H L having R 2 -value greater than 0.9 for both the training and validation set. Likewise, R 2 -value &gt;0.9 is achieved for best- C L (GEP11). Furthermore, the mean absolute error (MAE) values for both the predictive H L ’ and C L ’ by prediction models were relatively less for both the training and testing databases. The sensitivity and parametric analysis reveal that the overall height (H o ), roof area (A f ), and glazing area (A g ) were the most influential parameters for both predictive models. Thus, GEP results demonstrate the robust performance in predicting the building energy.},
  archive      = {J_EAAI},
  author       = {Majed Alzara and Muhammad Faisal Rehman and Furqan Farooq and Mujahid Ali and Ashraf A.A. Beshr and Ahmed.M. Yosri and S.B. A El Sayed},
  doi          = {10.1016/j.engappai.2023.106958},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106958},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of building energy performance using mathematical gene-expression programming for a selected region of dry-summer climate},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequence2Self: Self-supervised image sequence denoising of
pixel-level spray breakup morphology. <em>EAAI</em>, <em>126</em>,
106957. (<a
href="https://doi.org/10.1016/j.engappai.2023.106957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical imaging of fast and transient phenomena such as the turbulent breakup of liquid sprays exhibit low signal-to-noise ratios due to the limited illumination intensity relative to the short exposure time. Image denoising is required to facilitate physical studies over these data but is challenging due to the absence of clean ground-truths and the stringency of the denoising task (e.g., strong and complex noise, limited resolution, preserving physical fidelity), preventing supervised and existing un-/self-supervised deep learning methods. To this end, Sequence2Self (Seq2S) is proposed, an extension of Self2Self (S2S) to image sequences that leverages both the signal’s spatial and temporal correlation. Seq2S is demonstrated on time-resolved x-ray phase contrast imaging of liquid jet fuel sprays in a gas turbine combustor, which possesses all of challenges detailed above. Experiments are conducted across four fuels with different breakup morphology using various state-of-the-art methods. Overall, many of the methods failed and Seq2S was most successful: (1) Accurate spray structures were reconstructed with consistent evolution across frames void of artifacts. (2) The performance was robust, invariant to the hyperparameter choice. (3) Computational time is short and can be made eligible for real-time denoising. In particular, the images denoised by Seq2S showed spray droplet diameter distributions with near-zero Kullback–Leibler divergence (0.01 ± 0.01) to a cleaner reference, whereas the second best method yielded 0.06 ± 0.03. This suggests that Seq2S can be reliably used prior to subsequent quantitative spray analyses as it retains (if not, improves) the statistical physical properties of the data.},
  archive      = {J_EAAI},
  author       = {Ji-Hun Oh and Eric Wood and Eric Mayhew and Alan Kastengren and Tonghun Lee},
  doi          = {10.1016/j.engappai.2023.106957},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106957},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sequence2Self: Self-supervised image sequence denoising of pixel-level spray breakup morphology},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global and local information integrated network for
remaining useful life prediction. <em>EAAI</em>, <em>126</em>, 106956.
(<a href="https://doi.org/10.1016/j.engappai.2023.106956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven methods routinely achieve promising results on remaining useful life prediction, but under a window-manner end-to-end paradigm, they suffer from unsatisfying generalization ability and low interpretability, as the consequence of neglecting diverse modes among the entire degradation processes of different entities. This article proposes a novel Transformer-based network, to tackle the problem by integration of global and local information. During offline training, the paired inputs containing full life and piece data are constructed, and then using cross-attention between the encoder and the decoder, the consistent position of the piece data in the full life is derived, which is directly associated with the degradation state. The designed paired inputs and model architecture ensures the strong generalization because the prediction result considering global information is adaptive to diverse degradation modes. Further, the designed cross-attention discrepancy utilizes prior knowledge of the consistent position such that similar degradation states are aligned more properly. Such a consistent position, visualized by the cross-attention distribution, is supposed to represent the intuitive relationship between degradation level and monitoring data, thus provides inherent interpretability about the prediction process. Finally, predictions of the online monitoring piece data with respect to all historical full lives with different degradation modes are aggregated to the final prediction. Extensive experiments on two datasets of turbofan and bearing show that our model provides competitive performance, especially under complicated working conditions and fault modes, achieving averagely 5.9% score reduction compared with the state-of-the-art method.},
  archive      = {J_EAAI},
  author       = {Zian Chen and Xiaohang Jin and Ziqian Kong and Feng Wang and Zhengguo Xu},
  doi          = {10.1016/j.engappai.2023.106956},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106956},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Global and local information integrated network for remaining useful life prediction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta pseudo labels for anomaly detection via partially
observed anomalies. <em>EAAI</em>, <em>126</em>, 106955. (<a
href="https://doi.org/10.1016/j.engappai.2023.106955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General anomaly detection has been an important research due to its broad and significant applications. Those algorithms that are based on weakly supervised or partially observed anomalies have attracted particular interest currently. However, most such algorithms treat the unlabeled set as a substitute for normal samples and ignore the potential anomalies in it, which on the one hand causes the noise of the normal set, and on the other hand, fails make full use of the abnormal supervision information. To address this issue, we propose a m eta- p seudo-label based framework for a nomaly d etection (MPAD). The framework strives to obtain effective pseudo anomalies from the unlabeled samples to supplement the observed anomaly set. Specifically, a teacher network is improved based on the feedback of a student network on a validation set, thereby generating more conducive pseudo anomalies to assist the student network while incurring less confirmation bias. In addition, we also design a model roll-back scheme to guarantee the performance of the student network. Extensive experiments show that the proposed MPAD algorithm outperforms current popular algorithms on five real datasets, and the framework can effectively improve the utilization of unlabeled samples while maintaining an advanced degree of robustness. In addition, the results of ablation experiments confirm the effectiveness of each module of our MPAD. Parameter experiments provide sufficient reference for parameter selecting.},
  archive      = {J_EAAI},
  author       = {Sinong Zhao and Zhaoyang Yu and Sifan Li and Xiaofei Wang and Trent G. Marbach and Gang Wang and Xiaoguang Liu},
  doi          = {10.1016/j.engappai.2023.106955},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106955},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Meta pseudo labels for anomaly detection via partially observed anomalies},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy local information c -means based clustering and
fractional dwarf mongoose optimization enabled deep learning for
relevant document retrieval. <em>EAAI</em>, <em>126</em>, 106954. (<a
href="https://doi.org/10.1016/j.engappai.2023.106954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document Retrieval (DR) needs an innovative model to rank and retrieve documents based on their relevancy with respect to some questions that requires strong text understanding capability. The prime motive of documents retrieval is to search the relevant documents that satisfy the user&#39;s questions. However, it is a complex process because it means the natural language textual content based on the syntax, context and semantics. Conventional techniques for listing files prefer typical word and sentence encrypting to create constant length document abiding. However, the widely used bag-of-words (BoW) method failed to integrate the signify context, which is a crucial problem to compreh end the document-query relevancy. In order to overcome such issues, deep neural networks (DNNs) have been put forward to arrange search outcomes with respect to user&#39;s questions. Here, a unified solution is provided to perform relevant document retrieval using Dwarf Mongoose Optimization Fractional-based Deep Convolutional Neural network (DMOF-Deep CNN). Here, the textual content processing is done based on BERT tokenization and feature term extraction. Moreover, the cluster based indexing by elastic search is accomplished using Fuzzy Local Information C-Means (FLICM) clustering and dice coefficient is employed to perform the query matching. Finally, re-ranking based document retrieval is conducted in terms of deep CNN, which is trained using designed DMOF. In addition, the designed DMOF-Deep CNN has outperformed other existing models by delivering maximum precision of 0.854, recall of 0.913, F1-score of 0.882.},
  archive      = {J_EAAI},
  author       = {Gunjan Chandwani and Anil Ahlawat},
  doi          = {10.1016/j.engappai.2023.106954},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106954},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy local information c -means based clustering and fractional dwarf mongoose optimization enabled deep learning for relevant document retrieval},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of high performance and energy efficient convolution
array for convolution neural network-based image inference engine.
<em>EAAI</em>, <em>126</em>, 106953. (<a
href="https://doi.org/10.1016/j.engappai.2023.106953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy efficiency of CNN-based inference engines predominately depends upon Giga-operations-per-second and power consumption. The sparse-based accelerator compresses the insignificant inputs (input feature maps &amp; weights), skips the inefficient computations, and improves energy efficiency. A sparse accelerator for weights could impact the accuracy of the inference. Therefore, a sparse network for Input Feature Maps (IFMs) is considered. MATLAB-based sparsity analysis is done layer-wise on the pre-trained CNN models like AlexNet, VGG-16, VGG-19, ResNet-18 &amp; ResNet-34. Layer-wise analysis reveals that ∼18%–90% of the IFMs are zeros. Besides, IFMs and Weights adopted the 16-bit Fix/Float data format to maintain an accuracy as close as 97% with Single Precision Floating Point (SPFP). A 3 × 1 C onvolutional array with improved Z ero-detect- S kip (CZS 3×1 ) control units for multiplier and adder/subtractor arrays is proposed. The modified rectified linear unit (RELU) converts IFM values ≤ 0 to zero and sets Detection-Bit (DB) to 1. These DBs decide the mode of effective zero-skip operations in CZS 3×1 . A 3 × 3 C ompressed P rocessing E lement (CPE) is designed using three CZS 3×1 . The 20-CPEs convolution array architecture is implemented in 65 nm technology libraries. The performance of 90 Giga-operations per second (GOP/s) and energy efficiency of 3.42 Tera operations per second per watt (TOPS/W) were attained for the proposed CPE. The CPE with improved control strategy enhanced the performance by a factor of 2.45 while consuming 8.8 times less energy on average than the state-of-the-art CNN accelerators.},
  archive      = {J_EAAI},
  author       = {S. Deepika and V. Arunachalam},
  doi          = {10.1016/j.engappai.2023.106953},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106953},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design of high performance and energy efficient convolution array for convolution neural network-based image inference engine},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real time adaptive PID controller based on quantum neural
network for nonlinear systems. <em>EAAI</em>, <em>126</em>, 106952. (<a
href="https://doi.org/10.1016/j.engappai.2023.106952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive proportional-integral-derivative (PID) controller based on a quantum neural network (APIDC-QNN) is introduced. In the proposed neural network structure, three neural layers are used namely: input layer, hidden layer, and output layer. The input and hidden layers use three and six quantum-processing neurons respectively. In contrast, in the output layer, the multiplication processing is used as an activation function free of the output weights which aims to reduce the number of tunable parameters. The output layer with three neurons represents the adaptive PID controller parameters. In this work, the tunable parameters are updated using the Lyapunov stability criterion to guarantee optimization and learning stability. In addition, the plant identification based on the Wiener-type model and quantum neural network is introduced to estimate the sensitivity of the plant output to the control signal. The proposed neural network structure yields only 30 tunable parameters for the proposed controller and 13 tunable parameters for the proposed identifier while the conventional neural network structure in other works requires 90 tunable parameters just for the controller. To evaluate the performance of the proposed APIDC-QNN, it is practically operated on a non-holonomic two-wheel mobile robot (NHWMR). Moreover, to investigate the robustness, superiority, and convergence speed of the proposed APIDC-QNN, some experimental tasks are discussed. The simulation and practical results show the powerful processing and the superiority of the proposed APIDC-QNN over that designed based on conventional neural networks by recording the minimum values of the performance indices.},
  archive      = {J_EAAI},
  author       = {Youssef F. Hanna and A. Aziz Khater and Mohammad El-Bardini and Ahmad M. El-Nagar},
  doi          = {10.1016/j.engappai.2023.106952},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106952},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real time adaptive PID controller based on quantum neural network for nonlinear systems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grid-based many-objective optimiser for aircraft conceptual
design with multiple aircraft configurations. <em>EAAI</em>,
<em>126</em>, 106951. (<a
href="https://doi.org/10.1016/j.engappai.2023.106951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an aircraft conceptual design technique with more than three objective functions, called many-objective optimisation. The selection of aircraft configuration is usually achieved using a system engineering approach. This selection approach has the design variables assigned to remove the configuration decision-making process. The design problem is demonstrated for the conceptual design of a fixed-wing unmanned aerial vehicle. Eight objective functions, including power required, take-off weight, take-off distance, landing distance, endurance, range, lift coefficient at cruise and drag coefficient at cruise, are posed, while the constraints are aircraft stability, performance required and take-off distance. Design variables simultaneously determine an aircraft configuration, shape and sizing parameters. Hence a new, many-objective metaheuristic is developed to increase the design performance. A grid-based many-objective metaheuristic with iterative parameter distribution estimation (MM-IPDE-Gr) is developed. It is an enhanced variant of the MM-IPDE with improved reproduction schemes, adaptive parameters and a grid-based clustering technique. Several additional reproduction schemes in mutation and crossover processes with two additional adaptive parameters are integrated to increase population diversity and improve the exploration ability of the algorithm. In addition, the grid-based method is integrated as a clustering technique to improve the Pareto clustering process in many-objective optimisation. The proposed method, with established newly invented metaheuristics, is used to solve the new design problem and its performance compared with existing design methods. It is shown that the proposed many-objective metaheuristic gives the best results.},
  archive      = {J_EAAI},
  author       = {Pakin Champasak and Natee Panagant and Nantiwat Pholdee and Sujin Bureerat and Parvathy Rajendran and Ali Riza Yildiz},
  doi          = {10.1016/j.engappai.2023.106951},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106951},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Grid-based many-objective optimiser for aircraft conceptual design with multiple aircraft configurations},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extended belief rule base with ensemble imbalanced learning
for lymph node metastasis diagnosis in endometrial carcinoma.
<em>EAAI</em>, <em>126</em>, 106950. (<a
href="https://doi.org/10.1016/j.engappai.2023.106950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lymph node metastasis (LNM) constitutes one of the main prognostic factors for long-term survival in endometrial carcinoma (EC). However, the previous studies on LNM diagnosis failed to consider both model interpretability and class imbalance. In this study, the extended belief rule base (EBRB) expert system is introduced to develop a novel EBRB-based LNM diagnosis model . First, the interpretability of the EBRB expert system is investigated to demonstrate the feasibility on LNM diagnosis; Second, imbalanced learning is introduced to improve rule generation scheme for constructing base EBRBs; Third, by considering the trust of base EBRBs and base diagnoses, ensemble learning is introduced to improve rule inference scheme for diagnosing final LNM. In the case study, real EC patient data collected from Fujian Provincial Maternity and Children&#39;s Hospital are used to verify the effectiveness of the proposed EBRB-based model by comparing with the variants of rule generation schemes and rule inference schemes, as well as some machine learning-based LNM diagnosis models. The comparative results showed that the proposed EBRB-based model has better sensitivity, specificity, and geometric mean in diagnosing LNM for EC patients.},
  archive      = {J_EAAI},
  author       = {Long-Hao Yang and Tian-Yu Ren and Fei-Fei Ye and Haibo Hu and Hui Wang and Hui Zheng},
  doi          = {10.1016/j.engappai.2023.106950},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106950},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Extended belief rule base with ensemble imbalanced learning for lymph node metastasis diagnosis in endometrial carcinoma},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent temporal detection network for
boundary-sensitive flight regime recognition. <em>EAAI</em>,
<em>126</em>, 106949. (<a
href="https://doi.org/10.1016/j.engappai.2023.106949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight regime recognition is critical in guaranteeing flight safety, making informed maintenance decisions for key components, and evaluating flight quality. However, previous methods take flight data points/segments as inputs to make point-wise/segment-wise prediction, which results in imprecise regime boundary localization, poor recognition accuracy or low efficiency. To this end, an intelligent temporal detection network is proposed from a brand-new perspective of regime detection, which directly handles long flight sequences and concurrently generates multiple regime boxes with corresponding categories. Moreover, specific model structures are designed for flight data, including an adaptive graph embedding to explore spatial relations of multi-modal flight parameters, a multi-scale Transformer encoder to recognize regimes of different durations, and a balanced joint loss to mitigate negative impact on imbalanced flight regimes. To validate the superiority of the proposed method, various parameters of real-world flight sorties are collected. Then flight regime dataset is constructed via manual annotation. Extensive experiments and ablation studies show that our method can achieve accurate and boundary-sensitive regime recognition simultaneously.},
  archive      = {J_EAAI},
  author       = {Chenye Hu and Jingyao Wu and Chuang Sun and Xuefeng Chen and Ruqiang Yan},
  doi          = {10.1016/j.engappai.2023.106949},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106949},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent temporal detection network for boundary-sensitive flight regime recognition},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stock price movement prediction based on relation type
guided graph convolutional network. <em>EAAI</em>, <em>126</em>, 106948.
(<a href="https://doi.org/10.1016/j.engappai.2023.106948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock Price Movement Prediction (SPMP) task tends to predict the future price fluctuation of some stocks, which is challenging because of the volatile nature of financial markets. Recent researches widely introduce Graph Convolutional Network (GCN) and achieve some competitive performances for SPMP. However, their works usually only extract the signal representations of individual stock in the phase of feature extraction whereas they ignore the real-time interactions among companies along the signal channels. In addition, when the financial relations among different entities (i.e., companies and executives) participate in the aggregation of GCN during feature encoding, the recent advances fail to consider the dynamics of the relation type representations and the iterative update between entities and relations. To address this problem, we propose a novel method consisting of an External Attention (EA) module and a Relation Type guided Graph Convolutional Network (RTGCN) for SPMP. In detail, to achieve the real-time interactions among companies along the signal channels, we introduce an external attention mechanism to share the company memory of the price and sentiment signals. Moreover, the proposed RTGCN considers the dynamics of the relation type embeddings and achieves iterative update between entity nodes and relation edges in the graph. The experiments on two open-source datasets (i.e., CSI100E and CSI300E) demonstrate that the proposed SPMP method can achieve state-of-the-art performances and can assuredly bring benefits for the performance improvement of SPMP.},
  archive      = {J_EAAI},
  author       = {Hao Peng and Ke Dong and Jie Yang},
  doi          = {10.1016/j.engappai.2023.106948},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106948},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stock price movement prediction based on relation type guided graph convolutional network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SHDM-NET: Heat map detail guidance with image matting for
industrial weld semantic segmentation network. <em>EAAI</em>,
<em>126</em>, 106946. (<a
href="https://doi.org/10.1016/j.engappai.2023.106946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Welding is widely used in metal components. The firm of weld components is very important in different applications, such as buildings, bridges, cars and airplanes, etc. Weld seam quality inspection is essential to ensure product quality. The area and shape of the weld seam are the basis for quality assessment. So the segmentation of the weld area is very important for quality assessment. To address the problem of segmentation of the weld seam region, a weld seam segmentation network based on heat map detail guidance with Matting is proposed in this paper, which provides a new idea for fine-grained segmentation of the weld seam region. The existing DCNN-based semantic segmentation algorithm model has a poor segmentation effect at the boundary and jagged segmentation boundary, which are unacceptable for the weld segmentation problem that requires clear and precise boundary positioning. To solve this problem, three innovations are made in this paper on the DCNN-based semantic segmentation network. (1) A heat map detail guidance module makes the segmentation boundary information focus on shallow features and enhances the representation of boundary information. (2) A segmentation head improvement method for fine-grained semantic segmentation is proposed. (3) In response to the loss of process details in the coding and decoding of the semantic segmentation network, resulting in poor segmentation boundary accuracy, this paper introduces a matting algorithm to calibrate the boundary of the weld seam segmentation region. Through many experiments on industrial weld data sets, the effectiveness of our method is demonstrated, and the MIoU (Mean Intersection over Union) reaches 96.32%. It is worth noting that this performance is comparable to human manual segmentation ( MIoU 96.38%).},
  archive      = {J_EAAI},
  author       = {Qi Wang and Jingwu Mei and Wuming Jiang and Hegui Zhu},
  doi          = {10.1016/j.engappai.2023.106946},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106946},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SHDM-NET: Heat map detail guidance with image matting for industrial weld semantic segmentation network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated decision support framework for resilient
vaccine supply chain network design. <em>EAAI</em>, <em>126</em>,
106945. (<a
href="https://doi.org/10.1016/j.engappai.2023.106945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing resilient supply chain networks for vaccine development and distribution requires reliable and robust infrastructure. This stud develops a novel two-stage decision support framework for configuring multi-echelon Supply Chain Networks (SCNs), resilient supplier selection, and order allocation under uncertainty. Resilient supplier selection is done using a hybrid Multi-Criteria Decision-Making (MCDM) approach based on Best-Worst Method (BWM), Weighted Aggregated Sum Product Assessment (WASPAS), and Type-2 Neutrosophic Fuzzy Numbers (T2NN). A robust multi-objective optimization model is then built for order allocation considering resiliency scores, reliability of facilities, and uncertain supply and demand. The objectives are to minimize the total cost of SCN design, maximize the resiliency score, and maximize the reliability of SC, respectively. A Non-dominated Sorting Genetic Algorithm II (NSGA-II) is developed to tackle the problem on large scales, tuned by the Taguchi design technique. The NSGA-II solution is compared to the ε-constraint and Multi-objective Particle Swarm Optimization (MOPSO) solutions using test problems. We demonstrate the superiority of the suggested NSGA-II method over the two competing methods according to five performance metrics. A case study is then investigated to illustrate the applicability and effectiveness of the offered methodology for COVID-19 vaccine distribution in a developing country. It is revealed that the models and algorithms can treat the problem optimally, such that Germany is the main source (approximately 25.61%) while India does not contribute to the supply of vaccines.},
  archive      = {J_EAAI},
  author       = {Erfan Babaee Tirkolaee and Ali Ebadi Torkayesh and Madjid Tavana and Alireza Goli and Vladimir Simic and Weiping Ding},
  doi          = {10.1016/j.engappai.2023.106945},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106945},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated decision support framework for resilient vaccine supply chain network design},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unmanned aerial vehicle remote sensing image registration
based on an improved oriented FAST and rotated BRIEF- random sample
consensus algorithm. <em>EAAI</em>, <em>126</em>, 106944. (<a
href="https://doi.org/10.1016/j.engappai.2023.106944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) remote sensing image registration is the key step of remote sensing image stitching, image fusion and multi-frames image super-resolution. Its speed and accuracy determines the effect of remote sensing image applications, such as object detection, environment monitoring. To meet the speed and accuracy requirements of UAV remote sensing image registration, an improved Oriented FAST and Rotated BRIEF- Random sample consensus (ORB-RANSAC) algorithm is proposed. Firstly, images to be registered are divided into non-overlapping sub-images, and then a simplified image pyramid is constructed for these sub-images to get scale invariance. Secondly, the traditional FAST corner detection algorithm is improved by setting the adaptive corner detection threshold, and more feature points are detected. Meanwhile, the traditional quadtree algorithm is improved to remove redundant feature points and keep the remaining high-quality feature points. Thirdly, feature points coarse matching is done by bidirectional matching combined with cosine similarity method. Finally, the improved RANSAC algorithm is used for feature points fine matching to eliminate mismatches and calculate the transformation matrix. Experiment results show that, comparing with the traditional ORB algorithm, the number of feature points detected is significantly increased and its distribution is more uniform, and the correct matching rate increases by 58.10% in the case of image scale changing. Comparing with the state-of-the-art UAV remote sensing image registration algorithm, the correct matching rate and mutual information of our method are increased by 0.68% and 1.91% respectively, matching time and root mean square error are reduced by 3.89% and 11.2% respectively.},
  archive      = {J_EAAI},
  author       = {Fuzhen Zhu and Huiling Li and Jiacheng Li and Bing Zhu and Siwen Lei},
  doi          = {10.1016/j.engappai.2023.106944},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106944},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unmanned aerial vehicle remote sensing image registration based on an improved oriented FAST and rotated BRIEF- random sample consensus algorithm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new approach to sentiment analysis algorithms: Extended
SWARA-MABAC method with 2-tuple linguistic q-rung orthopair fuzzy
information. <em>EAAI</em>, <em>126</em>, 106943. (<a
href="https://doi.org/10.1016/j.engappai.2023.106943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a process of computationally identifying and categorizing opinions expressed in a piece of text. It employs several algorithms including Bayesian, support vector machine, and naive Bayes. Such algorithms utilize text analysis and natural language processing to categorize words as positive, negative, or neutral. It needs decision-making techniques i.e. algorithms to process the words, which ultimately enable companies to obtain a comprehensive understanding of their customers’ perceptions of the brand. These techniques are mostly interlinked with computer science, and software that have vital roles in numerous decision-making and problem-solving processes. Natural language processing is one of these techniques which focused on endowing computers with the capacity to comprehend text and spoken language akin to human beings. It is often regarded as a common multi-attribute group decision-making (MAGDM) issue in the field of sentiment analysis. A scenario in which individuals simultaneously choose from the options presented to them is referred to as group decision-making. As a result, this article examines the theory of sentiment analysis algorithms and uses the Step-Wise Weight Assessing Ratio Analysis (SWARA) with Multi-Attributive Border Approximation Area Comparison (MABAC) to evaluate the intrinsic and global advantages, disadvantages, potential, and threats of different sentiment analysis algorithms in detail. This study indicates that (1) accuracy; (2) domain-specificity; (3) scalability; and (4) customizability, are four key components that significantly effect the algorithm’s adoption and enhance users’ satisfaction. Furthermore, the SWARA is used to determine the weights of attributes. The MABAC approach is then employed to address the decision-making problem scenario. We use a numerical case to compare the extended MABAC approach to other approaches to assess its validity in the field of computer science.},
  archive      = {J_EAAI},
  author       = {Sumera Naz and Aqsa Shafiq and Shariq Aziz Butt and Rabia Ijaz},
  doi          = {10.1016/j.engappai.2023.106943},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106943},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new approach to sentiment analysis algorithms: Extended SWARA-MABAC method with 2-tuple linguistic q-rung orthopair fuzzy information},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Instance segmentation of stack composed of unknown objects.
<em>EAAI</em>, <em>126</em>, 106942. (<a
href="https://doi.org/10.1016/j.engappai.2023.106942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article reviews neural network architectures designed for the segmentation task. It focuses mainly on instance segmentation of stacked objects. The main assumption is that segmentation is based on a color image with an additional depth layer. The paper also introduces the Stacked Bricks Dataset based on three cameras: RealSense L515, ZED2, and a synthetic one. Selected architectures: DeepLab, Mask RCNN, DEtection TRansformer, Geometry-Aware Instance Segmentation, Shapemask, Synthetic Depth Mask RCNN, Synthetic Fusion Mask RCNN (SF-Mask), Unseen Object Instance Segmentation (UOIS), Unseen Object Clustering (UOC), and You Look Only At Coefficients, have been tested on various datasets. The results show that the best architectures for stacked elements segmentation are UOIS, SF-Mask, and UOC.},
  archive      = {J_EAAI},
  author       = {Michał Czubenko and Artur Chrzanowski and Rafał Okuński},
  doi          = {10.1016/j.engappai.2023.106942},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106942},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instance segmentation of stack composed of unknown objects},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep reinforcement learning algorithm to control a
two-wheeled scooter with a humanoid robot. <em>EAAI</em>, <em>126</em>,
106941. (<a
href="https://doi.org/10.1016/j.engappai.2023.106941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing a two-wheeled scooter is considered a challenging task for robots, as it is a non-linear control problem in a highly dynamic environment. The rapid pace of development of deep reinforcement learning has enabled robots to perform complex control tasks. In this paper, a deep reinforcement learning algorithm is proposed to learn the steering control of the scooter for balancing and patch tracking using an unmodified humanoid robot. Two control strategies are developed, analyzed, and compared: a classical Proportional–Integral–Derivative (PID) controller and a Deep Reinforcement Learning (DRL) controller based on Proximal Policy Optimization (PPO) algorithm. The ability of the robot to balance the scooter using both approaches is extensively evaluated. Challenging control scenarios are tested at low scooter speeds, including 2.5, 5, and 10 km/h. Steering velocities are also varied, including 10, 20, and 40 rad/s. The evaluations include upright balance without disturbances, upright balance under disturbances, tracking sinusoidal path, and path tracking. A 3D model of the humanoid robot and scooter system is developed, which is simulated in a state-of-the-art GPU-based simulation environment as a training and test bed (NVidia’s Isaac Gym). Despite the fact that the PID controller successfully balances the robot, better final results are achieved with the proposed DRL. The results indicate a 52% improvement on average in different speeds with better performance in path tracking control. Controller command evaluation on the real robot and scooter indicates the robot’s complete capability to realize steering control velocities.},
  archive      = {J_EAAI},
  author       = {Jacky Baltes and Guilherme Christmann and Saeed Saeedvand},
  doi          = {10.1016/j.engappai.2023.106941},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106941},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning algorithm to control a two-wheeled scooter with a humanoid robot},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Single-valued neutrosophic dynamic aggregation information
with time sequence preference for IoT technology in supply chain
management. <em>EAAI</em>, <em>126</em>, 106940. (<a
href="https://doi.org/10.1016/j.engappai.2023.106940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of thing (IoT) is a global platform for connecting intelligent objects over the Internet. It facilitates the integration of the “supply chain (SC)” and “information and communication technology (ICT)” infrastructures inside a company and with its vendors and clients. The “supply chain management (SCM)” is presently required if a firm wishes to keep up with the rapid evolution of its consumers’ needs. Several research has demonstrated that manufacturing companies must expedite the transition of their attention to sustainable development and the application of innovative technologies, such as IoT, in order to achieve their organizational objectives most efficiently. This study intends to examine the IoT’s applicability in SCM and assess the most popular IoT systems. The difficulty of identifying the best suitable IoT system is dependent on a multitude of variables, which are sometimes stated as incomplete and unreliable estimations. In order to reach an outcome, this paper proposes a multi-criteria paradigm for IoT solution selection in a single-valued neutrosophic environment. Single-valued neutrosophic set (SiVNS) is a strong model to address uncertain information in terms of three membership functions, namely indeterminacy, truthfulness, and falsity. The goal of this study is to introduce some dynamic single-valued neutrosophic aggregation operators (AOs) for multi-period decision-making problems that involve uncertain single-valued neutrosophic information. We develop novel Einstein AOs named as “dynamic single-valued neutrosophic Einstein weighted averaging (DSiVNEWA) operator and dynamic single-valued neutrosophic Einstein weighted geometric (DSiVNEWG) operator”. Several characteristics of the suggested AOs are investigated. Additionally, we develop a multi-stage dynamic decision analysis utilizing ideal solutions. To illustrate the proposed technique, a numerical example is presented. Comparison and authenticity analyses are conducted to ascertain the efficacy and superiority of the suggested multi-stage dynamic decision analysis in the practical situation.},
  archive      = {J_EAAI},
  author       = {Hafiz Muhammad Athar Farid and Muhammad Riaz},
  doi          = {10.1016/j.engappai.2023.106940},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106940},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Single-valued neutrosophic dynamic aggregation information with time sequence preference for IoT technology in supply chain management},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MmSignature: Semi-supervised human identification system
based on millimeter wave radar. <em>EAAI</em>, <em>126</em>, 106939. (<a
href="https://doi.org/10.1016/j.engappai.2023.106939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human identification is vital in health monitoring, human-computer interaction, safety detection, and other fields. Compared with traditional vision-based methods, millimeter wave radar sensors can protect users&#39; privacy and work in dark environments, which has a wide range of application prospects in iot fields such as smart homes and smart medical care. Previous studies need to manually collect labeled data, which makes the data collection work need substantial human resources and is unsuitable for popularization and application. We automatically collect multi-modal radar signals in users &#39; daily lives without requiring researchers to label data manually. Based on the proposed data collection method, we established the first semi-supervised data set for human identification, which includes synchronous radar point cloud data and range-velocity map data. The dataset contains four experiments, including ten monitoring users and ten other users. We propose a semi-supervised co-training framework based on multi-modal data fusion for human identification. The framework guides the models to learn from unlabeled data using the complementary characteristics of point cloud data and range-velocity map data. In addition, we propose an information fusion method to fuse the radar data of two modes to further improve the model&#39;s performance. The experimental results show that the proposed method achieves 93.7% human identification accuracy, showing radar-based human identification technology&#39;s application and promotion potential.},
  archive      = {J_EAAI},
  author       = {Yicheng Yao and Hao Zhang and Pan Xia and Changyu Liu and Fanglin Geng and Zhongrui Bai and Lidong Du and Xianxiang Chen and Peng Wang and Baoshi Han and Ting Yang and Zhen Fang},
  doi          = {10.1016/j.engappai.2023.106939},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106939},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MmSignature: Semi-supervised human identification system based on millimeter wave radar},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel approach to intelligent monitoring of gas
composition and light mode of greenhouse crop growing zone on the basis
of fuzzy modelling and human-in-the-loop techniques. <em>EAAI</em>,
<em>126</em>, 106938. (<a
href="https://doi.org/10.1016/j.engappai.2023.106938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas composition and light mode of industrial greenhouses are some of the most determining factors in the process of growing vegetable crops in greenhouse conditions. The intelligentisation of information technologies for monitoring and control based on artificial intelligence methods can increase the efficiency of agrotechnical procedures for greenhouse cultivation. One of the efficient approaches in today&#39;s world practice is the development and implementation of trustworthy hybrid decision-support systems based on the techniques of Fuzzy logic and Human-in-the-Loop. The research object is non-stationary processes of complex intelligent transformation of measurement data on the concentration of carbon dioxide and effective energy illumination in the growing zone of industrial greenhouses. The scientific novelty and practical value of the obtained research results consist in creating a computer model for aggregation and intelligent processing of agricultural monitoring data for greenhouses. The developed computer model is fully transformed into peripheral-level software of Internet of Things systems for agricultural purposes. This makes it possible to implement the for-computing architecture of monitoring systems in greenhouses. The obtained research results make it possible to optimise the resources used in growing crops in greenhouse conditions through the implementation of hardware and software intelligent monitoring tools that are adaptive to the types and periods of crop vegetation. The scientific and applied effect of the research is creating the novel approach of development and practical use of intelligent technologies for agrotechnical monitoring by substantiating the methodological provisions for synthesis of structural and algorithmic organisation of the corresponding software and hardware solutions.},
  archive      = {J_EAAI},
  author       = {Ivan Laktionov and Leszek Rutkowski and Oleksandr Vovna and Aleksander Byrski and Maryna Kabanets},
  doi          = {10.1016/j.engappai.2023.106938},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106938},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel approach to intelligent monitoring of gas composition and light mode of greenhouse crop growing zone on the basis of fuzzy modelling and human-in-the-loop techniques},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Piggybacking on past problem for faster optimization in
aluminum electrolysis process design. <em>EAAI</em>, <em>126</em>,
106937. (<a
href="https://doi.org/10.1016/j.engappai.2023.106937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In process industry, it is a habitual phenomenon that the production efficiency is improved via replacing the obsolete devices with the advanced ones. To achieve an optimal performance, these devices are always required for heavily empirical adjustments, which is very time-consuming and inefficient. Though outdated, invaluable experiences for adjusting devices towards a more efficient industrial production have been accumulated by those replaced facilities. Thereby, new devices are expected to adapt to perform the industrial task without many modulations if the aforementioned experiences can be appropriately utilized. Inspired by the fact that evolutionary multitasking is capable of exploiting latent similarities and commonalities among multiple optimization tasks so as to improve the overall convergence of multi-task optimization, in this paper, we propose a novel framework to automatically search for the optimal settings for new devices based on the knowledge accumulated by the old. The framework, dubbed Piggybacking on Past Problem for Faster Optimization (PPPFO), is able to piggyback on the past optimization problem for a faster convergence of the targeted. By means of automatically transferring search experiences (i.e. genetic and cultural characteristics) from source task to the target, PPPFO can assist an engineering optimizer to improve its search exercises. PPPFO has been tested with a number of widely used benchmark functions and has been successfully adopted to an important real application, i.e., aluminum electrolysis process design. The remarkable results verify the efficacy and efficiency of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Lizhong Yao and Tiantian He and Haijun Luo},
  doi          = {10.1016/j.engappai.2023.106937},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106937},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Piggybacking on past problem for faster optimization in aluminum electrolysis process design},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance diagnostics of gas turbines operating under
transient conditions based on dynamic engine model and artificial neural
networks. <em>EAAI</em>, <em>126</em>, 106936. (<a
href="https://doi.org/10.1016/j.engappai.2023.106936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas turbine engines are machines of high complexity and non-linearity. Interpreting the vast amount of data from a gas turbine and converting them into customer value requires the combination of domain knowledge and modern computational intelligence tools. Reaching to an accurate and reliable diagnosis of gas turbines is a process that is becoming increasingly complex. The engines are now expected to operate in more dynamic conditions to compensate for the intermittent nature of renewables. Transient operating conditions will accelerate the deterioration of gas turbine components which motivates the development of new methods and tools to cope with such type of information. In this paper, we propose a novel performance diagnostic method for gas turbines that combines a dynamic engine model with artificial neural networks (ANN). An engine model of a two shaft gas turbine has been developed in MATLAB/Simulink and used by a family of ANNs to detect the degradation of the engine operating under transient conditions, when all of its components are experiencing degradation. The conducted case studies consider various degradation scenarios. The advantage of the proposed method is that it deals effectively with both fixed and time-evolving degradation. Furthermore, in cases where there is limited amount of data for training ANNs the model can fill this gap by simulating plethora of scenarios that can potentially extend the applicability of ANNs to gas turbine diagnostics. The proposed method could be used as a tool for supporting the operation and maintenance activities of gas turbines.},
  archive      = {J_EAAI},
  author       = {Elias Tsoutsanis and Imran Qureshi and Mustafa Hesham},
  doi          = {10.1016/j.engappai.2023.106936},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106936},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Performance diagnostics of gas turbines operating under transient conditions based on dynamic engine model and artificial neural networks},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new multi-sensor fusion with hybrid convolutional neural
network with wiener model for remaining useful life estimation.
<em>EAAI</em>, <em>126</em>, 106934. (<a
href="https://doi.org/10.1016/j.engappai.2023.106934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of smart manufacturing, the health monitoring of the machines has become important. Remaining useful life (RUL) estimation, which could predict the future machine state, has attracted much more attentions. Deep learning (DL) based RUL has achieved remarkable results. But it still faces the issues on the multi-sensor fusion process and the health index (HI) construction, and both of these two issues can affect DL models for RUL. To overcome these issues, this research designed a new hybrid model of Convolutional Neural Network (CNN) and Wiener process, named hybrid CNN-Wiener model. First, the CNN network is adopted to achieve feature-level fusion of multi-sensor signals and to calculate the virtual HI of the machine. Second, the Wiener process model is developed to estimate the value of RUL using virtual HI. Third, the Wiener process model is designed as the layer in CNN network and trained with CNN together. The hybrid CNN-Wiener model has been tested on the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) dataset, and its results show that the hybrid CNN-Wiener model has obtained the remarkable promotion by comparing with other famous DL models. The ablation studies have been tested and it shows that the hybrid CNN-Wiener model has been promotion largely with the Wiener model and the multi-sensor fusion techniques.},
  archive      = {J_EAAI},
  author       = {Long Wen and Shaoquan Su and Bin Wang and Jian Ge and Liang Gao and Ke Lin},
  doi          = {10.1016/j.engappai.2023.106934},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106934},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new multi-sensor fusion with hybrid convolutional neural network with wiener model for remaining useful life estimation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective high-dimensional multi-fractional-order
optimization algorithm for multi-objective high-dimensional
multi-fractional-order optimization controller parameters of doubly-fed
induction generator-based wind turbines. <em>EAAI</em>, <em>126</em>,
106929. (<a
href="https://doi.org/10.1016/j.engappai.2023.106929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the operation control of doubly-fed induction generator-wind energy systems, this study firstly introduces multi-dimensional information feedback and fractional-order theory and designs a high-dimensional multi-fractional-order controller in the rotor side converter. Secondly, for the tuning optimization of controller parameters of doubly-fed induction generators, this study proposes a high-dimensional multi-fractional-order optimization. Finally, this study proposes a multi-objective high-dimensional multi-fractional-order optimization algorithm for the multi-objective optimization problems of control parameters tuning and optimization. This study adopts an adaptive grid strategy to update non-dominated solutions for external archives with crowded conditions. Furthermore, this study adopts a roulette strategy to select the optimal global position in the iterative process. This study utilizes multi-objective test functions to verify the effectiveness of the proposed multi-objective optimization. The Pareto optimal solutions and five types of statistical data from two indexes show that the proposed multi-objective optimization has improved convergence, diversity, and operational stability. Compared with five algorithms, the proposed multi-objective optimization can obtain Pareto optimal solutions with uniform distribution and good diversity in the multi-objective tuning of control parameters of the designed multi-objective controllers for doubly-fed induction generators. Therefore, decision-makers can choose the control parameters according to the actual needs. The test results show that the designed multi-objective controller optimized by the proposed multi-objective optimization has more accurate power tracking ability and superior control performance.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Wenyu Ding},
  doi          = {10.1016/j.engappai.2023.106929},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106929},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective high-dimensional multi-fractional-order optimization algorithm for multi-objective high-dimensional multi-fractional-order optimization controller parameters of doubly-fed induction generator-based wind turbines},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mining graph-based dynamic relationships for object
detection. <em>EAAI</em>, <em>126</em>, 106928. (<a
href="https://doi.org/10.1016/j.engappai.2023.106928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the propagation of deep neural networks results in the loss of detailed feature information, the performance of most object detection methods is limited due to their tendency to learn regional features in visual space while neglecting relationships between objects. Therefore, this study proposes the Graph Relational Decision Network (GRDN), which mines relationships between objects in a dataset. The GRDN consists of a graph decision network, decision coefficient, and step-wise relation deduction module. The graph decision network comprises an edge decision network, and a node decision network, wherein a data-driven technique is employed to obtain implicit relationships between labels in a dataset. These relationships are expressed through an adaptive dynamic graph, which is subsequently recoded by means of the decision coefficient, which can enhance semantic information. In the step-wise relation deduction module, semantic information is employed as a guide to prevent distraction. A series of experiments were conducted on the MS COCO dataset. The proposed method achieves 52.8% box AP on object detection, which is 2.3% box AP higher than Cascade Mask R-CNN. The experimental results show that the addition of dynamic semantic information in this study can make up for the loss of detailed information and focus on key information, thereby improving the detection ability of small objects and occluded objects. In summary, this study extracts inter-object relationships to obtain more complete semantic information, which enriches the research of object detection.},
  archive      = {J_EAAI},
  author       = {Xiwei Yang and Zhixin Li and Xinfang Zhong and Canlong Zhang and Huifang Ma},
  doi          = {10.1016/j.engappai.2023.106928},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106928},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mining graph-based dynamic relationships for object detection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph attention u-net to fuse multi-sensor signals for
long-tailed distribution fault diagnosis. <em>EAAI</em>, <em>126</em>,
106927. (<a
href="https://doi.org/10.1016/j.engappai.2023.106927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the occasionality and unsustainable characteristics of mechanical faults, the collected data in real scenario is normally imbalanced that subsequently bottlenecks the appropriate fault recognition. In the actual operation of the equipment, there often exists many fault types, but the sample size of each fault is usually extremely unbalanced, which case is similar to the issue of long-tailed distribution. However, most existing approaches dealing with the long-tail problem seldomly utilize sensor structure information to reduce the imbalance impact and the commonly employed cost-sensitive losses fail to meet the comprehensively and complexity of the problem. To address these shortcomings, here we intend to construct a sensor network from the multi-sensor of the system and propose the graph attention U-Net (GATU-Net) to model the sensor network for the fault diagnosis featured with long-tailed distribution. Our proposed algorithm employs graph attention networks for the message passing and feature mining of structural relations among those sensors, and obtains favorable graph embeddings through the U-Nets architecture. In addition, a weighted shrinkage loss is proposed to allow the model to penalize the attention to low-valued samples and increase the attention to high-valued samples. Two experimental case studies unveil that GATU-Net is capable of achieving great performance for fault diagnosis with long-tailed distribution.},
  archive      = {J_EAAI},
  author       = {Yuangui Yang and Tianfu Li and Chuang Sun and Liuyang Zhang and Ruqiang Yan},
  doi          = {10.1016/j.engappai.2023.106927},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106927},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph attention U-net to fuse multi-sensor signals for long-tailed distribution fault diagnosis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CBFLNet: Cross-boundary feature learning for large-scale
point cloud segmentation. <em>EAAI</em>, <em>126</em>, 106926. (<a
href="https://doi.org/10.1016/j.engappai.2023.106926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale point cloud semantic segmentation presents a crucial yet challenging task. Current point cloud analysis approaches typically partition data into volumetric blocks, independently assigning labels to each point within these blocks. However, this strategy often compromises segmentation accuracy at block boundaries due to the isolated processing of each block, thus hindering the model’s contextual understanding. To address this issue, we present CBFLNet, an innovative semantic segmentation model that enables offset-free feature upsampling and cross-boundary feature learning. CBFLNet facilitates interaction between adjacent blocks, extending its receptive field beyond the input block. As a result, it notably mitigates errors in block boundary segmentation. CBFLNet is composed of three modules: an explicit local representation module, a symmetric sampling module, and a cross-boundary feature fusion module. The explicit local representation module is a plug-and-play module that takes two overlapping point cloud blocks as input to construct an approximate local spatial representation. In the symmetric sampling module, point features are symmetrically downsampled and upsampled, effectively avoiding feature offset caused by interpolation. Lastly, the cross-boundary feature fusion module enables cross-boundary local feature learning and multi-scale feature fusion. CBFLNet demonstrates a significant performance improvement, achieving a 0.9% mIoU increase over state-of-the-art methods on the S3DIS dataset and exhibiting competitive performance on the ScannetV2 dataset.},
  archive      = {J_EAAI},
  author       = {Liping Zhu and Cong Peng and Bingyao Wang and Chengyang Li and Kaijie Zhu},
  doi          = {10.1016/j.engappai.2023.106926},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106926},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CBFLNet: Cross-boundary feature learning for large-scale point cloud segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BOLD-net: Brightness enhancement for old images using deep
curve estimation and attention modules. <em>EAAI</em>, <em>126</em>,
106925. (<a
href="https://doi.org/10.1016/j.engappai.2023.106925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel deep-learning network for the brightness enhancement of old images is proposed. Although the task for brightness enhancement of old images is similar to the low-light enhancement problem of modern images, the causes of darkness and image characteristics are significantly different. Unlike modern images, bright degradation in old images is due to low-quality camera sensors, unsophisticated techniques that capture the images, and the harsh environment where the photos/films were stored. Though existing low-light enhancement networks show good reconstruction capabilities for modern images, they result in overexposed, color-distorted outputs if applied to old images. To resolve these, we propose a novel deep-learning network with a combination of two convolutional neural networks, which estimates curve maps to adjust the dynamic range, and an attention-guided illumination map to adjust the illumination of the given input image. In addition, channel attention blocks in the illumination map estimation network are further performed to reduce image noise and prevent over- or underexposure. The networks perform in parallel to enhance the brightness of the image and preserve inherent colors and texture details. The proposed method was evaluated on the peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and learned perceptual image patch similarity (LPIPS) and compared with the state-of-the-art methods on a dataset containing old video frames from different decades. Experimental results show that the proposed method outperforms state-of-the-art methods in terms of visual quality for brightness enhancement on old photo and video datasets.},
  archive      = {J_EAAI},
  author       = {Arshiana Shamir and Nokap Park and Bumshik Lee},
  doi          = {10.1016/j.engappai.2023.106925},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106925},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BOLD-net: Brightness enhancement for old images using deep curve estimation and attention modules},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A swarming neural network computing approach to solve the
zika virus model. <em>EAAI</em>, <em>126</em>, 106924. (<a
href="https://doi.org/10.1016/j.engappai.2023.106924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a swarming computational procedure is presented for the numerical treatment of the dynamical model of the susceptible, exposed, infected, and recovered (SEIR) classes that portrayed the spreading of Zika virus. The artificial neural network procedures (ANNPs) have been applied to solve the SEIR mathematical model for spreading of the Zika virus together with the hybridization efficiency of global swarming and local search schemes. The global particle swarm optimization (PSO) and local search active-set algorithm (ASA) have been proposed to solve the model. An error based objective function is presented for the SEIR differential model and then optimized by the hybrid computing efficiency of PSO-ASA. Five neurons, fifteen variables of each class and ten numbers of trials have been used to solve the SEIR mathematical model for spreading of the Zika virus. The correctness of the proposed computing ANNPs-PSO-ASA is observed by using the comparison of the obtained and reference solutions along with the performances of the absolute error, ranges around 10 −06 to 10 −08 . The reliability of the designed computing ANNPs-PSO-ASA technique is observed by using the statistical operator performances on single/multiple trials for the SEIR system for spreading of the Zika virus dynamics.},
  archive      = {J_EAAI},
  author       = {Zulqurnain Sabir and Shahid Ahmad Bhat and Muhammad Asif Zahoor Raja and Sharifah E. Alhazmi},
  doi          = {10.1016/j.engappai.2023.106924},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106924},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A swarming neural network computing approach to solve the zika virus model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reduced-order modeling of the two-dimensional
rayleigh–bénard convection flow through a non-intrusive operator
inference. <em>EAAI</em>, <em>126</em>, 106923. (<a
href="https://doi.org/10.1016/j.engappai.2023.106923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing availability of large datasets provided by high-fidelity numerical simulations (HFNSs) of physical phenomena, data-driven reduced-order models (ROMs) have become a reliable alternative to those described by partial differential equations, especially when dealing with optimization problems that require multiple evaluations of parameter dependent solutions. These models may be built through different methodologies, among which are the physics-informed neural networks (PINNs) and operator learning frameworks (OLFs). While some recent studies suggest that PINNs have some difficulties in handling convective-dominant physical systems, others show OLFs struggle to accurately predict state variables of interest along the testing interval. In the present work, a ROM for the two-dimensional Rayleigh-Bénard convection flow was built through an incremental proper orthogonal decomposition (IPOD) of a high-fidelity dataset followed by a non-intrusive operator inference (OpInf) approach. Then, the predictive capabilities of the model were assessed for two test cases with different high Rayleigh numbers ( R a = 1 0 9 and R a = 1 0 11 ). Very good agreements were achieved between the OpInf-based ROMs and the HFNSs for temperature and velocity fields along training and testing intervals. For instance, time-averaged normalized ROM errors along the testing interval for all the flow variables were below 15% at a given probe location when R a = 1 0 9 . For each case, while the computational fluid dynamics simulation took about 2 h, the reduced model required less than 3 s to predict the system’s states given its initial condition. This fact illustrates the substantial computational time reduction provided by the ROM. Regarding the case in which the Rayleigh number is higher, the ROM had more difficulties in approximating velocity fields due to the existence of more complex turbulence patterns. Finally, the quality of the data decomposition and of the selected regularization technique, often seen in artificial intelligence algorithms, was investigated. The results suggest the OpInf technique may be successfully applied on the surrogate modeling of turbulent buoyancy-driven flows.},
  archive      = {J_EAAI},
  author       = {Pedro Roberto Barbosa Rocha and João Lucas de Sousa Almeida and Marcos Sebastião de Paula Gomes and Alberto Costa Nogueira Junior},
  doi          = {10.1016/j.engappai.2023.106923},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106923},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reduced-order modeling of the two-dimensional Rayleigh–Bénard convection flow through a non-intrusive operator inference},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recurrent neural network based design of fractional order
power system stabilizer for effective damping of power oscillations in
multimachine system. <em>EAAI</em>, <em>126</em>, 106922. (<a
href="https://doi.org/10.1016/j.engappai.2023.106922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of modern power systems has risen due to the growing demand for electricity. To mitigate this problem, the role of the electric utility in supplying safe and reliable electricity has become increasingly crucial. Low-frequency oscillations (LFOs) in a power system are an inevitable aspect. Therefore, the reliability of the system requires appropriate damping to overcome these LFOs. This paper proposes a novel design methodology for a fractional-order power system stabilizer (FO-PSS) to enhance the stability of the power system network. FO-PSS is designed to effectively dampen LFOs in both single-machine infinite bus systems (SMIB) and multi-machine power systems (MMPS). Recurrent neural network (RNN) is used to predict the parameters of proposed PSSs. To evaluate the efficacy of the proposed PSS, various test cases are considered. The results are compared to those obtained from traditional PSSs and optimization based PSSs. The effectiveness of the proposed RNN-based FO-PSS is demonstrated under diverse loading conditions.},
  archive      = {J_EAAI},
  author       = {Devesh Umesh Sarkar and Tapan Prakash},
  doi          = {10.1016/j.engappai.2023.106922},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106922},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recurrent neural network based design of fractional order power system stabilizer for effective damping of power oscillations in multimachine system},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extended dissipative filtering of discrete-time interval
type-2 models with mode-dependent bounded semi-markovian switching.
<em>EAAI</em>, <em>126</em>, 106921. (<a
href="https://doi.org/10.1016/j.engappai.2023.106921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the extended dissipative filtering for IT2 systems with semi-Markovian switching. In order to obtain general filtering results, the mode-dependent boundness is introduced for the semi-Markovian chain. An analysis result for the underlying system is established by utilizing a novel stochastic characteristic of index function in extended dissipativity. Facilitated by a decoupling technique, the extended dissipative filter can be developed in light of the obtained analysis result. Simulation examples including tunnel diode circuit are provided to demonstrate the effectiveness of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Han Dong and Shaosheng Zhou},
  doi          = {10.1016/j.engappai.2023.106921},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106921},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Extended dissipative filtering of discrete-time interval type-2 models with mode-dependent bounded semi-markovian switching},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PolarGAN: Creating realistic arctic sea ice concentration
images with user-defined geometric preferences. <em>EAAI</em>,
<em>126</em>, 106920. (<a
href="https://doi.org/10.1016/j.engappai.2023.106920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel generative adversarial network (GAN), called PolarGAN, that is capable of creating realistic artificial images of Arctic sea ice concentration (SIC) for data augmentation. One of the key features of the PolarGAN is that it considers real-valued geometric preferences, defined by six statistics, to generate SIC images that align with specific geometric characteristics. Unlike other GANs that also consider user-defined preferences, the PolarGAN allows for more detailed control over the shape and size of the generated images by using differentiable projection functions to convert the created images into geometric features, and a newly-designed loss function to minimize the gap between the user-defined preferences and the geometric features of the generated images. Through extensive experimentation, we compare the PolarGAN with other GANs and demonstrate artificial SIC scenarios that can be used to test the performance of algorithms for Arctic route planning in edge cases or to improve data-driven models such as SIC prediction models which require additional data to avoid overfitting issues.},
  archive      = {J_EAAI},
  author       = {Mingyu Kim and Jaekyeong Lee and Leechan Choi and Minjoo Choi},
  doi          = {10.1016/j.engappai.2023.106920},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106920},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PolarGAN: Creating realistic arctic sea ice concentration images with user-defined geometric preferences},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HOLT-net: Detecting smokers via human–object interaction
with lite transformer network. <em>EAAI</em>, <em>126</em>, 106919. (<a
href="https://doi.org/10.1016/j.engappai.2023.106919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concerns of public health and safety lead to a practical need to detect smoking behaviors (or smokers) in public places. Previous smoker detection methods often focus on cigarette detection, which overlook the interaction between the smoker and the cigarette. In light of this, this paper presents a single-image smoker detection framework via h uman- o bject interaction with l ite t ransformer net work (HOLT-Net). Specifically, a one-stage human–object interaction module is devised to identify the interaction between the smoker and the cigarette. To incorporate the global information for better feature representation, a simple yet powerful lite transformer module is leveraged, where the multi-head self-attention blocks are exploited. Beyond that, a post-refinement module is integrated for taking advantage of an additional fine-grained cigarette detector to enhance the interaction detection accuracy. It is noteworthy that we present a new benchmark dataset named SCAU-Smoker Detection (SCAU-SD), which, to the best of our knowledge, is the first benchmark dataset for the specific task of smoker detection in single images with human–object interaction annotations. Extensive experimental results demonstrate the effectiveness of our HOLT-Net framework. The code is publicly available at https://github.com/JackKoLing/HOLT-Net .},
  archive      = {J_EAAI},
  author       = {Hua-Bao Ling and Dong Huang and Jinrong Cui and Chang-Dong Wang},
  doi          = {10.1016/j.engappai.2023.106919},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106919},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HOLT-net: Detecting smokers via human–object interaction with lite transformer network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-sensor signals multi-scale fusion method for fault
detection of high-speed and high-power diesel engine under variable
operating conditions. <em>EAAI</em>, <em>126</em>, 106912. (<a
href="https://doi.org/10.1016/j.engappai.2023.106912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting faults in high-speed and high-power diesel engines under complex variable operating conditions is highly challenging. Online vibration monitoring systems have been used in such diesel engines in key fields, in which vibration sensors are installed on each cylinder to enable comprehensive monitoring. In this paper, a fault detection method for diesel engines under variable operating conditions is proposed based on multi-sensor signal multi-scale fusion. Firstly, a preprocessing framework is established for the raw vibration signals collected from each cylinder to eliminate random interference and system noise. Then, the resulting signals are phase-aligned based on the engine firing sequence and analyzed using a signal correlation algorithm to produce a multi-sensor multi-scale similarity matrix (MSMSSM). Finally, a multi-branch residual convolutional neural network (MBRCNN) model is constructed with the MSMSSM as the input to detect abnormal health states of the diesel engine. Fault simulation experiments are conducted on a 12-cylinder V-type high-speed and high-power diesel engine test rig. The comparative test results indicate that the proposed MSMSSM-MBRCNN method shows both the highest accuracy of 95.28% and the lowest standard deviation of 3.57% compared to other typical methods. The multi-sensor signals multi-scale fusion method proposed in this paper fully utilizes the key information that remains basically consistent in the synchronous acquisition signals of multiple sensors under different operating conditions. This can effectively reduce the interference of operating condition changes and improve the accuracy and robustness of fault detection.},
  archive      = {J_EAAI},
  author       = {Jiaqi Liang and Zhiwei Mao and Fengchun Liu and Xiangxin Kong and Jinjie Zhang and Zhinong Jiang},
  doi          = {10.1016/j.engappai.2023.106912},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106912},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-sensor signals multi-scale fusion method for fault detection of high-speed and high-power diesel engine under variable operating conditions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review of resampling techniques for the treatment of
imbalanced industrial data classification in equipment condition
monitoring. <em>EAAI</em>, <em>126</em>, 106911. (<a
href="https://doi.org/10.1016/j.engappai.2023.106911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an actual industrial scenario, machines typically operate normally for the majority of the time, with malfunctions occurring only occasionally. As a result, there is very little recorded data on defects. Consequently, the fault diagnostic dataset becomes imbalanced, with a significantly lower number of fault samples compared to normal samples. Furthermore, with the rapid development of the manufacturing industry, the increasing complexity of machines and equipment leads to various challenges in collecting fault data, such as noise, within-class imbalance, multi-class imbalance, and time series imbalance. It is worth noting that this study is the first to comprehensively summarize these four specific challenges. Therefore, addressing these issues has become a critical research focus and a pain point in the field of fault diagnosis, and numerous solutions have emerged. This study provides a comprehensive overview of these solutions at three levels: data preprocessing, feature extraction, and classifier improvement. It also describes the applications of imbalanced data classification methods, including pure resampling techniques, as well as sampling techniques that combine resampling algorithms with feature extraction and classifier improvement in industrial scenarios. Finally, we summarize the challenges facing imbalanced data classification research and suggest potential directions for future studies.},
  archive      = {J_EAAI},
  author       = {Yage Yuan and Jianan Wei and Haisong Huang and Weidong Jiao and Jiaxin Wang and Hualin Chen},
  doi          = {10.1016/j.engappai.2023.106911},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106911},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review of resampling techniques for the treatment of imbalanced industrial data classification in equipment condition monitoring},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of advanced hybrid mechanistic-artificial
intelligence computational model for learning of numerical data of flow
in porous membranes. <em>EAAI</em>, <em>126</em>, 106910. (<a
href="https://doi.org/10.1016/j.engappai.2023.106910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical analysis and machine learning regression were carried out for understanding and description of ozonation process combined with membrane separation. The main focus was on mass transfer modeling to simulate concentration distribution of ozone in liquid phase. Machine learning regression models were utilized to decrease the computational expenses of CFD (Computational Fluid Dynamics) simulations. For machine learning models, we compared the performance of three regression models, namely Gaussian Process Regression (GPR), Deep Neural Network (DNN), and Extreme Gradient Boosting (XGB or XGboost) for predicting the obtained output of CFD simulations which was ozone concentration in the feed, i.e., C (mol/m 3 ) as function of radial and axial coordinates. Hyper-parameter tuning for these models was performed using the Tabu Search algorithm. The results indicate that both GPR and DNN models achieved excellent prediction accuracy, with R-squared values of 0.99999 and 0.99998, respectively. Also, the RMSE for GPR and DNN were 3.8481E-03 and 4.9835E-03, respectively, while their maximum errors were 6.08501E-02 and 4.47909E-02, respectively. On the other hand, the XGB model showed a lower performance, with an R-squared value of 0.99402, an RMSE of 8.9484E-02, and a maximum error of 4.51381E-01},
  archive      = {J_EAAI},
  author       = {Hongwang Zhao and Sameer Alshehri},
  doi          = {10.1016/j.engappai.2023.106910},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106910},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of advanced hybrid mechanistic-artificial intelligence computational model for learning of numerical data of flow in porous membranes},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization of inserted coiled tube three-fluid heat
exchanger using genetic algorithms. <em>EAAI</em>, <em>126</em>, 106909.
(<a href="https://doi.org/10.1016/j.engappai.2023.106909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The three-fluid heat exchanger is a multi-stream heat exchanger that provides three streams at different temperatures for certain usage objectives. Recently, optimizing heat exchangers generally and three-fluid heat exchangers especially have received great attention in the energy field. The current study objective is to get the optimal mass flow rate of the three streams to minimize the entropy generation number and maximize effectiveness. Optimization is performed on the inserted coiled tube type for 24 cases with different usage objectives and different mass flow rate constraints. The optimization is done using an analytical approach for the temperature profiles and a regressed model for the overall heat transfer coefficients. Single-objective and multi-objective genetic algorithms are the optimization algorithms. The result shows that cooling the hot fluid is the most efficient usage objective; however, heating the intermediate-temperature fluid is the less efficient usage objective. Also, the study shows that the entropy generation number is dependent on the mass flow rate constraint. The maximum effectiveness of 0.693 occurs when the usage objective is cooling the hot fluid. In this case, the mass flow rate of the cold and the intermediate-temperature fluids are maxima while the mass flow rate of the hot fluid is minimum. The minimum entropy generation number 0.0486 occurs when the mass flow rate of the cold fluid is maximum while the mass flow rate of the hot fluid and intermediate-temperature fluid are minimal.},
  archive      = {J_EAAI},
  author       = {Mohammed H. Hamed and Ahmed N. Shmroukh and Mohammed Attalla and Hussein M. Maghrabie},
  doi          = {10.1016/j.engappai.2023.106909},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106909},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization of inserted coiled tube three-fluid heat exchanger using genetic algorithms},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A gradient-enhanced physics-informed neural network (gPINN)
scheme for the coupled non-fickian/non-fourierian
diffusion-thermoelasticity analysis: A novel gPINN structure.
<em>EAAI</em>, <em>126</em>, 106908. (<a
href="https://doi.org/10.1016/j.engappai.2023.106908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a modified artificial intelligence (AI) approach based on the gradient-enhanced physics-informed neural network (gPINN) with a novel structure for the generalized coupled non-Fickian/non-Fourierian diffusion-thermoelasticity analysis. Previous successful application of gPINN in function approximation and single partial differential equation (PDE) problems gave us enough motivation to develop its application with a novel structure for solving a system of coupled PDEs. The governing equations are formulated for a copper-made strip based upon the Lord-Shulman theory of the generalized coupled thermoelasticity. In order to shed light on the capacity of the gPINN-based approach, three examples with different boundary conditions for a one-dimensional half-space are presented, as well as an example for a two-dimensional half-space. The primary goal is to investigate the transient behavior of field variables (i.e., non-dimensional molar concentration, non-dimensional displacement, and non-dimensional temperature). Variations of dimensionless stress are also examined in depth. Performance comparisons between the gPINN-based method and commonly used approaches support the efficacy of the gPINN with a novel structure. Detailed sensitivity analyses are provided to sufficiently explore the impact of neural network hyperparameters. Moreover, the effect of relaxation time on the behavior of mass concentration is addressed in a single scenario. Overall, the proposed gPINN-based method with a novel structure yields consistently encouraging and satisfactory results, and this approach entails the capability to be applied to more complicated problems. Numerical results underline the importance of the weights assigned to the derivatives of the loss terms to achieve more accurate predictions. Nonparametric statistical tests offer further evidence for exceptional agreement between gPINN solutions with certain weights and outcomes derived by commonly used analytical techniques.},
  archive      = {J_EAAI},
  author       = {Katayoun Eshkofti and Seyed Mahmoud Hosseini},
  doi          = {10.1016/j.engappai.2023.106908},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106908},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A gradient-enhanced physics-informed neural network (gPINN) scheme for the coupled non-fickian/non-fourierian diffusion-thermoelasticity analysis: A novel gPINN structure},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Physics-informed few-shot deep learning for elastoplastic
constitutive relationships. <em>EAAI</em>, <em>126</em>, 106907. (<a
href="https://doi.org/10.1016/j.engappai.2023.106907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elastoplastic modeling is essential for accurately predicting material behavior in various engineering applications. However, existing approaches to developing intelligent models for elastoplasticity face limitations due to the scarcity of available data, particularly in cases where experiments cannot support full training of these models. To address this challenge, we propose a physics-informed few-shot learning framework that incorporates classic elastoplasticity theory as prior knowledge. Instead of directly solving specific constitutive ordinary differential equations, we utilize general mechanical inequations as physical regularization to confine the optimization space. Our framework is model-agnostic in the uniaxial scenario and free from complicated numerical implementation, preserving the advantages of the data-driven paradigm in terms of efficiency and simplicity. In the multiaxial scenario, the framework can automatically calibrate multiple interwoven material parameters of the underlying constitutive model, facilitating the generation of ample multiaxial data for downstream learning. To further improve convergence, we introduce a novel training strategy. A numerical experiments with only 32 pieces of training data validate the effectiveness of the developed framework. The trained uniaxial model exhibits exceptional generalization capabilities, achieving 44.9% higher accuracy than the purely data-driven model. For multiaxial relationships, our framework demonstrates remarkable efficiency in calibrating material constants compared to conventional machine or manual methods, and the trained model accurately reproduces highly nonlinear multiaxial elastoplastic curves. Our work addresses the pressing need for accurate elastoplastic modeling in the absence of large datasets and provides a promising new solution that can significantly improve generalization capabilities.},
  archive      = {J_EAAI},
  author       = {Chen Wang and You-quan He and Hong-ming Lu and Jian-guo Nie and Jian-sheng Fan},
  doi          = {10.1016/j.engappai.2023.106907},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106907},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed few-shot deep learning for elastoplastic constitutive relationships},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing and performance analysis of an integrated
electromagnetic and hydraulic retarder for heavy-duty vehicles.
<em>EAAI</em>, <em>126</em>, 106906. (<a
href="https://doi.org/10.1016/j.engappai.2023.106906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydraulic retarder and eddy current retarder are important auxiliary braking component, which installed on heavy-duty vehicles. However, the hydraulic retarder has poor braking performance at low speeds, while the eddy-current retarder presents serious thermal recession at high speed. To overcome these issues and ensure safe driving during downhill conditions, a novel Integrated Electromagnetic and Hydraulic Retarder (IEHR) is proposed. The design includes a rotor with blades, double salient poles, and a coil built in a C-type stator. The electromagnetic field model of the IEHR is established and analyzed using the Finite Element Method. Moreover, the nonlinear eddy viscosity model of the flow field is generated and analyzed using the Computational Fluid Dynamics. The Blend braking control strategy is adopted to distribute the braking torque at high speed and low speed The IEHR performance was tested at a test bench. The test results show that the calculated braking characteristics of the electromagnetic and hydraulic subsystems were reasonable agreement with the measured results. The road test was carried out on a vehicle with a total mass of 49 tons. The deceleration and torque peaked at 0.75 m/s 2 and 3620 N m, respectively. These results indicated that the IEHR has better performance than conventional hydraulic retarders and eddy current retarder, and is more suitable for heavy vehicles.},
  archive      = {J_EAAI},
  author       = {Kai Zhang and Huichao Shang and Jing Xu and Jigao Niu and Yonggao Yue},
  doi          = {10.1016/j.engappai.2023.106906},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106906},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Testing and performance analysis of an integrated electromagnetic and hydraulic retarder for heavy-duty vehicles},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating embedding spaces for re-identifying pallets from
their chipwood patterns. <em>EAAI</em>, <em>126</em>, 106905. (<a
href="https://doi.org/10.1016/j.engappai.2023.106905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern logistics rely on continuous tracking of even most basic entities like pallets. While tracking is nowadays achieved via additional markers (e.g., barcodes), pallets have a unique woodchip pattern in their blocks that can be exploited for re-identification if suitable methods are employed. This paper shows how this task can be accomplished in an open-set scenario. In this work, images of pallet blocks are transformed into vector representations using neural networks based on the ResNet-50 architecture. The networks are trained such that the Euclidean distance between image vectors of the same palette block is small. Several approaches, i.e., cross entropy, contrastive and triplet loss, to create the embedding space are compared. It is shown that Triplet Loss has advantages over other methods with a top-1 accuracy of 0.86 on the pallet-block-32965 dataset. In addition, a neighborhood-based approach to novelty detection called NSAND is presented, which outperforms a purely distance-based approach by up to 20% .},
  archive      = {J_EAAI},
  author       = {Nils Schwenzfeier and Jérôme Rutinowski and Marc Hesenius and Christopher Reining and Maribel Acosta},
  doi          = {10.1016/j.engappai.2023.106905},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106905},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generating embedding spaces for re-identifying pallets from their chipwood patterns},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A k-net-based hybrid semantic segmentation method for
extracting lake water bodies. <em>EAAI</em>, <em>126</em>, 106904. (<a
href="https://doi.org/10.1016/j.engappai.2023.106904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lakes have a crucial impact on natural disaster prevention, resource recycling, maintenance of agricultural production and daily life. The traditional way of acquiring lake water body information lacks efficiency, is dangerous, and is not suitable for lake water body information acquisition and real-time monitoring. For this reason, the automated lake water body extraction method based on deep learning semantic segmentation model is gradually becoming a mainstream method. However, most of the semantic segmentation models used for lake extraction today express features through static semantics, while ignoring the extraction relationships of different convolutional kernels for these features. In order to better extract lake water bodies from remote sensing images, this paper proposes a hybrid semantic segmentation method based on K-Net, which achieves high accuracy extraction of lake water bodies by introducing dynamic semantic kernels to iteratively refine the feature information. The superiority of the K-Net-based hybrid model on a Google remote sensing image dataset of lakes is validated. The experimental results show that (1) the hybrid model is able to achieve accurate extraction of lake water bodies, with the UperNet + K-Net model using Swin-l performing the best among all six evaluation metrics, with mean intersection over union (mIoU) reaching 97.77%; and that (2) after incorporating the K-Net module, all tested models obtain a larger mIoU than before.},
  archive      = {J_EAAI},
  author       = {Cong Chen and Yuzhu Wang and Shuang Yang and Xiaohui Ji and Gongwen Wang},
  doi          = {10.1016/j.engappai.2023.106904},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106904},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A K-net-based hybrid semantic segmentation method for extracting lake water bodies},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated insomnia detection using wavelet scattering
network technique with single-channel EEG signals. <em>EAAI</em>,
<em>126</em>, 106903. (<a
href="https://doi.org/10.1016/j.engappai.2023.106903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep is crucial for both the physical and mental well-being of human life. As the sleep pattern varies in every individual, it is essential to develop a methodology that enables us to detect sleep-related disorders precisely. Insomnia is one such disorder that affects humans mentally and physically. Signals from Polysomnograms (PSGs) are typically used to identify different sleep disorders. The PSG signals need a lot of handling time and are not patient-friendly. This work proposes to develop a method to automatically identify insomnia using single-channel Electroencephalogram (EEG) signals. We have employed a Wavelet Scattering Network (WSN), a variant of deep convolutional networks, to extract features effectively WSN is an optimized network capable of learning features that assist in discriminating patterns concealed within signals. In addition, WSNs are insensitive to local disturbances, enhancing the network’s dependability and efficiency. We have used single-channel EEG derivation, C4-A1, to create six separate subsets variants based on the sleep-stage annotations, developing the model individually and collectively for the wake, N1, N2, N3, and Rapid Eye Movement (REM) sleep stages To build the proposed model, 12,576 epochs from the Cyclic Alternating Pattern (CAP) sleep database and 20,523 epochs from the Sleep Disorders Research Center (SDRC) dataset were considered. Our proposed model has attained the highest classification Accuracy (Acc) of 97% and area under the curve (AUC) of 0.98 using a Trilayered Neural Network (TNN) classifier considering the wake-sleep stage of the CAP database. Our devised method is straightforward and computationally efficient. Hence, it could be used for clinical applications.},
  archive      = {J_EAAI},
  author       = {Manish Sharma and Divyansh Anand and Sarv Verma and U. Rajendra Acharya},
  doi          = {10.1016/j.engappai.2023.106903},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106903},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated insomnia detection using wavelet scattering network technique with single-channel EEG signals},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lung-EffNet: Lung cancer classification using EfficientNet
from CT-scan images. <em>EAAI</em>, <em>126</em>, 106902. (<a
href="https://doi.org/10.1016/j.engappai.2023.106902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer (LC) remains a leading cause of death worldwide. Early diagnosis is critical to protect innocent human lives. Computed tomography (CT) scans are one of the primary imaging modalities for lung cancer diagnosis. However, manual CT scan analysis is time-consuming and prone to errors/not accurate. Considering these shortcomings, computational methods especially machine learning and deep learning algorithms are leveraged as an alternative to accelerate the accurate detection of CT scans as cancerous, and non-cancerous. In the present article, we proposed a novel transfer learning-based predictor called, Lung-EffNet for lung cancer classification. Lung-EffNet is built based on the architecture of EfficientNet and further modified by adding top layers in the classification head of the model. Lung-EffNet is evaluated by utilizing five variants of EfficientNet i.e., B0–B4. The experiments are conducted on the benchmark dataset “IQ-OTH/NCCD” for lung cancer patients grouped as benign, malignant, or normal based on the presence or absence of lung cancer. The class imbalance issue was handled through multiple data augmentation methods to overcome the biases. The developed model Lung-EffNet attained 99.10% of accuracy and a score of 0.97 to 0.99 of ROC on the test set. We compared the efficacy of the proposed fine-tuned pre-trained EfficientNet with other pre-trained CNN architectures. The predicted outcomes demonstrate that EfficientNetB1 based Lung-EffNet outperforms other CNNs in terms of both accuracy and efficiency. Moreover, it is faster and requires fewer parameters to train than other CNN based models, making it a good choice for large-scale deployment in clinical settings and a promising tool for automated lung cancer diagnosis from CT scan images.},
  archive      = {J_EAAI},
  author       = {Rehan Raza and Fatima Zulfiqar and Muhammad Owais Khan and Muhammad Arif and Atif Alvi and Muhammad Aksam Iftikhar and Tanvir Alam},
  doi          = {10.1016/j.engappai.2023.106902},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106902},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lung-EffNet: Lung cancer classification using EfficientNet from CT-scan images},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time semantic segmentation in traffic scene using cross
stage partial-based encoder–decoder network. <em>EAAI</em>,
<em>126</em>, 106901. (<a
href="https://doi.org/10.1016/j.engappai.2023.106901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time semantic segmentation in traffic scenes plays an essential part in autonomous driving. The encoder–decoder-based network architecture can well combine the context information and detailed information required for the semantic segmentation task. Achieving a good balance between inference speed and accuracy is a crucial challenge, as considerable real-time semantic segmentation models process information in real-time at the expense of accuracy degradation. This paper presents an encoder–decoder network model based on Cross Stage Partial (CSP) block for real-time semantic segmentation in traffic scenes. Integrating the CSP block can not only lessen the computational overhead but also enhance the feature extraction ability of the network. In addition, we append the Fast Spatial Pyramid Pooling module to the backbone of the network, which can aggregate global information at a low computational cost. On NVIDIA RTX 3090, the middle model of our method can achieve a mean intersection over union (mIOU) of 80.8% at 64.3 frames per second (FPS) on the Cityscapes test set and an mIOU of 81.3% at 105.3 FPS on the CamVid Test Set. The large model of our method can realize an mIOU of 81.5% at 48.4 FPS on the test set of Cityscapes. Our source code is available at https://github.com/zhouliguo/cspsg .},
  archive      = {J_EAAI},
  author       = {Liguo Zhou and Guang Chen and Lian Liu and Ruining Wang and Alois Knoll},
  doi          = {10.1016/j.engappai.2023.106901},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106901},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time semantic segmentation in traffic scene using cross stage partial-based encoder–decoder network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of improved direct torque control based on a five
level torque controller and a new sugeno-takagi fuzzy super-twisting
controller applied to an induction machine. <em>EAAI</em>, <em>126</em>,
106900. (<a
href="https://doi.org/10.1016/j.engappai.2023.106900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the design and Hardware In Loop (HIL) verification of a novel intelligent Super-twisting Sliding Mode Speed Controller (STSMSC) based on a Sugeno-Takagi Fuzzy Logic System (STFLS) for an induction motor controlled by an improved Modified Direct Torque Control (MDTC) approach. Indeed, Conventional Super-twisting Sliding Mode Speed Controller (CSTSMSC) is chosen as an alternative solution for attenuating the chattering phenomenon brought on by the discontinuous control law of the First Order Sliding Mode Speed Control (FOSMSC) and maintaining its advantages like simplicity, robustness and accuracy. Moreover, the STSMSC is a type of a second order sliding mode control technique that needs only the information about the sliding surface, not its time derivative. However, the choice parameters of the CSTSMSC existing in the control law effects the tracking accuracy, the overshoot and the amplitude of the chattering. Therefore, an STSMSC based on an STFLS (STFLS-STSMSC) is proposed for online tuning of these parameters in transient and steady state operations. In fact, the STFLS is considered as an intelligent supervisor to adjust these parameter values according to the system state, which consequently provides excellent performance consisting in a higher robustness rate under disturbances and uncertainties, tracking with excellent accuracy and reduced chattering in steady state and transient operations. Numerous simulation and HIL co-simulation results are presented to demonstrate the effectiveness of the suggested STFLS-STSMSC based MDTC implemented on a Xilinx FPGA Zynq 7000 SoC ZC702.},
  archive      = {J_EAAI},
  author       = {Saber Krim and Mohamed Faouzi Mimouni},
  doi          = {10.1016/j.engappai.2023.106900},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106900},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design of improved direct torque control based on a five level torque controller and a new sugeno-takagi fuzzy super-twisting controller applied to an induction machine},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Outcome-oriented prescriptive process monitoring based on
temporal logic patterns. <em>EAAI</em>, <em>126</em>, 106899. (<a
href="https://doi.org/10.1016/j.engappai.2023.106899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Prescriptive Process Monitoring systems aim at recommending, during the execution of a business process, interventions that, if followed, prevent poor performance of the process. Such interventions have to be (i) reliable: they have to guarantee the achievement of the desired outcome or performance and (ii) flexible: they cannot overturn the normal process execution. Problem: Most of the Prescriptive Process Monitoring solutions perform well in terms of recommendation reliability but provide the users with recommendations expressed in terms of specific activities that have to be executed without caring about their feasibility. Method: We propose a new Outcome-Oriented Prescriptive Process Monitoring system recommending temporal relations among activities that have to be guaranteed during the process execution. The proposed system is based on a Machine Learning model that learns the correlations between temporal relations among activities and the (positive) outcome of the process. Then, given the prefix of an ongoing process, the model is queried to return the most promising recommendations. Contribution: The main contribution is that the proposed system softens the mandatory execution of an activity at a given point in time, thus leaving more freedom to the user in deciding the interventions to put in place. This is achieved by providing recommendations that are expressed as Linear Temporal Logic formulas over activities. Results: The proposed system has been widely assessed using a pool of 22 real-life datasets. The results demonstrate the reliability of the provided recommendations by achieving an F1 score higher than 90% on 18 datasets out of 22.},
  archive      = {J_EAAI},
  author       = {Ivan Donadello and Chiara Di Francescomarino and Fabrizio Maria Maggi and Francesco Ricci and Aladdin Shikhizada},
  doi          = {10.1016/j.engappai.2023.106899},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106899},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Outcome-oriented prescriptive process monitoring based on temporal logic patterns},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimized inversion method for thermal parameters of
concrete dam under the insulated condition. <em>EAAI</em>, <em>126</em>,
106898. (<a
href="https://doi.org/10.1016/j.engappai.2023.106898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to study how thermal characteristics of concrete dam change over time, especially in cold regions, in order to guarantee long-term safety of the engineering projects. In this manuscript, an inverse analysis method by coupling the numerical simulation model and dam safety monitoring data, is proposed to solve the problem that true thermal parameters of the whole structure cannot be obtained by laboratory experiments or field tests of single points. Moreover, a numerical equivalence method of the dam and its insulation layer is introduced, in order to overcome the problem that the thickness of the insulation layer is much smaller than that of the concrete dam, resulting in low accuracy of the simulation model. Thirdly, the particle swarm optimization is introduced, in order to solve the ill-posed problems occurring during the solution process of multi-parameter inverse analysis. Considering the problem that the original particle swarm algorithm is easy to fall into local optimum and stuck edge, this study improves particles velocity and inertia weights. Benchmark function tests are applied to show the performance compared to several typical optimized algorithms. Numerical simulation and engineering verification are used to demonstrate the rationality and feasibility of the proposed method. The cases show that the residual box diagram of two typical measuring points calculated by inversion value is smaller than the median line and mean point calculated by design value. Moreover, the change law of the temperature field of the finite element calculation using the inversion values is closer to the actual measured value than that of the design value. The results indicate that the multi-parameter inverse method is feasible in insulated dam engineering. In addition, the result of the improved PSO optimization converges faster and has a higher fitness value than that of the original algorithm. It suggests that the improved PSO algorithm for thermal parameters inversion has fitting accuracy and rationality for insulated concrete dams in cold regions.},
  archive      = {J_EAAI},
  author       = {Chen Bo and Wang Qingyi and Chen Weinan and Gu Hao},
  doi          = {10.1016/j.engappai.2023.106898},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106898},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimized inversion method for thermal parameters of concrete dam under the insulated condition},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hesitant fuzzy time series forecasting model of higher order
based on one and two-factor aggregate logical relationship.
<em>EAAI</em>, <em>126</em>, 106897. (<a
href="https://doi.org/10.1016/j.engappai.2023.106897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy time series forecasting is a methodology that incorporates fuzzy logic to handle uncertainty in time series data. It allows for more flexible and accurate predictions by considering the linguistic terms and membership functions associated with each data point, enabling a better representation of complex patterns and trends within the time series. A time series forecasting model examines the relationships between present and past observations for future measurement. This article proposes a hesitant fuzzy time series forecasting (FTSF) technique for higher order based on one and two-factor aggregate fuzzy relationships. The proposed method presents a new approach to partitioning intervals into an unequal and equal length. The hesitant fuzzy sets are defined for each observation, and fuzzification is based on their maximum score function. Further, aggregated triangular fuzzy numbers are defined using an aggregation operator corresponding to the fuzzified datum. In order to enhance forecasting performance, this work also introduces a novel defuzzification rule based on aggregated fuzzy logical relationship groups (AFLRGs) for higher order one and two-factor fuzzy time series. The implementation of the proposed approach is verified on two data sets to the forecasting of enrollment data and TAIFEX and TAIEX stock index data sets, and the forecasting error is tested in term of different statistical parameters. Thus, the model validates the effectiveness of the proposed method with higher forecasting accuracy rate in the environment hesitant fuzzy information.},
  archive      = {J_EAAI},
  author       = {Anil Kumar Nishad and Gunjan Aggarwal and Abhishekh},
  doi          = {10.1016/j.engappai.2023.106897},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106897},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hesitant fuzzy time series forecasting model of higher order based on one and two-factor aggregate logical relationship},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph attention-based u-net conditional generative
adversarial networks for the identification of synchronous generation
unit parameters. <em>EAAI</em>, <em>126</em>, 106896. (<a
href="https://doi.org/10.1016/j.engappai.2023.106896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After generation units are connected to the power grid, electrical parameters such as generation unit output voltage, current and power need to be monitored for the safe and reliable function of grids. Obtaining accurate parameters of synchronous generation units (SGUs) is normally the basic requirement for grid stability analysis and control. To improve the accuracy of identifying SGU parameters, this study proposes graph attention-based U-Net conditional generative adversarial networks (GAUCGANs) for the identification of SGU parameters. The mapping between real and generated samples is modeled by applying conditional generative adversarial networks (CGANs). The CGANs of the GAUCGANs proposed in this study consist of U-Nets-based generators, fully convolutional networks-based discriminators, and graph attention networks (GATs). The U-Nets of the GAUCGANs enhance the ability of generators to generate generative samples that are infinitely close to real samples. The U-Nets-based generators of the GAUCGANs are responsible for generating the SGU parameters; the fully convolutional networks-based discriminators of the GAUCGANs determine whether data is from the generator or the real data. In addition, the classification loss and sample labels are derived from the GATs. The addition of GATs will further enhance the ability of the generators to remove adversarial disturbances. In this study, the proposed GAUCGAN for parameter identification is compared with the traditional parameter identification algorithms. The comparison algorithms are applied to the Simulink standard SGU, hydroelectric unit No. 6 of the waterfall gorge hydropower plant, and the generation unit at the 18th bus of the IEEE 36-bus power system. The numerical simulation results from the GAUCGANs verify that the GAUCGAN can more accurately identify SGU parameters than the traditional parameter identification algorithms. The GAUCGANs improve the accuracy by at least 61.60% on average over the other methods by comparing the RMSE, MAE, MAPE, and SMAPE under three cases comprehensively.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Wanqiong Zhao},
  doi          = {10.1016/j.engappai.2023.106896},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106896},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph attention-based U-net conditional generative adversarial networks for the identification of synchronous generation unit parameters},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-perspective conformance checking of uncertain process
traces: An SMT-based approach. <em>EAAI</em>, <em>126</em>, 106895. (<a
href="https://doi.org/10.1016/j.engappai.2023.106895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformance checking, one of the central tasks in process mining, compares the expected behavior described by a reference process model to the actual behavior recorded in an event log, with the goal of detecting deviations. Traditionally, it is assumed that the log provides a faithful and complete digital footprint of reality. However, assuming perfect logs is often unrealistic: real-life logs typically suffer from data quality issues, exposing uncertainty in their events, timestamps, and data attributes. We attack this problem by introducing a comprehensive framework for multi-perspective conformance checking dealing with uncertainty along three perspectives: control-flow, time, and data. From the modeling point of view, we consider process models formalized as Petri nets operating over data variables, and event logs presenting uncertainty at the event- and attribute-level. We cast conformance checking as an alignment problem, extending the traditional notions of alignment and cost function to deal with uncertainty along the three aforementioned perspectives. From the operational point of view, we show how (optimal) alignments can be computed through well-established automated reasoning techniques from Satisfiability Modulo Theories (SMT). Specifically, we show how previous results on data-aware SMT-based conformance checking can be lifted to this more sophisticated setting, obtaining a flexible framework that can seamlessly handle different variants of the problem. We formally prove correctness of our approach and implement it in the conformance checker cocomot . Finally, we perform a thorough experimental evaluation on synthetic and real-life logs, demonstrating the overall promising performance of our framework.},
  archive      = {J_EAAI},
  author       = {Paolo Felli and Alessandro Gianola and Marco Montali and Andrey Rivkin and Sarah Winkler},
  doi          = {10.1016/j.engappai.2023.106895},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106895},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-perspective conformance checking of uncertain process traces: An SMT-based approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed graph neural networks accelerating
microneedle simulations towards novelty of micro-nano scale materials
discovery. <em>EAAI</em>, <em>126</em>, 106894. (<a
href="https://doi.org/10.1016/j.engappai.2023.106894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To commercialize the micro-nano needle as a drug delivery or biosensing platform, it is essential to validate the effectiveness and reliability of the piercing process for each needle material composition. However, proper microneedle material selection and fabrication requires sophisticated and costly semiconductor technology. This work aims to accelerate the material selection process of microneedles, focusing on polymeric materials due to their biocompatibility and flexibility. In this study, simulations of microneedles with various materials are used to generate training and testing data for a physics-informed machine learning model to predict von Mises stress distribution on microneedles of new materials. The training dataset is comprised of results from fifteen different materials. Different machine learning models are used, such as traditional tree-based, neural network, point cloud network, and graph-based models. Random-index selection is utilized to reduce the required number of data points by an order of magnitude. The graph attention network model is the best-performing model for predicting the von Mises stress of microneedles, with a mean square error of 8 . 3 × 1 0 − 5 MPa . The resulting model only requires 7 ms to evaluate a new microneedle material, significantly faster than practical fabrication in a laboratory. The models also successfully handle data with a decimal scale obtained from microstructure simulations and predict physical behavior such as stress curves.},
  archive      = {J_EAAI},
  author       = {Romrawin Chumpu and Chun-Lin Chu and Tanyakarn Treeratanaphitak and Sanparith Marukatat and Shu-Han Hsu},
  doi          = {10.1016/j.engappai.2023.106894},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106894},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed graph neural networks accelerating microneedle simulations towards novelty of micro-nano scale materials discovery},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combustion state identification of MSWI processes using
ViT-IDFC. <em>EAAI</em>, <em>126</em>, 106893. (<a
href="https://doi.org/10.1016/j.engappai.2023.106893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Municipal solid waste (MSW) incineration processes often experience fluctuations in the physical and chemical properties of waste materials, leading to unstable combustion and increased flue-gas emissions. This hinders the development of greener waste-treatment methods. Currently, experts rely on their experience in observing flames during field operations to determine the combustion state. However, this process is energy consuming, subjective, and not optimal for controlling MSW incineration (MSWI). To address this issue, this study proposes a dataset of MSWI flame images for identifying combustion states using a vision-transformer-improved deep forest classification (ViT-IDFC) algorithm. The ViT-IDFC algorithm extracts multilayer visual transformation features from flame images based on a pre-trained ViT model’s transformer coding layer. The experience of domain experts was used to select the depth features. The algorithm then constructed an IDFC model by combining the selected ViT visual transformation features and the original flame image as inputs for the cascade forest. The proposed method was evaluated using a dataset of flame images, and the results demonstrated accuracies of 98.15% and 96.43% in identifying the left and right grate flame images, respectively, which are acceptable in the industry.},
  archive      = {J_EAAI},
  author       = {Xiaotong Pan and Jian Tang and Heng Xia and Wen Yu and Junfei Qiao},
  doi          = {10.1016/j.engappai.2023.106893},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106893},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combustion state identification of MSWI processes using ViT-IDFC},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive error bounded piecewise linear approximation for
time-series representation. <em>EAAI</em>, <em>126</em>, 106892. (<a
href="https://doi.org/10.1016/j.engappai.2023.106892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error-bounded piecewise linear approximation ( l ∞ -PLA) has been proven effective in addressing challenges in data management and analytics. It works by approximating the original time series with linear segments such that the approximation error on each data point does not exceed a pre-defined threshold. To achieve this goal, most prior works on l ∞ -PLA use a fixed error threshold during the entire approximation process, assuming a stable time series. However, in many real-world applications, the distribution of values on the time series undergoes substantial changes in different temporal stages. This introduces a need to adaptively tune the error threshold based on the properties of the time series while considering the trade-off between representation error and storage resources. In this work, we propose a general framework for constructing l ∞ -PLA with adaptive error bounds (AEPLA). It works by dividing the original time series into a set of intervals and assigns adaptive error bounds to these sub-sequences based on their fluctuation levels. Next, these sub-sequences are approximated using a user-defined l ∞ -PLA method. We implement this framework by employing three different types of l ∞ -PLA methods and evaluate the performance of our approach on an extensive set of real-world time-series datasets from industrial and scientific domains. Our experiments show that constructing l ∞ -PLA using the AEPLA framework can provide better a trade-off between representation error and storage resources and achieves lower time and space costs than applying the original l ∞ -PLA methods.},
  archive      = {J_EAAI},
  author       = {Zhou Zhou and Mitra Baratchi and Gangquan Si and Holger H. Hoos and Gang Huang},
  doi          = {10.1016/j.engappai.2023.106892},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106892},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive error bounded piecewise linear approximation for time-series representation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). FAST-AlertNet: Early warning fire-induced collapse of
large-span steel truss structures. <em>EAAI</em>, <em>126</em>, 106891.
(<a href="https://doi.org/10.1016/j.engappai.2023.106891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-span steel trusses are often adopted as roof structures of public and industrial buildings. Besides significant property loss, the unexpected and sudden collapse of large-span steel trusses caused by fires also threatens the lives of firefighters and trapped people in fires. To prevent casualties to the greatest extent, real-time evaluation of the structural collapse state of the building at fire rescue scenes is critical. This paper presents a novel framework for early warning the collapse of large-span steel truss structures in fire based on proposing the FAST-AlertNet. The FAST-AlertNet can easily obtain real-time displacements based on easily-measured rotations and temperatures of the steel trusses during fire synchronously. Rotations and temperatures, which reflect uncertain structural parameters of steel trusses and fire scenarios, serve as inputs, while displacements are the outputs. A dynamic weighted loss function is employed in the FAST-AlertNet, yielding better performance reflecting the early-warning points than traditional loss functions. To address the high computational cost of obtaining real spatiotemporal patterns of temperature development inside the building in real fire scenes, transfer learning is utilized to transfer the interlinkage among displacements, temperatures, and rotations established by simplified parametric temperature curves, resulting in improved prediction accuracy in reality. A case study demonstrates the availability of the proposed framework, with the predicted remaining pre-collapse time of a typical steel truss satisfactorily matching the real value. Notably, the proposed framework provides a new methodology for early warning building collapse without requiring the difficultly-measured displacements in fire, which advances its feasibility for practical application.},
  archive      = {J_EAAI},
  author       = {Jinyu Li and Guo-Qiang Li and Shaojun Zhu},
  doi          = {10.1016/j.engappai.2023.106891},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106891},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FAST-AlertNet: Early warning fire-induced collapse of large-span steel truss structures},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LCW-net: Low-light-image-based crop and weed segmentation
network using attention module in two decoders. <em>EAAI</em>,
<em>126</em>, 106890. (<a
href="https://doi.org/10.1016/j.engappai.2023.106890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop segmentation using cameras is commonly used in large agricultural areas, but the time and duration of crop harvesting varies in large farms. Considering this situation, there is a need for low-light image-based segmentation of crop and weed images for late-time harvesting, but no prior research has considered this. As a first study on this topic, we propose a low-light image-based crop and weed segmentation network (LCW-Net) that uses an attention module in two decoders to perform only one step without restoration of low-light images. We also design a loss function to accurately segment regions of objects, crops, and weeds in low-light images to avoid training overfitting and balance the learning task for object, crop, and weed segmentation. There are no existing low-light public databases, and it is difficult to obtain ground truth segmentation information for self-collected database in low-light environments. Therefore, we experimented with converting two public databases, the crop and weed field image dataset (CWFID) and BoniRob dataset, into low-light datasets. The experimental results showed that the mean intersection of unions ( mIoUs ) of segmentation for crops and weeds were 0.8718 and 0.8693 for the BoniRob dataset, respectively, and 0.8337 and 0.8221 for the CWFID dataset, respectively, indicating that LCW-Net outperforms the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Yu Hwan Kim and Sung Jae Lee and Chaeyeong Yun and Su Jin Im and Kang Ryoung Park},
  doi          = {10.1016/j.engappai.2023.106890},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106890},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LCW-net: Low-light-image-based crop and weed segmentation network using attention module in two decoders},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial displacement tracking of vibrating structure using
multiple feature points assisted binocular visual reconstruction.
<em>EAAI</em>, <em>126</em>, 106889. (<a
href="https://doi.org/10.1016/j.engappai.2023.106889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current vision-based displacement measurement methods have limitations of requiring manual target and parameter adjustment, along with significant user involvement to achieve the desired results. This paper proposes an advanced and comprehensive vision system based on ZED cameras for full-field three-dimensional (3D) vibration displacement measurement of civil structures. Compared to existing binocular systems consisting of multiple monoculars, ZED binoculars offer greater flexibility on instrument setup and data acquisition. A novel keypoint detection and matching algorithm based on deep learning is used to achieve target-free measurement, which is capable of capturing feature points with high precision. The performance of the proposed vision-based approach is evaluated through experimental studies on a six-story scaled frame structure. Statistical analysis of the comparative results in sinusoidal cases demonstrates that the displacement responses obtained from the proposed vision-based approach show consistent results in compliance with displacement sensor measurements. System identification of the target structure is achieved through a seismic case and the error analysis is also concluded in detail.},
  archive      = {J_EAAI},
  author       = {Tao Huang and Cheng Yuan and Peizhen Li and Shiran Xu and Qingzhao Kong},
  doi          = {10.1016/j.engappai.2023.106889},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106889},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatial displacement tracking of vibrating structure using multiple feature points assisted binocular visual reconstruction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial neural network chaotic PRNG and simple encryption
on FPGA. <em>EAAI</em>, <em>126</em>, 106888. (<a
href="https://doi.org/10.1016/j.engappai.2023.106888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Neural Networks (ANNs) are remarkably able to fit complex functions, making them useful in various applications and systems. This paper uses ANN to fit the Pehlivan–Uyaroglu Chaotic System (PUCS) to produce an Artificial Neural Network Chaotic Pseudo-Random Number Generator (ANNC-PRNG). The proposed PRNG imitates the PUCS chaotic system’s properties and attractor shape. The proposed ANNC-PRNG is implemented in a simple image encryption system on the Xilinx Kintex-7 Genesys 2 Field Programmable Gate Array (FPGA) board. Hardware realization of an ANN trained on chaotic time series has not been presented before. The proposed ANN can be used for different numerical methods or chaotic systems, including fractional-order systems while keeping the same resources despite the methods’ complexity or chaotic systems’ complexity. Extensive testing for the ANNC-PRNG was done to prove the randomness of the produced outputs. The proposed ANNC-PRNG and the encryption system passed various well-established security and statistical tests and produced good results compared to recent similar research. The encryption system is robust against different attacks. The proposed hardware architecture is fast as it reaches a maximum frequency of 12.553 MHz throughput of 301 Mbit/s.},
  archive      = {J_EAAI},
  author       = {Bishoy K. Sharobim and Mohammed H. Yacoub and Wafaa S. Sayed and Ahmed G. Radwan and Lobna A. Said},
  doi          = {10.1016/j.engappai.2023.106888},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106888},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural network chaotic PRNG and simple encryption on FPGA},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable attention ResNet18-based model for asthma
detection using stethoscope lung sounds. <em>EAAI</em>, <em>126</em>,
106887. (<a
href="https://doi.org/10.1016/j.engappai.2023.106887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an accurate asthma detection model using an attention network and machine learning technique. The objective of this study is the automated detection of asthma using an attention network. The lung sounds from 203 subjects involving 767 segments from asthma and 722 segments from healthy subjects were collected using a stethoscope. A novel Attention ResNet18-based deep feature engineering model has been developed in five phases: preprocessing, training the Attention ResNet18 network, extracting deep features, iterative feature selection, and classification using k-nearest neighbor (kNN) or support vector machine (SVM). Gradient-weighted class activation mapping (Grad-CAM) was used to generate heat maps, effectively distinguishing asthma lung sounds from those of normal individuals. By using Grad-CAM, explainable results have been presented. Our proposed model obtained an accuracy of 99.73% using SVM with 10-fold cross-validation, surpassing the performance obtained by previous models. Hence, the developed model has the potential to detect asthma in the real-world scenario. scenario to detect.},
  archive      = {J_EAAI},
  author       = {Ihsan Topaloglu and Prabal Datta Barua and Arif Metehan Yildiz and Tugce Keles and Sengul Dogan and Mehmet Baygin and Huseyin Fatih Gul and Turker Tuncer and Ru-San Tan and U. Rajendra Acharya},
  doi          = {10.1016/j.engappai.2023.106887},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106887},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable attention ResNet18-based model for asthma detection using stethoscope lung sounds},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy management in residential communities with shared
storage based on multi-agent systems: Application to smart grids.
<em>EAAI</em>, <em>126</em>, 106886. (<a
href="https://doi.org/10.1016/j.engappai.2023.106886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution towards smart grids (SGs) is mainly characterized by the integration of renewable energy sources (RESs) throughout the grid. The intermittent nature of these sources necessitated the installation of energy storage systems (ESSs) to improve the efficiency and reliability in the power system. Moreover, the ongoing high price of batteries has encouraged the installation of shared ESSs in residential communities. However, managing the shared ESS and the energy flows in the community is considered a key challenge. In order to handle this issue, we introduce a novel energy management system (EMS), namely E nergy M anagement I n residential CO mmunities with shared storage based on multi-agent systems (EMICO). It finds the optimal energy trading operations between households, as well as the operations of the shared ESS that minimize the total energy losses. We first propose a new cluster-based architecture for the residential community in which we integrate Internet of Energy (IoE) devices to manage energy flows and find the shortest path to transfer energy with minimal loss from a cluster to the other. Then, we model our energy management problem as a constrained optimization problem and we use Lagrange multiplier method to solve it in a centralized way. In order to preserve households’ privacy, we propose a decentralized approach based on multi-agent systems (MASs) to solve our problem. We test our approach on real data traces obtained from a set of households located in the United Kingdom. Numerical results show that EMICO outperforms a literature approach in terms of energy losses (up to 35.66% of reduction in energy losses), electricity bill (up to 21.21% cheaper), number of exchanged messages (up to 83.81% less messages exchanged), and length of required cables (up to 95.03% less cables required).},
  archive      = {J_EAAI},
  author       = {Bashar Chreim and Moez Esseghir and Leila Merghem-Boulahia},
  doi          = {10.1016/j.engappai.2023.106886},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106886},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy management in residential communities with shared storage based on multi-agent systems: Application to smart grids},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CGINet: Cross-modality grade interaction network for RGB-t
crowd counting. <em>EAAI</em>, <em>126</em>, 106885. (<a
href="https://doi.org/10.1016/j.engappai.2023.106885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting is a fundamental and challenging task that requires rich information to generate a pixel-level crowd density map. Additionally, the development of thermal sensing and its applicability to computer vision has enabled the use of thermal information for crowd counting. Considering the complementary characteristics of RGB (red–green–blue) and thermal images in different feature encoding stages, we propose a cross-modality grade interaction network (CGINet) for RGB-T (RGB and thermal) crowd counting. We introduce an RGB cooperative enhancement module for thermal information to correctly extract low-level features from scenes containing objects with different scales. As RGB information is sensitive to lighting and occlusion while extracting high-level features, we propose a thermal information supplementary module to increase the RGB feature robustness. In addition, a novel multilayer decoding module fully integrates features at different levels, exploits the features of different layers, and predicts the crowd density map. Results from comprehensive experiments on the RGBT-CC benchmark demonstrate the effectiveness of the proposed CGINet for RGB-T crowd counting. In addition, CGINet achieves excellent results on the ShanghaiTechRGB dataset containing paired RGB images and depth maps. The experimental results highlight the advanced architecture and generalization ability of CGINet for multimodality crowd counting.},
  archive      = {J_EAAI},
  author       = {Yi Pan and Wujie Zhou and Xiaohong Qian and Shanshan Mao and Rongwang Yang and Lu Yu},
  doi          = {10.1016/j.engappai.2023.106885},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106885},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CGINet: Cross-modality grade interaction network for RGB-T crowd counting},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A strategy based on wave swarm for the formation task
inspired by the traveling salesman problem. <em>EAAI</em>, <em>126</em>,
106884. (<a
href="https://doi.org/10.1016/j.engappai.2023.106884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-robots can perform complex tasks such as exploration, foraging, and formation. Efficient communication between robots can contribute to the accomplishment of collective tasks through efficient message exchange. This paper proposes a strategy based on the message’s propagation technique, Wave Swarm, for the formation task inspired by the Traveling Salesman Problem. The Wave Swarm communication approach uses the concept of wave propagation for message exchange between neighbors, establishing a Father and Son relationship between robots. However, different pairs of Father and Son robots can impact the simulation time, the average distance traveled by each robot, and the number of messages exchanged during the formation task. Thus, given a random distribution of robots into a swarm, we model the problem of assigning one position and route for each robot to achieve its place in the formation as a Traveling Salesman Problem. The routes resulting from the TSP solution establish a new parental relationship between the robots in the swarm. We performed preliminary experiments to define the technique used in the TSP resolution. We tested reinforcement learning and the genetic algorithm using the TSPLIB95 library. Thus, we develop a strategy for formation tasks based on Wave Swarm and TSP solved with reinforcement learning. We adopted the leader–follower approach in an unknown environment to validate the proposal. The results show the behavior of different sizes of robot groups for various desired shapes. Experiments with the robot simulator CoppeliaSim (V-REP) validate the proposed strategy and highlight its efficiency and robustness while running the formation task.},
  archive      = {J_EAAI},
  author       = {Rubisson Duarte Lamperti and Lucia Valéria Ramos de Arruda},
  doi          = {10.1016/j.engappai.2023.106884},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106884},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A strategy based on wave swarm for the formation task inspired by the traveling salesman problem},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cloud-assisted collaborative estimation for next-generation
automobile sensing. <em>EAAI</em>, <em>126</em>, 106883. (<a
href="https://doi.org/10.1016/j.engappai.2023.106883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a unique cloud-assisted collaborative estimating system for on-road sensors like potholes, ice, and road profile to develop next-generation automobiles that are safer, more efficient, and more comfortable. Conventional road information finding methods for a single vehicle are prone to model uncertainty and measurement mistakes. The proposed system iteratively improves estimate performance using many heterogeneous vehicles. Each vehicle merges its onboard measurements with pseudomeasurements from previous participating cars and transmits the resulting local onboard estimate back to the cloud for updating. The system uses a Noisy Input Gaussian Process (NIGP) approach to manage uncertain readings. The study includes the road segment length of 40 m, 2 sensors for sprung mass and suspension displacements, time span of 1.5 s, a sampling time of 0.01 s, and 151 estimation points per Kalman Filter (KF). Additionally, the Root Mean Squared Error (RMSE) was calculated for onboard estimation performance, and training was conducted using data from one vehicle and 10 vehicles for the cloud-based NIGP performance evaluation. Using pseudo-measurements from preceding vehicles significantly improves performance. Comparing the standard GP regression, the NIGP regression and a benchmark based on KF averaging estimations. The NIGP provides better variance and reduces uncertainty. Moreover, the pseudo-measurement strategy iteratively improves onboard performance when using NIGP pseudo-measurements. A detailed experimental plan is described to measure the performance of the proposed collaborative estimating method while considering fleet heterogeneity, measurement noise, and model uncertainty.},
  archive      = {J_EAAI},
  author       = {Ali Louati},
  doi          = {10.1016/j.engappai.2023.106883},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106883},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cloud-assisted collaborative estimation for next-generation automobile sensing},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse dynamical features generation, application to
parkinson’s disease diagnosis. <em>EAAI</em>, <em>126</em>, 106882. (<a
href="https://doi.org/10.1016/j.engappai.2023.106882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the diagnosis of Parkinson’s Disease (PD) based on electroencephalogram (EEG) signals. A novel approach inspired by the functioning of the brain is proposed, which uses the dynamics, frequency, and temporal content of EEGs to extract new discriminant features of the disease. The generated sparse dynamic features (SDFs) allow, through a transformation, to change the point of view on the data giving access to more informative features that are more faithful to the concept of EEG generation. Nevertheless, the method remains generic and can be applied to any signal but for this application it was evaluated on a publicly available dataset containing EEG signals recorded during a 3-oddball auditory task involving N = 50 subjects, of whom 25 suffer from PD. Given the adequate perspective on the data, it comes out that by using only two extracted features from the generated SDFs the healthy and unhealthy subjects are separated using a linear classifier. The classification yields an accuracy of 90.0% ( p &lt; 0 . 03 ) using a single channel. By aggregating the information from three channels and making them vote, an accuracy of 94%, a sensitivity of 96% and a specificity of 92% is obtained. The evaluation was carried out using a nested Leave-One-Out cross-validation procedure, thus preventing data leakage problems and giving a less biased evaluation. Several tests were carried out to assess the validity and robustness of our approach.},
  archive      = {J_EAAI},
  author       = {Houssem Meghnoudj and Bogdan Robu and Mazen Alamir},
  doi          = {10.1016/j.engappai.2023.106882},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106882},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse dynamical features generation, application to parkinson’s disease diagnosis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Socio-political evaluation of renewable energy resources
under uncertain environment. <em>EAAI</em>, <em>126</em>, 106881. (<a
href="https://doi.org/10.1016/j.engappai.2023.106881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Countries are developing green transition policies to reduce their dependency on conventional resources and to eliminate environmental concerns while meeting increasing energy demand. Renewable energy, thus, has a crucial effect on accomplishing these policies. To ensure a rapid spread of renewable energy and develop resilient renewable energy policies concerning the evaluation of renewable energy resources, socio-political factors should be considered. However, evaluating renewable energy technologies regarding the socio-political aspect is clearly more difficult and uncertain than a study focused only on quantifiable objectives, but it is critical since real projects are affected by such aspects. Multi-criteria decision-making (MCDM) techniques are best for addressing such issues with conflicting objectives. In this study, an integrated AHP-TOPSIS method with Pythagorean fuzzy sets (PFSs) was used to create the socio-political index for evaluating renewable energy hybrid technologies and Battery Energy Storage Systems (BESSs) in Turkey. The results showed that while solar energy has the highest socio-political index, Run of River with BESSs alternative ranks as the lowest.},
  archive      = {J_EAAI},
  author       = {Yağmur Torul Yürek and Bahar Özyörük and Evrencan Özcan and Merve Bulut},
  doi          = {10.1016/j.engappai.2023.106881},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106881},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Socio-political evaluation of renewable energy resources under uncertain environment},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023f). Advanced crack detection and quantification strategy based
on CLAHE enhanced DeepLabv3+. <em>EAAI</em>, <em>126</em>, 106880. (<a
href="https://doi.org/10.1016/j.engappai.2023.106880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning method has been developed for pavement crack detection. The improvement in detection accuracy is limited by the image quantity and detection algorithm in engineering practice. This study proposes an innovative method to efficiently identify pavement cracks by moderating the training process. The dataset was established after a sensitivity analysis by considering the shooting height and image volume. The DeepLabv3+ model was used to train the originally collected images, and the CLAHE-augmented images were used for prediction. The result showed that the detection accuracy was enhanced by an average of 1.51%. This new method was validated in two scenarios, leading to average accuracies of 95.07% and 96.61% in detecting linear and alligator cracks, respectively. This detection process avoids repeatedly investing new images in model training, accelerating crack recognition by augmenting the images to be detected. The proposed method fulfills the requirements of engineering practice, based on which a road maintenance strategy is proposed.},
  archive      = {J_EAAI},
  author       = {Xuefei Wang and Tingkai Wang and Jiale Li},
  doi          = {10.1016/j.engappai.2023.106880},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106880},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advanced crack detection and quantification strategy based on CLAHE enhanced DeepLabv3+},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computational intelligence-based approaches to
fault-tolerant and self-healing control and maintenance of dynamic
systems. <em>EAAI</em>, <em>126</em>, 106879. (<a
href="https://doi.org/10.1016/j.engappai.2023.106879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Marcin Witczak and Vicenc Puig and Silvio Simani},
  doi          = {10.1016/j.engappai.2023.106879},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106879},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Computational intelligence-based approaches to fault-tolerant and self-healing control and maintenance of dynamic systems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new heuristic algorithm based on multi-criteria resilience
assessment of human–robot​ collaboration disassembly for supporting spent
lithium-ion battery recycling. <em>EAAI</em>, <em>126</em>, 106878. (<a
href="https://doi.org/10.1016/j.engappai.2023.106878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recycling spent lithium-ion batteries is a significant way to achieve life-cycle management and a green circular economy, helping to achieve carbon neutrality. The form of battery pack disassembly has gradually moved away from manual manipulation to a human–robot collaborative process. However, there is no established methodology for assessing spent lithium-ion battery disassembly between the environmental benefits, technical feasibility, and economic viability of human–robot collaborative disassembly (HRCD). To ensure the efficiency and security of HRCD processes, this paper develops a resilience assessment model for HRCD using stability, redundancy, efficiency and adaptation metrics. The resilience assessment theory is used to obtain the internal relations among the resilience indicators of the system. In this work, we evaluate the resilience of HRCD for lithium-ion battery disassembly by integrating fuzzy Bayesian fusion with an analytical network process unfolding cloud. The 2017 Chevrolet Bolt driver demonstrated the feasibility and effectiveness of the proposed approach, which allows greater flexibility in complex tasks performed by humans and robots. In case study, the weights values of stability, redundancy, efficiency and adaptability are 0.340533, 0.161384, 0.203835 and 0.294248, respectively. IR2&amp;HO1 and IR3&amp;HO2 have an assessment value of 93 and 95, respectively, with eigenvalues of 1.28 and 1.23, which are level I. RI3&amp;HO1 and RI4&amp;HO3 belong to level IV, with an evaluation value of 38 and 45, respectively, and a characteristic value of 2.27 and 2.55, respectively. The integrated methodology proposed in this paper could be effectively used by disassembly management, to evaluate the HRCD disassembly scheme resilient strategies for better managing production.},
  archive      = {J_EAAI},
  author       = {Gang Yuan and Xiaojun Liu and Chaoyong Zhang and Duc Truong Pham and Zhiwu Li},
  doi          = {10.1016/j.engappai.2023.106878},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106878},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new heuristic algorithm based on multi-criteria resilience assessment of human–robot​ collaboration disassembly for supporting spent lithium-ion battery recycling},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fake news detection in dravidian languages using transfer
learning with adaptive finetuning. <em>EAAI</em>, <em>126</em>, 106877.
(<a href="https://doi.org/10.1016/j.engappai.2023.106877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news has become a major challenge for online platforms and society as a whole, with potentially harmful consequences for individuals and organizations. While there has been a lot of research on detecting fake news in high-resource languages, very little attention has been paid to low-resource languages. Due to a lack of corpora and annotated data, the classification of fake news in low-resource languages remains in its infancy. In this research, we present a novel transfer learning strategy for detecting fake news in Dravidian languages. We introduced a Dravidian_Fake a new dataset for fake news classification in Dravidian languages, and we created multilingual datasets by combining the English ISOT with the Dravidian_Fake datasets. We fine-tuned the mBERT and XLM-R pretrained transformer models with adaptive learning using English and Dravidian language fake news datasets. The classification model is evaluated using transfer learning, and the suggested model outperforms current approaches and provides a viable solution for sentence-level fake news classification in a resource-constrained environment. Experimental results on a Dravidian fake news dataset of low-resource languages demonstrate the efficacy of our approach in detecting fake news with an average accuracy of 93.31 percent in multilingual transfer learning.},
  archive      = {J_EAAI},
  author       = {Eduri Raja and Badal Soni and Samir Kumar Borgohain},
  doi          = {10.1016/j.engappai.2023.106877},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106877},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fake news detection in dravidian languages using transfer learning with adaptive finetuning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepCrackAT: An effective crack segmentation framework based
on learning multi-scale crack features. <em>EAAI</em>, <em>126</em>,
106876. (<a
href="https://doi.org/10.1016/j.engappai.2023.106876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of cracks is essential for assessing and maintaining building and road safety. However, the large appearance variations and the complex topological structures of cracks bring challenges to automatic crack detection. To alleviate the above challenges, we propose a deep multi-scale crack feature learning model called DeepCrackAT for crack segmentation, which is based on an encoder–decoder network with feature tokenization mechanism and attention mechanism. Specifically, we use hybrid dilated convolutions in the first three layers of the encoder–decoder to increase the network’s receptive field and capture more crack information. Then, we introduce a tokenized multilayer perceptron (Tok-MLP) in the last two layers of the encoder–decoder to tokenize and project high-dimensional crack features into low-dimensional space. This helps to reduce parameters and enhance the network’s ability of noise resistance. Next, we concatenate the features corresponding to the encoder–decoder layers and introduce the convolutional block attention module (CBAM) to enhance the network’s perception of the critical crack region. Finally, the five-layer features are fused to generate a binary segmentation map of the crack image. We conducted extensive experiments and ablation studies on two real-world crack datasets, and DeepCrackAT achieved 97.41% and 97.25% accuracy on these datasets, respectively. The experimental results show that the proposed method outperforms the current state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Qinghua Lin and Wei Li and Xiangpan Zheng and Haoyi Fan and Zuoyong Li},
  doi          = {10.1016/j.engappai.2023.106876},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106876},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DeepCrackAT: An effective crack segmentation framework based on learning multi-scale crack features},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SOF-RRT*: An improved path planning algorithm using spatial
offset sampling. <em>EAAI</em>, <em>126</em>, 106875. (<a
href="https://doi.org/10.1016/j.engappai.2023.106875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, sampling-based algorithms have demonstrated advantages in complex and high-dimensional environments. The RRT* algorithm, as the best variant of RRT, provides progressive optimality. It is shown that the RRT* algorithm has a slow convergence speed and a high initial path cost that result in the low efficiency of the algorithm, due to the low probability of adequate sampling caused by the invalid expansion of the tree and redundant sampling. To overcome these limitations, the SOF-RRT* algorithm is proposed to generate better initial solutions with higher stability and faster convergence. The SOF-RRT* algorithm is an improvement on the F-RRT* algorithm. The SOF-RRT* algorithm introduces a spatial probability weight sampling strategy into sampling, which makes the sampling probability higher in the area with a large feasible area. It reduces redundant sampling and increases the effective sampling rate. In the aspect of tree expansion, the strategy of target bias and obstacle tangential bias is introduced to improve the tree expansion efficiency, which makes tree expansion away from obstacles and bias to the target point. The proposed algorithm improves the expansion efficiency of sampling and tree. Finally, the initial path generation and convergence speed are simulated and compared, which proves that the algorithm has been greatly optimized in terms of the number of iterations, path quality, and convergence speed.},
  archive      = {J_EAAI},
  author       = {Shanen Yu and Jianke Chen and Guangyu Liu and Xiaolong Tong and Yingyi Sun},
  doi          = {10.1016/j.engappai.2023.106875},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106875},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SOF-RRT*: An improved path planning algorithm using spatial offset sampling},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating color cues to improve multimodal sentiment
analysis in social media. <em>EAAI</em>, <em>126</em>, 106874. (<a
href="https://doi.org/10.1016/j.engappai.2023.106874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis is an emerging and critical area of research, particularly in the context of social media where users express their emotions through both text and images. However, existing methods that learn common semantic features between visual and textual modalities for multimodal sentiment analysis often overlook the importance of color information, which plays a crucial role in sentiment expression, according to psychology and art theory. This paper proposes a novel model, named ICCI, which aims to enhance multimodal sentiment analysis in social media by integrating color cues, in order to address the limitation in existing approaches. The proposed model leverages both the semantic information from image-text pairs and the color cues from images to improve the accuracy of sentiment analysis. The model comprises a feature extraction module that extracts semantic features from both images and text, as well as color features from images. Furthermore, the feature interaction module employs a cross-attention mechanism to enable the interaction of information between semantic features and color features. Finally, the label prediction module integrates all attention features to enhance multimodal sentiment analysis. The proposed model was evaluated through experiments on two widely used benchmark datasets, namely MVSA-Single and MVSA-Multiple datasets, demonstrating its effectiveness in outperforming existing methods. On MVSA-Single, ICCI achieved an accuracy of 79.33%. Similarly, on MVSA-Multiple, ICCI achieved an accuracy of 73.29%. The results underscore the importance of integrating color information for more accurate sentiment analysis in social media.},
  archive      = {J_EAAI},
  author       = {Jieyu An and Wan Mohd Nazmee Wan Zainon},
  doi          = {10.1016/j.engappai.2023.106874},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106874},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating color cues to improve multimodal sentiment analysis in social media},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-based heat deflection temperature
prediction and effect analysis in polypropylene composites using
catboost and shapley additive explanations. <em>EAAI</em>, <em>126</em>,
106873. (<a
href="https://doi.org/10.1016/j.engappai.2023.106873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the various physical properties of polypropylene composites (PPCs), heat deflection temperature (HDT) during PPC production is significant because it is directly related to the mechanical behavior of such products. However, it is difficult to predict and analyze the HDT of PPCs owing to the absence of a mathematical or theoretical model. Moreover, categorical data which has different physical properties despite using same substances made predictions highly difficult in PPCs. Here, this study proposed an indicator to analyze the categorical data and Catboost-based model for HDT prediction considering the categorical data. First, the categorization and minimum-based values (MBVs), a dimensionless factor used to calculate HDT differences in the categorical dataset, are applied to detect and split categorical data in a PPC dataset. Second, a case study was conducted on the dataset using three algorithms to compare the proposed model with other traditional machine-learning approaches. As a result, the proposed model provides the highest prediction performance of R 2 = 0 . 8965 and 0.9801, for the total test dataset and the categorical dataset, respectively. In addition, the effect analysis of substances on HDT was conducted to get some prospective substances for the required HDT using Shapley Additive Explanations (SHAP). Thus, the results of this study can provide a guidance for selecting prospective substances using SHAP result for the target HDT and adjusting the substance ratio using the proposed model. It is expected that this framework has the potential for being applied to the other blending processes to produce products with the required properties.},
  archive      = {J_EAAI},
  author       = {Chonghyo Joo and Hyundo Park and Jongkoo Lim and Hyungtae Cho and Junghwan Kim},
  doi          = {10.1016/j.engappai.2023.106873},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106873},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based heat deflection temperature prediction and effect analysis in polypropylene composites using catboost and shapley additive explanations},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic spectrum loss generative adversarial network for
intelligent fault diagnosis with imbalanced data. <em>EAAI</em>,
<em>126</em>, 106872. (<a
href="https://doi.org/10.1016/j.engappai.2023.106872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis with imbalanced data is a problem that often raises concerns. The diagnosis is more effective when the imbalanced dataset is supplemented with data augmentation methods, but there is always a gap between the real data and the generated data, especially in the frequency domain. Therefore, a dynamic spectrum loss generative adversarial network (DSLGAN) is developed for intelligent fault diagnosis. Firstly, a generative information enhancement module is built to simultaneously enhance inefficient information of the generative network from different information sources, thus creating a stable and efficient environment for the generation. Secondly, the spectrum distance is designed to find the difference in spectrum location between the real data and the generated data quantitatively by distance metric, which is used to guide the model training to generate high-quality data with similar features to the real data. Finally, the dynamic spectrum loss is proposed based on the spectrum distance to break through the synthesis of difficult frequencies in the data, by reducing the weight of easily synthesized frequencies in the spectrum while dynamically focusing on the difficult frequency components during training to achieve better generation results. In addition, experiments are conducted using several datasets, and the diagnostic accuracy of DSLGAN is 99.63% and 99.65%, reaching a very high level and verifying the effectiveness and superiority of DSLGAN.},
  archive      = {J_EAAI},
  author       = {Xin Wang and Hongkai Jiang and Yunpeng Liu and Shaowei Liu and Qiao Yang},
  doi          = {10.1016/j.engappai.2023.106872},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106872},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic spectrum loss generative adversarial network for intelligent fault diagnosis with imbalanced data},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advances in dynamic load identification based on data-driven
techniques. <em>EAAI</em>, <em>126</em>, 106871. (<a
href="https://doi.org/10.1016/j.engappai.2023.106871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic loads on engineering structures are often difficult to measure directly. Therefore, indirect identification methods based on dynamic responses are commonly used. However, this approach is often influenced by ill-conditioned matrices, noise interference, unknown structural and/or material parameters, and difficulty of constructing transfer functions when the traditional physics-based model is used. To address these issues, significant strides have been made in data-driven identification of dynamic loads, which are model-free and independent of structural characteristics. This paper tries to present a comprehensive review of dynamic load identification methods based on data-driven techniques, covering two aspects: load localization and load reconstruction. Features of the widely used data-driven techniques such as the geometric method, reference database method, machine learning methods including SVM-based methods and ANN-based methods and deep learning methods are discussed in detail. Additionally, this paper offers insight into the challenges and prospects of the data-driven techniques for dynamic load identification. The review aims to provide valuable insights for identifying dynamic loads in complex structures based on data-driven techniques and suggests future research directions.},
  archive      = {J_EAAI},
  author       = {Daixin Fu and Lingyi Wang and Guanlin Lv and Zhengyu Shen and Hao Zhu and W.D. Zhu},
  doi          = {10.1016/j.engappai.2023.106871},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106871},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advances in dynamic load identification based on data-driven techniques},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Price forecasts of ten steel products using gaussian process
regressions. <em>EAAI</em>, <em>126</em>, 106870. (<a
href="https://doi.org/10.1016/j.engappai.2023.106870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing price forecasting problems is an important exercise to policymakers and market participants in the resource business sector. In this work, we build Gaussian process regression models through cross validation and Bayesian optimizations over different kernels and basis functions for daily price index forecasting of ten major steel products in the Chinese market during July 20, 2011–April 15, 2021. This study aims to be the first attempt of exploring potential of Gaussian process regressions for price forecasting exercises with the coverage of all of the ten most important steel products that carry enormous economic significance in China as the largest steel consumer and producer in the world. The models offer accurate out-of-sample forecasts for the two-year period of April 16, 2019–April 15, 2021 with relative root mean square errors ranging from 0.07404% to 0.22379% across the ten price indices and correlation coefficients above 99.9%. They also lead to better forecast performance than some traditional econometric models and some other machine learning models as benchmarks. The models constructed here could be utilized by policymakers as part of policy design and implementations and by market participants as part of market assessments and decision making.},
  archive      = {J_EAAI},
  author       = {Xiaojie Xu and Yun Zhang},
  doi          = {10.1016/j.engappai.2023.106870},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106870},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Price forecasts of ten steel products using gaussian process regressions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent state assessment of complex autonomous objects
based on wavelet analysis. <em>EAAI</em>, <em>126</em>, 106869. (<a
href="https://doi.org/10.1016/j.engappai.2023.106869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolutionary development of complex autonomous technical objects (CATOs), which include bodynets, unmanned vehicles, aircraft, and other robotic systems, is characterized by increased requirements for the quality of their functioning, security, and reliability under the influence of various kinds of destabilizing factors. This determines the importance of the problem of assessing their technical state, including monitoring degradation (aging) and supporting the dynamic adaptation of CATOs. To solve this problem, the article proposes a new method for intelligent assessment of the CATO technical state. The method is based on the representation of knowledge about the results of interval estimation of controlled parameters in the knowledge base of the system for assessing the CATO technical state. In this case, the process of estimating the controlled parameters is based on the application of wavelet analysis. The article discusses the architecture and implementation issues of the intelligent system for assessing the CATO technical state. A special place in this system is occupied by the knowledge base containing information about the emergency and normal states of controlled parameters. An experimental evaluation of the proposed assessment method showed that the joint use of knowledge representation processes in the knowledge base and wavelet analysis for the formation of CATO operability regions increases the accuracy and credibility of the state identification results. In addition, this approach expands the possibilities of applying technical means of control and diagnostics concerning evolving CATO.},
  archive      = {J_EAAI},
  author       = {Igor Kotenko and Igor Saenko and Alexey Vinogradenko and Nikita Budko},
  doi          = {10.1016/j.engappai.2023.106869},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106869},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent state assessment of complex autonomous objects based on wavelet analysis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent multiobjective optimization for high-performance
concrete mix proportion design: A hybrid machine learning approach.
<em>EAAI</em>, <em>126</em>, 106868. (<a
href="https://doi.org/10.1016/j.engappai.2023.106868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concrete mix proportion design process is complex but important, especially in cold, ocean, underground and other complex engineering environments. In this study, a hybrid intelligent optimization method based on the random forest (RF), recursive feature elimination (RFE), Bayesian optimization (BO), least squares support vector machine (LSSVM) and nondominated sorting genetic algorithm (NGSA)-III was proposed to optimize the concrete mix proportion and rapidly and accurately predict the frost resistance, chloride ion penetration resistance and concrete strength (CS). Adopting a key project in Jilin Province as an example, the RF-RFE-BO-LSSVM-NSGA-III algorithm achieved a significant optimization effect in terms of the chloride ion permeability coefficient (CIPC), relative dynamic elastic modulus (RDEM) and 28-day CS. After optimization, the chloride ion penetration resistance, frost resistance and CS increased by 34.6%, 4.1% and 3.7%, respectively, over the average levels of the sample data. This study can provide basis for concrete mix proportion design in complex environment.},
  archive      = {J_EAAI},
  author       = {Sai Yang and Hongyu Chen and Zongbao Feng and Yawei Qin and Jian Zhang and Yuan Cao and Yang Liu},
  doi          = {10.1016/j.engappai.2023.106868},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106868},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent multiobjective optimization for high-performance concrete mix proportion design: A hybrid machine learning approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TGM-nets: A deep learning framework for enhanced forecasting
of tumor growth by integrating imaging and modeling. <em>EAAI</em>,
<em>126</em>, 106867. (<a
href="https://doi.org/10.1016/j.engappai.2023.106867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction and uncertainty quantification of tumor progression are vital in clinical practice, i.e., disease prognosis and decision-making on treatment strategies. In this work, we propose TGM-Nets, a deep learning framework that combines bioimaging and tumor growth modeling (TGM) for enhanced prediction of tumor growth. This proposed framework, developed based on physics-informed neural networks (PINNs), is capable of integrating the TGM and sequential observations of tumor morphology for patient-specific prediction of tumor growth. The novelties of the design of TGM-Nets include the employment of Fourier layers to extract the features of the input images as well as the utilization of sequential learning and fine-tuning with physics for extrapolation to improve the prediction accuracy. The validity of TGM-Nets for tumor growth forecasting is verified by testing the model performance on synthetic and in-vitro datasets, respectively. Our results show that the TGM-Nets not only can track the growth rates of the mild and aggressive tumors but also capture their detailed morphological features within and outside the training domain. In particular, TGM-Nets can be used to predict the long time dynamics of tumor growth in mild and aggressive cases. Our results show that the parameters inferred from the TGM-Nets can be used for long-time prediction for up to 4 months with a maximum error of ∼ 4%. We also systematically study the effects of the number of training points and noisy data on the performance of TGM-Nets as well as quantify the uncertainty of the model predictions. We show that TGM-Nets can integrate the biomedical images to predict the growth of the in-vitro cultured pancreatic cancer cells and identify the associated growth rates, demonstrating the possibilities of using TGM-Nets in clinical practice. In summary, we propose a new deep learning model that combines imaging and TGM to improve the current approaches for predicting tumor growth and thus provide an advanced computational tool for patient-specific tumor prognosis.},
  archive      = {J_EAAI},
  author       = {Qijing Chen and Qi Ye and Weiqi Zhang and He Li and Xiaoning Zheng},
  doi          = {10.1016/j.engappai.2023.106867},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106867},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TGM-nets: A deep learning framework for enhanced forecasting of tumor growth by integrating imaging and modeling},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised underwater image enhancement via content-style
representation disentanglement. <em>EAAI</em>, <em>126</em>, 106866. (<a
href="https://doi.org/10.1016/j.engappai.2023.106866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The absorption and scattering properties of the water medium cause various types of distortion in underwater images, which seriously affects the accuracy and effectiveness of subsequent processing. The application of supervised learning algorithms in underwater image enhancement is limited by the difficulty of obtaining a large number of underwater paired images in practical applications. As a solution, we propose an unsupervised representation disentanglement based underwater image enhancement method (URD-UIE). URD-UIE disentangles content information (e.g., texture, semantics) and style information (e.g., chromatic aberration, blur, noise, and clarity) from underwater images and then employs the disentangled information to generate the target distortion-free image. Our proposed method URD-UIE adopts an unsupervised cycle-consistent adversarial translation architecture and combines multiple loss functions to impose specific constraints on the output results of each module to ensure the structural consistency of underwater images before and after enhancement. The experimental results demonstrate that the URD-UIE technique effectively enhances the quality of underwater images when training with unpaired data, resulting in a significant improvement in the performance of the standard model for underwater object detection and semantic segmentation.},
  archive      = {J_EAAI},
  author       = {Pengli Zhu and Yancheng Liu and Yuanquan Wen and Minyi Xu and Xianping Fu and Siyuan Liu},
  doi          = {10.1016/j.engappai.2023.106866},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106866},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised underwater image enhancement via content-style representation disentanglement},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe resource management of non-cooperative microgrids based
on deep reinforcement learning. <em>EAAI</em>, <em>126</em>, 106865. (<a
href="https://doi.org/10.1016/j.engappai.2023.106865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper solves a bi-level optimization problem in which at the first level, the distribution system operator (DSO) as a retailer tends to extract selling energy price signals so that increases its profit and reduces the peak-to-average ratio (PAR) of the MMG transactive energy; and at the second level energy management problems of non-cooperative networked microgrids (MGs) are solved individually to minimize their cost. This game theoretically problem is known as the Stackelberg game and has been solved with classical optimization methods like Karush–Kuhn–Tucker (KKT) method previously. To solve this problem with the classical KKT method, the MGs’ information should be provided for the DSO as a game starter, which is not the MGs’ desire for their privacy concerns. With the aim of preserving the privacy of MGs, this paper has developed a decision-making mechanism based on reinforcement learning (RL) to help the DSO extract energy prices individually for each MG. Also, the deep neural network (DNN) is used as a practical tool to predict MGs’ behavior in response to signal price. Furthermore, in the model used in this study, energy storage systems (ESSs) are dedicated to MGs which makes the model non-linear, thus the proposed method unlike the classic method is able to solve such a problem. The results obtained from the comparison between the classic and proposed method show that the implementation of this machine learning-based method is not only accurate enough but also is faster than the classical method, in addition to its privilege of privacy-preserving. Finally, a sensitivity analysis has been conducted to evaluate the DSO profit and PAR under different weighting factors of the objective function to obtain an appropriate performance.},
  archive      = {J_EAAI},
  author       = {Mahdi Shademan and Hamid Karimi and Shahram Jadid},
  doi          = {10.1016/j.engappai.2023.106865},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106865},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safe resource management of non-cooperative microgrids based on deep reinforcement learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective green scheduling of integrated flexible job
shop and automated guided vehicles. <em>EAAI</em>, <em>126</em>, 106864.
(<a href="https://doi.org/10.1016/j.engappai.2023.106864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional flexible job shop scheduling problem (FJSP) ignores transportation issues or merely introduces a time lag for transportation tasks while assuming an infinite number of transportation resources. With the development of intelligent manufacturing, automated guided vehicles (AGVs), which are the key transportation equipment for manufacturing enterprises, have been widely used for their high flexibility and stability. In addition, the increase in energy consumption and the trend of green manufacturing make it critical to take into account energy-related objectives in the decision-making of scheduling. Therefore, the multi-objective green scheduling problem of integrated flexible job shop and AGVs (MOGSP-IFJS&amp;AGVs) is addressed in this paper. To solve this problem effectively, the multi-objective mixed-integer programming (MMIP) model is formulated to minimize total energy consumption and makespan simultaneously. An efficient heuristic algorithm (EHA) is designed to solve the MMIP model. In the EHA, one solution encoding scheme and corresponding greedy insertion decoding method considering the selection of AGVs are presented. To acquire a high-quality initial population, the population initialization method balancing the processing time and energy consumption is designed. Further, a local search strategy is presented to enhance the quality of solutions and accelerate the convergence speed of the EHA. Experiment results of 45 test instances indicate that the EHA can obtain better solutions than that of comparison algorithms, which confirms the effectiveness of the EHA for solving the MOGSP-IFJS&amp;AGVs.},
  archive      = {J_EAAI},
  author       = {Gongjie Xu and Qiang Bao and Hongliang Zhang},
  doi          = {10.1016/j.engappai.2023.106864},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106864},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective green scheduling of integrated flexible job shop and automated guided vehicles},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantification of event related brain patterns for the motor
imagery tasks using inter-trial variance technique. <em>EAAI</em>,
<em>126</em>, 106863. (<a
href="https://doi.org/10.1016/j.engappai.2023.106863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantification of event-related (de) synchronization (ERD/ERS) patterns is a challenging task in the field of motor imagery (MI)-based brain–computer interface (BCI). Accurately determining the optimal time and frequency band for localizing the ERD/ERS brain patterns is crucial in designing a robust MI-based BCI. To address above issue, this study proposes an inter-trial variance (IV) technique that focuses on localizing the ERD/ERS brain patterns and classifying the left and right hand imaginations of the subjects. The effectiveness of the proposed technique is validated using the BCI Competition-IV, Dataset-2b, which includes raw EEG signals from nine healthy subjects performing both left and right hand MI movements. In this technique, the sensorimotor frequency band (8–30 Hz) and its ERD/ERS brain patterns related to the left and right hand MI movements are derived from the signals. The obtained brain patterns are fed into various ML models, and the efficiency of the models is assessed using the classification accuracy (%CA) and Cohen’s kappa coefficient (K). The outcomes show that the proposed technique enhances the performance of the BCI system, classifying both left and right hand imaginations of the subjects with higher %CA (86.11%) and K (0.72), and outperforming the state-of-the-art techniques. This concludes that the ERD and ERS brain patterns extracted from the proposed technique are significant features in designing the MI-based BCI system.},
  archive      = {J_EAAI},
  author       = {Fatemeh Shahlaei and Niraj Bagh and M.S. Zambare and M. Ramasubba Reddy},
  doi          = {10.1016/j.engappai.2023.106863},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106863},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantification of event related brain patterns for the motor imagery tasks using inter-trial variance technique},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nonlinear and infinite gain scheduling neural predictive
control of the outlet temperature in a parabolic trough solar field: A
comparative study. <em>EAAI</em>, <em>126</em>, 106862. (<a
href="https://doi.org/10.1016/j.engappai.2023.106862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar thermal plants have high nonlinearities and non-manipulated energy source which make their control task a very challenging work. Linear controllers cannot cope with undesirable deviations of the outlet temperature over all the operation range of the dynamics of this type of plants. Moreover, nonlinear predictive control relying on online nonlinear optimization have the drawback of time consuming and numerical calculus issues. In this paper, an infinite gain scheduling neural predictive control is designed and applied to control the temperature in a distributed parabolic trough solar collector field. The performance of both tracking and disturbance rejection of the proposed controller is compared to those of four nonlinear predictive control variants: Two unconstrained neural predictive control using the Levenberg–Marquardt and the Broyden–Fletcher–Goldfarb–Shanno algorithms, and two constrained nonlinear predictive control using interior point algorithm, one is based on a neural network model and the other one is based on a first principal model. The superiority of the proposed control strategy is well demonstrated through simulation results.},
  archive      = {J_EAAI},
  author       = {Yassine Himour and Mohamed Tadjine and Mohamed Seghir Boucherit},
  doi          = {10.1016/j.engappai.2023.106862},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106862},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear and infinite gain scheduling neural predictive control of the outlet temperature in a parabolic trough solar field: A comparative study},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quasi opposite-based learning and double evolutionary QPSO
with its application in optimization problems. <em>EAAI</em>,
<em>126</em>, 106861. (<a
href="https://doi.org/10.1016/j.engappai.2023.106861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although quantum-behaved particle swarm optimization (QPSO) algorithm has the advantages of few parameters and simple implementation, it suffers from these problems of low precision while calculating high-dimensional complex problems and being caught in local optimum during the later stage of iteration. To tackle these shortages effectively, a modified QPSO (QDQPSO) algorithm is presented. In order to improve the search efficiency and convergence speed of the algorithm, the idea of quasi opposite-based learning is used in the initialization stage. For enhancing the overall performance of the algorithm, the double evolutionary mechanism is applied to update the individual location during the iterative process. Furthermore, perturbation at global optimum position and bound constraint handling are considered to help the algorithm to escape from local optimum and maintain the diversity of population. According to the results obtained by QDQPSO and other nine optimization algorithms on 28 benchmark functions under different dimensions, it is found that QDQPSO performs better on the accuracy and stability of the optimal solution. Subsequently, Wilcoxon rank-sum test and Friedman test demonstrate significant advantages of the improved algorithm. Finally, QDQPSO algorithm displays superior performance in solving five practical optimization problems compared to several optimization methods.},
  archive      = {J_EAAI},
  author       = {Guang He and Xiao-li Lu},
  doi          = {10.1016/j.engappai.2023.106861},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106861},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quasi opposite-based learning and double evolutionary QPSO with its application in optimization problems},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meteorological data layout and task scheduling in a
multi-cloud environment. <em>EAAI</em>, <em>126</em>, 106860. (<a
href="https://doi.org/10.1016/j.engappai.2023.106860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The meteorological cloud mainly provides computing ability and meteorological datasets for meteorological model tasks. If the location of the required dataset and the execution location of the task are different, this will consume a large amount of time and bandwidth to transfer the data for the task. Meteorological data layout allocates meteorological datasets to various clouds. Because meteorological datasets are required by multiple meteorological model tasks and multiple times, the data layout is very important in the meteorological clouds. This paper focuses on how to layout out the meteorological datasets based on the association (internal meteorological datasets and between meteorological model tasks) and schedule resources for meteorological model tasks in the meteorological cloud. First, to find the association in the meteorological datasets and meteorological models, we use Apriori algorithm to mine frequent itemsets between datasets used by different meteorological models, and then we use the result to help layout meteorological data. After that, we present a heuristic algorithm for scheduling meteorological tasks. Finally, simulation comparison shows that the meteorological data layout method has a lowest value in the number of involved clouds for every task, the average size of transmitted datasets from other clouds, and the average time of transmitted datasets between clouds. We also prove that the scheduling method based on the data layout increases the number of completed tasks before their deadlines and reduces the average execution time.},
  archive      = {J_EAAI},
  author       = {Yongsheng Hao and Jie Cao and Qi Wang and Tinghuai Ma and Qin Wang and Xin Zhang},
  doi          = {10.1016/j.engappai.2023.106860},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106860},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Meteorological data layout and task scheduling in a multi-cloud environment},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust fleet-based anomaly detection framework applied to
wind turbine vibration data. <em>EAAI</em>, <em>126</em>, 106859. (<a
href="https://doi.org/10.1016/j.engappai.2023.106859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large amounts of unlabeled data are produced from wind turbine condition monitoring systems to catch their operational status. With this unmanageable amount of data, developing robust systems with good performance on unseen test data to detect incipient wind turbine faults is crucial to maximizing wind farm performance. This paper presents an implementation of a robust unsupervised machine-learning approach capable of executing fleet-based anomaly detection in wind turbines’ critical components. The proposed methodology is applied to noisy, unlabeled, and unstructured vibration data, which must go through the databank decoding, data engineering, preprocessing, and feature extraction. Twelve operational wind turbines with varying health conditions are used to train, validate, and test the models. Features from different domains (time, frequency, and mechanical domain) are extracted and represented in the model’s input. A labeling procedure from expert analysis regarding the condition of each wind turbine component through the evaluation of CMS output was carried out. Combining distinctive approaches to optimize eleven unsupervised machine learning algorithms through an unusual 5×2 cross-validation approach applied to real, noisy, and unstructured wind turbine data represents the paper’s novelty. The methodology selected the six best models (k-nearest neighbors, clustering-based local outlier, histogram-based outlier, isolation forest, principal component analysis, and minimum covariance determinant) based on robust performance metrics such as accuracy, F1-score, precision, recall, and area under the ROC (Receiver Operating Characteristic Curve). These models generalized the problem well and returned reasonable classification metrics for such a complex problem, with values above 90% for the area under the ROC.},
  archive      = {J_EAAI},
  author       = {Gustavo de Novaes Pires Leite and Felipe Costa Farias and Tiago Gomes de Sá and Alexandre Carlos Araújo da Costa and Leonardo José Petribú Brennand and Marrison Gabriel Guedes de Souza and Alvaro Antonio Ochoa Villa and Enrique Lopez Droguett},
  doi          = {10.1016/j.engappai.2023.106859},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106859},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust fleet-based anomaly detection framework applied to wind turbine vibration data},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vibration-based building health monitoring using
spatio-temporal learning model. <em>EAAI</em>, <em>126</em>, 106858. (<a
href="https://doi.org/10.1016/j.engappai.2023.106858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration-based building health monitoring is a promising and feasible approach to assess the operational state of building structures in a remote, automated, and continuous fashion; however, efficiently handling high-dimensional vibration signals from multiple sensors and effectively coping with missing/noisy data represent two main technical challenges. In order to overcome these issues, this study proposes a novel, reliable and robust framework, abbreviated CLG-BHM, based on a hybrid deep learning architecture. First, the framework uses a 1D convolutional neural network layer to learn low-dimensional representation vectors of long sensor signals, which preserve underlying structures’ dynamic characteristics. Second, temporal relationships within data are distilled via a Long-Short Term Memory layer. Third, the representation vectors of sensors are aggregated with those of their neighbors in a principled way via a graph attention network layer, resulting in a new latent representation rich in both temporal and spatial information. Finally, the latter is gone through a fully-connected layer to provide damage detection results. The performance and viability of the present method are evidenced via various examples involving a simple lumped mass structure, a semi-rigid steel frame, and an experimental 4-story structure from the literature. Moreover, a robustness study is performed, showing that the method can provide reasonable results with the presence of noisy and missing data.},
  archive      = {J_EAAI},
  author       = {Viet-Hung Dang and Hoang-Anh Pham},
  doi          = {10.1016/j.engappai.2023.106858},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106858},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vibration-based building health monitoring using spatio-temporal learning model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VIKOR method for pythagorean hesitant fuzzy multi-attribute
decision-making based on regret theory. <em>EAAI</em>, <em>126</em>,
106857. (<a
href="https://doi.org/10.1016/j.engappai.2023.106857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reality, influenced by fuzzy information and irrational behavior, decision-makers are typically difficult to make decisions. Therefore, how to comprehensively express the evaluation information and accurately quantify the psychological behavior becomes a primary key to improve the efficiency of decision-making. Aiming at multi-attribute decision-making problem with completely unknown weight information and Pythagorean hesitate fuzzy evaluation value, a VIKOR method based on regret theory is proposed. Firstly, the weights are determined from two levels of alternative and attribute. Secondly, the relative closeness decision matrix is constructed by TOPSIS method. Then, the VIKOR method is used to calculate the values of group utility and individual regret based on regret perception value, which can describe the ranking of alternatives. Finally, the availability and effectiveness of this method are proved by sensitivity and comparative analysis. In conclusion, the proposed method not only considers the compromise preference under Pythagorean hesitant fuzzy environment, but also takes into account regret psychologic behavior of decision-makers.},
  archive      = {J_EAAI},
  author       = {Nian Zhang and Yifan Zhou and Jin Liu and Guiwu Wei},
  doi          = {10.1016/j.engappai.2023.106857},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106857},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {VIKOR method for pythagorean hesitant fuzzy multi-attribute decision-making based on regret theory},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid multi-start metaheuristic scheduler for
astronomical observations. <em>EAAI</em>, <em>126</em>, 106856. (<a
href="https://doi.org/10.1016/j.engappai.2023.106856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate Astronomical Observations Scheduling which is a type of Multi-Objective Combinatorial Optimization Problem, and detail its specific challenges and requirements and propose the Hybrid Accumulative Planner (HAP), a hybrid multi-start metaheuristic scheduler able to adapt to the different variations and demands of the problem. To illustrate the capabilities of the proposal in a real-world scenario, HAP is tested on the Atmospheric Remote-sensing Infrared Exoplanet Large-survey ( Ariel ) mission of the European Space Agency (ESA), and compared with other studies on this subject including an Evolutionary Algorithm (EA) approach. The results show that the proposal outperforms the other methods in the evaluation and achieves better scientific goals than its peers. The consistency of HAP in obtaining better results on the available datasets for Ariel, with various sizes and constraints, demonstrates its competence in scalability and adaptability to different conditions of the problem.},
  archive      = {J_EAAI},
  author       = {Nariman Nakhjiri and Maria Salamó and Miquel Sànchez-Marrè and Juan Carlos Morales},
  doi          = {10.1016/j.engappai.2023.106856},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106856},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid multi-start metaheuristic scheduler for astronomical observations},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature reconstruction graph convolutional network for
skeleton-based action recognition. <em>EAAI</em>, <em>126</em>, 106855.
(<a href="https://doi.org/10.1016/j.engappai.2023.106855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition is an important task in computer vision. Recently, graph convolutional networks (GCNs) have been successfully applied to this task and achieved remarkable results. However, there are still some non-negligible limitations with existing GCN-based methods. First, the artificial predefined skeleton partition lacks the joint modeling for different types of edges. Second, most GCN models use interleaved deployment of spatial-only and temporal-only modules to achieve feature learning, which makes them ineffective in capturing spatiotemporal co-occurrence from action sequences. To tackle the above issues, we propose a novel feature reconstruction graph convolutional network (FR-GCN) for skeleton-based action recognition. The proposed FR-GC combines coarse-grained temporal and spatial features to reconstruct fine-grained spatiotemporal features, realizing simultaneous learning of temporal and spatial representations in a single module and significantly improving the capability of the model for spatiotemporal feature extraction. We also propose a topology partition enhancement module to achieve adaptive complementation among different types of edges. Moreover, an efficient multi-scale dual-domain temporal convolution is used to complete further temporal modeling. Compared with state-of-the-art methods, the proposed FR-GCN achieves competitive results on both NTU RGB+D 60 dataset and NTU RGB+D 120 dataset. Especially under the cross-subject benchmarks of the two datasets, the proposed FR-GCN achieves new state-of-the-art performance.},
  archive      = {J_EAAI},
  author       = {Junhao Huang and Ziming Wang and Jian Peng and Feihu Huang},
  doi          = {10.1016/j.engappai.2023.106855},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106855},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature reconstruction graph convolutional network for skeleton-based action recognition},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal graph neural network for multivariate
multi-step ahead time-series forecasting of sea temperature.
<em>EAAI</em>, <em>126</em>, 106854. (<a
href="https://doi.org/10.1016/j.engappai.2023.106854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a spatiotemporal graph neural network capable of effective representation learning of the spatiotemporal interrelationships and interdependencies of in-situ observation data from multiple locations for multivariate multi-step ahead time-series forecasting. The propose model is largely composed of graph learning, spatial encoder, and temporal decoder, and ablation studies on variants of the three modules and comparative experiments with state-of-the-art deep neural networks for sequence modeling were also performed extensively. The proposed model showed improved predictability than conventional numerical model-based approaches or state-of-the-art models by applying consecutive multi-step ahead time-series prediction of sea surface temperature at multiple locations along the coast. For more rigorous performance evaluation, not only the overall performance of the test data, but also the performance of extreme cases included in the test data based on historical records were separately assessed. The prediction rationales were also presented through quantified relative contributions between neighbor locations using the trained adjacency matrix obtained through graph learning. The results showed that it is well consistent with the ocean physics and geographical domain knowledge, demonstrating the feasibility and reliability of the proposed method. Therefore, the proposed method shows sufficient potential to be used as a scientific tool for decision-making in extreme events such as marine heat waves or for operational ocean forecasting.},
  archive      = {J_EAAI},
  author       = {Jinah Kim and Taekyung Kim and Joon-Gyu Ryu and Jaeil Kim},
  doi          = {10.1016/j.engappai.2023.106854},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106854},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatiotemporal graph neural network for multivariate multi-step ahead time-series forecasting of sea temperature},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learn-to-supervise: Causal reinforcement learning for
high-level control in industrial processes. <em>EAAI</em>, <em>126</em>,
106853. (<a
href="https://doi.org/10.1016/j.engappai.2023.106853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Possessing efficient supervisory control systems is crucial for maintaining the desired operational performance of complex industrial processes. Several challenges face the developers of these systems, such as requiring accurate physical models, dealing with the variability and uncertainty of process operating conditions and coordinating between local controllers to reach desired global performance. This paper proposes an intelligent supervisory control approach based on causal reinforcement learning (CRL) to effectively manipulate the controllers’ setpoints of the process in a way that optimizes its key performance indicators (KPIs), thereby improving the energy efficiency of the process. The approach adopts deep reinforcement learning (DRL) to develop an efficient control policy through interaction with a process simulation. The DRL training history is then exploited using interpretable machine learning and process mining to build a discrete event system (DES) model, in the form of a state-event graph. The DES model identifies causal relationships between events and provides interpretability to the control policy developed by the DRL method. The DES discovered is exploited as a Markov decision process to apply the Q-learning algorithm as a CRL supervisor. The supervisor incorporates causal knowledge into its training process, thus improving the DRL control policy developed and identifying the event paths that optimize the process’s KPIs. The proposed approach is validated using two heat recovery systems in a pulp &amp; paper mill. It successfully achieves a control policy that reduces energy consumption by up to 15.6% for the first system and 5.02% for the second, compared to the expert’s baseline methods.},
  archive      = {J_EAAI},
  author       = {Karim Nadim and Mohamed-Salah Ouali and Hakim Ghezzaz and Ahmed Ragab},
  doi          = {10.1016/j.engappai.2023.106853},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106853},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learn-to-supervise: Causal reinforcement learning for high-level control in industrial processes},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault diagnosis of power-shift system in continuously
variable transmission tractors based on improved echo state network.
<em>EAAI</em>, <em>126</em>, 106852. (<a
href="https://doi.org/10.1016/j.engappai.2023.106852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For better reliability of tractors with continuously variable transmission, reported here is fault diagnosis of their power-shift systems. First, four hydraulic system faults are analyzed, i.e., pipe leakage, pipe blockage, a stuck solenoid valve spool, and a stuck clutch piston, and it is shown that these lead to clutch energy loss during power shifting and possibly even clutch burn-out. Second, fault simulations give more than 30000 groups of test data, and an improved dynamic time warping algorithm is used to segment the data samples automatically. Third, an improved echo state network is proposed to classify the above fault samples, and its performance is compared with those of traditional algorithms. Finally, the robustness of the proposed algorithm is tested using samples with noise superimposed. The results show that the accuracy, precision, recall, and F1-score of the improved echo state network are 96.87%, 96.31%, 97.11%, and 96.71%, respectively, making it equivalent in performance to a convolutional neural network with long short-term memory. However, the training speed of the former is significantly better than that of the latter, and even under the influence of strong noise, the proposed algorithm can still achieve an accuracy of 91.32%, which is better than the latter’s 86.62%. This is significantly better than traditional algorithms, thus demonstrating the better generalization characteristics and robustness of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Guangming Wang and Lijun Xue and Youfeng Zhu and Yehui Zhao and Honghua Jiang and Jinxing Wang},
  doi          = {10.1016/j.engappai.2023.106852},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106852},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis of power-shift system in continuously variable transmission tractors based on improved echo state network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Multisensor fault diagnosis via markov chain and evidence
theory. <em>EAAI</em>, <em>126</em>, 106851. (<a
href="https://doi.org/10.1016/j.engappai.2023.106851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-sensor fusion, the Dempster–Shafer theory is frequently used for fault diagnosis and other decision-making problems. However, if the information collected from various sensors exhibits uncertainty and high conflict, the classical Dempster’s Combination Rule may produce a counter-intuitive result. Various studies were conducted by Ghosh and other scholars to solve this problem, and good results were achieved. This work provides a novel idea which uses the Markov chain to model the uncertainty information in evidence theory, explore the ordered rules in random evidence, and then obtain the evidence support degree, thereby reducing the effect of high-conflict evidence. Considering the information amount of evidence combined with the evidence support degree, the final credibility of evidence is obtained, and the weighted summation is used to obtain new evidence. Finally, the classical Dempster combination rule is used to process new evidence and make the final decision. Through numerical examples and case studies, the proposed method’s superior efficiency and robustness over the existing multisensor fault diagnosis methods are illustrated.},
  archive      = {J_EAAI},
  author       = {Kejun Wang and Wenqing Wang and Yabo Zhao and Bodi Yuan and Zirui Xiang},
  doi          = {10.1016/j.engappai.2023.106851},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106851},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multisensor fault diagnosis via markov chain and evidence theory},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A nonlinear solver based on residual network for seepage
equation. <em>EAAI</em>, <em>126</em>, 106850. (<a
href="https://doi.org/10.1016/j.engappai.2023.106850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reservoir simulation, the linearization process after the discretization of the seepage equation will additionally introduce new errors, which can be avoided by using a nonlinear solver based on a deep neural network. In this paper, we propose a new solution method without needing linearization of the discretized seepage equation, which combines residual network and correction iteration method to solve nonlinear system of equations instead of using Newton method. The residual network is trained based on label data generated by seepage equation and approximates the solution, and the error of approximated solution is used as the new input of the trained residual network model for the next correction iteration. The single-phase seepage equation is solved to confirm the effectiveness of the proposed method. Numerical results indicate that, error caused by linearization significantly affects the solution accuracy, which reduces solution accuracy and time step. Under the same time step, the proposed solution method has higher accuracy, and under the premise of ensuring the solution accuracy, the time step of proposed method increases by more than three times.},
  archive      = {J_EAAI},
  author       = {Daolun Li and Shuaijun Lv and Wenshu Zha and Luhang Shen and Yan Xing},
  doi          = {10.1016/j.engappai.2023.106850},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106850},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A nonlinear solver based on residual network for seepage equation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A representation-learning-based approach to predict stock
price trend via dynamic spatiotemporal feature embedding. <em>EAAI</em>,
<em>126</em>, 106849. (<a
href="https://doi.org/10.1016/j.engappai.2023.106849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price trend prediction is a fascinating but difficult research topic. Recently, GNN-based models have been continuously proposed, which are believed to be more effective since they consider the information about stocks themselves and the information between stocks. However, the graph data are often static, unstructured and not all-inclusive, which cannot dynamically reflect all relationships between stocks. Therefore, we propose a novel model PriceExploration-Network (PE-Net), effectively utilizing both temporal and cross-sectional information contained in price to predict the price trend. PE-Net only requires the price data effectively saving the trouble of fetching alternative data and is able to capture the dynamic implicit relations between stocks by combining clustering techniques and GAT architecture. The effectiveness of PE-Net is examined on real-world S&amp;P 500 constituents and the results demonstrate that PE-Net can outperform state-of-the-art models w.r.t. both accuracy and AUC.},
  archive      = {J_EAAI},
  author       = {Bowen Pang and Wei Wei and Xing Li and Xiangnan Feng and Chao Li},
  doi          = {10.1016/j.engappai.2023.106849},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106849},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A representation-learning-based approach to predict stock price trend via dynamic spatiotemporal feature embedding},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart investigation of artificial intelligence in renewable
energy system technologies by natural language processing: Insightful
pattern for decision-makers. <em>EAAI</em>, <em>126</em>, 106848. (<a
href="https://doi.org/10.1016/j.engappai.2023.106848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to provide a framework which enables decision-makers and researchers to identify AI technology patterns in renewable energy systems from a massive data set of textual data. However, the study was challenged by the Scopus database limitation that allows users to retrieve only 2000 documents per query. Therefore, we developed a search engine based on the Scopus Application Programming Interface (API) that enables us to download an unlimited number of documents per query based on our desirable settings. We extracted 5661 renewable energy systems-related publications from Scopus database and leveraged Natural Language Processing (NLP) and unsupervised algorithms to identify the most frequent computational science models and dense meta-topics and investigate their evolution throughout the period 2000-2021. Our findings showed 7 meta-topics based on the class-based Term Frequency-Inverse Document Frequency (c-TD-IDF) score and term score decline graph. Emerging advanced algorithms, such as different deep learning architectures, directly impacted growing meta-topics involving problems with uncertainty and dynamic conditions.},
  archive      = {J_EAAI},
  author       = {Kamran Niroomand and Noori M. Cata Saady and Carlos Bazan and Sohrab Zendehboudi and Amilcar Soares and Talib M. Albayati},
  doi          = {10.1016/j.engappai.2023.106848},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106848},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Smart investigation of artificial intelligence in renewable energy system technologies by natural language processing: Insightful pattern for decision-makers},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A soft sensor modeling framework embedded with domain
knowledge based on spatio-temporal deep LSTM for process industry.
<em>EAAI</em>, <em>126</em>, 106847. (<a
href="https://doi.org/10.1016/j.engappai.2023.106847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process industries, the complex mechanisms, the many variables with complex interactions, the high uncertainty and errors in instrumentation, etc. make it very difficult to build accurate soft sensor models. Domain knowledge plays a very important role in soft sensor modeling. However, current data-driven methods lack domain knowledge of the specific processes. Therefore, a spatio-temporal deep learning soft sensor modeling framework embedded with domain knowledge is proposed in this paper. First, the time-delays between the key variable and the other process variables are analyzed to align the process variables temporally and select secondary variables. A spatio-temporal structure model (STSM) of the process is then constructed by using domain knowledge to decouple the sub-processes. Finally, a deep Long Short-Term Memory (LSTM) model embedded with the STSM is proposed to learn the characteristics of the spatiotemporal nonlinear dynamic features between the sub-process variables and the key variable in industrial processes. The effectiveness of the framework is verified by prediction of the key indices in two mineral processing processes.},
  archive      = {J_EAAI},
  author       = {Jia-yi Zhou and Chun-hua Yang and Xiao-li Wang and Si-yu Cao},
  doi          = {10.1016/j.engappai.2023.106847},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106847},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A soft sensor modeling framework embedded with domain knowledge based on spatio-temporal deep LSTM for process industry},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel aczel-alsina triangular norm-based group
decision-making approach under dual hesitant q-rung orthopair fuzzy
context for parcel lockers’ location selection. <em>EAAI</em>,
<em>126</em>, 106846. (<a
href="https://doi.org/10.1016/j.engappai.2023.106846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For complex last mile problems, the parcel lockers play an important role in urban areas. So, selecting a suitable location is very much crucial to provide optimal service and better logistical performance. From that viewpoint, a multicriteria group decision making method is developed in this article using dual hesitant q -rung orthopair fuzzy (DH q -ROF) set which is more effective than existing variations of fuzzy sets. The Aczel-Alsina (AA) class of t -conorms and t -norms (AA t -CNs&amp; t -Ns) emerged as an important class of union and intersection operations due to its greater flexibility in the information fusion process. To take advantage of the benefits of AA t -CNs&amp; t -Ns and hybrid aggregation operators in DH q -ROF environments, several fundamental operations based on AA t -CNs&amp; t -Ns are first defined. Following the introduction of these stated operations, a series of aggregation operators, viz., DH q -ROF AA weighted averaging, ordered weighted averaging, hybrid averaging and their geometric versions with DH q -ROF information, has been proposed. Based on these operators, a creative approach to handle multi-attribute group decision-making problems has been framed. The parcel lockers’ location selection problem is estimated to validate the created strategy and show its applicability and efficacy. The achieved results establish that the post office is the best location for locating parcel lockers.},
  archive      = {J_EAAI},
  author       = {Souvik Gayen and Animesh Biswas and Arun Sarkar and Tapan Senapati and Sarbast Moslem},
  doi          = {10.1016/j.engappai.2023.106846},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106846},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel aczel-alsina triangular norm-based group decision-making approach under dual hesitant q-rung orthopair fuzzy context for parcel lockers’ location selection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overview of fault prognosis for traction systems in
high-speed trains: A deep learning perspective. <em>EAAI</em>,
<em>126</em>, 106845. (<a
href="https://doi.org/10.1016/j.engappai.2023.106845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the “heart” of high-speed train, traction systems play an important role in the safe operation of trains, of which the operation and maintenance level is still unable to meet the needs of modern railway transportation. Fortunately, multifarious advanced fault prognosis methods have been developed to deal with the dilemma. Among them, deep learning ones have received special attention due to their unique advantages. This paper first reveals the structural characteristics of traction systems in high-speed trains. Then, various representative deep learning based prognosis methods are compared and summarized, focusing on the analysis of their pros and cons. Finally, we point out the challenges and speculate the future trends in this field. This paper may serve as a referee for the interested researchers in fault prognosis and high-speed train traction systems fields, along with the potential directions.},
  archive      = {J_EAAI},
  author       = {Kai Zhong and Jiayi Wang and Shuiqing Xu and Chao Cheng and Hongtian Chen},
  doi          = {10.1016/j.engappai.2023.106845},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106845},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Overview of fault prognosis for traction systems in high-speed trains: A deep learning perspective},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of mechanistic-artificial intelligence model for
simulation of numerical data of water flow in porous materials.
<em>EAAI</em>, <em>126</em>, 106844. (<a
href="https://doi.org/10.1016/j.engappai.2023.106844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluid dynamics of water flow through porous metallic media is significant for cooling and heating applications. The prediction of the velocity of fluid flowing inside the porous media could provide useful data for pressure drop calculations. This prediction is usually performed by a mathematical modeling approach like computational fluid dynamics (CFD). The computational method is a powerful means of precision calculation, although it could take more time and expenditure for more complex geometries or more complex fluid flow regimes. Artificial intelligence (AI) algorithms could learn and map CFD data under several conditions. AI algorithms could continue the prediction of physical data, saving computing time and performance. The present study focuses on CFD modeling of water flow inside a pipe filled with copper porous media. For the first time, the fuzzy bee algorithm (BAFIS) maps the generated CFD data to inlet velocities of 0.5, 0.7, 1.1, and 1.3 m/s. The BAFIS intelligence assessment for accurate convective flow prediction in porous media is not available in the literature. Additionally, the reliability of this method for missing CFD data prediction has not been considered yet. The results showed that the maximum intelligence (regression=0.97) is for a bee number of 140. Using the most intelligent BAFIS, the outlet velocity can be predicted by the artificial intelligence method for further nodes and inlet velocities without CFD modeling. BAFIS could precisely predict the outlet velocity for missing data with an inlet velocity of 0.91 m/s based on previously mapped data. A comparison was made between BAFIS and the fuzzy neural network (ANFIS) for CFD data predictions. The mean-square error and the root-mean-square error of ANFIS were slightly more than BAFIS (i.e., 0.1% and 3%, respectively).},
  archive      = {J_EAAI},
  author       = {Hadil Faris Alotaibi and Zainab Ali Bu sinnah and Ahmad J. Obaidullah and Saad M. Alshahrani and Halah Jawad Al-fanhrawi and Afrasyab Khan},
  doi          = {10.1016/j.engappai.2023.106844},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106844},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of mechanistic-artificial intelligence model for simulation of numerical data of water flow in porous materials},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Modified TODIM method based on cumulative prospect theory
with type-2 neutrosophic number for green supplier selection.
<em>EAAI</em>, <em>126</em>, 106843. (<a
href="https://doi.org/10.1016/j.engappai.2023.106843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s consumers’ awareness of environmental protection and social morality is forcing companies to implement sustainable supply chains. Choosing a green supplier can not only determine the sustainable development of the supply chain, but also protect the environment and enhance the company’s reputation, in line with the background of green development. Green supplier selection is a multi-attribute decision-making (MADM) problem. Type-2 neutrosophic number (T2NN) can be compatible with more fuzzy information, and the green supplier selection problem also has a lot of fuzzy information, which makes T2NN very suitable for supplier selection. In this paper, a new method named CPT-TODIM-CDMT is proposed for green supplier selection of T2NN set based on TODIM. A new distance measure named cosine distance measure is proposed for T2NN set, and is applied in TODIM method. In this new method, attribute weight is determined by entropy method and optimized by CPT. The gains and losses preference in the CPT is also applied to the step of calculating the dominance degree in the TODIM method. A case study is used to verify the method. Through the comparison of the results of different decision-making models and the sensitivity research of the coefficients in the model, the correctness, validity and stability of the model are verified.},
  archive      = {J_EAAI},
  author       = {Zeyuan Wang and Qiang Cai and Guiwu Wei},
  doi          = {10.1016/j.engappai.2023.106843},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106843},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modified TODIM method based on cumulative prospect theory with type-2 neutrosophic number for green supplier selection},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Measuring similarity based on user activeness in recommender
systems to improve algorithm scalability. <em>EAAI</em>, <em>126</em>,
106842. (<a
href="https://doi.org/10.1016/j.engappai.2023.106842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems analyze user preferences and predict their preferred products based on available data, saving users time in the search for preferred products. However, accurate recommendations for both the system and the user may require complicated computations or the need to store more neighbors, leading to a less scalable algorithm. To address this issue, we define user activity coefficients and then analyze the relationship between different activity coefficients and similarity to design a novel approach for measuring user activity-based similarity in recommender systems. By examining the similarity of inactive user groups, our approach considers the accurate calculation of their similarity as one of the keys to influencing the number of required neighbors for optimal performance. As compared to several advanced collaborative filtering algorithms on two datasets, the algorithm developed in this paper can reduce the number of neighbors by 35.58%–75.38% while maintaining high prediction accuracy. The results indicate that user activity in recommender systems has a significant impact on similarity evaluation, which should be considered in relevant models.},
  archive      = {J_EAAI},
  author       = {Jun Ai and Yifang Cai and Zhan Su and Dunlu Peng and Fengyu Zhao},
  doi          = {10.1016/j.engappai.2023.106842},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106842},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Measuring similarity based on user activeness in recommender systems to improve algorithm scalability},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MOIT: A novel task for mining opinions towards implicit
targets. <em>EAAI</em>, <em>126</em>, 106841. (<a
href="https://doi.org/10.1016/j.engappai.2023.106841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of opinions and their corresponding targets has gained significant interest recently, as it offers valuable insights into Opinion Mining (OM) at a granular level. Opinion and target terms to be extracted by existing OM tasks need to be explicitly present in reviews. Targets that are not present but implied in contextual semantics, are neglected by existing OM tasks, even though an investigation reported that about 60% of reviews contain implicit targets. To enable implicit target extraction, a novel task named Mining Opinions towards Implicit Targets (MOIT) under the fine-grained OM, is proposed to extract both opinions and their corresponding implicit targets, enabling a more comprehensive analysis of reviews. To set up the basis for follow-up research on MOIT, two large-scale datasets were constructed as resources in two languages, where the Chinese dataset was built from scratch via a standard human annotation process, and the English dataset was built semi-automatically through machine translation and manual checking. Furthermore, three baseline models adapting three representative paradigms of information extraction, namely sequence labeling, question answering, and text generation, were proposed to solve MOIT. Extensive experiments demonstrated the effectiveness of the models. The proposed MOIT task extends the field of OM research, and the datasets and models establish a foundation for future studies in this area.},
  archive      = {J_EAAI},
  author       = {Jun Zhou and Fei Li and Chong Teng and Yijiang Liu and Chunli Xiang and Donghong Ji},
  doi          = {10.1016/j.engappai.2023.106841},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106841},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MOIT: A novel task for mining opinions towards implicit targets},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting train driveshaft damages using accelerometer
signals and differential convolutional neural networks. <em>EAAI</em>,
<em>126</em>, 106840. (<a
href="https://doi.org/10.1016/j.engappai.2023.106840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining railway axles is crucial to prevent catastrophic failures and enormous human and economic costs. In recent years, there has been a growing interest in the railway industry to adopt condition monitoring techniques to enhance the safety and efficiency of the rail transport system, which maintenance is currently based on periodic inspections. In this context, this work presents a technique for real-time crack diagnosis on railway axles, based on advanced 2D-Convolutional Neural Network (CNN) architectures applied to time–frequency representations of vibration signals. One of the critical novelties is introducing a differential CNN structure that captures the system’s statistical properties, enabling generalisation between different mechanical sets and conditions. The proposed system has been trained with data corresponding to a unique wheelset assembly, showing that the model is able to diagnose cracks on the three different wheelset tested in operation under 32 different combinations of conditions, such as load, speed, sense of rotation and vibration direction. Four different crack levels have been introduced, representing the maximum one a 0.08% of the axle diameter, and the method proposed achieved Area Under the Curve (AUC) score of 0.85, significantly outperforming results obtained with other architectures proposed in the state-of-the-art, the score of the next below is 0.76. The results demonstrate the effectiveness and practicality of this approach to accurately classify the four crack levels tested within a condition monitoring system for non-stationary conditions, that would enable reliable real-time diagnosis, thus paving the way towards a more robust and efficient railway axle maintenance system.},
  archive      = {J_EAAI},
  author       = {Antía López Galdo and Alejandro Guerrero-López and Pablo M. Olmos and María Jesús Gómez García},
  doi          = {10.1016/j.engappai.2023.106840},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106840},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting train driveshaft damages using accelerometer signals and differential convolutional neural networks},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revolutionizing sustainable supply chain management: A
review of metaheuristics. <em>EAAI</em>, <em>126</em>, 106839. (<a
href="https://doi.org/10.1016/j.engappai.2023.106839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews the application of metaheuristics for optimized sustainable supply chain management (SSCM). This paper explores the potential of metaheuristics to improve the supply chain’s sustainability while enhancing its efficiency and competitiveness. The paper provides an overview of the principles of SSCM and the challenges businesses face in achieving sustainable supply chain management. It then introduces the concept of metaheuristics and describes their use in solving complex optimization problems. The paper reviews various metaheuristics algorithms applied to sustainable supply chain management and analyzes their effectiveness in addressing the challenges of SSCM. The paper also identifies the key factors that influence the success of using metaheuristics for SSCM, such as the choice of algorithm, problem complexity, and data quality. Finally, the paper provides recommendations for future research in this area and highlights the potential of metaheuristics to promote sustainable supply chain management. The review suggests that metaheuristics can be a valuable tool for optimizing sustainable supply chain management and improving supply chain operations’ sustainability, efficiency, and competitiveness.},
  archive      = {J_EAAI},
  author       = {Laith Abualigah and Essam Said Hanandeh and Raed Abu Zitar and Cuong-Le Thanh and Samir Khatir and Amir H. Gandomi},
  doi          = {10.1016/j.engappai.2023.106839},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106839},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Revolutionizing sustainable supply chain management: A review of metaheuristics},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neuromorphic electronics for robotic perception, navigation
and control: A survey. <em>EAAI</em>, <em>126</em>, 106838. (<a
href="https://doi.org/10.1016/j.engappai.2023.106838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic electronics have great potential in the emulation of the sensory, cognitive, self-learning, and actuating functions of robots. While typically implemented in rigid silicon, emerging technologies in organic and flexible electronic materials have also led to tremendous advances in the development of neuromorphic perception systems. However, a comprehensive review of the contribution/role of organic neuromorphic electronics for robotic applications is still missing. This review presents advancements in silicon-based and organic neuromorphic electronics for intelligent robot development, focusing on perception, navigation, and learning-based control. Organic synaptic devices, along with dynamic vision sensors, enable diverse forms of sensory-enabled computational perception, offering tunability, stability, low power consumption, and conformal substrates. Integration of simultaneous localization and mapping techniques and path planning algorithms empowers robots to efficiently navigate, build accurate maps, and make informed decisions. Different learning algorithms and their hardware implementations in neuromorphic robotic control are explored, enabling robots to learn and adapt to dynamic environments. The review highlights the potential of neuromorphic electronics for sensing, thinking, and acting in advanced robotic systems. Organic, inorganic, and hybrid materials are discussed for implementing perception, navigation, and control in robots. Future research directions in the field are outlined. Leveraging various neuromorphic electronics unlocks the full potential of intelligent robotic systems for diverse applications.},
  archive      = {J_EAAI},
  author       = {Yi Yang and Chiara Bartolozzi and Haiyan H. Zhang and Robert A. Nawrocki},
  doi          = {10.1016/j.engappai.2023.106838},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106838},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neuromorphic electronics for robotic perception, navigation and control: A survey},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A nonlinear multi-label learning model based on tanh
mapping. <em>EAAI</em>, <em>126</em>, 106837. (<a
href="https://doi.org/10.1016/j.engappai.2023.106837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationship between features and labels plays an important role in multi-label learning. The purpose of multi-label learning is to learn a mapping from the feature space to the label space. Many of the existing methods decompose the observed label matrix into the product of a low-rank latent label matrix and a projection matrix, and construct a linear mapping between the feature space and low-rank latent label space. However, in practice, the relationship between two high-dimensional spaces is often nonlinear. Consequently, these linear models may not sufficiently capture the data distribution and the true dependencies between features and labels. Herein, a novel classification model for multi-label learning is proposed, which considers nonlinear mapping from the feature space to the latent label space. Because of correlation between labels, the label matrix is usually of a low rank. To explore the low-rank structure, a latent label matrix is obtained using the decomposition of the original label matrix. To characterize the nonlinear relationship between features and latent labels, the tanh function is employed to learn a nonlinear classifier. The tanh function describes the distribution of labels by constraining the domain of the latent label space to the interval [ − 1 , 1 ] . In addition, the Frobenius norm regularization constraint is imposed on the variables in the model for optimization. The experimental results demonstrate that the proposed method is robust and comparable to state-of-the-art multi-label learning methods.},
  archive      = {J_EAAI},
  author       = {Changzhong Wang and Yan Wang and Tingquan Deng and Yang Huang},
  doi          = {10.1016/j.engappai.2023.106837},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106837},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A nonlinear multi-label learning model based on tanh mapping},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adoption of energy consumption in urban mobility considering
digital carbon footprint: A two-phase interval-valued fermatean fuzzy
dominance methodology. <em>EAAI</em>, <em>126</em>, 106836. (<a
href="https://doi.org/10.1016/j.engappai.2023.106836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued Fermatean fuzzy sets play a significant role in modelling decision-making problems with incomplete information more accurately than intuitionistic fuzzy sets. Various decision-making methods have been introduced for the different classes IFSs. In this study, we aim to introduce a novel two-phase interval-valued Fermatean fuzzy dominance method which suits the decision-making problems modelled under the IVFFS environment well and study its applications in the adoption of energy consumption in Urban mobility considering digital carbon footprint. The proposed method considers the importance and performance of one alternative with respect to all others, which is not the case with many available decision-making algorithms introduced in the literature. Transportation is one of the most significant sources of global greenhouse gas (GHG) emissions. Numerous potential remedies are proposed to reduce the quantity of GHG generated by transportation activities, including regulatory measures and public transit digitalization initiatives. Decision-makers, however, should consider the digital carbon footprint of such projects. This study proposes three alternatives for reducing GHG emissions from transportation activities: incremental adoption of digital technologies to reduce energy consumption and greenhouse gases, disruptive digitalization technologies in urban mobility, and redesign of urban mobility using regulatory approaches and economic instruments. The proposed novel two-phase interval-valued Fermatean fuzzy dominance method will be utilized to rank these alternative projects in order of advantage. First, the problem is converted into a multi-criterion group decision-making problem. Then a novel two-phase interval-valued Fermatean fuzzy dominance method is designed and developed to rank the alternatives. The importance and advantage of the proposed two-phase method over other existing methods are discussed by using sensitivity and comparative analysis. The results indicate that rethinking urban mobility through governmental policies and economic tools is the least advantageous choice, while incremental adoption of digital technologies is the most advantageous.},
  archive      = {J_EAAI},
  author       = {Jeevaraj S. and Ilgin Gokasar and Muhammet Deveci and Dursun Delen and Bilal Bahaa Zaidan and Xin Wen and Wen-Long Shang and Gang Kou},
  doi          = {10.1016/j.engappai.2023.106836},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106836},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adoption of energy consumption in urban mobility considering digital carbon footprint: A two-phase interval-valued fermatean fuzzy dominance methodology},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Product online multidimensional ratings aggregation
decision-making model based on group division and attribute interaction.
<em>EAAI</em>, <em>126</em>, 106835. (<a
href="https://doi.org/10.1016/j.engappai.2023.106835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to develop a novel approach to product online ratings aggregation decision-making, which can provide method support for consumers to obtain useful decision-making knowledge and more credible product ranking results. First, the personalized characteristics contained in the information disclosed by rating individual user are mined to establish the credibility model supporting individual weight allocation, and the multi-level division mechanism is designed to propose the aggregation method of group ratings. Then, the intuitionistic fuzzy improved normalized Bonferroni mean with weighted interaction (IFINWIBM) operator is defined, which can apply to aggregate product multidimensional ratings. Moreover, driven by expert knowledge and large-scale ratings, the learning mechanism of operator parameters is designed to describe the degree of interaction between attributes, which can avoid the unscientific caused by subjectivity. We further develop an online multidimensional ratings aggregation decision-making model to solve the product ranking problem. Finally, a numerical example and comparative analysis are given to illustrate the feasibility and advantages of the proposed method, which can reduce the interference of false groups on large-scale information aggregation and improve the rationality of attribute interaction coefficient acquisition.},
  archive      = {J_EAAI},
  author       = {Yi Yang and Feifan Yang and Guodong Yi and Danxia Xia and Jieyue Li},
  doi          = {10.1016/j.engappai.2023.106835},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106835},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Product online multidimensional ratings aggregation decision-making model based on group division and attribute interaction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bridging the gap between AI and the industry — a study on
bearing fault detection in PMSM-driven systems using CNN and inverter
measurement. <em>EAAI</em>, <em>126</em>, 106834. (<a
href="https://doi.org/10.1016/j.engappai.2023.106834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning-based identification and diagnosis of faults in industrial assets has received much attention. It does not need a deep understanding of the target domain or complex signal-processing techniques for time-consuming feature identification and selection. The vast majority of approaches developed in this field rely on public data recorded in laboratory conditions with high-performance measurement equipment. Moreover, primarily vibration data is used for condition monitoring tasks, which is particularly sensitive to typical error patterns in rotating machinery. These conditions are difficult to maintain in industrial environments since using high-performance measurement systems would not be economically feasible. This paper demonstrates that modern deep learning can achieve extraordinary fault detection results with industrial standard low-cost measurement systems. We determine measurements taken from the industrial-sensory equipment that potentially capture the system’s fault patterns. Hereafter, we apply traditional failure detection and identification techniques to evaluate the suitability of the taken measurements for bearing fault detection. These techniques apply envelope analysis to reveal the fault patterns in the signals and a support vector machine to separate the fault classes. We can conclude that the used low-cost sensory equipment is capable to capture meaningful, fault-describing patterns. To improve the failure detection performance we are investigating a 2D, as well as 1D, convolutional neural network approach to identify the error patterns and classify the respective errors. We compare the deep-learning-based methods with the traditional methods. Furthermore, we assess which inverter signal carries the largest fault-describing information content. Experimental results indicate that the proposed deep learning methods outperform traditional fault diagnosis methods, hence, demonstrating the effectiveness in an industrial condition monitoring application.},
  archive      = {J_EAAI},
  author       = {Philipp N. Mueller and Lukas Woelfl and Suat Can},
  doi          = {10.1016/j.engappai.2023.106834},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106834},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bridging the gap between AI and the industry — a study on bearing fault detection in PMSM-driven systems using CNN and inverter measurement},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DLIRIR: Deep learning based improved reverse image
retrieval. <em>EAAI</em>, <em>126</em>, 106833. (<a
href="https://doi.org/10.1016/j.engappai.2023.106833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep feature search has transpired as a sub-problem of large-scale Reverse Image Retrieval (RIR) algorithms in computer vision. In light of recent progress, transforming deep features into binary codes and employing various search strategies to delineate similar images has gained popularity. However, these binary codes cannot accurately define the similarity between two images, which is essential for image retrieval. Moreover, when retrieving k closest images, the existing RIR approaches show a drop in precision value as k increases. In this paper, we put forward a method, Deep Learning based Improved Reverse Image Retrieval (DLIRIR), which solves the RIR problem by utilizing a deep neural network, clustering methodology, and dimensionality reduction technique. Motivated by the need to prevent information loss in converting deep features to binary codes and reduce search time, we cluster image features and select some features from each cluster called Representative Points (RPs). These RPs are then compared to features of an image (query) to retrieve images similar to it from the database. The Euclidean distances of the query feature and the RPs indicate similarity between the query and the cluster of images represented by that RP. We reduce the number of comparisons by selecting as few RPs as possible. We evaluate the performance of DLIRIR by comparing it with other state-of-the-art algorithms in the RIR domain. Our method achieves a precision greater than 99% in benchmark datasets Caltech 256, Corel 10k, and Adaptiope, while a precision between 80%–85% on large size datasets Cifar 100, Tiny ImageNet, and VGGFace2.},
  archive      = {J_EAAI},
  author       = {Divya Singh and Jimson Mathew and Mayank Agarwal and Mahesh Govind},
  doi          = {10.1016/j.engappai.2023.106833},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106833},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DLIRIR: Deep learning based improved reverse image retrieval},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient intelligent task management in autonomous
vehicles using AIIOT and optimal kernel adaptive SVM. <em>EAAI</em>,
<em>126</em>, 106832. (<a
href="https://doi.org/10.1016/j.engappai.2023.106832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast evolution of artificial intelligence (AI) and the IoT gained more interest in the development of autonomous vehicles. The main challenges faced by autonomous car manufacturers are high computation costs and the lag of intelligent task management systems. The accident rates created by autonomous vehicles are increasing rapidly due to their unrestrained traffic, inaccurate location, and mapping methods. So, secure driving becomes the main concern in self-driving vehicle design. Moreover, the inadequate battery life and computation power made the system complex to minimize execution time as well as resource computation. Therefore, to handle all these complications, an intelligent task-managing system for autonomous vehicles is proposed in this paper. In this, each task is optimally executed by invoking the supervised resource predictor kernel data adaptive support vector machine-based multimodal bacterial foraging (KDASVM-MBF) method. The KDASVM-MBF intelligent task scheduling method is proposed to distribute all the tasks to the suitable processor based on central processing unit (CPU) usage and emergency. The proposed model is implemented in Python IDE-version 3.8 and examined using two multicore processors (Nvidia and AIIoT). The potential capability of the introduced type is evaluated by computing the performance methods such as response time, resource utilization, CPU utilization, execution time, prediction accuracy, and task miss rate. The experimental results reveal that the established KDASVM-MBF method accomplishes prediction accuracy of about 97% and 98% for Nvidia and AIIoT processors respectively with minimum task miss rate and execution time.},
  archive      = {J_EAAI},
  author       = {Ravikumar Sethuraman and Jeyalakshmi S. and Sekar Sellappan and Chitra Sundramiah and Isaiyarasi Thangarajan and Nagarani Velusamy},
  doi          = {10.1016/j.engappai.2023.106832},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106832},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient intelligent task management in autonomous vehicles using AIIOT and optimal kernel adaptive SVM},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Outranking-based failure mode and effects analysis
considering interactions between risk factors and its application to
food cold chain management. <em>EAAI</em>, <em>126</em>, 106831. (<a
href="https://doi.org/10.1016/j.engappai.2023.106831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effects analysis (FMEA) is helpful to control potential risks of enterprises by ranking failure modes based on their evaluation values regarding multiple risk factors. However, due to the cognitive limitation of experts, obtaining explicit evaluation of failure modes is difficult; in addition, existing literature on FMEA rarely considered interactions between risk factors. To bridge these research gaps, this paper proposes an outranking-based hesitant fuzzy linguistic FMEA method. Firstly, inspired by the PROMETHEE-II and the best-worst method, the outranking relation between each failure mode and the best or the worst failure mode is determined, so as to reduce the number of pairwise comparisons. Also, the hesitant fuzzy linguistic term set is used to express the ambiguity of expert judgments regarding the comparisons of failure modes. The Choquet integral is applied to integrate the scores of risk factors considering their interactions. Finally, the proposed method is implemented in an example of food cold chain risk assessment. Results shows that failure modes with high risks are the illness of cold chain workers, product loss and long-time transportation. This study contributes theories about managing ranking efficiency of failure modes in FMEA under fuzzy evaluation environment with interactive risk factors when addressing food cold chain risk evaluation problems.},
  archive      = {J_EAAI},
  author       = {Huchang Liao and Zhiyao Hu and Zhiying Zhang and Ming Tang and Audrius Banaitis},
  doi          = {10.1016/j.engappai.2023.106831},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106831},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Outranking-based failure mode and effects analysis considering interactions between risk factors and its application to food cold chain management},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LIDN: A novel light invariant image dehazing network.
<em>EAAI</em>, <em>126</em>, 106830. (<a
href="https://doi.org/10.1016/j.engappai.2023.106830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand for efficient image dehazing solutions in computer vision algorithms, particularly for autonomous systems, a research focus on low-inference time yet high-performance dehazing techniques has emerged. Existing dehazing methods predominantly rely on either daytime or nighttime haze models, limiting their effectiveness in handling haziness under varying lighting conditions. To address this limitation, this research paper introduces the Light Invariant Dehazing Network (LIDN), an end-to-end image dehazing network consisting of four sub-modules: Feature Extractor, Deep Global Atmospheric Light Estimator, Medium Transmission Extractor, and Encoder-Decoder. The proposed model, trained using Quadruplet loss, effectively reduces artifacts and produces sharper dehazed images. Extensive experiments conducted under diverse lighting conditions demonstrate the superior performance of the proposed LIDN model compared to state-of-the-art daytime and nighttime dehazing approaches. Remarkably, the proposed model achieves these exceptional results with a runtime of only 0.24s per image, making it highly efficient than existing dehazing algorithms.},
  archive      = {J_EAAI},
  author       = {Asfak Ali and Avra Ghosh and Sheli Sinha Chaudhuri},
  doi          = {10.1016/j.engappai.2023.106830},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106830},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LIDN: A novel light invariant image dehazing network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent diagnosis method for oil-well pump leakage
fault in oilfield production internet of things system based on
convolutional attention residual learning. <em>EAAI</em>, <em>126</em>,
106829. (<a
href="https://doi.org/10.1016/j.engappai.2023.106829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of Things (IoT) system for oil field production, oil-well pump leakage is one of the most challenging faults to detect. Once the pump leakage fault occurs, it will severely impact crude oil production. Therefore, accurate diagnosis of oil-well pump leakage faults is highly necessary. However, achieving accurate diagnosis through existing artificial intelligence methods remains a challenge due to the prolonged and progressive nature of oil-well pump leakage faults. This paper proposes a novel methodology for diagnosing oil-well pump leakage. Specifically, we propose a time-series data transformation method that ingeniously transforms difficult-to-identify pump leakage long time-series data variation features into image pixel-level texture features, and based on the characteristics of differences in image texture features under different states, we propose the structure of convolutional residual blocks with attributes and spatial attention for oil-well pump leakage fault diagnosis, which enables more accurate fault diagnosis by assigning more attention weights to extract valuable fault information. Through extensive experimentation, we found that the diagnosis process proposed in this paper outperforms sequence models such as LSTM and GRU, achieving a diagnostic accuracy of 98.36% for oil-well pump leakage faults. Moreover, it leads to a significant improvement of 19.40% and 10.36% in accuracy compared to conventional CNN and ResNet models, respectively. Therefore, in the actual production of oilfields, this method can effectively meet the detection requirements for oil-well pump leakage.},
  archive      = {J_EAAI},
  author       = {Zongchao Huang and Kewen Li and Cuihong Ke and Hongjie Duan and Mei Wang and Shaoqiang Bing},
  doi          = {10.1016/j.engappai.2023.106829},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106829},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intelligent diagnosis method for oil-well pump leakage fault in oilfield production internet of things system based on convolutional attention residual learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Theoretical investigations on the purification of petroleum
using catalytic hydrodesulfurization process: AI optimization of SO2
emission and process cost. <em>EAAI</em>, <em>126</em>, 106828. (<a
href="https://doi.org/10.1016/j.engappai.2023.106828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of SO 2 emission and the process cost in catalytic hydrodesulfurization (HDS) is of great importance for the petroleum industry. Given that the process of HDS is complicated, machine learning-based models are suitable for the purpose of process optimization in which the cost and separation efficiency can be optimized efficiently. In this investigation, we are working with a data collection on the HDS process to model via machine learning models. Pressure, temperature, initial sulfur content, and catalyst dose constitute the inputs for the models. Outputs include sulfur concentration (ppm), emission of gas (%), and HDS process cost ($). To model the process, for the first time, four tree-based ensemble methods are developed including Gradient Boosting, Extreme gradient boosting, Random Forest, and Extra Trees to optimize the HDS process. The models tuned on the available dataset and then the best ones selected for each output For sulfur concentration the extra tree model is the most accurate and for other outputs extreme gradient boosting has the best performance. For the models, the R 2 scores for outputs are 0.983, 0.982, and 0.995, respectively.},
  archive      = {J_EAAI},
  author       = {Dalal A. Alshammari and Ahmad J. Obaidullah and Mohammad A. Khasawneh and Mohamed A. El-Sakhawy and Safaa M. Elkholi and Mustafa Fahem Albaghdadi},
  doi          = {10.1016/j.engappai.2023.106828},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106828},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Theoretical investigations on the purification of petroleum using catalytic hydrodesulfurization process: AI optimization of SO2 emission and process cost},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explainable conformance checking: Understanding patterns of
anomalous behavior. <em>EAAI</em>, <em>126</em>, 106827. (<a
href="https://doi.org/10.1016/j.engappai.2023.106827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in the execution of business processes in the organizations has a high level of complexity due to the consideration of various process perspectives and their constraints, business rules, privacy policies, and regulations. Furthermore, only detection of anomalies is not sufficient. There is a crucial need for the results of anomaly detection to be explainable and interpretable, enabling users to adapt the decision making process and handle the detected anomalies. The work presented in this paper aims to provide business process owners with human-interpretable explanations for patterns of deviations found between process models and event data recorded during the execution of business processes, while traditional conformance checking methods only report low-level deviations found. First, by introducing an automated approach for multi-perspective conformance checking and anomaly detection in business process executions, we extract expected and unexpected behavior from event logs and identify patterns in deviations. Finally, by focusing on identifying the context involved in patterns of unexpected behavior, our approach facilitates the interpretations of detected patterns. The approach has been implemented in the open source ProM framework and its applicability is evaluated through a real-life dataset from a financial organization. The experiment not only shows that we can automatically detect more complex anomalies such as spurious data processing and misusage of authorizations, but also that we can explain these deviations in context.},
  archive      = {J_EAAI},
  author       = {Azadeh Sadat Mozafari Mehr and Renata M. de Carvalho and Boudewijn van Dongen},
  doi          = {10.1016/j.engappai.2023.106827},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106827},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable conformance checking: Understanding patterns of anomalous behavior},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Short-term district power load self-prediction based on
improved XGBoost model. <em>EAAI</em>, <em>126</em>, 106826. (<a
href="https://doi.org/10.1016/j.engappai.2023.106826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed generation and diversified loads increase the uncertainty of district power prediction. Useful prediction requires a highly accurate model, and there are several challenges facing the designers of a new power system with intelligent power distribution. To solve them, we improved an XGBoost model from three aspects: model, data, and performance. This paper proposes an XGBoost model with a windowed mechanism and random grid search (WR-XGBoost model) for self-prediction of short-term district power load. Specifically, a causal sliding window with different strides is introduced into the model optimization stage to process the training and test sets separately. In data optimization, the model initially processes the data organized in forms and then uses discrete difference data as input. Finally, in optimizing the performance, a random grid search method reduces the debugging of hyperparameters. The results show that the WR-XGBoost model outperforms five comparison models in terms of predictive power and generalization, using four datasets and seven statistical indicators.},
  archive      = {J_EAAI},
  author       = {Wangbin Cao and Yanping Liu and Huawei Mei and Honglin Shang and Yang Yu},
  doi          = {10.1016/j.engappai.2023.106826},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106826},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Short-term district power load self-prediction based on improved XGBoost model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Research on real-time detection method of rail corrugation
based on improved ShuffleNet v2. <em>EAAI</em>, <em>126</em>, 106825.
(<a href="https://doi.org/10.1016/j.engappai.2023.106825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail corrugation is a common wear mechanism of high-speed railways and subways, which can cause derailment and running noise. However, rail corrugation only has slight texture change on the rail surface, so it is difficult to detect accurately by traditional detection methods. In this paper, a real-time detection method of rail corrugation based on machine vision and a convolutional neural network is proposed, which effectively improves the accuracy and efficiency of rail corrugation detection. Combined with the gray features of each part of the image, a rail surface segmentation method based on the gray maximum value of the sliding window is also proposed. Moreover, the obtained rail surface image is clearer and the feature information of the rail surface can be completely retained, compared with the adaptive threshold segmentation and edge detection segmentation. ShuffleNet V2, a lightweight convolutional neural network, was selected as the corrugation detection model. The squeeze-and-excitation module was integrated into its basic unit to improve its channel attention, and the activation function was re-selected to make the detection have better real-time performance and accuracy. Through experimental verification, the average detection time of a single image of the improved model is 4.01ms, and the detection accuracy is 2.78% higher than that of the unimproved ShuffleNet V2. The research results will be beneficial to the development of the intelligent real-time detection of rail corrugation.},
  archive      = {J_EAAI},
  author       = {Hongjuan Yang and Jiaxin Liu and Guiming Mei and Dongsheng Yang and Xingqiao Deng and Chao Duan},
  doi          = {10.1016/j.engappai.2023.106825},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106825},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on real-time detection method of rail corrugation based on improved ShuffleNet v2},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data analysis for panoramic x-ray selection: Fermatean fuzzy
type correlation coefficients approach. <em>EAAI</em>, <em>126</em>,
106824. (<a
href="https://doi.org/10.1016/j.engappai.2023.106824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interval-valued Fermatean hesitant fuzzy set (IVFHFS) not only can be regarded as the union of some interval-valued Fermatean fuzzy sets (IVFFSs) but also represent the Fermatean hesitant fuzzy elements (FHFEs) in the form of interval values. So IVFHFSs are extensions of FHFSs and IVFFSs, which are powerful tools to represent more complicated, uncertain, and vague information. This paper focuses on the four kinds of correlation coefficients for FHFSs and extends them to the correlation coefficients and the weighted correlation coefficients for IVFHFSs. In the processing, we develop the least common multiple expansion (LCME) methods to solve the problem that the cardinalities of Fermatean hesitant fuzzy elements (FHFEs) (or interval-valued Fermatean hesitant fuzzy elements (IVPHFEs)) are different. In addition, we propose score functions and accuracy functions of FFEs (or IVFFEs) to rank all the FFEs (or IVFFEs) in an FHFE (or an IVFHFE). Especially, score functions and accuracy functions of IVFFEs are both presented as interval numbers. Then use the comparison method of interval numbers to compare two revised IVFHFEs in order to keep the original fuzzy information as far as possible. What is more, we define the local correlations and local informational energies which can depict the similarity between two IVFHFEs more meticulously and completely. At last, the numerical examples show the feasibility and applicability of the proposed methods in multiple criteria decision-making (MCDM) and clustering analysis.},
  archive      = {J_EAAI},
  author       = {Murat Kirişci},
  doi          = {10.1016/j.engappai.2023.106824},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106824},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data analysis for panoramic X-ray selection: Fermatean fuzzy type correlation coefficients approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SReResNet: A stage recursive residual network for
suppressing semantic redundancy during feature extraction.
<em>EAAI</em>, <em>126</em>, 106823. (<a
href="https://doi.org/10.1016/j.engappai.2023.106823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction neural networks are essential components of computer vision systems. As the most famous one, ResNet has been widely used in engineering. Although many modern networks have outperformed ResNet, the costly pretraining and hyper-parameter optimization processes prevent their application of them in industrial computer vision systems. To avoid these costly processes, a Stage Recursive Residual Network (SReResNet) is proposed, which merely adjusts the forward propagation pipeline without changing the parameter architecture of ResNet. Thus, it can inherit existing model parameters of ResNet and replace ResNet through simple fine-tuning. Moreover, SReResNet is the first network to improve accuracy by utilizing the semantic trend during feature extraction instead of well-designed modules. It models a series of cascaded modules as a semantic unit and feeds the high-level feature maps back to the low-level modules for further semantic redundancy suppression through one feedback connection within the unit based on the semantic trend and the mechanism of looking and thinking twice. For object detection tasks, a Stage Recursive Feature Pyramid Network (SReFPN) is also proposed to rethink and suppress semantic redundancy further. Experiments demonstrate that SReResNet outperforms its counterparts in object detection and image classification tasks. On the MS COCO 2017 dataset, SReResNet outperforms ResNet with 1.2 Box AP improvement, and SReResNet with SReFPN further achieves 2.5 Box AP improvement without bells and whistles. On the CIFAR-100 dataset, SReResNet outperforms its counterparts, such as ResNet, DenseNet, and ConvNeXt, with at least 2.33% top-1 acc improvement. The code is available at https://github.com/unbelieboomboom/SReResNet .},
  archive      = {J_EAAI},
  author       = {Chaojun Lin and Ying Shi and Changjun Xie and Yue Chen},
  doi          = {10.1016/j.engappai.2023.106823},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106823},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SReResNet: A stage recursive residual network for suppressing semantic redundancy during feature extraction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MPDNet: An underwater image deblurring framework with
stepwise feature refinement module. <em>EAAI</em>, <em>126</em>, 106822.
(<a href="https://doi.org/10.1016/j.engappai.2023.106822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a general network model called multi-progressive image deblurring network is proposed to correct blurring artifacts and local imaging details in underwater images. As a solution to nonuniform image distortion, a deformable convolution module was designed to enrich the encoded information of the image representation. Using a stepwise feature refinement module, multi-progressive image deblurring network can reduce the loss of contextual information to produce a more realistic underwater image for subsequent applications. Constructing a loss function based on multi-scale content can help the model improve image perception quality. We conducted experimental evaluations on large-scale image deblurring benchmark datasets, such as GoPro and HIDE, achieving excellent results with 32.84 dB and 31.03 dB peak signal-to-noise ratio, respectively, using the proposed method. Subsequently, a detailed optimization comparison was conducted on the in-house underwater image deblurring dataset. Multi-progressive image deblurring network obtained higher-quality, clearer images. Compared with the current state-of-the-art image deblurring algorithms, the proposed model achieved significant results with a 6.6% increase in deblur performance in peak signal-to-noise ratio. Finally, we conducted ablation experiments to evaluate the effectiveness of all the modules in the proposed framework.},
  archive      = {J_EAAI},
  author       = {Guangjie Han and Min Wang and Hongbo Zhu and Chuan Lin},
  doi          = {10.1016/j.engappai.2023.106822},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106822},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MPDNet: An underwater image deblurring framework with stepwise feature refinement module},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A committee machine-based estimation of shear velocity log
by combining intelligent systems and rock-physics model using
metaheuristic algorithms. <em>EAAI</em>, <em>126</em>, 106821. (<a
href="https://doi.org/10.1016/j.engappai.2023.106821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of reservoir parameters such as porosity, lithology and determination of elastic moduli is based on well-logging data and seismic velocity information. However, the lack of shear velocity log in many wells, and the high costs of its acquisition have led to developing different approaches for shear velocity estimation. Currently, shear velocity estimation is accomplished by common industrial methods such as empirical equations, regression analysis, intelligent methods and rock-physics models (RPMs). The current study proposes that robust, accurate and cost-effective intelligent methods coupled with suitable RPM provide reasonable estimations of the shear velocity in an optimal processing time. Hybridizing intelligent models with RPMs in the framework of a committee machine is an optimal solution for shear velocity estimation of carbonate reservoirs. The intelligent methods used in this study include neural network (NN), fuzzy logic (FL) and an adaptive-neuro fuzzy inference system (ANFIS). In this research, for each individual intelligent model and a developed RPM, the optimal weights were allocated by Metaheuristic optimization algorithms including genetic algorithm (GA), ant colony optimization routing (ACO R ) and simulated annealing (SA)). To obtain the best results with the lowest mean squared error (MSE), a total of 9408, 10801 and 12288 models were created and tested in MATLAB to optimally parametrize the GA, ACO R and SA, respectively. The results showed that the combination of the applied intelligent models with the developed RPMs leads to a higher correlation coefficient with reference to the measured Shear velocity in test dataset. The use of a combination of intelligent methods in the form of committee-machine instead of individual methods has led to a reduction in error and improved the results by up to 2% Considering the high sensitivity of shear wave velocity in geomechanical and reservoir characterization studies, even small improvements in its estimation can significantly reduce error in the characterization of hydrocarbon reservoirs.},
  archive      = {J_EAAI},
  author       = {Behzad Nasrnia and Reza Falahat and Ali Kadkhodaie and Ali Gholami Vijouyeh},
  doi          = {10.1016/j.engappai.2023.106821},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106821},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A committee machine-based estimation of shear velocity log by combining intelligent systems and rock-physics model using metaheuristic algorithms},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Covid-19 epidemic and regional carbon emissions: A study
based on metabolic multivariate grey model with new information
priority. <em>EAAI</em>, <em>126</em>, 106820. (<a
href="https://doi.org/10.1016/j.engappai.2023.106820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 epidemic has had an unexpected impact on global carbon emissions. In this context, carbon emission prediction is very important for policy formulation and implementation. It is worth pondering how the grey model deals with the prediction of unexpected events. Considering the spatial dependence of carbon emissions, this paper improves the multivariate grey model, gives new information a higher reference weight, and constructs a metabolic multivariate grey model -MMGM(1,m | λ ) which takes new information as the priority. An optimization algorithm is constructed with the minimum error as the goal to determine the value of the weight adjustment parameter λ . Then we simulate and predict the carbon emissions of three regions: China’s Yangtze River Delta (Shanghai, Jiangsu, Zhejiang, and Anhui), the North American Free Trade Area (Canada, Mexico, and the US), and West Europe (the UK and France). These three cases have different regions, different numbers of behavioural variables, different degrees of influence by COVID-19, and different trends, which are comparative. The results show that the new model has a good fitting effect, and it is still applicable in dealing with unexpected events. The new model can reflect regional carbon emission changes more systematically and accurately. Finally, according to cases and discussions, we get some management enlightenment to promote regional environmental collaborative governance.},
  archive      = {J_EAAI},
  author       = {Pingping Xiong and Xiaojie Wu and Xiaosu Zeng and Lingshan Hu and Xue Yan},
  doi          = {10.1016/j.engappai.2023.106820},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106820},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Covid-19 epidemic and regional carbon emissions: A study based on metabolic multivariate grey model with new information priority},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A novel acoustic emission signal segmentation network for
bearing fault fingerprint feature extraction under varying speed
conditions. <em>EAAI</em>, <em>126</em>, 106819. (<a
href="https://doi.org/10.1016/j.engappai.2023.106819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acoustic emission (AE) technique is known for its sensitivity to early damage and is well-suited for online condition monitoring of rolling element bearings (REBs) in various industrial application scenarios. Nonetheless, identifying weak faults under varying speed and strong background noise conditions still remains challenging. In addition, the comprehensive modelling of AE signal from faulty REB in electromechanical systems is still a pending issue. In light of this, a well-considered model is firstly developed for the AE signal of faulty REBs in this work. After that, a novel bearing fault diagnosis framework based on semantic segmentation networks is devised. Precisely, the proposed framework consists of three main components: a preprocessing step depending on the signal segmentation algorithm, a diagnosis step using fault fingerprint mapping, and a postprocessing evaluation step supplemented by a density peak clustering (DPC) approach. We evaluate the presented procedures through simulation analysis and an experimental case under varying speed conditions. Meanwhile, the comparison with the original threshold-based fault fingerprint recognition algorithm is also conducted. The comprehensive results demonstrate the efficacy of identifying fault-associated fingerprint feature (FPF), indicating that the proposed framework holds promise for condition monitoring.},
  archive      = {J_EAAI},
  author       = {Zongyang Liu and Hao Li and Jing Lin and Jinyang Jiao and Tian Shen and Boyao Zhang and Hanyang Liu},
  doi          = {10.1016/j.engappai.2023.106819},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106819},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel acoustic emission signal segmentation network for bearing fault fingerprint feature extraction under varying speed conditions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Plant intelligence-based PILLO underwater target detection
algorithm. <em>EAAI</em>, <em>126</em>, 106818. (<a
href="https://doi.org/10.1016/j.engappai.2023.106818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development in the field of marine exploration, underwater robots play an increasingly important role in the military, fisheries, aquaculture, resource protection, etc. The main way for underwater robots to obtain information is underwater target detection, and the development of underwater robots is inseparable from the development of underwater target detection technology. Existing target detection algorithms have achieved good results on land, but are often unsatisfactory in actual underwater target detection. In this paper, based on the principle of plant intelligence and the target detection algorithm YOLOv5, our proposes the PILLO algorithm to adapt to the underwater environment with blurred imaging and insufficient light, and is specially used for underwater target detection. Specifically, the Swin Transformer is improved based on the principles of the multicore plant intelligence model, which then replaces part of the backbone network of the PILLO algorithm. The Shuffle Attention mechanism is improved based on the principles of the plant logical space transfer mechanism and added to the neck network of the PILLO algorithm. The SIOU loss function was improved based on the principle of the plant ecological regulation module and applied to the PILLO algorithm. The experimental results show that the PILLO model can improve the average accuracy (mAP) of underwater target detection by 87.1%, which is better than the common target detection model.},
  archive      = {J_EAAI},
  author       = {Lizhao Liu and Pinrui Li},
  doi          = {10.1016/j.engappai.2023.106818},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106818},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plant intelligence-based PILLO underwater target detection algorithm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tutorial on time series prediction using 1D-CNN and BiLSTM:
A case example of peak electricity demand and system marginal price
prediction. <em>EAAI</em>, <em>126</em>, 106817. (<a
href="https://doi.org/10.1016/j.engappai.2023.106817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although research on time series prediction based on deep learning is being actively carried out in various industries, deep learning technology still has a high entry barrier for researchers who have not majored in computer science. This paper presents a tutorial on time series prediction using a deep learning-based model. The entire process of time series data prediction is presented—from data collection to evaluation of prediction results. The details of each step are shown through a case example of predicting peak electricity demand and system marginal price of Jeju Island in Korea using the 1D-CNN and BiLSTM model. In Jeju Island, the proportion of renewable energy in the total power generation capacity is increased to 67% in 2021, requiring more accurate electricity demand forecasts. Therefore, using 808 days of training data from February 2018, electricity demand and SMP for the next 21 days were predicted. To make it easier for readers to follow, the example uses only open public data, and the entire Python source code is shared via a GitHub repository. The prediction error calculated by WRMSSE showed 0.42 in electricity demand and 0.63 in SMP max. A WRMSSE value less than one means that the forecast was relatively good, that is, better than naïve forecasting. This tutorial is not limited to the energy industry but can be utilized for any application requiring time-series data prediction. This article is expected to be of great help to researchers who need to understand the process of time series prediction using deep learning and use it for application in their industry.},
  archive      = {J_EAAI},
  author       = {Jaedong Kim and Seunghwan Oh and Heesoo Kim and Woosung Choi},
  doi          = {10.1016/j.engappai.2023.106817},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106817},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tutorial on time series prediction using 1D-CNN and BiLSTM: A case example of peak electricity demand and system marginal price prediction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Single-shot pruning and quantization for hardware-friendly
neural network acceleration. <em>EAAI</em>, <em>126</em>, 106816. (<a
href="https://doi.org/10.1016/j.engappai.2023.106816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying CNN on embedded systems is challenging due to model size limitations. Pruning and quantization can help, but are time-consuming to apply separately. Our Single-Shot Pruning and Quantization strategy addresses these issues by quantizing and pruning in a single process. We evaluated our method on CIFAR-10 and CIFAR-100 datasets for image classification. Our model is 69.4% smaller with little accuracy loss, and runs 6–8 times faster on NVIDIA Xavier NX hardware.},
  archive      = {J_EAAI},
  author       = {Bofeng Jiang and Jun Chen and Yong Liu},
  doi          = {10.1016/j.engappai.2023.106816},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106816},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Single-shot pruning and quantization for hardware-friendly neural network acceleration},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HOMOCHAR: A novel adversarial attack framework for exposing
the vulnerability of text based neural sentiment classifiers.
<em>EAAI</em>, <em>126</em>, 106815. (<a
href="https://doi.org/10.1016/j.engappai.2023.106815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art deep learning algorithms have demonstrated remarkable proficiency in the task of text classification. Despite the widespread use of deep learning-based language models, there remains much work to be done in order to improve the security of these models. This is particularly concerning for their growing use in sensitive applications, such as sentiment analysis. This study demonstrates that language models possess inherent susceptibility to textual adversarial attacks, wherein a small number of words or characters are modified to produce an adversarial text that deceives the machine into producing erroneous predictions while maintaining its true meaning for human readers. The current study offers HOMOCHAR, a novel textual adversarial attack that operates within a black box setting. The proposed method generates more robust adversarial examples by considering the task of perturbing a text input with transformations at the character level. The objective is to deceive a target NLP model while adhering to specific linguistic constraints in a way such that the perturbations are imperceptible to humans. Comprehensive experiments are performed to assess the effectiveness of the proposed attack method against several popular models, including Word-CNN, Word-LSTM along with five powerful transformer models on two benchmark datasets, i.e., MR &amp; IMDB utilized for sentiment analysis task. Empirical findings indicate that the proposed attack model consistently attains significantly greater attack success rates (ASR) and generates high-quality adversarial examples when compared to conventional methods. The results indicate that text-based sentiment prediction techniques can be circumvented, leading to potential consequences for existing policy measures.},
  archive      = {J_EAAI},
  author       = {Ashish Bajaj and Dinesh Kumar Vishwakarma},
  doi          = {10.1016/j.engappai.2023.106815},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106815},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HOMOCHAR: A novel adversarial attack framework for exposing the vulnerability of text based neural sentiment classifiers},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy-aided finite-time frequency controller of
renewable-integrated power systems with hydrogen energy storage.
<em>EAAI</em>, <em>126</em>, 106814. (<a
href="https://doi.org/10.1016/j.engappai.2023.106814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable frequency regulation of power systems integrated with low-inertia variable renewable energy generations (REGs) is crucial in islanded mode operation. It demands a resilient control framework to uphold grid stability/security against undeniable physical disturbances/cyber-attacks. This work maidenly develops and applies a fuzzy disturbance observer (FDO)-based resilient frequency controller to advance the dynamic stability of REGs-integrated large-scale power plants. Further, to enhance the damping of frequency/power oscillations, hydrogen energy storage (HES) has been incorporated, and its effectiveness is analyzed. The estimated disturbance using FDO is augmented into secondary control law derived from a non-singular terminal sliding mode strategy to increase active disturbance rejection proficiency of the overall closed-loop system. The global exponential finite-time stability of the testbed under the developed control framework has been rigorously reviewed using the Lyapunov theory. The qualitative assessment of simulation outcomes has confirmed the proficiency and resiliency of the developed control framework regarding superior frequency regulation against unknown disturbance inputs. The practicability of the developed control framework has been further quantified on IEEE 68-bus large-scale testbed, and a comparative study is presented following unknown/uncertain disturbances. Lastly, the cyber-tolerance of the applied resilient controller has been established against detectable DoS cyber-attack.},
  archive      = {J_EAAI},
  author       = {Dipayan Guha},
  doi          = {10.1016/j.engappai.2023.106814},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106814},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy-aided finite-time frequency controller of renewable-integrated power systems with hydrogen energy storage},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The role of artificial intelligence and digital technologies
in dam engineering: Narrative review and outlook. <em>EAAI</em>,
<em>126</em>, 106813. (<a
href="https://doi.org/10.1016/j.engappai.2023.106813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This narrative review paper explores the diverse applications of artificial intelligence (AI) in the field of dam engineering. Authored by research engineers specializing in civil engineering and data science, and reviewed by experienced dam engineers and AI experts, the paper aims to provide a comprehensive overview of the subject. The paper is structured into three parts. Part 1 offers a concise introduction to AI, covering its historical background, major categories, and current state of development. In Part 2, the focus shifts to the specific applications of AI in hydropower and dam engineering. This section delves into the utilization of AI for predictive modeling, real-time monitoring, optimization, and planning and design. Notable case studies and examples of machine learning techniques applied to predictive models and numerical simulations in the context of dams and levees are also discussed. Part 3 explores the current and emerging technologies being implemented in the industry, including automated decision-making systems and the use of AI-powered drones for efficient dam inspection. Additionally, the section sheds light on the challenges that must be addressed to fully integrate AI into dam engineering practices. This paper targets dam engineers, AI experts, and individuals interested in the intersection of these fields. Its primary contribution lies in providing a comprehensive and up-to-date review of the applications, challenges, and potential future developments of AI in dam engineering. Over 3300 articles on the intersection of dam engineering and AI were identified, and approximately 550 articles (about 17%) were further processed for inclusion in this study. Moreover, it emphasizes the need for robust data management, algorithmic transparency, and ethical considerations in the implementation of AI systems.},
  archive      = {J_EAAI},
  author       = {M. Amin Hariri-Ardebili and Golsa Mahdavi and Larry K. Nuss and Upmanu Lall},
  doi          = {10.1016/j.engappai.2023.106813},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106813},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The role of artificial intelligence and digital technologies in dam engineering: Narrative review and outlook},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hesitant hierarchical t–s fuzzy system with fuzzily weighted
recursive least square. <em>EAAI</em>, <em>126</em>, 106812. (<a
href="https://doi.org/10.1016/j.engappai.2023.106812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical fuzzy systems have been an increasingly prevalent research topic, however, most of them are with fixed structures. This could reduce the flexibility of the method in applications and make it difficult to build an elastic multilayer structure for different input information. Hesitant fuzzy set (HFS) consists of rich and flexible hesitant fuzzy elements, which have been widely developed and applied in recent years, and related basic concepts and theories have been constantly developed and improved. By using the flexible expressing capabilities of HFS, we constructively construct a new serial-based hierarchical fuzzy system with flexible and adaptive rules in each layer, named after hesitant hierarchical T–S fuzzy system (HHFS). In the general HHFS, lengths of HFS elements play an important role generating constructions of each layer and consequent parameters of rules are adjusted by fuzzily weighted recursive least square method. It is the first time to build a multilayer fuzzy system using HFS. To adapt HHFS into the application of maneuvering target tracking, another newly adapted one, time-sequential hesitant fuzzy set (TSHFS) is utilized. The function of the conventional HFS is still generating structures of subsystems, and the TSHFS is utilized to optimize parameters of consequent parts with the new proposed approach for fluctuated hesitant information under TSHFS environment. In HHFS, the rules of subsystems are adaptively changeable according to different inputs, namely subsystems of each layer are with variant structures. Compared with state-of-the-art algorithms, the effectiveness and advantage of HHFS are exhibited in various experiments.},
  archive      = {J_EAAI},
  author       = {Lingyu Meng and Weixin Xie and Liangqun Li and Yanshan Li and Zongxiang Liu},
  doi          = {10.1016/j.engappai.2023.106812},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106812},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hesitant hierarchical T–S fuzzy system with fuzzily weighted recursive least square},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of sustainable strategies for urban parcel
delivery: Linguistic q-rung orthopair fuzzy choquet integral approach.
<em>EAAI</em>, <em>126</em>, 106811. (<a
href="https://doi.org/10.1016/j.engappai.2023.106811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the first time, the critical problem of selecting the most sustainable strategy for urban parcel delivery is addressed and solved in this paper. It aims to help not only postal and logistics companies but also regulatory agencies and city authorities find an environmentally friendly, socially responsible, and economically viable solution. Three alternatives for organizing urban parcel delivery are defined, which are traditional, united consolidation center, and inner-city hubs. According to the three pillars of sustainability, an assessment framework for practitioners is proposed. This paper introduces a linguistic q-rung orthopair fuzzy Choquet integral approach to evaluate sustainable strategies for urban parcel delivery. The linguistic q-rung orthopair fuzzy Choquet integral averaging and linguistic q-rung orthopair fuzzy Choquet integral geometric operators have been constructed for the first time for this purpose. The operator-related qualities are demonstrated. The operators are used to create a multi-criteria group decision-making approach. The case study of the city of Belgrade illustrates the practical applicability of the linguistic q-rung orthopair fuzzy Choquet integral approach. This research findings show that the united consolidation center is the most sustainable strategy for organizing urban parcel delivery.},
  archive      = {J_EAAI},
  author       = {Chiranjibe Jana and Momčilo Dobrodolac and Vladimir Simic and Madhumangal Pal and Biswajit Sarkar and Željko Stević},
  doi          = {10.1016/j.engappai.2023.106811},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106811},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluation of sustainable strategies for urban parcel delivery: Linguistic q-rung orthopair fuzzy choquet integral approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Wooden spoon crack detection by prior knowledge-enriched
deep convolutional network. <em>EAAI</em>, <em>126</em>, 106810. (<a
href="https://doi.org/10.1016/j.engappai.2023.106810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the outbreak of COVID-19, in order to reduce people’s contact, the takeaway business has been developed rapidly, bringing a large demand for disposable and degradable tableware (e.g., wooden spoon). However, in the production process of wooden spoon, the selection of crack spoons still relies on manual labour. Therefore, in order to detect cracked wooden spoons more effectively and reduce production costs, we propose a wooden spoon crack detection method by using machine vision techniques and apply it in real-world industrial factory. In the production system, the captured color of crack regions is black while the good region shows normal log color. The positions of crack regions are located frequently in the central or marginal areas of spoons and their directions of cracks are often same due to the extrusion of the mold in the production process. Based on these two types of prior knowledge (i.e., color and spatial prior information), three modules are designed to explore these priors by jointly integrating with the current mainstream detection network of YOLO-v5, which satisfies the speed and accuracy for detecting cracks. The color fusion module is designed to explore the color difference between good regions and crack regions. The attention and orientation modules are then combined and embedded into the backbone of deep architecture. Reported experiments on our collected database show that our proposed detection method can locate the spoon cracks very well and significantly outperforms the model of YOLO-v5 with the protocols of R e c a l l , P r e c i s i o n and m e a n A v e r a g e P r e c i s i o n ( m A P ) .},
  archive      = {J_EAAI},
  author       = {Lei Li and Zongwei Li and Huijian Han and Lei Yang and Xiaoyi Feng and Fabio Roli and Zhaoqiang Xia},
  doi          = {10.1016/j.engappai.2023.106810},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106810},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wooden spoon crack detection by prior knowledge-enriched deep convolutional network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ART-LSTANet: An adaptive intelligent method for wind turbine
wake analysis. <em>EAAI</em>, <em>126</em>, 106809. (<a
href="https://doi.org/10.1016/j.engappai.2023.106809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of wake effects within wind farms is paramount to elevating power generation efficiency, especially when considering the losses incurred by wake effects. In the present investigation, we introduce an innovative neural network-based model – adaptive reduction three-way long short term attention network (ART-LSTANet) – designed to augment the precision of wind turbine wake flow field predictions. Unlike conventional methodologies that often segregate the reduced-order model from the prediction procedure, our proposed model exploits adaptive order reduction to swiftly procure the necessary input for the predictive model, thus curtailing the time expenditure throughout the entire process. The predictive model subsequently incorporates carefully designed feature extraction components tailored to multiple temporal scales, with parameters being updated via a data-driven approach. A comparative analysis with six established intelligent algorithms underscores the superiority of the ART-LSTANet. Comprehensive results indicate that ART-LSTANet delivers superior performance in the reconstruction of the wake flow field, demonstrating a reduction in the mean squared error by up to 9.0% and in the root mean squared error by up to 3.3% compared to traditional methodologies. Numerical errors calculated under a spectrum of additional evaluation metrics consistently yield the lowest values.},
  archive      = {J_EAAI},
  author       = {Li Xu and Guanhao Zhou and Zhaoliang Guo},
  doi          = {10.1016/j.engappai.2023.106809},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106809},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ART-LSTANet: An adaptive intelligent method for wind turbine wake analysis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of an obstacle avoiding autonomous vehicle by
using stereo depth estimation and artificial intelligence based semantic
segmentation. <em>EAAI</em>, <em>126</em>, 106808. (<a
href="https://doi.org/10.1016/j.engappai.2023.106808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an autonomous vehicle that can avoid obstacles has been developed by using stereo imaging systems and artificial intelligence applications together. An integrated stereo camera module and NVIDIA Jetson Nano developer kit were used as computer vision system. Checkerboard calibration was performed to prevent camera distortions. The images of the cameras were rectified and the difference costs between the left and right image pairs on the same epipolar plane were calculated. These difference costs were passed through the weighted least squares (WLS) filter, thus a depth map of the left camera image was created. The rectified left camera view was also processed by artificial intelligence-based semantic segmentation. Segmentation was carried out using a previously trained artificial intelligence network (SegNet). These semantic segmentation outputs were passed through the HSV color mask and a mask image was hereby obtained. Using the mask image; movable ground, obstacle, and background information was extracted. Useful data analysis was performed on the depth map and semantic segmentation outputs of the same frame. This information is transmitted to the 2-wheeled vehicle which is designed based on ROS that provides the movement, and decisions are made within the scope of the avoidance algorithm. This study’s novel contribution involves the integration of a passive depth sensing system and artificial intelligence based semantic segmentation, in tandem with a real-time obstacle avoidance algorithm that utilizes these combined technologies. Consequently, the autonomous vehicle is capable of making semantic inferences about its environment while effectively avoiding obstacles.},
  archive      = {J_EAAI},
  author       = {Utku Ulusoy and Oğulcan Eren and Ayşe Demi̇rhan},
  doi          = {10.1016/j.engappai.2023.106808},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106808},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of an obstacle avoiding autonomous vehicle by using stereo depth estimation and artificial intelligence based semantic segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPSNet: Boosting 3D point-based object detectors with stable
point sampling. <em>EAAI</em>, <em>126</em>, 106807. (<a
href="https://doi.org/10.1016/j.engappai.2023.106807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the primary focus of 3D point-based detectors is to enhance their performance by primarily increasing the recall rate of foreground points at the semantic level. However, this approach is suboptimal. On one hand, ground-truth annotations of 3D bounding boxes are inherently ambiguous due to occlusions, signal distortion, or manual annotation errors, which can obscure genuine semantic information. On the other hand, the saliency of each point varies. In this paper, we propose SPSNet based on Bayes theorem to explore the mapping relationship between the sampled point and the corresponding bounding box, which we call point stability. This is a plug-and-play module and used as the basis for downsampling instead of relying on semantic information obtained through hard supervision of 3D bounding boxes. We incorporate the proposed method into the most popular point-based detector, IA-SSD, called SPSNet-IA. On the challenging KITTI validation set, with only changes to the downsampling strategy, it obtains 1.18, 2.78 and 2.96 gains for the metric of A P 3 D on the easy, moderate and hard levels, respectively. In addition, SPSNet-IA outperforms all published point-based approaches by a large margin and ranks 1st among single-modal methods. We also design qualitative and quantitative experiments to explain the meaning of stability learned from SPSNet. These additional experiments demonstrate that SPSNet is not only a performance-enhancing model but also a saliency analysis model. The code is available at https://github.com/AlanLiangC/SPSNet.git .},
  archive      = {J_EAAI},
  author       = {Ao Liang and Hao Zhang and Haiyang Hua and Whenyu Chen and Huaici Zhao},
  doi          = {10.1016/j.engappai.2023.106807},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106807},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SPSNet: Boosting 3D point-based object detectors with stable point sampling},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid fuzzy support vector machine approach for coconut
tree classification using image measurement. <em>EAAI</em>,
<em>126</em>, 106806. (<a
href="https://doi.org/10.1016/j.engappai.2023.106806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of trees based on morphological parameters is important for identification, taxonomy, ecological research, conservation etc. The manual measurement of these parameters is tedious, laborious, and inconsistent. Even though there are many tree classification methods based on the morphological parameters available in the literature, there is hardly any research in classification of Coconut trees based on morphological parameters. This research proposes a novel hybrid fuzzy support vector machine approach for classification of Coconut trees based on three critical morphological parameters such as height, inclination, and orientation. A fuzzy logic-based parameter measurement from image is used to estimate critical morphological parameters the from the images. An original dataset of 17000 images of Indian west coast tall Coconut trees is created to train and test the proposed method. The classification for each of the three parameters is carried out separately using fuzzy logic and support vector machine and the best classification is chosen using confidence voting method. The final classification of the Coconut trees based on all the three parameters is obtained using weight-based indexing by combining the individual outcome of confidence voting method. The results showed that the proposed architecture gives better performance than state-of-the-art classifiers, with an accuracy of 88.86%. The statistical analysis showed that the proposed architecture is stable and robust than other methods, gives least confidence interval value of ± 2.5, ± 3.2, ± 1.9 for three different datasets other than the original dataset.},
  archive      = {J_EAAI},
  author       = {Sakthiprasad Kuttankulangara Manoharan and Rajesh Kannan Megalingam and Avinash Hegde Kota and Vijaya Krishna Tejaswi P. and Kariparambil Sudheesh Sankardas},
  doi          = {10.1016/j.engappai.2023.106806},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106806},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid fuzzy support vector machine approach for coconut tree classification using image measurement},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Density-based one-shot active learning for image
segmentation. <em>EAAI</em>, <em>126</em>, 106805. (<a
href="https://doi.org/10.1016/j.engappai.2023.106805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a key step in image processing tasks, which has significant applications in computer vision field such as medical image analysis, scene understanding and video monitoring, etc. However, image segmentation tasks usually require a large number of labeled samples to obtain great performance of convolutional neural networks (CNNs). Active learning (AL) can select valuable samples for annotation, so as to reduce the annotation cost as much as possible while maintaining the performance of CNNs. Further, one-shot AL can select valuable samples by once, which eliminates the need for iterative sample selection and annotation. However, existing one-shot AL approaches extremely rely on complex clustering algorithm, which brings a limitation in practice, i.e., we often do not know how to set the hyperparameters. In this paper, we propose a clustering-free one-shot AL framework, which is based on self-supervised feature learning and density-based query strategy. Our framework can select samples with high local density robustly against hyperparameters. The experimental results are impressive that state-of-the-art one-shot active learning performance can be achieved with simple density-based sampling.},
  archive      = {J_EAAI},
  author       = {Qiuye Jin and Shiman Li and Xiaofei Du and Mingzhi Yuan and Manning Wang and Zhijian Song},
  doi          = {10.1016/j.engappai.2023.106805},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106805},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Density-based one-shot active learning for image segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous finite-time fuzzy control of mechanical systems
via non-lipschitz membership functions. <em>EAAI</em>, <em>126</em>,
106804. (<a
href="https://doi.org/10.1016/j.engappai.2023.106804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This document presents a method to construct continuous fuzzy controllers that yield finite-time stability of the closed-loop system. The proposed approach allows the user to follow classical design procedures for fuzzy systems without using other finite-time techniques such as sliding modes. The finite-time stability property is a consequence of a special kind of input membership function of the fuzzy inference system. The continuity properties of the fuzzy inference system are studied. Sufficient conditions for the output of the fuzzy inference system to be Lipschitz continuous are stated. A comparison with the asymptotic counterpart of the controller is also presented. The results support the hypothesis that finite-time controllers provide improved robustness to the steady state response.},
  archive      = {J_EAAI},
  author       = {Jorge Villalobos-Chin and Andres Pizarro-Lerma and Víctor Santibáñez and Ramón García-Hernández and Arturo Zavala-Río},
  doi          = {10.1016/j.engappai.2023.106804},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106804},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continuous finite-time fuzzy control of mechanical systems via non-lipschitz membership functions},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual learning classification method with
human-in-the-loop based on the artificial immune system. <em>EAAI</em>,
<em>126</em>, 106803. (<a
href="https://doi.org/10.1016/j.engappai.2023.106803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, most classification algorithms may suffer from serious misclassification when faced with unbalanced or new data, for lacking feedback and update capability. Many existing classification methods learn from the continuous learning mechanism in the biological immune system to realize the learning of new data. However, these methods in classifying new data, because of the lack of feedback, lead to a search for a long time, even may deviate from the correct results. Humans can make the immune response proceed to a certain extent as they wish through a variety of intervention techniques. Motivated by this, this paper proposes a continual learning classification method with human-in-the-loop (H-CLCM) based on the artificial immune system. H-CLCM adjusts parameters online corresponding to misidentified data by integrating human experience during the testing phase. This enables it not only to converge to an accurate prediction model at minimal cost but also to have the capability to learn new classes of data without retraining the classifier. Experiments on 10 benchmark datasets demonstrate the performances and advantages of the proposed method. The experimental results show that H-CLCM has superior classification performance than the other approaches under the same data.},
  archive      = {J_EAAI},
  author       = {Jia Liu and Dong Li and Wangweiyi Shan and Shulin Liu},
  doi          = {10.1016/j.engappai.2023.106803},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106803},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continual learning classification method with human-in-the-loop based on the artificial immune system},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient adaptive large neighborhood search algorithm
based on heuristics and reformulations for the generalized quadratic
assignment problem. <em>EAAI</em>, <em>126</em>, 106802. (<a
href="https://doi.org/10.1016/j.engappai.2023.106802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operations Research (OR) analytics play a crucial role in optimizing decision-making processes for real-world problems. The assignment problem, with applications in supply chains, healthcare logistics, and production scheduling, represents a prominent optimization challenge. This paper focuses on addressing the Generalized Quadratic Assignment Problem (GQAP), a well-known NP-hard combinatorial optimization problem. To tackle the GQAP, we propose an OR analytical approach that incorporates efficient relaxations, reformulations, heuristics, and a metaheuristic algorithm. Initially, we employ the Reformulation Linearization Technique (RLT) to generate various linear relaxation models, carefully selecting the most efficient ones. Building upon this foundation, we introduce a robust reformulation based on Benders Decomposition (BD), which serves as the basis for an iterative optimization algorithm applied to the GQAP. Furthermore, we develop a constructive heuristic algorithm to identify near-optimal solutions, followed by an enhancement utilizing an Adaptive Large Neighborhood Search (ALNS) metaheuristic algorithm. This ALNS algorithm is enhanced through the integration of a tabu list derived from Tabu Search (TS) and a decision rule inspired by Simulated Annealing (SA). To validate our approach and evaluate its performance, we conduct a comparative analysis against state-of-the-art algorithms documented in the literature. This comparison confirms the significant improvements achieved in terms of solution quality and computational efficiency through our proposed methodology. These advancements contribute to the state of the art in solving the GQAP and hold the potential to enhance decision-making processes in a wide range of domains. Our methodology demonstrates remarkable improvements in solution quality and computational efficiency when compared to existing approaches, as evidenced by the comparative results with state-of-the-art algorithms. The potential implications of our research extend to optimizing decision-making processes in diverse fields, rendering it highly relevant and impactful.},
  archive      = {J_EAAI},
  author       = {Amir M. Fathollahi-Fard and Kuan Yew Wong and Mohammed Aljuaid},
  doi          = {10.1016/j.engappai.2023.106802},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106802},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient adaptive large neighborhood search algorithm based on heuristics and reformulations for the generalized quadratic assignment problem},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generation of broadband spectra from physics-based
simulations using stochastic LSTM network. <em>EAAI</em>, <em>126</em>,
106801. (<a
href="https://doi.org/10.1016/j.engappai.2023.106801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop a model that predicts high-frequency response spectra and damage-related ground motion parameters using low-frequency physics-based simulations (PBS) for horizontal and vertical components. The model is a stochastic dropout-based long short-term memory (LSTM) network, which accounts for spectra interdependencies and high-frequency spectra’s stochastic nature. Adding anelastic distance as an input term significantly improved the model’s performance. Models are developed for different cutoff periods (validity of PBS low-frequency spectra): 0.75 s, 1 s, 1.5 s, and 2 s, using the 2015 Nepal main and aftershocks and combining them with global near-source strong-motion data. The models are validated using near- and far-field predictions and a good agreement with the recorded data is observed. The mean squared error, mean absolute error, and coefficient of determination for the 0.75 s horizontal model is 0.174, 0.3171, and 0.9295, respectively. Additionally, the study generates spectra and time histories for the 2001 M w 7.6 Bhuj earthquake, which had no recordings. The obtained spectral values agree well with global stable-continental region models, and the time histories could capture characteristics such as duration, amplitude, and arrival times.},
  archive      = {J_EAAI},
  author       = {Vemula Sreenath and K.P. Sreejaya and S.T.G. Raghukanth},
  doi          = {10.1016/j.engappai.2023.106801},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106801},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generation of broadband spectra from physics-based simulations using stochastic LSTM network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Projective quasi-synchronization of complex-valued recurrent
neural networks with proportional delay and mismatched parameters via
matrix measure approach. <em>EAAI</em>, <em>126</em>, 106800. (<a
href="https://doi.org/10.1016/j.engappai.2023.106800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the projective quasi-synchronization of non-identical complex-valued recurrent neural networks (CVRNNs) with proportional delays and mismatched parameters. The nonlinear Lipschitz activation functions under Lyapunov stability criteria and matrix measure approach have been employed. By designing a suitable controller, a sufficient condition for projective quasi-synchronization criteria of the non-identical CVRNNs model has been derived through the proper description of the matrix measure approach. A significant result for the CVRNNs with mismatched parameters and proportional delays is provided. Finally, a numerical simulation result is given to validate the usefulness and persistence of the theoretical results. The results for different particular cases are displayed graphically.},
  archive      = {J_EAAI},
  author       = {Ankit Kumar and Sunny Singh and Subir Das and Yang Cao},
  doi          = {10.1016/j.engappai.2023.106800},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106800},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Projective quasi-synchronization of complex-valued recurrent neural networks with proportional delay and mismatched parameters via matrix measure approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-slice nested recurrence plot (MsNRP): A robust
approach for person identification using daily ECG or PPG signals.
<em>EAAI</em>, <em>126</em>, 106799. (<a
href="https://doi.org/10.1016/j.engappai.2023.106799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel approach called Multi-slice Nested Recurrence Plot (MsNRP) for person identification using noisy bio-signals. Prior studies in biometrics have predominantly relied on ideal datasets of 5–10 min, which introduces uncertainty in accuracy when dealing with noisy bio-signals. The proposed MsNRP method captures features from one and multiple cycles without the need for preprocessing, making it well-suited for photoplethysmograms(PPG) and electrocardiograms(ECG). By overcoming the limitations of traditional recurrence plots(RP), MsNRP demonstrates robustness to noisy bio-signal datasets, thus offering a reliable solution for identification in practical scenarios. We demonstrate the experiments of MsNRP on both 5–10 min datasets, similar to previous related work and day-long datasets, measured in daily life emphasizing its robustness in handling noisy data.},
  archive      = {J_EAAI},
  author       = {YeongJun Jeon and Soon Ju Kang},
  doi          = {10.1016/j.engappai.2023.106799},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106799},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-slice nested recurrence plot (MsNRP): A robust approach for person identification using daily ECG or PPG signals},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent predictive maintenance of hydraulic systems
based on virtual knowledge graph. <em>EAAI</em>, <em>126</em>, 106798.
(<a href="https://doi.org/10.1016/j.engappai.2023.106798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the manufacturing industry, a hydraulic system harnesses liquid fluid power to create powerful machines. Under the trend of Industry 4.0, the predictive maintenance of hydraulic systems is transforming to more intelligent and automated approaches that leverage the strong power of artificial intelligence and data science technologies. However, due to the knowledge-intensive and heterogeneous nature of the manufacturing domain, the data and information required for predictive maintenance are normally collected from ubiquitous sensing networks. This leads to the gap between massive heterogeneous data/information resources in hydraulic system components and the limited cognitive ability of system users. Moreover, how to capture and structure useful domain knowledge (in a machine-readable way) for solving domain-specific tasks remains an open challenge for the predictive maintenance of hydraulic systems. To address these challenges, in this paper we propose a virtual knowledge graph-based approach for the digital modeling and intelligent predictive analytics of hydraulic systems. We evaluate the functionalities and effectiveness of the proposed approach on a predictive maintenance task under real-world industrial contexts. Results show that our proposed approach is capable and feasible to be implemented for digital modeling, data access, data integration, and predictive analytics.},
  archive      = {J_EAAI},
  author       = {Wei Yan and Yu Shi and Zengyan Ji and Yuan Sui and Zhenzhen Tian and Wanjing Wang and Qiushi Cao},
  doi          = {10.1016/j.engappai.2023.106798},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106798},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent predictive maintenance of hydraulic systems based on virtual knowledge graph},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query-support semantic correlation mining for few-shot
segmentation. <em>EAAI</em>, <em>126</em>, 106797. (<a
href="https://doi.org/10.1016/j.engappai.2023.106797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given one or several annotation samples, few-shot segmentation has the capability to complete the segmentation of unseen target objects, thereby reducing the need for extensive data annotation. However, due to the scarcity and diversity of data, it becomes challenging to employ a few support samples effectively for guiding the segmentation of one query sample. Most existing approaches are committed to excavating support samples’ information while ignoring the crucial relationship between query and support samples. To address this limitation and capture richer mutual information, we propose a query-support semantic correlation mining module that serves as an elaborate guide for subsequent dense matching. Specifically, two kinds of query guide maps are generated that leverage global and local similarities to learn the comprehensive correlation between multi-scale support and query features. By incorporating this module, the network can better execute dense matching and mitigate the possibility of misclassification effectively. In addition, a dual-attention module is introduced to obtain a discriminating initial prototype representation to avert prototype bias. Furthermore, our method generalizes well in the k -shot setting. Extensive experiments on PASCAL- 5 i and COCO- 2 0 i datasets demonstrate that the proposed method is potent and successful, which yields competitive segmentation results with state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Ji Shao and Bo Gong and Kanyuan Dai and Daoliang Li and Ling Jing and Yingyi Chen},
  doi          = {10.1016/j.engappai.2023.106797},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106797},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Query-support semantic correlation mining for few-shot segmentation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Method of locating loose particles inside aerospace
equipment based on parameter-optimized XGBoost. <em>EAAI</em>,
<em>126</em>, 106796. (<a
href="https://doi.org/10.1016/j.engappai.2023.106796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex internal structure and heterogeneous composition material of aerospace equipment make it difficult to apply traditional acoustic emission source localization methods to the loose particle localization research. In previous studies, the authors transformed the loose particle localization problem into the multi-classification problem in machine learning, trained the loose particle localization model, but there were problems of low classification accuracy and low practicality. In this paper, the authors first introduced the ensemble learning idea into the loose particle detection field, designed a complete loose particle localization scheme, analyzed the above problems from multiple perspectives, and proposed new algorithms or strategies to enhance the superiority and practicability of the loose particle localization model. Specifically, in view of the low classification accuracy, the authors carried out the research on pulse preprocessing, feature engineering and model training from the four perspectives of signal, feature, data set and classifier, respectively. The zero-pulse-filling pulse matching algorithm and the channel-weighting-based feature selection method was newly proposed, Mel-Frequency Cepstral Coefficients features was newly extracted, feature optimization scheme was designed, and XGBoost ensemble classifier was trained. Thus, high-quality loose particle signals, high-quality localization data sets and high-performance loose particle localization models were obtained, respectively. Test results show that, the classification accuracy achieved by the new loose particle localization model was 96.80%, which was a significant improvement compared to the 83.53% achieved in previous studies. In view of the low practicality, the authors built the loose particle localization experimental system, gave the specific implementation steps of the loose particle localization method, as well as the general procedures for applying the loose particle localization model for physical testing. Meanwhile, taking into account the requirements of aerospace engineering applications, the authors added the majority voting strategy to convert classification results into localization results, thus newly proposed the definition of equipment-level loose particle localization accuracy. Several physical testing results show that, the loose particle localization model achieved a localization accuracy of 90.91%, which effectively verified the feasibility and stability of the proposed method. This study is an important supplement to the loose particle detection research, and of great significance in improving the reliability of aerospace systems.},
  archive      = {J_EAAI},
  author       = {Zhigang Sun and Guotao Wang and Guofu Zhai and Pengfei Li and Qi Liang and Min Zhang},
  doi          = {10.1016/j.engappai.2023.106796},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106796},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Method of locating loose particles inside aerospace equipment based on parameter-optimized XGBoost},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust facial expression recognition with transformer block
enhancement module. <em>EAAI</em>, <em>126</em>, 106795. (<a
href="https://doi.org/10.1016/j.engappai.2023.106795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, facial expression recognition (FER) methods have achieved significant progress. However, FER is still challenged by factors such as uneven illumination and low-quality expression images. Exploring the potential of facial expression features to achieve robust FER is particularly important. Inspired by the Transformer’s excellent performance in modeling long-range dependencies and in vision tasks, this paper proposes a Transformer Block Enhancement Module (TBEM) for enhancing the feature representation of facial expressions. The proposed module contains a Channel Enhancement (CE) block and a Spatial Enhancement (SE) block. The CE block can adaptively enhance the expression features on the channel dimension by effectively leveraging the channel dependency information, while the SE block enhances the expression features on the spatial dimension by integrating the spatial dependency information. TBEM can output a more robust expression representation by combining CE and SE. The proposed artificial intelligence learning module greatly improves the recognition accuracy of FER engineering tasks. To further illustrate the application of TBEM in real-world FER engineering, three engineering problems are used for verification. Extensive experiments demonstrate that the proposed method improves FER performance by focusing on more accurate decisional features and can be easily embedded into regular convolutional neural network models to help them improve the accuracy on FER tasks by about 2.64%–3.03%. The results show the proposed method achieves accuracies of 90.57% on FERPlus, 89.41% on RAFDB basic and 68.43% on RAFDB compound, respectively. The proposed method also provides a meaningful reference for further research on applying Transformer to other tasks.},
  archive      = {J_EAAI},
  author       = {Yuanlun Xie and Wenhong Tian and Zitong Yu},
  doi          = {10.1016/j.engappai.2023.106795},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106795},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust facial expression recognition with transformer block enhancement module},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated classification of brain diseases using the
restricted boltzmann machine and the generative adversarial network.
<em>EAAI</em>, <em>126</em>, 106794. (<a
href="https://doi.org/10.1016/j.engappai.2023.106794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Early diagnosis of brain diseases is very important. Brain disease classification is a common and complex topic in biomedical engineering. Therefore, machine learning methods are the most reliable and common methods for the automatic detection of brain diseases. Materials and methods: The brain diseases dataset consists of four classes: atrophy, normal, white matter density, and ischemia. First, data augmentation and normalization is applied to the dataset. Then, deep feature extraction is applied to this preprocessed dataset with the Restricted Boltzmann Machine (RBM) method. Deep feature data are given as input to the generator unit of the Generative Adversarial Network (GAN) method. Finally, classification is performed by Tree, Linear discriminant, Naïve Bayes, Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Ensemble, Neural Network classifiers and K-mean. Results: In the classification applied before feature extraction with the RBM method, the highest accuracy is calculated in the SVM classifier with 97.94%, and the lowest accuracy is calculated in the Naïve Bayes classifier with 80.43%. After applying the RBM feature extraction, the highest accuracy is calculated as 99.65% in the SVM classifier and 83.74% in the lowest Naïve Bayes classifier. Conclusion: This study shows that the performance criteria values of the presented methods is improved with RBM-GAN.},
  archive      = {J_EAAI},
  author       = {Narin Aslan and Sengul Dogan and Gonca Ozmen Koca},
  doi          = {10.1016/j.engappai.2023.106794},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106794},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated classification of brain diseases using the restricted boltzmann machine and the generative adversarial network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic spatial distributed information clustering method
for aluminum electrolysis cell. <em>EAAI</em>, <em>126</em>, 106793. (<a
href="https://doi.org/10.1016/j.engappai.2023.106793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed anode current (DAC) is a high-dimensional spatial-distributed signal that can be measured online in the industrial aluminum electrolysis process. The difference of physicochemical properties in different spatial regions in an aluminum electrolysis cell can be obtained by spatial clustering analysis of DAC data. In this study, a dynamic spatial distributed information clustering method (DSDIC) for aluminum electrolysis cell is proposed. This method can effectively capture the complex dynamic spatio-temporal correlations in DAC. Firstly, the dynamic graph is identified to capture the complex dynamicity of the DAC. Then, the anode-spatial structure information (ASSI) extends the one-dimensional current signal generated by each carbon anode into a feature matrix to achieve the fusion of data and spatial structure knowledge. Finally, the adjacency matrix of dynamic graph performs low-pass filtering on the feature matrix to obtain low-frequency information that is beneficial to downstream learning tasks. Meanwhile, a fixed graph structure based on process mechanism knowledge is designed to capture the spatial correlation caused by external periodic operations in industrial process. The experimental results on the actual industrial aluminum electrolysis datasets show that our method improves the clustering accuracy by 3.96% compared with existing clustering methods.},
  archive      = {J_EAAI},
  author       = {Yubo Sun and Weihua Gui and Xiaofang Chen and Yongfang Xie and Shiwen Xie and Zhong Zou},
  doi          = {10.1016/j.engappai.2023.106793},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106793},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic spatial distributed information clustering method for aluminum electrolysis cell},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A design methodology based on two dimensional fuzzy
linguistic variables for attribute control charts with real case
applications. <em>EAAI</em>, <em>126</em>, 106792. (<a
href="https://doi.org/10.1016/j.engappai.2023.106792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute control charts (ACCs) effectively evaluate process’ situation based on nonconforming items (NCIs) and defects of items in a process. The traditional control charts (CCs) that analyze process control situations need a major adjustment to take into account uncertainties into eal case problems that can occur due to human evaluations and hesitancies, measurement systems errors, and process situations. The fuzzy set theory (FST) has been used successfully to reach this aim. Recently, some fuzzy set extensions have been integrated into traditional CCs to more extensively and sensitively model the uncertainty by involving other uncertainty parameters, such as non-membership value and hesitancy function. In this paper, one of these extensions, Pythagorean fuzzy sets (PFSs), has been adjusted with CCs to model the vagueness of human evaluations, their hesitancies, and uncertainties regarding the process. For this aim, the well-known ACCs based on the total count of defects and NCIs and called c , u , p , and n p CCs, respectively, have been re-designed by using PFSs. Additionally, the control procedure of these CCs has been deeply analyzed with respect to fuzzy limit values and fuzzy measurements. Also, a rule-based approach that checks in-control and out-of-control situations regarding distance measurements is suggested to check the sample’s status more accurately. The proposed CCs based on PFSs have also been applied on a real case study from a manufacturing factory. The obtained results confirm that the CCs based on PFSs have an ability to create accurate, sensitive, and flexible results by using the input data while analyzing the process’ stability.},
  archive      = {J_EAAI},
  author       = {İhsan Kaya and Esra İlbahar and Ali Karaşan},
  doi          = {10.1016/j.engappai.2023.106792},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106792},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A design methodology based on two dimensional fuzzy linguistic variables for attribute control charts with real case applications},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint task offloading and resource allocation for multi-user
and multi-server MEC networks: A deep reinforcement learning approach
with multi-branch architecture. <em>EAAI</em>, <em>126</em>, 106790. (<a
href="https://doi.org/10.1016/j.engappai.2023.106790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) is a promising computing paradigm in the context of 5G networks, as it enables the migration of workloads from User Equipments (UEs) to nearby MEC servers, thereby providing additional computing resources to UEs. In this paper, we propose a joint optimization approach to offloading decisions and resource allocation in a multi-user and multi-server MEC system, which operates in a time-varying environment. Our objective is to minimize the average task latency and discard rate under the constraints of latency and limited computing resources of the server. While traditional optimization methods have been used to solve computational offloading problems in static environments, these methods are not suitable for time-varying systems. Deep reinforcement learning can be an effective method for solving optimization problems in time-varying environments, as it can be used to adjust strategies in real-time in response to changes in the environment. However, the increased number of UEs in the system leads to a combinatorial increase in the number of possible actions, making it difficult for the algorithm to learn. To address this issue, we propose a multi-branch network based Deep Q Network (DQN) algorithm called Branch Deep Q Network (BDQN), which modifies the action generation network into a multi-branch network structure, each branch generates one-dimensional action. This modification makes the number of network outputs increase linearly. Numerical results show that the BDQN algorithm outperforms other baseline algorithms in terms of average task latency and discard rate.},
  archive      = {J_EAAI},
  author       = {Yu Sun and Qijie He},
  doi          = {10.1016/j.engappai.2023.106790},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106790},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Joint task offloading and resource allocation for multi-user and multi-server MEC networks: A deep reinforcement learning approach with multi-branch architecture},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A metaheuristic-driven physical asset risk management
framework for manufacturing system considering continuity measures.
<em>EAAI</em>, <em>126</em>, 106789. (<a
href="https://doi.org/10.1016/j.engappai.2023.106789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the uninterrupted operation of physical assets, the effective implementation of risk mitigation plans (RMPs) and business continuity plans (BCPs) for critical assets is required. However, manufacturing decision-makers face the challenge of allocating limited resources between RMPs and BCPs while prioritizing sustained success. To address this challenge, a novel approach proposes integrating a metaheuristic algorithm into a risk management framework that considers interconnected risks. The framework utilizes a Bayesian Network (BN) to model interdependencies among critical physical asset risks. It determines the optimal combination of BCPs and RMPs, considering continuity measures and resource limitations. A physical asset risk assessment process evaluates operational and disruption risks based on expected loss and probabilities within the risk network. Given the complexity, the proposed framework incorporates hybrid multi-objective metaheuristic algorithms (e.g., Nondominated Sorting Genetic Algorithm II (NSGA-II), Strength Pareto Evolutionary Algorithm 2 (SPEA2), Multi-Objective Particle Swarm Optimization (MOPSO), and Pareto Envelope-based Selection Algorithm II (PESA-II)) combined with a reinforcement learning approach. A case study of a manufacturing company demonstrates the framework’s applicability and discusses the results. The findings show a significant reduction in the expected loss within the risk network and migration of most physical asset risks from high-risk to acceptable areas. Additionally, a sensitivity analysis examines the available budget, aiding decision-makers in determining the necessary compromise between asset availability and network risk level. In conclusion, the proposed framework empowers decision-makers to allocate resources effectively, prioritize RMPs and BCPs, and ensure continuity for critical physical assets, thereby fostering sustained success in manufacturing systems.},
  archive      = {J_EAAI},
  author       = {Mohsen Aghabegloo and Kamran Rezaie and S. Ali Torabi and Maziar Yazdani},
  doi          = {10.1016/j.engappai.2023.106789},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106789},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A metaheuristic-driven physical asset risk management framework for manufacturing system considering continuity measures},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of outlying patterns from sparse and irregularly
sampled electronic health records data. <em>EAAI</em>, <em>126</em>,
106788. (<a
href="https://doi.org/10.1016/j.engappai.2023.106788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the intensive care unit (ICU), vital signs such as arterial blood pressure (ABP) collected from electronic health records (EHRs) are typically recorded at different and uneven sampling frequencies and are often infrequently measured due to the nature of the medical treatment. Furthermore, from a temporal trajectory perspective, EHR data are likely to be corrupted by outlying patterns that deviate from normal samples in terms of the curves’ magnitude and shape. In this work, we propose a two-stage outlier detection approach for sparse and irregularly sampled (SiS) temporal data using functional data analysis (FDA) tools. In the first stage, an outlier identification measure is defined by a max–min statistic and a clean subset that contains nonoutliers. In the second stage, a multiple hypothesis testing problem is formulated based on the asymptotic distribution of the proposed measure. The simulation-based framework shows that the proposed method is robust to different types of shape and magnitude outliers. The detection results are more accurate than the widely used functional depth methods, especially in extremely sparse settings where the proportion of the observed data points over the entire time series is approximately 10%. Extensive experiments are also conducted on the real-world MIMIC-II dataset, which demonstrate that the method effectively detects clinically meaningful outlying patterns.},
  archive      = {J_EAAI},
  author       = {Xiaokang Wang and Chengjian Li and Hao Shi and Congshan Wu and Chao Liu},
  doi          = {10.1016/j.engappai.2023.106788},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106788},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection of outlying patterns from sparse and irregularly sampled electronic health records data},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A prospect theory-based MABAC algorithm with novel
similarity measures and interactional operations for picture fuzzy sets
and its applications. <em>EAAI</em>, <em>126</em>, 106787. (<a
href="https://doi.org/10.1016/j.engappai.2023.106787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy set (PFS) is one the reliable tool to handle the uncertainties in the data as compared to the intuitionistic fuzzy set (IFS) or fuzzy set. PFS simultaneously handle the four degrees namely, membership, neutrality, non-membership, and refusal, and thus widely applicable to solve the real-life decision-making problems more accurately. Keeping their advantages, in this paper, we present some interactive operational laws for the picture fuzzy numbers (PFNs) to aggregate picture fuzzy information. Also, we state some new information measures namely picture fuzzy similarity measures (PFSimMs) based on fuzzy strict negations, which can overcome the various drawbacks of the existing PFSimMs. The various properties and their features are studied in detail to show their advantages. Finally, we develop a prospect theory-based multi-attributive border approximation area comparison (MABAC) method under picture fuzzy environment by using the proposed operational laws and PFSimMs to solve the decision-making problems. The applicability of the developed algorithm is explained through a numerical example and show its superiorities.},
  archive      = {J_EAAI},
  author       = {Tao Wang and Xinxing Wu and Harish Garg and Qian Liu and Guanrong Chen},
  doi          = {10.1016/j.engappai.2023.106787},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106787},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A prospect theory-based MABAC algorithm with novel similarity measures and interactional operations for picture fuzzy sets and its applications},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development and application of an optimal COVID-19 screening
scale utilizing an interpretable machine learning algorithm.
<em>EAAI</em>, <em>126</em>, 106786. (<a
href="https://doi.org/10.1016/j.engappai.2023.106786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is a huge global challenge, on which numerous people and resources all over the world have been focused over the last three years to slow down its spread. A screening scale for the early detection of COVID-19 cases is highly important to diagnose patients before they transmit the disease to others. Using the data collected from Sept. 2020 to Nov. 2020 from 12,123 employees of a company including a weekly self-report questionnaire and information on their demographics, chronic disease, work, and commute, we developed a short, optimized screening scale for the early detection of COVID-19. To develop the scale, we have modified an interpretable machine learning (ML) method which uses integer programming​ techniques, and consequently reduced its computational cost significantly and made it robust to erroneous data and protective of sensitive information without loss of performance. The developed scale is highly interpretable and easily scored to the extent that it does not require a computer or even a calculator. However, we showed that the operating characteristics of the screening scale on the test dataset are excellent (area under the ROC curve = 82% and area under the Precision–Recall curve = 27%) and comparable to other well-known ML models such as penalized logistic regression and random forest when predicting positive PCR test results within 7 days from the date the self-report questionnaire was filled out. From Dec. 2020 to Nov. 2021, the developed scale has been used in the company weekly to monitor and assess its employees. Although different variants of COVID-19 have emerged since the development of the scale, the results show that the scale has performed well in the early detection of COVID-19, which helped the company take appropriate actions to slow down the spread of COVID-19 among its employees successfully. We expect our findings in this paper to help researchers have a better understanding of COVID-19 and control the spread of the disease.},
  archive      = {J_EAAI},
  author       = {Sara Sharifi Sedeh and Afsaneh Fatemi and Mohammad Ali Nematbakhsh},
  doi          = {10.1016/j.engappai.2023.106786},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106786},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development and application of an optimal COVID-19 screening scale utilizing an interpretable machine learning algorithm},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal model-free adaptive control based on reinforcement
q-learning for solar thermal collector fields. <em>EAAI</em>,
<em>126</em>, 106785. (<a
href="https://doi.org/10.1016/j.engappai.2023.106785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge and related difficulties of controlling solar collector fields (SCFs) using high-complex models by proposing an adaptive optimal model-free controller based on the Reinforcement Q-Learning algorithm. The controller aims to achieve optimal performance using only plant measurements, particularly the working fluid temperature, flow rate, and reference trajectory. The proposed solution offers advantages over model-based controllers, as it can handle nonlinearities, time-varying model parameters, and computational costs associated with nonlinear models. Additionally, the Q-Learning algorithm requires a small amount of data, overcoming data-driven solutions presented in the literature till now for SCF systems. To ensure the controller performance, simulations are conducted using a validated SCF model based on actual data from the CIESOL thermal plant located in Almería, Spain. The results demonstrate the effectiveness and usefulness of the model-free controller as the Q-Learning algorithm converges to the optimal gains of the Linear Quadratic Tracking (LQT) controller, exhibiting adaptive optimal response. Furthermore, the Q-Learning strategy outperforms the LQT controller in managing steady-state errors, particularly on sunny days with smooth solar irradiance variations. The average discrepancy in gains computed with reinforcement learning in a one-day campaign trial considering 18000 data is less than 15% compared to optimal LQT gains. This model-free approach proves its value and can easily be extended to different SCF systems without altering the general control formulation.},
  archive      = {J_EAAI},
  author       = {Igor M.L. Pataro and Rita Cunha and Juan D. Gil and José L. Guzmán and Manuel Berenguel and João M. Lemos},
  doi          = {10.1016/j.engappai.2023.106785},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106785},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal model-free adaptive control based on reinforcement Q-learning for solar thermal collector fields},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). A grey breakpoint prediction model and its application in
forecasting and policy evaluation. <em>EAAI</em>, <em>126</em>, 106784.
(<a href="https://doi.org/10.1016/j.engappai.2023.106784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To realize accurate predictions for a system with a new disturbance, the concept of a time breakpoint is introduced, and the grey breakpoint prediction model GBPM(1,1,t) and corresponding optimized model OGBPM(1,1,t) are established. A variety of methods are introduced to calculate the model coefficients. The results show that with the establishment of time breakpoints and accurately estimated parameters, the grey breakpoint prediction model can effectively capture the system changes caused by changes in the external environment to achieve accurate system predictions. Additionally, the application of the grey breakpoint prediction model in policy evaluation is discussed. The new model requires only a small amount of data to evaluate policy effectiveness. Compared with traditional policy evaluation methods such as the double difference and breakpoint regression methods, the proposed approach is more convenient. Finally, the validity of the new model for forecasting and policy evaluation is verified using four practical cases. In comparisons with the BP, ARIMA, GM(1,1), and FGM(1,1) models, the grey breakpoint model, especially OGBPM(1,1,t), displays the best modeling performance, the best fitting accuracy and the highest precision. Through four cases, it is found that the grey breakpoint prediction model displays good applicability and superiority in forecasting and policy evaluation tasks.},
  archive      = {J_EAAI},
  author       = {Zhun Zhang and Huiping Wang},
  doi          = {10.1016/j.engappai.2023.106784},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106784},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A grey breakpoint prediction model and its application in forecasting and policy evaluation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven hospitals staff and resources allocation using
agent-based simulation and deep reinforcement learning. <em>EAAI</em>,
<em>126</em>, 106783. (<a
href="https://doi.org/10.1016/j.engappai.2023.106783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital staff and resources allocation (HSRA) is a critical challenge in healthcare systems, as it involves balancing the demands of patients, the availability of resources, and the need to provide high-quality health in resource-bounded settings. Traditional approaches to HSRA have relied on manual planning and ad-hoc adjustments, which can be time-consuming and usually lead to sub-optimal outcomes. Recent studies show that machine learning solutions are able to produce better HSRA results compared to manual planning. However, these outcomes usually focused on a single hospital and objective. In this paper, we solve the HSRA task using a novel agent-based simulation with a deep reinforcement learning agent. We used real-world data to generate a wide range of synthetic instances that were used to train the HSRA agent. Our results show that the proposed model is able to achieve better outcomes in terms of patient treatment success and cost-effectiveness compared to previous resource allocation algorithms. We show that different planning horizons obtain similar performance in handling anomalies. In addition, we show a second-order polynomial connection between the patient treatment success and both the hospital’s initial budget and funding over time. These results suggest that our approach has the potential to improve the efficiency and effectiveness of HSRA in healthcare systems.},
  archive      = {J_EAAI},
  author       = {Teddy Lazebnik},
  doi          = {10.1016/j.engappai.2023.106783},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106783},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven hospitals staff and resources allocation using agent-based simulation and deep reinforcement learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IPDNet: A dual convolutional network combined with image
prior for single image dehazing. <em>EAAI</em>, <em>126</em>, 106782.
(<a href="https://doi.org/10.1016/j.engappai.2023.106782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dehazing based on deep learning neural networks (CNNs) has achieved remarkable results. However, the most existing dehazing CNNs perform well only on synthetic images and struggle with realistic hazy images. Moreover, training complex dehazing models is challenging due to the limited availability of realistic image datasets, leading to suboptimal performance. For this purpose, we develop a novel Image Prior Dehazing Network called IPDNet to tackle the challenge of dehazing realistic images with limited training data. The IPDNet comprises two sub-networks and a learnable fusion block. The global and local features are obtained by atmospheric scattering and direct mapping via two sub-networks with a sparse mechanism. And the learnable fusion block is settled to acquire the optimal fusion solution to improve the dehazing quality. The IPDNet offers several benefits: (1) a dual network with a learnable fusion block can effectively generate high-quality dehazed images at low computational cost; (2) an image preprocessing block based on dehazing prior can acquires the salient features of realistic hazy image, enhancing the dehazing performance on realistic hazy images; (3) the sub-network is designed by incorporating a feature attention (FA) block into the U-net structure, allowing flexible feature extraction on limited datasets. Extensive experiments on SOTS, NH-HAZE, and DENSE-HAZE datasets show that IPDNet outperforms other state-of-the-art methods on synthetic and realistic datasets. Specifically, our model achieved an improvement of approximately 0.84 dB in PSNR and 11.6% in SSIM, demonstrating its effectiveness in realistic scenarios, which contributes to improving traffic safety in adverse weather conditions.},
  archive      = {J_EAAI},
  author       = {Yan Chen and Zhiyu Lyu and Yimin Hou},
  doi          = {10.1016/j.engappai.2023.106782},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106782},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IPDNet: A dual convolutional network combined with image prior for single image dehazing},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Small samples noise prediction of train electric traction
system fan based on a multiple regression-fuzzy neural network.
<em>EAAI</em>, <em>126</em>, 106781. (<a
href="https://doi.org/10.1016/j.engappai.2023.106781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fan noise in the train electric traction system contributes to the main noise of the train, affecting the comfort of the passengers. The prediction of fan noise can serve as a foundation for the design and fault diagnosis of the fan in the train electric traction system as well as noise reduction. This paper proposes a prediction model based on multiple regression analysis and a double-layer fuzzy neural network (MRA-2LFNN). After the multiple regression analysis of the train electric traction system fan noise is performed to determine the prediction input, a fuzzy neural network is used to predict the fan noise. Afterward, further analysis of noise influencing factors is presented based on the experimental results, and the possibility of the fan optimal design is discussed. This method can make accurate predictions using a small sample of fan noise data, reducing the need for data samples and lowering costs. The experimental results show that the proposed method can achieve better prediction results using the small sample dataset by training and verifying the actual train electric traction system fan noise data, and the average prediction accuracy rate is 94.15%, After discussion, when the number of fan blades is 16, the train electric traction system exhibits improved noise performance.},
  archive      = {J_EAAI},
  author       = {Tao Li and Xiaoting Wu and Yuyao He and Xuanlin Peng and Jun Yang and Rongjun Ding and Caichun He},
  doi          = {10.1016/j.engappai.2023.106781},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106781},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Small samples noise prediction of train electric traction system fan based on a multiple regression-fuzzy neural network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of total dissolved solids, based on optimization
of new hybrid SVM models. <em>EAAI</em>, <em>126</em>, 106780. (<a
href="https://doi.org/10.1016/j.engappai.2023.106780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate monitoring of water quality is of great importance, especially in arid and semi-arid countries such as Iran. The Total Dissolved Solids (TDS) plays quite a significant role in rivers water quality. In most studies sampling isn’t considered due to difficulty of measuring elements its time-consuming and expensive nature. Herein several hybrid models including SVM-CA, SVM-HS and SVM-TLBO were developed to predict TDS in Babolrood River, Iran. The monthly measured and unpublished data of Ca, Mg, HCO 3 , Na, SO 4 , Cl, pH, and TDS, from 1968 to 2016 were used. Based on Shannon’s entropy and correlation matrix approaches most influential inputs were identified in five scenarios. Results were analyzed using several statistical indicators, including SI, MAE, U95, R 2 , RMSE and Taylor diagram. SVM-TLBO 5 model improved MAE by 66% and 81% compared to LS-SVR 1 model at Quran-Talar and Koushtargah stations, respectively. Based on SI, SVM-TLBO5 model improved predictions 87% and 79% compared to LS-SVR 1 at Quran-Talar and Koushtargah stations. RMSE, MAE, SI, R 2 , U95, and T-STAT at Quran-Talar station obtained equal 10.1 mg/l, 0.022, 35.14, 10.22 mg/l, 0.022 and 33.59. Also, the same values for the Koushtargah station obtained equal to 6.73 mg/l, 0.993, 1.56, 4.51 mg/l, 0.997 and 0.674.},
  archive      = {J_EAAI},
  author       = {Fatemeh Akhoni Pourhosseini and Kumars Ebrahimi and Mohammad Hosein Omid},
  doi          = {10.1016/j.engappai.2023.106780},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106780},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of total dissolved solids, based on optimization of new hybrid SVM models},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing project portfolio risk via an enhanced GA-BPNN
combined with PCA. <em>EAAI</em>, <em>126</em>, 106779. (<a
href="https://doi.org/10.1016/j.engappai.2023.106779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing project portfolio risk (PPR) is essential for organizations to grasp the overall risk levels of project portfolios (PPs) and realize PPR mitigation. However, current research is inadequate to effectively assess PPR, which brings challenges to managing PPR. In this context, the purpose of this study is to develop a PPR assessment model via an enhanced backpropagation neural network (BPNN). First, PPR assessment criteria considering project interdependencies are determined. Second, fuzzy logic is used to obtain original data for assessment criteria. Principal component analysis (PCA) is then employed to reduce the dimensionality of assessment criteria and derive the input and output of BPNN. Third, an improved genetic algorithm (IGA) is designed to optimize the initial weights and thresholds of BPNN. On this basis, the PCA-IGA-BPNN assessment model is constructed, followed by training and testing, possessing a test accuracy of 98.6%. Finally, comparison experiments are conducted from both internal and external perspectives. For internal comparison, the proposed model yields less mean absolute percentage error (MAPE), mean square error (MSE), and root mean square error (RMSE) than PCA-GA-BPNN, IGA-BPNN, PCA-BPNN and BPNN and offers the largest convergence speed ( γ ). As for external comparison, the presented model produces lower MAPE, MSE, and RMSE than Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbor (KNN) and has the largest coefficient of determination ( R 2 ). Results indicate that the established model performs more satisfactorily in assessing PPR. This research enriches PPR assessment methods and provides managers with a useful tool to evaluate PPR.},
  archive      = {J_EAAI},
  author       = {Libiao Bai and Chaopeng Song and Xinyu Zhou and Yuanyuan Tian and Lan Wei},
  doi          = {10.1016/j.engappai.2023.106779},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106779},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessing project portfolio risk via an enhanced GA-BPNN combined with PCA},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust optimization of the design of monopropellant
propulsion control systems using an advanced teaching-learning-based
optimization method. <em>EAAI</em>, <em>126</em>, 106778. (<a
href="https://doi.org/10.1016/j.engappai.2023.106778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a novel approach for the robust optimization of the design of hydrogen peroxide propulsion control systems using the efficient and advanced Teaching-Learning-Based Optimization (TLBO) method. This study adopts a robust design optimization (RDO) formulation that considers both epistemic and aleatory uncertainties, including sparse points and interval data, and uses the Johnson distribution family for uncertainty representation. The maximum likelihood estimation method is applied to determine the distribution parameters, also considering interval data with a nested optimization technique. A novel advanced TLBO method with high accuracy and convergence rate is employed to optimization of this robust design approach. The method’s originality and advancement come from two categories of modifications to the original framework: the structure of the teaching and learning phases and the initialization and search approach. The efficacy and applicability of the proposed Ad-TLBO, respectively, were evaluated using benchmark problems from the CEC2020 competition and three real-world engineering problems, with a comparison to some recently published and the CEC competition’s top-ranked algorithms. The results and statistical analyses of the Quade test, Wilcoxon signed-rank test, and Friedman test show that the proposed Ad-TLBO method outperforms the other algorithms. The proposed optimization method is eventually applied to design a monopropellant propulsion system as the control actuator of a satellite orbital transfer system. It is found that the proposed advanced TLBO is effective in handling uncertainty in real design problems and improves both the convergence rate and accuracy of the optimization process.},
  archive      = {J_EAAI},
  author       = {Mohammad Fatehi and Alireza Toloei and Enrico Zio and S.T.A. Niaki and Behrooz Keshtegar},
  doi          = {10.1016/j.engappai.2023.106778},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106778},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust optimization of the design of monopropellant propulsion control systems using an advanced teaching-learning-based optimization method},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Marine and land economy–energy–environment systems
forecasting by novel structural-adaptive fractional time-delay nonlinear
systematic grey model. <em>EAAI</em>, <em>126</em>, 106777. (<a
href="https://doi.org/10.1016/j.engappai.2023.106777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid economic growth and rising energy consumption have inevitably led to environmental problems, which is a cutting-edge issue of sustainable development. To distinguish the internal structure of marine and land economy–energy–environment (3E) systems and the non-linear relationships between the variables, a novel structural-adaptive fractional time-delay nonlinear systematic grey prediction model (FTDNSGM(1,m)) is established. Additionally, the solving process of each layer model of FTDNSGM(1,m) is described in detail, and the derived models of underlying layer FBTDGM(1,1) and upper layer FBTDGM(1,N) are deduced respectively, which constitute the nested grey difference equations. Furthermore, combined with comparative analysis and Monte-Carlo simulation, optimal non-linear parameters are determined by Beluga Whale Optimization (BWO) algorithm with robustness. Empirically, based on five case datasets under the national–regional dimensions, the FTDNSGM(1,m) model is scientifically verified to have superlative validity and stability. The results demonstrate that the average MAPEs of the proposed model in training and test sets are 0.38%, 0.28%, 0.34%, 0.26%, 0.21%, and 0.38%, 0.88%, 0.47%, 1.36%, 0.67%. Ulteriorly, the proposed model is of applicability to assess the impact on 3E systems attributed to the COVID-19 pandemic in 2020 and 2021. Predictably, from 2022 to 2025, with sustained economic growth, marine and land energy consumption will rise within reasonable limits, while coastal water quality will continue to grow and NOx emissions will keep going down.},
  archive      = {J_EAAI},
  author       = {Xuemei Li and Shiwei Zhou and Yufeng Zhao and Benshuo Yang},
  doi          = {10.1016/j.engappai.2023.106777},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106777},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Marine and land economy–energy–environment systems forecasting by novel structural-adaptive fractional time-delay nonlinear systematic grey model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional temporal GAN for intent-aware vessel trajectory
prediction in the precautionary area. <em>EAAI</em>, <em>126</em>,
106776. (<a
href="https://doi.org/10.1016/j.engappai.2023.106776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate vessel trajectory prediction is crucial for ensuring maritime traffic safety and efficiency, particularly in precaution areas characterized by multi-waterway branch merging and frequent traffic conflicts. However, predicting trajectories in these areas poses significant challenges due to the uncertain future intents of different directional branches resulting in diverse motion patterns and multiple possible paths. To address this issue and minimize the prediction error, we propose a conditional temporal generative adversarial network (CTGAN). Specifically, in this method, the trajectory generator is developed to capture the inherently dynamic of ship motions and outputs the future trajectory proposals, while the intent classifier is designed to evaluate whether the trajectory proposals are consistent with the hidden intention. With the adversarial training strategy, the trajectory generator and intent classifier form a closed loop, feedback informative signals to each other that enables generating the intent-constrained trajectory. In addition, a mixed adversarial loss function was designed to capture the spatial–temporal dependencies among the vessel motions for producing consistent trajectories that complied with plausible ship dynamics. Experiments on extensive naturalistic vessel trajectory data demonstrate that compared with the baseline methods, the proposed model achieves comparable or better prediction performance.},
  archive      = {J_EAAI},
  author       = {Chengfeng Jia and Jie Ma},
  doi          = {10.1016/j.engappai.2023.106776},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106776},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Conditional temporal GAN for intent-aware vessel trajectory prediction in the precautionary area},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Short-term electric load forecasting using particle swarm
optimization-based convolutional neural network. <em>EAAI</em>,
<em>126</em>, 106773. (<a
href="https://doi.org/10.1016/j.engappai.2023.106773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electric load forecasting is essential for the operation of power systems and the power market, including economic dispatch, unit commitment, peak load shaving, load management and bidding strategy development. This paper presents a novel method that uses a hybrid convolutional neural network (CNN) that is cascaded with a fully-connected network, to conduct 24h-ahead electric load forecasting in power systems. Spearman’s rank-order correlation, which serves as input size information for the CNN, was used to measure the cross-correlation between two sets of observations (chronological loads) of time shifts or lags. Both max and average pooling operations were utilized to extract data features in concatenation while spatial and conventional dropouts were employed to avoid overfitting in the hybrid CNN. The proposed method used two loops to yield the optimal CNN. The outer loop optimizes the structure and hyperparameters (such as kernel size) of the hybrid CNN by a proposed method of enhanced elite-based particle swarm optimization (EEPSO) while the inner loop optimizes the parameters (such as values of a kernel) and weights in neural networks using the Adam optimizer. The EEPSO is based on the mean search and chaotic descending inertia weight. The proposed method was used to study the 2018 and 2019 hourly load data in Taiwan Power Company. Simulation results show that the proposed method outperforms the well-known ARIMA, Radial Basis Function Network, Support Vector Regression, Long Short-term Memory and their hybrid variants.},
  archive      = {J_EAAI},
  author       = {Ying-Yi Hong and Yu-Hsuan Chan},
  doi          = {10.1016/j.engappai.2023.106773},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106773},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Short-term electric load forecasting using particle swarm optimization-based convolutional neural network},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of slight variations in combustion conditions with
machine learning and computer vision. <em>EAAI</em>, <em>126</em>,
106772. (<a
href="https://doi.org/10.1016/j.engappai.2023.106772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When monitoring combustion conditions, detecting minor variations, which may be complex even for the human eye, is critical for providing a fast response and correcting deviations. The aim of this study is to detect slight variations in combustion conditions by developing a flame monitoring system using machine learning and computer vision techniques applied to color images. Predictive models are developed for fuel blends with different heating values. The predictive models classify the combustion equivalence ratio based on multiple conditions, using a mean step size of 0.10 between states, a lower value than previously reported in related studies. Three machine learning algorithms are used for each fuel blend: logistic regression, support vector machine, and artificial neural network (multilayer perceptron). These models are fed the statistical, geometrical, and textural features extracted from the color images of the flames. The classification achieves accuracies from 0.78 to 0.97 in the detection of slight variations in the combustion conditions for all heating values. Thus, the monitoring system developed in this study is a promising alternative for implementation on an industrial scale and quick detection of changes in combustion conditions.},
  archive      = {J_EAAI},
  author       = {Pedro Compais and Jorge Arroyo and Miguel Ángel Castán-Lascorz and Jorge Barrio and Antonia Gil},
  doi          = {10.1016/j.engappai.2023.106772},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106772},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection of slight variations in combustion conditions with machine learning and computer vision},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Identification and classification for multiple cyber
attacks in power grids based on the deep capsule CNN. <em>EAAI</em>,
<em>126</em>, 106771. (<a
href="https://doi.org/10.1016/j.engappai.2023.106771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-attacks have become one of the main threats to the security, reliability, and economic operation of power systems. Detection and classification of multiple cyber-attacks pose challenges for ensuring the stability and security of power systems. To address this issue, this study proposes an automatic identification and classification method for multiple cyber-attacks based on the deep capsule convolution neural network. Spatial correlations among different nodes and temporal features from history operation status in the transmitted data packets are extracted by the convolution neural network. Capsules in the proposed structure have important implications for maintaining the topological consistency contained in the measurement matrix. Furthermore, the proposed method is model-free and avoids the impact of system parameters uncertainties on detection performance. Multiple kinds of typical cyber-attacks, including false data injection attacks, replay attacks, denial of service attacks, time-delay attacks, and deception attacks, are considered and modeled in this paper. Numerical results on the IEEE 39-bus test system show that the proposed method can achieve 99.97% detection accuracy on single cyber-attacks and 96.25% detection accuracy on multiple cyber-attacks. Comparative results illustrate the proposed method outperforms than traditional neural networks. This approach provides a solution for the problem of multiple cyber-attack detection and classification.},
  archive      = {J_EAAI},
  author       = {Guangdou Zhang and Jian Li and Olusola Bamisile and Yankai Xing and Di Cao and Qi Huang},
  doi          = {10.1016/j.engappai.2023.106771},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106771},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification and classification for multiple cyber attacks in power grids based on the deep capsule CNN},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimisation of LSTM neural networks with NSGA-II and FDA
for PV installations characterisation. <em>EAAI</em>, <em>126</em>,
106770. (<a
href="https://doi.org/10.1016/j.engappai.2023.106770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar PV generation is renewable energy source that in the last years has contributed to reduce the use of fossil fuels. Controlling the efficiency of photovoltaic (PV) installations is essential in order for its use to spread. Deep learning (DL) models have demonstrated their efficiency in this context. The purpose of this work is to show a methodology to optimised deep learning models and show a specific application of the optimised model to characterise PV installations. The estimations yielded by this model are obtained without the need for real PV data to the training process; synthetic data are used. The built multivariate neural network is optimised through the use of a multiobjective genetic algorithm and the use of a feature engineering tool based on functional data analysis (FDA) clustering. This method was applied on synthetic data and on a PV installation located in north-western Spain, where the number of parallel modules, the azimuth and the slope in the installation are estimated. The results show that the model optimised using the non-dominant sorting genetic algorithm (NSGA-II) and the customised dataset with FDA, achieve lower errors or in the same range by reducing the complexity of the model or the complexity of the dataset used. Specifically, the bests models generates estimations with an average error between 6% and 18% on synthetic data and between 6% and 12% on real data.},
  archive      = {J_EAAI},
  author       = {Miguel Martínez-Comesaña and Javier Martínez-Torres and Pablo Eguía-Oller},
  doi          = {10.1016/j.engappai.2023.106770},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106770},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimisation of LSTM neural networks with NSGA-II and FDA for PV installations characterisation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preference-based multi-attribute decision-making method with
spherical-z fuzzy sets for green product design. <em>EAAI</em>,
<em>126</em>, 106767. (<a
href="https://doi.org/10.1016/j.engappai.2023.106767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green product design, i.e., design that harmonizes with the environment, is a crucial component for addressing environmental considerations in the earliest stages of the product life cycle, e.g., new energy vehicles (NEVs), that minimize negative environmental impacts. The designs can encompass material selection, resource use, production requirements, recycling, reuse and the disposal of products. Selecting the optimal design alternative considering multiple attribute indices, e.g., environmental indicators and functional indicators, is a typical multi-attribute decision-making (MADM) problem. This study proposes a hybrid preference-based MADM method with spherical-Z fuzzy numbers (SZFNs) for solving the green product design fuzzy information problem. SZFNs are designed to mine the internal hidden information of traditional Z-numbers, and they combine the characteristics of the reliability constraints of Z-numbers and the advantages of spherical linguistic sets. The operation, aggregation operators and probabilistic measure method of SZFNs are defined in this study. The weight vector of the criteria is obtained by adopting the degree of possibility of spherical-Z (DPSZ). The hybrid MADM method is developed by incorporating the total utility of spherical-Z, which is used to convert the internal meaning of the evaluation information into an additive ratio assessment using gray relation analysis (ARAS-GRA) to obtain the optimal alternative. Finally, a case study, i.e., five green product design schemes for NEVs, is adopted to verify the effectiveness and robustness of this proposed method. A comparative analysis, sensitivity analysis and comprehensive discussion are conducted in this research. The results confirm that this proposed method has an improved performance, and provides some references for designers.},
  archive      = {J_EAAI},
  author       = {Zhongwei Huang and Honghao Zhang and Danqi Wang and Hao Yu and Lingyu Wang and Dongtao Yu and Yong Peng},
  doi          = {10.1016/j.engappai.2023.106767},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106767},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Preference-based multi-attribute decision-making method with spherical-Z fuzzy sets for green product design},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ADD: An automatic desensitization fisheye dataset for
autonomous driving. <em>EAAI</em>, <em>126</em>, 106766. (<a
href="https://doi.org/10.1016/j.engappai.2023.106766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving systems require many images for analyzing the surrounding environment. However, there is fewer data protection for private information among these captured images, such as pedestrian faces or vehicle license plates, which has become a significant issue. In this paper, in response to the call for data security laws and regulations and based on the advantages of large Field of View (FoV) of the fisheye camera, we build the first A utopilot D esensitization D ataset, called ADD , and formulate the first deep-learning-based image desensitization framework, to promote the study of image desensitization in autonomous driving scenarios. The compiled dataset consists of 650K images, including different face and vehicle license plate information captured by the surround-view fisheye camera. It covers various autonomous driving scenarios, including diverse facial characteristics and license plate colors. Then, we propose an efficient multitask desensitization network called DesCenterNet as a benchmark on the ADD dataset, which can perform face and vehicle license plate detection and desensitization tasks. Based on ADD , we further provide an evaluation criterion for desensitization performance, and extensive comparison experiments have verified the effectiveness and superiority of our method on image desensitization.},
  archive      = {J_EAAI},
  author       = {Zizhang Wu and Xinyuan Chen and Hongyang Wei and Fan Song and Tianhao Xu},
  doi          = {10.1016/j.engappai.2023.106766},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106766},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ADD: An automatic desensitization fisheye dataset for autonomous driving},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mining recency–frequency–monetary enriched insights into
resources’ collaboration behavior from event data. <em>EAAI</em>,
<em>126</em>, 106765. (<a
href="https://doi.org/10.1016/j.engappai.2023.106765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organizations increasingly rely on teamwork to achieve their goals. Therefore they continuously strive to improve their teams as their performance is interwoven with that of the organization. To implement beneficial changes, accurate insights into the working of the team are necessary. However, team leaders tend to have an understanding of the team’s collaboration that is subjective and seldom completely accurate. Recently there has been an increase in the adoption of digital support systems for collaborative work that capture objective data on how the work took place in reality. This creates the opportunity for data-driven extraction of insights into the collaboration behavior of a team. This data however, does not explicitly record the collaboration relationships, which many existing techniques expect as input. Therefore, these relationships first have to be discovered. Existing techniques that apply discovery are not generally applicable because their notion of collaboration is tailored to the application domain. Moreover, the information that these techniques extract from the data about the nature of the relationships is often limited to the network level. Therefore, this research proposes a generic algorithm that can discover collaboration relationships between resources from event data on any collaborative project. The algorithm adopts an established framework to provide insights into collaboration on a fine-grained level. To this end, three properties are calculated for both the resources and their collaboration relationships: a recency, frequency, and monetary value. The technique’s ability to provide valuable insights into the team structure and characteristics is empirically validated on two use cases.},
  archive      = {J_EAAI},
  author       = {Leen Jooken and Benoît Depaire and Mieke Jans},
  doi          = {10.1016/j.engappai.2023.106765},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106765},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mining Recency–Frequency–Monetary enriched insights into resources’ collaboration behavior from event data},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual objective bounded abstaining model to control
performance for safety-critical applications. <em>EAAI</em>,
<em>126</em>, 106762. (<a
href="https://doi.org/10.1016/j.engappai.2023.106762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstaining models have been widely used in safety-critical fields to avoid uncertain classification and reduce misclassification costs. Previous abstaining models have two main disadvantages. First, the costs of classification and rejection need to be set. Unfortunately, it is difficult to obtain or estimate costs in practical applications. When costs change, the trained model will be no longer applicable. Second, a single indicator, such as the error rate or AUC, is optimized, which has poor robustness for different application requirements. To solve such problems, a dual objective bounded abstaining (DOBA) model is proposed. DOBA optimizes the binary confusion matrix with rejection by minimizing the false positive and negative rates under class-specific reject constraints. The DOBA model is solved using an evolutionary multi-objective optimization algorithm. The requirement-oriented abstaining classifier can be selected from a set of Pareto-optimal solutions. Extensive experiments prove the effectiveness and superiority of DOBA compared to other abstaining models.},
  archive      = {J_EAAI},
  author       = {Hongjiao Guan and Xiangjun Dong and Chuan Chen and Long Zhao and Xiaoqiang Ren},
  doi          = {10.1016/j.engappai.2023.106762},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106762},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual objective bounded abstaining model to control performance for safety-critical applications},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An encoder framework for taxi-demand prediction using
spatio-temporal function approximation. <em>EAAI</em>, <em>126</em>,
106760. (<a
href="https://doi.org/10.1016/j.engappai.2023.106760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting taxi demands in large cities can help in better traffic management as well as ensure better commuter satisfaction for an intelligent transportation system. However, the traffic demands across different locations have varying spatio-temporal correlations that are difficult to model. Despite the ability of the existing Deep Neural Network (DNN) models to capture the non-linearity in spatial and temporal characteristics of the demand time-series, capturing spatio-temporal characteristics in different real-world scenarios like varying historic and prediction time frame, spatio-temporal variations due to noise or missing data, etc. still remain a big challenge for the state-of-the-art models. In this paper, we introduce En coder- App ro X imator (EnAppX), an encoder–decoder DNN-based model that uses Chebyshev function approximation in the decoding stage for taxi demand times-series prediction and can better estimate the time-series in the presence of large spatio-temporal variations. Opposed to any existing state-of-the-art model, the proposed model approximates complete spatio-temporal characteristics in the frequency domain which in turn enables the model to make a robust and improved prediction in different scenarios. Validation over two real-world taxi datasets from different cities shows a considerable improvement of around 23% in RMSE scores compared to the state-of-the-art baseline model. Unlike several existing state-of-the-art models, EnAppX also produces improved prediction accuracy across two regions for both to and fro demands.},
  archive      = {J_EAAI},
  author       = {Manish Bhanu and Saswata Roy and Shalini Priya and João Mendes-Moreira and Joydeep Chandra},
  doi          = {10.1016/j.engappai.2023.106760},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106760},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An encoder framework for taxi-demand prediction using spatio-temporal function approximation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-aware explainable deep learning approach for next
activity prediction. <em>EAAI</em>, <em>126</em>, 106758. (<a
href="https://doi.org/10.1016/j.engappai.2023.106758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of the next activity in a business process can be very useful in revealing inefficiencies and take decisions to avoid undesired activities. In this direction, further advantages can gather from the knowledge of the activities within their attributes that influence the occurrence of the predicted activity. This paper faces this issue by introducing a Data-aware Explainable Next Activity Prediction approach called DENAP based on the adoption of Long Short-Term Memory (LSTM) neural networks and Layer-Wise Relevance Propagation (LRP) method for the detection of next activity prediction in a business process and for the evaluation of the past activities and data that influence the prediction. The DENAP approach is validated on a set of synthetic and real logs. The obtained results show the good capability of DENAP to predict the next activity and indicate the more relevant activities/data with respect to the prediction.},
  archive      = {J_EAAI},
  author       = {Lerina Aversano and Mario Luca Bernardi and Marta Cimitile and Martina Iammarino and Chiara Verdone},
  doi          = {10.1016/j.engappai.2023.106758},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106758},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-aware explainable deep learning approach for next activity prediction},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge addition for improving the transfer learning from
the laboratory to identify defects of hydraulic machinery.
<em>EAAI</em>, <em>126</em>, 106756. (<a
href="https://doi.org/10.1016/j.engappai.2023.106756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a solution to improve transfer learning from laboratory environment to real-world hydraulic machinery (centrifugal pump) for the effective identification of defects. The proposed method involves collecting vibration data, normalizing and computing Fast Fourier Transform (FFT) of the data, and adding attributes by combining the FFT of healthy real-world machinery with the FFT of laboratory machinery. The attribute addition is performed in the frequency domain to address phase lag issues in time-domain data. The resulting signal is transformed back to the time domain, and the envelope spectrum is obtained. An approximation model is constructed using the envelope spectrum and refined using data from industrial machinery. The refined model is then employed to identify defects in real machinery, specifically the centrifugal pump. The proposed knowledge addition-based transfer learning achieves an accuracy of 93%, which is 51% higher than the accuracy attained by the domain-adversarial neural network method.},
  archive      = {J_EAAI},
  author       = {Anil Kumar and Adam Glowacz and Hesheng Tang and Jiawei Xiang},
  doi          = {10.1016/j.engappai.2023.106756},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106756},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Knowledge addition for improving the transfer learning from the laboratory to identify defects of hydraulic machinery},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid learning-oriented approaches for predicting covid-19
time series data: A comparative analytical study. <em>EAAI</em>,
<em>126</em>, 106754. (<a
href="https://doi.org/10.1016/j.engappai.2023.106754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using medical science alongside time series data analysis can be given a strong tool to develop efficient decision support systems in Corona pandemic. In this regard, many hybrid learning-oriented (HL) approaches have been presented, which rely on modeling the linear and non-linear components of the time series. However, there is a lack of comprehensive study of such approaches to achieve a macro vision of Covid-19 data prediction models in an unified reference. We conducted a comparative analytical study on (HL) approaches for predicting Covid-19 data. The main scope of current study is the investigate of such approaches. The original contribution of the paper is to present a reference-point and roadmap for future studies, which is provided in three forms. First, we experimentally evaluated the efficiency of all learning-based combinations on types of Covid-19 data in a similar context. Second, we tried to provide a guidance for choosing a more proper hybrid through valid empirical and statistical evaluations. Third, we presented an efficient and generalizable approach called HL-ALL ( H ybrid L earning A RIMA L STM L STM). Evaluation results show high potential of HL-ALL in dealing Covid-19 data when prediction.},
  archive      = {J_EAAI},
  author       = {Soheila Mehrmolaei and Mohammad Savargiv and Mohammad Reza Keyvanpour},
  doi          = {10.1016/j.engappai.2023.106754},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106754},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid learning-oriented approaches for predicting covid-19 time series data: A comparative analytical study},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A complex belief χ2 divergence in complex evidence theory
and its application for pattern classification. <em>EAAI</em>,
<em>126</em>, 106752. (<a
href="https://doi.org/10.1016/j.engappai.2023.106752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex evidence theory (CET) is crucial in modeling uncertain information in the complex domain. With the development of the research on CET, how to measure the conflict between complex basic belief assignments (CBBAs) accurately remains an open issue. Thus, we propose the complex belief χ 2 divergence (called CB χ 2 divergence) tending to solve conflict management issues. The proposed complex belief χ 2 divergence which considers the quantum interference effects is a generalized model of traditional belief χ 2 divergence. Furthermore, the proposed complex belief χ 2 divergence satisfies the properties of symmetry, non-degeneracy and continuity. Besides, an algorithm for decision-making based on the complex belief χ 2 divergence is proposed. This method is applied in several datasets from UCI machine learning repository including the iris dataset, the seeds dataset and the heart disease dataset for pattern recognition. The result shows the proposed method has better classification accuracy compared with the related methods.},
  archive      = {J_EAAI},
  author       = {Linlu Gao and Fuyuan Xiao and Danilo Pelusi},
  doi          = {10.1016/j.engappai.2023.106752},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106752},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A complex belief χ2 divergence in complex evidence theory and its application for pattern classification},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on the application of process discovery techniques
to smart spaces data. <em>EAAI</em>, <em>126</em>, 106748. (<a
href="https://doi.org/10.1016/j.engappai.2023.106748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last years, a number of studies have experimented with applying process discovery techniques with the goal of automatically modelling human routines as if they were business processes. However, while promising results have already been achieved, applying process-oriented techniques to smart spaces data comes with its own set of challenges, due to the nature of smart spaces data and characteristics of human behaviour. This paper surveys existing approaches that apply process discovery to smart spaces data and analyses how they deal with the following challenges identified in the literature: choosing a suitable modelling formalism for human behaviour; bridging the abstraction gap between sensor and event logs; segmenting logs in traces; handling multi-user environments; and addressing human behaviour evolution. The main contribution of this article is two-fold: (i) providing the research community with an analysis of the existing applications of process discovery to smart spaces and how they address the above challenges, and (ii) assisting further research efforts by outlining opportunities for future work.},
  archive      = {J_EAAI},
  author       = {Yannis Bertrand and Bram Van den Abbeele and Silvestro Veneruso and Francesco Leotta and Massimo Mecella and Estefanía Serral},
  doi          = {10.1016/j.engappai.2023.106748},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106748},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A survey on the application of process discovery techniques to smart spaces data},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of a deep learning semantic segmentation model
to helium bubbles and voids in nuclear materials. <em>EAAI</em>,
<em>126</em>, 106747. (<a
href="https://doi.org/10.1016/j.engappai.2023.106747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging nanoscale radiation-induced defects using the transmission electron microscope (TEM) is a key factor in the successful implementation of materials for nuclear energy structural applications. Analyzing each defect in a TEM micrograph is currently a manual task. To identify the defects in a single image can take anywhere from 15 min to an hour and a project can require the analysis of anywhere from tens to ≥ 100 images. Here, we use artificial intelligence (AI) models to automate this task. For simplification, we evaluated images with only a single type of defect; helium bubbles. We performed semantic segmentation of these helium bubble defects in electron microscopy images of irradiated FeCrAl alloys using a deep learning DefectSegNet model. This model, which was previously used to classify crystal defects, is inspired by the classic DenseNet and U-Net image segmentation models. It claims high spatial resolution, but has poor performance at object boundaries. Our paper improves the DefectSegNet model’s application by adding two new features. First, the DefectSegNet model is applied not only to perform calculation pixel-wise but also object (or feature) wise. Because object-wise metrics are directly relevant to our final goal of detecting bubbles, whereas pixel-wise classification is only an intermediate step, it is an important part of our study. Second, a distance map loss (DML) function has been added to increase its performance at object boundaries. It is crucial to accurately represent defects boundaries, especially bubbles, in order to track the bubble-induced swelling caused by irradiation. The boundary-focused DML function is also compared to other loss functions like Cross-entropy, Weighted Binary Cross Entropy (WBCE), Dice and Intersection over Union (IOU). Finally, by incorporating new features, we found a marked improvement on segmentation quality and better shape preservation at the boundaries and areas of the bubbles.},
  archive      = {J_EAAI},
  author       = {S. Agarwal and A. Sawant and M. Faisal and S.E. Copp and J. Reyes-Zacarias and Yan-Ru Lin and S.J. Zinkle},
  doi          = {10.1016/j.engappai.2023.106747},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106747},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of a deep learning semantic segmentation model to helium bubbles and voids in nuclear materials},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HANNA: Human-friendly provisioning and configuration of
smart devices. <em>EAAI</em>, <em>126</em>, 106745. (<a
href="https://doi.org/10.1016/j.engappai.2023.106745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, there are billions of connected IoT devices and their number continues to grow as they contribute to the digitalization of infrastructures. However, the deployment process of these smart wireless devices when delivered to customer premises is slow and error prone as each of them needs to be provisioned with authentication credentials to access the corporate network. In this paper, we propose HANNA, a human-friendly provisioning and configuration framework for smart devices, that extends the zero-touch paradigm to large IoT deployments by introducing voice assisted configuration in combination with large scale ad-hoc communications to overcome the initial installation effort of IoT deployments. The most prominent role in HANNA is played by the assisting device, which includes a voice assistant capable of correctly understanding a minimum number of keywords required for initial provisioning and configuration of the devices. The device’s role is to interact with the user and ensure that all provisioning details are received. These are then converted into appropriate machine instructions for further use by the mass provisioning mechanism. We provide an example prototype implementation of HANNA and evaluate the performance of the assisting device in the human-to-machine communication phase and the performance of the selected communication technique in the machine-to-machine communication phase. Our results show the potential of existing speech-to-text engines for this application area and also reveal shortcomings with respect to the robustness of the engines in office-like working environments as well as with respect to user’s gender and language proficiency level. Additionally we show that the proposed machine-to-machine provisioning approach is always faster compared to manual provisioning for cases with more than ten devices.},
  archive      = {J_EAAI},
  author       = {Carolina Fortuna and Halil Yetgin and Leo Ogrizek and Esteban Municio and Johann M. Marquez-Barja and Mihael Mohorcic},
  doi          = {10.1016/j.engappai.2023.106745},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106745},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HANNA: Human-friendly provisioning and configuration of smart devices},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient multilayer adaptive self-organizing modeling
methodology for improving the generalization ability of organic rankine
cycle (ORC) data-driven model. <em>EAAI</em>, <em>126</em>, 106744. (<a
href="https://doi.org/10.1016/j.engappai.2023.106744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient and accurate model construction of an organic Rankine cycle (ORC) system is the key to its analysis, prediction, and optimization. As a typical multidisturbance nonlinear dynamic system, the ORC system always operates in a nonstationary state. Under uncertain disturbance, accurately identifying the thermal power conversion process state and quickly realizing the accurate association of various mappings are the key considerations of constructing the data-driven model of the ORC system. From the perspective of data selection, parameter association, and structural design, this study proposes a methodology for the efficient multilayer adaptive self-organizing modeling of ORC systems. This methodology can realize efficient autonomous modeling in the whole design process of the data-driven model of the ORC system. Moreover, the proposed methodology can minimize the structural risk of the model by balancing the empirical risk and structural complexity. By taking real data as the test base, the generalization ability and time cost of the data self-selection layer, information self-correlation layer and adaptive self-organizing part of the structure layer are evaluated. Compared with the direct construction of the ORC system data model, the proposed methodology can reduce the model construction time cost by 75.54% and improve the generalization ability by 61.88%. In addition, maximizing the generalization capability with minimum structural risk is an important part of data-driven model construction of ORC systems. In this study, a data-driven model structural reliability assessment approach for ORC systems is proposed. Then, the proposed adaptive self-organizing optimization methodology is verified on the basis of the structural reliability assessment model. The multilayer adaptive self-organizing modeling methodology proposed in this study can provide new ideas and necessary theoretical guidance.},
  archive      = {J_EAAI},
  author       = {Xu Ping and Fubin Yang and Hongguang Zhang and Chengda Xing and Anren Yang and Yan Wang},
  doi          = {10.1016/j.engappai.2023.106744},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106744},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient multilayer adaptive self-organizing modeling methodology for improving the generalization ability of organic rankine cycle (ORC) data-driven model},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physical-informed deep learning framework for CO2-injected
EOR compositional simulation. <em>EAAI</em>, <em>126</em>, 106742. (<a
href="https://doi.org/10.1016/j.engappai.2023.106742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CO 2 injection for enhanced oil recovery ( CO 2 -EOR) is one of the industry’s most widely applied techniques for CO 2 utilization. People use the compositional simulation technique to clearly describe CO 2 injection processes for EOR, which is always computational-expensive. The main objective of this study is to utilize deep learning (DL) techniques to describe phase behaviors and accelerate compositional simulations. First, we constructed a new DL-based compositional simulation framework. Instead of solving equations of state for every grid cell, this framework can aggregate millions of phase behavior solvers and determine all mixtures’ phase status in one single round of calculation. This trait can significantly improve the efficiency of solving numerical equations. Next, we illustrated how to develop DL-based phase behavior models to determine phase status accurately. Our newly proposed single-phase identification model can resolve the difficulty in inaccurate single-phase labeling within compositional simulations, greatly benefiting the numerical convergence of simulation. Finally, we tested abundant complicated cases covering near-miscible and miscible gas injection processes and demonstrated the new DL-based method’s strength in accelerating the compositional simulation. Besides, we also presented the DL-based method’s more substantial power in numerical convergences that it could succeed in cases where the standard simulation method fails. This work can contribute to more efficiently and effectively describing complex fluid displacement processes, benefiting CO 2 injection EOR and other utilizations like CO 2 sequestrations.},
  archive      = {J_EAAI},
  author       = {Ruixiao Sun and Huanquan Pan and Hongyu Xiong and Hamdi Tchelepi},
  doi          = {10.1016/j.engappai.2023.106742},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106742},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physical-informed deep learning framework for CO2-injected EOR compositional simulation},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast end-to-end method for automatic interior progress
evaluation using panoramic images. <em>EAAI</em>, <em>126</em>, 106733.
(<a href="https://doi.org/10.1016/j.engappai.2023.106733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interior construction makes up a large portion of project budget and time and is more prone to schedule delays. Most research efforts on progress management focus on exterior environment, while few on interior construction. Although progress monitoring methods based on laser point clouds and computer vision are investigated before, the problems of costly acquisition and creation of point clouds and images are still open, which impede the study of progress evaluation, particularly in interior construction environments where clutters and occlusions are universal. This paper introduces a method based on 360° panoramic images and deep learning for fast end-to-end interior progress evaluation in room units. The method takes only one or two 360° panoramic images as input, estimates key corners, generates and registers room layouts, and semantically segments sparse point cloud. With the extracted corners and segmentation results, the progress states of interior trades can be evaluated. The experimental results show that the proposed method based on deep learning techniques achieves comparable performance against those on public data sets with 3D Intersection over Union ( 3D IoU ) of 83.69% vs 84.23%, Corner Error ( CE ) of 0.4% vs 0.69%, and mean class Interaction over Union ( mIoU ) of 70.28% vs 53.5%. A case study of an interior decoration project of a hotel is adopted to demonstrate the feasibility and practical capabilities of the proposed method.},
  archive      = {J_EAAI},
  author       = {Xin Fang and Heng Li and Haitao Wu and Lang Fan and Ting Kong and Yue Wu},
  doi          = {10.1016/j.engappai.2023.106733},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106733},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast end-to-end method for automatic interior progress evaluation using panoramic images},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Converting semantic web services into formal planning domain
descriptions to enable manufacturing process planning and scheduling in
industry 4.0. <em>EAAI</em>, <em>126</em>, 106727. (<a
href="https://doi.org/10.1016/j.engappai.2023.106727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To build intelligent manufacturing systems that react flexibly in case of failures or unexpected circumstances, manufacturing capabilities of production systems must be utilized as much as possible. Artificial Intelligence (AI) and, in particular, automated planning can contribute to this by enabling flexible production processes. To efficiently leverage automated planning, an almost complete planning domain description of the real-world is necessary. However, creating such planning descriptions is a demanding and error-prone task that requires high manual efforts even for domain experts. In addition, maintaining the encoded knowledge is laborious and, thus, can lead to outdated domain descriptions. To reduce the high efforts, already existing knowledge can be reused and transformed automatically into planning descriptions to benefit from organization-wide knowledge engineering activities. This paper presents a novel approach that reduces the described efforts by reusing existing knowledge for planning and scheduling in Industry 4.0 (I4.0). For this purpose, requirements for developing a converter that transforms existing knowledge are derived from literature. Based on these requirements, the SWS2PDDL converter is developed that transforms the knowledge into formal Planning Domain Definition Language (PDDL) descriptions. The approach’s usefulness is verified by a practical evaluation with a near real-world application scenario by generating failures in a physical smart factory and evaluating the generated re-planned production processes. When comparing the resulting plan quality to those achieved by using a manually modeled planning domain by a domain expert, the automatic transformation by SWS2PDDL leads to comparable or even better results without requiring the otherwise high manual modeling efforts.},
  archive      = {J_EAAI},
  author       = {Lukas Malburg and Patrick Klein and Ralph Bergmann},
  doi          = {10.1016/j.engappai.2023.106727},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106727},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Converting semantic web services into formal planning domain descriptions to enable manufacturing process planning and scheduling in industry 4.0},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated chance-constrained stochastic model for a
preemptive multi-skilled multi-mode resource-constrained project
scheduling problem: A case study of building a sports center.
<em>EAAI</em>, <em>126</em>, 106726. (<a
href="https://doi.org/10.1016/j.engappai.2023.106726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-mode resource-constrained project scheduling problem (MRCPSP) with multiple skills is investigated in this paper. Unlike the traditional form of this problem, and considering the real-world project circumstances, project activities can be preempted. In this paper, a new multi-objective mixed-integer linear programming (MILP) model with three objective functions is extended. These objectives are: (1) minimizing the project makespan, (2) minimizing the total resource costs, and (3) minimizing the total project risk. Based on real-life projects, non-renewable resources are represented as an uncertain stochastic parameter. To cope with the uncertain environment, chance-constrained programming with a confidence level is considered. A real-world construction project of a sports center in Tehran is utilized to demonstrate the applicability of the presented formulation. A well-known lexicographic optimization method, namely AUGMECON2, is applied to solve the proposed formulation with three objectives. Ultimately, for the case study and two datasets J30 and MM50, the proposed lexicographic optimization algorithm is compared with an efficient multi-objective mathematical programming technique known as the AUGMECON method. The comparison is based on performance metrics (i.e., IGD and HV) commonly used in multi-objective optimization. The results show the relative dominance of the proposed lexicographic optimization algorithm over the AUGMECON method in all sizes of the problem instances.},
  archive      = {J_EAAI},
  author       = {Seyed-Ali Mirnezami and Reza Tavakkoli-Moghaddam and Reza Shahabi-Shahmiri and Mohammad Ghasemi},
  doi          = {10.1016/j.engappai.2023.106726},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106726},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated chance-constrained stochastic model for a preemptive multi-skilled multi-mode resource-constrained project scheduling problem: A case study of building a sports center},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A patent recommendation method based on KG representation
learning. <em>EAAI</em>, <em>126</em>, 106722. (<a
href="https://doi.org/10.1016/j.engappai.2023.106722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of patents is constantly increasing, providing an invaluable knowledge base. But retrieving this knowledge becomes ever more challenging with the increase in data. In this context, this study proposes a patent recommendation method based on knowledge graph (KG) representation. Although KG-based recommendation systems received broad attention in the literature, there is still a lack of literature that explores how it can be used for patent recommendations. First, and in terms of KG construction, the existing methods encounter issues when it comes to simultaneously accounting for accuracy and recall rate. This study proposes a combination of rule-based and deep learning methods for KG construction to solve this problem. Second, existing methods have performance and semantic association limitations when learning KG representations. This study therefore uses high-performance graph neural networks for encoding and models the semantic association limitations in graphs using traditional KG representation learning methods. Finally, existing recommendation systems usually focus on the semantic correlation between interaction items in recommendations, ignoring their direct relationships. This study therefore applies the KG representation learning method for the patent recommendation task, using KG representation learning to model the semantic association and constraints in the product–patent heterogeneous graph. Experiments based on a practical case example demonstrate that the proposed method outperforms baseline methods, and that it can guide innovative design processes. Findings have important implications for research and practice.},
  archive      = {J_EAAI},
  author       = {Yan Xiao and Congdong Li and Matthias Thürer},
  doi          = {10.1016/j.engappai.2023.106722},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106722},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A patent recommendation method based on KG representation learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MVMA-GCN: Multi-view multi-layer attention graph
convolutional networks. <em>EAAI</em>, <em>126</em>, 106717. (<a
href="https://doi.org/10.1016/j.engappai.2023.106717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of graph representation learning is highly dependent on the precise characterization of node relationships. However, representing the complex and diverse networks in the real world using a single type of node or link is challenging, often resulting in incomplete information. Moreover, different types of nodes and links convey rich information, which makes it difficult to design a graph network that can integrate diverse links. This paper introduces a novel multi-view and multi-layer attention model designed to optimize node embeddings for semi-supervised node classification. The proposed model exploits various types of inter-node links and employs the Hilbert–Schmidt independence criterion to maximize the dissimilarity between distinct node relationships. Furthermore, the multi-layer attention mechanism is used to discern the impact of different neighboring nodes and relationships between various node relationships. The performance of the proposed model, MVMA-GCN, was assessed on numerous real-world multi-view datasets. It was observed that MVMA-GCN consistently outperformed existing models, demonstrating superior accuracy in semi-supervised classification tasks. We have made our code publicly available at here to ensure the reproducibility of our results.},
  archive      = {J_EAAI},
  author       = {Pengyu Zhang and Yong Zhang and Jingcheng Wang and Baocai Yin},
  doi          = {10.1016/j.engappai.2023.106717},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106717},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MVMA-GCN: Multi-view multi-layer attention graph convolutional networks},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient city supply chain management through spherical
fuzzy dynamic multistage decision analysis. <em>EAAI</em>, <em>126</em>,
106712. (<a
href="https://doi.org/10.1016/j.engappai.2023.106712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this paper is to introduce several dynamic spherical fuzzy aggregation operators (AOs) for “multi-period decision-making” (MPDM) problems. In these problems, decision-makers (DMs) have access to all information in the form of spherical fuzzy numbers (SpFNs) that cover different time periods. AOs hold a crucial responsibility in the decision-making process, particularly in situations where there are conflicting factors that must be considered. When working with different data sets, the main problem is coming up with appropriate aggregating algorithms. “Spherical fuzzy dynamic Einstein weighted averaging (SpFDEWA) and spherical fuzzy dynamic Einstein weighted geometric (SpFDEWG) operators” are two novel Einstein AOs that we have introduced. These AOs have a number of enticing qualities that are discussed in detail. We also provide a method for dealing with MPDM issues using the best possible solutions. Along with an explanation of how the suggested method might be used, a numerical illustration of municipal supply chain management is given. A comparative analysis is conducted between the proposed and existing research to evaluate the efficacy of the proposed approach. An analysis of authenticity is also included to showcase the efficacy of the proposed strategy. Multi-stage and dynamic decision analysis are often pertinent to suggested pathways of action and decision-making processes in the real world.},
  archive      = {J_EAAI},
  author       = {Muhammad Riaz and Hafiz Muhammad Athar Farid and Chiranjibe Jana and Madhumangal Pal and Biswajit Sarkar},
  doi          = {10.1016/j.engappai.2023.106712},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106712},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient city supply chain management through spherical fuzzy dynamic multistage decision analysis},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Use of augmented output membership functions to improve
control accuracy of second-order fuzzy system. <em>EAAI</em>,
<em>126</em>, 106711. (<a
href="https://doi.org/10.1016/j.engappai.2023.106711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficacious application of fuzzy-based systems largely depends on some parameters of subjective decisions, e.g., fuzzy membership functions (MFs). The second-order fuzzy-based system with decoupling technique, which is generally a multi-inputs single-output (MISO) system executing augmented output MFs, is introduced to enhance the fuzzy system’s precision, heftiness, and recital. The best suitable protocol for input and output MFs is presented to design the input and output MFs in the discourse. The results of the uniformed and augmented designed output MFs are compared in identical circumstances. The experimental results and simulation results are in virtuous agreement. By applying the proposed method to different fuzzy systems, the mean absolute error (MAE) was reduced 82%, and the relative error was decreased to an adequate ( ≤ ± 10 % ) range. The control precision is enhanced, and the heftiness is improved by reducing the MAE through the proposed second-order fuzzy model. Furthermore, the energy and cost efficacy of the proposed second-order fuzzy model will be highly enhanced by applying the augmented output MFs.},
  archive      = {J_EAAI},
  author       = {Salah-ud-din Khokhar},
  doi          = {10.1016/j.engappai.2023.106711},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106711},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Use of augmented output membership functions to improve control accuracy of second-order fuzzy system},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ASVMK: A novel SVMs kernel based on apollonius function and
density peak clustering. <em>EAAI</em>, <em>126</em>, 106704. (<a
href="https://doi.org/10.1016/j.engappai.2023.106704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support Vector Machine (SVM) is one of the successful methods of machine learning. SVM uses kernel tricks to efficiently learn non-linear classification tasks. The kernel function is applied to each data instance to map the original non-linear observations into a higher-dimensional space in which they become separable. The Gaussian kernel in Radial-Basis Function (RBF) is a popular kernel function used in various kernelized learning methods. In the RBF kernel, the sigma parameter (bandwidth of kernel function) should be fine-tuned, which is a challenging job. If the sigma value is very small, the decision boundary is highly non-linear. On the other hand, if the sigma value is large, the decision boundary tends to be linear. In this paper, an efficient kernel method called the Apollonius SVM Kernel (ASVMK) is introduced. Our algorithm adjusts the width of the kernel based on the data density and the representativeness of each class. The main idea is to introduce a kernel without adjusting the bandwidth of the kernel based on landmark points and the Apollonius similarity function. ASVMK finds the correlation of dense points and their neighbors in the data and tries to map the original non-linear observations in the highest dimensional space from these features. Reducing memory problems and low computations due to the shrinkage of the gram matrix are some of the benefits of the proposed kernel. The proposed method outperformed the state-of-the-art methods by up to 11%.},
  archive      = {J_EAAI},
  author       = {Shahin Pourbahrami and Mohammad Ali Balafar and Leyli Mohammad Khanli},
  doi          = {10.1016/j.engappai.2023.106704},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106704},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ASVMK: A novel SVMs kernel based on apollonius function and density peak clustering},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reflectance material classification using optimized deep
learning and change detection of LANDSAT surface reflectance images.
<em>EAAI</em>, <em>126</em>, 106697. (<a
href="https://doi.org/10.1016/j.engappai.2023.106697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time-series changes that are affected by a specific alteration cannot be accurately found using change detection techniques. However, there are not many techniques available for identifying seasonal changes. This study develops a new deep model for identifying reflectance materials depending on optimization. At time instances “t” and “t-1” the images are accumulated in this instance. The Type 2 Fuzzy and Cuckoo Search-Based Filter (T2FCS) is used for the pre-processing of two images. Then, Fuzzy Local Information C-Means (FLICM) is used to segment both images. On the image accumulated at time “t” the feature extraction is performed to extract statistical features like mean, variance, kurtosis, energy, skewness, and standard deviation as well as imperative features like Local Optimal Oriented Pattern (LOOP), Local Ternary Pattern (LTP), Local Gabor XOR Pattern (LGXP), and others. The reflectance material is then categorized using a Deep Neuro-Fuzzy Network (DNFN) with segments created from images collected at time instance “t-1” and features collected from “t”. The proposed Jaya Student psychology-based optimization (JSPO), which was created by fusing the Jaya algorithm and the Student psychology-based optimization method(SPBO), is used here to train the DNFN. The segmented output that was collected at times “t” and “t-1” is then used to do the change detection. With the highest accuracy (94.1%) and maximum sensitivity (93.8%), the proposed JSPO-based DNFN demonstrated improved performance. For applications involving optical imagery, the Landsat program is crucial.},
  archive      = {J_EAAI},
  author       = {Madhuri Balasaheb Mulik and Jayashree V. and Pandurangarao N. Kulkarni},
  doi          = {10.1016/j.engappai.2023.106697},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106697},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reflectance material classification using optimized deep learning and change detection of LANDSAT surface reflectance images},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VasLine: Realize online detection and augmented NIR using
deep learning. <em>EAAI</em>, <em>126</em>, 106684. (<a
href="https://doi.org/10.1016/j.engappai.2023.106684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The chemical information acquisition capabilities of near infrared (NIR) have attracted great interests of investigators on exploring its potential as process analytical technologies (PAT) on the traditional Chinese medicine (TCM). However, due to the operation environment of TCM is complex and noisy, the accurate online composition detection and analysis is challenging and remains unsolved. Therefore, in this paper, we propose a new online TCM composition analysis platform for high quality online spectral data acquisition. We design, VasLine, a generative framework based on deep learning to estimate the multiple critical quality attributes (CQAs). To demonstrate the feasibility of the system, the platform was applied to the extraction process of Xiao’er Xiaoji Zhike Oral Liquid (XXZOL) and the framework was trained to estimate the content of the 7 CQAs. In the evaluation, we carried out 16 batches extraction experiments and collected extensive online NIR data, offline NIR data and high-performance liquid chromatography (HPLC) data for TCM composition analysis. The results show that the estimation accuracy of VasLine outperforms the state-of-the-art regression approaches significantly for all the 7 different CQAs, e.g., the R 2 metrics of VasLine for the CQAs are all higher than 0.95. This study aims to propose a novel generative framework based on a deep learning model, and the framework is applied in the self-developed platform to estimate CQAs with high-quality generative data from noisy online NIR accurately. The experiments for online TCM composition analysis show that VasLine is a new solution for the quality improvement of the actual pharmaceutical industry.},
  archive      = {J_EAAI},
  author       = {Zhongxin Chen and Yiran Shen and Binbin Chen and Jun Zhou and Panling Huang and Hengchang Zang and Yongxia Guan},
  doi          = {10.1016/j.engappai.2023.106684},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106684},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {VasLine: Realize online detection and augmented NIR using deep learning},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic segmentation using vision transformers: A survey.
<em>EAAI</em>, <em>126</em>, 106669. (<a
href="https://doi.org/10.1016/j.engappai.2023.106669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation has a broad range of applications in a variety of domains including land coverage analysis, autonomous driving, and medical image analysis. Convolutional neural networks (CNN) and Vision Transformers (ViTs) provide the architecture models for semantic segmentation. Even though ViTs have proven success in image classification, they cannot be directly applied to dense prediction tasks such as image segmentation and object detection since ViT is not a general purpose backbone due to its patch partitioning scheme. In this survey, we discuss some of the different ViT architectures that can be used for semantic segmentation and how their evolution managed the above-stated challenge. The rise of ViT and its performance with a high success rate motivated the community to slowly replace the traditional convolutional neural networks in various computer vision tasks. This survey aims to review and compare the performances of ViT architectures designed for semantic segmentation using benchmarking datasets. This will be worthwhile for the community to yield knowledge regarding the implementations carried out in semantic segmentation and to discover more efficient methodologies using ViTs.},
  archive      = {J_EAAI},
  author       = {Hans Thisanke and Chamli Deshan and Kavindu Chamith and Sachith Seneviratne and Rajith Vidanaarachchi and Damayanthi Herath},
  doi          = {10.1016/j.engappai.2023.106669},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106669},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic segmentation using vision transformers: A survey},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved saddle point prediction in stochastic two-player
zero-sum games with a deep learning approach. <em>EAAI</em>,
<em>126</em>, 106664. (<a
href="https://doi.org/10.1016/j.engappai.2023.106664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel deep learning approach for predicting saddle points in stochastic two-player zero-sum games. Our method combines neurodynamic optimization and deep neural networks. First, we model the stochastic two-player zero-sum game as an ordinary differential equation (ODE) system using neurodynamic optimization. Second, we develop a neural network to approximate the solution to the ODE system, which includes the saddle point prediction for the game problem. Third, we introduce a specialized algorithm for training the neural network to enhance the accuracy of the saddle point prediction. Our experiments demonstrate that our model outperforms existing approaches, yielding faster convergence and more accurate saddle point predictions.},
  archive      = {J_EAAI},
  author       = {Dawen Wu and Abdel Lisser},
  doi          = {10.1016/j.engappai.2023.106664},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106664},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved saddle point prediction in stochastic two-player zero-sum games with a deep learning approach},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-attribute group decision-making based on q-rung
orthopair fuzzy aczel–alsina power aggregation operators. <em>EAAI</em>,
<em>126</em>, 106629. (<a
href="https://doi.org/10.1016/j.engappai.2023.106629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to develop the Aczel–Alsina operational laws based on power aggregation operators (PAOs) for the q-Rung orthopair fuzzy set (FS) (q-ROFS) framework. Changing the parameter can alter these sets according to the degree of fluctuation, providing a range of options. The decision-making sciences use “q-ROFS” to describe the family of the most distinct fuzzy information thoughts. In response to the degree of variation, the q-ROFSs can increasingly adjust the information region by fluctuating the restriction q ≥ 1 , making numerous options. But on the other hand, PAOs have the advantage of vanishing the influence of awkward data from the final results. To take advantages of POAs, based on Aczel- Alsina (AA) operational laws, q-Rung orthopair fuzzy (q-ROF) AA power-weighted averaging (q-ROFAAPWA) and q-ROF AA power-weighted geometric (q-ROFAAPWG) operators are stated. Also, it studied that the proposed AOs fulfilled the conditions of boundedness, monotonicity, and idempotency. Based on these newly constructed AOs, a technique for dealing the multi-attribute group decision-making (MAGDM) problems is suggested. Numerous research, correlations with another modern approach and a numerical example of selecting stock market companies have been used to show the suggested system’s applicability. The sensitivity analysis of the developed method is examined. A comparative study with other prevailing methods is also providing for superiority analysis. Finally, we demonstrated that in the results and discussion section, the proposed AOs in the q-ROPFS framework are more reliable in aggregating information than intuitionistic fuzzy (IF) set (IFS) and Pythagorean FS (PyFS) frameworks.},
  archive      = {J_EAAI},
  author       = {Muhammad Rizwan Khan and Kifayat Ullah and Hanen Karamti and Qaisar Khan and Tahir Mahmood},
  doi          = {10.1016/j.engappai.2023.106629},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {106629},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-attribute group decision-making based on q-rung orthopair fuzzy Aczel–Alsina power aggregation operators},
  volume       = {126},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic empirical study on word embedding based methods
in discovering chinese black keywords. <em>EAAI</em>, <em>125</em>,
106775. (<a
href="https://doi.org/10.1016/j.engappai.2023.106775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of online transactions, the Chinese cyber black market is proliferating and facilitates many cybercrimes. It is difficult to understand the cyber black market due to the confusing jargon (called black keywords in this paper) used by criminals to conceal underground transactions. To discover black keywords automatically, some natural language processing based methods have been proposed by comparing the similarity of word vectors generated by word embedding models. Therefore, the quality of word vectors generated has a significant impact on black keyword discovery and it is necessary to evaluate different word embedding models in discovering black keywords. To this end, we design a Chinese black keyword discovery framework and conduct a systematic empirical study on six existing word embedding models including both static and dynamic types in discovering Chinese black keywords. In specific, we classify Chinese black keywords in four types: domain specific words (DSWs), new meaning words (NMWs), similar pronunciation words (SPWs), and similar glyph words (SGWs). We experimentally find that different word embedding models vary greatly in performance when discovering black keywords, e.g., dynamic models perform well in discovering DSWs and NMWs, static ones perform poorly in discovering NMWs. We improve the static word embedding model based NMW discovery algorithm by additionally comparing the differences in cross-corpus word nearest-neighbors before and after domain incremental training. For effectively discovering variant words like SPWs and SGWs, we additionally introduce Chinese pronunciation and glyph features. The experimental results demonstrate the effectiveness of the proposed Chinese black keyword discovery framework, with detection accuracies of over 90% for DSWs, 80% for NWMs, 90% for SPWs, and 61% for SGWs.},
  archive      = {J_EAAI},
  author       = {Chenyang Wang and Yi Shen and Yuwei Li and Min Zhang and Miao Hu and Jinghua Zheng},
  doi          = {10.1016/j.engappai.2023.106775},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106775},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic empirical study on word embedding based methods in discovering chinese black keywords},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Merged LSTM-based pattern recognition of structural behavior
of cable-supported bridges. <em>EAAI</em>, <em>125</em>, 106774. (<a
href="https://doi.org/10.1016/j.engappai.2023.106774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural responses of bridges occur based on their structural characteristics and conditions. After the structural pattern is identified from the long-term measured response datasets, the structural responses can be evaluated and predicted using a pattern model. In the absence of significant variations in the structural condition, the difference between the predicted and measured responses is negligible. Otherwise, the differences can be identified, and this would be evidence of the variation in the structural condition. Therefore, the structural pattern model can be used effectively to investigate variations in the structural state and conditions. This study proposes an effective structural pattern recognition method using deep learning. A merged model is proposed by combining deep neural network (DNN) and long short-term memory (LSTM) algorithms to handle long-term responses from various sensors in the time domain and reflect statistical properties. Long-term (five-year) measured response datasets of an existing cable-supported bridge were used to validate the proposed method. According to the study, the proposed method can effectively identify the structural behavioral pattern of a cable-supported bridge.},
  archive      = {J_EAAI},
  author       = {Seongi Min and Yunwoo Lee and Yong-Hoon Byun and Young Jong Kang and Seungjun Kim},
  doi          = {10.1016/j.engappai.2023.106774},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106774},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Merged LSTM-based pattern recognition of structural behavior of cable-supported bridges},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A GMDH model and parametric investigation of geopolymeric
recycled concrete FRP-spiral-confined members. <em>EAAI</em>,
<em>125</em>, 106769. (<a
href="https://doi.org/10.1016/j.engappai.2023.106769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the sustainability of the environment, minimization of the carbon dioxide (CO 2 ) emissions from the production of cement and resolving the issues related to the dumping of construction and demolition waste have become the most important measures. Furthermore, deep learning and numerical models have been required for the accurate predictions of the axial structural efficiency of glass fiber reinforced polymer (GFRP) reinforced geopolymeric recycled aggregate concrete (GRC) columns with synthetic fibers (GGRC columns). The present study investigated the behavior of novel GGRC columns under concentric and eccentric loads. A set of 9 circular spirals confined concrete columns (300 mm x 1200 mm) was produced. A new three-dimensional (3-D) finite element model (FEM) for capturing the mechanical efficacy of GGRC columns was put forward. A parametric study was carried out using the projected FEM to examine the impact of reinforcement of longitudinal FRP rebars ( ρ l ), compression stress of concrete ( f c o ′ ), the diameter of GGRC columns ( D ), Young’s modulus of FRP rebars ( E f ), the height of GGRC members ( H ), and the ultimate tensile stress of FRP rebars ( f y ). The results indicated that the GGRC members presented better structural efficiency in terms of axial stress and ductility under concentric and eccentric loads. The increment in axial stress for GGRC concentric members was noticed to be 9% at a reduction of spiral spacing from 100 mm to 50 mm. The suggested FEM portrayed 1.66% and 9.13% divergence of results for axial stress and relative axial strain of the samples, correspondingly. An artificial neural network (ANN) model was projected using the Group Method of Data Handling (GMDH) based on the previous experimental database for predicting the stress of GGRC members. The advised GMDH model performed well over the dataset by involving the axial contribution of GFRP bars and the confinement efficiency of spirals and reported the highest accuracy with M A E = 195.67, R M S E = 255.41, and R 2 = 0.94 as compared with the previous models.},
  archive      = {J_EAAI},
  author       = {Ali Raza and Selmi Abdellatif and Mohamed Hechmi El Ouni},
  doi          = {10.1016/j.engappai.2023.106769},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106769},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A GMDH model and parametric investigation of geopolymeric recycled concrete FRP-spiral-confined members},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault diagnosis based on residual–knowledge–data jointly
driven method for chillers. <em>EAAI</em>, <em>125</em>, 106768. (<a
href="https://doi.org/10.1016/j.engappai.2023.106768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is crucial for energy conversation in building energy systems. There are three different types of fault diagnosis methods: residual-, knowledge-, and data-driven. Each of them has its unique advantages and drawbacks. This study proposes a hybrid Bayesian network (HBN) to merge these methods to make their advantages complementary. The symptom layer of the HBN includes three different types of nodes: residual nodes composed of the feature residuals from the residual-driven part, knowledge nodes composed of the knowledge from the knowledge-driven part, and data nodes composed of the feature measurements from the data-driven part. Based on such fusion mechanisms, residual, knowledge, and data are merged into a single framework, and play roles in a parallel way, meaning that it can tolerate missing any kind of part in the fault diagnosis process. The proposed method can be easily customized by users, and, to a certain extent, overcomes the weaknesses of the individual methods when used separately, thus achieving outstanding field application performance. Meanwhile, a generic framework to develop the residual–knowledge–data jointly driven method is given. Applied to two experimental chillers and compared with existing frequently-used methods, the proposed method is proven to have better overall and individual performance.},
  archive      = {J_EAAI},
  author       = {Zhanwei Wang and Boyang Liang and JingJing Guo and Lin Wang and Yingying Tan and Xiuzhen Li},
  doi          = {10.1016/j.engappai.2023.106768},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106768},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis based on residual–knowledge–data jointly driven method for chillers},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preserving complex object-centric graph structures to
improve machine learning tasks in process mining. <em>EAAI</em>,
<em>125</em>, 106764. (<a
href="https://doi.org/10.1016/j.engappai.2023.106764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactions of multiple processes and different objects can be captured using object-centric event data. Object-centric event data represent process executions as event graphs of interacting objects. When applying machine learning techniques to object-centric event data, the event log has to be flattened into sequential process executions used as input for traditional process mining approaches. However, sequentializing the events by flattening removes the graph structure of object-centric event data and, therefore, constitutes an information loss. In this paper, we present a general approach to preserve the graph structures of object-centric event data across machine learning tasks in process mining. We provide two different techniques to preserve these structures depending on the required input format of machine learning techniques: as direct graph encodings or as graph embeddings. We evaluate our contributions by applying three different predictive process monitoring tasks to direct graph encodings, graph embeddings, and flattened event logs. Based on the relative performances, we assess the information contained in the graph structure of object-centric event logs that is, currently, lost in machine learning approaches for traditional process mining. Furthermore, we compare different graph embedding techniques for object-centric event logs to derive recommendations for future research and deployment. To conclude, we assess the improvement that graph embeddings constitute over state-of-the-art approaches that capture object information through specific features. Our contributions improve predictive process monitoring on object-centric event data and quantify the potential performance increases of predictive models. These contributions are especially relevant when looking at real-life applications of predictive process monitoring which are often applied to information systems with relational databases that contain multiple objects and, currently, still enforce flattening.},
  archive      = {J_EAAI},
  author       = {Jan Niklas Adams and Gyunam Park and Wil M.P. van der Aalst},
  doi          = {10.1016/j.engappai.2023.106764},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106764},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Preserving complex object-centric graph structures to improve machine learning tasks in process mining},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GFBLS: Graph-regularized fuzzy broad learning system for
detection of interictal epileptic discharges. <em>EAAI</em>,
<em>125</em>, 106763. (<a
href="https://doi.org/10.1016/j.engappai.2023.106763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy as the most common neurological disorder globally has drawn more and more attention. However, it is time-consuming and labor-intensive for manual detection of interictal epileptic discharges (IEDs). Thus, there is an urgent need to develop an efficient and automated detection approach as a more accurate diagnostic alternative for epilepsy detection. Recently, fuzzy broad learning system (FBLS) has been recognized as an alternative to deep learning and utilized in various fields. Nevertheless, FBLS ignores the locally invariant property of data. To effectively address this issue and further improve the performance of FBLS, a novel graph-regularized fuzzy broad learning system (GFBLS) is first proposed based on graph regularization. Moreover, an automated GFBLS-based approach is proposed for IEDs detection from EEG recordings. In the proposed method, graph convolutional neural networks (GCN) is firstly utilized to extract features from line graphs with undirected connections, which are constructed by EEG recordings, then extracted features by GCN are fed into GFBLS for IEDs detection. The experimental results demonstrated that GFBLS can achieve accuracy of 92.20%, specificity of 90.90% and precision of 91.13% with the training time of only 31.6 s, which is superior or comparable performance compared with other state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Zixuan Huang and Junwei Duan},
  doi          = {10.1016/j.engappai.2023.106763},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106763},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GFBLS: Graph-regularized fuzzy broad learning system for detection of interictal epileptic discharges},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot person re-identification based on feature set
augmentation and metric fusion. <em>EAAI</em>, <em>125</em>, 106761. (<a
href="https://doi.org/10.1016/j.engappai.2023.106761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification identifies pedestrians by analyzing image information from surveillance videos. However, it faces challenges like occlusion, changing lighting, and costly annotation. Thus, it is often performed in a few-shot environment with limited images. In response to the problem of insufficient available pedestrian images in person re-identification, a few-shot person re-identification method based on feature set augmentation and metric fusion is proposed. In this work, firstly, a feature augmentation method is introduced into the feature embedding module. This method introduces multi-head self-attention in different feature extraction layers and spatial attention in feature fusion of different feature extraction layers, which can extract more diverse and discriminative pedestrian features. Secondly, a dual metric method combining Euclidean and cosine distance is proposed in the metric module to comprehensively measure the absolute spatial distance and directional difference of pedestrian features. In this way, the reliability of pedestrian similarity measurement is improved. Then, pedestrian feature similarity scores are obtained separately using the dual metric and relation metric methods. Finally, the combined metric score is obtained by weighted fusion, and the combined metric score is used to construct the joint loss to realize the overall optimization and training of the network. Experimental results on three small datasets, Market-mini, Duke-mini, and MSMT17-mini, show that the proposed method significantly improves recognition performance compared to other few-shot learning algorithms. Specifically, in scenarios 5-way 1-shot and 5-way 5-shot, the average recognition accuracies are 92.54% and 96.99%, 87.93% and 96.08%, and 71.68% and 84.51%, respectively.},
  archive      = {J_EAAI},
  author       = {Guizhen Chen and Guofeng Zou and Yue Liu and Xiaofei Zhang and Guixia Fu},
  doi          = {10.1016/j.engappai.2023.106761},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106761},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Few-shot person re-identification based on feature set augmentation and metric fusion},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantized-state-based decentralized neural network control
of a class of uncertain interconnected nonlinear systems with input and
interaction time delays. <em>EAAI</em>, <em>125</em>, 106759. (<a
href="https://doi.org/10.1016/j.engappai.2023.106759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a quantized-state-based decentralized control strategy for uncertain interconnected nonlinear systems with time-varying delays under a networked control environment. Full state variables quantized via a uniform-hysteretic quantizer are available only for a decentralized adaptive control design. Unlike the existing decentralized adaptive recursive control designs, this study is focused on establishing a quantized-state-based decentralized learning mechanism for neural networks using discontinuously quantized states. Moreover, the stability of a decentralized neural network tracking system in the presence of time delays is analyzed. For each subsystem, a neural-network-based local adaptive tracker using a delay compensator is designed based on the local quantized state feedback. Technical lemmas pertaining to quantization errors and adaptive laws are presented to ensure the boundedness of all closed-loop signals and the convergence of local tracking errors to an adjustable neighborhood of the origin. Finally, illustrative simulations clarify and verify the decentralization strategy of the developed state-quantized adaptive tracking system. The control performance is evaluated using the root mean square control errors, where the values are 0.0293 and 0.0134 for each subsystem in Example 1 and 0.0467 and 0.0384 for each subsystem in Example 2.},
  archive      = {J_EAAI},
  author       = {Yun Ho Choi and Sung Jin Yoo},
  doi          = {10.1016/j.engappai.2023.106759},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106759},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantized-state-based decentralized neural network control of a class of uncertain interconnected nonlinear systems with input and interaction time delays},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Condition monitoring of wind turbine using novel deep
learning method and dynamic kernel principal components mahalanobis
distance. <em>EAAI</em>, <em>125</em>, 106757. (<a
href="https://doi.org/10.1016/j.engappai.2023.106757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring (CM) of wind turbine (WT) has been increasingly adopted for its fault diagnosis and maintenance decision-making. However, the data collected in CM is typically noisy, multidimensional, and highly nonlinear, which causes significant challenges in achieving the effective CM of WT. This paper proposes a novel CM method using a deep learning model with temporal pattern attention (TPA) and a dynamic kernel principal components Mahalanobis distance (DKPMD). The method can evaluate the WT performance accurately for detecting faults. First, outliers are recognized and removed using isolation forest improved by sparse autoencoder and fuzzy c-means clustering (FSIF) from raw wind turbine data of health state for enhancing the quality and reliability of data in modeling. Then, a gated recurrent unit (GRU) is developed for data reconstruction of the objective variables using LassoNet and TPA, which can capture the short- and long-term temporal relationships under different time steps based on selected variables. Meanwhile, kernel RMSE (KRMSE) is applied as a loss function, which avoids the negative effects of large reconstructed errors in parameter optimization. A condition index (CI) is constructed using DKPMD based on the reconstructed errors to consider the dynamic correlation between the variables. Finally, a delay perception-based IF(DPIF) is utilized to determine the threshold. Experiments with data from real WT demonstrate the effectiveness of the developed approach in detecting early abnormal conditions, which outperforms other state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Wenhe Chen and Hanting Zhou and Longsheng Cheng and Jing Liu and Min Xia},
  doi          = {10.1016/j.engappai.2023.106757},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106757},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Condition monitoring of wind turbine using novel deep learning method and dynamic kernel principal components mahalanobis distance},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive convolutional transformer for image restoration.
<em>EAAI</em>, <em>125</em>, 106755. (<a
href="https://doi.org/10.1016/j.engappai.2023.106755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, convolutional neural networks (CNNs) have become the primary workhorse for image restoration tasks. However, the deficiency of modeling long-range dependencies due to the local computational property of convolution greatly limits the restoration performance. To overcome this limitation, we propose a novel multi-stage progressive convolutional Transformer to recursively restore the degraded images, termed PCformer, which enjoys a high capability for capturing local context and global dependencies with friendly computational cost. Specifically, each stage of PCformer is an asymmetric encoder–decoder network whose bottleneck is built upon a tailored Transformer block with convolution operation deployed to avoid any loss of local context. Both encoder and decoder are convolution-based modules, thus allowing to explore rich contextualized information for image recovery. Taking the low-resolution features encoded by the encoder as tokens input into the Transformer bottleneck guarantees that long-range pixel interactions are captured while reducing the computational burden. Meanwhile, we apply a gated module for filtering redundant information propagation between every two phases. In addition, long-range enhanced inpainting is further introduced to mining the ability of PCformer to exploit distant complementary features. Extensive experiments yield superior results and in particular establishing new state-of-the-art results on several image restoration tasks, including deraining ( + 0 . 37 dB on Rain13K), denoising ( + 0 . 11 dB on DND), dehazing ( + 0 . 56 dB on I-HAZE), enhancement ( + 0 . 72 dB on SICE), and shadow removal ( + 0 . 65 RMSE on ISTD). The implementation code is available at https://github.com/Jeasco/PCformer .},
  archive      = {J_EAAI},
  author       = {Yecong Wan and Mingwen Shao and Yuanshuo Cheng and Deyu Meng and Wangmeng Zuo},
  doi          = {10.1016/j.engappai.2023.106755},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106755},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive convolutional transformer for image restoration},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data augmentation guided breast tumor segmentation based on
generative adversarial neural networks. <em>EAAI</em>, <em>125</em>,
106753. (<a
href="https://doi.org/10.1016/j.engappai.2023.106753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast tumor segmentation built on Dynamic Contrast-Enhanced Magnetic Resonance Imaging is a noteworthy phase for the quantifiable radiomics study of breast cancer. Manual tumor explanation is an inefficient method and encompasses medical associates, influenced, persuaded to error, and inter-user divergence. The quantities of contemporary preparations have exposed the competence of deep learning depictions in image segmentation. At this point, we designate a 3D Connected-AUNets for tumor segmentation from 3D MRIs built on encoder–decoder design. Owing to a constrained training dataset size, a generative adversarial networks channel is complementary to modernizing the input image itself to recognize the shared decoder and implement added controls on its layers. Based on the preliminary segmentation of Connected-AUNets, a fully connected 3D condition random field is used to improve segmentation results by determining 2D neighbor areas and 3D volume statistics. Furthermore, 3D connected components assessment is used to sustain around large components and reduce segmentation noise. The proposed system has been estimated on two regularly available datasets, apparently INbreast and the Curated Breast Imaging Subset of Digital Database for Screening Mammography. The proposed system has also been evaluated using a private dataset. The experimental significances show that the proposed model outperforms the state-of-the-art processes for breast tumor segmentation.},
  archive      = {J_EAAI},
  author       = {Balaji Kannappan and MariaNavin J.R. and Sridevi N. and Suresh P.},
  doi          = {10.1016/j.engappai.2023.106753},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106753},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data augmentation guided breast tumor segmentation based on generative adversarial neural networks},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An unsupervised learning based MCDM approach for optimal
placement of fault indicators in distribution networks. <em>EAAI</em>,
<em>125</em>, 106751. (<a
href="https://doi.org/10.1016/j.engappai.2023.106751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel integrated model based on multi-criteria decision-making (MCDM) method to assess and rank the feeder sections to optimally locate fault indicators in a large-scale distribution network. First, decision makers’ weights are computed based on the subjective weighting information. Then, dataset including data calculated for every alternative under active power flow, failure rate, repair time, number of customers, and customer type criteria are grouped using mixed-type clustering algorithm. This leads to the number of clusters extracted from the dataset, then obtained number of clusters are utilized to set the required linguistic terms. Finally, the ranking order of alternative is assessed by using the fuzzy similarity measure-based technique for order of preference by similarity to ideal solution (TOPSIS). The newly proposed model combines the merits of integrated enhanced particle swarm optimization (EPSO) fuzzy analytic hierarchy process (AHP) model in dealing with fuzziness and vagueness of linguistic assessments, the merits of clustering algorithm focused on representing performance values of each alternative with respect to each decision criterion and the merits of similarity measure-based TOPSIS in solving complex decision-making problems. The proposed model is applied to the RBTS4 and then sensitivity analysis is performed in the optimal solution.},
  archive      = {J_EAAI},
  author       = {Milad Khani and Reza Ghazi and Behnam Nazari},
  doi          = {10.1016/j.engappai.2023.106751},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106751},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An unsupervised learning based MCDM approach for optimal placement of fault indicators in distribution networks},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cooperative population-based iterated greedy algorithm for
distributed permutation flowshop group scheduling problem.
<em>EAAI</em>, <em>125</em>, 106750. (<a
href="https://doi.org/10.1016/j.engappai.2023.106750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the distributed permutation flowshop group scheduling problem (DPFGSP) with the consideration of minimizing total flowtime ( T F ), which has important applications in the modern manufacturing process. Based on the characteristics of the problem, a cooperative population-based iterated greedy (CPIG) algorithm is proposed by combining the advantages of the divide-and-rule policy, population-based evolution and iterated greedy algorithm. The CPIG divides the DPFGSP into two coupled sub-problems of group scheduling sub-problem and job scheduling sub-problem, and starts with a single population for simplicity. Unlike in the traditional cooperative co-evolutionary algorithms, the two-coupled sub-problems are addressed with a certain probability that can be determined in favor of solving the whole scheduling problem. Some advanced technologies are used, including the constructive heuristics based initialization, the critical factories based destruction and construction, the new best solution based population updating mechanism. The comprehensive experimental evaluation of 810 instances shows that the CPIG algorithm performs much better than the five state-of-the-art metaheuristics in the literature which are closely related to the considered scheduling problem.},
  archive      = {J_EAAI},
  author       = {Hui Zhao and Quan-Ke Pan and Kai-Zhou Gao},
  doi          = {10.1016/j.engappai.2023.106750},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106750},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A cooperative population-based iterated greedy algorithm for distributed permutation flowshop group scheduling problem},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale feature retention and aggregation for colorectal
cancer diagnosis using gastrointestinal images. <em>EAAI</em>,
<em>125</em>, 106749. (<a
href="https://doi.org/10.1016/j.engappai.2023.106749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colonoscopy is considered the gold standard for colorectal cancer diagnosis and prognosis. However, existing methods are less accurate and prone to overlooking lesions during gastrointestinal endoscopic examinations. Computer-assisted diagnosis combined with robot-assisted minimally invasive surgery (RMIS) can significantly help medical practitioners detect and treat lesions. Therefore, two novel architectures are developed for polyp and surgical instrument segmentation to aid colorectal cancer diagnosis, assessment, and treatment. Colorectal cancer segmentation network (CCS-Net) is the base network used in this study. It uses the maximum convolutional layers near the input image for effective feature extraction from low-level information. In addition, CCS-Net uses an efficient feature upsampling unit to efficiently increase the input spatial features’ map size. Hence, CCS-Net is capable of providing a fair performance with satisfactory computational efficiency The multi-scale feature retention and aggregation network (MFRA-Net) is the final network in this study. MFRA-Net is developed to improve the segmentation accuracy of the CCS-Net further as it uses multi-scale feature retention to retain low-level spatial features and transfers them to deep stages of the network. MFRA-Net also combines multi-scale high-strided low-level information with high-level information to boost network segmentation performance. Finally, all the transferred multi-scale features from the early stages of the network are aggregated with high-level features in the deep levels of the network. This multi-scale feature retention and aggregation mechanism enables the network to maintain a better segmentation performance compared with other methods even with challenging blur, specular reflection, low contrast, and high variation cases. We evaluated both architectures on four challenging datasets: Kvasir-SEG, CVC-ClinicDB, Kvasir-Instrument, and the UW-Sinus-Surgery-Live dataset. The proposed method achieves dice similarity coefficients of 95.98%, 94.19%, 92.81%, and 88.57% for the CVC-ClinicDB, Kvasir-SEG, Kvasir-Instrument, and UW-Sinus-Surgery-Live datasets. The proposed method achieves superior segmentation performance compared with state-of-the-art methods and requires only 4.9 million trainable parameters for complete training. Therefore, the proposed networks can effectively assist health professionals in surgical procedures and colorectal cancer diagnosis through surgical instruments and polyp segmentation, respectively.},
  archive      = {J_EAAI},
  author       = {Adnan Haider and Muhammad Arsalan and Se Hyun Nam and Jin Seong Hong and Haseeb Sultan and Kang Ryoung Park},
  doi          = {10.1016/j.engappai.2023.106749},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106749},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale feature retention and aggregation for colorectal cancer diagnosis using gastrointestinal images},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrating spherical fuzzy AHP and axiomatic design
approach and its application in human–machine interface design
evaluation. <em>EAAI</em>, <em>125</em>, 106746. (<a
href="https://doi.org/10.1016/j.engappai.2023.106746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–machine interface (HMI) design evaluation is critical in interactive product development because it directly affects the cost of subsequent design and user experiments. The evaluation information of HMI design mainly depends on the subjective perception and preference of experts, especially the hesitancy degree is rarely considered. We propose an integrated spherical fuzzy AHP (SF-AHP) and spherical fuzzy axiomatic design (SF-AD) method to choose a reasonable HMI alternative, considering the potential risks caused by the hesitancy degree of experts. Firstly, we introduce a process of automatically repairing inconsistent spherical fuzzy preference relations (SFPR) for SF-AHP. After that, we build suitable evaluation criteria and calculate the criteria weight by the SF-AHP method. We further extend the axiomatic design to the spherical fuzzy environment and propose a multi-criteria decision-making (MCDM) method based on SF-AD to evaluate HMI alternatives. The case analysis results demonstrate the effectiveness of the proposed method in the HMI design evaluation process, and the sensitivity and comparative analysis results indicate that the proposed method is stable and reliable.},
  archive      = {J_EAAI},
  author       = {Qinghua Liu and Jiadui Chen and Kai Yang and Dan Liu and Ling He and Qing Qin and Yuqing Wang},
  doi          = {10.1016/j.engappai.2023.106746},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106746},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrating spherical fuzzy AHP and axiomatic design approach and its application in human–machine interface design evaluation},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Hierarchical attention aggregation with multi-resolution
feature learning for GAN-based underwater image enhancement.
<em>EAAI</em>, <em>125</em>, 106743. (<a
href="https://doi.org/10.1016/j.engappai.2023.106743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, underwater image enhancement and restoration technologies have become increasingly important in order to optimize the efficiency of maritime operations and promote the automatic machine learning of the maritime industry. A new hierarchical attention aggregation with multi-resolution feature learning for GAN-based underwater image enhancement is proposed to address the problems of color bias, underexposure, and blurring in underwater images. The proposed method consists of a generator and a discriminator. Specifically, the generator includes an encoder, a bottleneck layer, and a decoder. Generator introduces inter-block serial connections for better adaptation to complex image scenes and task requirements, and parallel connections to extract multi-level features and enhance the expressive capacity of the network. To extract semantic and contextual information, hierarchical attention dense aggregation is designed in the encoder, which includes multi-scale feature hierarchy and dense feature hierarchy. Additionally, a multi-scale spatial attention mechanism is designed in the bottleneck layer to handle variations in underwater image scenes. In the decoder, the feature channel layer is emphasized, and a multi-channel attention mechanism is proposed to restore the multi-resolution channel features to a three-channel enhanced image. Furthermore, the angular loss function is introduced as additional supervision, which improves the similarity between the generated and original images, increases image clarity, and reduces color bias. Meanwhile, we employ the patch discriminator to enhance machine vision. Extensive experiments demonstrate that the proposed method outperforms state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Dehuan Zhang and Chenyu Wu and Jingchun Zhou and Weishi Zhang and Chaolei Li and Zifan Lin},
  doi          = {10.1016/j.engappai.2023.106743},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106743},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical attention aggregation with multi-resolution feature learning for GAN-based underwater image enhancement},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mul-DesLSTM: An integrative multi-time granularity deep
learning prediction method for urban rail transit short-term passenger
flow. <em>EAAI</em>, <em>125</em>, 106741. (<a
href="https://doi.org/10.1016/j.engappai.2023.106741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is critical for the management and control of urban rail transit (URT) to be able to predict passenger flow accurately and in real time. Considering that the high-resolution data aggregated by the automatic fare collection (AFC) system is wasted, this paper analyzes the problem of applying a multi-time granularity passenger flow data fusion forecasting process. First, we examine the challenge of constructing a dataset of passenger flow data with different time granularities. Thus, an algorithm is proposed for selecting passenger flow datasets with multi-time granularity. Furthermore, a multi-time granularity dense residual network (Mul-DesLSTM) with a dense residual structure and LSTM (long short-term memory) as the predictor is constructed, inspired by a residual network. Using Mul-DesLSTM, finer-grained passenger flow features can be fused layer by layer while maintaining the accuracy of traditional single-granularity passenger flow predictions. Lastly, Mul-DesLSTM is applied to the URT system of Shanghai, China, and compared with baselines. As a result, the proposed Mul-DesLSTM outperforms the baselines with LSTM as a predictor and state-of-the-art model. When the predicted time granularity is 30 min, compared to the single-time granularity LSTM network, the mean absolute error, root mean square error, and symmetric mean absolute percentage error can be reduced by 51%, 63%, and 15%, respectively. The results can serve as a reference and basis for the operation and management of URT systems.},
  archive      = {J_EAAI},
  author       = {Wenbo Lu and Yong Zhang and Peikun Li and Ting Wang},
  doi          = {10.1016/j.engappai.2023.106741},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106741},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mul-DesLSTM: An integrative multi-time granularity deep learning prediction method for urban rail transit short-term passenger flow},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Instance-specific algorithm configuration via unsupervised
deep graph clustering. <em>EAAI</em>, <em>125</em>, 106740. (<a
href="https://doi.org/10.1016/j.engappai.2023.106740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance-specific Algorithm Configuration (AC) methods are effective in automatically generating high-quality algorithm parameters for heterogeneous NP-hard problems from multiple sources. However, existing works rely on manually designed features to describe training instances, which are simple numerical attributes and cannot fully capture structural differences. Targeting at Mixed-Integer Programming (MIP) solvers, this paper proposes a novel instances-specific AC method based on end-to-end deep graph clustering. By representing an MIP instance as a bipartite graph, a random walk algorithm is designed to extract raw features with both numerical and structural information from the instance graph. Then an auto-encoder is designed to learn dense instance embeddings unsupervisedly, which facilitates clustering heterogeneous instances into homogeneous clusters for training instance-specific configurations. Experimental results on multiple benchmarks show that the proposed method can improve the solving efficiency of CPLEX on highly heterogeneous instances, and outperform existing instance specific AC methods.},
  archive      = {J_EAAI},
  author       = {Wen Song and Yi Liu and Zhiguang Cao and Yaoxin Wu and Qiqiang Li},
  doi          = {10.1016/j.engappai.2023.106740},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106740},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Instance-specific algorithm configuration via unsupervised deep graph clustering},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Portfolio optimization using predictive auxiliary classifier
generative adversarial networks. <em>EAAI</em>, <em>125</em>, 106739.
(<a href="https://doi.org/10.1016/j.engappai.2023.106739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In financial engineering, portfolio optimization has been of consistent interest. Portfolio optimization is a process of modulating asset distributions to maximize expected returns and minimize risks. Despite numerous studies on shallow learning models, they have shown limited success in analyzing the complex nature of massive stock data, a task where recent deep learning models excel. However, the deterministic nature of conventional deep learning models impedes their consideration of portfolio risk due to an inherent lack of uncertainty quantification in their predictions. This paper proposes a novel portfolio weighting strategy, incorporating both risk and return considerations within a deep learning framework. We propose the Predictive Auxiliary Classifier Generative Adversarial Networks (PredACGAN), a probabilistic deep learning model, to measure prediction uncertainty. The PredACGAN generator leverages latent vectors and historical stock prices to predict future returns. The model synthesizes predictive distributions from various latent vectors and past prices. The associated risk is produced via the entropy of these distributions, facilitating portfolio optimization through both return and risk considerations. The proposed algorithm removes high-risk assets from the investment universe at rebalancing moments, enabling PredACGAN to optimize portfolios considering both return and risk. We evaluated PredACGAN and the accompanying algorithm with S&amp;P 500 stocks from 1990 to 2020, with portfolios rebalanced monthly based on PredACGAN predictions and risk measures. The PredACGAN portfolios yielded 9.123% annual returns and a 1.054 Sharpe ratio, outperforming a risk-agnostic portfolio yielding 1.024% annual returns and a 0.236 Sharpe ratio. The PredACGAN portfolio also exhibited lower maximum drawdowns, highlighting its effectiveness.},
  archive      = {J_EAAI},
  author       = {Jiwook Kim and Minhyeok Lee},
  doi          = {10.1016/j.engappai.2023.106739},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106739},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Portfolio optimization using predictive auxiliary classifier generative adversarial networks},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Handling imbalanced class in melanoma: Kemeny–young rule
based optimal rank aggregation and self-adaptive differential evolution
optimization. <em>EAAI</em>, <em>125</em>, 106738. (<a
href="https://doi.org/10.1016/j.engappai.2023.106738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melanoma, despite its relatively low incidence compared to other types of skin cancer, accounts for a significant proportion of skin cancer-related deaths. Early detection of melanoma is crucial for improving patient survival rates. Deep learning algorithms, which heavily rely on data, are widely used in melanoma detection. However, the performance of these algorithms is greatly influenced by the distribution of the dataset, particularly class imbalance. In this manuscript, the authors present a novel method based on the Kemeny–Young rule for optimal rank aggregation to address the class imbalance problem in melanoma detection. The proposed approach aims to reduce class bias and enhance overall classification accuracy. Furthermore, a cost-sensitive learning approach is introduced to improve the classifier’s ability to handle class imbalance effectively. This novel cost-sensitive learning method utilizes Self-Adaptive Differential Evolution Optimization to determine optimal weights for each class. Our approach differs from traditional methods that assign weights based on predefined criteria. To evaluate the effectiveness of the proposed methods, extensive experiments and ablation studies are conducted on the highly imbalanced ISIC 2020 dataset, which is widely used in melanoma detection research. The Kemeny–Young rule-based majority voting achieves an overall error rate of 2.44%, while the cost-sensitive learning based on the Self-Adaptive Differential Evolution approach achieves an even lower error rate of 1.99%. Moreover, the proposed method achieves a sensitivity of 87.93% and a specificity of 98.19%. These experimental results demonstrate the competitiveness and effectiveness of the proposed methods in addressing the challenges posed by class imbalance and improving the accuracy of melanoma detection. By effectively mitigating class imbalance, these methods improve the accuracy and reliability of melanoma detection, thus offering valuable insights for developing advanced computer-aided diagnosis systems in dermatology. The relevant codes for our proposed approach are publicly available at: https://github.com/ctrl-gaurav/Handling-Imbalanced-Class-in-Melanoma .},
  archive      = {J_EAAI},
  author       = {Gaurav Srivastava and Nitesh Pradhan},
  doi          = {10.1016/j.engappai.2023.106738},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106738},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Handling imbalanced class in melanoma: Kemeny–Young rule based optimal rank aggregation and self-adaptive differential evolution optimization},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast o(NlgN) time hybrid clustering algorithm using the
circumference proximity based merging technique for diversified
datasets. <em>EAAI</em>, <em>125</em>, 106737. (<a
href="https://doi.org/10.1016/j.engappai.2023.106737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering has been widely employed for extracting intrinsic groups because of its low reliance on domain knowledge. Though several clustering techniques have been developed in the literature, the majority of them become inefficient due to their dependence on user-defined parameters or inability to cluster multi-scale datasets. To handle these issues, several hybrid clustering algorithms which combine the advantages of partitional, hierarchical, and graph-based clustering techniques have been developed. Hybrid clustering algorithms first partition the data into smaller clusters and then merge them into genuine clusters. However, most of them incur a quadratic time complexity which limits their application for large datasets. The proposed work presents a two-step fast hybrid clustering algorithm based on partitions and efficient merging to reduce the computational cost by maintaining the clustering quality. In the first step, the dispersion of the data is considered to produce balanced partitions. Then graph circumference proximity-based merging technique is proposed to merge the sub-clusters. The overall computational complexity of the algorithm is O ( N lg N ) where N is the number of data points, ignoring the dimension. To the best of our knowledge, this is the fastest known graph neighborhood-based hybrid clustering algorithm. Experimental results on various diversified datasets exhibit a significant improvement in the running time as well as cluster quality and robustness against noise.},
  archive      = {J_EAAI},
  author       = {Mohammad Maksood Akhter and Sraban Kumar Mohanty},
  doi          = {10.1016/j.engappai.2023.106737},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106737},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast O(NlgN) time hybrid clustering algorithm using the circumference proximity based merging technique for diversified datasets},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cocoa beans classification using enhanced image feature
extraction techniques and a regularized artificial neural network model.
<em>EAAI</em>, <em>125</em>, 106736. (<a
href="https://doi.org/10.1016/j.engappai.2023.106736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cut-Test technique employs visual inspection of interior coloration, compartmentalization, and defects of beans for effective classification of cocoa beans. However, due to its subjective nature and natural variations in visual perception, it is intrinsically limited, resulting in disparities in verdicts, imprecision, discordance, and time-consuming and labor-intensive classification procedures. Machine Learning (ML) techniques have been proposed to address these challenges with significant results, but there is still a need for improvement. In this paper, we propose a color and texture extraction technique for image representation, as well as a generalized, less complex Neural Network model, to help improve the performance of machine classification of Cut-Test cocoa beans. A total of 1400 beans were classified into 14 grades. Experimental results on the equal cocoa cut-test dataset, which is the standard publicly available cut-test dataset, show that the novel extraction method combined with the developed Artificial Neural Networks provides a more homogeneous classification rate for all grades, obtaining 85.36%, 85%, 83%, and 83% for accuracy, precision, recall, and F1 measure, respectively. The proposed model outperforms other ML models, such as Support Vector Machines, Decision Trees, Random Forests, and Naïve Bayes, on the same dataset. Additionally, the proposed ANN model demonstrates relatively better generalization when compared with earlier work by Santos on the same dataset. The proposed techniques in this work are robust on the cut-test dataset and can serve as an accurate Computer-Aided Diagnostic tool for cocoa bean classification.},
  archive      = {J_EAAI},
  author       = {Opoku Eric and Rose-Mary Owusuaa Mensah Gyening and Obed Appiah and Kate Takyi and Peter Appiahene},
  doi          = {10.1016/j.engappai.2023.106736},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106736},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cocoa beans classification using enhanced image feature extraction techniques and a regularized artificial neural network model},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained image recognition via attention interaction and
counterfactual attention network. <em>EAAI</em>, <em>125</em>, 106735.
(<a href="https://doi.org/10.1016/j.engappai.2023.106735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning subtle and discriminative regions plays an important role in fine-grained image recognition, and attention mechanisms have shown great potential in such tasks. Recent research mainly focuses on employing the attention mechanism to locate key discriminative regions and learn salient features, whilst ignoring imperceptible complementary features and the causal relationship between prediction results and attention. To address the above issues, we propose an Attention Interaction and Counterfactual Attention Network (AICA-Net). Specifically, we propose an Attention Interaction Fusion Module (AIFM) to model the negative correlation between the attention map channels to locate the complementary features, and fuse the complementary features and key discriminative features to generate richer fine-grained features. Simultaneously, an Enhanced Counterfactual Attention Module (ECAM) is proposed to generate a counterfactual attention map. By comparing the impact of the learned attention map and the counterfactual attention map on the final prediction results, quantifying the quality of attention drives the network to learn more effective attention. Extensive experiments on CUB-200-2011, FGVC-Aircraft and Stanford Cars datasets have shown that our AICA-Net can get outstanding results. In particular, it achieves 90.83% and 95.87% accuracy on two open competitive benchmark datasets CUB-200-2011 and Stanford Cars, respectively. Experiments demonstrate that our method outperforms state-of-the-art solutions.},
  archive      = {J_EAAI},
  author       = {Lei Huang and Chen An and Xiaodong Wang and Leon Bevan Bullock and Zhiqiang Wei},
  doi          = {10.1016/j.engappai.2023.106735},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106735},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fine-grained image recognition via attention interaction and counterfactual attention network},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MATC-net: Learning compact sequence representation for
hierarchical loop closure detection. <em>EAAI</em>, <em>125</em>,
106734. (<a
href="https://doi.org/10.1016/j.engappai.2023.106734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loop closure detection (LCD) is a challenging task to judge whether the current position of an intelligent robot returns to the previously visited position. Mainstream appearance-based approaches apply robust image representation techniques to describe the scene. However, most of these methods are designed for single images, and the sequence representation method incorporating temporal sequence information is still in the preliminary exploration. In this paper, we propose a compact sequence representation method for hierarchical LCD, ensuring conspicuous performance for the LCD task. Deriving from a group of global features of image sequences, we propose a multi-scale asymmetric temporal convolution network (MATC-Net), which generates sequential features and transformed global features through its aggregation branch and transformation branch, respectively. Based on these two types of features, a MATC-Net-based hierarchical LCD framework including two similarity measurement processes is constructed, through which the best place match is identified. The experimental results show that our method outperforms other counterparts on three datasets, exhibiting the promising potential of leveraging sequential features to LCD task.},
  archive      = {J_EAAI},
  author       = {Fuji Fu and Jinfu Yang and Jiahui Zhang and Jiaqi Ma},
  doi          = {10.1016/j.engappai.2023.106734},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106734},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MATC-net: Learning compact sequence representation for hierarchical loop closure detection},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The determination of limit wheel profile for hunting
instability of railway vehicles using stacking feature deep forest.
<em>EAAI</em>, <em>125</em>, 106732. (<a
href="https://doi.org/10.1016/j.engappai.2023.106732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheel and rail profiles have significant impacts on the vehicle system dynamics. Improper wheel and rail profiles lead to the decay of vehicle dynamics performance, hunting instability and derailment. In this study, we propose a model, stacking feature deep forest, to determine the limit wheel profile for hunting instability using wheel/rail geometric contact parameters. We calculate the critical speed of the vehicles under various wheel and rail profiles and record their wheel/rail geometric contact parameters as samples. Two experiments are conducted. One is the binary classification aiming to identify whether the wheel/rail geometric contact parameters guarantee the vehicle’s critical speed is higher than the threshold of its operational speed. The other is the multi-classification to determine the interval of the critical speed. The results show the stacking feature deep forest achieves an accuracy of 85.10% on the test set which is higher than other popular ensemble models. However, all models’ accuracy is lower than 70% in multi-classification. The Shapley additive explanations are utilized to enhance the explainability of the stacking feature deep forest. The Shapley additive explanation importance reveals that the equivalent conicity of 1 mm has the most impact on hunting. Its importance is 1.32 times more than the equivalent conicity of 3 mm. Nevertheless, the equivalent conicity of 3 mm is nearly positively correlated to the hunting probability and this characteristic is suitable as a qualitative criterion.},
  archive      = {J_EAAI},
  author       = {Xinliang Dai and Sheng Qu and Caihong Huang and Pingbo Wu},
  doi          = {10.1016/j.engappai.2023.106732},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106732},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The determination of limit wheel profile for hunting instability of railway vehicles using stacking feature deep forest},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-model: Revised imaging network and visual perception
correction for underwater image enhancement. <em>EAAI</em>,
<em>125</em>, 106731. (<a
href="https://doi.org/10.1016/j.engappai.2023.106731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the limitation of a single physics-based or deep learning-based method, this paper proposes an effective Dual-model methodology for underwater image enhancement. The Dual-model mainly consists of two branches: the Revised Imaging Network-model (RIN-model) and the Visual Perception Correction-model (VPC-model). Specifically, instead of directly learning an image-to-image mapping strategy, the RIN-model constructs a compact network to estimate the ambient-light and direct-transmission parameters, which are used to reconstruct the preliminary enhanced image based on the revised underwater image formation model. Based on the pre-trained RIN-model, the ambient-light and direct-transmission parameters estimated using only a single input image may be biased, especially for these severely degraded underwater images. To further correct the visual perception of the preliminary enhanced image, the VPC-model incorporates the adaptive-stretching histogram and relative-stretching histogram for contrast enhancement and color restoration, respectively. We also present an adaptive color balance compensation method to estimate the maximum attenuation channel and equalize the information distribution of the three channels in the preliminary enhanced image, which acts as a transition procedure to prevent color distortion or detail destruction caused by excessive stretching in the VPC-model. Comprehensive qualitative and quantitative evaluations have revealed that our Dual-model outperforms seven state-of-the-art underwater image enhancement methods, including the MLLE, Haze-Lines, HLRP, ACDC, UWCNN, FUnIE-GAN, and Water-Net. In the UIEB and EUVP datasets, our methodology achieves relatively better performance than other methods on both full-reference and no-reference evaluation metrics. We also validate that the proposed methodology facilitates the advanced image applications of local feature matching and edge detection.},
  archive      = {J_EAAI},
  author       = {Huajun Song and Laibin Chang and Hao Wang and Peng Ren},
  doi          = {10.1016/j.engappai.2023.106731},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106731},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-model: Revised imaging network and visual perception correction for underwater image enhancement},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revolutionizing sentiment classification: A deep learning
approach using self-attention based encoding–decoding transformers with
feature fusion. <em>EAAI</em>, <em>125</em>, 106730. (<a
href="https://doi.org/10.1016/j.engappai.2023.106730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the growth of human computer interaction and Artificial Intelligence attains more interest especially in facial expression detection. Though the field has attained tremendous progress, still many issues are pertained as the facial expressions are complex. Therefore the present study aims to increase the efficiency in classifying the emotions of humans from the images of FER-2013 dataset and strives to attain optimal accuracy. Most of the studies have averted multi-modal parameters like a video for emotion detection. Moreover, existing studies lacked a detection rate due to ineffective feature extraction that negatively impacted the classification rate. For avoiding such pitfalls, this study proposes suitable data mining-based algorithms with the main intention to attain high accuracy. The present study proposes Deep Location Attention Forest method for emotion detection with higher accuracy. To accomplish this, DLFAT (Deep Location Feed Attention Transformers) is used for feature extraction from various sub-space representation at different position of the image. CK-PCA (Canonical Kernel-Principal Component Analysis) is performed feature fusion to improve the performance of the classifier. MRF (Modified Random Forest) is proposed to perform classification and predicts the emotions based on the facial expressions. The main intention of RF relies on learning all the data subset weights that alleviate loss amongst the predicted value for accomplishing better input classification to the related label. The proposed system is validated by the performance metrics in which the outcome is found to be 0.96197 as accuracy, 0.96 as F1-Score, 0.97 as recall and 0.96 as precision and the outcomes reveal the efficacy of the system in emotion detection.},
  archive      = {J_EAAI},
  author       = {Tejashwini S.G. and Dr. Aradhana D.},
  doi          = {10.1016/j.engappai.2023.106730},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106730},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Revolutionizing sentiment classification: A deep learning approach using self-attention based encoding–decoding transformers with feature fusion},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DRNet: Dual-stage refinement network with boundary inference
for RGB-d semantic segmentation of indoor scenes. <em>EAAI</em>,
<em>125</em>, 106729. (<a
href="https://doi.org/10.1016/j.engappai.2023.106729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a dense pixel prediction task, and its accuracy depends on the extraction of long-range contextual knowledge and refinement of segmentation boundaries. Most segmentation methods are based on feature extraction using a convolutional neural network, and layer-by-layer sampling and fusion are applied to solve inherent problems such as chaotic boundaries and scattered objects. Owing to the limited receptive field and loss of details during downsampling, the segmentation results may be unsatisfactory. To address existing shortcomings, we propose a dual-stage refinement network (DRNet) for semantic segmentation. In the first stage, we adopt an efficient spatiotemporal representation learning framework called UniFormer. We also use a novel boundary extractor and initial segmentation map generator to obtain rough segmentation results. In the second stage, we use the rough segmentation map and extracted boundary information in a graph reasoning module that restores the class boundary features while completing global modeling and local information inference. Benefiting from the acquisition of long-range dependencies between image pixels, contextual information promotes the distinction of pixel categories. In addition, edge information can increase the interclass distinguishability and refine the segmentation boundaries. Results from extensive experiments demonstrate that the proposed DRNet outperforms state-of-the-art semantic segmentation methods. The codes and results are available at: https://github.com/EnquanYang2022/DRNet .},
  archive      = {J_EAAI},
  author       = {Enquan Yang and Wujie Zhou and Xiaohong Qian and Jingsheng Lei and Lu Yu},
  doi          = {10.1016/j.engappai.2023.106729},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106729},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DRNet: Dual-stage refinement network with boundary inference for RGB-D semantic segmentation of indoor scenes},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoBERT: A contextual BERT model for recommending
employability profiles of information technology students in unstable
developing countries. <em>EAAI</em>, <em>125</em>, 106728. (<a
href="https://doi.org/10.1016/j.engappai.2023.106728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unemployment constitutes one of the major problems in developing countries, with factors such as unavailable skills and the proliferation of unskilled workers being cited as main causes. The existing literature has shown that using social networks analysis techniques, employment options for students and graduates can be accurately generated through recommender systems (RS) to optimize the chances of employment. Therefore, this study proposes a fine-tuned Bidirectional Encoder Representations from Transformers (BERT) model named Contextual BERT (CoBERT) for item-centered content-based (CB) filtering RS. The model uses socio-political background, graduate-employer relationship and graduate academic competencies of information technology (IT) students as contextual factors to recommend employability profiles of IT students in unstable developing countries (UDCs) such as the Democratic Republic of Congo (DRC). The performance of the proposed model is verified using four metrics. To evaluate the online performance of the model, the metrics of Diversity and Novelty are used. The metrics of normalized discounted cumulative gain (nDCG) and mean average precision (MAP) are applied to evaluate the model offline. The proposed model shows a high nDCG value at Top-N=4, equaling to 0.99. Validation statistics of 0.5 MAP score and significant t-statistics test values for Diversity and Novelty indicate that the proposed model can be generalized in the DRC and other similar UDCs. The RS model proposed in the current study contributes to the literature on employability models by advancing beyond traditional approaches such as fuzzy logic (FL), and also by taking graduate skills into account. The proposed model is a novel employability recommendation technique that provides highly precise and contextual recommendations. The output from this study contributes a theoretical foundation for implementing RSs in education and the industry.},
  archive      = {J_EAAI},
  author       = {Héritier Nsenge Mpia and Lucy Waruguru Mburu and Simon Nyaga Mwendia},
  doi          = {10.1016/j.engappai.2023.106728},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106728},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CoBERT: A contextual BERT model for recommending employability profiles of information technology students in unstable developing countries},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-variety and small-batch production quality forecasting
by novel data-driven grey weibull model. <em>EAAI</em>, <em>125</em>,
106725. (<a
href="https://doi.org/10.1016/j.engappai.2023.106725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the coming of intelligent manufacturing, multi-variety and small-batch production mode has gradually become popular. Aiming at the characteristics of high dimensional information and limited samples in this mode, a novel data-driven grey Weibull model is established for product quality prediction. Firstly, a high-dimensional information from the production process is integrated as the process variation using a data-driven method. Then, the quality prediction function is deducted by considering that process variation follows Weibull distribution-based mechanism, the Hausdorff difference scheme is adopted to weaken the error from the difference to the differential, heuristic algorithm is selected to optimize the distribution parameters of the model. Finally, an experimental analysis is designed using the dataset from some personalized customization manufacturer in China. Results show that the proposed model is not only superior to the other eight models in terms of stability and prediction accuracy, but also boasts the features of amalgamation of data-driven and mechanism-driven methods, which can simultaneously process high-dimensional information and limited samples in multi-variety and small-batch production system.},
  archive      = {J_EAAI},
  author       = {Qinzi Xiao and Mingyun Gao and Lin Chen and Mark Goh},
  doi          = {10.1016/j.engappai.2023.106725},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106725},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-variety and small-batch production quality forecasting by novel data-driven grey weibull model},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning based dual flat-spherical indentation
approach for rough metallic surfaces. <em>EAAI</em>, <em>125</em>,
106724. (<a
href="https://doi.org/10.1016/j.engappai.2023.106724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instrumented indentation test (IIT) is regarded as one of the non-destructive test methods for mechanical characterization and safety assessment of engineering components. However, indentation test is very sensitive to surface topography i.e surface roughness, requiring specimens with ideally flat and smooth surface for producing reliable and reproducible test results. Recently, a dual flat-spherical indentation (DFSI) technique was proposed to extract material properties directly from rough metallic surface via indentation tests. Integration of DFSI technique with machine learning (ML) approach can facilitate reliable and fast characterization of rough metallic surfaces. Here, ML models including artificial neural network (ANN) and physics-informed artificial neural network (PI-ANN) are established, and then trained by using a database of indentation parameters generated via DFSI simulations. Spherical indentation techniques available in the literature are used to calculate the physics-informed loss in the PI-ANN model. The performances of trained ANN and PI-ANN models are compared, and an optimal ML model with hyperparameters is suggested based on validation study; PI-ANN model with sigmoid activation function shows a better performance than the ANN model and baseline model. The model performances are evaluated by performing DFSI experiments with SM45C and SS304. The applicability of ML based-DFSI method is demonstrated for extracting the mechanical properties from the rough surface of general metals.},
  archive      = {J_EAAI},
  author       = {Karuppasamy Pandian Marimuthu and Jaemu Lee and Giyeol Han and Hyungyil Lee},
  doi          = {10.1016/j.engappai.2023.106724},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106724},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning based dual flat-spherical indentation approach for rough metallic surfaces},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving attention network to realize joint extraction for
the construction of equipment knowledge graph. <em>EAAI</em>,
<em>125</em>, 106723. (<a
href="https://doi.org/10.1016/j.engappai.2023.106723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of promoting autonomous decision, intelligent interaction, and concept recognition of the equipment, constructing an equipment Knowledge Graph (KG) is the key technology to facilitate this. In this article, we propose a method that combines design rules and automatic extraction to construct equipment KG from equipment manuals. We define that equipment KG is scheme-based and depicts scheme in the form of KG triples (a.k.a design rules, scheme layer of KG, or concept KG). Our contributions include designing an initial concept KG for the equipment domain and improving the BERT (Bidirectional Encoder Representations from Transformers) model to jointly extract knowledge from texts to enrich the KG. The BERT model was improved from internal calculations so that joint extraction could be achieved directly without extra additional parts. We applied our model to a standard dataset “SemEval2010 Task 8” and achieved the F1 score of 89.55 which demonstrates its rationality. We also established a dataset called “Equipment Manuals Corpus for KG” based on the concept KG and applied the joint model in the dataset to extract knowledge. The result was visualized in the form of a graph.},
  archive      = {J_EAAI},
  author       = {Huanrong Ren and Maolin Yang and Pingyu Jiang},
  doi          = {10.1016/j.engappai.2023.106723},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106723},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving attention network to realize joint extraction for the construction of equipment knowledge graph},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Neural network-based analytical solver for fokker–planck
equation. <em>EAAI</em>, <em>125</em>, 106721. (<a
href="https://doi.org/10.1016/j.engappai.2023.106721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fokker–Planck equation has significant applications in dynamical systems. In recent years, some neural network methods have been used in combination with physical models to obtain its numerical solutions. However, it is also appealing if the analytical solution of the physical model can be obtained. This paper proposes a neural network-based method for the analytical solution of the FP equation. It relies on neural networks and uses their explicit model as the trial function for the FP equation. The trial function contains the weights and biases in the neural network. Therefore, the solving of the FP equation is converted into the calculation of the weights and biases. In the proposed method, the FP equations are first reduced to a set of easily solvable nonlinear algebraic equations using some trial functions, and then the corresponding weights and biases are determined using the method of pending coefficients. In this paper, linear and nonlinear numerical examples were used to verify the effectiveness of the proposed method. The results demonstrated that the proposed method can obtain the exact solution of the FP equations without data samples. Finally, the proposed method is compared in detail with physics-informed neural networks in terms of computational theory and computational effectiveness.},
  archive      = {J_EAAI},
  author       = {Yang Zhang and Run-Fa Zhang and Ka-Veng Yuen},
  doi          = {10.1016/j.engappai.2023.106721},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106721},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural network-based analytical solver for Fokker–Planck equation},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Internet of agriculture: Analyzing and predicting tractor
ride comfort through supervised machine learning. <em>EAAI</em>,
<em>125</em>, 106720. (<a
href="https://doi.org/10.1016/j.engappai.2023.106720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to improve ride comfort among tractor drivers by utilizing Internet of Things (IoT) technology and Machine Learning (ML) techniques to analyze and predict vibration exposure. The study explores the association between tractor ride characteristics, including average speed, tool depth, and pulling force, and ride comfort during actual rotary soil tillage operations. Ride comfort was evaluated by calculating the Overall Vibration Value (OVV) at three measurement locations (i.e., the floor, seat pan, and seat backrest). The study employed spectral analysis i.e., Fast Fourier Transform (FFT) and Power Spectral Density (PSD) to determine the predominant resonant frequencies. In addition, ML approaches i.e., Linear Regression (LR), Decision Tree Regressor (DTR), Support Vector Regression (SVR), Gaussian Process Regression (GPR), and Artificial Neural Network (ANN) were used to predict ride comfort response. Three hyperparameter optimization techniques, including Grid Search, Random Search, and Bayesian optimization were used. Tractor-tiller system was operated on a real agricultural field by five male tractor drivers. Vibration levels were measured along three translational axes at three measurement locations using a smart monitoring device based on the IoT concept. Average OVV magnitude was computed as 0.84 m/s 2 i.e., exceeding the ISO 2631-1 (1997) threshold limits. FFT and PSD analysis revealed a variety of dominant frequencies, including resonance peaks at 2 Hz, 6–7 Hz, and 9–11 Hz. The analysis of variance (ANOVA) indicates that tractor speed and tool depth are significant variables (at the 5% level) in determining ride comfort. Regarding predictive accuracy, the ANN model exhibits the highest coefficient of determination of 0.90, followed by the SVM and GPR models with a coefficient of determination of 0.89. The DTR and LR models demonstrate slightly lower coefficient of determination values of 0.83 and 0.82, respectively. Furthermore, Bayesian optimization proved to be an effective approach in achieving more accurate predictions of tractor ride comfort. In general, the study outcomes can be utilized by tractor designers in numerous ways to optimize tractor design (such as suspension system, cab design, seat design, etc.) to improve tractor ride comfort in real field applications.},
  archive      = {J_EAAI},
  author       = {Amandeep Singh and Naser Nawayseh and Harwinder Singh and Yash Kumar Dhabi and Siby Samuel},
  doi          = {10.1016/j.engappai.2023.106720},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106720},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Internet of agriculture: Analyzing and predicting tractor ride comfort through supervised machine learning},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling public opinion dissemination in a multilayer
network with SEIR model based on real social networks. <em>EAAI</em>,
<em>125</em>, 106719. (<a
href="https://doi.org/10.1016/j.engappai.2023.106719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity of social relationships, Internet users are active in multiple social networks and receive or release information in various ways and channels. Therefore, the spread of public opinion is not limited to a closed single network. Considering the structural characteristics of WeChat, Weibo and Tiktok, we built a multi-layer network based on the complex network theory. Based on the environmental and personal factors, the calculation methods of transmission rate and immunity rate is proposed. The trends of information transmission in the multi-layer network is simulated through an improved SEIR model. Through simulation, the differences of information transmission between multi-layer networks and single-layer networks are explored, and the impacts of network structure, coupling strength between layers and interlayer connection mode on information transmission are studied. More than 76,000 tweets from 7 events on Weibo are collected to verify the effectiveness of the model and explore the dissemination trends of actual public opinions. Through the research, it is found that (1) the public opinion transmission efficiency of multi-layer network is higher, the scale is larger, and the time is longer. (2) Compared with Weibo and Tiktok, the information transmission in WeChat is more efficient and lasts longer, and promotes the information transmission in the other two networks. (3) With the increase of coupling strength between layers, the efficiency of information transmission becomes higher and the scale becomes larger. This study provides new ideas for the research of public opinion dissemination, and helps relevant departments to correctly guide public opinion.},
  archive      = {J_EAAI},
  author       = {Lixiao Geng and Shuran Yang and Ke Wang and Qi Zhou and Lisha Geng},
  doi          = {10.1016/j.engappai.2023.106719},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106719},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modeling public opinion dissemination in a multilayer network with SEIR model based on real social networks},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving news headline text generation quality through
frequent POS-tag patterns analysis. <em>EAAI</em>, <em>125</em>, 106718.
(<a href="https://doi.org/10.1016/j.engappai.2023.106718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Original synthetic content writing is one of the human abilities that algorithms aspire to emulate. The advent of sophisticated algorithms, especially based on neural networks has shown promising results in recent times. A watershed moment was witnessed when the attention mechanism was introduced which paved the way for transformers, a new exciting architecture in natural language processing. Recent sensations like GPT and BERT for synthetic text generation rely on NLP transformers. Although, GPT and BERT-based models are capable of generating creative text given they are properly trained on abundant data, however, the generated text suffers the quality aspect when limited data is available. This is especially an issue for low-resource languages where labeled data is still scarce. In such cases, the generated text, more often than not, lacks the proper sentence structure, thus unreadable. This study proposes a post-processing step in text generation that improves the quality of generated text through the GPT model. The proposed post-processing step is based on the analysis of POS tagging patterns in the original text and accepts only those generated sentences from GPT which satisfy POS patterns that are originally learned from the data. We exploit the GPT model to generate English headlines by utilizing Australian Broadcasting Corporation (ABC) news dataset. Furthermore, for assessing the applicability of the model in low-resource languages, we also train the model on the Urdu news dataset for Urdu news headlines generation. The experiments presented in this paper on these datasets from high- and low-resource languages show that the performance of generated headlines has a significant improvement by using the proposed headline POS pattern extraction. We evaluate the performance through subjective evaluation as well as using text generation quality metrics like BLEU and ROUGE.},
  archive      = {J_EAAI},
  author       = {Noureen Fatima and Sher Muhammad Daudpota and Zenun Kastrati and Ali Shariq Imran and Saif Hassan and Nouh Sabri Elmitwally},
  doi          = {10.1016/j.engappai.2023.106718},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106718},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving news headline text generation quality through frequent POS-tag patterns analysis},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A probabilistic reliable linguistic PROBID method for
selecting electronic mental health platforms considering users’ bounded
rationality. <em>EAAI</em>, <em>125</em>, 106716. (<a
href="https://doi.org/10.1016/j.engappai.2023.106716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reports of deteriorating mental health among citizens constitute an urgent global health alert. Electronic mental health (EMH) platforms are a great resource for mitigating mental health disorders. Extant literature on EMH has determined the attributes and indicators that reflect the feasibility, acceptability and safety of EMH platforms. However, these evaluation indicators are complex and usually conflict each other in the decision-making process. Moreover, the evaluation indicators are qualitative in nature and may be characterized by fuzziness and imprecision. Therefore, selecting an EMH platform becomes a complex cognitive process. Given the ubiquity of EMH platforms and the absence of a comprehensive decision-making model, we present a novel probabilistic reliable linguistic multi-attribute decision making (PRLMADM) model. With this model, we employ the probabilistic reliable linguistic term sets (PRLTSs) to solve decision makers’ (DMs) uncertainty and reliability of evaluation information. We construct a novel Pearson correlation measure for PRLTSs and extend it to design a weighting method known as probabilistic reliable linguistic CRiteria Importance Through Inter-criteria Correlation (PRL-CRITIC). Employing the TODIM (an acronym in Portuguese for Interactive Multicriteria Decision Making) and the PROBID (Preference Ranking on the Basis of Ideal-average Distance) techniques, we propose the probabilistic reliable linguistic (PRL) TODIM-based PROBID ranking approach, which considers the DMs’ bounded rationality. Finally, we present an illustrative example of EMH platform selection to prove the applicability of the proposed model. We demonstrate the benefits of our probabilistic reliable linguistic TODIM-based PROBID model through a series of comparisons and sensitivity analyses.},
  archive      = {J_EAAI},
  author       = {Adjei Peter Darko and Collins Opoku Antwi and Kwame Omono Asamoah and Evans Opoku-Mensah and Jun Ren},
  doi          = {10.1016/j.engappai.2023.106716},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106716},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A probabilistic reliable linguistic PROBID method for selecting electronic mental health platforms considering users’ bounded rationality},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated failure analysis using machine learning
predictive system for smart management of medical equipment maintenance.
<em>EAAI</em>, <em>125</em>, 106715. (<a
href="https://doi.org/10.1016/j.engappai.2023.106715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study aims to develop the failure analysis predictive models, which prognosticate first failure event (FFE), failure-to-year ratio (FYR), and failure rectification group (FRG). The construction of predictive models involved nineteen categories of 13,350 units of medical equipment. We proposed thirteen novel features in assessing medical equipment failures. The failure analysis predictive models were categorised into several classes for training and testing the developed models. There was seven supervised machine learning classifiers and performance metrics applied in the experiment. The experiment demonstrates that Support Vector Machine is the best classifier for the FFE predictive model, which achieves an accuracy of 96.9% after hyperparameter optimisation. Furthermore, Decision Tree is the best classifier for FYR, with an accuracy of 83.9%. Meanwhile, the comparative analysis for FRG discovered that Artificial Neural Network achieved the highest accuracy among others with 76.7% accuracy after the hyperparameter optimisation process. Findings from this study indicate that this failure analysis predictive model functions as a main instrument for conducting predictive maintenance in the direction of smart maintenance practices. Through the developed predictive systems, timely maintenance of medical equipment can be performed. This will also assist healthcare service providers in initiating the remanufacturing and refurbishment programme, ensuring efficient medical care delivery. The suggested framework of machine learning-assisted failure analysis for medical equipment maintenance management may provide clinical engineers with guidance for managing the strategic maintenance management for medical equipment.},
  archive      = {J_EAAI},
  author       = {Aizat Hilmi Zamzam and Khairunnisa Hasikin and Ahmad Khairi Abdul Wahab},
  doi          = {10.1016/j.engappai.2023.106715},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106715},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrated failure analysis using machine learning predictive system for smart management of medical equipment maintenance},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-driven multi-objective dynamic switch
migration in software defined networking (SDN)/network function
virtualization (NFV)-based 5G networks. <em>EAAI</em>, <em>125</em>,
106714. (<a
href="https://doi.org/10.1016/j.engappai.2023.106714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of switch migration in software defined networking (SDN)/network function virtualization (NFV)-based fifth generation (5G) networks in which SDN controllers are deployed as virtualized network functions (VNFs). The problem of switch migration is how to properly transfer the traffic of some SDN switches to one or multiple other virtualized SDN controllers in order to cope with the traffic fluctuations and the changing network topology. The highly dynamic environment of 5G networks requires the simultaneous consideration of multiple conflicting objectives in this problem including controllers load-balancing and network stability. In this paper, this multi-objective problem is formulated as a mixed integer non-linear program (MINLP) which is computationally expensive to solve. Therefore, a mathematical-based solution method is first provided based on the successive convex approximation (SCA) technique for the single-objective problem in which preference parameters are given to describe associated importance of the objectives. Taking into account the time restrictions for practical developments, an extended deep learning (DL) approach is then proposed to produce multiple mappings over multiple objectives. The verification results show that the proposed multi-objective DL algorithm can generate high quality Pareto Fronts close to those of the state-of-the-art algorithms based on optimization with orders of magnitude speedup in the computational time.},
  archive      = {J_EAAI},
  author       = {Elaheh Vaezpour},
  doi          = {10.1016/j.engappai.2023.106714},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106714},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-driven multi-objective dynamic switch migration in software defined networking (SDN)/network function virtualization (NFV)-based 5G networks},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Magnetic signal denoising based on auxiliary sensor array
and deep noise reconstruction. <em>EAAI</em>, <em>125</em>, 106713. (<a
href="https://doi.org/10.1016/j.engappai.2023.106713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic field measurement technologies are extensively applied in nondestructive testing, quality inspection, and fault diagnosis of machines and equipment. Magnetic signals are highly susceptible to noise interference, and how to effectively conduct signal denoising under strong noise disturbance remains a challenge. This study designs a novel auxiliary sensor array comprising center and distributed satellite sensors for magnetic noise reconstruction and signal denoising. The signals of the center and satellite sensors are highly correlative owing to the propagation of the magnetic noise through space. An attention-based long short term memory model is designed and trained to establish the mapping relationship among the center and satellite signals. The noise of the center sensor can then be reconstructed from those of the satellite sensors in the procedure of magnetic field measurement. Finally, the denoised signal of the center sensor is obtained by subtracting the noisy signal with the reconstructed noise. The effectiveness and superiority of the proposed method are validated by experiments and compared with the conventional methods. The designed auxiliary sensor array and algorithm are easily implemented with remarkable robustness, flexibility, and scalability, thereby showing greatly potential use for magnetic signal denoising in a variety of mechatronic systems.},
  archive      = {J_EAAI},
  author       = {Xiaoxian Wang and Shiwu Zhang and Juncai Song and Yongbin Liu and Siliang Lu},
  doi          = {10.1016/j.engappai.2023.106713},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106713},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Magnetic signal denoising based on auxiliary sensor array and deep noise reconstruction},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CVT on-line error measurement hybrid-driven by domain
knowledge and stacking model. <em>EAAI</em>, <em>125</em>, 106710. (<a
href="https://doi.org/10.1016/j.engappai.2023.106710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of Capacitive Voltage Transformer (CVT) degrades over time, making measurement error monitoring a research hotspot in the field of smart grid. At present, these are several challenges such as complex data features, a lack of criteria for selecting optimal measurement models, and low precision. CVT measurement errors can be classified into ideal error and additional one. The former is typically evaluated via mutual information and redundancy within the topology-level transformer group. Considering that a single model cannot process the time series, strong randomness and nonlinearity of the additional error, the Stacking model is selected. Based on the principle of heterogeneity and high-quality, correlation coefficient and feature contribution degree, Random Forest, eXtreme Gradient Boosting, Ridge Regression, K Nearest Neighbors, Support Vector Regression, and Long Short-Term Memory are chosen as base learners through correlation and feature contribution analysis; while extra-trees with strong generalization and robustness is chosen as the meta learner. To improve the measurement precision, the attention-like mechanism is used to scale time and accuracy weights. Finally, according to the power domain knowledge, a linear superposition model is developed to fuse the ideal and additional errors, and thus realize online error measurement for CVTs. The experimental results indicate that the improved Stacking model outperforms mainstream measurement models by an average reduction of 59.47%, and 52.58% in the root mean squared error and the mean absolute error with the best R 2 closest to 1. It not only effectively improves the accuracy but also meets speed requirement for online error measurement.},
  archive      = {J_EAAI},
  author       = {Jingping Wang and Ying Shi and Rui Zhang and Zhonghua Wu and Hao Ye and Shenwei Li},
  doi          = {10.1016/j.engappai.2023.106710},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106710},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CVT on-line error measurement hybrid-driven by domain knowledge and stacking model},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COVID-19 symptom identification using deep learning and
hardware emulated systems. <em>EAAI</em>, <em>125</em>, 106709. (<a
href="https://doi.org/10.1016/j.engappai.2023.106709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic disrupted regular global activities in every possible way. This pandemic, caused by the transmission of the infectious Coronavirus, is characterized by main symptoms such as fever, fatigue, cough, and loss of smell. A current key focus of the scientific community is to develop automated methods that can effectively identify COVID-19 patients and are also adaptable for foreseen future virus outbreaks. To classify COVID-19 suspects, it is required to use contactless automatic measurements of more than one symptom. This study explores the effectiveness of using Deep Learning combined with a hardware-emulated system to identify COVID-19 patients in Sri Lanka based on two main symptoms: cough and shortness of breath. To achieve this, a Convolutional Neural Network (CNN) based on Transfer Learning was employed to analyze and compare the features of a COVID-19 cough with other types of coughs. Real-time video footage was captured using a FLIR C2 thermal camera and a web camera and subsequently processed using OpenCV image processing algorithms. The objective was to detect the nasal cavities in the video frames and measure the breath cycles per minute, thereby identifying instances of shortness of breath. The proposed method was first tested on crowd-sourced datasets (Coswara, Coughvid, ESC-50, and a dataset from Kaggle) obtained online. It was then applied and verified using a dataset obtained from local hospitals in Sri Lanka. The accuracy of the developed methodologies in diagnosing cough resemblance and recognizing shortness of breath was found to be 94% and 95%, respectively.},
  archive      = {J_EAAI},
  author       = {Rashini Liyanarachchi and Janaka Wijekoon and Manujaya Premathilaka and Samitha Vidhanaarachchi},
  doi          = {10.1016/j.engappai.2023.106709},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106709},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {COVID-19 symptom identification using deep learning and hardware emulated systems},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PPLC: Data-driven offline learning approach for excavating
control of cutter suction dredgers. <em>EAAI</em>, <em>125</em>, 106708.
(<a href="https://doi.org/10.1016/j.engappai.2023.106708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutter suction dredgers (CSDs) play a very important role in the construction of ports, waterways and navigational channels. Currently, most of CSDs are mainly manipulated by human operators, and a large amount of instrument data needs to be monitored in real time in case of unforeseen accidents. In order to reduce the heavy workload of the operators, we propose a data-driven offline learning approach, named Preprocessing-Prediction-Learning Control (PPLC), for obtaining the optimal control policy of the excavating operation of CSDs. The proposed framework consists of three modules, i.e., a data preprocessing module, a dynamics prediction module realized by a Convolutional Neural Network (CNN), and a deep reinforcement learning based control module. The first module is responsible for filtering out irrelevant variables through correlation analysis and dimensionality reduction of raw data. The second module works as a state transition function that provides the dynamics prediction of the excavating operation of a CSD. To realize the learning control, the third module employs the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm to control the swing speed during the excavating operation. The simulation results show that the proposed framework can provide an effective and reliable solution to the automated excavating control of a CSD.},
  archive      = {J_EAAI},
  author       = {Changyun Wei and Hao Wang and Haonan Bai and Ze Ji and Zenghui Liu},
  doi          = {10.1016/j.engappai.2023.106708},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106708},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PPLC: Data-driven offline learning approach for excavating control of cutter suction dredgers},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A unified out-of-distribution detection framework for
trustworthy prognostics and health management in renewable energy
systems. <em>EAAI</em>, <em>125</em>, 106707. (<a
href="https://doi.org/10.1016/j.engappai.2023.106707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in artificial intelligence, there is a growing expectation of more automatic and intelligent prognostics and health management (PHM) systems for the real-time monitoring of renewable energy systems. Although the deep learning significantly promotes the development of PHM, it generally works in a close-world assumption that the real-time monitoring data are in-distribution (ID). These methods may lack the ability to alert the system when encountering the out-of-distribution (OOD) data that are previously unseen/unknown. In this study, a unified OOD detection framework is proposed for the intelligent PHM, so as to enhance its reliability and trustworthiness. Specifically, two types of OOD data from unseen working conditions and unseen fault types are comprehensively considered in the unified framework. A class-wise outlier detection strategy is presented to detect the OOD inputs during decision-making. To suppress the unexpected distribution shift caused by variable working conditions, a novel generalization representation of learning towards unseen working conditions is developed by using supervised contrastive learning. The proposed OOD detection framework can not only flag the unreliable diagnostic output of deep learning models, but also reduce the interference of variable working conditions, showing its applicability in real application scenarios. Extensive experiments demonstrate the advantages and the significance of the proposed unified OOD detection framework to establish highly reliable and trustworthy PHM models.},
  archive      = {J_EAAI},
  author       = {Wenzhen Xie and Te Han and Zhongyi Pei and Min Xie},
  doi          = {10.1016/j.engappai.2023.106707},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106707},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A unified out-of-distribution detection framework for trustworthy prognostics and health management in renewable energy systems},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel probabilistic linguistic decision-making model based
on discrete evidence fusion and attribute weight optimization.
<em>EAAI</em>, <em>125</em>, 106706. (<a
href="https://doi.org/10.1016/j.engappai.2023.106706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic linguistic term set (PLTS) is an effective tool to describe qualitative evaluation, where decision-makers’ hesitation is expressed by multiple linguistic terms and decision-makers’ preferences for possible linguistic evaluations are obtained through probabilistic information. Recently, many multi-attribute decision models based on PLTSs have been developed greatly. However, the existing models fail to consider the interactions among multiple attributes under the framework of intuitionistic fuzzy sets for a decision-making problem given in the form of PLTSs. To solve this problem, a novel probabilistic linguistic decision-making model of discrete evidence is proposed in this paper. Specifically, an optimization model of evidence entropy is established to obtain non-additive attribute weights. Then by using these weights as fuzzy measures, a Choquet intuitionistic fuzzy logit (CIFL) model is defined to acquire decision results. The proposed CIFL model fully takes interactive attributes into account and extends the intuitionistic fuzzy logit (IFL) model. Finally, in a case study of an emergency plan selection, the optimal alternative is chosen correctly with the highest probability by the proposed model. A sensitivity analysis under two entropy functions and four scores, a comparative analysis with seven existing methods and a theoretical analysis are utilized to prove the rationality and validity of the developed model.},
  archive      = {J_EAAI},
  author       = {Siyu Xue and Yang Yang and Xinyang Deng},
  doi          = {10.1016/j.engappai.2023.106706},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106706},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel probabilistic linguistic decision-making model based on discrete evidence fusion and attribute weight optimization},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel feature engineering approach for high-frequency
financial data. <em>EAAI</em>, <em>125</em>, 106705. (<a
href="https://doi.org/10.1016/j.engappai.2023.106705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature engineering for high-frequency financial data based on constructing dynamic data subsets, defined by time intervals in which high-frequency trends occur, is proposed. These intervals are obtained through time series segmentation. This methodology allows us to extract and analyze variables by intraday trends as well as to feed artificial intelligence models to forecast response variables in future trends. Furthermore, to show how to use this feature engineering, this methodology is applied to estimate high-frequency volatility, duration and direction linked to future intraday trends, developing multiclass classification models based on the machine learning method extreme gradient boosting . Experimentation was conducted using high-frequency financial data from the Brazil Stock Exchange, corresponding to 206 trading days related to 20 listed assets from this financial market.},
  archive      = {J_EAAI},
  author       = {Pablo Mantilla and Sebastián Dormido-Canto},
  doi          = {10.1016/j.engappai.2023.106705},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106705},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel feature engineering approach for high-frequency financial data},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Subtask-masked curriculum learning for reinforcement
learning with application to UAV maneuver decision-making.
<em>EAAI</em>, <em>125</em>, 106703. (<a
href="https://doi.org/10.1016/j.engappai.2023.106703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) maneuver strategy learning remains a challenge when using Reinforcement Learning (RL) in this sparse reward task. In this paper, we propose Subtask-Masked curriculum learning for RL ( Sub Mas -RL), an efficient RL paradigm that implements curriculum learning and knowledge transfer for UAV maneuver scenarios involving multiple missiles. First, this study introduces a novel concept known as subtask mask to create source tasks from a target task by masking partial subtasks. Then, a subtask-masked curriculum generation method is proposed to generate a sequenced curriculum by alternately conducting task generation and task sequencing. To establish efficient knowledge transfer and avoid negative transfer, this paper employs two transfer techniques, policy distillation and policy reuse, along with an explicit transfer condition that masks irrelevant knowledge. Experimental results demonstrate that our method achieves a 94.8% success rate in the UAV maneuver scenario, where the direct use of reinforcement learning always fails. The proposed RL framework Sub Mas -RL is expected to learn an effective policy in complex tasks with sparse rewards.},
  archive      = {J_EAAI},
  author       = {Yueqi Hou and Xiaolong Liang and Maolong Lv and Qisong Yang and Yang Li},
  doi          = {10.1016/j.engappai.2023.106703},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106703},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Subtask-masked curriculum learning for reinforcement learning with application to UAV maneuver decision-making},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous intelligent control of earth pressure balance
shield machine based on deep reinforcement learning. <em>EAAI</em>,
<em>125</em>, 106702. (<a
href="https://doi.org/10.1016/j.engappai.2023.106702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to reduce the construction risk caused by human operation error and improve the geological adaptive ability of the shield machine, an autonomous intelligent control method is proposed for shield machine within the framework of interaction–judgment–decision based on Deep Deterministic Policy Gradient (DDPG) deep reinforcement learning in this study. Due to the strong nonlinear relationship between the shield machine&#39;s tunneling parameters, this research builds a deep reinforcement learning environment using mechanism model of sealed cabin pressure. DDPG agent model of the shield machine is established to replace the shield machine to interact and train with the geological environment. By minimizing the difference between the target pressure setting value and the sealed cabin pressure value, the dynamic balance between the sealed cabin pressure and the pressure on the excavation surface is realized, and the best strategy is obtained. Through real-time interaction with the geological environment, the method in this paper can dynamically adjust the tunneling parameters, accurately control the sealed cabin pressure, and has a strong geological adaptive ability. By realizing the intelligent decision-making of the tunneling parameters, it greatly improves the independent decision-making ability of the shield machine system, reduces the inaccuracy of human operation, and provides an effective guarantee for the efficient and safe operation of the shield machine. This study applies deep reinforcement learning technology to the control field of earth pressure balance shield machine, promotes AI technology, and provides a new idea for the development of AI construction technology in engineering field.},
  archive      = {J_EAAI},
  author       = {Xuanyu Liu and Wenshuai Zhang and Cheng Shao and Yudong Wang and Qiumei Cong},
  doi          = {10.1016/j.engappai.2023.106702},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106702},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Autonomous intelligent control of earth pressure balance shield machine based on deep reinforcement learning},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent model based proactive risk management for equity
investment. <em>EAAI</em>, <em>125</em>, 106701. (<a
href="https://doi.org/10.1016/j.engappai.2023.106701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing and applying new artificial intelligence (AI) techniques in finance has become popular and one of the growing areas. Although many studies focus on return prediction and do not pay much attention to price formation, revealing its mechanism is essential in risk management, particularly in proactive risk management for investment to improve the performance. Thus, this paper introduces a novel multi-agent model, which is able to explain how agents’ portfolio rebalances determine the market price dynamics to clarify the price formation by applying a state space model. The technical novelty is the effective integration of state space modeling and fuzzy logic into a multi-agent model with four types of typical investors and their fuzzy trading strategies. By using the estimated unobservable fund flows of each trader in the model, this work proposes a new proactive warning signal. As a result, the signal improves both the risk and return of the investment in the Japanese and United States equity markets. Our findings indicate that the agents’ estimated fund flows driving asset prices help us to avoid a market crash, reduce the risk and improve the return in investment practice.},
  archive      = {J_EAAI},
  author       = {Daiya Mita and Akihiko Takahashi},
  doi          = {10.1016/j.engappai.2023.106701},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106701},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-agent model based proactive risk management for equity investment},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of parkinson’s disease based on spectrograms of
voice recordings and extreme learning machine random weight neural
networks. <em>EAAI</em>, <em>125</em>, 106700. (<a
href="https://doi.org/10.1016/j.engappai.2023.106700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease consists in the degeneration of the mesencephalic black substance, affecting the dopaminergic vias. Its causes are varied, including exposure to pesticides, genetic factors and, one of the most influential ones, age. Given the decrease in dopamine levels, the most common symptoms are the appearance of tremors and muscle rigidity. Due to the rigidity of the muscles, the patient has voice alterations which have great potential for non-invasive and early diagnosis of the disease. In addition, considering the low cost of the sound recorder respect to the clinical studies, this approach allows the diagnosis of Parkinson’s disease in a large number of people. Recent works, which present the analysis of voice recordings through Convolutional Neural Networks, show high level of accuracy in the diagnosis of Parkinson’s disease. Convolutional Neural Networks use a Multilayer Neural Network to classify convolutional feature vectors. In order to improve the training time of the classifier, in this paper the use Extreme Learning Machines are proposed. Experiments considering 4 types of spectrograms with AlexNet, VGG-16, SqueezeNet, Inception V3 and ResNet-50 Convolutional Neural Networks models. In the experiments, hit rate, training and testing time, sensitivity and the specificity indicators of all the neural architectures involved in the work are objectively compared. It is shown that the Extreme Learning Machine have a high level of accuracy in the diagnosis of Parkinson’s disease but with reduced training time.},
  archive      = {J_EAAI},
  author       = {Renata Guatelli and Verónica Aubin and Marco Mora and Jose Naranjo-Torres and Antonia Mora-Olivari},
  doi          = {10.1016/j.engappai.2023.106700},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106700},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection of parkinson’s disease based on spectrograms of voice recordings and extreme learning machine random weight neural networks},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of novel optimized deep learning algorithms for
wildfire modeling: A case study of maui, hawai‘i. <em>EAAI</em>,
<em>125</em>, 106699. (<a
href="https://doi.org/10.1016/j.engappai.2023.106699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the growing global concern regarding increased wildfire occurrences and their widespread socio-ecological impacts, cost-effective and practical approaches must be urgently identified to accurately predict the probability of wildfire incidents. The objective of this study was to develop deep learning models to estimate the likelihood of wildfire incidents and compare the predictive capability of the methods. To this end, the group method of data handling (GMDH) and convolutional neural network (CNN) algorithms were coupled with the biogeography-based optimization (BBO) and ant colony optimization (ACO) algorithms to enhance the predictive performance of the models. Overall, 1745 historical wildfires were identified in the island of Maui, Hawai‘i. Among them, 1221 events (70%) were randomly selected to generate the models, and the remaining 524 (30%) were used for validation. The frequency ratio, information gain ratio (IGR), and variance inflation factor methods were used to select the optimal number of predictor variables for model development. 13 influencing factors: elevation, aspect, slope, plan curvature, slope length, valley depth, topographic wetness index, mean annual wind speed, mean annual air temperature, mean monthly rainfall, distance to the road, distance to the river, and normalized difference vegetation index were selected to generate the proposed models and detect fire-prone areas. The IGR values indicated that the key parameters for predicting wildfire susceptibility were the distance to the road, mean annual air temperature, elevation, and slope. Finally, the area under the receiver operating characteristic curve (AUROC) was computed to verify the reliability and accuracy of the wildfire susceptibility maps. Both the optimization algorithms enhanced the performances of the GMDH and CNN models. The ACO most notably enhanced the CNN performance compared with the models (AUROC Training = 0 . 889 and AUROC Testing = 0 . 885 ). The findings demonstrated the potential of coupled models in overcoming the limitations of individual models for mapping fire-susceptible areas and analyzing the multifactorial aspects that lead to wildfire occurrence. Overall, the proposed frameworks can be used to predict the spatio-temporal patterns of wildfire occurrence, which are of significance for land management, wildfire prevention, and mitigation of wildfire consequences.},
  archive      = {J_EAAI},
  author       = {Fatemeh Rezaie and Mahdi Panahi and Sayed M. Bateni and Saro Lee and Changhyun Jun and Clay Trauernicht and Christopher M.U. Neale},
  doi          = {10.1016/j.engappai.2023.106699},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106699},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of novel optimized deep learning algorithms for wildfire modeling: A case study of maui, hawai‘i},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Monthly ship price forecasting based on multivariate
variational mode decomposition. <em>EAAI</em>, <em>125</em>, 106698. (<a
href="https://doi.org/10.1016/j.engappai.2023.106698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable ship price forecasts can assist shipping firms, investors, and other participants to withstand risks and make profits in a highly volatile shipping market. Considering the nonlinear behavior and sophisticated interrelationship of the shipping market, in this paper, a novel multiscale and multivariable methodology based on multivariate variational mode decomposition (MVMD) and machine learning (ML) algorithms is proposed for forecasting monthly newbuilding ship price ( NSP ), secondhand ship price ( SSP ), and ship scrap value ( SSV ). The proposed methodology involves three main modules: (1) data decomposition by MVMD; (2) mode forecasting using ML algorithms, including multi-layer perceptron, support vector regression, long short-term memory, and gated recurrent unit; and (3) ensemble forecasts via simple addition. The novelty of this paper lies in the employment of MVMD, which is capable of capturing complicated multiscale relationships among the NSP , SSP , and SSV data by extracting multiple frequency-aligned oscillatory modes. This will largely help in the multivariable forecasting of ship prices at each timescale. With Capesize bulker and VLCC tanker as study samples, the empirical results show that the novel methodology outperforms other considered benchmark models in terms of both level and directional forecasting accuracy. This suggests that the developed multiscale and multivariable methodology is a promising alternative for shipping market analysis and forecasting.},
  archive      = {J_EAAI},
  author       = {Zicheng Wang and Liren Chen and Huayou Chen and Naveed ur Rehman},
  doi          = {10.1016/j.engappai.2023.106698},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106698},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Monthly ship price forecasting based on multivariate variational mode decomposition},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transfer learning-based approach to maritime warships
re-identification. <em>EAAI</em>, <em>125</em>, 106696. (<a
href="https://doi.org/10.1016/j.engappai.2023.106696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine vessel re-identification technology is an important component of intelligent shipping systems and an important part of the visual perception tasks required for marine surveillance. However, unlike the situation on land, the maritime environment is complex and volatile, and ships are prone to different degrees of swaying. Warships, as a class of ships, are characterized by fewer image samples and high similarity, and it is more difficult to re-identify warships at sea. Therefore, this paper proposes a dynamic alignment re-identification network model incorporating transfer learning methods. Various types of ships are used as source domain data to assist the network in learning the target domain warships so as to improve the recognition accuracy of warships. At the same time, the swaying situation of warships at sea is simulated and tested to improve the recognition difficulty so as to cope with the impact caused by complex sea conditions. The effect of different types of ships as transfer objects is also discussed. The experimental results show that the improved algorithm improves the mean average accuracy (mAP) by 10.2% and the first hit rate (Rank1) by 4.9% on average.},
  archive      = {J_EAAI},
  author       = {Guangmiao Zeng and Rongjie Wang and Wanneng Yu and Anhui Lin and Huihui Li and Yifan Shang},
  doi          = {10.1016/j.engappai.2023.106696},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106696},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transfer learning-based approach to maritime warships re-identification},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot structural repair decision of civil aircraft based
on deep meta-learning. <em>EAAI</em>, <em>125</em>, 106695. (<a
href="https://doi.org/10.1016/j.engappai.2023.106695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the difficulties in extracting general features of few-shot high-dimensional structural health monitoring data and making accurate repair decision, a civil aircraft structural repair decision method based on deep meta-learning (DML) is proposed in this paper. Firstly, multi-source structural health monitoring data such as component name, cumulative flight hours, inspection level and state parameters are collected as model input. In addition, the damage condition, repair level and repair definition are used as data labels. Secondly, DML model is used for few-shot learning of repair cases. Monitoring data and corresponding labels make up different target datasets, which can be used for training of base-learner and meta-learner. Thirdly, the historical cases in manual are used for in-sample prediction by meta-learning model, while the new cases are utilized for out-of-sample prediction by fine-tuning the initialized deep meta-learning model. Finally, the aircraft aluminum lap joint damage dataset is used for case study. The results show that the proposed deep meta-learning model can achieve higher accuracy when dealing with few-shot high-dimensional input. Compared with other models, the task oriented DML model has more strong generalization ability and higher classification accuracy in analyzing multi-task cases.},
  archive      = {J_EAAI},
  author       = {Changchang Che and Huawei Wang and Xiaomei Ni and Minglan Xiong},
  doi          = {10.1016/j.engappai.2023.106695},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106695},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Few-shot structural repair decision of civil aircraft based on deep meta-learning},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-stage fuzzy object grasping controller for a humanoid
robot with proximal policy optimization. <em>EAAI</em>, <em>125</em>,
106694. (<a
href="https://doi.org/10.1016/j.engappai.2023.106694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As science and technology have developed, an increasing amount of research on humanoid robots has been conducted. In this paper, a method based on deep reinforcement learning, optimization algorithms, and fuzzy logic for self-guided learning in humanoid robots is proposed. The method primarily relies on proximal policy optimization. The proposed model enables the humanoid robot to determine the optimal action on the basis of environmental feedback. A task was divided into two steps to train the optimal model for each step of the task; these models were then integrated. This division of the task was completed to prevent bias towards a single step. The performance of numerous optimization algorithms was evaluated, and the artificial bee colony algorithm was found to be the most successful algorithm for determining the optimal combination of parameters for the task. Deep reinforcement learning was demonstrated to be an effective method for enabling the humanoid robot to learn how to grasp objects and place them in target areas. The proposed learning method also combines optimization algorithms with fuzzy logic theory to further improve performance. The feasibility of the proposed method was validated through experiments.},
  archive      = {J_EAAI},
  author       = {Ping-Huan Kuo and Kuan-Lin Chen},
  doi          = {10.1016/j.engappai.2023.106694},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106694},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-stage fuzzy object grasping controller for a humanoid robot with proximal policy optimization},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Twin-delayed deep deterministic policy gradient algorithm
for the energy management of microgrids. <em>EAAI</em>, <em>125</em>,
106693. (<a
href="https://doi.org/10.1016/j.engappai.2023.106693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The microgrid market is growing significantly due to several drivers, such as the need to lower greenhouse gas emissions by integrating higher shares of distributed renewable energy sources, falling costs of microgrid components, the need for more reliable power supply infrastructures, and new off-grid solutions to foster electricity access in developing economies. Coordinated management of the microgrid components is crucial for their effectiveness, and this can be very challenging when hosting solar or wind generation. This paper studies the energy management problem of a microgrid based on reinforcement learning algorithms. The advantage of using these algorithms against other optimization and machine learning techniques is that they do not need past experiences to learn a strategy. The learning is based on trial and error experiences, which facilitates its easy implementation to other microgrids while demonstrating their facility to be applied in real cases. In particular, this paper proposes an implementation for an Energy Management System (EMS) in microgrids using the Twin-Delayed Deep Deterministic Policy Gradient (TD3) algorithm. Moreover, it compares the proposed algorithm with the Deep Q-Network (DQN). This comparison evaluates the improvement over exploiting the continuous nature of the decision variables against a discretization of the same since the DQN cannot make actions over a continuous space.},
  archive      = {J_EAAI},
  author       = {David Domínguez-Barbero and Javier García-González and Miguel Á. Sanz-Bobi},
  doi          = {10.1016/j.engappai.2023.106693},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106693},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Twin-delayed deep deterministic policy gradient algorithm for the energy management of microgrids},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A new hybrid prediction model of COVID-19 daily new case
data. <em>EAAI</em>, <em>125</em>, 106692. (<a
href="https://doi.org/10.1016/j.engappai.2023.106692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of new mutant corona virus disease 2019 (COVID-19) strains such as Delta and Omicron, the number of infected people in various countries has reached a new high. Accurate prediction of the number of infected people is of far-reaching sig Nificance to epidemiological prevention in all countries of the world. In order to improve the prediction accuracy of COVID-19 daily new case data, a new hybrid prediction model of COVID-19 is proposed, which consists of four modules: decomposition, complexity judgment, prediction and error correction. Firstly, singular spectrum decomposition is used to decompose the COVID-19 data into singular spectrum components (SSC). Secondly, the complexity judgment is innovatively divided into high-complexity SSC and low-complexity SSC by neural network estimation time entropy. Thirdly, an improved LSSVM by GODLIKE optimization algorithm, named GLSSVM, is proposed to improve its prediction accuracy. Then, each low-complexity SSC is predicted by ARIMA, and each high-complexity SSC is predicted by GLSSVM, and the prediction error of each high-complexity SSC is predicted by GLSSVM. Finally, the predicted results are combined and reconstructed. Simulation experiments in Japan, Germany and Russia show that the proposed model has the highest prediction accuracy and the lowest prediction error. Diebold Mariano (DM) test is introduced to evaluate the model comprehensively. Taking Japan as an example, compared with ARIMA prediction model, the RMSE, average error and MAPE of the proposed model are reduced by 93.17%, 91.42% and 81.20% respectively.},
  archive      = {J_EAAI},
  author       = {Guohui Li and Jin Lu and Kang Chen and Hong Yang},
  doi          = {10.1016/j.engappai.2023.106692},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106692},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new hybrid prediction model of COVID-19 daily new case data},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed deep neural network for modeling the
chloride diffusion in concrete. <em>EAAI</em>, <em>125</em>, 106691. (<a
href="https://doi.org/10.1016/j.engappai.2023.106691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chloride diffusion in concrete is a complex chemo-physical process and it is of pivotal importance to forecast the initiation time of corrosion. But limited equations are accessible to simulate the chloride diffusion considering the nonlinear chloride binding capacity of concrete. This study proposes a physics-informed deep neural network to simulate the chloride diffusion mechanism and forecast the distribution of chloride concentrations in concrete. Physical laws are formulated as a loss term to guide the training process and to mitigate the data required for model training. The physical constraint loss (based on the governing equation and boundary conditions) and the training loss (based on the neural network) are then fused to produce the loss function. Different experimental cases are first employed to validate the proposed model and then the model is compared to numerical applications and purely data-driven approaches. Results revealed that the proposed model could effectively simulate the chloride transport behavior and forecast the diffusion coefficient of concrete with high precision over other states of art methods. The application of this method to the temporal and spatial domains of the chloride concentration within the concrete samples showed its potential as a powerful tool for investigating concrete properties.},
  archive      = {J_EAAI},
  author       = {Wafaa Mohamed Shaban and Khalid Elbaz and Annan Zhou and Shui-Long Shen},
  doi          = {10.1016/j.engappai.2023.106691},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106691},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed deep neural network for modeling the chloride diffusion in concrete},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarking chemical neural ordinary differential equations
to obtain reaction network-constrained kinetic models from spectroscopic
data. <em>EAAI</em>, <em>125</em>, 106690. (<a
href="https://doi.org/10.1016/j.engappai.2023.106690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinetic model identification relies on accurate concentration measurements and physical constraints to limit solution multiplicity. Not having these measurements and prior knowledge of species and reactions creates considerable challenges that are currently unresolved. We address these by developing a data-driven framework using realtime spectroscopic data, comprising: (i) multivariate curve resolution to deconvolve the spectra of the reacting mixture into those of its pseudocomponents and their corresponding concentrations, which enables species identification without prior information, (ii) Bayesian structure learning among the pseudocomponent spectra to enable hypothesizing reaction pathways, and (iii) neural ordinary differential equations (ODE) that are physically constrained by the hypothesized reaction network and the laws of mass action and temperature dependence to learn kinetic models from the temporal concentration projections of the realtime spectra. The predictive performance of the constrained neural ODEs is limited by the accuracy of spectral deconvolution in the presence of noise, and has been benchmarked against a constrained regression approach by varying signal:noise ratios in the synthetic spectroscopic data of reacting mixtures. Although the hypothesized reaction network differs from the actual reaction template, owing to noise, the network-constrained neural ODEs are seen to result in a 75.2% and 68.15% decrease in the root mean squared error (RMSE) of the concentration profile predictions as compared to the constrained regression method, when trained on time projected concentration data of the synthetic spectra generated at a signal to noise ratio of 35 and 100, respectively.},
  archive      = {J_EAAI},
  author       = {Anjana Puliyanda and Karthik Srinivasan and Zukui Li and Vinay Prasad},
  doi          = {10.1016/j.engappai.2023.106690},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106690},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Benchmarking chemical neural ordinary differential equations to obtain reaction network-constrained kinetic models from spectroscopic data},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning the dynamical response of nonlinear non-autonomous
dynamical systems with deep operator neural networks. <em>EAAI</em>,
<em>125</em>, 106689. (<a
href="https://doi.org/10.1016/j.engappai.2023.106689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose using operator learning to approximate the dynamical response of non-autonomous systems, such as nonlinear control systems. Unlike classical function learning, operator learning maps between two function spaces, does not require discretization of the output function, and provides flexibility in data preparation and solution prediction. Particularly, we apply and redesign the Deep Operator Neural Network (DeepONet) to recursively learn the solution trajectories of the dynamical systems. Our approach involves constructing and training a DeepONet that approximates the system’s local solution operator. We then develop a numerical scheme that recursively simulates the system’s long/medium-term dynamic response for given inputs and initial conditions, using the trained DeepONet. We accompany the proposed scheme with an estimate for the error bound of the associated cumulative error. Moreover, we propose a data-driven Runge–Kutta (RK) explicit scheme that leverages the DeepONet’s forward pass and automatic differentiation to better approximate the system’s response when the numerical scheme’s step size is small. Numerical experiments on the predator–prey, pendulum, and cart pole systems demonstrate that our proposed DeepONet framework effectively learns to approximate the dynamical response of non-autonomous systems with time-dependent inputs.},
  archive      = {J_EAAI},
  author       = {Guang Lin and Christian Moya and Zecheng Zhang},
  doi          = {10.1016/j.engappai.2023.106689},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106689},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning the dynamical response of nonlinear non-autonomous dynamical systems with deep operator neural networks},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strategies for enhancing the performance of news article
classification in bangla: Handling imbalance and interpretation.
<em>EAAI</em>, <em>125</em>, 106688. (<a
href="https://doi.org/10.1016/j.engappai.2023.106688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in obtainable online text data has made text categorization an important tool for data analysts to extract relevant information on the web. However, incorrect or incomplete classification of marginalized groups may result from using biased text data. In order to remedy the disparity in available data, this research suggests a system for classifying and analyzing Bangla news articles. The suggested approach first uses both Random Under-Sampling (RUS) and Synthetic Minority Oversampling Techniques to balance the massive unbalanced Bangla News dataset consisting of 4,37,948 instances (SMOTE). Secondly, the proposed system employs three machine learning models: Logistic Regression, Decision Tree, and Stochastic Gradient Descent along with three deep learning models: Artificial Neural Network (ANN), Convolutional Neural Network (CNN), and Bidirectional Encoder Representations from Transformers (BERT) for Bangla text categorization. The experimental results signify the superior performance of BERT to other classification models of the system as well as other existing methods in this domain. The proposed system achieves the maximum accuracy of 99.04% in balanced dataset and 72.23% in imbalanced dataset using BERT. K-fold cross validation with varied K values is used to determine the performance consistency of BERT. Finally, both LIME (Local Interpretable Model agnostic Explanations and SHAP (SHapley Additive exPlanations) techniques are applied for interpreting each prediction made by BERT.},
  archive      = {J_EAAI},
  author       = {Khan Md Hasib and Nurul Akter Towhid and Kazi Omar Faruk and Jubayer Al Mahmud and M.F. Mridha},
  doi          = {10.1016/j.engappai.2023.106688},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106688},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Strategies for enhancing the performance of news article classification in bangla: Handling imbalance and interpretation},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An unsupervised neural network for graphical health index
construction and residual life prediction. <em>EAAI</em>, <em>125</em>,
106687. (<a
href="https://doi.org/10.1016/j.engappai.2023.106687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To better characterize the health status and performing remaining useful life prediction, a composite health index is developed through the fusion of multi-channel signals. However, most of the existing literature limits the data fusion to be linear, which implies that the underlying degradation pattern must follow a linear form. This strong prerequisite of these approaches undermines the effectiveness of existing techniques for capturing the potential nonlinear nature of degradation process. In order to overcome this limitation as well as to improve the predictability, this paper proposes a nonlinear health index construction method achieving by an unsupervised neural network. Specifically, a neural network structure is introduced to approximate the highly nonlinear relationship between signals and health status. Furthermore, we consider the remaining useful life prediction as a binary classification problem, and then propose a maximal classification margin constraint, which is integrated with the monotonicity and minimal variability at the failure time to formulate the novel loss function. To estimate the model parameter, we developed a customized adaptive moment estimation algorithm (Adam). The comprehensive case study is performed based on the benchmark C-MAPSS dataset. As reported in the experiment, the constructed health index can better characterize the underlying degradation process.},
  archive      = {J_EAAI},
  author       = {Zhen Li and Tao Tao and Meng Yang and Jibin Wang and Zhuo Chen and Jianguo Wu},
  doi          = {10.1016/j.engappai.2023.106687},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106687},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An unsupervised neural network for graphical health index construction and residual life prediction},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Orientation-aware ship detection via a rotation feature
decoupling supported deep learning approach. <em>EAAI</em>,
<em>125</em>, 106686. (<a
href="https://doi.org/10.1016/j.engappai.2023.106686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ship imaging position plays an important role in visual navigation, and thus significant focuses have been paid to accurately extract ship imaging positions in maritime videos. Previous studies are mainly conducted in the horizontal ship detection manner from maritime image sequences. This can lead to unsatisfied ship detection performance due to that some background pixels maybe wrongly identified as ship contours. To address the issue, we propose a novel rotational you only look once (YOLO) based model (RYM) to accurately yet fast detect ships from maritime images by considering ship rotation angle. The proposed RYM model are designed to detect tilted ships from images with the help of a rotation decoupled (RD) head, attentional mechanism and bidirectional feature network (BiFPN). The experimental results suggested that RYM can obtain satisfied ship detection performance considering that average accuracy reaches 96.7%. The precision and recall indicators are 93.2% and 94.7%, respectively. The proposed framework can be applied into real-time ship detection task due to that the processing speed is 45.6 frames per second (FPS).},
  archive      = {J_EAAI},
  author       = {Xinqiang Chen and Hao Wu and Bing Han and Wei Liu and Jakub Montewka and Ryan Wen Liu},
  doi          = {10.1016/j.engappai.2023.106686},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106686},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Orientation-aware ship detection via a rotation feature decoupling supported deep learning approach},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Terrain information-involved power allocation optimization
for fuel cell/battery/ultracapacitor hybrid electric vehicles via an
improved deep reinforcement learning. <em>EAAI</em>, <em>125</em>,
106685. (<a
href="https://doi.org/10.1016/j.engappai.2023.106685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As for fuel cell hybrid electric vehicles (FCHEV) powered by fuel cell, battery, and ultracapacitor, its complex topology structure and the variable terrain environment bring challenges to the energy management for power sources lifespan and fuel economy. In this paper, a terrain information-involved energy management strategy (EMS) obtained by an improved deep reinforcement learning (DRL) algorithm is proposed to distribute reasonably the power demand for FCHEV. Specially, an action-value-based adaptive noise and an action-screening-mechanism-based priority experience replay are designed for efficient strategy learning with the adopted algorithm. To protect fuel cell and battery from peak power, a hierarchical energy management framework is established by introducing an adaptive fuzzy filter. Then, an equivalent consumption minimization strategy based on multi-objective optimization is constructed and used as the reward of the improved algorithm to achieve the minimum fuel consumption. Meanwhile, based on historical experimental data, the terrain-information-considered transition probability matrix is obtained and applied to the algorithm to reduce computational load and get the optimal EMS. Finally, the effectiveness of the proposed EMS is verified by a series of comprehensive simulations under different driving cycles. The simulation results show that the hierarchical EMS framework can better protect the service life of fuel cell and battery. In addition, compared with the EMS without considering terrain information, the incorporation of terrain information in EMS can enhance the operational efficiency of fuel cell, improve fuel economy by about 8%, and can reach the dynamic programming benchmark level of 89.5%.},
  archive      = {J_EAAI},
  author       = {Fazhan Tao and Huixian Gong and Zhumu Fu and Zhengyu Guo and Qihong Chen and Shuzhong Song},
  doi          = {10.1016/j.engappai.2023.106685},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106685},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Terrain information-involved power allocation optimization for fuel cell/battery/ultracapacitor hybrid electric vehicles via an improved deep reinforcement learning},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural session key exchange in the industrial internet of
things using hyperchaotic-guided vector-valued artificial neural
synchronization. <em>EAAI</em>, <em>125</em>, 106683. (<a
href="https://doi.org/10.1016/j.engappai.2023.106683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Industrial Internet of Things’ (IIoT) ongoing growth has provided engineers with a wealth of prospects for improving machine throughput. Due to advancement, owing to the unreliable aspect of the communication route, many business managers still hesitate to operate their equipment online. Security is critical in the IIoT, as certain IIoT devices gather sensory data for vital societal production and living. If the entities are authenticated and confidence is established, the use of the Internet to manage industrial activities can become widely embraced. The hyperchaotic neuronal coordinated vector-valued key exchange presented in this study enables safe Wireless Sensor Network (WSN) transmission in the IIoT. Key coordination in IIoT is the main issue. As a part of the security protocols for IIoT, this study presented a vector-valued neuronal coordination-based key synchronization. How well the ANNs on the collaborating edges synchronize instead of each other’s weights is a key factor in neural coordination. Existing techniques take too long to evaluate collaboration, endangering the secrecy of neural synchronization. In addition, minimal studies have been conducted on the reciprocal training of a set of ANNs and the use of a robust PRNG to provide a common input. The suggested approach has a lot of benefits: (1) This research describes the fast evaluation of the coordination of a group of ANNs using a hyperchaotic framework to coordinate ANNs for key agreement. (2) ANNs are coordinated via bidirectional training to spread the neuronal key over a communication link. (3) The measure in which the ANNs have provided similar outputs in previous rounds is used to determine synchronization. (4) The input sequencing for ANN are produced using a collaboratively created 4D, 5D, and 6D hyperchaotic-guided PRNG. (5) The IIoT network’s session key is created via a reciprocating neuronal synchronization of vector-valued ANNs. (6) In compared to earlier methodologies, the proposed technique accelerates the procedure through which participated ANNs achieve perfect synchronization. The suggested approach works better than comparable methods that have been published.},
  archive      = {J_EAAI},
  author       = {Tao Hai and Arindam Sarkar and Rahul Karmakar and Mohammad Zubair Khan and Ayman Noor and Talal H. Noor and Abhinav Kumar and A. Yvaz},
  doi          = {10.1016/j.engappai.2023.106683},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106683},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural session key exchange in the industrial internet of things using hyperchaotic-guided vector-valued artificial neural synchronization},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). M-GaitFormer: Mobile biometric gait verification using
transformers. <em>EAAI</em>, <em>125</em>, 106682. (<a
href="https://doi.org/10.1016/j.engappai.2023.106682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile devices such as smartphones and smartwatches are part of our everyday life, acquiring large amount of personal information that needs to be properly secured. Among the different authentication techniques, behavioural biometrics has become a very popular method as it allows authentication in a non-intrusive and continuous way. This study proposes M-GaitFormer, a novel mobile biometric gait verification system based on Transformer architectures. This biometric system only considers the accelerometer and gyroscope data acquired by the mobile device. A complete analysis of the proposed M-GaitFormer is carried out using the popular available databases whuGAIT and OU-ISIR. M-GaitFormer achieves Equal Error Rate (EER) values of 3.42% and 2.90% on whuGAIT and OU-ISIR, respectively, outperforming other state-of-the-art approaches based on popular Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).},
  archive      = {J_EAAI},
  author       = {Paula Delgado-Santos and Ruben Tolosana and Richard Guest and Ruben Vera-Rodriguez and Julian Fierrez},
  doi          = {10.1016/j.engappai.2023.106682},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106682},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {M-GaitFormer: Mobile biometric gait verification using transformers},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of genetic algorithm and terminal sliding
surface to improve the effectiveness of the proportional–integral
controller for the direct power control of the induction generator power
system. <em>EAAI</em>, <em>125</em>, 106681. (<a
href="https://doi.org/10.1016/j.engappai.2023.106681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proportional–integral regulator is one of the most famous and widely used linear controllers in the industrial field because of its easy adjustment of the results, simplicity, and inexpensive. The negative of this controller is that it is affected by the change of system parameters, which causes several problems, including the high value of ripples and low quality of the power/current. To reduce this defect, a new proportional–integral regulator is suggested based on the use of the terminal sliding surface technique and genetic algorithm. This suggested nonlinear controller is discussed for the first time in this work to use it to ameliorate the quality of energy output from a dual-rotor wind power system using an induction generator. The use of a new controller to regulate the generator energy will inevitably lead to an increase in power errors, power ripples, and harmonic distortion of current especially if the system parameters are changed. Also, the traditional direct power control based on the proposed nonlinear controllers of the induction generator is a robust control, does not need the mathematical form of the generator, is simple, and does not need a specialist. Moreover, the suggested method is applied to the rotor inverter of the 1.5 MW generator using Matlab software. The suggested technique takes full advantage and the power regulation objective of the suggested power system is confirmed by the numerical results compared to the conventional technique and other published controls.},
  archive      = {J_EAAI},
  author       = {Habib Benbouhenni and Ilhami Colak and Nicu Bizon},
  doi          = {10.1016/j.engappai.2023.106681},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106681},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of genetic algorithm and terminal sliding surface to improve the effectiveness of the proportional–integral controller for the direct power control of the induction generator power system},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable and effective artificial intelligence for
multivariate radar environment. <em>EAAI</em>, <em>125</em>, 106680. (<a
href="https://doi.org/10.1016/j.engappai.2023.106680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ground based radar is a key system for aerial defence of any country. Current generations of radar use Moving Target Indicator (MTI) filter, Constant False Alarm Rate (CFAR) and Peak Detection (PD) algorithms for detection of target and rejection of non-target (static clutter, dynamic clutter, interference and noise) objects. These conventional Radar Signal Processing (RSP) techniques find their limitation when either targets are not detected or false alarms are generated due to lack of built-in intelligence. In order to eliminate both the issues, a realistic radar environment has been analyzed using Artificial Intelligence (AI). Special emphasis has been made on invalid detections caused by weather clutter, which was never worked upon previously using AI. A novel deep learning based object detection approach has been devised keeping radar environment, high accuracy requirement and real-time constraint of radar in view. The proposed approach has been validated for its efficacy through standalone testing as well as Poof of Concept (PoC) implementation on a real radar. Integration of AI model in radar platform also involves a novel implementation scheme, whereby results of AI model are augmented by conventional RSP. Inference time of AI models is a bottleneck for their use in radar systems, in this context, new strategies have also been analyzed to achieve a real-time performance for radar application. As the objective of this research is to devise scalable and effective solutions for upcoming generations of radar; therefore, the work is of practical value for realistic deployments.},
  archive      = {J_EAAI},
  author       = {Mahshan Zaheer Awan and Khurram Khan Jadoon and Ammar Masood},
  doi          = {10.1016/j.engappai.2023.106680},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106680},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scalable and effective artificial intelligence for multivariate radar environment},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ResNet and yolov5-enabled non-invasive meat identification
for high-accuracy box label verification. <em>EAAI</em>, <em>125</em>,
106679. (<a
href="https://doi.org/10.1016/j.engappai.2023.106679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compliance issues riddle the agricultural sector despite being an essential industry for the human race. Many factors contribute to compliance issues; however, meat cut label verification is one of the most critical concerns due to its erroneous nature. In addition, meat cut identification is complex for the human eye. Thus, access to a skilled labor force is challenging. Nevertheless, meat compliance is essential since it has export compliance ramifications. These factors, along with others, are pushing for a digital alternative. An alternative that can augment human decision-making in verifying meat cut box labels. Artificial Intelligence (AI) is a digital alternative that can boost quality assurance tasks. One of AI’s potential quality assurance solutions is a Meat Box Labeling Verification (BLV) solution that can verify the boxed meat type against the label to ensure no mismatch. Two major components make up the BLV solution: Meat Identification and Label Analysis. This work aims to solve the former component by exploring different meat-type identification techniques. It explores them by building, evaluating, and testing different computer vision solutions. Hence, the novel contribution of this work is three folds. We first build, test, and design computer vision solutions that detect meat boxes and pieces accurately. These solutions include deep learning methods in classification and object detection techniques. Following that, we evaluate these models and derive key insights. Such insights are valuable for prototyping such solutions in production environments. For example, classification models achieve a 99% testing accuracy in identifying box types. In contrast, object detection achieved 89% mAP@.5:.95 in identified individual meat cuts. Finally, we prototype an object detection model in a natural meat processing environment—the demonstration showed comparable object detection precision at 85% mAP@.5:.95.},
  archive      = {J_EAAI},
  author       = {Omar Jarkas and Josh Hall and Stuart Smith and Redowan Mahmud and Parham Khojasteh and Joshua Scarsbrook and Ryan K.L. Ko},
  doi          = {10.1016/j.engappai.2023.106679},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106679},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ResNet and yolov5-enabled non-invasive meat identification for high-accuracy box label verification},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating multi-level explanations for process outcome
predictions. <em>EAAI</em>, <em>125</em>, 106678. (<a
href="https://doi.org/10.1016/j.engappai.2023.106678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining focuses on the analysis of event log data to build various process analytical capabilities. Predictive process analytics has emerged as one of such key capabilities and it uses machine learning techniques to construct process prediction models. In recent years, deep neural networks have gained increasing interest in process prediction since they can handle multi-dimensional sequential inputs with minimal information loss. However, they are considered black-box models and existing studies in explaining deep neural network-based process predictions rely on only event-level features for explanation. In this paper, we propose a new approach for generating explanations for process outcome predictions at multiple levels. The approach is underpinned by three different prediction models: a transparent model for generating global explanations based on case-level features, an attention-based deep neural network for generating local explanations based on event-level features, and a novel eXplainable Dual-learning Deep network (XD 2 -net) for generating local explanations based on case-level features. Using three publicly available datasets, we have tested the applicability of the approach and further examined the multi-level explanations generated by the approach through an elaborate case study. Unlike others, the design of our approach promotes the idea of leveraging the complementary capabilities of different models and utilizing their strengths, rather than focusing on model performance competition. This will contribute towards generating more comprehensive explanations that meet the needs of different end users and purposes in the future.},
  archive      = {J_EAAI},
  author       = {Bemali Wickramanayake and Chun Ouyang and Yue Xu and Catarina Moreira},
  doi          = {10.1016/j.engappai.2023.106678},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106678},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generating multi-level explanations for process outcome predictions},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ITran: A novel transformer-based approach for industrial
anomaly detection and localization. <em>EAAI</em>, <em>125</em>, 106677.
(<a href="https://doi.org/10.1016/j.engappai.2023.106677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is currently an essential quality monitoring process in industrial production. It is often affected by factors such as under or over reconstruction of images and unclear criteria for feature distribution evaluation, thus making it challenging to improve detection performance. To solve the above problems, this paper proposes a novel transformer-based approach, Inductive Transformer (ITran) for industrial anomaly detection and localization, which utilizes a multi-layer pyramid structure and multi-level jump connections to extract multi-scale features of the data, putting the anomaly detection into the feature space and achieving more accurate industrial anomaly detection and localization results. It incorporates inductive bias and convolution operations into the Transformer which helps to break the myth of Transformer being “data hungry”. Compared with the common Transformers, ITran significantly reduces the computational cost and memory usage and makes it work well on small datasets. In addition, we basically eliminate the effect of positional embedding on the proposed Transformer model. Sufficient experiments have been conducted to validate global anomaly detection on three datasets MNIST, Fashion-MNST and Cifar-10, as well as local anomaly detection on the industrial datasets MVTec AD, Concrete Crack Image and BTAD. The proposed ITran achieves outstanding results on all the above datasets.},
  archive      = {J_EAAI},
  author       = {Xiangyu Cai and Ruliang Xiao and Zhixia Zeng and Ping Gong and Youcong Ni},
  doi          = {10.1016/j.engappai.2023.106677},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106677},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ITran: A novel transformer-based approach for industrial anomaly detection and localization},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online learning using deep random vector functional link
network. <em>EAAI</em>, <em>125</em>, 106676. (<a
href="https://doi.org/10.1016/j.engappai.2023.106676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have shown their promise in recent years with their state-of-the-art results. Yet, backpropagation-based methods may suffer from time-consuming training process and catastrophic forgetting when performing online learning. In this work we attempt to curtail them by employing the ensemble deep Random Vector Functional Link (edRVFL). As opposed to backpropagation-based neural networks that adjust weights iteratively, RVFL uses a closed-form solution method without iterative parameter learning. In addition, our approach allows the model to grow incrementally as new data is made available so that it can more resemble real-life learning scenarios. Our proposed online learning models were able to perform better on 72% of the datasets in the classification scenario and 80% of the datasets in the regression scenario, when compared to other available randomization-based online learning models in the literature. This is further supported by statistical comparisons which also show the stability of our network.},
  archive      = {J_EAAI},
  author       = {Sreenivasan Shiva and Minghui Hu and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1016/j.engappai.2023.106676},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106676},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online learning using deep random vector functional link network},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sensor fault analysis of aero-engine using ensemble SCNN and
bayesian interval estimation. <em>EAAI</em>, <em>125</em>, 106675. (<a
href="https://doi.org/10.1016/j.engappai.2023.106675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensors of an aircraft engine have the problems of multiple kinds of faults and difficulty to diagnose. Moreover, the diagnosis performance cannot meet practical demands. Therefore, this paper proposes a novel approach for sensor fault diagnosis integrating the advantages of selective ensemble learning, siamese convolutional neural network (SCNN), and Bayesian interval estimation (BIE). The Bayesian interval estimation with hypothesis testing is developed with real-time data update to reduce the confidence interval. The attention mechanism is introduced to enhance fault diagnosis performance. Moreover, ensemble selection learning with Akaike information criteria is proposed to obtain optimal SCNNs. The theorems of convergence and optimal confidence data in ensemble learning are proven. Furthermore, this paper develops a novel improved learning algorithm based on AdaMod (Adaptive and momental bound method) and SGD (stochastic gradient descent), and achieves a new fault diagnosis algorithm to improve the diagnosis performance. The sensor data of aircraft engines from China Eastern Airlines is adopted for validation and experimental results show that proposed approach reaches an excellent tradeoff between sensor diagnosis performance, confidence interval, and runtime. The ablation studies are performed to analyze the role of leaner’s components. The proposed method improves training accuracy by 6.2%, fault diagnosis performance by 5.1%, fault prediction mean result by 4.6%, and fault prediction variance is reduced by 38.1% than the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Junqiang Liu},
  doi          = {10.1016/j.engappai.2023.106675},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106675},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sensor fault analysis of aero-engine using ensemble SCNN and bayesian interval estimation},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A partial domain adaptation scheme based on weighted
adversarial nets with improved CBAM for fault diagnosis of wind turbine
gearbox. <em>EAAI</em>, <em>125</em>, 106674. (<a
href="https://doi.org/10.1016/j.engappai.2023.106674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most domain adaptation methods for fault diagnosis depend heavily on the precondition that the source and target domain have an identical label space, which is hard to be satisfied in industrial sites. Recently, many approaches have been developed to implement partial domain adaptation. However, most existing methods adopt classic convolutional neural network as the feature extractor, which limits the ability to learn discriminative representations from non-stationary vibration signals of wind turbine (WT) gearboxes. Moreover, the design of multiple subdomain adaptation will cause complex network structure with many source classes. To address these problems, this paper proposes a partial domain adaptation scheme based on weighted adversarial nets with improved convolutional block attention module (CBAM) for WT gearbox unsupervised fault diagnosis. In detail, a residual convolutional network combining the improved CBAM is designed to extract finer domain discriminative features for knowledge transfer. Meanwhile, a weighting mechanism based on the two-stage domain discriminator is designed to evaluate the contribution of each source sample, through which a simplified transfer network structure is constructed and the source samples unrelated to the target domain can be filtered. Furthermore, an adversarial transfer strategy is introduced to decrease the distribution discrepancy between domains, then the helpful diagnosis knowledge can be transferred. Experiments on two cases demonstrate the superiority and effectiveness of the proposed method compared with existing domain adaptation methods.},
  archive      = {J_EAAI},
  author       = {Yunyi Zhu and Yan Pei and Anqi Wang and Bin Xie and Zheng Qian},
  doi          = {10.1016/j.engappai.2023.106674},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106674},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A partial domain adaptation scheme based on weighted adversarial nets with improved CBAM for fault diagnosis of wind turbine gearbox},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multidimensional bayesian architecture for real-time
anomaly detection and recovery in mobile robot sensory systems.
<em>EAAI</em>, <em>125</em>, 106673. (<a
href="https://doi.org/10.1016/j.engappai.2023.106673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For mobile robots to operate in an autonomous and safe manner they must be able to adequately perceive their environment despite challenging or unpredictable conditions in their sensory apparatus. Usually, this is addressed through ad-hoc, not easily generalizable Fault Detection and Diagnosis (FDD) approaches. In this work, we leverage Bayesian Networks (BNs) to propose a novel probabilistic inference architecture that provides generality, rigorous inferences and real-time performance for the detection, diagnosis and recovery of diverse and multiple sensory failures in robotic systems. Our proposal achieves all these goals by structuring a BN in a multidimensional setting that up to our knowledge deals coherently and rigorously for the first time with the following issues: modeling of complex interactions among the components of the system, including sensors, anomaly detection and recovery; representation of sensory information and other kinds of knowledge at different levels of cognitive abstraction; and management of the temporal evolution of sensory behavior. Real-time performance is achieved through the compilation of these BNs into feedforward neural networks. Our proposal has been implemented and tested for mobile robot navigation in environments with human presence, a complex task that involves diverse sensor anomalies. The results obtained from both simulated and real experiments prove that our architecture enhances the safety and robustness of robotic operation: among others, the minimum distance to pedestrians, the tracking time and the navigation time all improve statistically in the presence of anomalies, with a diversity of changes in medians ranging from ≃ 20 % to ≃ 500 % .},
  archive      = {J_EAAI},
  author       = {Manuel Castellano-Quero and Manuel Castillo-López and Juan-Antonio Fernández-Madrigal and Vicente Arévalo-Espejo and Holger Voos and Alfonso García-Cerezo},
  doi          = {10.1016/j.engappai.2023.106673},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106673},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multidimensional bayesian architecture for real-time anomaly detection and recovery in mobile robot sensory systems},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-strategy improved differential evolution algorithm
for UAV 3D trajectory planning in complex mountainous environments.
<em>EAAI</em>, <em>125</em>, 106672. (<a
href="https://doi.org/10.1016/j.engappai.2023.106672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the complexity of power repair in mountainous areas and the limitations of traditional vehicles due to terrain constraints, this study focuses on the three-dimensional trajectory planning problem of UAVs (Unmanned Aerial Vehicles) in mountainous environments. Our goal is to provide effective solutions for the trajectory planning problem of UAVs in mountainous environments. Firstly, a UAV trajectory planning model is established, incorporating optimization objectives such as energy consumption, trajectory cost, obstacle avoidance cost, smoothing cost, and stability cost. The trajectory planning problem is transformed into an objective function optimization task with multiple performance constraints. To overcome the inefficiency and infeasibility of traditional algorithms in solving complex three-dimensional flight environments, we propose improvements to the Differential Evolution (DE) algorithm through three strategies: incorporating mutation crossover factor optimization strategy, an adaptive guidance mechanism, and an elite disturbance mechanism based on population classification. The Multi-Strategy Improved Differential Evolution (MSIDE) algorithm is introduced, and its time and space complexity are analyzed. Finally, the proposed method is compared with various algorithms through benchmark functions tests, Friedman test, Wilcoxon rank-sum test, simulation experiments in three-dimensional environments, and parameter sensitivity analysis experiments. The simulation results show that compared with the current state-of-the-art algorithms, the MSIDE algorithm improves the objective function value by 11.34% on average in regular terrain and 5.04% on average in complex terrain environments. The results demonstrate the convergence, multi-objective search capability, and global search ability of MSIDE, validating its effectiveness in solving the trajectory planning problem of UAVs in complex mountainous environments.},
  archive      = {J_EAAI},
  author       = {Miaohan Zhang and Yuhang Han and Shiyun Chen and Mingxian Liu and Zhaolei He and Nan Pan},
  doi          = {10.1016/j.engappai.2023.106672},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106672},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-strategy improved differential evolution algorithm for UAV 3D trajectory planning in complex mountainous environments},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decision support system based on a multivariate supervised
regression strategy for estimating supply lead times. <em>EAAI</em>,
<em>125</em>, 106671. (<a
href="https://doi.org/10.1016/j.engappai.2023.106671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply lead time constitutes a core parameter in inventory management and plays a critical role in supply chain performance. Yet, how to promote better supply lead time estimations that account for multivariate effects of historical supplier dynamics remains poorly understood. This paper proposes a decision support system that uses a supervised regression strategy with multivariate information for estimating supply lead times. We combine ideas from big data analytics and data mining to explore the effects of different supply-related variables on the dynamics of supply lead time. We design a robust rolling window evaluation scheme to compare both the statistical and inventory performance of different well-known data mining models. Numerical tests with empirical data from a large automotive manufacturer demonstrate that the Random Forest model consistently outperforms other competing models, leading to median decreases of 18%–24% in the mean absolute errors of supply lead time estimations. As a consequence of our results, we also provide insights on how these estimations contribute to the proactive management of safety stocks.},
  archive      = {J_EAAI},
  author       = {Júlio Barros and João N.C. Gonçalves and Paulo Cortez and M. Sameiro Carvalho},
  doi          = {10.1016/j.engappai.2023.106671},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106671},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A decision support system based on a multivariate supervised regression strategy for estimating supply lead times},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transferable dynamic enhanced cost-sensitive network for
cross-domain intelligent diagnosis of rotating machinery under
imbalanced datasets. <em>EAAI</em>, <em>125</em>, 106670. (<a
href="https://doi.org/10.1016/j.engappai.2023.106670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalance is an inevitable problem in mechanical fault diagnostics, as most of the monitored samples for mechanical devices are normal, which results in the decision boundary of the classifier being heavily driven by the dominant class and ignoring the minority class. To settle this problem, a transferable dynamic enhanced cost-sensitive network (TDECN) is proposed in this study. Within this framework, the maximum classifier discrepancy approach is utilized as the backbone, in which sliced 1-Wasserstein discrepancy is exploited to measure the distance between two outputs and detect outlier targets. By doing this, the relationship between the task-specific decision border and the target features during distribution matching is considered. Simultaneously, a dynamic enhanced focal loss (DEL) is devised and embedded into the network. which makes the model pay more attention to error-prone and minor class instances compared with routine focal loss. Finally, extensive diagnostic experiments were implemented to evaluate the effectiveness of the proposed TDECN. The noticeable accuracy improvement demonstrates that our method is superior in resolving imbalanced cross-domain fault diagnosis problems over other approaches.},
  archive      = {J_EAAI},
  author       = {Gang Mao and Yongbo Li and Zhiqiang Cai and Bin Qiao and Sixiang Jia},
  doi          = {10.1016/j.engappai.2023.106670},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106670},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transferable dynamic enhanced cost-sensitive network for cross-domain intelligent diagnosis of rotating machinery under imbalanced datasets},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A quantum algorithm for solving weapon target assignment
problem. <em>EAAI</em>, <em>125</em>, 106668. (<a
href="https://doi.org/10.1016/j.engappai.2023.106668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computers, known to have the potential for exponential speedup in solving some problems due to their superposition property, are expected to facilitate the solution of NP-hard optimisation problems. This study proposes a quantum algorithm to solve the weapon target assignment problem (WTAP), one of the NP-hard optimisation problems. The proposed quantum algorithm is a gate-based approach, and scenario examples are executed on Qiskit quantum computing platform and IBM Lima quantum computer with Falcon r4T processor type. The results manifest that the proposed quantum algorithm has low space and time complexity, demonstrating its memory and computational resources efficiency.},
  archive      = {J_EAAI},
  author       = {Erdi Acar and Saim Hatipoğlu and İhsan Yılmaz},
  doi          = {10.1016/j.engappai.2023.106668},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106668},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A quantum algorithm for solving weapon target assignment problem},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic dual hesitant fuzzy MAGDM method based on
generalized extended power average operator and its application to
online teaching platform supplier selection. <em>EAAI</em>,
<em>125</em>, 106667. (<a
href="https://doi.org/10.1016/j.engappai.2023.106667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic dual hesitation fuzzy set (PDHFS) is a new tool used to enhance fuzzy and imprecise information in a changing and complex decision-making environment. Compared with the existing fuzzy sets, PDHFS is more suitable for identifying uncertain evaluation data in complex and realistic decision-making situations. The extended power average (EPA) and generalized power average (GPA) operators provide more information for the information aggregation process, reflecting the mutual support among all aggregation values. To solve the evaluation problems related to decision analysis involving extremely complex information, especially in the case of extreme data in the consideration of decision problems. In this paper, the generalized extended power average (GEPA) operator is proposed in the PDHF environment. This research has the following four important contributions. First, we propose a probability splitting algorithm of normalizing PDHFE, and give some new basic operations, score function, distance measures and aggregation operators. Second, to better integrate the advantages of EPA and GPA operators, we developed the GEPA operator, weighted form (WGEPA) and ordered form (GEPOWA). Meanwhile, by adjusting the parameter in three types of operators, we can find that many existing operators are special forms of the three types of operators. Third, extended the three types of operators to the PDHF environment, the PDHFGEPA, PDHFWGEPA, PDHFGEPOWA operators and some special aggregation operators are obtained, and studied their valuable properties in detail. Finally, taking the application of PDHFWGEPA operator as an example, a new multi-attribute group decision-making (MAGDM) technique is developed and used to solve the problem of online teaching platform supplier selection (OTPSS). Through parameter sensitivity analysis, the flexibility and stability of MAGDM technique are illustrated, and compared with some existing decision-making methods, the effectiveness of MAGDM method is proved. In addition, this technique also provides some theoretical references for dealing with other complex MAGDM problems, and provides a new operator for the extension of GEPA operator in other fuzzy environments. The biggest advantage of several operators is that they can pay full attention to the special role of extreme data in decision-making.},
  archive      = {J_EAAI},
  author       = {Baoquan Ning and Hongjun Wang and Guiwu Wei and Cun Wei},
  doi          = {10.1016/j.engappai.2023.106667},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106667},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic dual hesitant fuzzy MAGDM method based on generalized extended power average operator and its application to online teaching platform supplier selection},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep supervision feature refinement attention network for
medical image segmentation. <em>EAAI</em>, <em>125</em>, 106666. (<a
href="https://doi.org/10.1016/j.engappai.2023.106666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improvement of medical technology is closely related to the development of computers. Deep learning methods have become an important means for medical image processing, and their accuracy in processing lesions will have a significant impact on the final diagnosis result. Currently, some traditional algorithms and classical deep learning methods are no longer able to meet the increasing demand for higher accuracy in medical image processing. In order to achieve better performance in handling the edge and detail features of lesions, we create the Deep Supervision Feature Refinement Attention Network (DSFRA-Net) through extensive experiments. In DSFRA-Net, the Depth Feature Attention Block is created to enhance the long-range dependency between pixels in deep neural networks. The Feature Refinement Block is developed to enhance the details in shallow features. The Adaptive Feature Extraction Block is created to strengthen the fusion of semantic information and detail information. A deep supervision mechanism is used to supervise each layer of the feature reconstruction process, feeding back the training in the form of a loss function to optimize the training. DSFRA-Net experiments on four datasets, all of which show better performance than the current mainstream networks. It shows superior capabilities in areas such as feature continuity and detailed feature processing.},
  archive      = {J_EAAI},
  author       = {Zhaojin Fu and Jinjiang Li and Zhen Hua and Linwei Fan},
  doi          = {10.1016/j.engappai.2023.106666},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106666},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep supervision feature refinement attention network for medical image segmentation},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using conceptual graph modeling and inference to support the
assessment and monitoring of bridge structural health. <em>EAAI</em>,
<em>125</em>, 106665. (<a
href="https://doi.org/10.1016/j.engappai.2023.106665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective bridge maintenance requires sufficient and accurate knowledge on structural health. However, despite the development of structural health monitoring (SHM) and inspection aids, bridge structural health monitoring remains challenging. This work proposes a comprehensive predictive description based on Conceptual Graphs (CG), of the bridge condition deterioration mechanism, with the formalization of the inspection history. The model combines formalized​ assumptions with several deterioration factors and expert knowledge to assess the evolution of the structural condition. The model is based on logical and graphical descriptions of the deterioration of the structural condition thanks to the use of the CG modeling. Through the graphical inference, the evolution of the apparent condition and the deterioration time can be assessed. The application to two bridge cases highlights the interest of this approach to help understanding the sequence of deterioration. The actual condition obtained and the formalized inspection history allow a better decision.},
  archive      = {J_EAAI},
  author       = {Sylvain Ndinga Okina and Franck Taillandier and Louis Ahouet and Quynh Anh Hoang and Denys Breysse and Paul Louzolo-Kimbembe},
  doi          = {10.1016/j.engappai.2023.106665},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106665},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Using conceptual graph modeling and inference to support the assessment and monitoring of bridge structural health},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Sparse representation learning using ℓ1−2 compressed
sensing and rank-revealing QR factorization. <em>EAAI</em>,
<em>125</em>, 106663. (<a
href="https://doi.org/10.1016/j.engappai.2023.106663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressive sensing can be conceptualized for a classification problem in the context of representation learning, which is frequently applied for signal reconstruction via a few measurements. A novel compressive sensing-based approach is presented to substantially reduce the number of required samples for classification. This technique considers the pixels of image as sensors and it seeks to identify the most optimum sensors as decision variables in feature space. In this study, Spatial sensor locations are acquired through learning to identify the regions within an image where the most discriminative information for classification is embedded. ℓ 1 − 2 minimization, as nonconvex but Lipschitz continuous, is solved to obtain the least non-zero elements of the full measurement vector to completely reconstruct the discriminative vector in feature space. Optimal sensors are localized from the training-set and subsequent test images are categorized based on learned sensors. The algorithm consists of three primary components: sparse minimization, feature space, and discrimination vector. ℓ 1 − 2 minimization, rank-revealing QR factorization (RRQR) and SVM are considered for enhanced sparsity exploitation, feature space extraction and discrimination vector acquiring, respectively. The proposed method is evaluated on four different experiments and is compared against a state-of-art technique. The results demonstrate the superiority of proposed method to the compared method.},
  archive      = {J_EAAI},
  author       = {Amir Moslemi},
  doi          = {10.1016/j.engappai.2023.106663},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106663},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sparse representation learning using ℓ1−2 compressed sensing and rank-revealing QR factorization},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple-criteria decision making, feature selection, and
deep learning: A golden triangle for heart disease identification.
<em>EAAI</em>, <em>125</em>, 106662. (<a
href="https://doi.org/10.1016/j.engappai.2023.106662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVD) are among the deadliest illnesses that suffer many people worldwide. Nevertheless, an on-time diagnosis of heart disease can play a significant role in healthcare; since it can reduce the chances of death and save much money in case of necessary treatment. This article develops an efficient and accurate system that uses artificial neural networks (ANN), feature selection (FS) methods, and multiple-criteria decision-making (MCDM) techniques to diagnose heart disease. Appropriate features are selected by utilizing five feature selection methods. Then, three artificial neural networks for CVD prediction were implemented, and their performances were checked according to eight solid criteria. In addition, Particle Swarm Optimizer (PSO) has been utilized to select the optimal hyperparameters to reach high accuracy. A novel integrated weighting method using MEREC and BWM is developed to consider experts’ statements and data evaluation in the criteria weighting operation to choose the best feature selection-artificial neural network method for heart disease detection. Then, an extended version of ELECTRE III is introduced to assess fifteen alternatives, which has proven to be more accurate than other ELECTRE methods in this research. Results validation has been done by utilizing eight MCDM techniques, the Pearson correlation coefficient test, and criteria weights sensitivity analysis by implementing ten scenarios to assess our methodology’s robustness. Finally, the outcomes indicate that LASSO-CNN, AdaBoost-CNN, and AdaBoost-MLP are the top 3 approaches with the accuracy of 99.51%, 98.54%, and 98.54%, respectively. To the best of our knowledge, these are the highest accuracy rates obtained in the literature so far.},
  archive      = {J_EAAI},
  author       = {Amirhossein Najafi and Alireza Nemati and Mahdi Ashrafzadeh and Sarfaraz Hashemkhani Zolfani},
  doi          = {10.1016/j.engappai.2023.106662},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106662},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple-criteria decision making, feature selection, and deep learning: A golden triangle for heart disease identification},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal expression detection (MED): A cutting-edge
review of current trends, challenges and solutions. <em>EAAI</em>,
<em>125</em>, 106661. (<a
href="https://doi.org/10.1016/j.engappai.2023.106661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of day-to-day learning, expressions are very vital. Detection of human expressions is growing and has caught the interest of many researchers in the past few years, to facilitate research on Affective Computing. Classification of expressions is necessarily needed to keep focus on several expressions for developing an efficient electronic learning system. This classification can provide several solutions in the application of psychology, human computer interaction, artificial intelligence, education, gaming etc. The core attention of this review is to highlight the most recent algorithms used for the extraction of features from multi-modal datasets and various classifiers that are used in the discipline of Multi-modal expression detection (MED). In this study, we review the literature on MED between 2015 and 2022, focusing mainly on feature extraction and classifier schemes. Their advantages, disadvantages and the entire vision have been discussed in brief. This survey also shows that the efficiency of the MED environment is better as compared to single-modal ones.},
  archive      = {J_EAAI},
  author       = {Nikhil Singh and Rajiv Kapoor},
  doi          = {10.1016/j.engappai.2023.106661},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106661},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modal expression detection (MED): A cutting-edge review of current trends, challenges and solutions},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed neural networks for mesh deformation with
exact boundary enforcement. <em>EAAI</em>, <em>125</em>, 106660. (<a
href="https://doi.org/10.1016/j.engappai.2023.106660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we have applied physics-informed neural networks (PINN) for solving mesh deformation problems. We used the collocation PINN method to capture the new positions of the vertex nodes while preserving the connectivity information. We use linear elasticity equations for mesh deformation. To prevent vertex collisions or edge overlap, the mesh movement in this work is conducted in steps with relatively small movements. For moving boundary problems, the exact position of the boundary is essential for having an accurate solution. However, PINNs are frequently unable to satisfy Dirichlet boundary conditions exactly. To overcome this issue, we have used hard boundary condition enforcement to automatically satisfy Dirichlet boundary conditions. Specifically, we first trained a PINN with soft boundary conditions to obtain a particular solution. Then, this solution was tuned with exact boundary positions and a proper distance function by using a new PINN considering only the equation residual. To assess the accuracy of our approach, we used the classical translation and rotation tests and compared them with a proper mesh quality metric considering the change in the element area and shape. The results show the accuracy of this approach is comparable with that of finite element solutions. We also solved different moving boundary problems, resembling commonly used fluid–structure interaction problems. This work provides insight into using PINN for mesh-deformation problems without needing a discretization scheme with reasonable accuracy.},
  archive      = {J_EAAI},
  author       = {Atakan Aygun and Romit Maulik and Ali Karakus},
  doi          = {10.1016/j.engappai.2023.106660},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106660},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed neural networks for mesh deformation with exact boundary enforcement},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-dimensional data analytics in civil engineering: A
review on matrix and tensor decomposition. <em>EAAI</em>, <em>125</em>,
106659. (<a
href="https://doi.org/10.1016/j.engappai.2023.106659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in sensing and monitoring techniques have led to the generation of high-dimensional data in the field of civil engineering. High-dimensional data analytics methods have thus been developed to interpret such complex data. Among the different high-dimensional data analytics techniques, matrix and tensor decomposition methods have acquired a notable interest in the civil engineering community over the past decade. Due to their unique ability to deal with highly redundant and correlated data, these methods are establishing themselves as promising and efficient tools to analyze high-dimensional data in the civil engineering arena. In this paper, high-dimensional data is referred to as a data set in which the number of features is comparable or larger than the number of observations. This review paper aims to summarize the applications of matrix and tensor decomposition methods in civil engineering over the last decade. The survey begins with a general overview of matrix and tensor decomposition followed by highlighting their significance in the field. Afterward, various applications of these high-dimensional data analytics methods in civil engineering are presented, while the advantages offered by these methods are discussed. Finally, challenges and potential research avenues for employing matrix and tensor decomposition and future emerging trends for their novel use are highlighted.},
  archive      = {J_EAAI},
  author       = {Hadi Salehi and Alex Gorodetsky and Roya Solhmirzaei and Pengcheng Jiao},
  doi          = {10.1016/j.engappai.2023.106659},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106659},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {High-dimensional data analytics in civil engineering: A review on matrix and tensor decomposition},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining knowledge extension with convolution neural
network for diabetes prediction. <em>EAAI</em>, <em>125</em>, 106658.
(<a href="https://doi.org/10.1016/j.engappai.2023.106658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction and diagnosis of diabetes are critical issues in the field of smart healthcare. However, the dependence of large-scale annotated diabetes data and the lack of diabetes knowledge represent significant challenges for diabetes prediction. To address these challenges, we propose a new diabetes prediction model named KE-CNN, which combines knowledge extension and convolution neural network. The KE-CNN model first extracts abnormal indicator features from physical examination index data of diabetic patients and uses Word2vec to embed the feature words. We then employ entity recognition technique named BERT-BiLSTM-CRF to identify medical entities in the condition description text and utilize a knowledge graph to extend the knowledge of each medical entity, followed by using pre-trained Chinese word vectors to embed the extended description text. Finally, we construct a semantic enhanced convolutional neural network model with word embedding vectors and text embedding vectors as dual-channel input, aiming to enhance the feature expression of the KE-CNN model. Our model not only learns and captures more fine-grained features of diabetes information, but also significantly reduces the amount of data required for model training and improves the prediction performance of convolutional neural network models. Our experiments show that the KE-CNN model effectively improves the accuracy of diabetes prediction compared with the benchmark model.},
  archive      = {J_EAAI},
  author       = {Haitao Cheng and Jingshu Zhu and Peng Li and He Xu},
  doi          = {10.1016/j.engappai.2023.106658},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106658},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combining knowledge extension with convolution neural network for diabetes prediction},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal reinforcement learning based on bayesian networks
applied to industrial settings. <em>EAAI</em>, <em>125</em>, 106657. (<a
href="https://doi.org/10.1016/j.engappai.2023.106657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing amount of real-time data collected from sensors in industrial environments has accelerated the application of machine learning in decision-making. Reinforcement learning (RL) is a powerful tool to find optimal policies for achieving a given goal. However, RL’s typical application is risky and insufficient in environments where actions can have irreversible consequences and require interpretability and fairness. While new trends in RL may provide guidance based on expert knowledge, they do not often consider uncertainty or include prior knowledge in the learning process. We propose a causal reinforcement learning alternative based on Bayesian networks (RLBNs) to address this challenge. The RLBN simultaneously models a policy and takes advantage of the joint distribution of the state and action space, reducing uncertainty in unknown situations. We propose a training algorithm for the network’s parameters and structure based on the reward function and likelihood of the effects and measurements taken. Our experiment with the CartPole benchmark and industrial fouling using ordinary differential equations (ODEs) demonstrates that RLBNs are interpretable, secure, flexible, and more robust than their competitors. Our contributions include a novel method that incorporates expert knowledge into the decision-making engine. It uses Bayesian networks with a predefined structure as a causal graph and a hybrid learning strategy that considers both likelihood and reward. This would avoid losing the virtues of the Bayesian network.},
  archive      = {J_EAAI},
  author       = {Gabriel Valverde and David Quesada and Pedro Larrañaga and Concha Bielza},
  doi          = {10.1016/j.engappai.2023.106657},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106657},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal reinforcement learning based on bayesian networks applied to industrial settings},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SIRN: An iterative reasoning network for transmission lines
based on scene prior knowledge. <em>EAAI</em>, <em>125</em>, 106656. (<a
href="https://doi.org/10.1016/j.engappai.2023.106656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-accuracy positioning and identification of transmission line components is the premise for their status detection and fault diagnosis. However, due to the limitations of imbalance object scale and distribution in aerial images, the problem of detecting dense-tiny objects still needs to be solved. Considering the prior knowledge of fixed connection scenes, we proposed a novel method named scene iterative reasoning network (SIRN) based on self-adaptive clustering and local scene knowledge. It consists of the coarse-grained detector (CGD), scene self-adaptive clustering (SSAC) subnetwork, and scene structure iterative reasoning (SSIR) subnetwork. The CGD was proposed to obtain global coarse detection results. Then, the SSAC subnetwork utilized unsupervised self-adaptive clustering to obtain accurate dense regions based on the CGD results. Finally, the SSIR subnetwork was designed to extract and fuse the scene semantic structure information of local regions for realizing accurate dense-tiny object detection. In summary, the SIRN model utilizes an iterative inference strategy to detect dense regions accurately. By leveraging scene structure information, the model effectively transforms the challenge of detecting dense objects into an advantage, resulting in precise detection. The SIRN model is compatible with single-stage and two-stage object detection models, achieving a notable mean average precision (mAP) improvement ranging from 4.4% to 12.2% compared to the baseline models. Compared to other state-of-the-art object detection models, SIRN demonstrates significant advantages in accuracy and error rate metrics. In addition, qualitative and quantitative experiments show that the SIRN model considerably enhanced the detection of dense-tiny objects. The code is available at https://github.com/CharmingWang/SIRN .},
  archive      = {J_EAAI},
  author       = {Qianming Wang and Congbin Guo and Zhenbing Zhao and Yaru Wang and Lifeng Hu and Yongjie Zhai},
  doi          = {10.1016/j.engappai.2023.106656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SIRN: An iterative reasoning network for transmission lines based on scene prior knowledge},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy decision-making approach of hobbing tool and cutting
parameters. <em>EAAI</em>, <em>125</em>, 106655. (<a
href="https://doi.org/10.1016/j.engappai.2023.106655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machining performance, such as carbon emission, machining time, and quality, can be improved by selecting appropriate tools and cutting parameters for gear hobbing. However, the importance machining performance is usually difficult for users to quantify. To resolve the decision-making problem of hobbing tools and cutting parameters in fuzzy evaluation, a multi-objective fuzzy decision-making approach for hobbing parameters is proposed. It uses spectral clustering, the multi-objective weighted mean of vectors (MOINFO) algorithm and the fuzzy technique for ordering preference by similarity to the ideal solution (TOPSIS) algorithm. First, spectral clustering is used to confirm the initial range of the hobbing parameters based on past machining cases. MOINFO is then applied to search for nondominated hobbing parameters based on the optimization model, taking the carbon emission, cutting time, and quality as the objectives. Finally, the nondominated hobbing parameters are sorted by fuzzy TOPSIS according to a user evaluation, and the hobbing parameter ranking is used to guide hob selection and machining. Decision-making experiments on the hobbing parameters are performed with actual hobbing. The comprehensive evaluation index C E I result for the proposed approach is 0.19. Compared with other methods, the proposed approach exhibits certain advantages. These results demonstrate that the multi-objective decision-making problem of hobbing parameters under fuzzy evaluation can be solved using the proposed approach.},
  archive      = {J_EAAI},
  author       = {Weidong Cao and Xingzheng Chen and Jianjun Ni},
  doi          = {10.1016/j.engappai.2023.106655},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106655},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy decision-making approach of hobbing tool and cutting parameters},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage data-driven metaheuristic to predict last-mile
delivery route sequences. <em>EAAI</em>, <em>125</em>, 106653. (<a
href="https://doi.org/10.1016/j.engappai.2023.106653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On delivery operations, vehicle routing problems regularly focus on optimizing route-solution quality. However, the real-life execution of routes often differs from the computed routing plan. Therefore, the routing algorithms should use information from historic routes and drivers’ decisions to make the planned route as similar as possible to the actual executed route. We study the problem of predicting route sequences that drivers follow in last-mile parcel delivery in the context of the 2021 Amazon Last-Mile Routing Research Challenge. We propose extracting information from historic routes using a probability estimation method that learns transition probabilities between clusters or zones, coupled with a simple yet effective two-stage Greedy Randomized Adaptive Search Procedure (GRASP) to incorporate the information from historical route data into route planning. Our GRASP includes components in the objective function that consider decisions observed on the historical route sequences supplied by Amazon. We evaluate the predicted route sequences using the score similarity metric provided in the Amazon challenge. The results show that our method obtains a similarity score of 0.0328, which is comparable to the scores achieved by the three winning teams of the Amazon challenge. The proposed method successfully uses historical routes to predict route sequences on a last-mile delivery setting.},
  archive      = {J_EAAI},
  author       = {Juan Pablo Mesa and Alejandro Montoya and Raúl Ramos-Pollán and Mauricio Toro},
  doi          = {10.1016/j.engappai.2023.106653},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106653},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage data-driven metaheuristic to predict last-mile delivery route sequences},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transformer neural network for AC series arc-fault
detection. <em>EAAI</em>, <em>125</em>, 106651. (<a
href="https://doi.org/10.1016/j.engappai.2023.106651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting series arcing faults in the electrical networks of aircraft can help mitigate dramatic consequences such as fires. Non-Artificial Intelligence algorithms often fail to generalise due to arc fault signals diversity. Most methods in the detection literature use multiple pre-processing (descriptors) associated to a machine learning model (or deep learning). These approaches require to handcraft the descriptors. We propose a deep learning approach without descriptors. We adapted a sequence-based model called a Transformer Neural Network (TNN) model to this time series problem. We repurposed the encoder of the transformer as a sequence-to-sequence model. The model takes as an input a window of electric current, with at least one period of the signals ( 800 Hz). The output is the label of each point in the input window. This required to propose an original manner of labelling the signals, for which we designed an automated algorithm, increasing the training supervision. Contrary to existing models on aircraft signals, our TNN model has been verified using a public experimental database of electrical-arc signals that simulates aircraft signals ( 230 V AC at 400 − 800 Hz, arcs in series with resistive loads). Our model obtained an identification accuracy of 96.3% at a 2% false positive rate. One of the significant performance of our model is that it has the lowest parameter number (2266) that can be found in scientific literature by quite some margin. TNNs are therefore an appropriate candidate for the purpose of arc fault detection, and our labelling method provides a very high temporal resolution of the output.},
  archive      = {J_EAAI},
  author       = {A. Chabert and M.C. Bakkay and P. Schweitzer and S. Weber and J. Andrea},
  doi          = {10.1016/j.engappai.2023.106651},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106651},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transformer neural network for AC series arc-fault detection},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Adaptive finite-time fault-tolerant control for the
full-state-constrained robotic manipulator with novel given performance.
<em>EAAI</em>, <em>125</em>, 106650. (<a
href="https://doi.org/10.1016/j.engappai.2023.106650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most robot manipulators usually operate under different nonlinearities, such as state constraints, time delays, and actuator input saturation faults. This paper proposes an adaptive finite-time fault-tolerant controller for the full-state-constrained robotic manipulator with novel prescribed performance and time-varying delays. Firstly, a novel prescribed performance function consisting of hyperbolic tangent and hyperbolic cotangent functions is constructed to the full-state performance constraints of the robotic manipulator. Such a design can circumvent the demands for accurate initial conditions of the state variables and guarantee the convergence of the state errors in a prescribed time. Then, based on the finite-time principle, a finite-time command filter and a compensation mechanism with fractional-power terms are used to bypass the “explosion of complexity” and further compensate for the filter errors within a finite time. Moreover, a proper Lyapunov–Krasovskii functional is devised within the controller design to compensate for the time-varying delays. And the radial basis function neural networks are used to estimate the other nonlinearities including actuator saturation faults, and external perturbations. Finally, simulation results exhibit that the controller designed in this paper has a faster convergence speed and minor state errors.},
  archive      = {J_EAAI},
  author       = {Menghan Li and Junxing Zhang and Shaobo Li and Fengbin Wu},
  doi          = {10.1016/j.engappai.2023.106650},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106650},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive finite-time fault-tolerant control for the full-state-constrained robotic manipulator with novel given performance},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-fidelity machine learning based uncertainty
quantification of progressive damage in composite laminates through
optimal data fusion. <em>EAAI</em>, <em>125</em>, 106647. (<a
href="https://doi.org/10.1016/j.engappai.2023.106647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently machine learning (ML) based approaches have gained significant attention in dealing with computationally intensive analyses such as uncertainty quantification of composite laminates. However, high-fidelity ML model construction is computationally demanding for such high-dimensional problems due to the required large amount of high-fidelity training data. We propose to address this issue effectively through multi-fidelity ML based surrogates which can use a training dataset consisting of optimally distributed high- and low-fidelity simulations. For forming multi-fidelity surrogates of progressive damage in composite laminates, we combine low-fidelity finite element analysis data obtained using Matzenmiller damage model with Hasin failure criteria and high-fidelity finite element analysis data obtained using three-dimensional continuum damage mechanics based model with P Linde’s failure criteria. It is shown that there is a significant computational advantage to using the multi-fidelity surrogate approach as compared to conventional single-fidelity surrogates. Such computational advantage through optimal data fusion without compromising accuracy becomes crucial for the subsequent data-driven uncertainty quantification and sensitivity analysis of composites involving thousands of realizations. Ply orientations come out to be the most sensitive parameters to matrix damage, fibre damage and reaction force in composite laminates. The degree of uncertainty in the output quantities depend on the input-level stochastic variations. For example, a combined stochastic variation of ± 10 % in material properties and ± 10 ° in ply orientations lead to 1.85%, 16.98% and 11.24% coefficient of variation in the matrix damage, fibre damage and reaction force respectively. In general, the numerical results obtained based on the efficient data-driven approach strongly suggest that source-uncertainty of composites significantly influences the progressive damage evolution and global mechanical behaviour, leading to the realization of the importance of adopting an inclusive analysis framework considering such inevitable random variabilities.},
  archive      = {J_EAAI},
  author       = {R.S. Chahar and T. Mukhopadhyay},
  doi          = {10.1016/j.engappai.2023.106647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-fidelity machine learning based uncertainty quantification of progressive damage in composite laminates through optimal data fusion},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On confidence computation and calibration of deep support
vector data description. <em>EAAI</em>, <em>125</em>, 106646. (<a
href="https://doi.org/10.1016/j.engappai.2023.106646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep support vector data description (DeSVDD) is an emerging anomaly detection method based on the deep learning methodology. However, few studies take the confidence of DeSVDD predictions into account so that the present DeSVDD models cannot indicate the reliability degree of the anomaly detection results. In this paper, we enrich the theory of DeSVDD by building the model confidence definition and developing the corresponding calibration strategy. For one thing, by revisiting the methodology of DeSVDD-based anomaly detection, the confidence of detection results is presented to indicate if the prediction of DeSVDD is reliable. For another, we propose a modified power T -scaling strategy to smooth the anomaly scores of DeSVDD model and improve its calibration performance without changing the original detection results. Six open experiment datasets are used to perform the method testing and the experimental results confirm the effectiveness of our proposed calibration strategy.},
  archive      = {J_EAAI},
  author       = {Xiaogang Deng and Xianhui Jiang},
  doi          = {10.1016/j.engappai.2023.106646},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106646},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On confidence computation and calibration of deep support vector data description},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tremor detection transformer: An automatic symptom
assessment framework based on refined whole-body pose estimation.
<em>EAAI</em>, <em>125</em>, 106645. (<a
href="https://doi.org/10.1016/j.engappai.2023.106645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Essential tremor (ET) is a prevalent neurological disorder that necessitates using objective and non-invasive methods for assessing symptom severity. Traditional visual assessments are often limited by subjectivity, while other wearable sensors or visual markers may result in unnatural movements. This study presents a novel contact-free visual-based pipeline for ET assessment that integrates refined whole-body pose estimation with Transformer-based tremor detection to quantify tremor severity at a fine-grained level. The proposed pose estimation method combines the Transformer with HRNet, effectively capturing spatial-temporal complementary information from multiple body parts and enabling highly accurate tremor detection. The Transformer-based tremor detection is well-suited for modeling long-range dependencies and sequential tremor data extracted by the pose estimation model, further improving the performance of our proposed method. Our study collected data from 61 patients with ET, achieving an average accuracy, recall, and F1 score of 95.6%/95.6%, 89.2%/95.0%, and 83.0%/92.4% for classifying ET severity both during rest and postural tasks, respectively. Our proposed method outperforms the temporal convolutional network baseline, increasing F1 scores by 21.17% and 14.22% for rest and postural tasks, respectively. This high level of accuracy makes our method highly useful for clinical applications such as remote monitoring, diagnosis, and treatment evaluation. Our proposed technique has many advantages over traditional ET assessment techniques, including non-invasiveness, contact-free operation, and not requiring any wearable sensors or visual markers. Moreover, our method can be applied to other movement disorders requiring objective measurements of symptom severity. In summary, our contact-free visual-based pipeline for ET assessment represents a significant improvement over traditional ET assessment techniques, and our quantification results demonstrate its potential for use in clinical settings.},
  archive      = {J_EAAI},
  author       = {Chenbin Ma and Lishuang Guo and Longsheng Pan and Xuemei Li and Chunyu Yin and Rui Zong and Zhengbo Zhang},
  doi          = {10.1016/j.engappai.2023.106645},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106645},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tremor detection transformer: An automatic symptom assessment framework based on refined whole-body pose estimation},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Spatiotemporal networks for ENSO forecasting with LICOM3
and remote sensing data. <em>EAAI</em>, <em>125</em>, 106641. (<a
href="https://doi.org/10.1016/j.engappai.2023.106641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {El Niño/Southern Oscillation (ENSO) is a complex coupled ocean-atmosphere event, usually manifested as an abnormal increase or decrease in Sea Surface Temperature (SST) in the equatorial Pacific Ocean. ENSO is one of the critical factors causing global climate extremes and ecosystem turbulence. Therefore, long-term robust ENSO predictions are essential for people’s productive life and social development. The statistical and dynamic models still face challenges in making long-lead-time ENSO forecasts, and the accuracy can be improved. Here, we have created three innovative efforts for ENSO forecasting: (1) To compensate for the lack of Remote Sensing (RSS) dataset, we apply transfer learning with the large SST dataset simulated from the LASG/IAP Climate Ocean Model Version 3 (LICOM3). (2) We propose a novel encoder-decoder structure with multiple Spatiotemporal prediction units (ST-Pred) named ED-PredRNN. The ST-Pred changes the original transfer direction by adding spatiotemporal memory cells, allowing the model to extract more information. (3) To reduce the memory bandwidth load, we use FP32 and FP16 mixed-precision computing methods to improve model training and inference speed.The result shows that during 2011–2020 verification period, the correlation skills of the Niño 3.4 index predicted by ED-PredRNN are over 0.77/0.64/0.53 within the lead time of 6/12/18 months respectively, which is superior to existing statistical models. Also, the precise predictions of the El Niño event (such as 2015/16) and the La Niña event (such as 2010/11), as well as a reasonable forecast for neutral ENSO conditions (2014), demonstrate the effectiveness and superiority of our proposed model.},
  archive      = {J_EAAI},
  author       = {Xuanying Zhang and Yuzhu Wang and Lianjing Wei and Jinrong Jiang and Pengfei Lin and Hailong Liu},
  doi          = {10.1016/j.engappai.2023.106641},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106641},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatiotemporal networks for ENSO forecasting with LICOM3 and remote sensing data},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MEFNET: Multi-expert fusion network for RGB-thermal semantic
segmentation. <em>EAAI</em>, <em>125</em>, 106638. (<a
href="https://doi.org/10.1016/j.engappai.2023.106638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation using RGB and thermal images is crucial in a variety of applications, including autonomous driving and video surveillance. However, the validity of information differs between modalities, which is typically addressed by weighting image features using complex and inefficient networks. To address this issue, we propose a Multi-Expert Fusion Network (MEFNet) that decouples the three-dimensional attention matrix of image features into a two-dimensional modal weight matrix and a channel attention vector. This approach focuses more on modal and channel differences while excluding interferences from other factors. Specifically, MEFNet multiplies RGB and thermal features by their respective modal weights, and then uses channel attention to select important feature channels. Comprehensive experiments demonstrate that MEFNet is competitive with state-of-the-art methods, achieving 62.6% mIoU on the IR SEG dataset.},
  archive      = {J_EAAI},
  author       = {Wenjie Lai and Fanyu Zeng and Xiao Hu and Wei Li and Shaowei He and Ziji Liu and Yadong Jiang},
  doi          = {10.1016/j.engappai.2023.106638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MEFNET: Multi-expert fusion network for RGB-thermal semantic segmentation},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time multi-factory scheduling in industry 4.0 with
virtual alliances. <em>EAAI</em>, <em>125</em>, 106636. (<a
href="https://doi.org/10.1016/j.engappai.2023.106636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-changing and dynamic market environment requires applying job shop systems based on real-time data. The establishment of physical-virtual systems in the production process has led to the emergence of intelligent factories. Compared with those employing traditional production methods, such factories manufacture products with higher quality, higher production speed, and other economic benefits. Regarding the virtual connections of factories, events such as the arrival of new jobs, and machine breakdowns, are identified by Radio Frequency Identification System between different production units, and related decisions are made quickly and carefully. In this intelligent job shop scheduling, it is assumed that independent factories create virtual production networks in which, each factory focuses on its own interests. Regarding the importance of this issue in today’s industry, this research explores the real-time scheduling problem in multi-agent production networks distributed in smart factories. Since this problem is a combination of static scheduling and real-time scheduling, a bi-objective model of mixed-integer linear programming is first developed. An approach is then proposed to solve the dynamic real-time scheduling problem. In addition, a learning-based memetic algorithm for solving large-size bi-objective instances is proposed due to the NP-hardness of the considered problem. Afterward, the results of the proposed algorithm are compared with the hybrid Pareto-based tabu search algorithm. The computational results show that in large-size instances, the proposed algorithm outperforms the competing algorithm.},
  archive      = {J_EAAI},
  author       = {N. Bagheri Rad and J. Behnamian},
  doi          = {10.1016/j.engappai.2023.106636},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106636},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time multi-factory scheduling in industry 4.0 with virtual alliances},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning assisted physics-based modeling of aluminum
extraction process. <em>EAAI</em>, <em>125</em>, 106623. (<a
href="https://doi.org/10.1016/j.engappai.2023.106623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling complex physical processes such as the extraction of aluminum is mainly done using pure physics-based models derived from first principles. However, the accuracy of these models can often suffer due to a partial understanding of the process, uncertainty in the input parameters, and numerous modeling assumptions. More recently, with the ever-increasing availability of data, there has been an explosion of interest in applying modern machine learning methods because of their ability to learn complex mappings directly from data. Unfortunately, these models tend to be black boxes, require an enormous amount of data, and do not utilize existing domain knowledge. In this work, we develop a novel approach combining physics-based and data-driven modeling approaches while eliminating some weaknesses. We use a data-driven model to correct a misspecified physics-based model of the Hall–Héroult process in an aluminum electrolysis cell using a corrective source term added to the set of governing ordinary differential equations. Our approach ensures that the existing knowledge is utilized to the maximum extent possible while relying on the data-driven models only to model those aspects which the physics-based model does not represent well. We compare this approach with an end-to-end learning approach and an ablated physics-based model, showing that the proposed hybrid method is more accurate, consistent, and stable for long-term predictions.},
  archive      = {J_EAAI},
  author       = {Haakon Robinson and Erlend Lundby and Adil Rasheed and Jan Tommy Gravdahl},
  doi          = {10.1016/j.engappai.2023.106623},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106623},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning assisted physics-based modeling of aluminum extraction process},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TrackSafe: A comparative study of data-driven techniques for
automated railway track fault detection using image datasets.
<em>EAAI</em>, <em>125</em>, 106622. (<a
href="https://doi.org/10.1016/j.engappai.2023.106622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway track accidents continue to occur despite manual inspections, which are often inaccurate and can lead to catastrophic events. While artificial intelligence has been applied in the railway sector, few studies have focused on defect detection using object detection tools. Additionally, there is a lack of studies that compare different models using the same dataset. This paper proposes new data-driven techniques that identify railway track faults using three object detection models: YOLOv5, Faster RCNN, and EfficientDet. These models are compared by testing a dataset of 31 images that contain three different railway track elements (clip, rail, and fishplate), both faulty and non-faulty. Six classes were differentiated in the training of the models: one faulty and one non-faulty for each of the three classes. Image pre-processing steps included data augmentation techniques and image resizing. Results show good precision (equivalent to 1) in detecting non-defective elements, but recall values for defective elements vary among models, with Faster RCNN performing the best (0.93), followed by EfficientDet (0.81), and YOLOv5 (0.68). The full paper discusses the strengths and weaknesses of these proposed techniques for railway fault detection.},
  archive      = {J_EAAI},
  author       = {Marta Garcia Minguell and Ravi Pandit},
  doi          = {10.1016/j.engappai.2023.106622},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106622},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TrackSafe: A comparative study of data-driven techniques for automated railway track fault detection using image datasets},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Train a central traffic prediction model using local data: A
spatio-temporal network based on federated learning. <em>EAAI</em>,
<em>125</em>, 106612. (<a
href="https://doi.org/10.1016/j.engappai.2023.106612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing complexity of onboard sensors and the widespread deployment of road sensors, deep learning enables fine-grained traffic prediction using massive amounts of raw traffic data, which facilitates accurate analysis of traffic information in the Internet of Vehicles (IoV). However, most existing studies focus on using all the local data to jointly build a prediction model, facing severe challenges of data security and privacy concerns as well as substantial communication overhead. To address these challenges, in this paper, we propose the Spatial-Temporal Traffic Prediction Network based on federated learning (F-STTP-Net), which only updates the model parameters to the centralized server without any private data. Firstly, we design a sub-area division method, which divides the road network into sub-areas with different macroscopic fundamental diagram properties. Then, we propose a local training model for each sub-area, which uses the graph attention network (GAT) and the long short-term memory (LSTM) to capture the spatio-temporal dependence of the road network. The model uses the branch structure to predict the traffic volume of each intersection in the sub-area. Finally, the local models are aggregated based on federated learning to form a powerful central model, which bridges the constraints on global data sharing and privacy guarantee. We conduct experiments on the real-life dataset in Xuchang Lotus Lake 5G automated vehicles demonstration area to demonstrate that F-STTP-Net can achieve excellent prediction performance without the interaction of sub-area raw data. In addition, the proposed model has a strong generalization ability and can be quickly transferred to a new sub-area.},
  archive      = {J_EAAI},
  author       = {Hao Huang and Zhiqun Hu and Yueting Wang and Zhaoming Lu and Xiangming Wen and Bin Fu},
  doi          = {10.1016/j.engappai.2023.106612},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106612},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Train a central traffic prediction model using local data: A spatio-temporal network based on federated learning},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Graph features dynamic fusion learning driven by multi-head
attention for large rotating machinery fault diagnosis with multi-sensor
data. <em>EAAI</em>, <em>125</em>, 106601. (<a
href="https://doi.org/10.1016/j.engappai.2023.106601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, rotating machinery fault diagnosis studies based on graph neural networks (GNN) have received some satisfactory achievements. But most of them are based on the analysis of the single sensor signals, which cannot capture the comprehensive fault information, especially aiming at large rotating machineries. A few research using GNN for multi-sensor fault diagnosis only fuse multi-source features in the construction of the input graph, and the fusion effect largely depends on the manual feature selection. Graph attention network (GAT), as an emerging GNN, can give trainable weights to vertices based on the self-attention mechanism to improve the effectiveness of feature learning. And it has not yet been used in the field of multi-sensor fault diagnosis. To fill this gap and utilize GAT’s advantages, this paper presents a multi-sensor multi-head GAT (MMHGAT) model for large rotating machinery fault diagnosis. With the input of several subgraphs, the designed MMHGAT model consisting of two graph attention layers (GAL), a feature fusion process and a Softmax classifier, can dynamically fuse and mine the high-level fault characteristics during the training process. By employing the experiment on the axial flow pump, the effectiveness and superiority of the proposed method are validated.},
  archive      = {J_EAAI},
  author       = {Xin Zhang and Xi Zhang and Jie Liu and Bo Wu and Youmin Hu},
  doi          = {10.1016/j.engappai.2023.106601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph features dynamic fusion learning driven by multi-head attention for large rotating machinery fault diagnosis with multi-sensor data},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Association of white matter volume with brain age
classification using deep learning network and region wise analysis.
<em>EAAI</em>, <em>125</em>, 106596. (<a
href="https://doi.org/10.1016/j.engappai.2023.106596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural magnetic resonance imaging (sMRI) has been used to examine age-related neuroanatomical changes in the human brain. In the present work, a pre-trained deep learning model and an ensemble deep random vector functional link (edRVFL) classifier have been used to create a brain age classification framework from magnetic resonance imaging (MRI) scans. A total of 155 MRI scans of the brain are obtained from the open-access OpenNeuro database and categorized into three age groups (3–5 years old, 7–12 years old, and 18–40 years old). To visualize the age connection across different brain regions, all MRI scans are first segmented into Gray Matter (GM), White Matter (WM), and Cerebrospinal Fluid (CSF). The ResNet-50 network is used to extract features from MRI images, while the edRVFL network is used to classify the retrieved features. Classification accuracy for GM, WM, CSF, and whole brain images are 96.11%, 98.33%, 93.33%, and 94.00%, respectively, using the edRVFL classifier. Region-wise analysis has also been done using Pearson’s correlation coefficient ( r ), coefficient of determination ( R 2 ), and root mean square error (RMSE) to analyze the relationship between brain age and brain tissue volumes. According to the findings of the suggested deep model for brain age categorization, and region-wise analysis, alterations in WM volume are strongly linked to brain aging.},
  archive      = {J_EAAI},
  author       = {Raveendra Pilli and Tripti Goel and R. Murugan and M. Tanveer},
  doi          = {10.1016/j.engappai.2023.106596},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106596},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Association of white matter volume with brain age classification using deep learning network and region wise analysis},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AdaBoost-driven multi-parameter real-time warning of rock
burst risk in coal mines. <em>EAAI</em>, <em>125</em>, 106591. (<a
href="https://doi.org/10.1016/j.engappai.2023.106591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stope dynamic disaster, which occurs around the mining space and is represented by stress-type rock burst and fracture-type rock burst, seriously affects the safety production of coal mine. How to effectively forewarn rock burst risk to reduce the disaster caused by rock burst is an urgent problem to be solved in stope. In this paper, the spatiotemporal parameters that affect the occurrence of stope dynamic disaster are collected, and the big data of stope state is established. Due to the complex temporal and spatial parameters of rock bursts with different intensities occurrence and their varying degrees, it is difficult for some machine learning methods to excavate their internal relationships and make accurate warning. In this paper, (1) a big data platform is used to record and integrate the multiple parameters of stope dynamic disaster, and data preprocessing technology is used to de-noise and standardize them. (2) Based on the fused historical data, a strong classifier is iteratively found by the classification algorithm AdaBoost to identify the existence of the rock burst risk, so as to achieve the purpose of accurately and timely warning of rock burst risk. The research of this paper uses big data mining technology and machine learning method to carry out intelligent perception warning of the rock burst risk in real time. The experimental results show that the proposed method has a good effect and is of great significance to the prevention and control of rock burst disaster in stope.},
  archive      = {J_EAAI},
  author       = {Rui Wang and Shaojie Chen and Xuelong Li and Gang Tian and Tongbin Zhao},
  doi          = {10.1016/j.engappai.2023.106591},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106591},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AdaBoost-driven multi-parameter real-time warning of rock burst risk in coal mines},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Swarm control based on artificial potential field method
with predicted state and input threshold. <em>EAAI</em>, <em>125</em>,
106567. (<a
href="https://doi.org/10.1016/j.engappai.2023.106567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an improved artificial potential field (APF) method with predictive state is proposed to reduce the influence of communication delay and physical delay on swarm control. The input threshold is introduced to optimize the problem of excessive APF method control input. The control of large-scale swarm systems is challenging due to the complexity of the communication topology. The second-order communication topology is introduced to simplify the coupling relationship of the system. The collision avoidance and formation maintenance control of the swarm system is realized by setting the collision avoidance and formation maintenance potential functions. Based on the proposed improved artificial potential field method, a new distributed controller for swarm system is designed and its stability is analyzed. Numerical simulations are conducted to prove the effectiveness of the proposed strategy.},
  archive      = {J_EAAI},
  author       = {Tao Zhang and Dianbiao Dong and Zhize Du and Jia Long and Dengxiu Yu and Zhen Wang and C.L. Philip Chen},
  doi          = {10.1016/j.engappai.2023.106567},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106567},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Swarm control based on artificial potential field method with predicted state and input threshold},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image captioning using transformer-based double attention
network. <em>EAAI</em>, <em>125</em>, 106545. (<a
href="https://doi.org/10.1016/j.engappai.2023.106545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning generates a human-like description for a query image, which has attracted considerable attention recently. The most broadly utilized model for image description is an encoder–decoder structure, where the encoder extracts the visual information of the image, and the decoder generates textual descriptions of the image. Transformers have significantly enhanced the performance of image description models. However, a single attention structure in transformers cannot consider more complex relationships between key and query vectors. Furthermore, attention weights are assigned to entire candidate vectors based on the assumption that entire vectors are related. In this paper, a new double-attention framework is presented, which improves the encoder–decoder structure to consider image captioning problems. Hence, a local generator module and a global generator module are designed to predict textual descriptions collaboratively. The proposed approach improves Self-Attention (SA) from two aspects to enhance the performance of image description. First, a Masked Self-Attention module is presented to attend on the most relevant information. Second, to evade a single shallow attention distribution and make deeper internal relations, a Hybrid Weight Distribution (HWD) module is proposed, that develops SA to use the relations between key and query vectors efficiently. Experiments over the Flickr30k and MS-COCO datasets prove that the proposed approach achieves desirable performance on different evaluation measures compared to the state-of-the-art frameworks.},
  archive      = {J_EAAI},
  author       = {Hashem Parvin and Ahmad Reza Naghsh-Nilchi and Hossein Mahvash Mohammadi},
  doi          = {10.1016/j.engappai.2023.106545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image captioning using transformer-based double attention network},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing TOC and IOC units of directional overcurrent
relays in mutually coupled circuits using evolutionary PSO: Requirements
and modeling. <em>EAAI</em>, <em>125</em>, 106389. (<a
href="https://doi.org/10.1016/j.engappai.2023.106389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient coordination of directional overcurrent relays is a challenging problem. Recent papers in the literature have focused on developing efficient algorithms to solve this issue. However, there is a lack of reporting practical procedures that affects the mathematical formulation to ensure accurate outputs by any optimization algorithm. In this paper, we show a comprehensive procedure that considers mutually coupled circuits via Graph Theory, the requirements of short-circuit current calculation, contingencies to be considered as well as the setting of Instantaneous Overcurrent (IOC) and Time Overcurrent (TOC) units, both for phase and ground protection. The simulation has been carried out by using a real electric network and C++ language programming. Computational simulation has shown the performance of the method, which provides high-quality solutions, with adequate coordination of the selected protective devices that increase the efficiency in setting this type of protection with safety. Evolutionary Particle Swarm Optimization (EPSO) outperformed conventional Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) as the best metaheuristic for optimally minimizing the proposed problem, achieving faster convergence times for the phase overcurrent protection scenario (16.36 s vs. 22.27 s and 17.03 s, respectively), and also for the ground overcurrent protection scenario (19.87 s vs. 20.44 s and 20.11 s, respectively).},
  archive      = {J_EAAI},
  author       = {Wellington Maycon S. Bernardes},
  doi          = {10.1016/j.engappai.2023.106389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {106389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing TOC and IOC units of directional overcurrent relays in mutually coupled circuits using evolutionary PSO: Requirements and modeling},
  volume       = {125},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedraTrees: A novel computation-communication efficient
federated learning framework investigated in smart grids. <em>EAAI</em>,
<em>124</em>, 106654. (<a
href="https://doi.org/10.1016/j.engappai.2023.106654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart energy performance monitoring and optimisation at the supplier and consumer levels is essential to realising smart cities. In order to implement a more sustainable energy management plan, it is crucial to conduct a better energy forecast. The next-generation smart meters can also be used to measure, record, and report energy consumption data, which can be used to train machine learning (ML) models for predicting energy needs. However, sharing energy consumption information to perform centralised learning may compromise data privacy and make it vulnerable to misuse, in addition to incurring high transmission overhead on communication resources. This study addresses these issues by utilising federated learning (FL), an emerging technique that performs ML model training at the user/substation level, where data resides. We introduce FedraTrees, a new, lightweight FL framework that benefits from the outstanding features of ensemble learning. Furthermore, we developed a delta-based FL stopping algorithm to monitor FL training and stop it when it does not need to continue. The simulation results demonstrate that FedraTrees outperforms the most popular federated averaging (FedAvg) framework and the baseline Persistence model for providing accurate energy forecasting patterns while taking only 2% of the computation time and 13% of the communication rounds compared to FedAvg, saving considerable amounts of computation and communication resources.},
  archive      = {J_EAAI},
  author       = {Mohammad Al-Quraan and Ahsan Khan and Anthony Centeno and Ahmed Zoha and Muhammad Ali Imran and Lina Mohjazi},
  doi          = {10.1016/j.engappai.2023.106654},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106654},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FedraTrees: A novel computation-communication efficient federated learning framework investigated in smart grids},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting secondary school student performance using a
double particle swarm optimization-based categorical boosting model.
<em>EAAI</em>, <em>124</em>, 106649. (<a
href="https://doi.org/10.1016/j.engappai.2023.106649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing the potential students who will fail the final exam at early stages is very challenging but important for the decision-makers in the educational institutions to take proper actions to prevent them from failure. To accurately predict the secondary school student performance, we propose a double particle swarm optimization (PSO)-based categorical boosting (P2CatBoost) model based on the demographic, school period grades, and social/school related features. Considering the machine learning models are sensitive to their hyper-parameter settings, we introduce the PSO to optimize the fitness function. In addition, the threshold of a standard binary classification task is 0.5, which might not be the optimal value in real-world applications. Thus, we optimize this threshold by the PSO. To evaluate the performance of our proposed model, two datasets downloaded from the University of California, Irvine Repository and the Kaggle, respectively, are used. The experimental results showed that our proposed P2CatBoost has the best performance in terms of all the metrics used. Our proposed P2CatBoost has the best accuracy of 96.62% and 94.45% for the final grade prediction of the Mathematics and Portuguese courses, respectively. In addition, our proposed model outperforms the other models under comparison from 4.5% to 8.3%. The statistical analyses verify that our P2CatBoost can significantly outperform the comparing models. These results confirm the effectiveness of our double PSO for improving the performance of student performance prediction, indicating our proposed model could be a useful tool in educational institutions to improve the quality of education.},
  archive      = {J_EAAI},
  author       = {Zongwen Fan and Jin Gou and Cheng Wang},
  doi          = {10.1016/j.engappai.2023.106649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting secondary school student performance using a double particle swarm optimization-based categorical boosting model},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic model-driven intelligent fault diagnosis method for
rotary vector reducers. <em>EAAI</em>, <em>124</em>, 106648. (<a
href="https://doi.org/10.1016/j.engappai.2023.106648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of faults in rotary vector (RV) reducers using machine data-driven artificial intelligence (AI) models plays an important role, but it is difficult to obtain complete fault sample labeled data. Without labeled data, AI-based intelligent fault diagnosis models will fail. To solve the problem of data scarcity, a lumped parameter model of an RV reducer is developed to produce a sufficient training sample for AI models. First, a lumped parameter model of the healthy RV reducer is constructed and updated by the Pearson correlation coefficient (PCC) technique to obtain an agreeable dynamic model with a certain precision. Then, mathematical expressions of numerous fault modes with different fault severities are inserted into the model to calculate the fault samples. The simulated failure samples serve as training samples of AI-based intelligent models. Finally, CNN, VGG and ResNet are selected as the representatives of AI model, and then unknown fault samples are identified by applying data from real-time machinery. The experimental results suggest that the present method can be used to overcome the problem of insufficient fault samples in RV reducers.},
  archive      = {J_EAAI},
  author       = {Junkang Zheng and Hui Wang and Anil Kumar and Jiawei Xiang},
  doi          = {10.1016/j.engappai.2023.106648},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106648},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic model-driven intelligent fault diagnosis method for rotary vector reducers},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature-based deep neural network approach for predicting
mortality risk in patients with COVID-19. <em>EAAI</em>, <em>124</em>,
106644. (<a
href="https://doi.org/10.1016/j.engappai.2023.106644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we integrate deep neural network (DNN) with hybrid approaches (feature selection and instance clustering) to build prediction models for predicting mortality risk in patients with COVID-19. Besides, we use cross-validation methods to evaluate the performance of these prediction models, including feature based DNN, cluster-based DNN, DNN, and neural network (multi-layer perceptron). The COVID-19 dataset with 12,020 instances and 10 cross-validation methods are used to evaluate the prediction models. The experimental results showed that the proposed feature based DNN model, holding Recall (98.62%), F1-score (91.99%), Accuracy (91.41%), and False Negative Rate (1.38%), outperforms than original prediction model (neural network) in the prediction performance. Furthermore, the proposed approach uses the Top 5 features to build a DNN prediction model with high prediction performance, exhibiting the well prediction as the model built by all features (57 features). The novelty of this study is that we integrate feature selection, instance clustering, and DNN techniques to improve prediction performance. Moreover, the proposed approach which is built with fewer features performs much better than the original prediction models in many metrics and can still remain high prediction performance.},
  archive      = {J_EAAI},
  author       = {Thing-Yuan Chang and Cheng-Kui Huang and Cheng-Hsiung Weng and Jing-Yuan Chen},
  doi          = {10.1016/j.engappai.2023.106644},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106644},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-based deep neural network approach for predicting mortality risk in patients with COVID-19},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review of artificial neural networks-contribution methods
integrated with structural equation modeling and multi-criteria decision
analysis for selection customization. <em>EAAI</em>, <em>124</em>,
106643. (<a
href="https://doi.org/10.1016/j.engappai.2023.106643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a review of literature on the usage of artificial neural networks (ANNs) architecture contribution method and structural equation modeling (SEM), and proposes a new selection process in the context of algorithm -based SEM-ANNs schemes. This study enriches academic literature by providing a review of all the main aspects of customization in ANNs and contribution methods in combination with SEM. Academic databases are examined for exhibition findings, yielding 253 papers published between 2016 and 2022. The retrieved papers are categorized according to inclusion criteria, and the final set of 73 articles are discussed based on two directions, namely, ‘Sector-based’ and ‘Algorithm-based’ as a new representation of taxonomy research. A state-of-the-art bibliographic analysis is presented. This review also identifies modern challenges and open issues in terms of multiple evaluation criteria, importance criteria, and data variations related to the selection of customizations in ANNs and contribution methods combined with SEM in different industrial cases. Several issues fall under multicriteria decision making for handling complexity problems in different ANNs and contribution methods. Thus, this study also presents a research proposal and recommends a solution based on a three-phase methodology for handling the selection and overcoming the identified issues, subsequently completing a strategic guideline solution.},
  archive      = {J_EAAI},
  author       = {A.A. Zaidan and Alhamzah Alnoor and O.S. Albahri and R.T. Mohammed and A.H. Alamoodi and A.S. Albahri and B.B. Zaidan and Salem Garfan and Hamsa Hameed and Mohammed S. Al-Samarraay and Ali Najm Jasim and R.Q. Malik},
  doi          = {10.1016/j.engappai.2023.106643},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106643},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review of artificial neural networks-contribution methods integrated with structural equation modeling and multi-criteria decision analysis for selection customization},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hyperbolic embedding steered spatiotemporal graph
convolutional network for video-based remote heart rate estimation.
<em>EAAI</em>, <em>124</em>, 106642. (<a
href="https://doi.org/10.1016/j.engappai.2023.106642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote heart rate estimation aims to predict cardiac activity signals from facial videos without any physical contact, which has been showing promising results recently. However, existing estimation methods based on deep convolutional networks only focus on the rigid receptive field, while ignoring potential spatial correlations of different facial regions, which obviously cannot reduce the overfitting caused by various noise and motion interference unrelated to cardiac activity. To address these issues, this paper proposes PhysGCN, an end-to-end spatiotemporal graph convolutional network with the hyperbolic embedding, to coordinate the contributions of intra- and inter-frame features of facial videos for long-term heart rate estimation. Specifically, firstly, we convert the facial video captured by the vision system into a graph-structure spatiotemporal map, and use the link set of the graph to determine and lock the spatial relative positions of multiple skin sub-regions formed by intra-frame face segmentation and projection. Secondly, to purify the signal and prevent the interference from heart rate irrelevant features, we integrate and measure the similarity between sub-regions within the graph in a non-Euclidean space by a hyperbolic embedding module, which can characterize the correlation more distinctly compared to the plane space. Finally, we dynamically and elaborately orchestrate the inherent temporal and learned spatial features in a graph convolutional module to obtain reliable heart rate waveforms. We conduct extensive comparative experiments and ablation studies on multiple public datasets to verify the superiority and robustness of our method. Experiments show that our method can effectively estimate heart rate from facial videos, and its performance surpasses or matches the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Hang Shao and Lei Luo and Shuo Chen and Chuanfei Hu and Jian Yang},
  doi          = {10.1016/j.engappai.2023.106642},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106642},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hyperbolic embedding steered spatiotemporal graph convolutional network for video-based remote heart rate estimation},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSN: Component supervised network for few-shot
classification. <em>EAAI</em>, <em>124</em>, 106640. (<a
href="https://doi.org/10.1016/j.engappai.2023.106640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The few-shot classification (FSC) task aims to classify data with limited labeled examples across different categories. Typically, researchers pre-train a feature extractor using base data and use it to extract features from novel data for classification Notably, the novel set only has a few annotated samples and has non-overlapped categories from the base set, which leads to the fact that the pre-trained feature extractor cannot adapt to the novel data flawlessly. We dub this problem as Feature-Extractor-Maladaptive (FEM) problem. Starting from the root cause of this problem, this paper presents a new scheme called Component Supervised Network (CSN), to improve the performance of FSC. We believe that even though the categories in the base and novel sets are different, their sample components share similarities. For example, both cats and dogs contain leg and head components. These entity components are intra-class stable and have cross-category versatility, making them useful for generalization to new categories. However, finding common information among different categories is difficult in real-world scenarios, hindering the possibility of modeling based on this assumption. To overcome this, we first design a Dictionary-based Implicit-Component Generator (DICG) to mine common information of different sets; then construct an implicit-component-based auxiliary task to improve the adaptability of the feature extractor. We evaluated our CSN on three benchmark datasets (mini-ImageNet, tiered-ImageNet, and FC100) and achieved improvements of at least 0.9% compared to classical methods, demonstrating the efficiency of our approach.},
  archive      = {J_EAAI},
  author       = {Rui Xu and Shuai Shao and Lei Xing and Yujun Wei and Weifeng Liu and Baodi Liu and Yanjiang Wang},
  doi          = {10.1016/j.engappai.2023.106640},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106640},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CSN: Component supervised network for few-shot classification},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing the device complexity for 3D human pose estimation:
A deep learning approach using monocular camera and IMUs. <em>EAAI</em>,
<em>124</em>, 106639. (<a
href="https://doi.org/10.1016/j.engappai.2023.106639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera and inertial measurement unit (IMU) based three-dimensional (3D) human pose estimation flourished in the last decade. However, existing methods are difficult to apply to clinical environments because of the many required devices. In this study, we attempt to reduce the devices and maintain their robustness. Occ-Corrector, a semantic convolution-based neural network, was proposed to estimate 3D human poses robustly in occlusion cases involving a single camera with the help of a few IMUs. It includes a simple Sensor-Reshape, which helps to fuse IMU information with the camera more effectively, and a new strategy of alternating the loss function, allowing the model to improve its accuracy in predicting challenging poses. By conducting an inverse analysis of the weight matrix, the importance of each IMU was investigated for device simplification purposes. The proposed method was verified by using the Total Capture dataset with two hypothetical occlusion conditions, and the result showed that only five IMUs can make the accuracy stable in different occlusion situations.},
  archive      = {J_EAAI},
  author       = {Changyu Zhao and Hirotaka Uchitomi and Taiki Ogata and Xianwen Ming and Yoshihiro Miyake},
  doi          = {10.1016/j.engappai.2023.106639},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106639},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reducing the device complexity for 3D human pose estimation: A deep learning approach using monocular camera and IMUs},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unauthorized access detection system to the equipments in a
room based on the persons identification by face recognition.
<em>EAAI</em>, <em>124</em>, 106637. (<a
href="https://doi.org/10.1016/j.engappai.2023.106637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition is a very active research topic due to the number of potential applications that use this technique and the number of challenges that still require efforts to solve them. However, new research problems arise when dealing with devices operating in real-time, and using a non-controlled image source such as surveillance cameras, due to the needs and context of end-use. A robust and efficient face recognition system is proposed in this paper to monitor unauthorized access to equipments in a room using a surveillance camera. The system is based on a person detection algorithm adapted to the context of use, a person tracking algorithm robust to occlusion, a face detection algorithm robust to orientation and scale, and a face recognition algorithm robust to illumination change. To enhance the efficiency of person identification, a novel strategy for estimating the confidence of face recognition is proposed in this paper. This is achieved by leveraging the general conditions of the image used for this purpose. This technique allows to increase the identification rate while minimizing the false alarm rate. An effort is also made to optimize the implementation of the developed algorithms to guarantee a real-time operation while keeping a very high efficiency. Also, the evaluations of the proposed algorithms on public and private data show an improvement of the accuracy on the whole context of use of the proposed system. Furthermore the evaluation of the system in general shows a high efficiency, 100% detection of unauthorized accesses and 0 false alarms.},
  archive      = {J_EAAI},
  author       = {Yahya Zennayi and Soukayna Benaissa and Hatim Derrouz and Zouhair Guennoun},
  doi          = {10.1016/j.engappai.2023.106637},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106637},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unauthorized access detection system to the equipments in a room based on the persons identification by face recognition},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty clustering internal validity assessment using
fréchet distance for unsupervised learning. <em>EAAI</em>, <em>124</em>,
106635. (<a
href="https://doi.org/10.1016/j.engappai.2023.106635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing the number of clusters a priori is one of the most challenging aspects of unsupervised learning. Clustering Internal Validity Indices (CIVIs) evaluate partitions in unsupervised algorithms based on metrics like compactness, separation, and density. However, specialized CIVIs for specific applications have been designed, and there is no general CIVI that works in all scenarios. The absence of CIVIs based on crisp uncertainty metrics is especially critical in decision-making processes that involve ambiguity, non-convex distributions, outliers, and overlapping data. To address this problem, we propose a novel Uncertainty Fréchet (UF) CIVI that assesses the certainty of a well-defined partition. UF leverages uncertainty fingerprints based on Type-2 fuzzy Gaussian Mixture Models (T2FGMM) and the Fréchet distance between clusters to introduce a metric that evaluates partition quality. We integrate UF into a merging methodology that combines similar clusters within a partition, allowing us to determine the number of clusters without the need to run the clustering algorithms iteratively as other CIVIs require. We undertake a comprehensive evaluation of our proposal on 5,250 convex, 36 non-convex synthetic datasets, and five benchmark real datasets. In addition, we apply UF in a real-world scenario that involves high uncertainty: Passive Acoustic Monitoring (PAM) of ecosystems, which aims to study ecological transformations through acoustic recordings. The results show that UF exhibits notable performance in synthetic and real-world scenarios, obtaining an Adjusted Mutual Information (AMI) score higher than 0.88 for normal, uniform, gamma, and triangular distribution datasets. In the PAM application, UF identifies the transformation of ecosystems through sound using clustering algorithms and UF, achieving an F1 score of 0.84. Therefore, results show that the UF index is a suitable tool for researchers and practitioners working with highly uncertain data.},
  archive      = {J_EAAI},
  author       = {Nestor Rendon and Jhony H. Giraldo and Thierry Bouwmans and Susana Rodríguez-Buritica and Edison Ramirez and Claudia Isaza},
  doi          = {10.1016/j.engappai.2023.106635},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106635},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty clustering internal validity assessment using fréchet distance for unsupervised learning},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DPCTN: Dual path context-aware transformer network for
medical image segmentation. <em>EAAI</em>, <em>124</em>, 106634. (<a
href="https://doi.org/10.1016/j.engappai.2023.106634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of lesions in medical images is a key step to assist clinicians in diagnosis and analysis. Most studies combine the Transformer model with CNN at a single scale or use the highest-level feature tensor extracted by CNN as input to Transformer without fully exploiting Transformer’s potential. In addition, for the problems of structural boundary blurring, heterogeneous textures, etc., in medical images, most existing methods pay attention to using contour information to solve this problem but simply fuse the contour information and ignore the potential relationship between the regions and the contours. We propose the DPCTN network based on the traditional encoding–decoding structure, consisting of the CNN, Transformer dual backbone networks and parallel attention mechanisms, to achieve accurate segmentation in medical image lesions. Local and global multiscale feature information is extracted by CNN and Transformer. The Transformer block of channel cross fusion can implement multiscale information fusion of the high-level local features and reduce the impact of the redundant information. The dual backbone feature fusion module effectively couples the local and global high-level feature information. The decoder refines and enriches the boundary and regional features, layer by layer, to achieve effective supervision of the boundary and region. Considering the possible dimension collapse in the attention mechanism, a novel three branch transposed self-attention module is designed to reduce the information loss caused by feature pooling. To verify the effectiveness of our proposed method, subjective and objective comparative experiments and ablation experiments were performed on four medical segmentation tasks, polyps, skin lesions, glands and breast tumors. A large number of experimental results show that our method is superior to the current state-of-the-art method, reduces the standard deviation and is more robust. Source code is released at https://github.com/sd-spf/DPCTN .},
  archive      = {J_EAAI},
  author       = {Pengfei Song and Zhe Yang and Jinjiang Li and Hui Fan},
  doi          = {10.1016/j.engappai.2023.106634},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106634},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DPCTN: Dual path context-aware transformer network for medical image segmentation},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WSAFormer-DFFN: A model for rotating machinery fault
diagnosis using 1D window-based multi-head self-attention and deep
feature fusion network. <em>EAAI</em>, <em>124</em>, 106633. (<a
href="https://doi.org/10.1016/j.engappai.2023.106633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is of great importance for rotating machinery maintenance. Deep learning is an intelligent diagnosis technology that attracts more attention at present. The ability to learn fault features of pure CNN and RNN models is limited due to inherent structural defects. Therefore, we build a fault diagnosis model (WSAFormer-DFFN) combining CNN and self-attention structure to enhance learning ability. Meanwhile, propose 1D window-based multi-head self-attention (1D W-MSA) for vibration signal and its representation to introduce local inductive bias, which improves the robustness of the model. A series of experiments on three rotating machinery datasets show that the proposed model has better recognition accuracy and less performance attenuation in interference conditions. On the bearing dataset of Case Western Reserve University, the accuracy rate increases by 21.29%–37.12% compared with several classic models when the signal-to-noise ratio is − 6 dB.},
  archive      = {J_EAAI},
  author       = {Qingzhe Wei and Xincheng Tian and Long Cui and Fuquan Zheng and Lida Liu},
  doi          = {10.1016/j.engappai.2023.106633},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106633},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WSAFormer-DFFN: A model for rotating machinery fault diagnosis using 1D window-based multi-head self-attention and deep feature fusion network},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable federated learning for machine condition
monitoring: Interpretable average global model as a fault feature
library. <em>EAAI</em>, <em>124</em>, 106632. (<a
href="https://doi.org/10.1016/j.engappai.2023.106632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is an emerging technique used to prevent the two contradictory problems of data silos and data privacy. Different from centralized learning, FL makes it possible to learn a global model while private data are stored locally. Nevertheless, statistical heterogeneity is a major challenge that has not been well addressed in literature and the interpretability of the model is always ignored. In this paper, an interpretable FL framework is constructed for machine condition monitoring and fault diagnosis. Since fault characteristic frequencies (FCFs) and their harmonics are closely connected with specific machine fault types, an interpretable local client model is designed to identify the FCFs and their harmonics of different clients. Theoretical investigation on the additivity of local model parameters in this paper prove that learned local parameters from the frequency domain are actually FCFs and their harmonics and their additivity is capable of constructing a fault feature library, which is beneficial to providing different fault information and quickly diagnosing fault types. The effectiveness of the method is demonstrated by experiments with two independent bearing run-to-failure datasets.},
  archive      = {J_EAAI},
  author       = {Xiao Feng and Dong Wang and Bingchang Hou and Tongtong Yan},
  doi          = {10.1016/j.engappai.2023.106632},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106632},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable federated learning for machine condition monitoring: Interpretable average global model as a fault feature library},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sustainable last mile parcel delivery and return service
using drones. <em>EAAI</em>, <em>124</em>, 106631. (<a
href="https://doi.org/10.1016/j.engappai.2023.106631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving last mile delivery, in terms of both efficiency and sustainability, has recently been enhanced using truck/drone tandems. However, nearly all these approaches focus only on deliveries, while returns are ignored. We propose a new model for integrating both delivery and returns in the combined operation of a truck and a drone, which we term the Flying Sidekick Traveling Salesman Problem integrating Deliveries and Returns with Multiple Payloads (FSTSP-DR-MP). This approach is more sustainable than truck-only deliveries as the drones operate through battery power with no emissions and can move more directly than vehicles along a road network. We formulate the problem as a mixed-integer linear program to minimize the total service time of the system, where the truck and the drone can perform both delivery and pickup of parcels during a single sortie. Because drones have a capacity of multiple parcels, each can visit more than one customer per dispatch, increasing drone utilization and responsiveness to customer expectations regarding return services, along with greater environmental improvements. Small-size cases are solved exactly using the MILP implemented in the CPLEX Python API. Since the MILP is not practical for realistically sized cases, we propose a meta-heuristic derived from Variable Neighborhood Search (VNS), which iteratively builds truck and drone routes. We show that this works well for up to 100 customers, a typical number in last-mile logistics. We assess the trade-offs between the ratio of returns to deliveries and drone capacity to provide managerial insights to the benefits of this approach for sustainable last mile logistics. Computational experiments show that integrating delivery and return truck-drone operations significantly reduces total service time and truck travel time compared to both traditional delivery schemes (single truck) and the well-known FSTSP drone schemes (one truck and one drone) up to 36.2% and 22.9%, respectively, by exploiting the nature of each customer (delivery or return) to increase the number of stops of each drone sortie. We also conduct a comparison with multiple drones have a single payload under similar scenarios. The results demonstrate that our model outperforms this alternative with an average improvement of 3.9% in total service time. Our approach addresses an important gap in the literature by accommodating returns, which are ubiquitous in last mile logistics, as well as providing for improved drone utilization, sustainability, and cost-effectiveness.},
  archive      = {J_EAAI},
  author       = {Nawin Yanpirat and Daniel F. Silva and Alice E. Smith},
  doi          = {10.1016/j.engappai.2023.106631},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106631},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sustainable last mile parcel delivery and return service using drones},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A local search-based non-dominated sorting genetic algorithm
for solving a multi-objective medical tourism trip design problem
considering the attractiveness of trips. <em>EAAI</em>, <em>124</em>,
106630. (<a
href="https://doi.org/10.1016/j.engappai.2023.106630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the medical tourism industry encourages many healthcare practitioners to provide high-quality and low-cost medical services for patients worldwide. The development of operations research models and algorithms is one important instrument for improving the medical tourism industry based on the economic, political, social, and cultural aspects. In this paper, a medical tourism trip design problem is developed where patients travel from their city of residence to a destination city that may be in another country to receive high-quality and low-cost medical care. The most important part of this problem is to visit a number of tourist cities for each patient individually in the destination. In addition to the total cost, the patients prefer to increase the attractiveness of trips by referring to the quality of medical services and the attractiveness of visiting tourist cities. As far as we know in the area of medical tourist studies, no study has considered the minimization of total cost and maximization of the attractiveness of trips, simultaneously using utility function. The proposed multi-objective optimization model assigns the patients from the origin country to the hospitals in the destination country while making their routing and scheduling decisions to visit the tourist cities. The proposed model is limited by patients’ interests and time restrictions while allocating patients to the hospital and orienteering the patients toward visiting tourist attractions. As a complex optimization problem, another significant novelty of this paper is the proposal of a local search-based non-dominated sorting genetic algorithm (LSNSGA-II) for solving the proposed multi-objective optimization model. The proposed algorithm is compared with the original non-dominated sorting genetic algorithm (NSGA-II) and epsilon constraint (EC) method based on different multi-objective criteria. Finally, one main finding from our analyses is finding a trade-off between the total cost and attractiveness of trips as a challenging decision while proposing high-quality solutions in a reasonable time (i.e., less than one hour).},
  archive      = {J_EAAI},
  author       = {Mansoureh Hasannia Kolaee and Seyed Mohammad Javad Mirzapour Al-e-Hashem and Armin Jabbarzadeh},
  doi          = {10.1016/j.engappai.2023.106630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A local search-based non-dominated sorting genetic algorithm for solving a multi-objective medical tourism trip design problem considering the attractiveness of trips},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-intrusive condition monitoring based on event detection
and functional data clustering. <em>EAAI</em>, <em>124</em>, 106625. (<a
href="https://doi.org/10.1016/j.engappai.2023.106625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing monitoring electricity consumption strategies in industrial environments provides improvements in both the maintenance process and energy efficiency. The contribution of this work is an industry-oriented non-intrusive load monitoring approach based on an unsupervised algorithm, encompassing a method of event detection, functional data clustering, and condition monitoring. With this method, multiple devices can be monitored by only one electric meter in industrial environments, enhancing the early detection of anomalies and energy inefficiencies. The proposed approach presents a robust event detection to deal with different industrial contexts due to its intuitive parameters, which allows adapting the detection to be more sensitive or to filter out higher noise variations. Unlike other feature-based clusterings, the proposed functional data clustering enables high-precision identification of transient state patterns, characterizing specific shapes for each pattern to properly cluster them, and provides higher reliability during load detection. Thus, this load detection segments the power consumption to extract transient states and identify which load acts on each event based on functional data clusters. By detecting when loads start to consume, the proposed energy disaggregation extracts the frequency spectrum of each device from the aggregate current consumption, which is used in a condition monitoring strategy to track the spectrum behavior of each device. In this way, the condition of multiple loads can be monitored using a single electric meter, whose information can be relevant to accurately schedule maintenance interventions and detect anomalies or inefficiencies early. The proposed approach was validated in three industrial contexts: The load detection accuracy was verified in an industrial testbed, giving a precision higher than 99% for monitoring five devices. The second and third industrial scenarios validate the accuracy of the proposed condition monitoring method. The last scenario was carried out at Bilbao airport to track the condition of multiple conveyor belts of a baggage handling system located at check-in. As a result, the degradation trend of three sets of conveyor belts was monitored.},
  archive      = {J_EAAI},
  author       = {Miguel Angel Bermeo-Ayerbe and Carlos Ocampo-Martinez and Javier Diaz-Rozo},
  doi          = {10.1016/j.engappai.2023.106625},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106625},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-intrusive condition monitoring based on event detection and functional data clustering},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lazy FSCA for unsupervised variable selection.
<em>EAAI</em>, <em>124</em>, 106624. (<a
href="https://doi.org/10.1016/j.engappai.2023.106624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various unsupervised greedy selection methods have been proposed as computationally tractable approximations to the NP-hard subset selection problem. These methods rely on sequentially selecting the variables that best improve performance with respect to a selection criterion. Theoretical results exist that provide performance bounds and enable ‘lazy greedy’ efficient implementations for selection criteria that satisfy a diminishing returns property known as submodularity. Recently, the authors introduced Forward Selection Component Analysis (FSCA) which uses variance explained as its selection criterion. While variance explained is not a submodular criterion, FSCA has been shown to be highly effective for applications such as measurement plan optimization. Motivated by the desire to achieve a more computationally efficient and scalable algorithm implementation, in this paper a ‘lazy’ implementation of FSCA (L-FSCA) is proposed, which, although not equivalent to FSCA due to the absence of submodularity, has the potential to yield comparable performance while being up to an order of magnitude faster to compute. The efficacy of L-FSCA is demonstrated by performing a systematic comparison with FSCA and five other unsupervised variable selection methods from the literature using simulated and real-world case studies. Experimental results confirm that L-FSCA yields almost identical performance to FSCA while reducing computation time by between 22% and 94% for the case studies considered.},
  archive      = {J_EAAI},
  author       = {Federico Zocco and Marco Maggipinto and Gian Antonio Susto and Seán McLoone},
  doi          = {10.1016/j.engappai.2023.106624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lazy FSCA for unsupervised variable selection},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-spatio-temporal fusion graph recurrent network for
traffic forecasting. <em>EAAI</em>, <em>124</em>, 106615. (<a
href="https://doi.org/10.1016/j.engappai.2023.106615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting is crucial for smart city development in the new era. However, the intricate spatial and temporal dependencies in traffic data present significant challenges for prediction accuracy. Existing methods often rely on predefined adjacency matrices to capture Spatio-temporal dependencies, which may not adapt well to the dynamic nature of road traffic. To address these challenges, we propose the Multi-Spatio-temporal Fusion Graph Recurrent Network (MSTFGRN). This innovative approach introduces a data-driven method for generating a weighted adjacency matrix, effectively capturing real-time spatial dependencies that are not adequately captured by predefined matrices. The MSTFGRN also incorporates a novel two-way Spatio-temporal fusion operation to learn hidden dependencies between parallel Spatio-temporal relations at different time points. Additionally, a global attention mechanism is integrated into the Spatio-temporal fusion module, enabling the simultaneous capture of global Spatio-temporal dependencies. Through extensive trials on publicly available highway traffic datasets, our method demonstrates state-of-the-art performance compared to alternative baselines.},
  archive      = {J_EAAI},
  author       = {Wei Zhao and Shiqi Zhang and Bing Zhou and Bei Wang},
  doi          = {10.1016/j.engappai.2023.106615},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106615},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-spatio-temporal fusion graph recurrent network for traffic forecasting},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-sensor information fusion and coordinate
attention-based fault diagnosis method and its interpretability
research. <em>EAAI</em>, <em>124</em>, 106614. (<a
href="https://doi.org/10.1016/j.engappai.2023.106614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is always challenging and meaningful to further enhance the feature extraction capability of the convolutional neural network (CNN) and understand the internal working principle of CNN. In order to ensure that CNN focuses on more key information in the one-dimensional signal and reduces the attention to other information, a novel CNN network architecture based on the fusion of multi-sensor information and coordinated attention (CA) is proposed and applied to fault diagnosis of rolling bearings. Further, we studied the interpretability of the proposed network and intuitively revealed the feature learning process and final expression form of the proposed network. First, a coordinated attention (CA) module suitable for one-dimensional vibration signals is proposed, and a lightweight coordinated attention convolution neural network model ACNN is established. Secondly, a kurtosis-weighted fusion strategy is designed to enhance the shock feature of the sensor channels. Then, based on ACNN and weighting fusion strategy, a fusion framework for multi-sensor information (Multi-sensor ACNN) is constructed. Finally, based on the Multi-sensor ACNN, a new rolling bearing fault diagnosis method is proposed.},
  archive      = {J_EAAI},
  author       = {Jinyu Tong and Cang Liu and Jinde Zheng and Haiyang Pan},
  doi          = {10.1016/j.engappai.2023.106614},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106614},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-sensor information fusion and coordinate attention-based fault diagnosis method and its interpretability research},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal navigation for AGVs: A soft actor–critic-based
reinforcement learning approach with composite auxiliary rewards.
<em>EAAI</em>, <em>124</em>, 106613. (<a
href="https://doi.org/10.1016/j.engappai.2023.106613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of real-time navigation and obstacle avoidance for automated guided vehicles (AGVs) in dynamic environments, which is a primary research area in collaborative control systems for AGVs. To overcome the computational inefficiency of recalculating optimal paths every time, we propose an improved Soft Actor–Critic (SAC)-based reinforcement learning methodology. This methodology utilizes a novel composite auxiliary reward structure and sum-tree prioritized experience replay (SAC-SP) to achieve real-time optimal feedback control. First, we formulate the navigation task as a Markov Decision Process that considers both static and dynamic obstacles. To accelerate the active learning of AGVs, we propose a novel strategy that uses composite auxiliary rewards. Next, we train the AGVs using the proposed SAC-SP methodology to handle real-time navigation with the composite auxiliary reward structure. The well-trained policy network can generate effective on-board optimal feedback actions given obstacle positions, targets, and AGV states. Simulation experiments demonstrate that our proposed method can steer AGVs to the destination with high robustness to original conditions and various obstacle restrictions, generating optimal feedback actions in the shortest amount of time.},
  archive      = {J_EAAI},
  author       = {Haisen Guo and Zhigang Ren and Jialun Lai and Zongze Wu and Shengli Xie},
  doi          = {10.1016/j.engappai.2023.106613},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106613},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal navigation for AGVs: A soft actor–critic-based reinforcement learning approach with composite auxiliary rewards},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-referenced low-light image enhancement with adaptive
filter network. <em>EAAI</em>, <em>124</em>, 106611. (<a
href="https://doi.org/10.1016/j.engappai.2023.106611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current strive toward efficient intelligent visual systems suffers from challenges in the task of low-light image enhancement. To improve image perception, the low-light scenes in different illumination conditions must be properly focused. However, typical CNN-based methods use the same set of parameters for all images, which limits the capability for handling complex scenes. Meanwhile, the existing deep models integrate the low-level and high-level features by simply adding or concatenating operations, lacking unique designs for the low-light image enhancement task. To address the above challenges, we propose a zero-referenced adaptive filter network (ZAFN) for low-light image enhancement. Specifically, the adaptive filters are generated by the integration of high-level contents from multiple partial scenes. The iterative enlightening process is then conducted using the low-level features that are dynamically modulated with the adaptive filters. To alleviate the requirement of paired training data and enable zero-referenced learning, we propose a color enhancement loss, a global consistency loss, and a self-regularized denoising loss for high-quality results. Our ZAFN model, which has a light model size and low computational cost, outperforms other state-of-the-art zero-referenced methods on four popular datasets.},
  archive      = {J_EAAI},
  author       = {Yuezhou Li and Yuzhen Niu and Rui Xu and Yuzhong Chen},
  doi          = {10.1016/j.engappai.2023.106611},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106611},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-referenced low-light image enhancement with adaptive filter network},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-label continual learning framework to scale deep
learning approaches for packaging equipment monitoring. <em>EAAI</em>,
<em>124</em>, 106610. (<a
href="https://doi.org/10.1016/j.engappai.2023.106610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Learning aims to learn from a stream of tasks, being able to remember at the same time both new and old tasks. We propose a scenario that holds immense appeal for various real-world applications, where a model adapts to handle a stream of machines with distribution shifts Tests on real packaging data proved the feasibility of Continual Learning for addressing such problems. Our study uncovers the limitations of previous algorithms in the Domain Incremental Learning. Our research presents a novel approach for tackling multi-label tasks in Continual Learning, achieving superior performance compared to existing approaches found in the literature. Our method not only achieves optimal performance but also has logarithmic complexity, significantly reducing computation times.},
  archive      = {J_EAAI},
  author       = {Davide Dalle Pezze and Denis Deronjic and Chiara Masiero and Diego Tosato and Alessandro Beghi and Gian Antonio Susto},
  doi          = {10.1016/j.engappai.2023.106610},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106610},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-label continual learning framework to scale deep learning approaches for packaging equipment monitoring},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A methodology for urban planning generation: A novel
approach based on generative design. <em>EAAI</em>, <em>124</em>,
106609. (<a
href="https://doi.org/10.1016/j.engappai.2023.106609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction sector is undergoing a digital transformation that aims to increase productivity, improve processes and take advantage of the new advances in digitalization. Urban planning is particularly susceptible of benefiting from these advances due to its complexity and the large amount of data and disciplines that come together. In this paper, we propose a novel methodology that aims to enhance current urban planning design methods, which are mainly designed by a planner, to an optimized process where the planner interacts with a software that automates many of the tasks. This methodology based on generative design principles, develop urban design solutions by subdividing a given plot and assigning different housing typologies on it. Our proposed software requires 3D urban models datasets as a reference to create solutions within a specific shape, style, proportions, among others, as well as input from the planner to guide the program according to project requirements and existing local norms. Higher automation in the design process eases project changes and allows for more and varied design testing, which in the end, contributes to better analysis and decision making. We tested our proposal in a case study in the city of Vienna to illustrate the design process, obtain several urban planning solutions and validate our methodology.},
  archive      = {J_EAAI},
  author       = {Ignacio Pérez-Martínez and María Martínez-Rojas and Jose Manuel Soto-Hidalgo},
  doi          = {10.1016/j.engappai.2023.106609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A methodology for urban planning generation: A novel approach based on generative design},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-scale mobile users deployment optimization based on a
two-stage hybrid global HS-DE algorithm in multi-UAV-enabled mobile edge
computing. <em>EAAI</em>, <em>124</em>, 106608. (<a
href="https://doi.org/10.1016/j.engappai.2023.106608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-UAV (unmanned aerial vehicle)-supported mobile edge computing system deploys multiple UAVs as flight edge clouds for large-scale users. In this system, how to optimize the deployment of UAVs is important for providing good service for all mobile users. Specifically, for each mobile user, we need to determine whether the task can be performed locally or on the drone (i.e., the unload decision) and how much resources should be allocated. In this paper, a new two-level optimization method is proposed for UAV deployment and task scheduling problem to minimize the system energy consumption. The proposed algorithm is named TSHGHSDE algorithm, in which a few features are designed to enhance the algorithm performance. Firstly, a two-stage optimization strategy is proposed based on HS-DE algorithm. In the early stage, HS algorithm is used for the local search in a limited space, and the DE algorithm is employed for the global search in the late stage. Secondly, we design an effective control parameter to adjust the search process, which aims to effectively combine the local search ability of HS algorithm and the global search ability of DE algorithm. Thirdly, a novel encoding mechanism is proposed in the process of the UAV deployment optimization. A global search strategy is designed to enhance the performance of the proposed algorithm. To assess the performance of the proposed algorithm, some well-known algorithms are used for comparison in experiments. The results demonstrate that the proposed algorithm performs better in terms of the search efficiency, search accuracy and stability.},
  archive      = {J_EAAI},
  author       = {Haibin Ouyang and Kang Liu and Chunliang Zhang and Steven Li and Liqun Gao},
  doi          = {10.1016/j.engappai.2023.106608},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106608},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Large-scale mobile users deployment optimization based on a two-stage hybrid global HS-DE algorithm in multi-UAV-enabled mobile edge computing},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GENEvaRX: A novel AI-driven method and web tool can identify
critical genes and effective drugs for lichen planus. <em>EAAI</em>,
<em>124</em>, 106607. (<a
href="https://doi.org/10.1016/j.engappai.2023.106607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lichen planus (LP) is an autoimmune disorder diagnosed based on physical symptoms and lab tests. Examples of symptoms include flat bumps, and itchy and purplish skin while lab tests include a shave biopsy of the lesion. When the pathology report shows consistency with LP and is negative for potential triggers for an allergy test and hepatitis C, a dermatologist typically prescribes corticosteroid in the form of pills or injection into the lesion to treat the symptoms. To understand the molecular mechanism of the disease and thereby overcome issues associated with disease treatment, there is a need to identify potential effective drugs, drug targets, and therapeutic targets associated the LP. Hence, we propose a novel computational framework based on new constrained optimization to support vector machines coupled with enrichment analysis. First, we downloaded three gene expression datasets ( GSE63741 , GSE193351 , GSE52130 ) pertaining to healthy and LP patients from the gene expression omnibus (GEO) database. We then processed each dataset and entered it into our computational framework to select important genes. Finally, we performed enrichment analysis of selected genes, reporting the following results. Our methods outperformed baseline methods in terms of identifying disease and skin tissue. Moreover, we report 5 drugs (including, dexamethasone, retinoic acid, and quercetin), 45 unique genes (including PSMB8, KRT31, KRT16, KRT19, KRT17, COL3A1, LCE2D, LCE2A), and 23 unique TFs (including NFKB1, STAT1, STAT3), reportedly related to LP pathogenesis, treatments, and therapeutic targets. Our methods are publicly available in the GENEvaRX web server at https://aibio.shinyapps.io/GENEvaRX/ .},
  archive      = {J_EAAI},
  author       = {Turki Turki and Y-h. Taguchi},
  doi          = {10.1016/j.engappai.2023.106607},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106607},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GENEvaRX: A novel AI-driven method and web tool can identify critical genes and effective drugs for lichen planus},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convolutional sparse filter with data and mechanism fusion:
A few-shot fault diagnosis method for power transformer. <em>EAAI</em>,
<em>124</em>, 106606. (<a
href="https://doi.org/10.1016/j.engappai.2023.106606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In actual industrial scenarios, fault data is rare and fault labels are difficult to obtain, which brings many obstacles for fault diagnosis. For this situation, this research proposes a novel semi-supervised convolutional sparse filter with local mechanism similarity regularization (CSF-LMSR) to construct a more reliable few-shot diagnosis method for power transformer. First, a sparse filter with local mechanism similarity regularization term (SF-LMSR) is designed as a more interpretable unsupervised feature extractor with prior knowledge. This unsupervised process enables the model to extract satisfactory features from the whole dataset even with a lower proportion of labeled data. Second, SF-LMSR is combined with convolutional neural network (CNN) by a novel coupling mode of kernel replacement, which enhances the learning ability of CNN. This classification model still adopts supervised learning training, but the demand for labeled fault data is greatly reduced, which reduces the burden of labels. The effectiveness of the proposed method is verified using real power transformer dissolved gas analysis (DGA) datasets. It can be seen from experimental results that the proposed method does provide a new perspective for transformer fault diagnosis, and it is a successful attempt for the power industry few-shot diagnosis problem.},
  archive      = {J_EAAI},
  author       = {Jia Qin and Dongsheng Yang and Nan Wang and Xueqing Ni},
  doi          = {10.1016/j.engappai.2023.106606},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106606},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Convolutional sparse filter with data and mechanism fusion: A few-shot fault diagnosis method for power transformer},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-training convolutional autoencoder for consumer
characteristics identification with imbalance datasets. <em>EAAI</em>,
<em>124</em>, 106605. (<a
href="https://doi.org/10.1016/j.engappai.2023.106605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer characteristics can help energy utilities implement efficient demand response programs and personalized services. However, there are two problems in obtaining consumer characteristics from smart meter data: label scarcity and class imbalance. The two problems greatly reduce the effectiveness of the existing supervised learning classifiers. Therefore, this paper proposes a self-training convolutional autoencoder (STCAE) framework for consumer characteristics identification with imbalance datasets. STCAE has three modules including encoder, decoder, and classifier. For the label scarcity problem, a seasonal pretext is designed to enable learning unlabeled samples through encoder–decoder structure of STCAE. For the class imbalance problem, a piecewise synthetic minority over-sampling technique (PSMOTE) method is designed for class rebalancing. Case studies and comparison studies demonstrate the validity of each major component and the superiority of STCAE over existing methods. In comparison studies of twelve consumer characteristics identification, the average improvements of accuracy and Matthews correlation coefficient are higher than 6.32% and 35.18%, respectively. Furthermore, in the ablation studies, STCAE performs better than the framework with different components in most consumer characteristics.},
  archive      = {J_EAAI},
  author       = {Hongliang Fang and Jiang-Wen Xiao and Yan-Wu Wang},
  doi          = {10.1016/j.engappai.2023.106605},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106605},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-training convolutional autoencoder for consumer characteristics identification with imbalance datasets},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Driver vigilance detection based on deep learning with fused
thermal image information for public transportation. <em>EAAI</em>,
<em>124</em>, 106604. (<a
href="https://doi.org/10.1016/j.engappai.2023.106604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous-rail Rapid Transit (ART) is a new type of road public transportation with an automatic driving function, and it is one of the main places for epidemic spread. Scientific wearing of masks has been proven to be an extremely effective way to prevent an epidemic. However, drivers wearing masks make it difficult for traditional driver alert detection methods based on facial information to operate effectively. This paper proposes an ART driver alert detection system based on multimodal information fusion and deep learning, which can be applied to drivers wearing masks. The detection system is mainly divided into three modules: data acquisition module, preprocessing module, and vigilance detection module. The data acquisition module collects real-time face thermal imaging data, and environment temperature information of 13 people in the vigilance and fatigue state of the ART simulated driving environment. The preprocessing module proposes a face thermal imaging key information extraction method based on the constraints between Yolov5 and thermal image interframe constraints and extracts the mean temperature information and the hot voxel information (HV) of the eyes, forehead, and mask areas. Then the extracted information and the environment temperature information are transmitted together to the vigilance detection module for learning and classification. The vigilance detection module proposes a lightweight hybrid-attention optimization network, and this paper extracts training sets and testing sets from the data of 13 subjects. And the training set data is enhanced. Each sample is 90 frames. The maximum accuracy rate of the testing set reaches 99.57%. The feasibility of the detection system proposed in this paper is proved, which makes the thermal imaging and attention model show great potential in the application of traffic safety operation and maintenance.},
  archive      = {J_EAAI},
  author       = {Zijie Zhou and Zheng Fang and Jirui Wang and Jiangfan Chen and Haobo Li and Lei Han and Zutao Zhang},
  doi          = {10.1016/j.engappai.2023.106604},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106604},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Driver vigilance detection based on deep learning with fused thermal image information for public transportation},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interval-valued fermatean fuzzy heronian mean operator-based
decision-making method for urban climate change policy for
transportation activities. <em>EAAI</em>, <em>124</em>, 106603. (<a
href="https://doi.org/10.1016/j.engappai.2023.106603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change affects the world. Due to excessive GHG emissions, urban transportation contributes to this threat. Policymakers and authorities want to reduce transportation-related GHG emissions. An imaginary urban area with high transportation-related greenhouse gas emissions, dense, interconnected transportation modes, and a high population density is considered. Istanbul, Turkey meets the criteria of this imaginary place, so the case analysis considers this city. Istanbul’s decision-makers are looking for effective strategies to prioritize urban climate change policy alternatives for transportation activities. Four alternative strategies and 13 criteria are presented in this context. Innovative multi-criteria decision-making (MCDM) method with the interval-valued Fermatean fuzzy sets (IVFFSs) strategies is proposed for advantage-prioritization so decision-makers can select the most effective strategies for policies. Utilizing the IVFFSs, the proposed method effectively tackles the qualitative/quantitative data and uncertain information that occurs in realistic applications. In this study, firstly IVFF-heronian mean operators with their desirable characteristics are presented to aggregate the IVFF information. The proposed operators can overcome the drawbacks of existing IVFF information-based operators by considering the relationships between IVFF numbers. Based on IVFF heronian mean operators, a hybrid decision-making framework is proposed by integrating criteria importance through inter-criteria correlation (CRITIC), rank sum (RS), and the double normalization-based multi-aggregation (DNMA) methods with IVFF information. In this method, the CRITIC and RS methods are implemented to derive the objective and subjective weights of the considered evaluation criteria and DNMA is applied to prioritize urban climate change policy alternatives for transportation activities. Sensitivity and comparative analyses with existing studies confirm the proposed framework. The evaluation results show that the integration of transportation sectors, strategies, and innovations across different urban areas in all regions option has the highest overall utility degree (0.731) among a set of four urban climate change policy alternatives for transportation activities.},
  archive      = {J_EAAI},
  author       = {Arunodaya Raj Mishra and Pratibha Rani and Muhammet Deveci and Ilgin Gokasar and Dragan Pamucar and Kannan Govindan},
  doi          = {10.1016/j.engappai.2023.106603},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106603},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interval-valued fermatean fuzzy heronian mean operator-based decision-making method for urban climate change policy for transportation activities},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing group-oriented multiple attribute decision-making
method based on dominance-based rough set model with advantaged
(disadvantaged) neighborhoods. <em>EAAI</em>, <em>124</em>, 106602. (<a
href="https://doi.org/10.1016/j.engappai.2023.106602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prominence of multi-attribute decision-making methods in the problem of intra-group interaction and inconsistency of ranking results in the problem of program group evaluation and ranking, group-based evaluation and ranking are receiving active attention. Although the group-oriented multi-attribute decision-making based on mixed advantage–disadvantage degree (GOMADMMADD) method innovatively proposes the idea of evaluating and ranking the group as a whole, there is an exponential explosion of the number of groups to be evaluated. Aiming at the above problems, this paper improves and optimizes the GOMADMMADD method. Firstly, this paper designs the advantaged neighborhood operator and disadvantaged neighborhood operator of the group from the perspective of the advantage relationship and disadvantage relationship between the data objects, designs the advantage–disadvantage neighborhood degree (ADND) according to the neighborhood operator, and studies the related properties. Secondly, based on ADND, a group-oriented multi-attribute decision-making method based on dominance-based rough set (GMADMDRS) is designed and optimized by using the properties of ADND. Thirdly, in the experiments of numerical examples, the experimental results of multiple traditional MADM methods show that GMADMDRS is reasonable. By comparing the experimental results of GMADMDRS before and after optimization on numerical examples, it is shown that the optimized GMADMDRS is consistent in the experimental results, and the time performance is greatly improved. Finally, the effectiveness of the optimized GMADMDRS method is verified on the UCI real dataset. The experimental results show that the GMADMDRS proposed in this paper can effectively deal with the problem of intra-group interaction and inconsistent ranking results in group-oriented evaluation and ranking, which has theoretical significance; it has practical significance for solving the exponential explosion of the number of groups to be evaluated. GMADMDRS provides a novel perspective and efficient method for multi-attribute decision-making problems.},
  archive      = {J_EAAI},
  author       = {Bin Yu and Ruihui Xu and Zeshui Xu and Jianhua Dai},
  doi          = {10.1016/j.engappai.2023.106602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing group-oriented multiple attribute decision-making method based on dominance-based rough set model with advantaged (disadvantaged) neighborhoods},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kernel general loss algorithm based on evolving
participatory learning for online time series prediction. <em>EAAI</em>,
<em>124</em>, 106600. (<a
href="https://doi.org/10.1016/j.engappai.2023.106600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a dynamic model for online time series prediction is proposed, namely kernel general loss algorithm based on evolving participatory learning (EPL-KGLA). The algorithm can develop its structure and parameters autonomously in response to complex environments, capturing the dynamic changes of time series and achieving accurate prediction. Specifically, EPL based on evolving fuzzy systems is employed in recursive clustering to fully utilize useful information in data streams and generate/prune structures to ensure compactness and reduce computational burden. Then, the general loss function is combined with online kernel learning to propose KGLA for updating consequent parameters in real-time, capturing the dynamic features of data streams and avoiding the negative effects of large anomalies or complex noise on model performance, thereby improving prediction accuracy. Finally, simulation experiments on a benchmark dataset and two real-world datasets are verified the robustness of EPL-KGLA.},
  archive      = {J_EAAI},
  author       = {Min Han and Huijuan Xia and Weijie Ren},
  doi          = {10.1016/j.engappai.2023.106600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Kernel general loss algorithm based on evolving participatory learning for online time series prediction},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Doctor selection based on aspect-based sentiment analysis
and neutrosophic TOPSIS method. <em>EAAI</em>, <em>124</em>, 106599. (<a
href="https://doi.org/10.1016/j.engappai.2023.106599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Physician-rating sites have become a convenient platform for patients to choose doctors. However, selecting an appropriate doctor through numerous online reviews is challengeable for patients. Although studies show that patients have different preferences for the aspects of healthcare services, existing doctor ranking methods rarely consider such preference information. Besides, they seldom handle the neutral sentiment information in patient reviews. Methods: To better assist patients in doctor selection, we propose a novel decision-making method that combines aspect-based sentiment analysis, single-valued neutrosophic sets and an extended Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method. The method utilizes Word2Vec to construct a feature dictionary of patient satisfaction. A rule-based approach is employed to extract the aspects and the related sentiments from patients’ text reviews. Moreover, it takes advantage of single-valued neutrosophic sets to address the positive, neutral and negative sentiment information. On this basis, we rank the doctors with an extended TOPSIS method considering the patient’s attitudinal character and the preference information. Results: A case study on a review dataset demonstrates the stability and flexibility of the method. The comparative analysis reveals that our method can efficiently reduce information loss and it is more practical than existing methods. Conclusion: Considering patients’ different preferences for the aspects of healthcare services, the method can better provide healthcare decision support for patients.},
  archive      = {J_EAAI},
  author       = {Xihua Li and Yun Luo and Hui Wang and Jiong Lin and Bin Deng},
  doi          = {10.1016/j.engappai.2023.106599},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106599},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Doctor selection based on aspect-based sentiment analysis and neutrosophic TOPSIS method},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep time–frequency learning for interpretable weak signal
enhancement of rotating machineries. <em>EAAI</em>, <em>124</em>,
106598. (<a
href="https://doi.org/10.1016/j.engappai.2023.106598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery generates periodic impulses when weak faults occur, but the fault resonant bands (FRB) which contains rich fault information is usually seriously contaminated by random interference and background noise. With the development of deep learning (DL), the existing signal enhancement methods based on DL have the property of ”black box”, i.e., limited interpretability, by which the fault components with clear physical meaning (CPM) cannot be extracted. Aiming at the aforementioned problems, an interpretable weak signal enhancement method based on deep time–frequency learning (DTFL) is proposed. Firstly, a series of simulated template signals of different resonant bands with CPM are constructed as training samples for DTFL, besides, a resonant band time–frequency ratio mask with CPM is generated as the training target by using the time–frequency representations (TFR) of pure and noise-added simulated template signals to construct a non-linear mapping relationship between the TFR of simulated template signals and resonant bands, thereby to achieve accurate enhancement of FRB and credible mask suppression of background noise interference. Therefore, the time–frequency ratio mask with CPM obtained from the DTFL model can be adapted to enhance the FRB, which enables the results of the enhanced FRB to be interpretable, thereby the constructed DTFL model is interpretable. The DTFL method overcomes the problem that the existing signal enhancement methods rely heavily on expert experience, which can provide a CPM of the FRB to support the diagnosis of weak faults in rotating machineries.},
  archive      = {J_EAAI},
  author       = {Jiakai Ding and Yi Wang and Yi Qin and Baoping Tang},
  doi          = {10.1016/j.engappai.2023.106598},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106598},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep time–frequency learning for interpretable weak signal enhancement of rotating machineries},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time anomaly detection on time series of industrial
furnaces: A comparison of autoencoder architectures. <em>EAAI</em>,
<em>124</em>, 106597. (<a
href="https://doi.org/10.1016/j.engappai.2023.106597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in industrial environments aims at detecting anomalies in the monitoring data of industrial machinery or equipment, as soon as possible, preferably presenting real-time alarms, to alert the monitoring staff and start maintenance activities timely. In this paper, the problem of anomaly detection of an industrial furnace is tackled, for the real-time recognition of punctual anomalies on multivariate time series. To this aim, a real-time anomaly detection approach is proposed: first, time series acquired from the real machinery are filtered, to select those of interest for possible anomalies, and pre-processed, to obtain sliding windows for real-time detection, then distinct univariate models are applied, to identify different anomaly types. For the application considered here, data regarding the machinery behaviour were available only for normal functioning, thus an unsupervised approach is chosen. In particular, deep learning models based on autoencoders are used to detect punctual anomalies, by reconstructing each window and evaluating the reconstruction error of its last point. An extensive set of autoencoder models is proposed, with varying architecture in terms of type of model (vanilla/variational autoencoders), type of layers (fully connected/LSTM/BiLSTM), and hyperparameters (number of layers, intermediate sizes, BiLSTM type). Available data are split, and used to train the models, and to test them on the normal signal and on synthetic anomalies injected on it, which are of particular interest and were designed according to domain experts. Performances of the proposed models show differences among them, depending on the model architecture. The most efficient models, in terms of F1 score of detection and number of parameters, are identified by their t-test comparison, and the capability of detecting anomalies online is demonstrated. In particular, the proposed anomaly detection approach, including a selected autoencoder with LSTM layers, is able to correctly recognize normal trends, with very few false positives, and promptly give alarms as different anomalous trends appear.},
  archive      = {J_EAAI},
  author       = {Marco Pota and Giuseppe De Pietro and Massimo Esposito},
  doi          = {10.1016/j.engappai.2023.106597},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106597},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time anomaly detection on time series of industrial furnaces: A comparison of autoencoder architectures},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of generative and non-generative adversarial attack
on context-rich images. <em>EAAI</em>, <em>124</em>, 106595. (<a
href="https://doi.org/10.1016/j.engappai.2023.106595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this fast-moving digital era, millions of images are added to repositories every millisecond. These images are context-rich images with ample underlying data that are extracted and analyzed by deep neural networks for innumerable research purposes. Significant breakthroughs in deep neural networks are harvesting multi-fold benefits and reaching higher accuracy and prediction rates. Though there is vertical progress in deep learning models there is always a threat to security which disintegrates the strength of deep neural networks. Archived images that an adversary manipulates will still look indistinguishable to the user. Such manipulations called adversarial attacks that trick deep learning models into making wrong predictions are on the rise nowadays. This paper reviews the varied types of adversarial attacks shedding light on their origin, their progressive advancement in multidimensions, along with their applications and challenges.},
  archive      = {J_EAAI},
  author       = {Hamil Stanly and Mercy Shalinie S. and Riji Paul},
  doi          = {10.1016/j.engappai.2023.106595},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106595},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of generative and non-generative adversarial attack on context-rich images},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Black-box attack against GAN-generated image detector with
contrastive perturbation. <em>EAAI</em>, <em>124</em>, 106594. (<a
href="https://doi.org/10.1016/j.engappai.2023.106594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of visually realistic GAN-generated facial images has raised concerns regarding potential misuse. In response, effective forensic algorithms have been developed to detect such synthetic images in recent years. However, the vulnerability of such forensic detectors to adversarial attacks remains an important issue that requires further investigation. In this paper, we propose a new black-box attack method against GAN-generated image detectors. It involves contrastive learning strategy to train an encoder–decoder anti-forensic network with a contrastive loss function. GAN-generated and corresponding simulated real images are constructed as positive and negative samples, respectively. By leveraging the trained attack model, we can apply imperceptible perturbation to input synthetic images for removing GAN fingerprint to some extent. GAN-generated image detectors may be deceived consequently. Extensive experimental results demonstrate that the proposed attack effectively reduces the accuracy of three state-of-the-art detectors on six popular GANs, while also achieving high visual quality of the attacked images. The source code will be available at https://github.com/ZXMMD/BAttGAND .},
  archive      = {J_EAAI},
  author       = {Zijie Lou and Gang Cao and Man Lin},
  doi          = {10.1016/j.engappai.2023.106594},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106594},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Black-box attack against GAN-generated image detector with contrastive perturbation},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active control of flexible rotors using deep reinforcement
learning with application of multi-actor-critic deep deterministic
policy gradient. <em>EAAI</em>, <em>124</em>, 106593. (<a
href="https://doi.org/10.1016/j.engappai.2023.106593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration in rotating machinery is one of the main causes of machine failure. Active and passive control methods have been developed in order to reduce vibration levels and extend the operating speeds of machines. These controllers are either manually tuned or tuned during operation using adaptive control techniques and are tailored to a single vibration source. In the field of artificial intelligence, deep reinforcement learning has greatly impacted the field of continuous control, from mastering simple games to controlling multiple actuators in a robot doing complex tasks. Deep reinforcement learning agents are capable of finding optimal control policies without a model of the underlying system. This work proposes the multi-actor-critic deep deterministic policy gradient (MAC-DDPG) algorithm by integrating multiple criteria to train concurrent actors in a periodic system. Using the frequency footprint of each type of vibration, a cost function is designed to train the critics and actors. The proposed controller is evaluated on a test rig supported by two patented Smart Electro-Magnetic Actuator Journal Integrated Bearings (SEMAJIB). The proposed controller is capable of finding optimal control policies for reducing the synchronous vibration caused by the rotor’s unbalance and stabilizing a system with oil whip vibration. A derivative controller actor and a harmonic actor are used concurrently for controlling the vibrations. The proposed controller is able to reach unbalance vibration reduction up to 93%. In addition, the proposed controller is successful in completely eliminating oil whip instability with up to 99% reduction.},
  archive      = {J_EAAI},
  author       = {Maheed H. Ahmed and Abdullah AboHussien and Aly El-Shafei and Ahmed M. Darwish and Ahmed H. Abdel-Gawad},
  doi          = {10.1016/j.engappai.2023.106593},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106593},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Active control of flexible rotors using deep reinforcement learning with application of multi-actor-critic deep deterministic policy gradient},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Study on a comprehensive indicator and online classification
of early warning of low frequency oscillation in power system.
<em>EAAI</em>, <em>124</em>, 106592. (<a
href="https://doi.org/10.1016/j.engappai.2023.106592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of smart grid technology in China, the study of low frequency oscillation early warning has become an important element of power system stability research. Aiming at the problems of single warning indicator with poor accuracy and lack of online warning system in the early warning strategy of low frequency oscillation in power system, a comprehensive low frequency oscillation early warning algorithm based on the evaluation method of kernel matrix hierarchical analysis of fuzzy comprehensive is proposed. Firstly, this method screens out the original data collected by Phasor Measurement Unit (PMU), and extracts the key data volume to form multiple early warning indicators, and generates the trapezoidal fuzzy number judgment matrix. Secondly, by calculating the kernel matrix and consistency test, it is determined whether or not the generated fuzzy matrix is reasonable and calculate the relative weights of the evaluation indicators. The affiliation function is constructed for each early warning indicator. A comprehensive indicator is calculated for multiple indicators, and the reasons of low frequency oscillation in power system are classified by the Random Forest (RF) algorithm. Then, the low-frequency oscillation system is constructed, and the algorithm convergence is proved by the Lyapunov indirect method. The algorithm can automatically determine whether low frequency oscillation occurs or not and classify different types of low frequency oscillations online. Finally, the correctness and validity of this paper’s method is verified by a New England 10-machine 39-node system. Compared with the traditional Analytic Hierarchy Process (AHP) method, the proposed method in this paper greatly improves the accuracy of early warning and meets the need of online warning.},
  archive      = {J_EAAI},
  author       = {Miao Yu and Weijie Du and Jinglin Li and Shouzhi Zhang and Jingxuan Hu},
  doi          = {10.1016/j.engappai.2023.106592},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106592},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Study on a comprehensive indicator and online classification of early warning of low frequency oscillation in power system},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent fault diagnosis of rotating machinery under
varying working conditions with global–local neighborhood and sparse
graphs embedding deep regularized autoencoder. <em>EAAI</em>,
<em>124</em>, 106590. (<a
href="https://doi.org/10.1016/j.engappai.2023.106590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the health management of rotating machinery based on deep learning has achieved remarkable results. Nevertheless, in the presence of variable working conditions, the sparse nature of the valuable fault information makes the traditional deep models insufficient to achieve effective fault identification. Attributing to the aforementioned challenges, this research presented a new local–global neighborhood graph and sparse graph embedding deep-regularized autoencoder method (LGSDLRAE) framework for variable operating fault diagnosis (FD). More specifically, the FD scheme leverages manifold neighborhood graph embedding ability to mine fault information, combined with sparse theory ability in improving the generalization performance, to improve the performance of the original autoencoder (AE) algorithm. In the feature extraction (FE) phase, to enhance the compactness of homogeneous-classes and increase the separation between heterogeneous-classes by adopted global–local regularization terms; meanwhile, adding L 1 / 2 − sparse regularization terms gather the L 1 regularization norm can make the data more sparse characteristics and L 2 regularization norm prevents overfitting of data performance of the model and improve the generalization ability of the model. Finally, the identification accuracy of the datasets constructed variable operating conditions of double-span rotor test rig and planetary gearboxes are both above 98%, proving the superior performance of LGSDLRAE, respectively.},
  archive      = {J_EAAI},
  author       = {Zejin Sun and Youren Wang and Jiahao Gao},
  doi          = {10.1016/j.engappai.2023.106590},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106590},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent fault diagnosis of rotating machinery under varying working conditions with global–local neighborhood and sparse graphs embedding deep regularized autoencoder},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimal initialisation for robust model reference
adaptive PI controller for grid-tied power systems under unbalanced grid
conditions. <em>EAAI</em>, <em>124</em>, 106589. (<a
href="https://doi.org/10.1016/j.engappai.2023.106589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an Optimal Robust Model Reference Adaptive Proportional–Integral controller for grid-tied power systems, which is automatically parametrised using a Genetic Algorithm. The task of choosing the adaptation rate and the controller’s initial gains set is now performed in a computational and automatic way, saving design time and ensuring satisfactory transient regimes.The use of a Genetic Algorithm for complete parametrisation of robust adaptive controllers applied to renewable energy power generation systems with LCL filter is first here explored. Five cost functions are considered in the optimisation process. A comparison of simulation results applying the optimised controller in a grid-tied Voltage Source Inverter with LCL filter points out the benefits and drawbacks of using each cost function. A framework for performance analysis and an in-depth discussion are provided. The function determined as the best one, which is integral of absolute error, is used in the controller implemented experimentally, ensuring suitable tracking of grid current references and rejection of grid voltage harmonics, even under unbalanced grid voltage conditions. An experimental comparison in a three-phase 6.75 kW power converter with the non-optimised controller is also provided, where the optimised controller obtains a reduction in the overshoot in all transient regimes and smaller tracking error, resulting in a reduction in the mean error of 14.31% and 60.30% in α and β coordinates, respectively. In addition, the optimised controller reduces total harmonic content, improving energy quality. This parametrisation procedure can be immediately extended to the control of any other power converter systems.},
  archive      = {J_EAAI},
  author       = {Paulo Jefferson Dias de Oliveira Evald and Guilherme Vieira Hollweg and Lucas Cielo Borin and Everson Mattos and Rodrigo Varella Tambara and Vinicius Folleto Montagner and Hilton Abílio Gründling},
  doi          = {10.1016/j.engappai.2023.106589},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106589},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimal initialisation for robust model reference adaptive PI controller for grid-tied power systems under unbalanced grid conditions},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy adaptive terminal sliding mode control based on
recurrent neural network compensation for a maglev system.
<em>EAAI</em>, <em>124</em>, 106588. (<a
href="https://doi.org/10.1016/j.engappai.2023.106588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reluctance motor has high force density while strong uncertainties. This paper concentrates on the research of the intelligent control method for a reluctance-motor maglev system (RMMS) with limited system information. To this end, we propose a new fuzzy adaptive terminal sliding mode control (FATSMC) method based on a novel full-regulated recurrent neural network (RNN) compensator. The RNN approximates the lumped uncertainty of the RMMS, and the controller handles the residual error and external disturbances. The presented increasing–decreasing fuzzy adaptive law, without the prior knowledge of uncertain upper bound, adjusts the switching gain by the dynamic information of the system. And the overestimation of the switching gain can be reduced. Moreover, the proposed method only uses the nominal parameters and model of the RMMS, thus avoiding complex modeling. This study provides strong support for the application of RMMS in high-precision situations. By constructing a Lyapunov function, the stability of the proposed method is analyzed, which is uniformly and ultimately bounded (UUB). In the experiment, the proposed method is compared with three existing methods in four cases. The results demonstrate that the presented method achieves nanoscale suspension accuracy, suppresses chattering significantly, and has strong robustness.},
  archive      = {J_EAAI},
  author       = {Xinyi Su and Xiaofeng Yang and Yunlang Xu},
  doi          = {10.1016/j.engappai.2023.106588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy adaptive terminal sliding mode control based on recurrent neural network compensation for a maglev system},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting biomechanical properties of additively
manufactured polydopamine coated poly lactic acid bone plates using deep
learning. <em>EAAI</em>, <em>124</em>, 106587. (<a
href="https://doi.org/10.1016/j.engappai.2023.106587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fused Filament Fabrication based bone plates lack mechanical strength, resulting in premature failure. Biocompatible Polydopamine (PDM) coating forms covalent bonds with Poly Lactic Acid (PLA), resulting in enhanced mechanical characteristics. Infill density, submersion time, shaker speed, and coating solution concentration, have a significant effect on the mechanical properties of coated bone plates. Monitoring the mechanical strength experimentally for each set of process parameters is a time-consuming and tedious procedure. Before resorting to experimental tests, it is important to model and predict the mechanical strength in order to increase the mechanical strength of bone plates. Predictive modeling using machine learning approaches has proven to be the best alternative to traditional statistical tools. In this study, various machine learning algorithms, including Random Forest, k-Nearest Neighbors, AdaBoost, and Decision Trees, and Long Short-Term Memory (LSTM) method, were utilized to predict tensile and flexural strengths. Error metrics consisting of Mean Square Error (MSE), Root Mean Square Error (RMSE), Correlation Coefficient (R 2 ), Mean Absolute Percentage Error (MAPE) and RRMSE (Root Relative Mean Squared Error) have been utilized to assess the performance of various models. Owing to the prediction findings, the LSTM model beat all ML-based models by demonstrating the best MSE, RMSE, and R 2 values for tensile and flexural strength, which were 5.96 MPa, 2.44 MPa, and 0.9169, respectively, and 11.14 MPa, 3.34 MPa, and 0.9242, respectively. Consequently, the results of this study suggest that LSTM is the best model for predicting the tensile and flexural strength of PDM-coated PLA bone plates without doing experiments.},
  archive      = {J_EAAI},
  author       = {Shrutika Sharma and Vishal Gupta and Deepa Mudgal and Vishal Srivastava},
  doi          = {10.1016/j.engappai.2023.106587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting biomechanical properties of additively manufactured polydopamine coated poly lactic acid bone plates using deep learning},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging the meta-embedding for text classification in a
resource-constrained language. <em>EAAI</em>, <em>124</em>, 106586. (<a
href="https://doi.org/10.1016/j.engappai.2023.106586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an intelligent text classification framework for a resource-constrained language like Bengali, which is considered a challenging task due to the lack of standard corpora, appropriate hyper-parameter tuning method, and pre-trained language-specific embedding . The proposed framework comprises an average meta-embedding feature fusion module and a convolutions neural network module called AVG-M+CNN. This work also proposes an algorithm, i.e., automatic hyperparameter tuning and selection, for enhancing the performance of the AVG-M+CNN technique. All meta-embedding models are evaluated using the intrinsic , e.g., semantic, syntactic, relatedness word similarity, analogy tasks and extrinsic evaluators. The intrinsic evaluator evaluates 200 Bengali semantic, syntactic and relatedness word pairs. Spearman ( ρ ˆ ), Pearson ( r ˆ ) and cosine similarity correlations are used to evaluate 18 individual embedding and 9 meta-embedding models. The 3COSADD and 3COSMUL evaluators evaluate the 300 analogy tasks. The extrinsic evaluator evaluates a total of 156 classification models on four corpora: BARD, IndicNLP, Prothom-Alo and B T C C 11 (a newly developed corpus having eleven distinct categories). Among these, the AVG-M+CNN model achieves the highest accuracy regarding four Bengali corpora: 95.92 ± .001% for BARD, 93.10 ± .001% for Prothom-Alo, 90.07 ± .001% for B T C C 11 and 87.44 ± .001% for IndicNLP, respectively.},
  archive      = {J_EAAI},
  author       = {Md. Rajib Hossain and Mohammed Moshiul Hoque and Nazmul Siddique},
  doi          = {10.1016/j.engappai.2023.106586},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106586},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging the meta-embedding for text classification in a resource-constrained language},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing a new sustainable test kit supply chain network
utilizing internet of things. <em>EAAI</em>, <em>124</em>, 106585. (<a
href="https://doi.org/10.1016/j.engappai.2023.106585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of COVID-19 put much economic pressure on countries worldwide, especially low-income countries. Providing test kits for Covid-19 posed a huge challenge at the beginning of the pandemic. Especially the low-income and less developed countries that did not have the technology to produce this kit and had to import it into the country, which itself cost a lot to buy and distribute these kits. This paper proposes a sustainable COVID-19 test kits supply chain network (STKSCN) for the first time to fill this gap. Distribution and transportation of test kits, location of distribution centers, and management of used test kits are considered in this network. A mixed integer linear programming Multi-Objective (MO), multi-period, multi-resource mathematical model is extended for the proposed supply chain. Another contribution is designing a platform based on the Internet of Things (IoT) to increase the speed, accuracy and security of the network. In this way, patients set their appointment online by registering their personal details and clinical symptoms. An augmented ɛ -constraint2 (AUGMECON2) is proposed for solving small and medium size of problem. Also, two meta-heuristic algorithms, namely NSGA-II and PESA-II are presented to solve the small, medium and large size of the problem. Taguchi method is utilized to control the parameters, and for comparison between meta-heuristic, five performance metrics are suggested. In addition, a case study in Iran is presented to validate the proposed model. Finally, the results show that PESA-II is more efficient and has better performance than the others based on assessment metrics and computational time.},
  archive      = {J_EAAI},
  author       = {Ali Navaei and Ata Allah Taleizadeh and Fariba Goodarzian},
  doi          = {10.1016/j.engappai.2023.106585},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106585},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Designing a new sustainable test kit supply chain network utilizing internet of things},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain adaptation assisted automatic real-time human-based
video summarization. <em>EAAI</em>, <em>124</em>, 106584. (<a
href="https://doi.org/10.1016/j.engappai.2023.106584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video summarization plays a momentous role for real-time surveillance for detection of suspicious human activities in public scenes. However, efficient, and accurate human-centric video summarization in real-time videos is still a challenging issue due to several inconsistencies such as noise, illumination effects, scale, or rotational variance, etc. Though, several prominent research studies are available related to human activities detection but a robust human-centric video summarization approach is a major issue. In this research, we expound an efficient video summary generation model (ReHuSum) that creates a short summary with human. Our approach employs the conception of domain adaptation for efficient summarization via transferring the knowledge of a potent pre-trained benchmark Inception-v3 model. Additionally, a frame differencing redundancy removal technique is adopted that aids in generating a precise and accurate video summary with human. Our model generates efficient short summaries from real-time videos with an overall human detection accuracy of 99.97%. Besides, we present two novel qualitative metrics namely; summarization rate ( S u m m r a t e ) and summarization loss ( S u m m l o s s ) for assessing the efficacy of overall summarization. The approach generates a real-time human-based summary of 46s with a ( S u m m r a t e ) of 98.7% and ( S u m m l o s s ) of 0.013 for an outdoor CCTV with a duration of 25.2 min. Similarly, an indoor CCTV of 40.10 min duration is summarized to 44s at a ( S u m m r a t e ) of 96.5% and ( S u m m l o s s ) of 0.035. The model can be utilized in real-time security applications (i.e., border or home surveillance, critical infrastructure, smart cities, etc.) to generate accurate video summaries with human.},
  archive      = {J_EAAI},
  author       = {Ambreen Sabha and Arvind Selwal},
  doi          = {10.1016/j.engappai.2023.106584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Domain adaptation assisted automatic real-time human-based video summarization},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-branch deep learning with spatial and pose constraints
for social group detection. <em>EAAI</em>, <em>124</em>, 106583. (<a
href="https://doi.org/10.1016/j.engappai.2023.106583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group detection is a crucial yet challenging task in various application domains, including video surveillance analysis and service robot interactions. Previous studies have struggled with complicated group structures and diverse human behaviors, resulting in low performance in multiple activity group detections. In this article, we propose a two-branch deep learning framework with spatial and pose constraints that combines physical proximity and social behavior to improve group detection performance. Specifically, we design an original Variable Group Detection Transform Network (VGDTN) that integrates dyad representations and contextual information to recognize complex group arrangements. Additionally, we present a novel pose-based refined clustering module that efficiently explores human behavior within multiple activity group detections by utilizing ternary postures classification. To address the computational intensity of DL-based methods in extensive surveillance video analysis, a designed lightweight VGDTN which consists of NIN blocks maintains good performance while reducing the computational burden. The experimental results show that our method outperforms the state-of-the-art methods by 7%, 5%, 2%, and 4% in F1_score (T = 1 ) on four public datasets.},
  archive      = {J_EAAI},
  author       = {Xiaoyan Lu and Xinde Li and Chuanfei Hu and Jin Deng and Weijie Sheng and Lianli Zhu},
  doi          = {10.1016/j.engappai.2023.106583},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106583},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-branch deep learning with spatial and pose constraints for social group detection},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of neuro-fuzzy ensembles across domains: A
systematic review of the two last decades (2000–2022). <em>EAAI</em>,
<em>124</em>, 106582. (<a
href="https://doi.org/10.1016/j.engappai.2023.106582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuro-fuzzy systems have received considerable attention from academia in the last decade. They can provide a tradeoff between the performance of artificial neural networks and the interpretability of fuzzy inference systems expressed through fuzzy rules. Single techniques do not always provide the optimal performance, especially when the results are susceptible to changes in the data or hyperparameters. Therefore, ensemble learning can be used to build a more stable and robust model. In this paper, a systematic literature review of studies evaluating neuro-fuzzy ensembles was performed to highlight the importance of ensemble learning and its role in improving the performance of neuro-fuzzy systems. Many aspects are highlighted, including publication years, sources, contribution types, application domains, single neuro-fuzzy systems, ensemble techniques, and the overall performance and interpretability. A total of forty-eight articles published from 2000 to March 2022 addressing the use of neuro-fuzzy ensembles in different engineering applications were selected and analyzed. Results show that: (i) Takagi–Sugeno–Kang neuro-fuzzy systems are the most evaluated category, especially the ANFIS single. (ii) Homogeneous​ ensembles, in particular boosting, are the most investigated. (iii) Logical, relational and ANFIS ensembles are outperforming. And (iv) The interpretability of neuro-fuzzy ensembles was not thoroughly investigated, but based on the number of rules, logical systems were the best.},
  archive      = {J_EAAI},
  author       = {Hafsaa Ouifak and Ali Idri},
  doi          = {10.1016/j.engappai.2023.106582},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106582},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of neuro-fuzzy ensembles across domains: A systematic review of the two last decades (2000–2022)},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Truth-value unconstrained face clustering for identity
resolution in a distributed environment of criminal police information
systems. <em>EAAI</em>, <em>124</em>, 106576. (<a
href="https://doi.org/10.1016/j.engappai.2023.106576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work of criminal police in contemporary society is characterized by the proliferation of data and information to be processed, a more significant limitation of access to personal data, increased public monitoring, and higher expectations in the efficiency of identifying perpetrators. Also, all information collected during investigations is distributed through police systems separated by different levels and organization units, and often there are insufficient human and material resources. Resolving the perpetrator’s identity in those circumstances is a complex task, and police decision support systems must group all available evidence related to specific persons. For that purpose, this paper proposes a new approach to unconstrained pairwise clustering of face feature vectors extracted from the histogram of oriented gradients descriptor, named Truth-value clustering (TVC), based on non-axiomatic logic and graphs. The clustering approach was experimentally tested with six different face image databases. They were created to simulate unconstrained conditions like IARPA Janus Benchmark-B Face Dataset (IJB-B), IMDb-Wiki, Labeled Faces in the Wild, and YouTube Faces. The results of the proposed solution are compared with other state-of-the-art methods, showing that the approach gives, in summary, significantly better results. Application of the IJB-B protocol created for testing face clustering showed that the new approach gives better results by an average of 8.25% ( σ = 4 . 2 ). The main advantage over other methods is the possibility of utilizing mechanisms from non-axiomatic logic such as revision, which can then acquire new knowledge based on information from different nodes of the distributed environment consisting of various police information systems.},
  archive      = {J_EAAI},
  author       = {Igor Vukovic},
  doi          = {10.1016/j.engappai.2023.106576},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106576},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Truth-value unconstrained face clustering for identity resolution in a distributed environment of criminal police information systems},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integration of ROV and vision-based underwater inspection
for limnoperna fortunei in water conveyance structure. <em>EAAI</em>,
<em>124</em>, 106575. (<a
href="https://doi.org/10.1016/j.engappai.2023.106575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The invasion of Limnoperna fortunei (L. fortunei) has been identified as one major biofouling in the operation of hydraulic engineering, which not only corrodes the concrete structures but also reduces the pipe diameter and increases the surface roughness, leading to the decrease of water conveyance capacity and the increase of the project operation cost. To better cope with this problem, an automated underwater inspection analysis scheme for the biofouling of L. fortune is provided in this study, which innovatively integrates the underwater remote operating rover (ROV) and computer vision techniques to inspect and evaluate the invasion of L. fortunei in water conveyance structure. This scheme first presents an image enhancement approach based on the fusion strategy to improve the quality of images extracted from underwater robot inspection videos. Then, the L. fortunei is segmented by U-Net in the enhanced underwater images, and the definition of adherent area ratio quantitatively assesses the biofouling severity. At last, the underwater inspection analysis scheme is implemented in a typical aqueduct, and the automatic analysis results are compared with the field investigation during the emptying maintenance of the aqueduct. In this study, the dataset of real ROV inspection video sequences was first used to evaluate the effectiveness of the proposed method for inspecting L. fortunei invasions in realistic scenarios, and then for the comparison with state-of-the-art methods. The results show that the proposed automated inspection scheme is capable of efficiently improving the underwater imaging quality and accurately detecting the L. fortunei.},
  archive      = {J_EAAI},
  author       = {Xin Fang and Heng Li and Sherong Zhang and Jikang Zhang and Chao Wang and Xiaohua Wang and Ziao Ma and He Jia},
  doi          = {10.1016/j.engappai.2023.106575},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106575},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integration of ROV and vision-based underwater inspection for limnoperna fortunei in water conveyance structure},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic defect detection and three-dimensional
reconstruction from pulsed thermography images based on a bidirectional
long-short term memory network. <em>EAAI</em>, <em>124</em>, 106574. (<a
href="https://doi.org/10.1016/j.engappai.2023.106574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning techniques have become increasingly applied to non-destructive testing based on pulsed thermography. However, existing methods need to extract characteristic data manually. The present work addresses this issue by applying a bidirectional long-short term memory (Bi-LSTM) network to identify defects, predict defect depths, and reconstruct defective materials in three dimensions automatically based on raw cooling data sequences. The network is trained and tested based on data collected for stainless-steel specimens with multiple flat-bottom holes introduced at various specimen depths. A dual-task method and a single-task method were proposed based on Bi-LSTM network. A classification model and a regression model are constructed in the dual-task method for identifying defects and predicting defect depths. Only the regression network is implemented in a single-task method to more quickly obtain the same results based on a depth threshold. Both methods are demonstrated to achieve satisfactory accuracy in the 3D reconstruction of the defects in the testing specimen. In addition, higher pulse energy and faster acquisition frequency can promote the prediction accuracy. Then the results of Bi-LSTM were compared with the results of 1D CNN and MLP. To verify the generalization of the proposed method, CFRP specimen is employed for 3D reconstruction, which also performed with good results.},
  archive      = {J_EAAI},
  author       = {Zhuoqiao Wu and Siyun Chen and Fan Feng and Jinrong Qi and Lichun Feng and Ning Tao and Cunlin Zhang},
  doi          = {10.1016/j.engappai.2023.106574},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106574},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic defect detection and three-dimensional reconstruction from pulsed thermography images based on a bidirectional long-short term memory network},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Danger assessment of the partial discharges temporal
evolution on a polluted insulator using UHF measurement and deep
learning. <em>EAAI</em>, <em>124</em>, 106573. (<a
href="https://doi.org/10.1016/j.engappai.2023.106573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pollution over insulators surfaces in outdoor environments is detrimental for long term operation of power systems. The temporal evolution of measurement signals as the contamination increases has not been given much attention. This work proposes presented the analysis of the time series of partial discharges measured with an antenna in an increasing pollution condition until flashover, using a deep learning algorithm in order to identify the early signs of an incoming flashover. Flashover was produced by gradually increasing pollution over a bushing insulator to carry out a binary classification of signals as low or high danger. Different time thresholds were tested and it was concluded that partial discharges measured with antennas can be used as early detection of flashover, and a time threshold at the 70% of total experiment time gave the best result, being noticeable transition from low to high danger signals before flashover.},
  archive      = {J_EAAI},
  author       = {Luis Orellana and Jorge Ardila-Rey and Gonzalo Avaria and Sergio Davis},
  doi          = {10.1016/j.engappai.2023.106573},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106573},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Danger assessment of the partial discharges temporal evolution on a polluted insulator using UHF measurement and deep learning},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A cascaded modeling approach for comprehensive reaction
state perception of a hydrometallurgical reactor. <em>EAAI</em>,
<em>124</em>, 106572. (<a
href="https://doi.org/10.1016/j.engappai.2023.106572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hydrometallurgical reactor is the central production unit in a hydrometallurgy process. Due to the correlation between multiple parallel reactions and feeding condition fluctuations, modeling the outlet technical indicator alone is insufficient to express the highly informative reaction state comprehensively. This paper proposes a cascaded modeling approach for comprehensive reaction state perception of a hydrometallurgical reactor by considering the feeding conditions, operation modes, outlet technical indicators, and their relations. First, propose a perception model based on the information of two adjacent reactors for feeding condition perception. Second, develop an online operating mode perception model, combining dynamic feature extraction methods based on dynamic inner principal component analysis and mechanism knowledge. Finally, an outlet technical indicator perception model integrates mechanism and data features for multiple operation modes. The simulation results reveal that the proposed model can comprehensively describe the reaction state and guide on-site control.},
  archive      = {J_EAAI},
  author       = {Xulong Zhang and Yonggang Li and Shuang Long and Guoxin Liu and Bei Sun and Chunhua Yang},
  doi          = {10.1016/j.engappai.2023.106572},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106572},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A cascaded modeling approach for comprehensive reaction state perception of a hydrometallurgical reactor},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised hierarchical ensemble clustering based on an
innovative distance metric and constraint information. <em>EAAI</em>,
<em>124</em>, 106571. (<a
href="https://doi.org/10.1016/j.engappai.2023.106571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agglomerative Hierarchical Clustering (AHC) is a bottom-up clustering strategy in which each object is originally a cluster, and more pairs of clusters are formed by traversing the hierarchy. It has been proven that there is no individual AHC clustering algorithm that can be efficient in all situations. In order to address this problem, ensemble clustering techniques have been introduced. These techniques combine the results of several output partitions to achieve a consensus with higher accuracy compared to an individual clustering algorithm. This paper proposes an AHC-based ensemble semi-supervised clustering algorithm to improve performance. In semi-supervised clustering, class membership information is used in some objects. Here, we introduce the Semi-Supervised Ensemble Hierarchical Clustering based on Constraints Information (SSEHCCI) algorithm. SSEHCCI is developed using several individual clustering algorithms based on AHC. SSEHCCI includes a flexible weighting policy to generate base partitions and uses the constraints information to configure the semi-supervised clustering. In addition, SSEHCCI uses an innovative distance measure to calculate the distance between each pair of objects. Experimental results show that SSEHCCI performs better than existing semi-supervised algorithms on some University of California Irvine (UCI) datasets. Specifically, we observed an average accuracy of SSEHCCI compared to SSDC and RSSC of 2.6% and 1.8%, respectively.},
  archive      = {J_EAAI},
  author       = {Baohua Shen and Juan Jiang and Feng Qian and Daoguo Li and Yanming Ye and Gholamreza Ahmadi},
  doi          = {10.1016/j.engappai.2023.106571},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106571},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised hierarchical ensemble clustering based on an innovative distance metric and constraint information},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extended natural neighborhood for SMOTE and its variants in
imbalanced classification. <em>EAAI</em>, <em>124</em>, 106570. (<a
href="https://doi.org/10.1016/j.engappai.2023.106570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data classification is a challenging issue encountered in many practical applications. Synthetic minority oversampling technique (SMOTE) and its variants are popular resampling methods. However, in most of these methods, the neighborhood determined by k -nearest neighbor ( k NN) cannot reflect the local distribution precisely, leading to the generation of noisy examples. To solve this problem, we propose a neighborhood concept without parameter k called extended natural neighbor (ENaN), which is derived from natural neighbor (NaN). ENaN unites k NN and reverse k NN to determine neighbors adaptively according to the sample distribution. Compared to NaN, ENaN explores broad neighborhoods, which facilitates to improve the quality of generated examples. ENaN-based SMOTE (ENaNSMOTE) can improve the sample distribution obtained by SMOTE and NaNSMOTE. Extensive experiments using 30 synthetic and 20 real-world datasets prove the effectiveness of ENaN in SMOTE and its variants.},
  archive      = {J_EAAI},
  author       = {Hongjiao Guan and Long Zhao and Xiangjun Dong and Chuan Chen},
  doi          = {10.1016/j.engappai.2023.106570},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106570},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Extended natural neighborhood for SMOTE and its variants in imbalanced classification},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IGAN: A collaborative filtering model based on improved
generative adversarial networks for recommendation. <em>EAAI</em>,
<em>124</em>, 106569. (<a
href="https://doi.org/10.1016/j.engappai.2023.106569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Generative Adversarial Networks (GANs) have been successfully applied to collaborative filtering for implicit feedback. However, the ability of GAN to learn user interest distributions is greatly reduced due to its difficulty in characterizing the features. In this paper, a collaborative filtering model based on Improved Generative Adversarial Networks (IGAN) is proposed to address the above issue. In IGAN, we first introduce the independent encoder and generator to learn features representation during adversarial training. Then, the Kullback–Leibler (KL) loss and reconstruction loss are added as the penalty term to further fit the interest distribution of users and achieve higher recommendation accuracy. Finally, this paper conducts extensive experiments on three real public datasets, showing that the IGAN method has a maximum improvement of 5.26% and 5.43% in P@5 and NDCG@5 compared with the current GAN-based methods.},
  archive      = {J_EAAI},
  author       = {Xiaoyuan Song and Jiwei Qin and Qiulin Ren and Jiong Zheng},
  doi          = {10.1016/j.engappai.2023.106569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IGAN: A collaborative filtering model based on improved generative adversarial networks for recommendation},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of artificial neural networks for predicting the
bearing capacity of the tip of a pile embedded in a rock mass.
<em>EAAI</em>, <em>124</em>, 106568. (<a
href="https://doi.org/10.1016/j.engappai.2023.106568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the problem of the bearing capacity of the tip of a pile in rock needs to consider a full-nonlinear behavior of the rock, as the Hoek and Brown failure criterion, and including the various geometric parameters defining the system geometry. It usually needs the use of complex numerical models. They require a high level of training and expertise and are commonly out of the reach of engineers on the day-to-day calculation procedures. Technical codes usually recommend simpler formulae based on one or two rock parameters, their accuracy relying on particular and local empirical testing. This research develops an artificial neural network (ANN) that solves the previous difficulties. The ANN is based on a group of 1440 calculations using the novel numerical procedure Discontinuity Layout Optimization (DLO). This numerical method can efficiently reproduce the non-linear behavior of the rock (including rock type, uniaxial compressive strength, and geological strength index) for every configuration of the model (foundation width, pile embedment, and height of the overlying soil). Once the ANN is trained and optimized, it can easily predict any result within its range of applicability. Furthermore, it can be reduced to a simple set of recursive equations to be implemented in a spreadsheet. The proposed ANN has only one hidden layer besides the input and output layers, with (6)-(8)-(1) neurons, respectively. It gives highly accurate results with minimum cost and can be a useful tool for engineers and scientists in the foundation field.},
  archive      = {J_EAAI},
  author       = {M.A. Millán and A. Picardo and R. Galindo},
  doi          = {10.1016/j.engappai.2023.106568},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106568},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of artificial neural networks for predicting the bearing capacity of the tip of a pile embedded in a rock mass},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An application of DEMATEL and fuzzy DEMATEL to evaluate the
interaction of safety management system and cybersecurity management
system in automated vehicles. <em>EAAI</em>, <em>124</em>, 106566. (<a
href="https://doi.org/10.1016/j.engappai.2023.106566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the safety and security of Automated Vehicles (Avs), the interaction between the Functional Safety (FuSa) and the Cybersecurity (CS) domains needs to be managed systematically. There is a demand to develop effective and structured management systems to support the homologation process. From this motivation, identifying the interaction between the Safety Management System (SMS) and the Cybersecurity Management System (CSMS) is a fundamental aspect and needs to be improved for HAD systems. Hence, the classical Decision Making Trial and Evaluation Laboratory (DEMATEL) method and fuzzy DEMATEL are applied to evaluate the influential factors that can impact the safety and security of the HAD systems. This paper proposes a list of influencing factors focusing on the interaction between SMS and CSMS for HAD systems. Additionally, the results of an anonymously conducted survey among experts from industry and research are presented and used as inputs for the methods. This work helps to understand the relationship between influencing factors and provides a simplified, easy-to-visualized, and valuable guide for developing HAD systems. The result of this study shows that the most important influential factor is F13. Moreover, the cause and effect of the factors are illustrated numerically and graphically. The influential factors F1 to F7 are identified as the cause and F8 to F13 are reasoned to effect. Finally, a circular representation of the influential factors and their interaction is presented in this paper.},
  archive      = {J_EAAI},
  author       = {Marzana Khatun and Florence Wagner and Rolf Jung and Michael Glaß},
  doi          = {10.1016/j.engappai.2023.106566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An application of DEMATEL and fuzzy DEMATEL to evaluate the interaction of safety management system and cybersecurity management system in automated vehicles},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development and comparative evaluation of various fault
detection algorithms for a drum brake using artificial neural networks
and a physics-based model. <em>EAAI</em>, <em>124</em>, 106565. (<a
href="https://doi.org/10.1016/j.engappai.2023.106565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drum brakes are among the essential safety components in automobiles; hence, it is critical to detect any fault in the system that might hinder its performance. A fault detection framework based on artificial intelligence and a rigid-body model of a system (as a digital experiment) is proposed to detect four of the most common faults in automotive drum brakes. First, a contact mechanics-based nonlinear model of a drum brake (incorporating conformal contact between the brake shoes and the brake drum) is developed to estimate the dynamic response accurately. The predictions from this model are compared with the data available in the literature. The responses estimated from the model with a known level of faults form the input data set for various fault quantification algorithms. Sensitivity-based pruning technique in conjunction with an artificial neural network is used to select the optimal set of features for which the physical interpretations are deduced. The developed fault detection methodologies are quantitatively compared, and the most applicable among them is determined based on the detection accuracy and the computational cost. Finally, the robustness of the selected methodology is tested under the presence of white Gaussian noise in the measured signals. The proposed framework and the selected methodology will help design an accurate health monitoring tool to diagnose faults in automotive drum brakes. Though the current study focuses on drum brakes, the possible generalization of its framework to other systems is discussed.},
  archive      = {J_EAAI},
  author       = {Akash Yella and Aditya Chaudhary and Sriram Sundar},
  doi          = {10.1016/j.engappai.2023.106565},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106565},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development and comparative evaluation of various fault detection algorithms for a drum brake using artificial neural networks and a physics-based model},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation-based decision support system for earthmoving
operations using computer vision. <em>EAAI</em>, <em>124</em>, 106564.
(<a href="https://doi.org/10.1016/j.engappai.2023.106564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A reliable Decision Support System (DSS), particularly in the construction domain, can be driven by quality input information. Although vision-based methods have been widely utilized to retrieve contextual information, their potential is not fully leveraged in construction simulation yet. This study introduces an automated framework that utilizes multi-view video footage for vision-based input modeling within simulation domains. The proposed framework addresses project uncertainties (e.g., equipment performance, operators’ skills, road network, and weather status) using a proactive approach where project task durations are modeled as probabilistic distributions. The modeled distributions are continuously calibrated using the Markov Chain Monte Carlo Bayesian Inference (MCMCBI) approach. A simulation-based Simulated Annealing (SA) optimization is also employed to provide an efficient resource assignment. The extracted vision-based data is validated statistically against actual and spatiotemporal data. The results demonstrate that the suggested vision-based approach can provide qualified DSS input. Statistical analysis also confirms that vision-based data is more consistent with actual data than spatiotemporal data. The presented approach is successfully applied to an actual case study of a large-scale earthmoving project.},
  archive      = {J_EAAI},
  author       = {Vahid Zamani PhD Candidate and Hosein Taghaddos PhD and Yaghob Gholipour PhD},
  doi          = {10.1016/j.engappai.2023.106564},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106564},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simulation-based decision support system for earthmoving operations using computer vision},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A two-stream network with complementary feature fusion for
pest image classification. <em>EAAI</em>, <em>124</em>, 106563. (<a
href="https://doi.org/10.1016/j.engappai.2023.106563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pests are diverse and the available datasets often contain an uneven number of examples for different pests (a.k.a., the long-tail distribution). This poses a great challenge to learning-based classification methods, especially deep networks, and often leads to degraded performance, especially for the minority (tail) classes. This paper presents a deep learning integration architecture based on decoupling training and fusion learning, which integrates different models with complementary performance on pest datasets with a long-tailed distribution to improve the overall classification performance of pests. A deep neural network is designed that fuses two complementary deep learning models at the feature level, which consists of a convolution neural network (ConvNeXt) and a Swin Transformer model for decoupling training. Experiments are conducted using three datasets (d0, insect, and IP102), and evaluation on accuracy, recall, and F1-Score is reported. For the large-scale pest dataset with long-tailed distribution IP102, the accuracy achieves 76.1%, which outperforms the state-of-the-art methods. In addition, the accuracy for d0 and insect datasets are 98.5% and 92.3%, respectively.},
  archive      = {J_EAAI},
  author       = {Chao Wang and Jinrui Zhang and Jin He and Wei Luo and Xiaohui Yuan and Lichuan Gu},
  doi          = {10.1016/j.engappai.2023.106563},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106563},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stream network with complementary feature fusion for pest image classification},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing multi-physics modelling with deep learning:
Predicting permeability through structural discontinuities.
<em>EAAI</em>, <em>124</em>, 106562. (<a
href="https://doi.org/10.1016/j.engappai.2023.106562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical modelling of complex structural discontinuities such as fractures poses a computational challenge, as it involves solving multi-scale and multi-physics phenomena and simulating various processes, including solid, fluid, thermal and chemical interactions. To overcome the limitations of long computation times, simplifications or conceptualizations are often required. However, in multi-physics modelling, it is desirable to obtain predictions of certain parameters without making simplifications. In this study, a data-driven deep learning approach is presented that predicts physical permeability parameters through discontinuities with complicated geometries based on digital images. Images of fractures were generated from a digitalized rough fracture surface of subsurface rock. Permeability was calculated using the Stokes equation and Finite Volume discretization for training and testing purposes. Two cases were analyzed: when the fluid velocity field of the fracture was provided to the CNN for training, and a more challenging case when it was not. Results show that deep learning can accurately predict permeability without fluid velocity information. Besides, the model generalizes well, providing accurate predictions of permeability for fractures with significantly different roughness parameters. In conclusion, this approach can reduce computation time during multi-physics modelling and can be used to predict continuous physical permeability values from an image of a fracture with a complex surface.},
  archive      = {J_EAAI},
  author       = {Amanzhol Kubeyev},
  doi          = {10.1016/j.engappai.2023.106562},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106562},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing multi-physics modelling with deep learning: Predicting permeability through structural discontinuities},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FEDA-NRP: A fixed-structure multivariate estimation of
distribution algorithm to solve the multi-objective next release problem
with requirements interactions. <em>EAAI</em>, <em>124</em>, 106555. (<a
href="https://doi.org/10.1016/j.engappai.2023.106555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the development of a software product, the Next Release Problem is the selection of the most appropriate subset of requirements (tasks) to include in the next release of the product, such that the selected subset maximises the overall satisfaction of the stakeholders and minimises the total cost. Furthermore, in most cases, requirements or tasks cannot be developed independently, as there are dependencies between them, which must be respected in the selection for the next release. In this paper, we approach the Next Release Problem as a constrained bi-objective optimisation problem. The main contribution is the design of an Estimation of Distribution Algorithm that exploits domain knowledge, i.e. the dependencies between the requirements, to define the structure of a Bayesian network that models the relationships between the binary variables (requirements) to be optimised. The use of a Bayesian network with a fixed structure reduces the complexity of the search process, since it is unnecessary to learn the structure at each iteration of the algorithm. Moreover, it ensures that the sampled individuals are always valid with respect to the required dependencies. The second main contribution is the generation of a corpus of synthetic datasets with cost estimations derived from agile and classic management methodologies. Standard multi-objective metrics are computed in order to assess our proposal and compare it with other evolutionary multi-criterion optimisation algorithms, determining that it is the optimal choice when dealing with complex datasets.},
  archive      = {J_EAAI},
  author       = {Víctor Pérez-Piqueras and Pablo Bermejo and José A. Gámez},
  doi          = {10.1016/j.engappai.2023.106555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FEDA-NRP: A fixed-structure multivariate estimation of distribution algorithm to solve the multi-objective next release problem with requirements interactions},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary dynamic stochastic search algorithm with support
vector regression for feature selection in low-velocity impact
localization problem. <em>EAAI</em>, <em>124</em>, 106554. (<a
href="https://doi.org/10.1016/j.engappai.2023.106554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locating low-velocity impacts (LVIs) on composite plates precisely is necessary. Support vector regression (SVR) is an effective method in addressing the LVI localization problem, whereas a large number of impact features may lead to a slow computational rate and over-fitting of the SVR model. In this paper, a binary dynamic stochastic search algorithm (BDSS) is proposed by introducing a threshold factor and the encoding concept of genetic algorithm into the original dynamic stochastic search algorithm (DSS). Then, a feature selection method is proposed by combining BDSS with SVR, which is called BDSS-SVR. BDSS-SVR as a wrapper method can simultaneously implement dimensionality reduction of impact features and optimize the SVR model’s parameters. Furthermore, a novel LVI localization method based on BDSS-SVR and multi-domain features is designed for accurately detecting the LVIs on a carbon fiber reinforced plastic (CFRP) plate. To analyze the performance of BDSS-SVR, a LVI localization system based on fiber Bragg grating (FBG) sensors is applied to the conduction of two experiments. Two additional control parameters of BDSS-SVR, including the threshold factor and weight coefficient, are tuned in the first experiment. Moreover, the statistical results in the second experiment illustrate that BDSS-SVR outperforms optimized SVR using DSS, feature selection methods based on five state-of-the-art algorithms and SVR, and five machine learning methods. For fifteen random LVIs on the CFRP plate, BDSS-SVR effectively reduces the number of impact features and provides satisfactory localization accuracy. The maximum, minimum, and average errors are 4.659 mm, 0.024 mm, and 3.065 mm, respectively.},
  archive      = {J_EAAI},
  author       = {Qi Liu and Fengde Wang and Wensheng Xiao and Junguo Cui},
  doi          = {10.1016/j.engappai.2023.106554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Binary dynamic stochastic search algorithm with support vector regression for feature selection in low-velocity impact localization problem},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced recommender system based on heterogeneous graph
link prediction. <em>EAAI</em>, <em>124</em>, 106553. (<a
href="https://doi.org/10.1016/j.engappai.2023.106553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based data has gained popularity in various applications, including social networks, recommendation systems, and knowledge graphs. Detecting missing links between nodes is a critical challenge in processing graph-based data, as it directly impacts the performance of these applications. The framework for inductive representation learning on large graphs called GraphSAGE method is commonly used for identifying node embeddings, but it has limitations in terms of sensitivity to hyperparameters and difficulties in processing large graphs and capturing global graph information. To address these issues, we propose an improved GraphSAGE architecture for link prediction. Our approach leverages advanced aggregation functions and diverse neural network architectures. Through extensive experimentation on benchmark datasets, we demonstrate the superiority of our method in terms of link prediction accuracy compared to standard GraphSAGE. Additionally, by integrating clustering techniques, we develop a robust recommender system that outperforms state-of-the-art techniques. Our findings highlight the practical potential of our methodology for recommendation tasks and underline its significance in graph-based data processing.},
  archive      = {J_EAAI},
  author       = {Yassine Afoudi and Mohamed Lazaar and Safae Hmaidi},
  doi          = {10.1016/j.engappai.2023.106553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced recommender system based on heterogeneous graph link prediction},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Multi-layer additive tensor decomposition of infrared video
for titanium alloy tensile testing. <em>EAAI</em>, <em>124</em>, 106552.
(<a href="https://doi.org/10.1016/j.engappai.2023.106552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared video (in mathematics terms, tensor) has been widely used in the tensile testing of metallic materials, such as titanium alloy and steel. The infrared video of the tensile testing process can effectively and efficiently determine the properties of metallic materials, e.g., Young’s modulus, Poisson’s ratio, yield strength, etc. The infrared video with structural properties, such as smoothness and sparsity, can be used to characterize the tensile testing process. To extract the features in the infrared video with structural properties, we propose a multi-layer additive tensor decomposition (MLATD) method based on regularization tensor regression for tensile testing. It decomposes a tensor into three classes of components: the multi-smooth layers (including background and foreground), the sparse layers (including between-tensor and in-tensor), and the noise layer. The scree plot is proposed to determine the number of multi-smooth layers, which is a downward curve of the difference between the smooth layers and the sparse layer. The alternating direction method of multipliers (ADMM) algorithm is proposed to solve the proposed method. The decomposition results of the simulation data and real-world case study revealed that the proposed method outperforms the existing state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Tao Zhang and Jian Liu and Yibo Ai and Weidong Zhang},
  doi          = {10.1016/j.engappai.2023.106552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-layer additive tensor decomposition of infrared video for titanium alloy tensile testing},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perceiving multiple representations for scene text image
super-resolution guided by text recognizer. <em>EAAI</em>, <em>124</em>,
106551. (<a
href="https://doi.org/10.1016/j.engappai.2023.106551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image super-resolution (SISR) aims to recover clear high-resolution images from low-resolution images, which has made great progress with the development of deep learning these years. Scene text image super-resolution (STISR) is a subfield of SISR with the goal of increasing the resolution of a low-resolution text image and enhancing the readability of characters in the image. Despite significant improvements in recent approaches, STISR remains a challenging task due to the diversity of background, text appearances and layouts, etc. This paper presents a Perceiving Multiple Representations (PerMR) method for better super-resolution performances in scene text images. PerMR is a unified network that combines super-resolution with text recognition and exploits the recognizer’s feedback to facilitate super-resolution. Specifically, contextual information from the text decoder is extracted to provide sequence-specific guidance and enable the super-resolution model to pay more attention to the text region. Meanwhile, low-level and high-level visual features from the vision backbone of the recognition network are integrated to further improve visual quality. Additionally, we incorporate a frequency branch into the vanilla convolution unit, which efficiently enhances global and local feature representations. Experiments on the STISR benchmark dataset TextZoom validate that PerMR can not only generate more distinguishable images, but also outperforms the current state-of-the-art methods. PerMR boosts the average recognition accuracy by 5.9% using ASTER, 5.8% using MORAN and 10.6% using CRNN compared to the baseline model TSRN. PerMR outperforms the advanced method TPGSR-3 by 1.4% on ASTER, 0.1% on MORAN, 0.2% on CRNN and boosts TATT by 0.6% on ASTER and 1.1% on MORAN respectively. Furthermore, PerMR demonstrates good robustness and generalization when tackling low-quality text images in multiple scene text recognition datasets. The experiment results verify the capabilities of PerMR to boost text recognition performance.},
  archive      = {J_EAAI},
  author       = {Qin Shi and Yu Zhu and Yatong Liu and Jiongyao Ye and Dawei Yang},
  doi          = {10.1016/j.engappai.2023.106551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Perceiving multiple representations for scene text image super-resolution guided by text recognizer},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new deep learning method for meteorological drought
estimation based-on standard precipitation evapotranspiration index.
<em>EAAI</em>, <em>124</em>, 106550. (<a
href="https://doi.org/10.1016/j.engappai.2023.106550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we studied drought parameter estimation based on the standard precipitation evapotranspiration index (SPEI), for four stations located at different places in Türkiye. We proposed a new hybrid deep structure of convolutional neural network (CNN) and long short-term memory (LSTM) methods and compared it with several other existing methods. Our extensive experimental results obtained in different cases of the station, time scale, and estimator show that better estimation results are often obtained with 12-month time scale for all methods. For instance using SPEI-9 values for Şanlıurfa station, the CNN method achieves 0.57 RMSE, 0.24 MADE, 0.11 MAE, and 99.38% R 2 , whereas the proposed adaptive CNN-LSTM obtains values of 0.42, 0.18, 0.04, and 99.69% for the same metrics, respectively. Also, using SPEI-6 values for Mardin station, the bidirectional-LSTM method achieves 0.72 RMSE, 0.35 MADE, 0.22 MAE, and 98.94% R 2 , while the proposed adaptive CNN-LSTM obtains values of 0.32, 0.12, 0.02, and 99.53%, respectively In this means, the proposed method is superior to existing methods in all cases in terms of almost all performance metrics. It is also robust to changes in given input time series data coming from different stations. We also investigated the percentage occurrence of drought categories at different time scales. The results of this analysis also show that the highest percentages are seen in the wet category for all stations. The percentages occurrence of drought wet category are 48.3, 50.07, 50.14, and 50.79 at SPEI-3, SPEI-6, SPEI-9, and SPEI-12 time scales, respectively.},
  archive      = {J_EAAI},
  author       = {Sercan Yalçın and Musa Eşit and Önder Çoban},
  doi          = {10.1016/j.engappai.2023.106550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new deep learning method for meteorological drought estimation based-on standard precipitation evapotranspiration index},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved teaching learning algorithm with laplacian operator
for solving nonlinear engineering optimization problems. <em>EAAI</em>,
<em>124</em>, 106549. (<a
href="https://doi.org/10.1016/j.engappai.2023.106549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teaching Learning Algorithm (TLA) is a recently developed nature-inspired optimization technique applicable to complex optimization problems. This paper proposes an improved TLA version using the Laplacian operator of the Genetic Algorithm (GA), named LX-TLA. The proposed algorithm is tested on benchmark optimization problems, including unimodal and multimodal problems. The numerical results are obtained in the form of objective function values, and a t-test is applied to compare the performance of LX-TLA and basic TLA. Convergence plots are given to provide insight into the convergence behavior of LX-TLA. The results reveal that proposed algorithm provides effective and efficient performance in solving benchmark test functions. The proposed algorithm is also applied to engineering design problems, such as Tuned Mass Damper (TMD), truss structure, welded beam, tension string, and pressure vessel. The results obtained using LX-TLA are compared with other nature-inspired optimization algorithms. The results demonstrate that the proposed algorithm is a robust and effective tool for solving complex optimization problems.},
  archive      = {J_EAAI},
  author       = {Vanita Garg and Kusum Deep and Sahil Bansal},
  doi          = {10.1016/j.engappai.2023.106549},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106549},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved teaching learning algorithm with laplacian operator for solving nonlinear engineering optimization problems},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple-signal defect identification of hydraulic pump
using an adaptive normalized model and s transform. <em>EAAI</em>,
<em>124</em>, 106548. (<a
href="https://doi.org/10.1016/j.engappai.2023.106548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Axial piston pump plays a pivotal role in a hydraulic transmission system since it can supply the core power source. The complexity of structure and the invisibility of failure feature bring more difficulties and challenges to fault identification of an axial piston pump. It is of great meaning to exploit an effective and feasible fault identification method for the safe and stable system operation. An improved convolutional neural network (CNN) is constructed by mining and utilizing the interdisciplinary advantages of artificial intelligence and machinery engineering. First, the modeling takes the batch normalization strategy into account due to its capability of decreasing the data distribution differences. Second, Bayesian algorithm is used for intelligent tuning of hyperparameters. Third, the improved CNN is applied to fault identification based on the S transform of multiple source signals. The performance of the proposed method is demonstrated by the experiments on an axial piston pump. The identification accuracies based on three signals reach 88.17%, 95.94%, and 99.44%. Results show that it can automatically recognize typical faults of the axial piston pump, and present the superiority to common CNNs.},
  archive      = {J_EAAI},
  author       = {Yong Zhu and Shengnan Tang and Shouqi Yuan},
  doi          = {10.1016/j.engappai.2023.106548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple-signal defect identification of hydraulic pump using an adaptive normalized model and s transform},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Unsupervised image-to-image translation in multi-parametric
MRI of bladder cancer. <em>EAAI</em>, <em>124</em>, 106547. (<a
href="https://doi.org/10.1016/j.engappai.2023.106547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of muscular invasive bladder cancer (MIBC) is critical for surgical selection of bladder cancer (BCa) patients. Currently, multi-parameter magnetic resonance imaging (mp-MRI) is the predominant approach for identifying MIBC. However, mp-MRI is still insufficient due to the presence of noise and artifacts. Our research aims to synthesize images from the existing sequences of mp-MRI to substitute missing or low signal-to-noise ratio sequences through image-to-image (I2I) translation. Using mp-MRI images of 255 BCa patients collected in our department, we here propose a one-to-many unsupervised I2I translation network with region-wise semantic enhancement to synthesize virtual samples. We introduce an improved adaptive instance normalization module to support the generator for synthesizing multi-domain images. In addition, a branch for region-wise semantic segmentation helps the generator to enhance the quality of image translation for a specific region. A semantically consistent loss is applied to maintaining the consistency between the synthesized and the input images via region-wise semantic segmentation. Experiments on the BraTS and BCa datasets indicate that our I2I translation approach outperforms several state of the art methods. Additionally, we perform clinical feasibility tests using the synthesis images. The clinicians reach a consensus between the Vesical Imaging Reporting and Data System (VI-RADS) scoring results from the synthesized and the real mp-MRI images. In addition, after the BCa training set has been expanded using the proposed generation model, the accuracy of the BCa muscular invasion classification is improved from 77.78% to 85.19%.},
  archive      = {J_EAAI},
  author       = {Zhiying Chen and Lingkai Cai and Chunxiao Chen and Xue Fu and Xiao Yang and Baorui Yuan and Qiang Lu and Huiyu Zhou},
  doi          = {10.1016/j.engappai.2023.106547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised image-to-image translation in multi-parametric MRI of bladder cancer},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterising surface roughness of ti-6Al-4V alloy machined
using coated and uncoated carbide tools with variable nose radius by
machine learning. <em>EAAI</em>, <em>124</em>, 106546. (<a
href="https://doi.org/10.1016/j.engappai.2023.106546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rich literature explores how cutting parameters influence surface roughness in machining different materials using two- or three-dimensional visualisations. Research on Ti-6Al-4V alloy, an important but difficult-to-machine material, is relatively nascent. This research conducts real-life turning operations for Ti-6Al-4V alloy using coated and uncoated carbide inserts with different nose radii and subsequently applies ML techniques to simulate and characterise surface roughness (Ra) for varying cutting parameters — cutting speed (v), feed rate (f), depth of cut (d). Additionally, it presents an innovative visualisation of all three machining parameters’ influences on the surface roughness for Ti-6Al-4V alloy. The results identify Support Vector Machine (SVM) with RBF kernel as a highly potential ML approach to characterise the impact compared to SVM with linear kernel, Random Forest, Deep Learning, and ensemble approaches. The results also demonstrate, for a low feed rate and cutting speed, the surface roughness is better irrespective of the depth of cut and cutting tool materials. For coated carbide with a 0.40 mm nose radius and feed rate of 0.10 mm/rev, for example, Ra values stay within the range of 0.68 to 1.16 m μ for all experimented cutting speeds ranging from 50 m/min to 250 m/min. A similar outcome occurs for other cutting tools. The surface roughness tends to be higher for a higher feed rate. However, the Ra values can decrease even for a high feed rate if the cutting speed exceeds 200 m/min. Overall, the visualisation indicates a nonlinear relationship between machining parameters and surface roughness.},
  archive      = {J_EAAI},
  author       = {Abdul Md Mazid and Tasadduq Imam and Kazi Badrul Ahsan and Neamul Khandoker},
  doi          = {10.1016/j.engappai.2023.106546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Characterising surface roughness of ti-6Al-4V alloy machined using coated and uncoated carbide tools with variable nose radius by machine learning},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic support ratio of selected feature-based
information for feature selection. <em>EAAI</em>, <em>124</em>, 106544.
(<a href="https://doi.org/10.1016/j.engappai.2023.106544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection aims to select crucial features to improve classification accuracy in machine learning and data mining. Existing methods concentrate on the classification information from candidate features while seldom considering the changing information supported by selected features. In this paper, we construct a dynamic support ratio (DSR), which employs the new information of selected features to support classification. DSR explicitly describes the dynamic interactions between selected features and candidate features. Simultaneously, the feature relevance and feature redundancy are treated adaptively. Thus, distinctive features can be noticed sensitively. Afterward, a novel feature selection method based on a dynamic support ratio (DSRFS) is proposed. The proposed method is established on 18 benchmark data sets with four different classifiers. Classification accuracy, standard deviation, recall and statistical validations are employed to measure the classification performance. Extensive experiments demonstrate that DSRFS not only reduces the dimension of the feature space effectively, but also obtains the best average classification accuracy.},
  archive      = {J_EAAI},
  author       = {Shijie Zhao and Mengchen Wang and Shilin Ma and Qianqian Cui},
  doi          = {10.1016/j.engappai.2023.106544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic support ratio of selected feature-based information for feature selection},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GTSNet: Flexible architecture under budget constraint for
real-time human activity recognition from wearable sensor.
<em>EAAI</em>, <em>124</em>, 106543. (<a
href="https://doi.org/10.1016/j.engappai.2023.106543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition is an essential task for human-centered intelligent systems such as healthcare and smart vehicles, which can be accomplished by analyzing time-series signals collected from sensors in wearable devices. In these applications, real-time response is vital because prompt action is necessary for urgent events such as an elderly person falling or driving while drowsy. Although recurrent neural networks have been widely used owing to their temporal modeling capabilities, recent studies have focused on convolutional neural networks (CNNs) that are suitable for real-time responses because they incur lower computational costs. However, CNNs with a manual design may fail to achieve optimal accuracy due to varying computational budgets with applications or devices. In this paper, we propose a novel design framework that uses a mathematical approach to derive a CNN architecture suitable for a given computational budget. As a result, we introduce a grouped temporal shift network (GTSNet) with the network architecture to be flexibly modified by predefining the theoretical computation cost. We demonstrate the effectiveness of our framework in experiments, achieving the best performance for well-known public benchmark datasets under limited computational budgets. The source codes of the GTSNet are publicly available at https://github.com/jgpark92/GTSNet .},
  archive      = {J_EAAI},
  author       = {Jaegyun Park and Won-Seon Lim and Dae-Won Kim and Jaesung Lee},
  doi          = {10.1016/j.engappai.2023.106543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GTSNet: Flexible architecture under budget constraint for real-time human activity recognition from wearable sensor},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative adversarial networks driven by multi-domain
information for improving the quality of generated samples in fault
diagnosis. <em>EAAI</em>, <em>124</em>, 106542. (<a
href="https://doi.org/10.1016/j.engappai.2023.106542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of intelligent fault diagnosis models is often hindered by the lack of available samples, a common issue in both the few-shot learning and imbalanced learning problems. While data generation has been shown to be an effective strategy for addressing this issue, existing methods tend to focus solely on the similarity of the generated samples, overlooking their diversity. In this regard, a self-reasoning training strategy that enables the participation of highly reliable generated samples in the training process is proposed. By augmenting the training samples, the strategy provides the generation model with diverse input information, effectively enhancing the diversity of the samples generated by the model. To assess the reliability of the generated samples, Pearson correlation coefficient between the generated and real samples in the amplitude–frequency domain is utilized. To this end, an amplitude–frequency domain generation model is constructed. In order to avoid issues such as gradient disappearance and convergence degradation during the generation process in the amplitude–frequency domain, a phase-frequency domain generation model as well as a time domain discriminator model are developed. While the phase-frequency domain generation model enhances the diversity of the generated samples in that domain, the time domain discriminator model ensures sample similarity by correlating the amplitude–frequency domain generation model with the phase-frequency domain generation model. Through experiments, it is demonstrated that the proposed method can effectively address the overfitting problem of generative adversarial networks with few samples, improving the diversity of the generated samples. Moreover, the improvement in fault diagnosis performance achieved by the samples generated by the proposed method further underscores its potential and superiority in practical applications.},
  archive      = {J_EAAI},
  author       = {Zhijun Ren and Dawei Gao and Yongsheng Zhu and Qing Ni and Ke Yan and Jun Hong},
  doi          = {10.1016/j.engappai.2023.106542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generative adversarial networks driven by multi-domain information for improving the quality of generated samples in fault diagnosis},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Novel aczel-alsina operations-based linguistic z-number
aggregation operators and their applications in multi-attribute group
decision-making process. <em>EAAI</em>, <em>124</em>, 106541. (<a
href="https://doi.org/10.1016/j.engappai.2023.106541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The change from multi-attribute decision-making (MADM) to multi-attribute group decision-making (MAGDM) has led to a doubling of data volume and a trend toward multi-attribute large group decision-making. At this time, operators need to be used to integrate these data, while also reflecting the psychological impact of decision-makers. Linguistic Z-number (LZN) is widely used for evaluating fuzzy information due to its unique flexibility and accuracy. However, in the LZN environment, aggregation operators, as an important component of decision-making, also have some shortcomings. Some aggregation operators currently used in LZN environments have low flexibility, high computational complexity, and are not convenient. This article cleverly utilizes Aczel Alsina t-norm and t-norm to obtain some aggregation operators with good algebraic properties, and proves these properties, which can also reflect the psychological influence of decision-makers. On this basis, we obtained a MAGDM model and successfully applied it in the following example, comparing it with other operators and verifying its superiority.},
  archive      = {J_EAAI},
  author       = {Bo Chen and Qiang Cai and Guiwu Wei and Zhiwen Mo},
  doi          = {10.1016/j.engappai.2023.106541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel aczel-alsina operations-based linguistic Z-number aggregation operators and their applications in multi-attribute group decision-making process},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Delayed evolutionary game clustering-based recommendation
algorithm via latent information and user preference. <em>EAAI</em>,
<em>124</em>, 106535. (<a
href="https://doi.org/10.1016/j.engappai.2023.106535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation system is widely used because of its personalized service. It helps users obtain satisfactory results due to ambiguous expression in search engines. However, with the increasing number of users and items, most of the existing recommendation algorithms have problems of cold start, sparse data and high complexity. To address the above issues, this paper applies the rating information and attribute information of users and items to better represent the preferences of users and the activity of items by enriching the available information. Furthermore, we propose a novel game-based evolutionary clustering method to divide interest communities for users, which not only reduces the complexity of recommendation, but also takes full account of users’ preferences. In addition, the impact of delayed information transmission on experimental performance is considered in the game-based evolutionary clustering. Since the calculation of similarity plays a significant role in finding the nearest neighbors of target users in the community, we propose a new similarity measurement strategy based on user preferences. Finally, the effectiveness of the proposed algorithm is verified by ablation experiment and comparison experiments. The experimental results illustrate that our algorithm outperforms the existing excellent algorithms.},
  archive      = {J_EAAI},
  author       = {Jianrui Chen and Tingting Zhu and Qilao Zha and Zhihui Wang},
  doi          = {10.1016/j.engappai.2023.106535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Delayed evolutionary game clustering-based recommendation algorithm via latent information and user preference},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart mobile robot fleet management based on hierarchical
multi-agent deep q network towards intelligent manufacturing.
<em>EAAI</em>, <em>124</em>, 106534. (<a
href="https://doi.org/10.1016/j.engappai.2023.106534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of intelligent manufacturing era, smart mobile robots have taken the major roles on transporting materials through intelligent dynamic production environment. It is paramount to efficiently manage the mobile robot fleet to complete the material transportation task so as to facilitate the smooth production in the workshop. However, many mobile robot fleet management systems adopt centralized control where the interaction between mobile robots and other resources cannot be updated promptly, and the in-time dynamic environment variance cannot be considered. To cope with the unexpected real-time change of the system, reinforcement learning (RL) method is suggested to handle the problem. To overcome the sparse reward problem of RL, we propose a hierarchical multi-agent deep Q network (HMDQN) algorithm of a two-layer structure, in which the goal layer is controlled by a main controller for selecting a current goal and the sub controller from action layer is for coordinating multi-agent controlled smart mobile robots. The main controller is aimed at learning how to determine the current goal based on the order status and production states. Simultaneously, the sub controller is learning to seek an optimal way that the smart mobile robot fleet jointly executes the transportation tasks through the information exchange between robot agent and production environment under the current goal. A smart mobile robot fleet management case in a PCBA company is studied to validate the feasibility of our approach. In addition, we utilized alternative methods to solve the same problem and compared the performance to prove our approach’s superiority. Furthermore, we demonstrated the adaptability of the proposed method by changing the problem scales.},
  archive      = {J_EAAI},
  author       = {Yue Bai and Yaqiong Lv and Jiatong Zhang},
  doi          = {10.1016/j.engappai.2023.106534},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106534},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Smart mobile robot fleet management based on hierarchical multi-agent deep q network towards intelligent manufacturing},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method of knowledge distillation based on feature fusion
and attention mechanism for complex traffic scenes. <em>EAAI</em>,
<em>124</em>, 106533. (<a
href="https://doi.org/10.1016/j.engappai.2023.106533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detectors based on deep learning can run smoothly on a terminal device in complex traffic scenes, and the model compression method has become a research hotspot. Considering student network single learning in the knowledge distillation algorithm, the dependence on loss function design leads to parameter sensitivity and other problems, we propose a new knowledge distillation method with second-order term attention mechanisms and feature fusion of adjacent layers. First, we build a knowledge distillation framework based on YOLOv5 and propose a new attention mechanism in the teacher network backbone to extract the hot map. Then, we combine the hot map features with the next level features through the fusion module. By fusing the useful information of the low convolution layer and the feature map of the high convolution layer to help the student network obtain the final prediction map. Finally, to improve the accuracy of small objects, we add a 160 × 160 detection head and use a transformer encoder block module to replace the convolution network of the head. Sufficient experimental results show that our method achieves state-of-the-art performance. The speed and number of parameters remain unchanged, but the average detection accuracy is 97.4% on the KITTI test set. On the Cityscapes test set, the average detection accuracy reaches 92.7%.},
  archive      = {J_EAAI},
  author       = {Cui-jin Li and Zhong Qu and Sheng-ye Wang},
  doi          = {10.1016/j.engappai.2023.106533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A method of knowledge distillation based on feature fusion and attention mechanism for complex traffic scenes},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BLEDNet: Bio-inspired lightweight neural network for edge
detection. <em>EAAI</em>, <em>124</em>, 106530. (<a
href="https://doi.org/10.1016/j.engappai.2023.106530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge detection is fundamental to advanced computer vision tasks. Although deep learning-based methods can generate excellent results, they tend to be computationally expensive. To address this issue, researchers have explored the development of lightweight CNNs. Physiological studies have shown that there are two visual pathways in the biological visual system. The second visual pathway can modulate the first visual pathway, aiding the visual cortex in extracting edges from images more quickly. The inferior temporal cortex can integrate the edge signals extracted by the visual pathways and generate edges. Inspired by this, we designed a bio-inspired lightweight edge detection CNN, which includes an Encoder and a Decoder. The Encoder consists of a bio-inspired first visual pathway network and a bio-inspired second visual pathway network. The Decoder consists of a compact receptive field enhanced network. Specifically, the bio-inspired first visual pathway network can calculate the rate of change of image pixels. Through adaptive antagonism, signals with different rates of change are mutually suppressed. Meanwhile, the bio-inspired second visual pathway network can guide the bio-inspired first visual pathway network to focus more on the salient parts of the image. In addition, the receptive field-enhanced network can perceive image features distributed along specific directions, helping the decoder generate clearer edges. Our proposed method achieves competitive results on the BSDS500 dataset with ODS=0.805 and on the NYUD-v2 dataset with ODS = 0.757, while also having lower computational costs than most existing methods. Therefore, our approach is suitable for devices with lower computing capabilities.},
  archive      = {J_EAAI},
  author       = {Zhengqiao Luo and Chuan Lin and Fuzhang Li and Yongcai Pan},
  doi          = {10.1016/j.engappai.2023.106530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BLEDNet: Bio-inspired lightweight neural network for edge detection},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new CNN-LSTM architecture for activity recognition
employing wearable motion sensor data: Enabling diverse feature
extraction. <em>EAAI</em>, <em>124</em>, 106529. (<a
href="https://doi.org/10.1016/j.engappai.2023.106529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting representative features to recognize human activities through the use of wearables is an area of on-going research. While hand-crafted features and machine learning (ML) techniques have been sufficiently well investigated in the past, the use of deep learning (DL) techniques is the current trend. Specifically, Convolutional Neural Networks (CNNs), Long Short Term Memory Networks (LSTMs), and hybrid models have been investigated. We propose a novel hybrid network architecture to recognize human activities through the use of wearable motion sensors and DL techniques. The LSTM and the 2D CNN branches of the model that run in parallel receive the raw signals and their spectrograms, respectively. We concatenate the features extracted at each branch and use them for activity recognition. We compare the classification performance of the proposed network with three single and three hybrid commonly used network architectures: 1D CNN, 2D CNN, LSTM, standard 1D CNN-LSTM, 1D CNN-LSTM proposed by Ordóñez and Roggen, and an alternative 1D CNN-LSTM model. We tune the hyper-parameters of six of the models using Bayesian optimization and test the models on two publicly available datasets. The comparison between the seven networks is based on four performance metrics and complexity measures. Because of the stochastic nature of DL algorithms, we provide the average values and standard deviations of the performance metrics over ten repetitions of each experiment. The proposed 2D CNN-LSTM architecture achieves the highest average accuracies of 95.66% and 92.95% on the two datasets, which are, respectively, 2.45% and 3.18% above those of the 2D CNN model that ranks the second. This improvement is a consequence of the proposed model enabling the extraction of a broader range of complementary features that comprehensively represent human activities. We evaluate the complexities of the networks in terms of the total number of parameters, model size, training/testing time, and the number of floating point operations (FLOPs). We also compare the results of the proposed network with those of recent related work that use the same datasets.},
  archive      = {J_EAAI},
  author       = {Enes Koşar and Billur Barshan},
  doi          = {10.1016/j.engappai.2023.106529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new CNN-LSTM architecture for activity recognition employing wearable motion sensor data: Enabling diverse feature extraction},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). EORNet: An improved rotating box detection model for
counting juvenile fish under occlusion and overlap. <em>EAAI</em>,
<em>124</em>, 106528. (<a
href="https://doi.org/10.1016/j.engappai.2023.106528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The juvenile fish cultivation stage is a very critical stage in the aquaculture process, and real-time monitoring and statistics of the number of juvenile fish is very important for the management of the aquaculture process. However, there are small targets, occlusion, and overlapping phenomena in cultivation stage, which seriously hinder the accurate detection and counting of juvenile fish. Conventional horizontal box detection has the phenomenon of feature reuse between targets in the face of severe occlusion or overlap. Therefore, this study tried to use the rotating box detection model to explore its ability to solve occlusion and overlap problems. First of all, this study constructed a data set of two kinds of juvenile fish in the incubation stage (including Brocarded Carp and Carp). Secondly, on the basis of Oriented RepPoints, the ECA attention mechanism is introduced to strengthen the feature map output at the end of the backbone feature extraction network, and an improved rotation box detection model EORNet is obtained. Finally, based on EORNet, the actual modeling effects (counting) of rotation box and horizontal box are compared to further explore the advantages of rotation box in mitigating occlusion and overlap problems. The results showed that the Recall and Precision of the rotation box detection model in the detection task reached 0.978 and 0.905 respectively, and the R 2 of the counting model in the counting task reached 0.937. The rotating frame detection method has been proved to be superior to the horizontal frame detection method in mitigating occlusion and overlap problems, and the rotating box detection is more conducive to capturing the key feature information of the target object, and then achieving accurate prediction. In addition to counting, the rotating box detection method is also expected to be used to accurately estimate the length, width and weight of aquaculture objects in the process of aquaculture.},
  archive      = {J_EAAI},
  author       = {Pan Zhang and Liang Wang and Guangxu Wang and Daoliang Li},
  doi          = {10.1016/j.engappai.2023.106528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EORNet: An improved rotating box detection model for counting juvenile fish under occlusion and overlap},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-object tracking via deep feature fusion and
association analysis. <em>EAAI</em>, <em>124</em>, 106527. (<a
href="https://doi.org/10.1016/j.engappai.2023.106527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a tracking-by-detection framework for multi-object tracking (MOT). It first detects the objects of interest in each frame of the video, followed by identifying association with the object detected in the previous frame. A deep association network is described to perform object feature matching in the arbitrary two frames to infer association degree of objects, and then similarity matrix loss is used to calculate association between each object in different frames to achieve an accurate tracking. The novelty of the work lies in the design of a multi-scale fusion strategy by gradually concatenating sub-networks of low-resolution feature maps in parallel to the main network of high-resolution feature maps, in the construction of a deeper backbone network which can enhance the semantic information of object features, and in the use of a siamese network for training a pair of discontinuous frames. The main advantage of our framework is that it avoids missing detection and partial detection. It is particularly suitable for solving the problem of object ID switch caused by occlusion, entering and leaving of objects. Our method is evaluated and demonstrated on the publicly available MOT15, MOT16, MOT17 and MOT20 benchmark datasets. Compared with the state-of-the-art methods, our method achieves better tracking performance, and is therefore, more suited for MOT tasks.},
  archive      = {J_EAAI},
  author       = {Hui Li and Yapeng Liu and Xiaoguo Liang and Yongfeng Yuan and Yuanzhi Cheng and Guanglei Zhang and Shinichi Tamura},
  doi          = {10.1016/j.engappai.2023.106527},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106527},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-object tracking via deep feature fusion and association analysis},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intuitionistic fuzzy linear mathematical model to
determine the hybrid manufacturing system’s optimal operation condition.
<em>EAAI</em>, <em>124</em>, 106519. (<a
href="https://doi.org/10.1016/j.engappai.2023.106519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recycling of the used products collected by the manufacturing companies for recycling from their customers and their inclusion in the production system for remanufacturing has become an essential topic regarding sustainable production systems. Using parts and equipment in the remanufacturing system, especially in electronic products and products in the automotive sector, is preferred because of the opportunities to reduce costs and increase energy and workforce efficiency. In this article, we analyzed the management of a hybrid production system that processes new or returned materials in the manufacturing system. An intuitionistic fuzzy linear mathematical model is developed to demonstrate financial benefit and make decisions about using used parts in remanufacturing systems. Our study contributes to the literature by first adapting the magnitude function to the hybrid manufacturing and remanufacturing process optimization problem. Also, the innovative scope of the paper is expanded by applying IVITFN to the remanufacturing process optimization problem for the first time using comparative analysis. We consider relevant costs, the uncertainty about the number of returned products, demand, unit costs and unit production times, and capacity limitation in determining the optimal operation condition. The proposed model results show smaller cost values against other models in the literature.},
  archive      = {J_EAAI},
  author       = {Esra Dinler and Kumru Didem Atalay and Yusuf Tansel Ic},
  doi          = {10.1016/j.engappai.2023.106519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intuitionistic fuzzy linear mathematical model to determine the hybrid manufacturing system’s optimal operation condition},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defect engineering of fatigue-resistant steels by
data-driven models. <em>EAAI</em>, <em>124</em>, 106517. (<a
href="https://doi.org/10.1016/j.engappai.2023.106517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As inclusions are inevitable from the material-producing processes, an engineering concept regarding multiple features of them is needed for material design. In this study, a unique approach integrating physical-meaningful microstructure-sensitive models with the machine-learning-based data-driven model is proposed to reveal the complex relationship between the fatigue life of materials with intrinsic features of inclusions including size, stiffness, thermal properties, and extrinsic stress amplitudes. This high-fidelity presentation of the relation of these variables enables a detailed and systematic analysis of the effects of inclusions on fatigue life. The data-based phase map provides a designing envelope of inclusion features for fatigue-resistant steels.},
  archive      = {J_EAAI},
  author       = {Chao Gu and Yanping Bao and Sayoojya Prasad and Ziyu Lyu and Junhe Lian},
  doi          = {10.1016/j.engappai.2023.106517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Defect engineering of fatigue-resistant steels by data-driven models},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved variational mode decomposition for combined
imbalance-and-misalignment fault recognition and severity
quantification. <em>EAAI</em>, <em>124</em>, 106516. (<a
href="https://doi.org/10.1016/j.engappai.2023.106516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machines are among the most used equipment in industrial environments. Monitoring the machine’s parameters as well as predicting its failures are crucial tasks, as they mitigate production losses and avoid severe damage to the equipment. The combined fault scenario, where more than one fault occur simultaneously with different severity levels in the rotating machines, appears frequently in industry and it has been little investigated in the literature. In order to tackle the decomposition of mixed imbalance and misalignment faults, which are the most frequent in industry, it was proposed in this paper the Improved Variable Mode Decomposition (IVMD) technique, since VMD has shown to be not effective in adequately separating combined types of faults. The proposed automatic fault detection system joins a classifier capable of distinguishing imbalance and misalignment isolated faults from combined faults, independently from the rotating speed or severity fault level, with IVMD. It was developed using Support Vector Machine (SVM) applied to the features obtained from the vibration signature. First, the SVM classifier discriminates between healthy or fault signal, which can originate from individual or combined faults, and when the fault decomposition is required, the IVMD is applied. Subsequently, a continuous range severity level is estimated, based on the vibration signal velocity, allowing the contribution of each fault individually to the overall vibration level to be observed. The obtained results reveal that the devised SVM-based algorithm presents an accuracy of 95.43% in identifying from healthy, single and mixed imbalance and misalignment faults, and the IVMD approach accurately separates the faults.},
  archive      = {J_EAAI},
  author       = {Dionísio H.C.S.S. Martins and Amaro A. de Lima and Ricardo H.R. Gutiérrez and Denys Pestana-Viana and Sérgio L. Netto and Luiz A.P. Vaz and Eduardo A.B. da Silva and Diego B. Haddad},
  doi          = {10.1016/j.engappai.2023.106516},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106516},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved variational mode decomposition for combined imbalance-and-misalignment fault recognition and severity quantification},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal power distribution with mitigation of DC voltage
fluctuations using artificial intelligent droop control scheme for MTDC
grid. <em>EAAI</em>, <em>124</em>, 106515. (<a
href="https://doi.org/10.1016/j.engappai.2023.106515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal power share contribution with minimum DC voltage deviations is highly recommended in voltage source converter multi-terminal DC (VSC-MTDC). Hence, in this study, an artificial neural network based intelligent adaptive droop control proposes to enhance MTDC closed-loop system dynamics in terms of optimal power share and small redistribution of terminal DC voltages with negligible oscillations even in the presence of AC grid load demand change, admittance matrix uncertainty, outage of terminals and integration of wind farms. This is achieved via three-layer neural network and its weights are adaptively updated using error-back propagation algorithm. The asymptotic convergence of proposed control is derived using the Lyapunov’s stability theorem. Thus, the proposed intelligent adaptive droop control strategy not only guarantees to improve power share contribution with minimum voltage but also improved power quality and service continuity of MTDC grid. The robustness of proposed intelligent adaptive droop control is demonstrated on five terminal multi-terminal DC grid via MATLAB®.},
  archive      = {J_EAAI},
  author       = {Lokesh Garg and Sheetla Prasad},
  doi          = {10.1016/j.engappai.2023.106515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal power distribution with mitigation of DC voltage fluctuations using artificial intelligent droop control scheme for MTDC grid},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed global adaptive bipartite consensus of
multi-agent systems with signed communication topology structure.
<em>EAAI</em>, <em>124</em>, 106514. (<a
href="https://doi.org/10.1016/j.engappai.2023.106514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on designing a fully distributed adaptive fuzzy bipartite consensus control protocol for unknown nonlinear multi-agent systems with a class of undirected signed graph. Utilizing the fuzzy logical system universal approximator as a compensator to describe the uncertain nonlinear dynamics, a fully distributed adaptive fuzzy control protocol is proposed by means of re-parameterized approach and bounding technique, the global bipartite consensus of leader-following multi-agent systems without using any dynamics of the leader is proven via constructing a new Lyapunov function. The proposed protocol overcomes the drawback of the semi-global consensus in existing literature. Furthermore, as an extension of the former result, a bipartite formation control problem is also solved. Finally, the proposed methods are validated by simulation examples.},
  archive      = {J_EAAI},
  author       = {Junmin Li and Xue Yang and Yueying Li},
  doi          = {10.1016/j.engappai.2023.106514},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106514},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributed global adaptive bipartite consensus of multi-agent systems with signed communication topology structure},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DGFaceNet: Lightweight and efficient face recognition.
<em>EAAI</em>, <em>124</em>, 106513. (<a
href="https://doi.org/10.1016/j.engappai.2023.106513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition has achieved great success due to the development of deep convolutional neural networks (DCNNs). However, complex DCNNs bring a large number of parameters as well as computational effort, which poses a significant challenge to resource-constrained embedded devices. Meanwhile, the commonly popular loss functions and lightweight networks are not so effective for face recognition. In this paper, we first investigate the impact of the number of similar features generated by inexpensive operations on model performance. It is shown that DCNNs can tolerate more similar features generated by cheap operations in the early stage of the network. We construct Dynamic Ghost Bottleneck based on this idea, and DGFaceNet is composed of stacking Dynamic Ghost Bottleneck. In addition, we propose a new class-margin-linear softmax loss function (CML-softmax) for lightweight networks. CML-softmax designs a quadratic function to replace the cosine function as the target logit, which allows better performance and convergence in low-dimensional output for face recognition. Meanwhile, CML-softmax introduces two margin functions to alleviate class imbalance and softmax early saturation problems, respectively. Our method demonstrates competitive results in many validation datasets and large-scale popular benchmark tests. Speed tests on embedded devices show that the actual inference time of DGFaceNet is 11.08 times, 8.57 times, 2.75 times, and 2.82 times faster than ResNet-50, EfficientNet, MobileNetV2, and MobileFaceNet, respectively. DGFaceNet can significantly improve the running efficiency of the model in resource-constrained embedded devices while ensuring the model’s performance.},
  archive      = {J_EAAI},
  author       = {Feng Zhao and Peng Zhang and Ran Zhang and Mengwei Li},
  doi          = {10.1016/j.engappai.2023.106513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DGFaceNet: Lightweight and efficient face recognition},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KGCL: A knowledge-enhanced graph contrastive learning
framework for session-based recommendation. <em>EAAI</em>, <em>124</em>,
106512. (<a
href="https://doi.org/10.1016/j.engappai.2023.106512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based Recommendation (SBR) aims at predicting the next item based on a short-term anonymous user behavior, whose main challenge lies at the sparsity problem of user–item​ interactions. Graph contrastive learning, which discovers ground-truth samples by data augmentation, is a promising paradigm to tackle this problem. However, the following two insights are often overlooked by most of these contrastive learning-based models. First, item knowledge (i.e., item attributes, which can be distilled from open knowledge graphs) provides side information to model the complex high-order relations among items. Second, effective embedding aggregating mechanism is capable of filtering noisy preference signals (i.e., unrelated items) in sessions and retaining higher weight for the related items. These insights motivate us to construct an item attribute hypergraph to summarize associations among items that share common attributes and develop a Knowledge-enhanced Graph Contrastive Learning framework for session-based recommendation (KGCL). Technically, KGCL constructs two independent and complementary views (cross-session graph and item attribute hypergraph) in terms of user–item interactions sequence and item intrinsic attributes respectively, so as to explicitly capture both internal and external factors of items. Then, we encode item and session embeddings with a query-aware graph attention network and a hypergraph convolutional network over the above two views. Finally, we devise two contrastive learning loss — global–global contrastive learning and local–global contrastive learning — that maximize agreement between these two views and generate high-quality recommendation results. Extensive experiments conducted on three real-world datasets show KGCL has a higher expressive power that enables SBR to predict the next item.},
  archive      = {J_EAAI},
  author       = {Xiaohui Zhang and Huifang Ma and Fanyi Yang and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.engappai.2023.106512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {KGCL: A knowledge-enhanced graph contrastive learning framework for session-based recommendation},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven model for sustainable and resilient supplier
selection and order allocation problem in a responsive supply chain: A
case study of healthcare system. <em>EAAI</em>, <em>124</em>, 106511.
(<a href="https://doi.org/10.1016/j.engappai.2023.106511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research attempts to study the Supplier Selection and Order Allocation Problem (SSOAP) considering three crucial concepts, namely responsiveness, sustainability, and resilience. To do so, the current research develops a Multi-Stage Decision-Making Framework (MSDMF) to select potential suppliers and determine the quantity of orders. The first stage aims at computing the scores of the suppliers based on several indicators. To do this, a novel decision-making approach named the Stochastic Fuzzy Best–Worst Method (SFBWM) is developed. Then, in the second stage, a Multi-Objective Model (MOM) is suggested to deal with supplier selection and order allocation decisions. In the next step, a data-driven Fuzzy Robust Stochastic (FRS) optimization approach, based on the fuzzy robust stochastic method and the Seasonal Autoregressive Integrated Moving Average (SARIMA) methods, is employed to efficiently treat the hybrid uncertainty of the problem. Afterwards, a novel solution method named the developed Chebyshev Multi-Choice Goal Programming with Utility Function (CMCGP-UF) is developed to obtain the optimal solution. Moreover, given the crucial role of the Medical Equipment (ME) industry in society’s health, especially during the recent Coronavirus disease, this important industry is taken into account. The outcomes of the first stage demonstrate that agility, cost, GHG emission, quality, robustness, and Waste Management (WM), respectively, are the most important criteria. The outcomes of the second stage determine the selected suppliers, utilized transportation systems, and established sites. It is also revealed that demand directly affects all the objective functions while increasing the rate of disruptions has a negative effect on the sustainability measures.},
  archive      = {J_EAAI},
  author       = {Sina Nayeri and Mohammad Amin Khoei and Mohammad Reza Rouhani-Tazangi and Mohssen GhanavatiNejad and Mohammad Rahmani and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.engappai.2023.106511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven model for sustainable and resilient supplier selection and order allocation problem in a responsive supply chain: A case study of healthcare system},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Convex granules and convex covering rough sets.
<em>EAAI</em>, <em>124</em>, 106509. (<a
href="https://doi.org/10.1016/j.engappai.2023.106509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many extensions of rough sets have been trying to seek appropriate granular structures, such as neighborhood systems, disjoint intervals and coverings. However, few of them consider data-driven approaches to generating posets-structured coverings based on granules of irregular shapes and variable sizes. By generalizing norm granules (intervals, δ -neighborhoods and k -nearest neighbors), the present study proposes a tree-structured model whose information granules are obtained through an “onion-peeling” strategy, CrossSift. Two comparative experiments are conducted in this paper. One shows that granules generated by CrossSift are able to achieve a higher dependency degree with fewer numbers than equal width/frequency intervals, δ -neighborhoods and k -nearest neighbors. The other shows the trees output by CrossSift outperform SVC, KNN, AdaBoost, Cart, LDA in the average rank of classification accuracy. The proposed method bridges a gap between rough sets and perceptrons, and is expected to contribute to dimensionality reduction, computer vision and geometry.},
  archive      = {J_EAAI},
  author       = {Zhuo Long and Mingjie Cai and Qingguo Li and Yizhu Li and Wanting Cai},
  doi          = {10.1016/j.engappai.2023.106509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Convex granules and convex covering rough sets},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnosisformer: An efficient rolling bearing fault
diagnosis method based on improved transformer. <em>EAAI</em>,
<em>124</em>, 106507. (<a
href="https://doi.org/10.1016/j.engappai.2023.106507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of low accuracy and robustness of traditional deep learning fault diagnosis methods, a novel attention-based multi-feature parallel fusion model Diagnosisformer is proposed for rolling bearing fault diagnosis utilizing Transformer as the basic network. Firstly, frequency domain features of the original data are extracted by Fast Fourier Transform (FFT), and then normalization operations and embeddings are performed on the model input. Secondly, the designed multi-feature parallel fusion encoder is exploited to extract the local and global features of the bearing data. The extracted features are fed to a cross-flipped decoder, followed by a classification head for fault classification. Finally, experimental verification is performed using data collected by the rotating machinery fault diagnosis experimental platform and the Case Western Reserve University (CWRU) bearing dataset. The average experimental results on the two fault diagnosis datasets are 99.84% and 99.85%, respectively. The results show that our diagnosis method significantly outperforms the state-of-the-art in accuracy, generalization, and robustness.},
  archive      = {J_EAAI},
  author       = {Yandong Hou and Jinjin Wang and Zhengquan Chen and Jiulong Ma and Tianzhi Li},
  doi          = {10.1016/j.engappai.2023.106507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diagnosisformer: An efficient rolling bearing fault diagnosis method based on improved transformer},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive large neighborhood search based approach for the
vehicle routing problem with zone-based pricing. <em>EAAI</em>,
<em>124</em>, 106506. (<a
href="https://doi.org/10.1016/j.engappai.2023.106506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the classical vehicle routing problems, the objective function is usually to minimize the transportation cost without considering the pricing decision-making. However, in some practical applications, such as riding-share services and fast-food delivery services, logistics companies aim to maximize profits, involving decision-making issues closely related to the pricing and route planning. This paper designs an adaptive large neighborhood search (ALNS) based approach to solve a vehicle routing problem with zone-based pricing (VRPZ). In the studied problem, the customers in the same zone share the same price for transportation, and each customer could accept or reject the price given by the logistics company. On the one hand, a too-high pricing strategy may reduce the number of served customers; on the other hand, a too-low pricing strategy may result in low earnings for logistics companies. VRPZ optimizes the routing planning and seeks an appropriate pricing strategy to maximize the total profit, which is the difference value of total earnings and costs. Considering that the studied problem is a computational challenge, we have developed an algorithm incorporating the local search into ALNS, particularly nested with two varying pricing operators: price + + and price − − , to solve the problem. The proposed algorithm has been compared with pure ALNS, variable neighborhood search (VNS) and Simulated Annealing (SA) by solving 472 benchmark instances in the published work. The compared results, which are validated by the statistic tests, highlight the efficiency and effectiveness of the proposed algorithm. To our best knowledge, this is the first heuristic to achieve a good performance in solving the benchmark instances. This study is significant for the retail industry to find a reasonable logistics pricing strategy and improve operational efficiency, as well as lays a foundation for developing a decision support system.},
  archive      = {J_EAAI},
  author       = {Yong Shi and Wenheng Liu and Yanjie Zhou},
  doi          = {10.1016/j.engappai.2023.106506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive large neighborhood search based approach for the vehicle routing problem with zone-based pricing},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid approach based on dual hesitant q-rung orthopair
fuzzy frank power partitioned heronian mean aggregation operators for
estimating sustainable urban transport solutions. <em>EAAI</em>,
<em>124</em>, 106505. (<a
href="https://doi.org/10.1016/j.engappai.2023.106505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation systems are a key part of sustainable development, and they need to be carefully evaluated to show that they have a strong impact on the target area’s social, environmental, and economic sustainability. For this reason, involving the developed decision support systems helps to shed light on the users’ demand and provide unblemished policy decisions considering the existing situation. The “ q -rung orthopair fuzzy set ( q -ROFS)” is a generalization of the “intuitionistic fuzzy sets (IFSs)” and “Pythagorean fuzzy sets (PFSs)” that expresses vague and uncertain data more efficiently. In the interim, the notion of “dual hesitant q -rung orthopair fuzzy set (DH q -ROFS)” is presented to account for human hesitancy, which may be more applicable to genuine “multicriteria group decision-making (MCGDM)” situations. The main goal of this study is to address MCGDM problems using Heronian mean (HM) and DH q -ROF data. The first step is to introduce the Frank t -norm and t -conorm-based DH q -ROF HM (DH q -ROFFHM) operator. DH q -ROFFHM’s features are next described in depth. In addition, the DH q -ROF Frank weighted HM (DH q -ROFFWHM) operator is presented, which takes into account different degrees of liking for input arguments. The DH q -ROF Frank weighted power partitioned HM model is then used to come up with a way to solve models in MCGDM problems where individual arguments are grouped together and have relationships with each other. A final example shows how the established model can be implemented and how well it works.},
  archive      = {J_EAAI},
  author       = {Arun Sarkar and Sarbast Moslem and Domokos Esztergár-Kiss and Muhammad Akram and LeSheng Jin and Tapan Senapati},
  doi          = {10.1016/j.engappai.2023.106505},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106505},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid approach based on dual hesitant q-rung orthopair fuzzy frank power partitioned heronian mean aggregation operators for estimating sustainable urban transport solutions},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuously evolving dropout with multi-objective
evolutionary optimisation. <em>EAAI</em>, <em>124</em>, 106504. (<a
href="https://doi.org/10.1016/j.engappai.2023.106504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dropout is an effective method of mitigating over-fitting while training deep neural networks (DNNs). This method consists of switching off (dropping) some of the neurons of the DNN and training it by keeping the remaining neurons active. This approach makes the DNN general and resilient to changes in its inputs. However, the probability of a neuron belonging to a layer to be dropped, the ’dropout rate’, is a hard-to-tune parameter that affects the performance of the trained model. Moreover, there is no reason, besides being more practical during parameter tuning, why the dropout rate should be the same for all neurons across a layer. This paper proposes a novel method to guide the dropout rate based on an evolutionary algorithm. In contrast to previous studies, we associate a dropout with each individual neuron of the network, thus allowing more flexibility in the training phase. The vector encoding the dropouts for the entire network is interpreted as the candidate solution of a bi-objective optimisation problem, where the first objective is the error reduction due to a set of dropout rates for a given data batch, while the second objective is the distance of the used dropout rates from a pre-arranged constant. The second objective is used to control the dropout rates and prevent them from becoming too small, hence ineffective; or too large, thereby dropping a too-large portion of the network. Experimental results show that the proposed method, namely GADropout, produces DNNs that consistently outperform DNNs designed by other dropout methods, some of them being modern advanced dropout methods representing the state-of-the-art. GADroput has been tested on multiple datasets and network architectures.},
  archive      = {J_EAAI},
  author       = {Pengcheng Jiang and Yu Xue and Ferrante Neri},
  doi          = {10.1016/j.engappai.2023.106504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continuously evolving dropout with multi-objective evolutionary optimisation},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault-tolerant design of non-linear iterative learning
control using neural networks. <em>EAAI</em>, <em>124</em>, 106501. (<a
href="https://doi.org/10.1016/j.engappai.2023.106501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of neural-network-based iterative learning control for non-linear systems is addressed in the setting of a fault tolerant control regime. Taking advantage of the repetitive character of the control task, the inherent uncertainty related to a potential faulty system state can be properly accommodated in terms of a data-driven iterative learning scheme with neural networks used for forward/inverse modeling as well as for controller synthesis. The resulting control technique is supposed to be flexible enough to accurately compensate the faults occurring on both the sensors and actuators and, additionally, take into account the disturbances and noise acting on the system. A complete characterization of the novel fault-tolerant iterative learning scheme is provided including system identification, fault detection and accommodation. Also, the painstaking convergence analysis is presented and the resulting sufficient conditions can be constructively used to determine the update of control law in the consecutive process trial. The excellent performance of the developed control scheme is illustrated by a nontrivial example of tracking control for a magnetic brake system on various scenarios involving actuator and/or sensor faults.},
  archive      = {J_EAAI},
  author       = {Krzysztof Patan and Maciej Patan},
  doi          = {10.1016/j.engappai.2023.106501},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106501},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault-tolerant design of non-linear iterative learning control using neural networks},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GTRF: A general deep learning framework for tuples
recognition towards supervised, semi-supervised and unsupervised
paradigms. <em>EAAI</em>, <em>124</em>, 106500. (<a
href="https://doi.org/10.1016/j.engappai.2023.106500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tuple, featured as sequences of elements are regarded as one of the most predominant data forms in structural health monitoring (SHM). Activated by powerful capabilities of deep learning (DL) techniques, the DL-driven tuple recognition regime has facilitated plenty of problems settlement in SHM practice by mapping tuples with structural patterns, whereas the determined feature extraction strategies, designated network architectures and specified learning schemas (i.e., supervision paradigms) degrade severely to the model’s transferability and generalizability. Thereby, this study devises a novel General Tuple Recognition Framework (GTRF) towards supervised (SL), unsupervised (UL) and semi-supervised learning (SSL) paradigms. In the framework, pattern-sensitive features (PSFs) are quantitatively defined via a novel feature extractor intervened by deep autoencoder for downstream label propagation via an optimized fuzzy clustering algorithm in SL, UL and SSL paradigms. With sophisticated networks integrated and exquisite novelties embedded, the proposed GTRF is competent for various tuple recognition tasks in diverse learning paradigms regardless of the measurement types or lengths. Multi-level experimental tasks implementation representative in SHM scope were conducted for validations, varying in vibration SL-recognition of a prototype skyscraper, damage UL-detection of a laboratory RC beam and condition SSL-assessment of a full-scale building model. The results comprehensively confirmed the effectiveness and generality of proposed GTRF as well as comparable superiority in recognition accuracy and model adaptability. With flexible paradigm specialization, broad application and great space for optimization, the proposed GTRF framework can promisingly be a prototype for bridging the gap for DL algorithms fusion and models integration of different learning paradigms.},
  archive      = {J_EAAI},
  author       = {Qingsong Xiong and Cheng Yuan and Bin He and Haibei Xiong and Qingzhao Kong},
  doi          = {10.1016/j.engappai.2023.106500},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106500},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GTRF: A general deep learning framework for tuples recognition towards supervised, semi-supervised and unsupervised paradigms},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-filter semi-supervised transformer model for fault
diagnosis. <em>EAAI</em>, <em>124</em>, 106498. (<a
href="https://doi.org/10.1016/j.engappai.2023.106498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dissolved Gas Analysis (DGA) is the most commonly used method for power transformer fault diagnosis. However, very few reliable and labeled fault DGA samples are available in the transformer substation whilst DGA data without labels is easier to obtain, which makes it difficult to train fault detectors in high-dimensional input space or select features using wrapper methods. Therefore, in order to improve the fault diagnosis accuracy using limited labeled DGA samples but more unlabeled DGA data, this paper proposes a novel multi-filter semi-supervised feature selection method for selecting optimal DGA features and building effective fault diagnosis models. A confidence criterion is also proposed for selecting high confidence unlabeled data to expand the training data set. Five filter techniques based on different evaluation criteria are employed to rank input DGA features, and a feature combination method is then applied to aggregate feature ranks by multiple filters and form a lower-dimensional candidate feature subset. The proposed method has been tested by using the IEC T10 dataset and compared with traditional supervised diagnostic models. The results show that the proposed method works well in optimizing DGA features and improving fault diagnosis accuracy significantly. Besides, the robustness of the selection of optimal feature subset is validated by testing DGA samples from the local power utility.},
  archive      = {J_EAAI},
  author       = {Xuemin Tan and Jun Qi and John Q. Gan and Jianglin Zhang and Chao Guo and Fu Wan and Ke Wang},
  doi          = {10.1016/j.engappai.2023.106498},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106498},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-filter semi-supervised transformer model for fault diagnosis},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). G2IFu: Graph-based implicit function for single-view 3D
reconstruction. <em>EAAI</em>, <em>124</em>, 106493. (<a
href="https://doi.org/10.1016/j.engappai.2023.106493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for 3D models increases, there is growing interest in reconstructing 3D objects from images using AI. In this paper, we propose G2IFu, a graph-based implicit function that successfully reconstructs a highly detailed 3D object mesh from a single image. Unlike previous methods that learn implicit functions with points, G2IFu aims to map graphs to implicit values. We make the following contributions: (1) Compared to independent 3D points, graphs have a larger perception space and contain specific spatial structure information. Therefore, we extend a 3D point p to a graph G p by generating hypothesis points and establishing edges between them. We then predict the corresponding implicit value using a graph convolution network. Our experiments show that this method can effectively improve the prediction accuracy of implicit functions. (2) We introduce a prior boundary loss based on G p to make the network pay more attention to the “key” points near the shape surface. To the best of our knowledge, G2IFu is the first model that introduces a graph into neural implicit representation. (3) Inspired by previous methods, we utilize the image’s global and local features to initialize G p . We also introduce a self-attention module into G2IFu for better performance. We conduct experiments on the ShapeNet dataset and demonstrate that G2IFu can generate higher-quality 3D object shapes than previous single-view reconstruction methods. Additionally, we extend G2IFu to multi-view 3D reconstruction and achieve good performance.},
  archive      = {J_EAAI},
  author       = {Rongshan Chen and Yuancheng Yang and Chao Tong},
  doi          = {10.1016/j.engappai.2023.106493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {G2IFu: Graph-based implicit function for single-view 3D reconstruction},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient SMD-PCBA detection based on YOLOv7 network
model. <em>EAAI</em>, <em>124</em>, 106492. (<a
href="https://doi.org/10.1016/j.engappai.2023.106492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern Printed Circuit Board Assembly (PCBA) manufacturing processes require more accurate and robust defect inspection methods. Despite the potential of deep learning algorithms in PCBA defect detection, their ability to handle environmental factors and multi-modal data is still limited. To overcome this, we propose an improved YOLOv7-based network model that enhances the detection performance of densely distributed multi-size Surface Mount Devices (SMD) in multi-modal PCBA. Specifically, the proposed model enhances feature representation by designing a detection head based on Coordinate Attention, and incorporates feedback connections in the feature fusion stage to improve feature recognition through low-level propagation. Additionally, we propose the SEIoU loss function to calculate position loss between the prediction box and the ground truth, resulting in superior regression accuracy of the anchor box and improved detection accuracy. We validate the effectiveness and improvement of our proposed method through ablation experiments and algorithm comparison. Our proposed model outperforms the baseline YOLOv7 model with a 2.1% increase in mAP@0.5 for the multi-modal PCBA dataset and a 4.5% increase in mAP@0.5:0.95 for the VOC 2012 dataset, and a 1.0% increase in mAP@0.5:0.95 for the COCO 2017 dataset. Our study’s results suggest that our proposed model is a promising alternative to existing methods for detecting PCBA defects, as it accurately detects multiple tiny components amidst complex backgrounds, effectively identifies diverse types of defects, and remains lightweight.},
  archive      = {J_EAAI},
  author       = {Zhijin Li and Jinfeng Yan and Jie Zhou and Xiaozhen Fan and Jiahui Tang},
  doi          = {10.1016/j.engappai.2023.106492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient SMD-PCBA detection based on YOLOv7 network model},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Res-HSA: Residual hybrid network with self-attention
mechanism for RUL prediction of rotating machinery. <em>EAAI</em>,
<em>124</em>, 106491. (<a
href="https://doi.org/10.1016/j.engappai.2023.106491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction is of great significance for improving maintenance efficiency and ensuring the reliability of rotating machinery. In recent years, there are a large number of deep-learning-based methods for RUL prediction of rotating machinery. However, the effect of conventional end-to-end RUL prediction methods relies on the distribution consistency of training data and test data, and conventional health indicator extrapolation RUL prediction methods are susceptible to interference from abnormal fluctuations in the health curve. To overcome the problem, this paper proposes a new RUL prediction method for rotating machinery using health indicators constructed by the residual hybrid network with self-attention mechanism (Res-HSA). First of all, we propose the residual hybrid network combined with self-attention mechanism to extract the high-level degenerate feature. Then, the health assessment model based on Res-HSA is proposed to generate the health indicators of the equipment. To assist in network training, the segmented data labels based on the degradation rule are applied to optimize the labels of training sets. Finally, to address the problem of abnormal fluctuations in the health curve, a fitting interval selection method is used to optimize conventional curve fitting schemes to calculate RUL. Two public datasets, IEEE-PHM-2012-challenge datasets and C-MAPSS datasets, are used to verify the effectiveness of the proposed method. The experiment results on two public datasets show that the RUL prediction method proposed in this paper has good prediction performance. Compared to the state-of-the-art method, the method proposed in this article reaches the most advanced level in some test projects, while the rest of the projects can be very close to the most advanced method.},
  archive      = {J_EAAI},
  author       = {Junjun Zhu and Quansheng Jiang and Yehu Shen and Fengyu Xu and Qixin Zhu},
  doi          = {10.1016/j.engappai.2023.106491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Res-HSA: Residual hybrid network with self-attention mechanism for RUL prediction of rotating machinery},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive policy learning for data-driven powertrain control
with eco-driving. <em>EAAI</em>, <em>124</em>, 106489. (<a
href="https://doi.org/10.1016/j.engappai.2023.106489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern powertrain control design practices rely on model-based approaches accompanied by costly calibrations in order to meet ever stringent energy use and emissions targets specified for standardized drive cycles. These practices struggle to capture the complexity and uncertainty of real-world driving. However, the deluge of operational data now available with connected vehicle technology presents opportunities to foster data-driven control design methods that adapt the powertrain control systems to their field use conditions. While the most attractive of these methods is reinforcement learning (RL), it is rarely directly applicable in physical applications due to its challenges of learning efficiency (sample complexity) and guaranteeing safety. In this paper, we propose and evaluate an adaptive policy learning (APL) framework that leverages existing source policies shipped with vehicles to accelerate initial learning while recovering the asymptotic performance of a reinforcement learning-based powertrain control agent trained from scratch. We present a critique of related residual policy learning approaches and detail our algorithmic implementations for two versions of the proposed framework. We find that the APL powertrain control agents offer in the order of 10% fuel economy improvement over a default powertrain controller of a commercial vehicle without compromising driver accommodation metrics. We demonstrate that the APL frameworks offer a viable approach towards potentially applying RL for real-world scenarios by addressing its learning efficiency issues.},
  archive      = {J_EAAI},
  author       = {Lindsey Kerbel and Beshah Ayalew and Andrej Ivanco},
  doi          = {10.1016/j.engappai.2023.106489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive policy learning for data-driven powertrain control with eco-driving},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monolingual, multilingual and cross-lingual code comment
classification. <em>EAAI</em>, <em>124</em>, 106485. (<a
href="https://doi.org/10.1016/j.engappai.2023.106485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code comments are one of the most useful forms of documentation and metadata for understanding software implementation. Previous research on code comment classification has focused only on comments in English, typically extracted from a few programming languages. This paper addresses the problem of code comment classification not only in the monolingual setting, but also in the multilingual and cross-lingual one, in order to examine whether they can outperform the traditional monolingual approach. To tackle this task, we introduce a novel, publicly available code comment dataset, consisting of over 10,000 code comments collected from software projects written in eight programming languages (C, C++, C#, Java, JavaScript/TypeScript, PHP, Python, and SQL). About half of them are written in Serbian while the other half are written in English. This dataset was manually annotated according to a newly proposed taxonomy of code comment categories. We fine-tune and evaluate multiple monolingual and multilingual pre-trained neural language models on the code comment classification task and compare their performances to several baselines. The best results for Serbian comments are obtained using the monolingual neural model BERTić, trained on Serbian and closely related languages. On the other hand, the optimal choice for English is the multilingual neural model multilingual BERT, which successfully extracts useful patterns from data in both languages. Although the cross-lingual setting shows some promise for simple binary classification, it has yet to reach sufficiently high performance levels for practical use. We also analyze model performance across different programming languages.},
  archive      = {J_EAAI},
  author       = {Marija Kostić and Vuk Batanović and Boško Nikolić},
  doi          = {10.1016/j.engappai.2023.106485},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106485},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Monolingual, multilingual and cross-lingual code comment classification},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ECG-NET: A deep LSTM autoencoder for detecting anomalous
ECG. <em>EAAI</em>, <em>124</em>, 106484. (<a
href="https://doi.org/10.1016/j.engappai.2023.106484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrocardiogram (ECG) is a standard test to monitor the activity of the heart. Many cardiac abnormalities are manifested in the ECG including arrhythmia that refers to an abnormal heart rhythm. The basis of arrhythmia diagnosis is the identification of normal versus abnormal heart beats, and their correct classification based on ECG morphology. This paper proposes a novel and robust approach for representation learning of ECG sequences using a LSTM autoencoder for anomaly detection. The encoder part encodes the ECG signal into a lower dimensional latent space representation and decoder part then tries to reconstruct the specified ECG signal. The model is trained only on normal (non-anomalous) ECG signals. Then reconstruction loss of test ECG signals are calculated. Next a reconstruction loss threshold value is determined from the frequency distribution of the reconstruction losses so that from the reconstruction loss value above a certain threshold is determined as anomaly, otherwise it will be treated as normal. Determination of threshold is done using manual and Kapur’s automated thresholding procedures. The aforementioned model has been applied on publicly available ECG5000 dataset. From the experimental results it is observed that the proposed model achieved more than 98% accuracy having precision, recall and F1 values more than 0.94, 0.97, 0.96 respectively. The performance of the proposed method is also found to be superior in most of the cases as compared to the results of seven other recent counter-part methods reported in the literature.},
  archive      = {J_EAAI},
  author       = {Moumita Roy and Sukanta Majumder and Anindya Halder and Utpal Biswas},
  doi          = {10.1016/j.engappai.2023.106484},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106484},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ECG-NET: A deep LSTM autoencoder for detecting anomalous ECG},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trainable guided attention based robust leather defect
detection. <em>EAAI</em>, <em>124</em>, 106438. (<a
href="https://doi.org/10.1016/j.engappai.2023.106438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic leather defect detection is becoming increasingly important as a crucial requirement for industry 4.0. It is a highly challenging problem due to the varying appearance and characteristics of various defect types. The diversified scale and spatial position of the defects, and high intra-class variance in addition to inter-class similarity, make the problem highly challenging. A novel optimized backbone network that uses reduced filters to extract global semantic information for defect detection. The feature pyramid network capture defects of different sizes, the spatial attention focuses the detector on precise defect locations, whereas the cross-channel guidance along with channel attention aid the network to discriminate between defects of similar and different classes. The current state bounding box regression methods are employed in conjunction with the proposed OAFE module for precise object localization.},
  archive      = {J_EAAI},
  author       = {Masood Aslam and Syed Saud Naqvi and Tariq Mahmood Khan and Geoff Holmes and Rafea Naffa},
  doi          = {10.1016/j.engappai.2023.106438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trainable guided attention based robust leather defect detection},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Digital twin-enabled 3D printer fault detection for smart
additive manufacturing. <em>EAAI</em>, <em>124</em>, 106430. (<a
href="https://doi.org/10.1016/j.engappai.2023.106430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early failure detection is required for Fused Deposition Modelling (FDM) 3D printers to reduce material waste. Typically, such systems are created based on images captured during printing or sensor data for tracking the extruder’s movement. This work presents a novel approach to sensor data-driven fault diagnosis, utilizing Artificial Intelligence (AI) technology to investigate the temperature imbalance in the extruder and printing surface. First, a Lightweight Convolutional Neural Network (LCNN) is proposed to detect faults from sensory data. The model’s architecture concatenates the CNN layer to extract additional features, improving the model’s performance while maintaining a lightweight configuration suitable for real-time monitoring systems. Second, the concept of Digital Twin (DT) technology for FDM 3D printer fault detection is introduced. The DT creates a virtual representation of a physical object, and its functionality is validated by examining the network’s latency and System Overhead (SO) as the number of clients increases. The simulation results show that the proposed LCNN with a DT environment can effectively monitor, detect, and control the physical workplace with an F1-Score of 0.9981 and an average latency of 995 . 4253 ms . Additionally, this research contributes to the development of future technologies for virtual condition monitoring of 3D printer abnormalities, which will be essential for intelligent and autonomous factories.},
  archive      = {J_EAAI},
  author       = {Syifa Maliah Rachmawati and Made Adi Paramartha Putra and Jae Min Lee and Dong Seong Kim},
  doi          = {10.1016/j.engappai.2023.106430},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106430},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Digital twin-enabled 3D printer fault detection for smart additive manufacturing},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Safety evaluation of buildings adjacent to shield
construction in karst areas: An improved extension cloud approach.
<em>EAAI</em>, <em>124</em>, 106386. (<a
href="https://doi.org/10.1016/j.engappai.2023.106386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To accurately evaluate the safety risk status of buildings adjacent to karst shield construction areas, a safety evaluation standard for buildings adjacent to shield construction in karst areas and a safety risk assessment method based on optimal cloud entropy are proposed. Comprehensive consideration of the tunnel characteristics, geological conditions, building conditions, construction, management and other influencing factors, a risk evaluation index system including 4 level-II indicators and 15 level-III indicators and evaluation criteria are established for buildings adjacent to shield construction in karst areas. The traditional extension cloud theory is improved based on the optimal cloud entropy calculation method for adaptive evaluation objects, and the clarity and fuzziness of index classification are considered. To verify the applicability of the proposed approach, it was applied to ten adjacent buildings in a karst geological section of Guiyang Rail transit Line 3. The results show that (a) the evaluation standard and the improved extended cloud safety risk assessment method proposed can effectively consider the uncertainty of risk events and that the evaluation results are consistent with the actual building safety risk status information with the calculated reliability factor of each building is close to 1. (b) The key risk factors are identified through sensitivity analysis. According to the key risk factors and risk statuses, effective measures can be taken, and high-risk buildings can be monitored to maintain a safe control state. Thus, the proposed approach can be feasibly used in various applications and can provide guidance for other similar projects.},
  archive      = {J_EAAI},
  author       = {Hongyu Chen and Sai Yang and Zongbao Feng and Yang Liu and Yawei Qin},
  doi          = {10.1016/j.engappai.2023.106386},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {106386},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safety evaluation of buildings adjacent to shield construction in karst areas: An improved extension cloud approach},
  volume       = {124},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic attention and relative scene depth-guided network
for underwater image enhancement. <em>EAAI</em>, <em>123</em>, 106532.
(<a href="https://doi.org/10.1016/j.engappai.2023.106532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, to solve unique underwater degradation challenges covering low contrast, color deviation and blurring, etc. , a novel semantic attention and relative scene depth-guided network (SARSDN) for underwater image enhancement is proposed. Main contributions are as follows: (1) By combining with diverse characteristics of red–green–blue, hue-saturation-value and Lab spaces, the multi-color space feature representation network (MSFRN) is elaborately developed, such that domain shifting can be effectively alleviated; (2) By utilizing position attention and devising multi-dilated-convolution depth perception unit, the underwater relative scene depth estimation network (URSDEN) is proposed to adapt attention weights to regions with different degrees of degradation, thereby exclusively accommodating scene depth-dependent attenuation and scattering; (3) The underwater scene semantic segmentation network (USSSN) is devised to estimate semantic attention map for reducing artifacts and increasing integrity of foreground objects during underwater image enhancement by virtue of encoder–decoder framework with deformable convolution network; and (4) The entire SARSDN scheme is ultimately created in a modular manner by integrating MSFRN, URSDEN and USSSN modules. Comprehensive experiments and comparisons thoroughly illustrate that the developed SARSDN framework outperforms typical underwater image enhancement approaches from both subjective and objective aspects, where UIQM scores are 0.8263, 0.9393, 1.1817, 0.5289, 0.6517, 0.5393, 0.7917 and 0.4651 higher than those of IBLA, ULAP, HLRP, UCM, RGHS, MLLE, UGAN and FUnIE-GAN schemes, respectively.},
  archive      = {J_EAAI},
  author       = {Tingkai Chen and Ning Wang and Yanzheng Chen and Xiangjun Kong and Yejin Lin and Hong Zhao and Hamid Reza Karimi},
  doi          = {10.1016/j.engappai.2023.106532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic attention and relative scene depth-guided network for underwater image enhancement},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TCGNN: Packet-grained network traffic classification via
graph neural networks. <em>EAAI</em>, <em>123</em>, 106531. (<a
href="https://doi.org/10.1016/j.engappai.2023.106531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network traffic classification is the fundamental and vital function for network management, network security and so on. With the traffic scenarios becoming more and more complex, current commonly used practices, e.g., port-based and payload-based classification methods, can hardly work. Even though the new emerging resorts, i.e., machine learning or deep learning methods, have increased classification accuracy, the performance is still under improvement. To improve the classification accuracy and performance, we propose a novel Graph Neural Network (GNN) based Traffic Classification proposal named TCGNN considering the insight of observing packets from a graph aspect. TCGNN first transforms each network packet into an undirected graph. Then it adopts a two-layer graph convolutional network with three different aggregation strategies so as to learn the latent application representation from the packet-transformed graph. Finally, relying on GNN’s powerful ability in learning graph representation, TCGNN can identify unknown network packets with an extremely high accuracy rate. Extensive experiments on two real-world traffic classification datasets demonstrate the superior effectiveness of TCGNN over the existing packet-grained traffic classification methods.},
  archive      = {J_EAAI},
  author       = {Guangwu Hu and Xi Xiao and Meng Shen and Bin Zhang and Xia Yan and Yunxia Liu},
  doi          = {10.1016/j.engappai.2023.106531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TCGNN: Packet-grained network traffic classification via graph neural networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A transformer condition recognition method based on
dissolved gas analysis features selection and multiple models fusion.
<em>EAAI</em>, <em>123</em>, 106518. (<a
href="https://doi.org/10.1016/j.engappai.2023.106518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent condition identification is the development trend of transformer condition recognition, However, the existing intelligent condition recognition has the disadvantage of single model and low recognition accuracy. In order to overcome the disadvantage, a transformer condition recognition method based on dissolved gas analysis features selection and multiple models fusion is proposed. At first, artificial bee colony (ABC) algorithm is employed to select a set of optimal dissolved gas analysis (DGA) features. Then, according to the selected feature set, support vector classifier (SVC) model, naive bayes classifier (NBC) model, and back-propagation neural network (BPNN) model are respectively established. Finally, the Dempster–Shafer​ (D-S) evidence theory is used to combine the output results of the three recognition models. The identification performances of the optimal DGA features set and the multiple models fusion are evaluated. The results reveal that the proposed method has the highest accuracy and consistency of 89.39% and 90.49% respectively. With the input vector of proposed optimal DGA features set, the overall performance of multiple model fusion method is superior than the SVC, NBC, BPNN, extreme learning machine (ELM) and K- Nearest-Neighbor (KNN). The accuracy and consistency are increased by 4.54%, 4.52%, and 10.42%, 14.68%, and 3.03%, 3.67%, and 10.6%, 13.45%, and 24.24%, 27.57% respectively. Also, the overall performance of multiple model fusion method with optimal DGA features set is increased significantly compared to multiple model fusion method with IEC Ratio, Rogers Ratio, Doernenburg Ratio, optimal DGA features set selected by particle swarm optimization (PSO) and harris hawks optimization (HHO). The accuracy and consistency are increased by 4.54%, 7.43%, and 6.06%, 7.33%, and 10.6%, 13.58%, and 1.51%, 1.39%, and 9.09%,10% respectively. This proves the effectiveness and the feasibility of the proposed method.},
  archive      = {J_EAAI},
  author       = {Xiaohui Han and Song Huang and Xu Zhang and Yingkuo Zhu and Guoqing An and Zhenbin Du},
  doi          = {10.1016/j.engappai.2023.106518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transformer condition recognition method based on dissolved gas analysis features selection and multiple models fusion},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultimate bearing capacity prediction method and sensitivity
analysis of PBL. <em>EAAI</em>, <em>123</em>, 106510. (<a
href="https://doi.org/10.1016/j.engappai.2023.106510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultimate bearing capacity of Perfobond leiste (PBL) is one of the key parameters to evaluate the bearing capacity and reliability of steel–concrete structures, and it is very important to predict the ultimate bearing capacity of PBL more accurately. Based on the improved cuckoo search algorithm (CS), two prediction model optimized by back propagation neural network (BPNN) algorithm and extreme learning machine (ELM) were proposed. The local search ability of CS algorithm was improved by the triangular mutation operator and the distance-based distributed discovery probability, and the global search ability was improved by multi-step selection strategy. The weight, threshold, number of input parameters and number of nodes in the hidden layer of BPNN and ELM were optimized by the triangular multi-step cuckoo search (TMCS). The comprehensive sensitivity analysis (CSA) method and Morris sensitivity analysis (MSA) method were used to analyze the sensitivity of six key parameters of PBL, such as thickness of perforated steel plate, diameter of perforated holes, number of perforated holes, diameter of through reinforcement, yield strength of through reinforcement and compressive strength of concrete. The experimental data of push-out tests in published literatures were selected as samples, and the results show that the proposed TMCS-ELM algorithm and TMCS-BPNN algorithm can accurately predict the ultimate bearing capacity of PBL, and the average errors are 4.17% and 2.16% respectively. The sensitivity analysis results show that the compressive strength of concrete has the highest influence on the bearing capacity of PBL, followed by the yield strength of through reinforcement.},
  archive      = {J_EAAI},
  author       = {Yixin Chen and Yanke Huang and Hao Liu and Yongsheng Liu and Ting Zhang},
  doi          = {10.1016/j.engappai.2023.106510},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106510},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ultimate bearing capacity prediction method and sensitivity analysis of PBL},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Container stacking optimization based on deep reinforcement
learning. <em>EAAI</em>, <em>123</em>, 106508. (<a
href="https://doi.org/10.1016/j.engappai.2023.106508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cargo storage is one of the key aspects of the maritime transportation. As the prior site planning, container stacking has a critical influence on the operation efficiency of the storage yard. To store a group of containers in a certain number of stacks with capacity constraints in order, we propose a self-attention based Deep Reinforcement Learning (DRL) method, which can learn high-quality policy to solve the container stacking problem. We design a Markov Decision Process (MDP) model to simulate the container stacking process and enable the DRL agent to learn to minimize the number of blockages when retrieving the containers. In the proposed DRL model, a novel feature extraction network based on self-attention is utilized to effectively capture the interrelationships between stacks and represent the state of all stacks. Additionally, the size-agnostic policy network enables the agent to have the ability to handle problems of different scales. Through extensive experimental verification, our method significantly outperforms general stacking rules, heuristic-search algorithm and mathematical programming in medium-scale and large-scale problems. Specifically, the proposed DRL method outperforms the optimal existing method by 54% and 80% for medium and large-scale problems, respectively. Moreover, the learned policies exhibit outstanding generalization performance on unseen scenarios with different scales and settings.},
  archive      = {J_EAAI},
  author       = {Xin Jin and Zhentang Duan and Wen Song and Qiqiang Li},
  doi          = {10.1016/j.engappai.2023.106508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Container stacking optimization based on deep reinforcement learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting online adaptation methods for energy domain.
<em>EAAI</em>, <em>123</em>, 106499. (<a
href="https://doi.org/10.1016/j.engappai.2023.106499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is crucial for addressing renewable energy optimization challenges, such as minimizing financial costs. Factors like seasonality and human activity induce concept drift in energy-related forecasting tasks. Despite this, the majority of studies concentrate on offline forecasting models, which are unable to accommodate concept drift. In response, we propose a replacement learning-based online adaptation framework for multivariate multi-step time series forecasting in the energy domain. This method tackles concept drift by retraining models from scratch, leveraging historical data via clustering-based sampling and dimensionality reduction. Furthermore, the forecast model’s predictions are refined using the proposed correcting factor, which serves to adjust for any inherent bias present in the forecasting model. Additionally, we develop an incremental learning model that adapts to concept drift by building on the previous model, offering a comparative analysis and investigation of incremental learning. Evaluations using synthetic building electricity demand and cooling system electricity demand datasets demonstrate the stability and effectiveness of our proposed replacement learning adaptation, outperforming offline models by over 50% across various dataset characteristics.},
  archive      = {J_EAAI},
  author       = {Haitao Wu and Dolgintseva Elizaveta and Anastasia Zhadan and Ovanes Petrosian},
  doi          = {10.1016/j.engappai.2023.106499},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106499},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting online adaptation methods for energy domain},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimal allocation method for power distribution network
partitions based on improved spectral clustering algorithm.
<em>EAAI</em>, <em>123</em>, 106497. (<a
href="https://doi.org/10.1016/j.engappai.2023.106497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distribution network nodes are numerous and monitoring devices are widely distributed. All monitoring data are uploaded to the cloud master for centralized processing may cause serious problems, such as network congestion, information delay and high computational complexity. The edge computing can provide a good solution, which requires reasonable distribution network partition. This paper proposes a Monte Carlo optimized spectral clustering (MCOSC) distribution network partition method for edge server configuration. Firstly, the objective function of distribution network partition number is constructed with economic and real-time communication indexes, which are more suitable for edge computing than electrical distance and voltage sensitivity indexes. Then the optimal number of partitions is obtained by particle swarm optimization (PSO) with the constraints of communication reliability. Secondly, to solve the problem that the traditional spectral clustering is easy to fall into the local optimal solution, a Monte Carlo optimized spectral clustering method is proposed to make the distribution network partition results more reasonable. Finally, the performance of the proposed method is evaluated by IEEE 33 bus and 69 bus systems distribution network models. The results indicate that the Monte Carlo optimization partition method has better accurate, robustness and convergence speed than traditional spectral clustering method.},
  archive      = {J_EAAI},
  author       = {Li Pan and Zhang Han and Zhao Shanshan and Wang Feng},
  doi          = {10.1016/j.engappai.2023.106497},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106497},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimal allocation method for power distribution network partitions based on improved spectral clustering algorithm},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive matching control method of multiple turboshaft
engines. <em>EAAI</em>, <em>123</em>, 106496. (<a
href="https://doi.org/10.1016/j.engappai.2023.106496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to overcome the problem that the conventional multi-engine matching control method never balance the service lives of engines and transmission system synchronously while engines have individual differences and performance degradations, an adaptive matching control method of multiple turboshaft engines is proposed and designed. Firstly, based on the deep neural network (DNN), the onboard adaptive model is established to simulate the coupling dynamics of multiple engines. It can automatically trace engine output torques, discharge temperatures of gas turbine and rotational speeds of compressor. Then, the numerical optimization problem of multi-engine matching is built to obtain the optimal discharge temperatures of gas turbine online. It is featured with a multi-objective function that integrates the maximum deviations of engine output torques, discharge temperatures of gas turbine and the relative rotational speeds of compressor. Finally, the optimal discharge temperatures of gas turbine are input to the conventional matching strategy to accomplish the adaptive matching control. The results demonstrate that compared with the conventional matching strategy, when the number of turboshaft engine is three, the adaptive matching control method can dramatically decrease the maximum matching error of compressor speeds and engine output torques by more than 40% and 60% individually with the maximum deviation of the discharge temperatures of gas turbine no more than 3%. It proves to be conducive to balancing the service lives of multiple engines and transmission system.},
  archive      = {J_EAAI},
  author       = {Yong Wang and Chuang Ji and Zhihua Xi and Haibo Zhang and Qijun Zhao},
  doi          = {10.1016/j.engappai.2023.106496},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106496},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive matching control method of multiple turboshaft engines},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Is your mouse attracted by your eyes: Non-intrusive stress
detection in off-the-shelf desktop environments. <em>EAAI</em>,
<em>123</em>, 106495. (<a
href="https://doi.org/10.1016/j.engappai.2023.106495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing number of people work long hours with computers under high cognitive load. This could potentially cause mental stress in workplaces. Prolonged exposure to mental stress contributes to poor working experience and even severe health problems. Despite the growing demand, the existing intelligent stress detection methods are limited when applied to actual workplaces. They often measure physiological and physical signals, via intrusive devices, to detect stress. The intrusiveness hampers their accessibility and applicability in daily life and workplaces. To overcome that, behavior-based methods were proposed. Models that explore mouse and gaze behaviors during computer usages were demonstrated to be particularly effective. However, the current methods rely on using prior knowledge of the user interface (UI) layout to construct models. Their applicability thus is limited, especially in real workplaces where task UI is often dynamic. This paper presents a novel stress detection method to address the challenges. It attains non-intrusiveness and UI-agnostic by modeling the relative movement and coordination of mouse and gaze. The method is evaluated on a dynamic-UI task, namely, web searching. An accuracy of 78.8% is achieved using a commercial eye-tracker for gaze estimation, beating the state-of-the-art approaches by around 20%. We further use webcam to estimate gaze locations substituting for the eye-tracker, to enhance the model accessibility. The method yields 68.6% accuracy of stress detection without using any special devices. Experimental results demonstrate the effectiveness and applicability of our method. It opens up a new avenue for cognitive-aware adaptive user interface, intelligent working environment, and related applications.},
  archive      = {J_EAAI},
  author       = {Jun Wang and Chunxi Yang and Eugene Yujun Fu and Grace Ngai and Hong Va Leong},
  doi          = {10.1016/j.engappai.2023.106495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Is your mouse attracted by your eyes: Non-intrusive stress detection in off-the-shelf desktop environments},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corrigendum to “unsupervised simple siamese representation
learning for blind super-resolution” [eng. Appl. Artif. Intell. 114
(2022) 105092]. <em>EAAI</em>, <em>123</em>, 106494. (<a
href="https://doi.org/10.1016/j.engappai.2023.106494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Pengfei Yin and Zhonghua Liu and Di Wu and Hua Huo and Haijun Wang and Kaibing Zhang},
  doi          = {10.1016/j.engappai.2023.106494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Unsupervised simple siamese representation learning for blind super-resolution” [Eng. appl. artif. intell. 114 (2022) 105092]},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Virtual reference feedback tuning with robustness
constraints: A swarm intelligence solution. <em>EAAI</em>, <em>123</em>,
106490. (<a
href="https://doi.org/10.1016/j.engappai.2023.106490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simplified modeling of a complex system allied with a low-order controller structure can lead to poor closed-loop performance and robustness. A feasible solution is to avoid the necessity of a model by using data for the controller design. The Virtual Reference Feedback Tuning (VRFT) is a data-driven design method that only requires a single batch of data and solves a reference tracking problem, although with no guarantee of robustness. In this work, the inclusion of an H ∞ robustness constraint to the VRFT cost function is addressed. The estimation of the H ∞ norm of the sensitivity transfer function is extended to maintain the one-shot characteristic of the VRFT. Swarm intelligence algorithms are used to solve the non-convex cost function. The proposed method is applied in two real-world inspired problems with four different swarm intelligence algorithms, which are compared with each other through a Monte Carlo experiment of 50 executions. The obtained results are satisfactory, achieving the desired robustness criteria.},
  archive      = {J_EAAI},
  author       = {Luan Vinícius Fiorio and Chrystian Lenon Remes and Patrick Wheeler and Yales Rômulo de Novaes},
  doi          = {10.1016/j.engappai.2023.106490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Virtual reference feedback tuning with robustness constraints: A swarm intelligence solution},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward improved surveillance of aedes aegypti breeding
grounds through artificially augmented data. <em>EAAI</em>,
<em>123</em>, 106488. (<a
href="https://doi.org/10.1016/j.engappai.2023.106488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Aedes aegypti mosquito transmits several diseases, including dengue, zika, and chikungunya. To prevent these diseases, identifying and removing mosquito breeding sites is essential, but it is a time-consuming and labor-intensive task. To improve efficiency, computer vision and machine learning can be used to detect potential breeding grounds automatically. In this context, we explore the use of data augmentation strategies including random scaling, rotation, as well as color and brightness adjustments for improving the automatic detection of potential Aedes aegypti breeding grounds using videos acquired by a drone. The faster region-based convolutional neural network (Faster R-CNN) and the you only look once (YOLO) v5 object detectors are used on a database of aerial videos containing breeding-related objects. When employing the data augmentation, tire-detection results show F 1 scores of 0.79 and 0.81 for the Faster R-CNN and YOLOv5 networks, respectively, surpassing current state-of-the-art values. The detection performance of the algorithms increased by up to 14.1%, which is a significant improvement. These results indicate that artificial data augmentation reduces overfitting, improving the models’ robustness. The developed system can be employed to help health agencies in locating potential Aedes aegypti outbreaks more efficiently.},
  archive      = {J_EAAI},
  author       = {Wesley L. Passos and Cesar da S. Barreto and Gabriel M. Araujo and Ubydul Haque and Sergio L. Netto and Eduardo A.B. da Silva},
  doi          = {10.1016/j.engappai.2023.106488},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106488},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward improved surveillance of aedes aegypti breeding grounds through artificially augmented data},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting physical activity levels from kinematic gait data
using machine learning techniques. <em>EAAI</em>, <em>123</em>, 106487.
(<a href="https://doi.org/10.1016/j.engappai.2023.106487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective analysis of gait abilities (Gait Analysis, GAn) in clinic is an essential motor assessment to improve clinical decision-making and provide precision rehabilitation approaches to recover gait functions. GAn is usually based on wearable motion sensors or camera-based systems, which generate an extensive set of data which are challenging to manage, analyse, and interpret. This makes GAn a time-consuming unfeasible assessment approach in clinical practice. Machine Learning (ML) techniques can provide a viable solution, as they can handle massive time series and complex data. This study aims to correctly classify subjects’ physical activity levels, using as ground truth a self-reported questionnaire (International Physical Activity Questionnaire, IPAQ), via kinematic features provided by wearable wireless Inertial Measurement Unit (IMU) sensors. Kinematic gait data were collected from 37 healthy subjects (24 male and 13 female) while walking on a sensorised treadmill at natural speed. Velocity, acceleration, jerk, and smoothness were calculated using the kinematic features and used to perform statistical feature extraction. The Neighbourhood Component Analysis (NCA) algorithm was used to process the statistical features space and select the most significant ones. Several models have been trained and tested before and after the feature selection to validate the approach’s effectiveness. Feature reduction resulted in a significant increase in accuracy for K-Nearest Neighbours (KNN) (81.978 ± 0.368), Random Forest (84.044 ± 3.409) and Rough-Set-Exploration-System Library K-Nearest Neighbours (RSesLib KNN) (83.956 ± 0), with an improvement of ≈ 20%. The performance of the best-performing classifiers was then analysed, observing the behaviour of accuracy by varying the number of features considered.},
  archive      = {J_EAAI},
  author       = {Svonko Galasso and Renato Baptista and Mario Molinara and Serena Pizzocaro and Rocco Salvatore Calabrò and Alessandro Marco De Nunzio},
  doi          = {10.1016/j.engappai.2023.106487},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106487},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting physical activity levels from kinematic gait data using machine learning techniques},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel inter-domain attention-based adversarial network for
aero-engine partial unsupervised cross-domain fault diagnosis.
<em>EAAI</em>, <em>123</em>, 106486. (<a
href="https://doi.org/10.1016/j.engappai.2023.106486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, domain adaptation methods have been widely applied in the field of aero-engine cross-domain fault diagnosis, which can effectively solve the problem of training and testing data coming from different distributions. However, existing methods commonly assume that the health states in the source and target domains are identical. In practice, the health states in the target domain are often a subset of the source domain, and there is no prior information on the target health states, which is defined as a partial unsupervised cross-domain fault diagnosis task. The most difficult problem in this scenario is determining the shared health state label space between the source and target domains. To address this issue, we propose an inter-domain attention mechanism that enables the neural network structure itself to dynamically learn the relationship between each source sample and each target sample by constructing a source sample attention vector. Furthermore, we propose an inter-domain attention-based encoder that can be seamlessly integrated into the widely adopted domain adversarial neural network (DANN). Finally, we conduct extensive experiments on two aero-engine datasets and the CWRU dataset, and the results show that our method achieves at least 1.05% improvement in average accuracy compared to other methods in the partial unsupervised cross-domain fault diagnosis task.},
  archive      = {J_EAAI},
  author       = {Yu-Qiang Wang and Yong-Ping Zhao},
  doi          = {10.1016/j.engappai.2023.106486},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106486},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel inter-domain attention-based adversarial network for aero-engine partial unsupervised cross-domain fault diagnosis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid multi-stage decision-making method with
probabilistic interval-valued hesitant fuzzy set for 3D printed
composite material selection. <em>EAAI</em>, <em>123</em>, 106483. (<a
href="https://doi.org/10.1016/j.engappai.2023.106483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 3D printed composite material selection is of great interest due to its extensive application prospect and can be considered as a challenging multiple-criteria decision making (MCDM) issue. The hesitation and uncertainty of experts are difficult to measure, and the high degree of interaction among criteria is often overlooked in the decision process. In addition, composites are required to serve in harsh environments for various mechanical and industrial fields, resulting in the degradation of mechanical properties. In this study, a hybrid multi-stage decision-making method is developed to conduct 3D printed composite material selection in harsh environments. The theory of probabilistic interval-valued hesitant fuzzy set (PIVHFS) is proposed to characterize the decision-making information of experts, which can effectively quantify the assessment in uncertain environments. An integrated method that combines Choquet fuzzy integral and Shapley value is proposed to obtain the weight vector of criteria, which can reflect the mutual influence between criteria and their overall importance. The final decision-making result and the optimal alternative can be calculated by the PIVHFS-based Tomada de Decisão Interativa Multicritério and Technique for order preference by similarity to an ideal solution (TODIM-TOPSIS) method. An empirical application, i.e., 3D printed composites in the background of automotive chassis, is applied to validate the application of the proposed method. Comparative analysis, sensitivity analysis, and managerial implications are also conducted to illustrate the validity of the method. This paper provides a valuable tool for addressing the material selection issue of 3D printed composites from a multi-criteria perspective.},
  archive      = {J_EAAI},
  author       = {Guoquan Xie and Kui Wang and Xuan Wu and Jin Wang and Tao Li and Yong Peng and Honghao Zhang},
  doi          = {10.1016/j.engappai.2023.106483},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106483},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid multi-stage decision-making method with probabilistic interval-valued hesitant fuzzy set for 3D printed composite material selection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Implicit neural representations of sheet stamping
geometries with small-scale features. <em>EAAI</em>, <em>123</em>,
106482. (<a
href="https://doi.org/10.1016/j.engappai.2023.106482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric deep learning models, like Convolutional Neural Networks (CNNs), show promise as surrogate models for predicting sheet stamping manufacturability but lack design variables essential for inverse problems like geometric optimisation. Recent developments in deep learning have enabled geometry generation from compact latent spaces that are suitable for optimisation. However, current methods do not accurately model small-scale geometric features that are crucial for stamping performance. This study proposes a new deep learning-based method to address this limitation and generate detailed stamping geometries for optimisation. Specifically, neural networks are trained to generate Signed Distance Fields (SDFs) for stamping geometries, where the zero-level-set of each SDF implicitly represents the generated geometry. A new training approach is proposed for generating SDFs of stamping geometries, which involves supervising geometric properties of the SDFs. A novel loss function is introduced that directly acts on the zero-level-set and places high emphasis on learning small-scale features. This approach is compared with the state-of-the-art approach DeepSDF by Park et al. (2019), which explicitly supervises SDF values using ground truth data. The geometry generation performance of networks trained using both approaches is evaluated quantitatively and qualitatively. The results demonstrate significantly greater geometric accuracy with the proposed approach, which can faithfully generate small-scale features. Further analysis of the new approach reveals an organised learned latent space and varying the network input generates high-quality geometries from this space. By integrating with CNN-based manufacturability surrogate models by Attar et al. (2021), this work could enable the first-ever manufacturability-constrained optimisation of arbitrary sheet stamping geometries, potentially reducing geometry design time and cost.},
  archive      = {J_EAAI},
  author       = {Hamid Reza Attar and Alistair Foster and Nan Li},
  doi          = {10.1016/j.engappai.2023.106482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Implicit neural representations of sheet stamping geometries with small-scale features},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Haze removal using deep convolutional neural network for
korea multi-purpose satellite-3A (KOMPSAT-3A) multispectral remote
sensing imagery. <em>EAAI</em>, <em>123</em>, 106481. (<a
href="https://doi.org/10.1016/j.engappai.2023.106481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a convolutional neural network to automatically remove the haze distribution using a single multispectral remote sensing image in the raw file format. To train the proposed dehazing network, we synthesized multispectral hazy images using the haze thickness map (HTM) and relative scattering model representing the wavelength-dependent scattering property of the haze distribution. Since the raw multispectral hazy images have a low dynamic range, we cannot accurately estimate the haze distribution directly from them. To differently impose a proper amount of attention to hazy and haze-free regions, we used the HTM from the contrast-enhanced version of the input hazy image. The proposed dehazing network consists of four sub-networks: (i) shallow feature extraction network (SFEN), (ii) cascaded residual dense block network (CRDBN), (iii) multiscale feature extraction network (MFEN), and (iv) refinement network (RN). The densely connected convolutional layers and local residual learning allow the residual dense block (RDB) to extract the abundant local features, and the cascaded architecture further improves the propagation of the local information and gradients. The MFEN is used to extract multiscale local features representing the hierarchical information for the haze distribution and haze-free region. Experimental results demonstrated that the proposed method can achieve improved dehazing performance on Korea Multi-Purpose Satellite-3A (KOMPSAT-3A) multispectral remote sensing imagery without undesired artifacts. In the sense of quantitative assessment, the proposed method produced improved peak signal-to-noise ratio (PSNR) by 10%, structural similarity index measure (SSIM) by 1%, and spectral angle mapper (SAM) by 19% compared with the existing best method.},
  archive      = {J_EAAI},
  author       = {Soohwan Yu and Doochun Seo and Joonki Paik},
  doi          = {10.1016/j.engappai.2023.106481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Haze removal using deep convolutional neural network for korea multi-purpose satellite-3A (KOMPSAT-3A) multispectral remote sensing imagery},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DA-LSTM: A dynamic drift-adaptive learning framework for
interval load forecasting with LSTM networks. <em>EAAI</em>,
<em>123</em>, 106480. (<a
href="https://doi.org/10.1016/j.engappai.2023.106480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Load forecasting is a crucial topic in energy management systems (EMS) due to its vital role in optimizing energy scheduling and enabling more flexible and intelligent power grid systems. As a result, these systems allow power utility companies to respond promptly to demands in the electricity market. Deep learning (DL) models have been commonly employed in load forecasting problems supported by adaptation mechanisms to cope with the changing pattern of consumption by customers, known as concept drift. A drift magnitude threshold should be defined to design change detection methods to identify drifts. While the drift magnitude in load forecasting problems can vary significantly over time, existing literature often assumes a fixed drift magnitude threshold, which should be dynamically adjusted rather than fixed during system evolution. To address this gap, in this paper, we propose a dynamic drift-adaptive Long Short-Term Memory (DA-LSTM) framework that can improve the performance of load forecasting models without requiring a drift threshold setting. We integrate several strategies into the framework based on active and passive adaptation approaches. To evaluate DA-LSTM in real-life settings, we thoroughly analyze the proposed framework and deploy it in a real-world problem through a cloud-based environment. Efficiency is evaluated in terms of the prediction performance of each approach and computational cost. The experiments show performance improvements on multiple evaluation metrics achieved by our framework compared to baseline methods from the literature. Finally, we present a trade-off analysis between prediction performance and computational costs.},
  archive      = {J_EAAI},
  author       = {Firas Bayram and Phil Aupke and Bestoun S. Ahmed and Andreas Kassler and Andreas Theocharis and Jonas Forsman},
  doi          = {10.1016/j.engappai.2023.106480},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106480},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DA-LSTM: A dynamic drift-adaptive learning framework for interval load forecasting with LSTM networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Electroencephalogram signal classification based on fourier
transform and pattern recognition network for epilepsy diagnosis.
<em>EAAI</em>, <em>123</em>, 106479. (<a
href="https://doi.org/10.1016/j.engappai.2023.106479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a central nervous system (CNS) disorder that affects nerve cells in the brain and produces seizures in which consciousness is lost. People with epilepsy have frequent seizures as a result of increased brain electrical activity, which disrupts the message system between brain cells, making epilepsy a serious condition that must be treated. Correct diagnosis of this disease can save the patient from death and complications caused by the disease. The recording of electroencephalogram (EEG) signals is an effective method for determining the electrical activity of the brain and learning a great deal about how the brain function. The Fast Fourier Transform (FFT), the Discrete Wavelet Transform (DWT), and a pattern recognition network are used in this study to offer a method for analyzing EEG signals. This study aimed to provide a multi-step algorithm for extracting signal features and diagnosing epilepsy. Wavelet transform is used to remove signal noise. For this purpose, the optimal wavelet mother (Dabichiz 8) was used. Then, signal features are extracted using the Fourier transform, and generate the EEG matrix. The features are regarded as the Pattern Recognition Network’s input. There were 5% of test data and 80% of training data. 15% of the data were left over for validation. The architecture was thought to consist of one input layer (14 neurons = number of selected features), one hidden layer (6 neurons), and two output layers (2 neurons = number of sleep stages). The result of this output was compared with other classifiers, such as multilayer perceptron (MLP) neural network. The results show that using a Pattern Recognition Network can classify the features with 92.5% accuracy. Using this method can process the signal with high accuracy while being simple. In fact, a new method based on the architecture of a new network was presented for AC signal processing. Hence, the proposed method can diagnose epilepsy with high accuracy while removing signal noise.},
  archive      = {J_EAAI},
  author       = {Qiang Gao and Alaa Hamza Omran and Yasamin Baghersad and Omid Mohammadi and Mohammed Ayad Alkhafaji and Abdul Kareem J. Al-Azzawi and Sara Hakem Al-Khafaji and Nafiseh Emami and D. Toghraie and Mohammad Javad Golkar},
  doi          = {10.1016/j.engappai.2023.106479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Electroencephalogram signal classification based on fourier transform and pattern recognition network for epilepsy diagnosis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rational software agents with the BDI reasoning model for
cyber–physical systems. <em>EAAI</em>, <em>123</em>, 106478. (<a
href="https://doi.org/10.1016/j.engappai.2023.106478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber–Physical Systems (CPSs) are complex and heterogeneous systems. Interacting with the physical world makes CPS unpredictable because of unanticipated events. Therefore, a CPS needs to reason these events autonomously. Henceforward, suitable reasoning mechanisms, such as rational agents with deliberative capabilities, should be selected and integrated into the CPSs. In this way, the integrated multi-agents can reason on environmental changes to find a plan that sustains the system’s operation for CPS. In addition, a layered architecture can pave the way to integrate the rational agents on embedded hardware and control the CPS. To this end, this paper presents an architecture, discusses a reference implementation and elaborates on the high-level integration of agents and CPS. Moreover, a complex and heterogeneous case study is provided to validate the effectiveness of rational agents in conducted experiments. Firstly, the rational agents utilising the belief–desire–intention (BDI) model required approximately three times less development time than simple-reflex agents. Secondly, the proposed approach resulted in up to 3 times less description complexity in language expressiveness. Lastly, the product quality is improved up to 66% by the rational agents and BDI model. As a result, our approach is beneficial to designing multi-agent CPS where it is aimed to use low-level control and high-level reasoning in a single platform.},
  archive      = {J_EAAI},
  author       = {Burak Karaduman and Baris Tekin Tezel and Moharram Challenger},
  doi          = {10.1016/j.engappai.2023.106478},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106478},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rational software agents with the BDI reasoning model for Cyber–Physical systems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multi-stage distribution correction: A promising data
augmentation method for few-shot fault diagnosis. <em>EAAI</em>,
<em>123</em>, 106477. (<a
href="https://doi.org/10.1016/j.engappai.2023.106477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the excellent capability of data processing, deep learning-based methods have been well applied in fault diagnosis. However, these methods may perform poorly due to lack of labeled data for training in real-world applications In few-shot learning settings, these methods may be trapped in overfitting since the data distribution estimated from a small number of labeled samples may be overly biased, which cannot cover the ground-truth data distribution. Given this problem, we propose a data augmentation method named Multi-Stage Distribution Correction (MSDC) for few-shot fault diagnosis. The proposed method can be divided into four training stages. In the first stage, unlabeled query features are clustered into several groups via an unsupervised Fuzzy C-means algorithm. Secondly, according to cosine similarity, the few labeled support features are assigned to the cluster with the highest similarity. Then, the Gaussian statistics of each cluster are extracted to correct the distributions of support features. Specifically, Our proposed method assumes that each dimension of the feature representation from the same class follows Gaussian distribution. New labeled features are generated by sampling from the corrected distributions. These generated features, along with the labeled support features, are used to train the task-specific classifier in the last stage. By joint training of the four stages, the scale of the labeled training dataset is effectively expanded, and the classification performance of the proposed method can be enhanced. The experimental results reveal that the proposed method outperforms the selected comparative methods in two case studies.},
  archive      = {J_EAAI},
  author       = {Xiao Zhang and Weiguo Huang and Rui Wang and Yi Liao and Chuancang Ding and Jun Wang and Juanjuan Shi},
  doi          = {10.1016/j.engappai.2023.106477},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106477},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-stage distribution correction: A promising data augmentation method for few-shot fault diagnosis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UAV sensor data applications with deep neural networks: A
comprehensive survey. <em>EAAI</em>, <em>123</em>, 106476. (<a
href="https://doi.org/10.1016/j.engappai.2023.106476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Unmanned Aerial Vehicles (UAVs) has become increasingly popular in recent years, leading to a surge in research on this topic that is widely represented in the literature. They would be examined in accordance with the requirements of the sensors they house, their operating limits, and the output information they give. Since perception, planning, localization, and control are the major tasks of UAVs, an outstanding problem solver “Deep learning” is recently used in these systems. It is ideally suited for UAV applications because of its great capacity for learning representations from the complicated data received in actual situations. This paper provides an extensive review and in-depth analysis of current advancements in UAVs that have applications with DNN, as well as a quick summary of research and development during the previous ten years. In terms of UAVs flight monitoring, remote sensing and vision capability, and energy modeling, this survey provides a roadmap for understanding the sequential development of sophisticated UAVs by reviewing 173 retrieved papers. For this purpose, first of all, the main titles of the studies carried out for UAV applications were gathered under a taxonomy, and then information about the studies carried out in recent years related to these main research fields was given. In the last part of the study, attention was drawn to the still challenging points, such as autonomous fault detection, path planning, and onboard event detection, which are anticipated to be the future trends involving UAV applications.},
  archive      = {J_EAAI},
  author       = {Hatice Vildan Dudukcu and Murat Taskiran and Nihan Kahraman},
  doi          = {10.1016/j.engappai.2023.106476},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106476},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {UAV sensor data applications with deep neural networks: A comprehensive survey},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fixed-time disturbance rejection control framework based
on artificial intelligence for the flight environment testbed system.
<em>EAAI</em>, <em>123</em>, 106475. (<a
href="https://doi.org/10.1016/j.engappai.2023.106475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fixed-time disturbance rejection control framework based on artificial intelligence is proposed to achieve rapid tracking control of the flight environment testbed (FET) system in this study. Firstly, to resist the violent disturbance caused by the change in engine operating conditions and other disturbances, fixed-time extended state observers (FESO) are used in this paper to estimate disturbances in a fixed time and improve the anti-disturbance capability of the system. Then, the anti-saturation fixed-time control (FTC) law is used to prevent the system from collapsing or significant tracking errors due to actuator saturation and ensure the fixed-time convergence of tracking errors. Finally, the gradient descent optimization algorithm based on long short-term memory (LSTM) network is used to optimize the controller parameters and further improve the controller’s adaptive ability. Simulation experiments prove the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yuebin Lun and Honglun Wang and Qiumeng Qian and Tiancai Wu and Song Zhang and Zhihong Dan and Jinbai Li},
  doi          = {10.1016/j.engappai.2023.106475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fixed-time disturbance rejection control framework based on artificial intelligence for the flight environment testbed system},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SMINet: Semantics-aware multi-level feature interaction
network for surface defect detection. <em>EAAI</em>, <em>123</em>,
106474. (<a
href="https://doi.org/10.1016/j.engappai.2023.106474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To boost the product quality, numerous saliency-based surface defect detection methods have been devoted to the areas of industrial production, construction consumable, road construction. However, the existing salient object detection (SOD) methods not only consume a significant amount of computing resources but also fail to meet the detection efficiency requirements of enterprises. Therefore, this paper proposes a lightweight semantics-aware multi-level feature interaction network (SMINet), to address the above issues. In the encoder phase, we integrate multiple adjacent level features in the cross-layer feature fusion (CFF) module to alleviate the discrepancy between multi-scale features. In the decoder phase, we first employ the semantic-aware feature extraction (SFE) module to mine the location cues embedded in the high-level features. Afterwards, we introduce the detail-aware context attention (DCA) module based on the attention mechanism to recover more spatial details. Extensive experiments on four surface defect datasets validate that our SMINet outperforms the existing state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Bin Wan and Xiaofei Zhou and Yaoqi Sun and Zunjie Zhu and Haibing Yin and Ji Hu and Jiyong Zhang and Chenggang Yan},
  doi          = {10.1016/j.engappai.2023.106474},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106474},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SMINet: Semantics-aware multi-level feature interaction network for surface defect detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label embedding asymmetric discrete hashing for efficient
cross-modal retrieval. <em>EAAI</em>, <em>123</em>, 106473. (<a
href="https://doi.org/10.1016/j.engappai.2023.106473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the exponential growth of multimedia data, how to swiftly and accurately retrieve information has grown in popularity. Among retrieval techniques, supervised hashing stands out due to its low memory footprint and relatively precise accuracy. Prior theoretical studies often inserted high-order tags into binary code learning, treating them as independent entities. Nevertheless, such approaches frequently neglect the latent category correlations revealed by the label information. Additionally, in terms of optimization, some algorithms employ a bit-by-bit scheme, leading to time-consuming, while others adopt a relaxation-based strategy, producing quantization inaccuracy. To address these issues, we formulate a novel, two-step hashing strategy, termed Label Embedding Asymmetric Discrete Hashing (LEADH). In this study, we provide an asymmetric technique to protect the discrete binary code constraints. Compared with the symmetric model, this method significantly reduces time consumption. In particular, a label-binary mutual mapping architecture is specifically recommended. This model can fully explore and utilize multi-label semantic information to provide better discriminative learned binary codes. Furthermore, to minimize quantization errors, an efficient and effective discrete optimization module based on augmented Lagrangian multipliers is elaborately designed. Extensive experimentation and theoretical study support our model’s superiority. Compared to the sub-optimal method, our LEADH achieves an improvement of 2.6%, 1.8%, and 1.1% on Wiki, MIRFlickr, and NUS-WIDE, respectively.},
  archive      = {J_EAAI},
  author       = {Fan Yang and Meng Han and Fumin Ma and Xiaojian Ding and Qiaoxi Zhang},
  doi          = {10.1016/j.engappai.2023.106473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Label embedding asymmetric discrete hashing for efficient cross-modal retrieval},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active contour model based on local kullback–leibler
divergence for fast image segmentation. <em>EAAI</em>, <em>123</em>,
106472. (<a
href="https://doi.org/10.1016/j.engappai.2023.106472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inhomogeneity of image intensity and noise are the main factors that affect the segmentation results. To overcome these challenges, a new active contour model is designed based on level set method and Kullback–Leibler Divergence. First of all, a new regional measurement of information scale is applied to construct energy functional, instead of Euclidean distance. Test results demonstrate that the Kullback–Leibler Divergence achieves a truly better segmentation. Then, a new Heaviside function has been proposed in this paper, which gives rise to a faster zero-crossing slope than traditional function. In this sense, it can stimulate the evolution of the level set function faster and allocate internal and external energy reasonably. In addition, the activation function has also been improved, which makes itself fluctuates over a smaller range than former activation function. Experiments reveal that the ‘Local Kullback–Leibler Divergency’ (LKLD) model has desired segmentation results both on real-world and medical images. Also, it owns a better noise robustness and is not limited to position of initial contour.},
  archive      = {J_EAAI},
  author       = {Chengxin Yang and Guirong Weng and Yiyang Chen},
  doi          = {10.1016/j.engappai.2023.106472},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106472},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Active contour model based on local Kullback–Leibler divergence for fast image segmentation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TCAMixer: A lightweight mixer based on a novel triple
concepts attention mechanism for NLP. <em>EAAI</em>, <em>123</em>,
106471. (<a
href="https://doi.org/10.1016/j.engappai.2023.106471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale model sizes and expensive computing costs cause the challenge of deploying and applying large pre-trained models. Hence, this paper presents a novel Triple Concepts Attention Mechanism and a lightweight TCAMixer model for edge devices to classify texts. Furthermore, the TCAMixer abstracts textual concepts in a human way, which is unmatched by other counterparts such as pNLP-Mixer (a projection-based MLP-Mixer model for Nature Language Processing) and HyperMixer (a hyper network using dynamic token-mixing layers). Experimental results on several public datasets demonstrate that the TCAMixer outperforms the counterparts by a significant margin, for example, achieving 3% higher accuracy with a smaller model size of 0.177M . Additionally, the TCAMixer achieves a performance of 85% to 98.7% compared to that of large pre-trained models but only occupies 1/3000 to 1/2000 of their size on most test datasets.},
  archive      = {J_EAAI},
  author       = {Xiaoyan Liu and Huanling Tang and Jie Zhao and Quansheng Dou and Mingyu Lu},
  doi          = {10.1016/j.engappai.2023.106471},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106471},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TCAMixer: A lightweight mixer based on a novel triple concepts attention mechanism for NLP},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing fuzzy evidential reasoning approach using dynamic
adjustment mechanism and new rule-based transformation for engineering
emergency response evaluation. <em>EAAI</em>, <em>123</em>, 106470. (<a
href="https://doi.org/10.1016/j.engappai.2023.106470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the frequent occurrence of various emergency events in engineering field, engineering emergency response (EER) evaluation plays an increasingly significant role in handling such situations and provides great challenges to research since the uncertain information and the urgent response time. Aiming at achieving timely and effective emergency response, an enhanced evidential reasoning (ER) approach based on the dynamic adjustment mechanism and new rule-based transformation is proposed. First, the linguistic terms to represent various preference information provided by experts are encoded into the trapezoidal interval type-2 fuzzy sets (TrIT2FSs) with different granularities. Second, for ensuring the validity of the information, based on the definition of the expert decision risk preference coefficients, a dynamic adjustment mechanism is constructed to identify and adjust the preference information. Meanwhile, combined with social network, the experts’ weights can be calculated and revised several times to obtain group information. Then, a new rule-based transformation and related optimization models are proposed to convert the TrIT2FSs into interval belief structures. Furthermore, considering the importance of attributes, the relative weights and interval belief structures are combined. Finally, according to integrated interval belief structures obtained by the analytical ER algorithm, a new ranking approach with the optimism degree and decision tendency degree is constructed to rank the interval expected utility and score utility of each alternative. To further show the effectiveness, superiorities, and stability of the proposed method, a case study on the EER evaluation is preformed and some comparisons and discussions are provided.},
  archive      = {J_EAAI},
  author       = {Yan Tu and Zhuang Ma and Jun Liu and Xiaoyang Zhou and Benjamin Lev},
  doi          = {10.1016/j.engappai.2023.106470},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106470},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing fuzzy evidential reasoning approach using dynamic adjustment mechanism and new rule-based transformation for engineering emergency response evaluation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing the parameters of hybrid active power filters
through a comprehensive and dynamic multi-swarm gravitational search
algorithm. <em>EAAI</em>, <em>123</em>, 106469. (<a
href="https://doi.org/10.1016/j.engappai.2023.106469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a dynamic comprehensive multi-swarm gravitational search algorithm with non-uniform mutation (cdGSA-2m) for optimizing hybrid active power filter (HAPF) parameters. The cdGSA-2m algorithm divides the population into two heterogeneous sub-populations with different learning mechanisms. The first sub-population focuses on exploitation with comprehensive learning, while the second sub-population emphasizes exploration with a dynamic multi-swarm strategy (DMS) with non-uniform mutation. Additionally, a non-linear adaptive parameter balances the search capabilities of the DMS sub-population. These mechanisms effectively control the exploration, exploitation, and diversity of the population. To analyse the effectiveness of implemented mechanisms in the cdGSA-2m, diversity and exploration–exploitation are discussed at length with a few experiments. An independent structural study of cdGSA-2m is also carried out to understand the effects of comprehensive learning, dynamic multi-swarm strategy, and non-uniform mutation mechanisms in the algorithm. The proposed cdGSA-2m is tested on IEEE-CEC 2017 benchmark problems, and the results of these problems are compared with twenty-two state-of-the-art algorithms in terms of mean error values and standard deviation of the fitness values. Based on the results, the algorithms are ranked against each other, along with statistical validation of the results. The proposed cdGSA-2 m also solves two case studies of the HAPF model and compares the results with existing state-of-the-art algorithms for the HAPF model. Experimental results demonstrate that the cdGSA-2m algorithm has better accuracy, convergence rate, search capability, and stability. The overall ranking of the algorithms suggests that cdGSA-2 m has outstanding potential to deal with difficult optimization problems.},
  archive      = {J_EAAI},
  author       = {Dikshit Chauhan and Anupam Yadav},
  doi          = {10.1016/j.engappai.2023.106469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing the parameters of hybrid active power filters through a comprehensive and dynamic multi-swarm gravitational search algorithm},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation of thermoelastic coupling in silicon single
crystal growth based on alternate two-stage physics-informed neural
network. <em>EAAI</em>, <em>123</em>, 106468. (<a
href="https://doi.org/10.1016/j.engappai.2023.106468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a alternate physics-informed neural network (PINN) with a two-stage training strategy to solve the thermoelastic coupling in the growth of Czochralski silicon single crystal. Particularly, neural networks with a two-stage training strategy are established for solving partial differential equations in the thermoelastic coupling model. At present, PINN still faces challenges in solving coupling models. Especially for the imbalance between and within equations in the coupling model. To solve this problem, this paper splits the model into two independent systems with their coupling term exchanged in the alternating iteration. Then, the imbalance inside a single solution of the coupling model is solved by the proposed two-stage training strategy, and the imbalance between solutions is avoided by alternative iterations. Experimental results show that the proposed alternate two-stage PINN (ATPINN) can accurately simulate the temperature and displacement in the thermoelastic coupling model. Compared with the finite element results, the error of temperature prediction and displacement prediction is acceptable. The numerical results demonstrate the feasibility and performance of the ATPINN. Furthermore, ATPINN can be extended to any type of coupling model, especially for coupling models with large differences in the magnitudes of the loss functions. The codes developed in this manuscript are publicy available at https://github.com/callmedrcom/ATPINN .},
  archive      = {J_EAAI},
  author       = {Shuyan Shi and Ding Liu and Zhiran Huo},
  doi          = {10.1016/j.engappai.2023.106468},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106468},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simulation of thermoelastic coupling in silicon single crystal growth based on alternate two-stage physics-informed neural network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-based condition monitoring on mechanical systems using
multibody dynamics models. <em>EAAI</em>, <em>123</em>, 106467. (<a
href="https://doi.org/10.1016/j.engappai.2023.106467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time monitoring of mechanical systems via vibration measurements allows for detection of faults in them and facilitates their predictive maintenance. Use of Artificial Intelligence (AI) in damage detection can provide an automated means for Condition Monitoring (CM) of the system while also allowing for characterization of the various health states when labeled damaged state training datasets are available. In this work, a novel CM framework using Convolutional Neural Networks (CNNs) is presented for damage detection and identification on mechanical systems, applied on an elevator door rail, using simulated data from a Multibody Dynamics (MBD) model of the physical system. First, an optimal MBD model of the actual structure is constructed by means of black box optimization, using a small number of initial healthy state measurements. Several of the most common nonlinear contact force models are examined before integrating the best suited one to the MBD model. Damaged states of the system are then simulated by modeling various fault mechanisms on the optimal MBD model, allowing for generation of labeled simulated training datasets for the CNNs. Uncertainty is introduced to the models by sampling their key parameters from a Gaussian distribution, thus considering the real system’s inherent uncertainty. The trained CNNs’ robustness and accuracy are then validated by accurately classifying faults on the physical system, proving the proposed damage detection method’s generalization capabilities and highlighting its potential. The proposed methodology may find application in mitigating the problem of data scarcity of damaged state responses which is present in most mechanical systems and can provide a means for more efficient predictive maintenance. Successful implementation of the proposed framework adds to the existing AI based damage detection and identification methodologies by allowing for extension of the method to industrial systems.},
  archive      = {J_EAAI},
  author       = {Josef Koutsoupakis and Dimitrios Giagopoulos and Iraklis Chatziparasidis},
  doi          = {10.1016/j.engappai.2023.106467},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106467},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AI-based condition monitoring on mechanical systems using multibody dynamics models},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic meter error detection with a data-driven approach.
<em>EAAI</em>, <em>123</em>, 106466. (<a
href="https://doi.org/10.1016/j.engappai.2023.106466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meter error is one of the main contributing factors to unexpected fuel losses or gains in storage tanks at service stations. Although fuel dispensers are expected to be calibrated to standard accuracy periodically to ensure fair and reliable trade in the fuel market, some fuel retailers are unable to keep up with the standards. The current industry practice relies on onsite inspection to identify the issue, which leads to a cost burden if inspections are scheduled too frequently. To the best of our knowledge, there is no previously reported research tailored to the remote meter error detection problem. In this paper, we propose a novel framework for remote and automatic meter error detection via a data-driven approach based on inventory data and fuel transaction data. Specifically, we propose to use mean shift change point detection methods, including statistical-based as well as deep learning-based methods (LSTM-VAE, VAE, Kernel learning), to approach the problem. We present results on our data sets containing both real-world and simulated meter error data, and further evaluate these methods on several widely-used benchmark datasets, to assess their validity, advantages and limitations. The obtained results show that LSTM-VAE outperforms other models in most of the settings for the meter error dataset and the benchmark datasets.},
  archive      = {J_EAAI},
  author       = {Ruimin Chu and Li Chik and Jeffrey Chan and Kurt Gutzmann and Xiaodong Li},
  doi          = {10.1016/j.engappai.2023.106466},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106466},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic meter error detection with a data-driven approach},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributional and hierarchical reinforcement learning for
physical systems with noisy state observations and exogenous
perturbations. <em>EAAI</em>, <em>123</em>, 106465. (<a
href="https://doi.org/10.1016/j.engappai.2023.106465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has shown remarkable success in various applications, and in some cases, even outperforms human performance. However, despite the potential of reinforcement learning, numerous challenges still exist. In this paper, we introduce a novel approach that exploits the synergies between hierarchical reinforcement learning and distributional reinforcement learning to address complex sparse-reward tasks, where noisy state observations or non-stationary exogenous perturbations are present. Our proposed method has a hierarchical policy structure, where random rewards are modeled as random variables that follow a value distribution. This approach enables the handling of complex tasks and increases robustness to uncertainties arising from measurement noise or exogenous perturbations, such as wind. To achieve this, we extend the distributional soft Bellman operator and temporal difference error to include the hierarchical structure, and we use quantile regression to approximate the reward distribution. We evaluate our method using a bipedal robot in the OpenAI Gym environment and an electric autonomous vehicle in the SUMO traffic simulator. The results demonstrate the effectiveness of our approach in solving complex tasks with the aforementioned uncertainties when compared to state-of-the-art methods. Our approach demonstrates promising results in handling uncertainties caused by noise and perturbations for challenging sparse-reward tasks, and could potentially pave the way for the development of more robust and effective reinforcement learning algorithms in real physical systems.},
  archive      = {J_EAAI},
  author       = {Jehyun Park and Jongeun Choi and Sungjae Nah and Dohee Kim},
  doi          = {10.1016/j.engappai.2023.106465},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106465},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributional and hierarchical reinforcement learning for physical systems with noisy state observations and exogenous perturbations},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal toolpath planning strategy prediction using machine
learning technique. <em>EAAI</em>, <em>123</em>, 106464. (<a
href="https://doi.org/10.1016/j.engappai.2023.106464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the best toolpath planning strategy for Computer Numerical Control (CNC) machining requires a trial-and-error approach. One needs to follow a number of steps: generating the toolpath, performing simulations/machining, measuring various parameters to quantify the quality of the toolpath, and then selecting the best toolpath. This conventional iterative approach is time-consuming and often error-prone, which is a bottleneck in the current CNC machining industry. This paper presents a novel framework to create a machine learning based system for choosing the best toolpath planning strategy for CNC machining (finishing) of complex freeform surfaces directly from the CAD model. Three tool path planning strategies are considered: Adaptive planar, Iso-scallop, and Hybrid. At first, a novel toolpath analysis module is presented to evaluate the quality of the toolpath considering three performance parameters: surface finish, toolpath length, and smoothness. This quality measurement technique is extensively tested for robustness and accuracy. It is then used to analyze and label a large number of CAD models to create a dataset for supervised learning. Finally, a Convolutional Neural Network (CNN) is designed and trained using this dataset to predict the best toolpath planning strategy. Compared to the conventional approaches, the developed system uses multiple performance parameters and chooses the best strategy directly from the CAD model. Results show that the proposed data-driven model achieved 96.8% test accuracy.},
  archive      = {J_EAAI},
  author       = {Aman Kukreja and Sanjay S. Pande},
  doi          = {10.1016/j.engappai.2023.106464},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106464},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal toolpath planning strategy prediction using machine learning technique},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid feature learning approach based on convolutional
kernels for ATM fault prediction using event-log data. <em>EAAI</em>,
<em>123</em>, 106463. (<a
href="https://doi.org/10.1016/j.engappai.2023.106463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Maintenance (PdM) methods aim to facilitate the scheduling of maintenance work before equipment failure. In this context, detecting early faults in automated teller machines (ATMs) has become increasingly important since these machines are susceptible to various types of unpredictable failures. ATMs track execution status by generating massive event-log data that collect system messages unrelated to the failure event. Predicting machine failure based on event logs poses additional challenges, mainly in extracting features that might represent sequences of events indicating impending failures. Accordingly, feature learning approaches are currently being used in PdM, where informative features are learned automatically from minimally processed sensor data. However, a gap remains to be seen on how these approaches can be exploited for deriving relevant features from event-log-based data. To fill this gap, we present a predictive model based on a convolutional kernel (MiniROCKET and HYDRA) to extract features from the original event-log data and a linear classifier to classify the sample based on the learned features. The proposed methodology is applied to a significant real-world collected dataset. Experimental results demonstrated how one of the proposed convolutional kernels (i.e. HYDRA) exhibited the best classification performance (accuracy of 0.759 and AUC of 0.693). In addition, statistical analysis revealed that the HYDRA and MiniROCKET models significantly overcome one of the established state-of-the-art approaches in time series classification (InceptionTime), and three non-temporal ML methods from the literature. The predictive model was integrated into a container-based decision support system to support operators in the timely maintenance of ATMs.},
  archive      = {J_EAAI},
  author       = {Víctor Manuel Vargas and Riccardo Rosati and César Hervás-Martínez and Adriano Mancini and Luca Romeo and Pedro Antonio Gutiérrez},
  doi          = {10.1016/j.engappai.2023.106463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid feature learning approach based on convolutional kernels for ATM fault prediction using event-log data},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated learning self-triggered control for model-free
continuous-time systems with convergence guarantees. <em>EAAI</em>,
<em>123</em>, 106462. (<a
href="https://doi.org/10.1016/j.engappai.2023.106462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an integrated self-triggered control strategy with convergence guarantees for model-free continuous-time systems using reinforcement learning. To consider the control cost and triggering consumption in the self-triggered scheme simultaneously, an integrated cost function is proposed. With this integrated cost function, the trade-off between the triggering occupation and control performance could be adjusted according to different requirements. Then, the actor-critic framework of reinforcement learning is employed to learn the control inputs and triggering intervals by minimizing the corresponding integrated cost function. Considering the divergent characteristics between the control inputs and triggering intervals, two different actors are utilized to learn the triggering strategy and control policy, respectively. Also, the convergence of the developed model-free self-triggered control learning algorithm is proved to ensure the limited learning duration of both the control policy and triggering strategy. The proposed framework can be used to design self-triggered controllers for a wide range of engineering systems with unknow dynamics, including control of aircraft, robots, chemical processes, and other automated systems. Finally, the effectiveness and superiorities of the proposed method are verified by an illustrative example.},
  archive      = {J_EAAI},
  author       = {Haiying Wan and Hamid Reza Karimi and Xiaoli Luan and Shuping He and Fei Liu},
  doi          = {10.1016/j.engappai.2023.106462},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106462},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrated learning self-triggered control for model-free continuous-time systems with convergence guarantees},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DARWIN: An online deep learning approach to handle concept
drifts in predictive process monitoring. <em>EAAI</em>, <em>123</em>,
106461. (<a
href="https://doi.org/10.1016/j.engappai.2023.106461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive process monitoring (PPM) is a specific task under the umbrella of Process Mining that aims to predict several factors of a business process (e.g., next activity prediction) based on the knowledge learned from historical event logs. Despite recent PPM algorithms have gained predictive accuracy using deep learning, they commonly perform an offline analysis of event data assuming that logged processes remain in a steady state over time. However, this is often not the real-world case due to concept drifts. The main goal of this work is to solve the next-activity prediction problem under dynamic conditions of business data streams. To this aim, we propose DARWIN as a novel PPM method that detects concept drifts and adapts a deep neural model to concept drifts. A deep empirical analysis of different factors that may influence the performance of DARWIN in streaming scenarios is provided. Experiments with various benchmark event streams show the effectiveness of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Vincenzo Pasquadibisceglie and Annalisa Appice and Giovanna Castellano and Donato Malerba},
  doi          = {10.1016/j.engappai.2023.106461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DARWIN: An online deep learning approach to handle concept drifts in predictive process monitoring},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph dropout self-learning hierarchical graph convolution
network for traffic prediction. <em>EAAI</em>, <em>123</em>, 106460. (<a
href="https://doi.org/10.1016/j.engappai.2023.106460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is a challenging topic in urban traffic construction and management due to its complex dynamic spatial–temporal correlations. Currently, graph neural network achieves good results in traffic prediction, but the existing methods usually do not take into account the multi-layer information of the graph and the redundant transmission of information. Moreover, they do not consider the over-smoothing of the graph. In this paper, we propose a novel graph dropout self-learning hierarchical graph convolution network (DHGCN). Firstly, we design a self-learning hierarchical graph convolution network, which captures spatial features at different layers through multiple self-learning dynamic graphs and avoids redundant information transmission. Secondly, a novel graph dropout structure is proposed to sparsify the graph and avoid the over-smoothing of the graph. Meanwhile, an encoder–decoder architecture with gated residuals is designed to capture dynamic temporal features. In addition, this paper addresses two important traffic forecasting tasks: traffic flow and traffic speed. Extensive experiments with six real-world datasets verify that our method achieves state-of-the-art performance in both traffic flow and traffic speed and consistently outperforms baselines.},
  archive      = {J_EAAI},
  author       = {Qingjian Ni and Wenqiang Peng and Yuntian Zhu and Ruotian Ye},
  doi          = {10.1016/j.engappai.2023.106460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph dropout self-learning hierarchical graph convolution network for traffic prediction},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybridized machine-learning for prompt prediction of
rheology and filtration properties of water-based drilling fluids.
<em>EAAI</em>, <em>123</em>, 106459. (<a
href="https://doi.org/10.1016/j.engappai.2023.106459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Careful design and preparation of drilling fluids with appropriate rheology and filtration properties, combined with operational monitoring, is essential for successful drilling operations. Field results reveal that most drilling-fluid problems encountered are avoidable based on prompt detection of unexpected changes in fluid rheology and filtration behavior. Drilling-fluid rheology and filtration properties are typically only checked once or twice a day, whereas other drilling-fluid properties, such as fluid density (FD), solid percentage (S%), and March funnel viscosity (MFV), tend to be monitored several times per hour. Machine learning is therefore applied to estimate rheology and filtration properties with FD, S%, and MFV as input variables. A 1160-record field dataset collected from 14 wells drilled in two oil and gas fields in southwest Iran with water-based drilling fluids is used to predict the drilling fluid’s rheological and filtration characteristics. Plastic viscosity (PV), yield point (YP), and filtrate volume (FV) are the targeted prediction objectives. Of six models tested, Multilayer extreme learning machine (MELM) hybridized with the cuckoo optimization algorithm (COA) provides the best PV, YP, and FV predictions. It achieves root mean squared error (RMSE) values of 0.6357 mL (FV), 0.6086 cP (PV), and 0.6796 lb/100 ft 2 (YP). MELM-COA generates rapid and accurate estimations of rheology and filtration properties with potential for real-time monitoring during drilling operations, without recourse to time-consuming laboratory filtration and rheological tests. This work delivers, in a novel way, accurate and reliable predictions of drilling fluid filtration properties using only the more readily available FD, MFV, and S% variables as input features.},
  archive      = {J_EAAI},
  author       = {Shadfar Davoodi and Mohammad Mehrad and David A. Wood and Hamzeh Ghorbani and Valeriy S. Rukavishnikov},
  doi          = {10.1016/j.engappai.2023.106459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybridized machine-learning for prompt prediction of rheology and filtration properties of water-based drilling fluids},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CWAN: Self-supervised learning for deep grape disease image
composition. <em>EAAI</em>, <em>123</em>, 106458. (<a
href="https://doi.org/10.1016/j.engappai.2023.106458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape leaf diseases seriously affect grape yield and directly lead to the loss of the industrial economy. An accurate diagnosis is crucial for effective spraying and control. Presently, the combination of image blending and a deep recognition model is the most effective method for accurately identifying grape leaf diseases. Existing methods of image blending depend primarily on single-channel and multi-scale channel blending, computing and optimizing the Poisson equation, and the iterative optimization of learning-based methods for simple composite results. Although these methods have had some success, they are not able to simultaneously address lesion and leaf gap size, color bleeding, and edge smoothness. In this paper, we propose a novel image blending method named cascade wavelet attention network (CWAN). Specifically, CWAN consists of a cascade wavelet attention (CWA) and a blending autoencoder. First, we build a CWA to decompose the image into a multi-level and multi-scale frequency domain image. Then, the detailed features of the source and target domains are extracted, and the edges are smoothed. Following this, a shared decoder is designed to fuse these features in the corresponding frequency-domain layers, and the result serves as the attention feature. Finally, we design a blending autoencoder with a feature fusion mechanism to seamlessly blend lesions and leaves enhanced by CWA. We also construct a weighted blended loss function to avoid leaf color infiltration into the lesion in the blended image. Comprehensive experiments on two grape leaf disease datasets. Qualitative and quantitative results demonstrate the superiority and effectiveness of our model.},
  archive      = {J_EAAI},
  author       = {Haibin Jin and Xiaoquan Chu and Jianfang Qi and Xinxin Zhang and Weisong Mu},
  doi          = {10.1016/j.engappai.2023.106458},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106458},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CWAN: Self-supervised learning for deep grape disease image composition},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Adaptive weighted multiscale retinex for underwater image
enhancement. <em>EAAI</em>, <em>123</em>, 106457. (<a
href="https://doi.org/10.1016/j.engappai.2023.106457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-dependent underwater vehicles are widely used in seabed resource exploration. The visual perception system of underwater vehicles relies heavily on high-quality images for its regular operation. However, underwater images taken underwater often have color distortion, blurriness, and poor contrast. To address these degradation issues, we develop an adaptive weighted multiscale retinex (AWMR) method for enhancing underwater images. To utilize the local detail features, we first divide the image into multiple sub-blocks and calculate the detail sparsity index for each one. Then, we combine the global detail sparsity index with the local detail sparsity indices to determine the optimal scale parameter and corresponding weights for each sub-block. We apply retinex processing to each sub-block using these parameters and then subject the processed sub-blocks to detail enhancement, color correction, and saturation correction. Finally, we use a gradient domain fusion method based on structure tensors to fuse the corrected and enhanced sub-blocks and obtain the final output image. Our approach improves underwater images through comparisons with current state-of-the-art (SOTA) techniques on several open-source datasets, both quality, and performance.},
  archive      = {J_EAAI},
  author       = {Dayi Li and Jingchun Zhou and Shiyin Wang and Dehuan Zhang and Weishi Zhang and Raghad Alwadai and Fayadh Alenezi and Prayag Tiwari and Taian Shi},
  doi          = {10.1016/j.engappai.2023.106457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive weighted multiscale retinex for underwater image enhancement},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-sequential hesitant fuzzy entropy, cross-entropy and
correlation coefficient and their application to decision making.
<em>EAAI</em>, <em>123</em>, 106455. (<a
href="https://doi.org/10.1016/j.engappai.2023.106455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision making problems, the hesitance of the decision maker to the same decision object is reflected not only in the length of multiple possible memberships under, but also in the time dimension. The newly proposed time-sequential hesitant fuzzy set (TSHFS) can show the hesitance in decision making information from the view of time dimension, and in which the concept of hesitance of hesitant fuzzy sets is improved from a constructive perspective. However, it is difficult to further explore the application prospects of TSHFS in decision making as the current measurement methods, such as entropy, cross-entropy, and correlation coefficient, could not be leveraged directly in the TSHFS environment. For that entropy, cross-entropy, and correlation coefficient are important metric components of fuzzy sets and in related scenarios, we propose corresponding methods for TSHFS in this work. Meanwhile, to make full use of the importance of attribute information in the decision matrix and make the decision results have better discrimination ability, hesitant fuzzy diffusion decision model is proposed. The proposed entropy measures are constructed on trigonometric functions, the new cross-entropy measure and correlation coefficients are derived from classical counterparts, which enrich ways to deal with problems under the TSHFS environment, especially referring to decision making. In hesitant fuzzy diffusion decision model, the prior ordered value is defined as the final decision result to measure relationships among alternatives. The effectiveness and advantages of proposed entropy measures, cross-entropy measure, correlation coefficients, and the proposed decision model are demonstrated through the application of decision making.},
  archive      = {J_EAAI},
  author       = {Lingyu Meng and Liangqun Li and Weixin Xie and Yanshan Li and Zongxiang Liu},
  doi          = {10.1016/j.engappai.2023.106455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time-sequential hesitant fuzzy entropy, cross-entropy and correlation coefficient and their application to decision making},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Problem-specific knowledge MOEA/d for energy-efficient
scheduling of distributed permutation flow shop in heterogeneous
factories. <em>EAAI</em>, <em>123</em>, 106454. (<a
href="https://doi.org/10.1016/j.engappai.2023.106454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the global economy and the enhancement of environmental awareness, energy-efficient permutation flow shop scheduling gets more attention. Nevertheless, research on distributed scheduling with heterogeneous factories is scarce. In this paper, a knowledge-driven MOEA/D (KMOEA/D) is proposed to address the energy-efficient scheduling of distributed permutation flow shop problem in heterogeneous factories (DPFSP-HF) with the criteria of minimizing the makespan ( C m a x ) and total energy consumption ( T E C ). First, an efficient energy-saving strategy is proposed to reduce the T E C criteria. Second, a constructive heuristic is designed to generate a high-quality solution set. Third, an ingenious genetic operator is utilized to maintain population diversity. Fourth, the knowledge-driven local search operator combined the problem-specific knowledge is constructed according to the properties of DPFSP-HF. Additionally, the Taguchi approach is used to calibrate the parameter configuration of KMOEA/D. We evaluate the effectiveness of each improvement of KMOEA/D and compare it to other well-known multi-objective optimization algorithms on different instances. The results indicate the effectiveness of each improvement of KMOEA/D, and verify that KMOEA/D is an efficient approach to address DPFSP-HF.},
  archive      = {J_EAAI},
  author       = {Cong Luo and Wenyin Gong and Rui Li and Chao Lu},
  doi          = {10.1016/j.engappai.2023.106454},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106454},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Problem-specific knowledge MOEA/D for energy-efficient scheduling of distributed permutation flow shop in heterogeneous factories},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive fusion representation learning for foreground
object detection. <em>EAAI</em>, <em>123</em>, 106453. (<a
href="https://doi.org/10.1016/j.engappai.2023.106453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of an effective and robust fusion representation method for foreground moving object detection. Many fusion representation learning approaches pay attention to the similarity measurement between the fusion results and source images in texture details and pixel intensity, ignoring the harmful information, e.g., noise, blur, and extreme illumination. Therefore, the aggregated features of infrared and visible images will introduce much harmful information, affecting the model performance of downstream visual tasks. This paper tackles these problems by proposing a contrastive fusion representation learning method for the foreground moving object detection task, which consists of two major modules: the upstream fusion representation module (FRM) and the downstream foreground moving object detection module (FODM). Unlike the traditional fusion optimization mechanism, the former aims to extract valuable features and reject harmful features via the maximum mutual information theory. The latter is a siamese convolutional neural network to detect foreground moving objects by aggregating the time-sequence images generated by FRM. Experimental results and comparisons with the state-of-the-art on three public datasets (i.e., TNO, MF, and cross-modal FOD dataset of infrared and visible images), validate the effectiveness, robustness, and overall superiority of the proposed contrast fusion representation learning method. Concisely, our contrastive fusion representation learning has gained 53 . 9 % , 43 . 2 % , 46 . 4 % , 52 . 3 % , 2 . 2 % , 87 . 1 % , 3 . 5 % on EI, SF, DF, AG, MI, and Nabf metrics compared with the best competitors.},
  archive      = {J_EAAI},
  author       = {Pei Wang and Junsheng Wu and Aiqing Fang and Zhixiang Zhu and Chenwu Wang and Pengyuan Mu},
  doi          = {10.1016/j.engappai.2023.106453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive fusion representation learning for foreground object detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning for cross-scene 3D pavement crack
detection based on enhanced deep edge features. <em>EAAI</em>,
<em>123</em>, 106452. (<a
href="https://doi.org/10.1016/j.engappai.2023.106452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by heterogeneity of rapid-increasing 3D pavement data and the generalization ability of transfer learning, a robust and generalized framework for cross-scene 3D pavement-crack detection and attribute extraction was proposed in this paper, called profile component decomposition model with holistically nested edge detection (PCDM-HED). The core purpose of the PCDM-HED is to construct the enhanced deep edge features. By applying profile frequency, sparse characteristics of 3D profiles, and fusing the multiscale and multilevel edge characteristics of 3D depth maps in HED network, the robust enhanced feature can highlight the essential properties of cracks in heterogeneous 3D data. It overcomes the complex domain shifts caused by different 3D imaging conditions, pavement textures, and crack distributions in heterogeneous data. Cross-domain transfer experiments were carried out over seven 3D/2D datasets with 915 pavement sections. The results show that proposed PCDM-HED achieved average buffered Hausdorff scores of 90.17 to 96.42, recall scores of 0.84 to 0.91, and F-values of 0.85 to 0.89 in six different datasets without labeled samples. Compared with 9 groups of comparison results, including the traditional and related state-of-the-art methods, the transfer generalization effect of proposed PCDM-HED is more than 23% higher than that of comparison results. The proposed PCDM-HED makes full use of limited off-the-shelf samples, demonstrated strong transfer learning capability. It provides an effective solution for heterogeneous 3D pavement-crack detection tasks in engineering, in the case of limited labeled samples or even no corresponding labeled samples.},
  archive      = {J_EAAI},
  author       = {Rong Gui and Qian Sun and Wenqing Wu and Dejin Zhang and Qingquan Li},
  doi          = {10.1016/j.engappai.2023.106452},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106452},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transfer learning for cross-scene 3D pavement crack detection based on enhanced deep edge features},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DCDA-net: Dual-convolutional dual-attention network for
obstructive sleep apnea diagnosis from single-lead electrocardiograms.
<em>EAAI</em>, <em>123</em>, 106451. (<a
href="https://doi.org/10.1016/j.engappai.2023.106451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive sleep apnea (OSA) is a breathing-related chronic disease in which the soft palate and tongue collapse and block the upper airway for at least 10 s during sleep. It can lead to many heart diseases such as hypertension, myocardial infarction, and coronary heart syndrome if not detected early. Artificial intelligence has facilitated the diagnosis of many diseases in healthcare. Polysomnography is a widely used but unpleasant, time-consuming, technically demanding, and financially expensive procedure to detect OSA. Some previous methods have detected OSA using time-domain information from an electrocardiogram (ECG), whereas others have used frequency-domain information. The limitations of these two approaches can be handled using the data’s time–frequency representation. Nevertheless, there is room for enhancing the detection accuracy of OSA using the time–frequency representation approach. Therefore, we propose a novel technique that takes the ECG signal and detects R-peaks from the QRS complexes. Afterward, we interpolate those R-peaks by linear interpolation and get an interpolated-R signal. Then we magnify the interpolated-R signal corresponding to the apnea and normal frequency ranges. After magnification in the time domain, we transformed the magnified version into a scalogram. We also transformed the original one-minute ECG signal into a spectrogram after denoising. Overall, we used ECG signals to generate scalograms and spectrograms for 2 dimensional convolutional neural network (2D CNN) to classify obstructive sleep apnea. For apnea classification, we proposed a dual convolutional dual attention network (DCDA-Net) that includes a dual convolutionally modified inception module, a spatial attention module, and a channel attention module. Finally, we apply a support vector machine to the probability scores obtained from DCDA-Net based on the scalogram and spectrogram. Extensive experimental results using the open PhysioNet apnea ECG dataset confirm the effectiveness of our method in terms of accuracy and F1 score of 98% and 97.5%, respectively, which outperforms state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Nadeem Ullah and Tahir Mahmood and Seung Gu Kim and Se Hyun Nam and Haseeb Sultan and Kang Ryoung Park},
  doi          = {10.1016/j.engappai.2023.106451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DCDA-net: Dual-convolutional dual-attention network for obstructive sleep apnea diagnosis from single-lead electrocardiograms},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault-tolerant control based on adaptive dynamic programming
for reentry vehicles subjected to state-dependent actuator fault.
<em>EAAI</em>, <em>123</em>, 106450. (<a
href="https://doi.org/10.1016/j.engappai.2023.106450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the problem of fault tolerant control (FTC) for reentry vehicles (RV) subject to actuator fault and perturbation. In contrast to the majority of papers assuming bounded and exogenous actuator fault effect, the adaptive dynamic programming (ADP) control algorithm has been considered here to tackle with the dependence of closed-loop states induced by the setup of an active FTC strategy. By this way, the FTC problem formulation takes theoretically into account the fact that an actuator fault can destabilize a closed-loop. First, the FTC problem in attitude tracking is transformed into an error-optimal control problem. Next, a cost function based on zero-sum game theory is considered to achieve tracking under the joint influence of state-dependent actuator faults and perturbations. Lyapunov theory has been next used to prove the stability of FTC architecture and the network weight convergence. Benefits of proposed ADP-FTC algorithm is finally highlighted on a numerical benchmark of RV.},
  archive      = {J_EAAI},
  author       = {Guanjie Hu and Jianguo Guo and Jérôme Cieslak and Yixin Ding and Zongyi Guo and David Henry},
  doi          = {10.1016/j.engappai.2023.106450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault-tolerant control based on adaptive dynamic programming for reentry vehicles subjected to state-dependent actuator fault},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hierarchical adversarial multi-target domain adaptation
for gear fault diagnosis under variable working condition based on raw
acoustic signal. <em>EAAI</em>, <em>123</em>, 106449. (<a
href="https://doi.org/10.1016/j.engappai.2023.106449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic-based diagnosis (ABD) relied on air-coupled measurement is received great attention in recent years due to its ability in overcoming the limitation of vibration-based diagnosis on contact measurement. However, most of the ABD approaches are only focus on a stable working condition for analysis and research. Main challenge of ABD task is the unstable working condition including variable load and speed in real-industrial scenarios, which involve variation in amplitude and phase of acoustic signal to cause domain shift problem for fault pattern detection. In this condition, to perform ABD task for meeting the requirement of scalability in dealing with multiple targets under continuously variable working condition, a novel hierarchical adversarial multiple-target domains adaptation (HAMT-DA) learning framework is proposed in this paper. Following the naturally solution idea, a target-compress adversarial adaptation (TCAA) mechanism is developed in the first-level of framework to compress multiple-target domains by minimizing the feature distribution discrepancy over all domains, and narrow the divergence between source and target domains concurrently. Then, domain invariant feature refining (DIFR) strategy is designed to take responsibility for second-level domain adaptation in the intermediate of framework by refining domain invariant attribute and encoding the domain invariant feature into high-level semantic representation space. Subsequently, a class-separate adversarial adaptation (CSAA) method is explored in the roof of the hierarchical framework for the exploration of fault-discriminative property by forming third-level domain adaptation. Thus, the entire HAMT-DA learning framework can be obtained for single source to multiple-target (SSMT) cross-domain ABD task. The experiment result in variable working conditions indicate that the proposed method has more than 94% average diagnosis performance for gear fault patterns in five cross-domain validation tasks and achieve the highest recognition accuracy among four verifications, which is about 7% average improvement than that of the optimal comparison method. It verifies the superiority of our method on robustness and generalization for acoustic-based gear fault diagnosis under SSMT setting.},
  archive      = {J_EAAI},
  author       = {Yong Yao PhD and Qiuyi Chen and Gui Gui and Suixian Yang and Sen Zhang},
  doi          = {10.1016/j.engappai.2023.106449},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106449},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hierarchical adversarial multi-target domain adaptation for gear fault diagnosis under variable working condition based on raw acoustic signal},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of coordinate systems for vessel trajectory
prediction improvement using a recurrent neural networks. <em>EAAI</em>,
<em>123</em>, 106448. (<a
href="https://doi.org/10.1016/j.engappai.2023.106448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the Global Maritime Insurance annual report, among human and non-human risk factors, the number of accidents in maritime transport remains a significant issue. One of the factors is vessel collisions and anomalies at sea. Massive historical data from automatic identification systems are analyzed, and intelligent transportation systems are being developed to solve the problem of vessel trajectory prediction. The most ordinary attempt to improve accuracy is by evaluating the historical vessel behavior and learning the patterns and similarities of the predicted vessel movements. However, this paper shows that a better forecast also may be reached by choosing a different trajectory calculation strategy. The geographical or polar coordinate system values are used in a classical way, but several modifications, such as Universal Transverse Mercator (UTM), have been proposed in this study as an alternative to Mercator’s projection coordinates. Two main positioning of the vessels motion transformations were tested: by changing the coordinates to measurements of the angular distance (haversine) and displacement angle (azimuth) functions between different time steps; degree coordinates transformation into a Cartesian system using UTM with vector subtraction. The last case improves the accuracy of almost 30% in the available data sample by using the autoencoder architecture, compared to the longitude and latitude predictions even with computed delta features. The research generally compared three recurrent network architectures (with their hyperparameter – cell sizes): Autoencoder Long Short-Term Memory, Bi-directional Long Short-Term Memory, and Gated Recurrent Unit networks. The model calculations are performed in a real historical dataset, exclusively on cargo vessel type trajectories in the Netherlands (North Sea) coastal region. Also, the methods were validated in another dataset of the Baltic Sea Region.},
  archive      = {J_EAAI},
  author       = {Robertas Jurkus and Julius Venskus and Povilas Treigys},
  doi          = {10.1016/j.engappai.2023.106448},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106448},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of coordinate systems for vessel trajectory prediction improvement using a recurrent neural networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Decoupled variational autoencoder with interactive
attention for affective text generation. <em>EAAI</em>, <em>123</em>,
106447. (<a
href="https://doi.org/10.1016/j.engappai.2023.106447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial emotional intelligence (AEI) is an important ability for intelligent systems. Representing emotional states as a continuous sentiment intensity could achieve a more fine-grained sentiment application than traditional categorical approaches. By using sentiment intensity, the main challenge of the existing variational autoencoder methods lies in distinguishing emotional information from semantic information. Practically, it is difficult to ensure that the input training texts do not contain any sentiment. If the disentangled latent variable for text generation contains sentiment features that conflict with the assigned sentiment, the generated texts will be messy. Therefore, we propose a decoupled variational autoencoder (VAE) with interactive attention to solve this problem. The proposed method applies a sentiment decoupler to extract the sentiment from the text. Then, sentiment embeddings are applied to map the intensities into the latent space. To enhance the representation ability of sentiment embeddings and the performance of the decoder, we consider affective text generation as a process of denoising, design a noisy sampling strategy in training, and then continuously update the emotional information with variational attention through a dynamic update mechanism. Extensive experiments are conducted on the Yelp dataset and the Amazon dataset, and the experimental results show that our method outperforms other VAE-based methods in fine-grained affective text generation.},
  archive      = {J_EAAI},
  author       = {Ruijun Chen and Jin Wang and Liang-Chih Yu and Xuejie Zhang},
  doi          = {10.1016/j.engappai.2023.106447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Decoupled variational autoencoder with interactive attention for affective text generation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parallel crosschecking neural network based fault-tolerant
flight parameter estimation and faulty sensor identification.
<em>EAAI</em>, <em>123</em>, 106446. (<a
href="https://doi.org/10.1016/j.engappai.2023.106446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable flight parameter estimation is crucial for the safe operation of unmanned air vehicles. Recent studies on flight parameter estimation based on distributed airflow sensors have shown promising results; however, how to extract reliable flight parameters and locate faults in case of sensor failures are not studied yet. This paper proposes a novel fault-tolerant flight parameter estimation method with capabilities to identify and isolate faulty sensors for a flight parameter estimation system based on distributed airflow sensors. First, the distributed sensors are grouped into subsets using combinations. Second, feedforward backpropagation neural networks of the same structure are designed and used by all subsets for flight parameter estimation. The crosschecking between these parallel networks improves the robustness of the estimation. In case of sensor failures, the sensor groups that contain any faulty sensors will result in wrong flight parameter estimations. Especially, a directional random sample consensus algorithm is developed and used to identify the subsets that contain faulty sensors. Then, the ratio of the faulty subsets is used to identify the number of faulty sensors. Finally, the faulty sensors will be identified according to the frequencies of their appearance in the subsets that contain faulty sensors. The effectiveness of the proposed method is validated by using wind tunnel tests. The results show that the proposed method can effectively provide reliable flight parameters and identify faulty sensors.},
  archive      = {J_EAAI},
  author       = {Wanyong Zou and Ni Li and Ban Wang and Kaibo Wang and Shuhui Bu and Ming Zhou and He Shen},
  doi          = {10.1016/j.engappai.2023.106446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parallel crosschecking neural network based fault-tolerant flight parameter estimation and faulty sensor identification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing detection performance for robotic harvesting
systems through RandAugment. <em>EAAI</em>, <em>123</em>, 106445. (<a
href="https://doi.org/10.1016/j.engappai.2023.106445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting crops accurately is the key challenge for harvesting robots, and deep learning methods are commonly used for this purpose. However, these methods require a large amount of training data, which can be a constraint. Data augmentation is frequently recommended to enlarge the size of training data and enhance the performance of the detection models. In this paper, we propose the use of RandAugment (RA) to improve crop detection performance by applying geometric, photometric, and partial occlusion transformations. We experimented with different transformation lists using popular detection networks on Tomato datasets. YOLOv3 with geometric transformations and partial occlusion achieved the highest accuracy of 76.42, showing a 3.47 increase over the baseline model without augmentation. RA also improved detection accuracy on other public datasets such as Apple, Kiwi, and Mango. We found that the optimal combination of transformations varied for each network to achieve the best performance. Additionally, we implemented YOLOv3 with the optimal transformation list to demonstrate the robotic tomato harvesting system and achieved a computing time of less than 60 ms from capturing the camera image to receiving the detection results.},
  archive      = {J_EAAI},
  author       = {Giwan Lee and Phayuth Yonrith and Doyeob Yeo and Ayoung Hong},
  doi          = {10.1016/j.engappai.2023.106445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing detection performance for robotic harvesting systems through RandAugment},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SAR ship localization method with denoising and feature
refinement. <em>EAAI</em>, <em>123</em>, 106444. (<a
href="https://doi.org/10.1016/j.engappai.2023.106444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) ship detection is greatly important to marine transportation monitoring and fishery resource management. To improve the detection accuracy of small ships, an SAR ship localization method with Denoising and Feature Refinement (DFR) is proposed in this paper. It consists of three parts. The first part is the denoising module, which uses non-local mean to suppress the speckle noise of the SAR image. The second part is Hierarchical Feature Fusion (HFF) module. It can integrate more low-level features by adding skip connections. This prevents the low-level spatial position information of the fused features from being diluted by high-level semantic information, therefore it is beneficial to the detection of small ships. The third part is a center-based ship predictor with Feature Refinement (FR). The FR module is proposed to refine the features and reduce the background interference, which is conducive to locate ships more accurately. Extensive experiments are conducted. The experimental results show that after adding the denoising and FR modules, the value of AP 0.5 is increased by 1.7% and 2.3%, respectively, which proves the effectiveness of these two modules. In inshore and offshore scenarios, the AP 0.5 values of DFR are 0.884 and 0.966, respectively, achieving the best results. The proposed method can also be generalized to mark lesion locations in medical images and detect offshore oil production platforms.},
  archive      = {J_EAAI},
  author       = {Cheng Zha and Weidong Min and Qing Han and Wei Li and Xin Xiong and Qi Wang and Meng Zhu},
  doi          = {10.1016/j.engappai.2023.106444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SAR ship localization method with denoising and feature refinement},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A nondominated sorting genetic algorithm III with three
crossover strategies for the combined heat and power dynamic economic
emission dispatch with or without prohibited operating zones.
<em>EAAI</em>, <em>123</em>, 106443. (<a
href="https://doi.org/10.1016/j.engappai.2023.106443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a nondominated sorting genetic algorithm III with three crossover strategies (NSGA-III-TCS) for the combined heat and power dynamic economic emission dispatch (CHPDEED) problems with or without prohibited operating zones. The first strategy updates the individuals of the first nondomination rank by a modified improvisation of the harmony search algorithm, which accelerates the information exchanges of the elite individuals. The second strategy regulates the individuals of the last nondomination rank according to a modified single-point crossover of the genetic algorithm, which strengthens the convergence of the population. The third strategy adjusts the remaining individuals in terms of a modified DE/rand-to-best/1 mutation of the differential evolution algorithm, and it guides these individuals to move towards the ones which have at least one minimum objective function value, which is beneficial for expanding the distribution range of the population. NSGA-III-TCS obtains the largest average hypervolumes and shows a desirable convergence for six CHPDEED problems. NSGA-III-TCS achieves relatively high coverage rates in most cases, indicating the dominance of the Pareto sets of NSGA-III-TCS over those of the other algorithms. Also, it has relatively low average spacings for all problems, suggesting the good evenness of the Pareto sets.},
  archive      = {J_EAAI},
  author       = {Deliang Li and Chunyu Yang and Dexuan Zou},
  doi          = {10.1016/j.engappai.2023.106443},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106443},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A nondominated sorting genetic algorithm III with three crossover strategies for the combined heat and power dynamic economic emission dispatch with or without prohibited operating zones},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixed local channel attention for object detection.
<em>EAAI</em>, <em>123</em>, 106442. (<a
href="https://doi.org/10.1016/j.engappai.2023.106442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention mechanism, one of the most extensively utilized components in computer vision, can assist neural networks in emphasizing significant elements and suppressing irrelevant ones. However, the vast majority of channel attention mechanisms only contain channel feature information and ignore spatial feature information, resulting in poor model representation effect or object detection performance, and the spatial attention modules were often complex and expensive. In order to strike a balance between performance and complexity, this paper proposes a lightweight Mixed Local Channel Attention (MLCA) module to improve the performance of the object detection network, and it can simultaneously incorporate both channel information and spatial information, as well as local information and global information to improve the expression effect of the network. On this basis, the MobileNet-Attention-YOLO(MAY) algorithm for comparing the performance of various attention modules is presented. On the Pascal VOC and SMID datasets, MLCA achieves a better balance between model representation efficacy, performance, and complexity than alternative attention techniques. Against the Squeeze-and-Excitation(SE) attention mechanism on the PASCAL VOC dataset and the Coordinate Attention(CA) method on the SIMD dataset, the mAP is enhanced by 1.0 % and 1.5 %, respectively.},
  archive      = {J_EAAI},
  author       = {Dahang Wan and Rongsheng Lu and Siyuan Shen and Ting Xu and Xianli Lang and Zhijie Ren},
  doi          = {10.1016/j.engappai.2023.106442},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106442},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mixed local channel attention for object detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LSTM-NV: A combined scheme against selective forwarding
attack in event-driven wireless sensor networks under harsh
environments. <em>EAAI</em>, <em>123</em>, 106441. (<a
href="https://doi.org/10.1016/j.engappai.2023.106441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) are susceptible to selective forwarding attacks, which can lead to reduced network efficiency and compromise the integrity of transmitted data. The indistinguishability between malicious behavior and normal packet loss in harsh environments exacerbates the challenge. To address this, in this paper, we provide a combined detection scheme called LSTM-NV, consisting of a training stage and a detecting stage. During the training stage, we integrate variational mode decomposition (VMD) with a long short term memory (LSTM) model to learn normal nodes’ forwarding behavior and then predict errors for each node. During the detecting stage, dynamic thresholds are determined to identify local anomaly points and a novel neighbor voting method is employed to differentiate between malicious and normal nodes. Our scheme demonstrates superior performance with a low average missed detection rate (MDR) of 0.6% and a low average false detection rate (FDR) of 3.3% compared to other effective methods, while also offering lower detection algorithmic complexity.},
  archive      = {J_EAAI},
  author       = {Xinyu Huang and Shunan Li and Yuanming Wu},
  doi          = {10.1016/j.engappai.2023.106441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LSTM-NV: A combined scheme against selective forwarding attack in event-driven wireless sensor networks under harsh environments},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based LSTM network-assisted time series
forecasting models for petroleum production. <em>EAAI</em>,
<em>123</em>, 106440. (<a
href="https://doi.org/10.1016/j.engappai.2023.106440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Petroleum production forecasting is the process of predicting fluid production from the wells using historical data. In contrast to the traditional methods of analysing surface and subsurface parameters governing fluid production, machine learning (ML) techniques are being applied to forecast the production. The major drawback of traditional and conventional ML techniques is that they are time-consuming and often lack good forecasting power. In this work, time-series forecast models based on powerful and efficient ML techniques are developed to forecast production with historical data. We have fused the attention mechanism into the long short-term memory network, which is referred as the attention-based long short-term memory (A-LSTM) network. The A-LSTM network is fast and accurate, thus solving the low forecasting power problem. To ensure no data leakage occurs during training, and to build a reliable data-driven forecasting approach, we construct the dynamic floating window with varying window sizes over the entire production data. The dynamic floating window slides one-step forward after every prediction and continues till the last production window enabling the model to fit the new data automatically. We have tested and validated the proposed forecasting models with the ML algorithm using actual production data for three wells from entirely different geographies. We then compared them with statistical, deep learning, hybrid, and ML approaches. The genetic algorithm (GA) is applied to optimize the hyper-parameters of the A-LSTM. The results of a comparative analysis show that the A-LSTM network statistically and computationally outperforms the other models for forecasting petroleum production.},
  archive      = {J_EAAI},
  author       = {Indrajeet Kumar and Bineet Kumar Tripathi and Anugrah Singh},
  doi          = {10.1016/j.engappai.2023.106440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention-based LSTM network-assisted time series forecasting models for petroleum production},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Adaptive adversarial learning based cross-modal retrieval.
<em>EAAI</em>, <em>123</em>, 106439. (<a
href="https://doi.org/10.1016/j.engappai.2023.106439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exists a heterogeneity gap between multi-modal data, hence it is difficult to directly measure the similarity between them. A common way to solve the problem is representation learning. Due to the unique adversarial optimization principle and the efficient cross-modal correlation learning ability, the cross-modal retrieval based on Generative Adversarial Network (GAN) has received significant attention recently. However, the potential semantic information is not fully explored in most GAN-based cross-modal learning approaches. In this paper, we propose a novel Adaptive Adversarial Learning (AAL) based cross-modal retrieval method. The generator of a specific modality projects heterogeneous data into the potential common subspace, while the discriminator is against the generator to maintain discriminability. In addition, three task-specific loss functions are designed in the generators to comprehensively exploit the semantic and label information. One problem is that directly optimizing the generator network will lead to ignoring the assessment of contribution to multi-loss functions. To overcome the above challenge, we present an adaptive balance strategy to match the appropriate contribution for each loss according to the degree of dispersion. Comprehensive experimental results on three widely-used databases show that the proposed method is effective and superior to the existing cross-modal retrieval methods.},
  archive      = {J_EAAI},
  author       = {Zhuoyi Li and Huibin Lu and Hao Fu and Zhongrui Wang and Guanghua Gu},
  doi          = {10.1016/j.engappai.2023.106439},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106439},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive adversarial learning based cross-modal retrieval},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discrete limited attentional collaborative filtering for
fast social recommendation. <em>EAAI</em>, <em>123</em>, 106437. (<a
href="https://doi.org/10.1016/j.engappai.2023.106437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few years, social recommendation has attracted tremendous attention due to the ever-growing online social platform such as Twitter and Facebook. However, as the number of users increases rapidly, recommendation efficiency has become the bottleneck of many existing social recommender systems due to the computation and storage of real-valued models. For addressing the efficiency problem, recent researches resolve it by introducing hashing technique into social recommender systems. By mapping real values to discrete values, the computational speed is guaranteed as well as the storage cost is reduced. Nevertheless, these methods suffer from two critical limitations: (1) The inevitable quantization loss brought by hash function decreases recommendation accuracy to a certain extent. (2) The original social relations contain massive noise that may result in sub-optimal accuracy of recommendation without considering the fact that people can only pay attention to a small number of their friends. Therefore, to tackle the above limitations and have a better tradeoff between accuracy and efficiency, in this paper, we propose a novel social recommendation method called Discrete Limited Attentional Collaborative Filtering (DLACF), which models recommendation objective with limited attention as a constrained mix-integer optimization problem. Since the original problem is NP-hard, we further devise a computationally efficient optimization algorithm to learn the binary codes as well as to estimate the best influential friends. Experimental results conducted on two real-world datasets demonstrate the effectiveness of our proposed model, achieving the averaged improvement of 118.7% and 54.7% compared to state-of-the-art discrete methods.},
  archive      = {J_EAAI},
  author       = {Zhibin Hu and Xuebin Zhou and Zhiwei He and Zehang Yang and Jian Chen and Jin Huang},
  doi          = {10.1016/j.engappai.2023.106437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Discrete limited attentional collaborative filtering for fast social recommendation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised deep learning for the moving morphable components
topology optimization framework. <em>EAAI</em>, <em>123</em>, 106436.
(<a href="https://doi.org/10.1016/j.engappai.2023.106436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of mechanical engineering design, the field of machine learning accelerated topology optimization is dominated by image-based models trained in a supervised manner on datasets with a limited diversity of boundary conditions. State-of-the-art methods show poor generalization capabilities and are strongly coupled to finite element mesh resolution, hindering scalability. In this paper, we leverage the explicit topology parameterization of the moving morphable components (MMC) framework to train a deep learning model that directly generates geometric design variables using a model architecture that is independent of the finite element mesh used for structural analysis. The developed model is trained on a large dataset of boundary conditions. Despite achieving state-of-the-art regression loss, evaluations reveal that direct-design approaches generate topologies with poor mechanical performance. Specifically, the model-generated topologies have, on average, a stiffness 11.48% lower than conventional MMC designs, as evidenced by in-distribution and out-of-distribution test samples. We demonstrate that this is due to the incompatibility between the regression loss function typically used in literature and the topology optimization objective of compliance minimization. To address this issue, we propose a novel acceleration approach that leverages the trained model to generate improved initial designs for conventional optimization. Specifically, the deep learning model is used to generate an initial design, which is then refined by conventional optimization to arrive at a final, optimal design. This approach shows a computation time-saving of 36.84% without sacrificing the final mechanical performance of the optimal topology compared to conventional optimization starting from a uniform initial layout.},
  archive      = {J_EAAI},
  author       = {Thomas Rochefort-Beaudoin and Aurelian Vadean and Jean-François Gamache and Sofiane Achiche},
  doi          = {10.1016/j.engappai.2023.106436},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106436},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Supervised deep learning for the moving morphable components topology optimization framework},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hydraulic informed multi-layer perceptron for estimating
discharge coefficient of labyrinth weir. <em>EAAI</em>, <em>123</em>,
106435. (<a
href="https://doi.org/10.1016/j.engappai.2023.106435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data science techniques (DST) are the most popular approaches for estimating the discharge coefficient ( C d ) of labyrinth weirs (LW). This study proposes a hydraulic-informed multi-layer perceptron (HI-MLP) by incorporating the effects of hydraulic phenomena on C d , which were previously neglected due to their immeasurability. The HI-MLP is not a black box and selects its internal parameters considering the nape behavior attributes. HI-MLP is trained using Levenberg–Marquardt and Genetic algorithms, resulting in HI-MLP-LM and HI-MLP-GA, which are compared against adaptive neuro-fuzzy inference systems (ANFIS), support vector regression (SVR), and standard MLP. Evaluating the models through randomly selected testing data shows that HI-MLP-GA is the most accurate, with an MAEP of 0.732%, while all techniques also had acceptable performances. Conversely, when estimating C d for LWs with excluded intermediate and extrapolated geometries, only HI-MLP-LM and HI-MLP-GA could predict accurate values with average MAEP of 1.94% and 0.62%, respectively. This value in ANFIS and SVR was equivalent to 27.01% and 6.47%, respectively. Furthermore, hydraulic-informed techniques could be trained with at least a 25% smaller dataset, while the robustness analysis indicated that they are less prone to overfitting. HI-MLP-GA has the highest computational effort and is almost five times slower than HI-MLP-LM. Nevertheless, due to the disappearance of the vanishing gradient and considering the higher generalizability of HI-MLP-GA, GA is still a more desirable learning algorithm than LM.},
  archive      = {J_EAAI},
  author       = {Ali Mahmoud and Tiesong Hu and Xiang Zeng and Peiran Jing and Xiang Li and Elvira Da Costa Ribeiro},
  doi          = {10.1016/j.engappai.2023.106435},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106435},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hydraulic informed multi-layer perceptron for estimating discharge coefficient of labyrinth weir},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online classification of soybean seeds based on deep
learning. <em>EAAI</em>, <em>123</em>, 106434. (<a
href="https://doi.org/10.1016/j.engappai.2023.106434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To quickly evaluate soybean quality, we proposed a deep learning-based method for online classification of soybean seeds. Firstly, images of soybean seeds with uneven illumination were segmented based on the multi-scale Retinex with color restoration (MSRCR). Then, a convolutional neural network (CNN) was constructed to achieve soybean seed four-classification with appropriate parameters. The F-score of the normal, damaged, abnormal, and non-classifiable soybeans reached about 95.97%, 97.41%, 97.25%, and 96.14%, respectively. Finally, the method was successfully applied in NVIDIA Jetson TX2 with an accuracy of 95.63% and an average classification time of 4.92 ms for a soybean seed, which can meet the requirement of online soybean quality assessment.},
  archive      = {J_EAAI},
  author       = {Wei Lin and Lei Shu and Weibo Zhong and Wei Lu and Daoyi Ma and Yizhen Meng},
  doi          = {10.1016/j.engappai.2023.106434},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106434},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online classification of soybean seeds based on deep learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A real-time mechanical fault diagnosis approach based on
lightweight architecture search considering industrial edge deployments.
<em>EAAI</em>, <em>123</em>, 106433. (<a
href="https://doi.org/10.1016/j.engappai.2023.106433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical intelligence diagnostic models based on deep learning have increased diagnostic accuracy. However, the industrial application of deep-learning models is hindered by the extra memory requirement and the increasing computational overhead of deep-learning models, which limit edge deployment and reduce real-time performance, respectively. Therefore, we propose a mechanical fault diagnosis strategy based on a multi-objective automatic optimization architecture search that combines variable layer search, efficient search space, and a real-time search strategy. A lightweight diagnostic network that integrates the computing requirements of edge deployment, real-time testing, and accuracy is constructed. The proposed model considers the influence of compound faults and the strong noise of rotating machinery in engineering applications. The experiments on the defect data of two sets of rotating equipment show that our model is more lightweight and has higher accuracy than other advanced baselines.},
  archive      = {J_EAAI},
  author       = {Sihan Ma and Hongchun Sun and Sheng Gao and Guixing Zhou},
  doi          = {10.1016/j.engappai.2023.106433},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106433},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time mechanical fault diagnosis approach based on lightweight architecture search considering industrial edge deployments},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a machine learning-based framework for DDOS attack
detection in software-defined IoT (SD-IoT) networks. <em>EAAI</em>,
<em>123</em>, 106432. (<a
href="https://doi.org/10.1016/j.engappai.2023.106432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a complex and diverse network consisting of resource-constrained sensors/devices/things that are vulnerable to various security threats, particularly Distributed Denial of Services (DDoS) attacks. Recently, the integration of Software Defined Networking (SDN) with IoT has emerged as a promising approach for improving security and access control mechanisms. However, DDoS attacks continue to pose a significant threat to IoT networks, as they can be executed through botnet or zombie attacks. Machine learning-based security frameworks offer a viable solution to scrutinize the behavior of IoT devices and compile a profile that enables the decision-making process to maintain the integrity of the IoT environment. In this paper, we present a machine learning-based approach to detect DDoS attacks in an SDN-WISE IoT controller. We have integrated a machine learning-based detection module into the controller and set up a testbed environment to simulate DDoS attack traffic generation. The traffic is captured by a logging mechanism added to the SDN-WISE controller, which writes network logs into a log file that is pre-processed and converted into a dataset. The machine learning DDoS detection module, integrated into the SDN-WISE controller, uses Naive Bayes (NB), Decision Tree (DT), and Support Vector Machine (SVM) algorithms to classify SDN-IoT network packets. We evaluate the performance of the proposed framework using different traffic simulation scenarios and compare the results generated by the machine learning DDoS detection module. The proposed framework achieved an accuracy rate of 97.4%, 96.1%, and 98.1% for NB, SVM, and DT, respectively. The attack detection module takes up to 30% usage of memory and CPU, and it saves about 70% memory while keeping the CPU free up to 70% to process the SD-IoT network traffic with an average throughput of 48 packets per second, achieving an accuracy of 97.2%. Our experimental results demonstrate the superiority of the proposed framework in detecting DDoS attacks in an SDN-WISE IoT environment. The proposed approach can be used to enhance the security of IoT networks and mitigate the risk of DDoS attacks.},
  archive      = {J_EAAI},
  author       = {Jalal Bhayo and Syed Attique Shah and Sufian Hameed and Awais Ahmed and Jamal Nasir and Dirk Draheim},
  doi          = {10.1016/j.engappai.2023.106432},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106432},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards a machine learning-based framework for DDOS attack detection in software-defined IoT (SD-IoT) networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assistance from the ambient intelligence: Cyber–physical​
system applications in smart buildings for cognitively declined
occupants. <em>EAAI</em>, <em>123</em>, 106431. (<a
href="https://doi.org/10.1016/j.engappai.2023.106431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caregivers have traditionally provided assistance and care to patients with cognitive decline, but this has resulted in financial and emotional burdens for both caregivers and patients, impacting their quality of life. To address this issue, Ambient Assistive Living (AAL) technologies that incorporate Internet of Things (IoT) and Artificial Intelligence (AI) can replace or complement caregivers by enabling intelligent learning in smart buildings. This review evaluates the intelligence complements provided by smart buildings enabled with such capabilities to increase the quality of life and autonomy of cognitively declined occupants. Existing contributions primarily focus on learning occupants’ behavior to identify assistive services and solutions, which are delivered through technological interventions or caregivers. However, there are several key research gaps that need to be addressed. The most important is the lack of adequate implementation of technological interventions to fully support the occupants’ autonomy and independence. Other gaps include challenges in usability and acceptability, ethical concerns, systems’ comprehensiveness, and the need for human-in-the-loop. To address these gaps, a conceptual framework is proposed as future research directions for the applications of smart buildings supporting cognitively declined occupants. The framework aims to facilitate the implementation of technological interventions that can enhance occupants’ autonomy and independence, address usability and acceptability challenges, and ensure ethical considerations and system comprehensiveness. This review provides insights into the current state-of-the-art of AAL technologies and highlights research directions for improving the quality of life and autonomy of cognitively declined occupants.},
  archive      = {J_EAAI},
  author       = {Xinghua Gao and Saeid Alimoradi and Jianli Chen and Yuqing Hu and Shu Tang},
  doi          = {10.1016/j.engappai.2023.106431},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106431},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assistance from the ambient intelligence: Cyber–physical​ system applications in smart buildings for cognitively declined occupants},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Universum twin support vector machine with truncated pinball
loss. <em>EAAI</em>, <em>123</em>, 106427. (<a
href="https://doi.org/10.1016/j.engappai.2023.106427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For classification problems, twin support vector machine with pinball loss (Pin-GTSVM) is noise insensitive and has better performance than twin support vector machine (TWSVM). However, it lacks sparsity in comparison to TWSVM. In this article, to maintain a trade-off between the noise insensitivity and sparsity of the model along with preserving the theoretical properties of pinball loss, we propose universum twin support vector machine with truncated pinball loss (Tpin-UTWSVM). The proposed Tpin-UTWSVM considers universum data which gives prior information about the distribution of the data, thus improves the generalization performance of the proposed model. Further, the proposed optimization problem is non-convex and non-differentiable which is solved by concave–convex procedure. We employed the SOR approach to train the proposed model effectively with minimum training time. We conducted numerical experiments on 19 UCI binary datasets with different noise levels to validate the noise insensitivity of the proposed Tpin-UTWSVM model. We also conducted numerical experiments for electroencephalogram (EEG) signal classification and Alzheimer’s disease (AD) detection. The overall experimental outcomes and statistical tests demonstrate the superiority of the proposed Tpin-UTWSVM model in comparison to the baseline models. The source code for the proposed Tpin-UTWSVM is available at https://github.com/mtanveer1/Universum-twin-SVM-with-truncated-pinball-loss .},
  archive      = {J_EAAI},
  author       = {Anuradha Kumari and M. Tanveer and Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.engappai.2023.106427},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106427},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Universum twin support vector machine with truncated pinball loss},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent initial model and case design analysis of smart
factory for shipyard in china. <em>EAAI</em>, <em>123</em>, 106426. (<a
href="https://doi.org/10.1016/j.engappai.2023.106426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, due to the lack of core technology and technological innovation ability, the design technology of traditional shipyards in China is backward. The operation mode of front-line workers in shipyards is highly dangerous. There are problems that endanger the physical and mental health of workers, such as noise and paint mist pollution, which lead to low production efficiency of workers and difficulties in personnel allocation. Under this background, “shipyard labor shortage” and other similar situations followed. If the concept of smart factory is introduced into traditional shipyards, the above problems can be effectively alleviated and solved. However, due to the complexity of ship product structure processing and manufacturing, the definition of smart shipyard in China is still vague, and the research process of smart shipyard is relatively slow. Aiming at the vague functional concept of smart shipyard, the lack of research on information design and management, smart production process and smart implementation process, this paper provides a conceptual architecture design model of civil smart shipbuilding factory. The functional definition of smart shipyard is discussed, and the initial conceptual model of smart shipyard is established, including information network platform model, smart production process model and smart implementation process model. The application case verifies the above model. Firstly, the information network platform model of α group is constructed, and the group brain control system is established. Secondly, the smart production process of shipyard A under α group is established. Finally, the smart implementation process of shipyard A is designed. The case study shows that: All ships completed 100% modeling, and the pre-outfitting rate increased to about 95%. By using the wire cutting robot, the production efficiency is increased by 70%. In the smart factory mode, the 60,000 tons bulk carrier can save 35thousand dollars labor costs and 11 million dollars in shipping fuel costs each year. The shell steel plate of the 300,000 tons ore carrier is reduced by 212 tons, and the weight is reduced by 10.5%. Case shipyard A under α group using the above smart factory model can save about 0.7 million dollars labor costs per year; reduce fuel costs by about 2.2 million dollars per year; saving 2.5 million steel usage per year. In total, shipyard A reduced expenditure by about 5.4 million dollars in one year.},
  archive      = {J_EAAI},
  author       = {Zhengyao Yi and Siyao Mi and Tianqi Tong and Haoming Li and Yan Lin and Wenbiao Wang and Jiangbo Li},
  doi          = {10.1016/j.engappai.2023.106426},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106426},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent initial model and case design analysis of smart factory for shipyard in china},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-adaptive physics-driven deep learning for seismic wave
modeling in complex topography. <em>EAAI</em>, <em>123</em>, 106425. (<a
href="https://doi.org/10.1016/j.engappai.2023.106425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving for the scattered wavefield is a key scientific problem in the field of seismology and earthquake engineering. Physics-informed neural networks (PINNs) developed in recent years have great potential in possibly increasing the flexibility and efficacy of seismic modeling and inversion. Inspired by self-adaptive physics-informed neural networks (SA-PINNs), we introduce a framework for modeling seismic waves in complex topography The relevant theoretical model construction was performed using the one-dimensional (1D) wave equation as an example. Using SA-PINNs and combining them with sparse initial wavefield data formed by the spectral element method (SEM), we carry out a numerical simulation of two-dimensional (2D) SH wave propagation to realize typical cases such as infinite/semi-infinite domain and arc-shaped canyon/hill topography. For complex scattered wavefields, a sequential learning method with time-domain decomposition was introduced in SA-PINNs to improve the scalability and solution accuracy of the network. The accuracy and reliability of the proposed method to simulate wave propagation in complex topography were verified by comparing the displacement seismograms calculated by the SA-PINNs method with those calculated by the SEM. The results show that the SA-PINNs have the advantage of gridless and fine-grained simulation and can realize numerical simulation conditions, such as free surface and side-boundary wavefield transmission.},
  archive      = {J_EAAI},
  author       = {Yi Ding and Su Chen and Xiaojun Li and Suyang Wang and Shaokai Luan and Hao Sun},
  doi          = {10.1016/j.engappai.2023.106425},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106425},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-adaptive physics-driven deep learning for seismic wave modeling in complex topography},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Process monitoring using recurrent kalman variational
auto-encoder for general complex dynamic processes. <em>EAAI</em>,
<em>123</em>, 106424. (<a
href="https://doi.org/10.1016/j.engappai.2023.106424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, latent models have continued to find advantages in statistical process monitoring, especially with multifarious extensions coping with the nonlinearity and dynamics confronted by the pattern extraction. However, when later performing the famous T 2 statistic on the patterns, the issue of non-Gaussianity has rarely been focused alongside, hence vitiating the control of Type-I and -II error in practice. In this paper, a model, in the name of recurrent Kalman variational auto-encoder (RKVAE), is theoretically derived for handling these properties simultaneously, and proposed for its use on monitoring general complex processes. The main idea is to build a monitoring panel on the basis of further reasoning the dynamics underlying the nonlinearly extracted Gaussian features. The model hierarchically consists of three parts: the vanilla VAE for encoding latent Gaussian features, a linear Gaussian state-space model (LGSSM) for temporally reasoning these features, and an RNN for recurrently updating the online LGSSM by fusing several candidate parameters. For the latter K in the name, it is the Kalman filter (KF) that facilitates the feature noise filtering and LGSSM identification. The model has, structurally, a good capacity to be extensible from both the depth and width when modelling complex processes. Finally, based on the explicit formula of LGSSM, a detection panel is designed, and two case studies are given to demonstrate its effectiveness in monitoring and relevant analysis.},
  archive      = {J_EAAI},
  author       = {Zheng Zhang and Jinlin Zhu and Shuyu Zhang and Furong Gao},
  doi          = {10.1016/j.engappai.2023.106424},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106424},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Process monitoring using recurrent kalman variational auto-encoder for general complex dynamic processes},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RDJCNN: A micro-convolutional neural network for radar
active jamming signal classification. <em>EAAI</em>, <em>123</em>,
106417. (<a
href="https://doi.org/10.1016/j.engappai.2023.106417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely awareness of jamming situations and classification of jamming categories are vital for radars to suppress jamming, ensure viability, and maintain functions in complex electromagnetic environments. To satisfy strict time requirements for radars on embedded devices, a micro-dynamic convolutional neural network for jamming signal classification is proposed in this paper. The proposed network takes the range-Doppler distribution obtained from built-in radar signal processing as input. The proposed data augmentation algorithm, together with the attention mechanism and the efficient convolutional architecture, improves the generalization capability and reduces the computational complexity. In addition, we propose a dynamic depth mechanism based on a task difficulty evaluator that enables the network to be adjusted automatically and further reduces the average computational complexity of classification. Simulation results verify the advantages of our approach in size, accuracy, and efficiency. The proposed network achieved 98.82% and 85.00% top-1 accuracy in two datasets with only 1.73 M multiply–accumulate operations.},
  archive      = {J_EAAI},
  author       = {Hairui Zhu and Shanhong Guo and Weixing Sheng},
  doi          = {10.1016/j.engappai.2023.106417},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106417},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RDJCNN: A micro-convolutional neural network for radar active jamming signal classification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning approach for pediatric pneumonia diagnosis
using channel attention deep CNN architectures. <em>EAAI</em>,
<em>123</em>, 106416. (<a
href="https://doi.org/10.1016/j.engappai.2023.106416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray is the most commonly adopted non-invasive and painless diagnostic test for pediatric pneumonia. However, the low radiation levels for diagnosis make accurate detection challenging, and this initiates the need for an unerring computer-aided diagnosis model. Our work proposes stacking ensemble learning on features extracted from channel attention deep CNN architectures. The features extracted from the channel attention-based ResNet50V2, ResNet101V2, ResNet152V2, Xception, and DenseNet169 are individually passed through Kernel PCA for dimensionality reduction and concatenated. A stacking classifier with Support Vector Classifier, Logistic Regression, K-Nearest Neighbour, Nu-SVC, and XGBClassifier is employed for the final- Normal and Pneumonia classification. The stacking classifier achieves an accuracy of 96.15%, precision of 97.91%, recall of 95.90%, F1 score of 96.89%, and an AUC score of 96.24% on the publicly available pediatric pneumonia dataset. We expect this model to help the real-time diagnosis of pediatric pneumonia significantly.},
  archive      = {J_EAAI},
  author       = {Arun Prakash J. and Asswin C.R. and Dharshan Kumar K.S. and Avinash Dora and Vinayakumar Ravi and Sowmya V. and E.A. Gopalakrishnan and Soman K.P.},
  doi          = {10.1016/j.engappai.2023.106416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transfer learning approach for pediatric pneumonia diagnosis using channel attention deep CNN architectures},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pulse repetition interval modulation recognition using deep
CNN evolved by extreme learning machines and IP-based BBO algorithm.
<em>EAAI</em>, <em>123</em>, 106415. (<a
href="https://doi.org/10.1016/j.engappai.2023.106415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pulse repetition interval modulation (PRIM) recognition is a critical task in electronic intelligence (ELINT) and electronic support measure (ESM) systems for detecting radar threats accurately. However, PRI recognition is a complex issue due to missing and spurious pulses, resulting in noisy PRI pattern changes in real environments. To address this problem, this paper proposes a novel approach that recognizes the five common types of PRIM through a four-phase process. In the first phase, a deep convolutional neural network (DCNN) is used as a feature extractor. Then, extreme learning machines (ELMs) are used for real-time recognition of the PRIM patterns in the second phase. In the third phase, we employ the biogeography-based optimizer (BBO) to enhance the network’s robustness by optimizing the connection weights and biases. To address the increasing complexity of the model, we introduce an optimized variable-length internet protocol-based BBO (VBBO) in the fourth phase. In this approach (i.e., DCNN-VBBO-ELM), each layer of DCNN is encoded by an IP address into a habitat of VBBO in the same sequence as the DCNN layers. To evaluate the proposed method, we develop a real experimental dataset consisting of five common PRI patterns. Our approach achieves a final accuracy of 97.05%, which is better than other ELM-based benchmark models. Moreover, the proposed model requires only 27 s of training time to process 50,000 training images, confirming its real-time capabilities. In conclusion, our proposed approach improves PRI recognition by leveraging DCNN, ELM, and VBBO, resulting in a more accurate and robust real-time radar PRI classifier.},
  archive      = {J_EAAI},
  author       = {Seyed Majid Hasani Azhdari and Azar Mahmoodzadeh and Mohammad Khishe and Hamed Agahi},
  doi          = {10.1016/j.engappai.2023.106415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pulse repetition interval modulation recognition using deep CNN evolved by extreme learning machines and IP-based BBO algorithm},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fetal ECG extraction from maternal ECG using deeply
supervised LinkNet++ model. <em>EAAI</em>, <em>123</em>, 106414. (<a
href="https://doi.org/10.1016/j.engappai.2023.106414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fetal heart monitoring and early disease detection using non-invasive fetal electrocardiograms (fECG) can help substantially to reduce infant death through improved diagnosis of Coronary Heart Disease (CHD) in the fetus. Despite the potential benefits, non-invasive fECG extraction from maternal abdominal ECG (mECG) is a challenging problem due to multiple factors such as the overlap of maternal and fetal R-peaks, low amplitude of fECG, and various systematic and environmental noises. Conventional fECG extraction techniques, such as adaptive filters, independent component analysis (ICA), empirical mode decomposition (EMD), etc., face various performance issues due to the fECG extraction challenges. In this paper, we proposed a novel deep learning architecture, LinkNet++ (motivated by the original LinkNet) to extract fECG from abdominal mECG automatically and efficiently using two different publicly available datasets. LinkNet++ is equipped with a feature-addition method to combine deep and shallow levels with residual blocks to overcome the limitations of U-Net and UNet++ models. It also has deep supervised and densely connected convolution blocks to overcome the limitations of the original LinkNet. The proposed LinkNet++ model was evaluated using fECG signal reconstruction and fetal QRS (fQRS) detection. As a signal-to-signal synthesis model, LinkNet++ performed very well in two real-life datasets and achieved 85.58% and 87.60% Pearson correlation coefficients (PCC) between the ground truth and predicted fECG on two datasets, respectively. In terms of fQRS detection, it also outperformed most of the previous works and showed excellent performance with more than 99% of F1 scores on both datasets. Our results indicate that the proposed model can potentially extract fECG non-invasively with excellent signal quality, thereby providing an excellent diagnostic tool for various fetal heart diseases.},
  archive      = {J_EAAI},
  author       = {Arafat Rahman and Sakib Mahmud and Muhammad E.H. Chowdhury and Huseyin Cagatay Yalcin and Amith Khandakar and Onur Mutlu and Zaid Bin Mahbub and Reema Yousef Kamal and Shona Pedersen},
  doi          = {10.1016/j.engappai.2023.106414},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106414},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fetal ECG extraction from maternal ECG using deeply supervised LinkNet++ model},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A hybrid deep learning approach for the design of 2D low
porosity auxetic metamaterials. <em>EAAI</em>, <em>123</em>, 106413. (<a
href="https://doi.org/10.1016/j.engappai.2023.106413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the remarkable ability of Deep learning (DL) to abstract hidden information, it has been proven to be a powerful tool in many tasks related to the design of metamaterials. DL-aided design techniques can be generally categorized into two types, including forward designs, which are training surrogate models to accelerate the simulation process, and inverse design, which uses inverse modeling techniques to generate the design that satisfies the corresponding requirement. Although generative models have a unique capability to generate multiple designs instantly with random information, they often underperform in accuracy compared to designs based on optimization techniques. In this paper, a hybrid design framework combining the advantages of both DL forward design and the inverse design based on the mixture density network (MDN) is proposed. Then the proposed framework is implemented for the inverse design of S-shaped perforated auxetic metamaterial. The hybrid design framework inherited the one-to-many mapping capability of MDN and has great capability of generating designs with designated mechanical properties at less than 10% relative errors, in most design scenarios (over 95% in the test set), at one to two orders of magnitude less computational cost compared to optimization-based forward design.},
  archive      = {J_EAAI},
  author       = {Chonghui Zhang and Jiarui Xie and Ali Shanian and Mitch Kibsey and Yaoyao Fiona Zhao},
  doi          = {10.1016/j.engappai.2023.106413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid deep learning approach for the design of 2D low porosity auxetic metamaterials},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An EA-based pruning on improved YOLOv3 for rapid copper
elbow surface defect detection. <em>EAAI</em>, <em>123</em>, 106412. (<a
href="https://doi.org/10.1016/j.engappai.2023.106412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though deep learning models can be applied for the surface defect detection of industry products, it remains a challenge to widely deploy them on embedded carriers due to high computation and large memory requirements. To deal with this challenge, this paper proposed to search for the best pruning architecture of the YOLO(You Only Look Once)v3 model with the Particle Swarm Optimization evolutionary algorithm for model channel Pruning (PSOP), in addition to focusing on the importance of filters in a convolutional layer. An automatic sparsity training technique is induced in PSOP to generate an initial model before pruning. PSO searching speed is accelerated as a fast evaluation method is employed during training. A linear multi-object strategy is utilized to help PSO find the best structure for the pruning model in the searching period. PSOP outperforms many outstanding pruning methods. For instance, evaluated by our copper elbow dataset, the pruned YOLOv3 saves 62.93% of the model volume, 72.28% floating-point operations, and 62.96% parameter size with only 3.13% accuracy loss. The pruned YOLOv3 model is successfully deployed on NVIDIA Jetson Nano B01 embedded platform to improve copper elbow plant productivity.},
  archive      = {J_EAAI},
  author       = {Yuanqing Xian and Yang Yu and Youzao Lian and Jinfu Fan and Zhongjie Wang},
  doi          = {10.1016/j.engappai.2023.106412},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106412},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An EA-based pruning on improved YOLOv3 for rapid copper elbow surface defect detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Error-distribution-free kernel extreme learning machine for
traffic flow forecasting. <em>EAAI</em>, <em>123</em>, 106411. (<a
href="https://doi.org/10.1016/j.engappai.2023.106411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow modeling plays a crucial role in intelligent transportation systems, which is of vital significance for mitigating traffic congestion and reducing carbon emissions. Owing to the uncertainties and nonlinear characteristics of traffic flow, it confronts a considerable challenge to establish a model to predict traffic flow efficiently and robustly. Kernel-based extreme learning machine (KELM), a natural extension of extreme learning machine (ELM) that incorporates kernel learning, has demonstrated excellent performance in traffic flow prediction. However, the performance of KELM may significantly decrease when the noise is non-Gaussian, as it was developed under the minimum mean square error (MMSE) criterion assuming Gaussian noise. To address this issue, we propose an error-distribution-free kernel extreme learning machine, termed ɛ D F KELM, by embedding a more robust optimization criterion to guide the training. In addition, we further develop an online version of the ɛ D F KELM model for continual forecasting, called ɛ D F KELM v 2 . We perform extensive experiments on two widely-used public benchmark traffic flow datasets, which illustrate that the ɛ D F KELM model outperforms the state-of-the-art approaches in terms of forecasting performance. ɛ D F KELM model achieves RMESE values of 251.49 vehs/h, 196.27 vehs/h, 216.97 vehs/h, and 160.92 vehs/h on the A1, A2, A4, and A8 highways of Amsterdam dataset, respectively.},
  archive      = {J_EAAI},
  author       = {Keer Wu and Changhong Xu and Jingwen Yan and Fei Wang and Zhizhe Lin and Teng Zhou},
  doi          = {10.1016/j.engappai.2023.106411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Error-distribution-free kernel extreme learning machine for traffic flow forecasting},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decision system for copper flotation backbone process.
<em>EAAI</em>, <em>123</em>, 106410. (<a
href="https://doi.org/10.1016/j.engappai.2023.106410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposed a decision system that can output the flotation backbone flowchart using the natural properties of copper ore. The proposed decision system includes three decision tasks: product scheme, flotation scheme and grinding scheme. Each decision task is a multi-label classification problem. To improve the classification effect of each sub-label, extreme gradient boosting (XGBoost) is used as a subclassifier, because of its ability to deal with small and high-dimensional samples. To selectively utilize the relations between the sub-labels in the same task, a modified classifier chain (MCC) was proposed. To specifically use the effect of a front-end task on a back-end task, the decision system connects the MCC-XGBoost corresponding to the three tasks in series. Accordingly, the outputs of a front-end task becomes the candidate features of a back-end task. To improve the recall rates of minority classes, the classification thresholds are customized using the Yoden index. Finally, the high performance of the decision system was demonstrated by hypothesis testing.},
  archive      = {J_EAAI},
  author       = {Haipei Dong and Fuli Wang and Dakuo He and Yan Liu},
  doi          = {10.1016/j.engappai.2023.106410},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106410},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Decision system for copper flotation backbone process},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaborative filtering recommendations based on
multi-factor random walks. <em>EAAI</em>, <em>123</em>, 106409. (<a
href="https://doi.org/10.1016/j.engappai.2023.106409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using trust relationships can improve the accuracy of recommendation systems; however, it is affected by data sparsity. Random walks can harvest the behavioral relationships between users and compensate for data sparsity. However, existing random walk methods may generate information of little value or even interference, which affects recommendation accuracy. A collaborative filter recommendation based on multi-factor random walk was proposed to address these problems. In this method, the comprehensive trust values of the current user over other users based on the rating time, user attribute preference, and number of mutual friends were computed more accurately to determine the trust neighborhood of the current user. Thus, trustworthy users with preferences similar to those of the current user were accurately and conveniently obtained to act as neighboring users, and the sparsity of the trust relationship could be alleviated. The final predicted rating of the target item was obtained using the ratings of multiple neighboring users for the target item or similar items to improve recommendation accuracy. Moreover, to avoid generating ratings that affect the prediction accuracy during the walk, a decision to stop the walk was made based on the comprehensive trust value, item similarity, and depth of the current walk, further improving the recommendation accuracy. An evaluation was performed on two datasets, and the proposed method achieved superior prediction accuracy and coverage rate even with sparse data and exhibited a high recommendation accuracy even with cold-start users.},
  archive      = {J_EAAI},
  author       = {Liangmin Guo and Kaixuan Luan and Li Sun and Yonglong Luo and Xiaoyao Zheng},
  doi          = {10.1016/j.engappai.2023.106409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Collaborative filtering recommendations based on multi-factor random walks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic clustering ensemble learning approach for crude
oil price forecasting. <em>EAAI</em>, <em>123</em>, 106408. (<a
href="https://doi.org/10.1016/j.engappai.2023.106408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate oil price forecasts matter, yet the nonstationarity of oil prices makes forecasting a challenging task. In this study, we propose a dynamic ensemble forecasting method for nonstationary oil prices using clustering approaches. Specifically, clustering is embedded in the ensemble forecasting framework, whereby the given period of historical observations is automatically classified into several clusters according to the data characteristics. This classification provides a solid groundwork for dynamically evaluating individual forecasting models in a targeted manner. We then propose a clustering-based regular increasing monotone weight assignment strategy that removes the influence of outliers and assigns appropriate weights to each forecasting model, thereby balancing the competitiveness and robustness of the proposed ensemble model. We verify the competitiveness and robustness of the proposed model by using West TX Intermediate oil prices. Results show that the proposed model significantly outperforms benchmarks and state-of-the-art methods in terms of horizontal and directional accuracy and is thus competitive. The robustness of the proposed model is validated using scenarios involving parameter variation and data missing assumptions. In summary, we present a model with promising effectiveness in promoting prediction performance in forecasting oil prices.},
  archive      = {J_EAAI},
  author       = {Jiaxin Yuan and Jianping Li and Jun Hao},
  doi          = {10.1016/j.engappai.2023.106408},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106408},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic clustering ensemble learning approach for crude oil price forecasting},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative adversarial super-resolution at the edge with
knowledge distillation. <em>EAAI</em>, <em>123</em>, 106407. (<a
href="https://doi.org/10.1016/j.engappai.2023.106407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-Image Super-Resolution can support robotic tasks in environments where a reliable visual stream is required to monitor the mission, handle teleoperation or study relevant visual details. In this work, we propose an efficient Generative Adversarial Network model for real-time Super-Resolution, called EdgeSRGAN 1 . We adopt a tailored architecture of the original SRGAN and model quantization to boost the execution on CPU and Edge TPU devices, achieving up to 200 fps inference. We further optimize our model by distilling its knowledge to a smaller version of the network and obtain remarkable improvements compared to the standard training approach. Our experiments show that our fast and lightweight model preserves considerably satisfying image quality compared to heavier state-of-the-art models. Finally, we conduct experiments on image transmission with bandwidth degradation to highlight the advantages of the proposed system for mobile robotic applications.},
  archive      = {J_EAAI},
  author       = {Simone Angarano and Francesco Salvetti and Mauro Martini and Marcello Chiaberge},
  doi          = {10.1016/j.engappai.2023.106407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generative adversarial super-resolution at the edge with knowledge distillation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiview abnormal video synopsis in real-time.
<em>EAAI</em>, <em>123</em>, 106406. (<a
href="https://doi.org/10.1016/j.engappai.2023.106406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of surveillance cameras has resulted in an exponential growth in video data, which has created several challenges for video data analysis, extraction, and storage. Video synopsis is an efficient methodology for analyzing and storing video data because it creates short videos. However, existing video synopsis methods are inappropriate for abnormal behavior situations (e.g., constructing a video synopsis of only abnormal frames emphasizing gun and knife characteristics to predict violent activity). As most existing video synopsis methods rely on the foreground and multiple objects tracking preprocessing, they perform poorly in real-time scenarios, particularly in crowded situations. We proposed a video synopsis approach suitable for multiview cameras to mitigate this problem; it can also be applied to radically diverse crowdedness. A considerable difference exists between the proposed method and existing approaches because it has several unique properties. We first detected abnormal segments from a given video and then tracked and extracted the frames. We can extract the required meaningful data by applying this method, which increases the synopsis generation performance. Second, we created a summary of all the videos. Finally, a stitching algorithm was used to create the synopsis.},
  archive      = {J_EAAI},
  author       = {Palash Yuvraj Ingle and Young-Gab Kim},
  doi          = {10.1016/j.engappai.2023.106406},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106406},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiview abnormal video synopsis in real-time},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent detection of warning bells at level crossings
through deep transfer learning for smarter railway maintenance.
<em>EAAI</em>, <em>123</em>, 106405. (<a
href="https://doi.org/10.1016/j.engappai.2023.106405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Level Crossings are among the most critical railway assets, concerning both the risk of accidents and their maintainability, due to intersections with promiscuous traffic and difficulties in remotely monitoring their health status. Failures can be originated from several factors, including malfunctions in the bar mechanisms and warning devices, such as light signals and bells. This paper focuses on the intelligent detection of anomalies in warning bells through non-intrusive acoustic monitoring by: (1) introducing a new concept for autonomous monitoring of level crossings; (2) generating and sharing a specific dataset collecting relevant audio signals from publicly available audio recordings; (3) implementing and evaluating a solution combining deep learning and transfer learning for warning bell detection. The results show a high accuracy in detecting anomalies and suggest viability of the approach in real-world applications, especially where network cameras with on-board microphones are installed for multi-purpose level crossing surveillance.},
  archive      = {J_EAAI},
  author       = {Lorenzo De Donato and Stefano Marrone and Francesco Flammini and Carlo Sansone and Valeria Vittorini and Roberto Nardone and Claudio Mazzariello and Frédéric Bernaudin},
  doi          = {10.1016/j.engappai.2023.106405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent detection of warning bells at level crossings through deep transfer learning for smarter railway maintenance},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional probability based multi-objective cooperative
task assignment for heterogeneous UAVs. <em>EAAI</em>, <em>123</em>,
106404. (<a
href="https://doi.org/10.1016/j.engappai.2023.106404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In actual air combat, there is an inevitable risk that an unmanned aerial vehicle (UAV) will be destroyed. However, this risk is rarely considered in the mission planning phase. In this paper, we focus on cooperative mission assignment for heterogeneous UAVs. We develop a multi-objective optimization model to find a balance between mission gains and UAV losses. The objective function is expressed using conditional probability theory by introducing the probabilities of mission success and UAV loss. Munitions loading capacity, time constraints, and priority constraints are modeled as constraints. To solve this combinatorial problem, an improved multi-objective genetic algorithm, which incorporates a natural chromosome encoding format and specially designed genetic operators, is developed. An efficient unlocking method is constructed to address the unavoidable dead-lock phenomenon meanwhile maintaining the population randomness. Numerical simulations for different problem sizes and ammunition stocks are performed, and the proposed algorithm is compared with the Multi-objective Particle Swarm Optimization and the Multi-objective Grey Wolf Optimization, respectively, using different unlocking approaches. The simulation and comparison results demonstrate the practical value and effectiveness of the developed model and the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Xiaohua Gao and Lei Wang and Xinyong Yu and Xichao Su and Yu Ding and Chen Lu and Haijun Peng and Xinwei Wang},
  doi          = {10.1016/j.engappai.2023.106404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Conditional probability based multi-objective cooperative task assignment for heterogeneous UAVs},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequency stability prediction of renewable energy
penetrated power systems using CoAtNet and SHAP values. <em>EAAI</em>,
<em>123</em>, 106403. (<a
href="https://doi.org/10.1016/j.engappai.2023.106403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the complexity of power systems increases, traditional model-driven methods for online frequency stability prediction (FSP) encounter constraints in both accuracy and efficiency. To enhance the accuracy and efficiency of FSP, an data-driven method using CoAtNet and SHAP values is proposed. By leveraging the combination of convolution and attention mechanisms, CoAtNet addresses the limitation of traditional deep learning approaches that may not be able to extract data features comprehensively. Moreover, selecting all features as input into a deep-learning model may cause a substantial computation burden. It is thus impractical for CoAtNet to perform FSP of large-scale power systems. For this problem, this paper develops a SHAP values-based feature selection method to select the effective features as input. This process greatly reduces the numerical complexity, maintaining a high prediction performance. Additionally, the marginally stable situation of the system frequency is ignored by most researchers. A frequency security index to identify marginally stable situations is thus employed to generate the data labels, which are classed as “absolute security”, “relative security”, and “insecurity”. Finally, verified by the comparison simulation, the proposed model outperforms other models with accuracies of 98.80% on the modified IEEE 39-bus system and 99.04% on the modified ACTIVSg500 system.},
  archive      = {J_EAAI},
  author       = {Peili Liu and Song Han and Na Rong},
  doi          = {10.1016/j.engappai.2023.106403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Frequency stability prediction of renewable energy penetrated power systems using CoAtNet and SHAP values},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-stream representation fusion learning for accurate
medical image segmentation. <em>EAAI</em>, <em>123</em>, 106402. (<a
href="https://doi.org/10.1016/j.engappai.2023.106402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmenting regions of interest in various medical images are essential to clinical research and applications. Although deep learning-based methods have achieved good results, the fully automated segmentation results still need to be refined on the tininess, complexities, and irregularities of lesion shapes. To address this issue, we propose a Dual-stream Representation Fusion Learning (DRFL) paradigm for accurate clinical segmentation, including Dual-stream Fusion Module, Representation Fusion Transformer Module and Peakiness Fusion Attention Module. Specifically, Dual-stream Fusion Module can simultaneously generate binary masks and high-resolution images with segmentation stream and super-resolution stream that share a feature extractor, then both prediction outputs are merged as the input of Fusion Module to further improve the performance of the network for generating the final segmentation result; Representation Fusion Transformer Module is lightweight to fuse high-resolution representation and fine-grained structure representation; Peakiness Fusion Attention Module can capture more salient features while fusing more spatial information to improve the performance of the network. The effectiveness of our dual-stream representation fusion learning is validated on different medical image segmentation tasks, and extensive experiments show that our DRFL outperforms the state-of-the-art methods in segmentation quality of lung nodule segmentation, lung segmentation, cell contour segmentation, and prostate segmentation. Our code is available at https://github.com/Rongtao-Xu/RepresentationLearning/tree/main/DRFL-EAAI2023 .},
  archive      = {J_EAAI},
  author       = {Rongtao Xu and Changwei Wang and Shibiao Xu and Weiliang Meng and Xiaopeng Zhang},
  doi          = {10.1016/j.engappai.2023.106402},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106402},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-stream representation fusion learning for accurate medical image segmentation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EEG-based seizure prediction via hybrid vision transformer
and data uncertainty learning. <em>EAAI</em>, <em>123</em>, 106401. (<a
href="https://doi.org/10.1016/j.engappai.2023.106401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature embeddings derived from continuous mapping using the deep neural network are critical for accurate classification in seizure prediction tasks. However, the embeddings of individual electroencephalogram (EEG) samples learned through modern decoding algorithms may contain ambiguous and noisy representations, owing to the susceptibility of weak EEG signals to interference from other signals unrelated to EEG activity. To address this issue, we consider data uncertainty learning (DUL), which models each representation of the EEG sample as a Gaussian or Laplacian distribution to mitigate potential noise interference and enhance model robustness. Moreover, data uncertainty learning for transformer architectures is seldom explored due to the limitation of multi-headed self-attention mechanisms in processing local features and the vanishing of potential top-level gradients. In this study, we introduce a novel hybrid visual transformer (HViT) architecture, which enhances the processing capability of localized features in the transformer through the convolutional neural network (CNN). Concretely, we learn the mean of the distribution using the HViT, and an additional branch is designed to capture the variance of the Gaussian distribution or the scale of the Laplacian distribution during training. We also propose a learnable manner to learn constraint coefficients in the loss functions for different patients, resulting in better optimization across patients. In addition, we introduce a simple uncertainty quantification method for each alarm of the k -of- n continuous prediction strategy by utilizing the continuity of the EEG signals. Empirical evaluations on two publicly available epilepsy datasets demonstrate the superiority of our DUL method and the effectiveness of the proposed HViT architecture.},
  archive      = {J_EAAI},
  author       = {Zhiwei Deng and Chang Li and Rencheng Song and Xiang Liu and Ruobing Qian and Xun Chen},
  doi          = {10.1016/j.engappai.2023.106401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EEG-based seizure prediction via hybrid vision transformer and data uncertainty learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An industrial disaster emergency decision-making based on
china’s tianjin city port explosion under complex probabilistic hesitant
fuzzy soft environment. <em>EAAI</em>, <em>123</em>, 106400. (<a
href="https://doi.org/10.1016/j.engappai.2023.106400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency decision-making is vital for nations or communities because it increases emergency management’s effectiveness and legitimacy, which in turn greatly minimizes environmental damage, fatalities, and economic loss. The evaluation of emergency judgements must take into account significant inaccuracy, fuzzyness, and ambiguity. While high risk and uncertainty are frequently characteristics of emergency decision-making (EDM) circumstances. The current EDM methodologies do not take into account the psychological behavior of the decision makers in addition to the various emergency situations and the various responses. In this paper, we presented a new method based on a Complex Probabilistic Hesitant Fuzzy Soft Set (CPHFSS) as represented by membership in 2-D with hesitant probability. The idea that is being put forth captures the ambiguity and takes into account emergency situations while also taking into account the psychological state of the decision-makers involved in the EDM procedure. The introduction of a new score function for the CPHFSS serves as the second objective of this paper, which is to address a number of comparability issues. We examine a novel family of hybrid operators for CPHFSS that utilize numerous independent variables as a solution to these unforeseen issues. The group decision-making strategy and EDAS technique are then suggested employing these operators. Later, an emergency decision-making situation involving a major fire in China is used to demonstrate the validity of the algorithms.},
  archive      = {J_EAAI},
  author       = {Shahzaib Ashraf and Harish Garg and Muneeba Kousar},
  doi          = {10.1016/j.engappai.2023.106400},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106400},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An industrial disaster emergency decision-making based on china’s tianjin city port explosion under complex probabilistic hesitant fuzzy soft environment},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage online remaining useful life prediction
framework for supercapacitors based on the fusion of deep learning
network and state estimation algorithm. <em>EAAI</em>, <em>123</em>,
106399. (<a
href="https://doi.org/10.1016/j.engappai.2023.106399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supercapacitors have been widely used in many fields. The safe and stable operation of supercapacitors requires accurate remaining useful life (RUL) prediction. This paper proposes a two-stage online RUL prediction framework based on the bidirectional long short-term memory (BiLSTM) network and the H ∞ observer. In Stage 1, the BiLSTM network as well as the Bayesian Optimization algorithm is used to estimate capacitance. The Bayesian Optimization (BO) algorithm aims to optimize the hyperparameters of the BiLSTM network. In Stage 2, the estimated capacitance is handled by the moving average filter (MAF) to alleviate short-term fluctuations. The double exponential model is employed to describe the degradation trajectory, and the model is iteratively updated by the H ∞ observer with the estimated capacitance as the measurement. Experiments are implemented to verify the validation of the proposed framework. The results indicate that the BiLSTM network can explain more than 99% variation of capacitance. The deviation of RUL prediction is less than 6% in most cases, and it is even less than 2.5% in late phase. The proposed framework takes the advantages of online deployment, and achieves competitive prediction accuracy when compared with offline methods.},
  archive      = {J_EAAI},
  author       = {Gongmao Lou and Wenwen Lin and Guoxin Huang and Wei Xiang},
  doi          = {10.1016/j.engappai.2023.106399},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106399},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage online remaining useful life prediction framework for supercapacitors based on the fusion of deep learning network and state estimation algorithm},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust scheduling of EMU first-level maintenance in a
stub-end depot under stochastic uncertainties. <em>EAAI</em>,
<em>123</em>, 106398. (<a
href="https://doi.org/10.1016/j.engappai.2023.106398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequently occurring and unavoidable perturbations in railway systems cause a reduction in performance and even the infeasibility of the original schedule. In addition, existing related studies assume that the maintenance routes are fixed in a deterministic situation. Therefore, it is necessary to focus on robust scheduling of electric multiple units first-level maintenance with flexible maintenance routes to defend against stochastic uncertainties. Firstly, a mixed-integer linear programming model with uncertain parameters in objective functions and constraints is built for the first time. Multiple constraints are formulated to consider flexible maintenance routes, train shunting conflicts, and track occupation conflicts in a stub-end depot. A robust optimization approach is adopted to obtain a deterministic robust counterpart model with uncertainties in processing/arrival/departure times. In this model, uncertainty and reliability levels are introduced to describe and quantify the disturbance degree of processing/arrival/departure times and the allowable violation degree of resource constraints respectively. Moreover, an adaptive iterative local search is proposed by embedding heuristic rules for the initialization. The proposed algorithm includes problem-specific neighborhood structures to improve the evolutionary ability, a variable neighborhood descent method to guide and drive the search toward promising areas of the search space, and an adaptive perturbation mechanism to enable the algorithm to jump out of local optimum. Numerical results from China’s railway system validate the proposed model and quantitatively demonstrate the merit of the proposed algorithm. Further analysis shows that our approach can achieve an appropriate trade-off between robustness and efficiency for various uncertainty and reliability levels.},
  archive      = {J_EAAI},
  author       = {Ming He and Qiuhua Tang and Jatinder N.D. Gupta and Zikai Zhang and Jun Cao},
  doi          = {10.1016/j.engappai.2023.106398},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106398},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust scheduling of EMU first-level maintenance in a stub-end depot under stochastic uncertainties},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Screening of retired batteries with gramian angular
difference fields and ConvNeXt. <em>EAAI</em>, <em>123</em>, 106397. (<a
href="https://doi.org/10.1016/j.engappai.2023.106397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of electric vehicles, the second usage of retired batteries becomes a key issue. The accuracy of existing screening methods for retired batteries is highly dependent on the feature selection from charging or discharging curves. This paper proposes a novel method of screening retired batteries, in which the constant current (CC) charging curves are converted into images by Gramian angular difference fields (GADF) and classified with a ConvNeXt network. Firstly, the CC charging voltage data is reasonably reduced by piecewise aggregation approximation. Secondly, the CC voltage curves are encoded into images by GADF to make small differences more distinguishable. Then, a ConvNeXt network is used for screening the retired batteries because of its excellent performance on accuracy and scalability. Finally, validation experiments are carried out on 143 retired high-power lithium-ion batteries, and the results show that the proposed screening method has a classification detection accuracy of 93.71%.},
  archive      = {J_EAAI},
  author       = {Mingqiang Lin and Jian Wu and Jinhao Meng and Wei Wang and Ji Wu},
  doi          = {10.1016/j.engappai.2023.106397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Screening of retired batteries with gramian angular difference fields and ConvNeXt},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-objective transportation problem under quantity
dependent credit period and cost structure policies in triangular
intuitionistic fuzzy environment. <em>EAAI</em>, <em>123</em>, 106396.
(<a href="https://doi.org/10.1016/j.engappai.2023.106396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major economic activities of a business concern is transportation of its products without any hassle. Therefore, the research on a transportation problem is very important now-a-days. In a classical transportation problem, the amount incurred for shipping the goods from the source to a destination is determined on the basis of unit transportation cost. But now, in many practical cases, it is seen that the unit transportation cost is settled on the basis of transported amount. In such a direction, this article develops a transportation problem to transport the produced items from a production house to some retailers through some distributors. The system has two cost parameters, one is actual unit transportation cost and other is demanded unit transportation cost. The actual unit transportation cost is the cost incurred during the transportation while the demanded unit transportation cost is the cost demanded by the distributors. Here, the demanded unit transportation cost has been decided depending on the amount of transported item. Since in the system, there are more than one distributor, distributors offer a credit period policy to attract the retailers. On the basis of the deterioration of the loaded amount, the transported items are classified into two categories. For the higher deteriorated items, the transportation cost is relatively larger and for the lower deteriorated items, the transportation cost is relatively lower with the increase in the loading amount. Considering the above two categories, two crisp models are developed. Due to the uncertain information of the actual unit transportation cost, the models are illustrated considering the actual unit transportation cost as a triangular intuitionistic fuzzy number. The main objective of this research is to minimize the total cost of the retailers and to maximize the total profit of the distributors simultaneously under the above circumstances. For crispification, two different methods have been used here — one is an existing method namely ordered weighted average operator and other is a developed average value approach. Also, the elitist non-dominated sorting genetic algorithm (NSGA-II) and the fuzzy programming technique have been used to get the optimal solution of this problem. To justify the impact and significance of the proposed models on this decision making system, some numerical studies have been done and it is observed that distributors and retailers both benefit more under the credit period policy than the policy without credit period. This study discusses the situation under which the uncertain parameters are to be expressed in terms of triangular intuitionistic fuzzy numbers. Also, it is identified that more accurate crispification has been done by the average value approach than the existing approach.},
  archive      = {J_EAAI},
  author       = {Raj Kumar Bera and Shyamal Kumar Mondal},
  doi          = {10.1016/j.engappai.2023.106396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective transportation problem under quantity dependent credit period and cost structure policies in triangular intuitionistic fuzzy environment},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel transfer learning network with adaptive input length
selection and lightweight structure for bearing fault diagnosis.
<em>EAAI</em>, <em>123</em>, 106395. (<a
href="https://doi.org/10.1016/j.engappai.2023.106395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, great progress has been made in intelligent bearing fault diagnosis based on transfer learning (TL). However, the huge number of parameters is ignored when using large convolutional neural network (CNN), and the input length of different bearings are almost not take into account. The high-energy hardware economic cost and time consumption caused by slow operation of large CNN have brought great difficulties to the engineering practice. Therefore, inspired by envelope demodulation and lightweight network signal processing methods, a novel lightweight TL network is proposed, which can adaptively select the input length (IL) and accurately identify the bearing health states under different work conditions. Firstly, an innovative adaptive IL selection strategy considering bearing differences is proposed to replace manually fixed IL. Secondly, a TL network containing group convolution and instance normalization is constructed to make the network lightweight and operate faster. Thirdly, maximum mean discrepancy is introduced to align the feature distribution between source domain and target domain. Lastly, 81 tasks are carried out on the across-domain datasets to validate the practicability of the proposed method. The results between accuracy and lightweight demonstrate that the proposed method is superior to other four state-of-the-art TL CNN, including three TL CNN and a lightweight model, under identical conditions.},
  archive      = {J_EAAI},
  author       = {Guiting Tang and Cai Yi and Lei Liu and Xingguo Yang and Du Xu and Qiuyang Zhou and Jianhui Lin},
  doi          = {10.1016/j.engappai.2023.106395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel transfer learning network with adaptive input length selection and lightweight structure for bearing fault diagnosis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial domain adaptation using contrastive learning.
<em>EAAI</em>, <em>123</em>, 106394. (<a
href="https://doi.org/10.1016/j.engappai.2023.106394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent research, problems with biased datasets or domain shift have presented challenges to the practical applications of deep learning methods. In this paper, we propose a simple method using adversarial learning combined with contrastive learning and domain adaptation to solve the domain-shift problem. Because domain shift is caused by differences in the distribution of data across domains, different approaches have been proposed to resolve this by rendering the data distributions closer through adversarial training. Contrastive learning is a method of acquiring valid feature representations for downstream tasks. By combining these approaches, we aim to achieve better domain adaptation. The proposed method is simple and intuitive. By introducing a domain discriminator into SimCLR, which is a typical contrastive learning model, and training it in an adversarial manner, the feature vectors of the source and target domains are rendered closer to acquire domain-invariant features. The proposed approach facilitates high-performance pretraining without labels and demonstrates a significant improvement in accuracy in comparison to standard benchmark methods, including conventional supervised models and SimCLR.},
  archive      = {J_EAAI},
  author       = {Chiori Azuma and Tomoyoshi Ito and Tomoyoshi Shimobaba},
  doi          = {10.1016/j.engappai.2023.106394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial domain adaptation using contrastive learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global conformance checking measures using shallow
representation and deep learning. <em>EAAI</em>, <em>123</em>, 106393.
(<a href="https://doi.org/10.1016/j.engappai.2023.106393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformance checking refers to techniques that can compare normative process behavior, typically captured by process models, and observed process behavior, usually captured in an event log. Recently, machine and deep learning methods have been proposed to tackle multiple problems in process mining, mostly for predictive process monitoring purposes. In this work, we propose two different neural network-based conformance checking techniques, allowing for a fully data-driven approach. Concretely, two approaches for measuring fitness and precision are introduced, using techniques from representation learning and deep learning respectively. The first approach relies on computing the distances between process traces coming from both an event log and a process model by means of vector representations extracted from a shallow neural network trained in a self-supervised setting. The second approach uses a recurrent neural network trained on an event log and a log containing artificially created counterfactuals. The first setup of these methods is tested on a proof-of-concept artificial event log, a plethora of artificially generated process models, and 4 real-life data sets. Our approaches exhibit generally promising and interesting results and in this way provide fully data-driven alternatives to other conformance checking techniques, which are usually model-driven. Moreover, they allow for a possible combination of different purposes, when already using neural networks for process discovery or predictive process monitoring.},
  archive      = {J_EAAI},
  author       = {Jari Peeperkorn and Seppe vanden Broucke and Jochen De Weerdt},
  doi          = {10.1016/j.engappai.2023.106393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Global conformance checking measures using shallow representation and deep learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on an unsupervised person re-identification based
on image quality enhancement method. <em>EAAI</em>, <em>123</em>,
106392. (<a
href="https://doi.org/10.1016/j.engappai.2023.106392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on person re-identification(Re-ID) has important value in pedestrian detection, target tracking, criminal investigation, and other related fields. In unsupervised pedestrian recognition algorithms, the accuracy of pseudo-labels is crucial to the recognition results. However, in practical scenarios, low-quality images caused by factors such as differences in camera resolution and shooting angles can affect the extraction of pedestrian features by these algorithms, thereby negatively impacting the accuracy of the labels and the learning process of the model. To address this problem, we propose an image quality enhancement algorithm for unsupervised person Re-ID (IQE). To the best of our knowledge, this study is the first to introduce detail enhancement and the application of low-light enhancement algorithms into unsupervised person Re-ID. By improving the feature extraction quality based on these two aspects, higher-quality pseudo-labels can be constructed. This method improves the accuracy of feature extraction and clustering, thereby increasing the accuracy of pseudo-labels and reducing the interference of noisy pseudo-labels. The experimental results showed that the IQE method outperformed state-of-the-art person Re-ID methods in terms of Rank-1 accuracy and mAP. Specifically, IQE achieved an 87.9% rank-1 accuracy and a 71.2% mAP on the Market-1501 dataset; a 78.1% rank-1 accuracy and a 61.7% mAP On the DukeMTMC-reID dataset; and a 51.1% rank-1 accuracy and 24.2% mAP on the MSMT17 dataset.},
  archive      = {J_EAAI},
  author       = {Zhangang Hao and Hongwei Ge and Jiajian Huang},
  doi          = {10.1016/j.engappai.2023.106392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on an unsupervised person re-identification based on image quality enhancement method},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cascade of convolutional models for few-shot automatic
cephalometric landmarks localization. <em>EAAI</em>, <em>123</em>,
106391. (<a
href="https://doi.org/10.1016/j.engappai.2023.106391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cephalometric landmarks are used in many forensic tasks of great relevance. Nevertheless, the automatic localization of such points is greatly underdeveloped in the scientific literature, especially on in-the-wild images where no published work is available. Inspired by state-of-the-art automatic facial landmark localization research, we present a method based on a cascade of conditional convolutional networks for predicting high-resolution cephalometric landmarks under specific conditions: using a size-limited dataset of in-the-wild images usually handled by forensic anthropologists. Every contribution is thoroughly ablated and validated. We compare our proposal against top-performing standard facial landmark localization methods. Furthermore, we conduct a user study comparing our performance against expert annotators on a different problem-specific dataset. The results show that we outperform competing methods in a cephalometric landmarks dataset by a large margin, two times better than the closest one, and achieve human-like performance in half of the cases. For its good results, our proposal will be included in Skeleton-ID, a commercial solution for forensic identification assisted by artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Guillermo Gomez-Trenado and Pablo Mesejo and Oscar Cordon},
  doi          = {10.1016/j.engappai.2023.106391},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106391},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cascade of convolutional models for few-shot automatic cephalometric landmarks localization},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IDD-net: Industrial defect detection method based on
deep-learning. <em>EAAI</em>, <em>123</em>, 106390. (<a
href="https://doi.org/10.1016/j.engappai.2023.106390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting defects in industrial products is one of the most widespread applications of industrial automation. Various product defects, large similarities, and drastic changes in scale in industrial scenarios pose challenges to existing industrial inspection networks. This paper proposes a deep learning-based industrial defect detection method (IDD-Net) to address the above challenges. Specifically, IDD-Net has three distinct features. First, for the defects of diversity and similarity (rolled-in_scale, crazing in steel defects), IDD-Net designed a novel local–global backbone feature network (LGB-Net). Second, IDD-Net proposes a novel Three-Layer Feature Aggregation network (TFLA-Net) to solve the problem of drastic scale changes. TFLA-Net adopts a novel three-layer descending method to aggregate semantic and fine-grained features effectively. At the same time, the dense connection of adjacent nodes of TFLA-Net ensures the efficient fusion of features of different scales in the network. In particular, this paper proposes a novel IoU loss (Defect-IoU loss) for the problem of object loss deviation at different scales. The novelty of Defect-IoU Loss is that the loss value is scaled by the difference in the area of different scale objects, which is more conducive to the balance of multi-scale object loss. The experimental results show that the calculation amount of IDD-Net is only 24.9 Gflops, and the mAP@.5 of 79.66%, 99.5%, and 95.9% in the steel defect, aluminium defect, and PCB defect datasets were respectively obtained, surpassing all comparison models. In addition, the test in the actual industrial scene also demonstrates the feasibility of the application of IDD-Net.},
  archive      = {J_EAAI},
  author       = {Zekai Zhang and Mingle Zhou and Honglin Wan and Min Li and Gang Li and Delong Han},
  doi          = {10.1016/j.engappai.2023.106390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IDD-net: Industrial defect detection method based on deep-learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning model for intelligent home energy management
system using renewable energy. <em>EAAI</em>, <em>123</em>, 106388. (<a
href="https://doi.org/10.1016/j.engappai.2023.106388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Home automation is seen as a potential pillar of the smart city revolution that combines smart mobility, lifestyle and ecosystem governed by intelligent sensors connected to the internet. Households can save money and be more comfortable with automated appliances. The cost of electricity and user comfort are fundamentally contradictory, so they can be presented as a dynamic multi-objective optimization problem with fluctuating priorities for the customer to use various devices at different times. For this reason, this paper proposes an advanced Intelligent Home Energy Management (IHEM) approach based on reinforcement learning to achieve home demand response (DR) efficiency. The optimal formulation of the one-hour-ahead energy consumption scheduling problem is considered a Markov Decision Process (MDP) with discrete time steps. An efficient Neural Network (NN)-based approach with a Q-learning algorithm is developed to address this problem, enabling the IHEM system to achieve better cost-effective scheduling performance. The accurate data of electricity price and energy supplied by the Photovoltaic (PV) system are analyzed in sliding periods by machine learning for uncertainty prediction. Using the newly developed approach, which has the dual objective of minimizing the electricity bill, it is possible to obtain scheduling decisions for appliances and energy storage. The results show that the proposed optimization method reduces the monthly electricity costs by 20% compared to the Integer Linear Programming (ILP)-based HEMS method.},
  archive      = {J_EAAI},
  author       = {Sami Ben Slama and Marwan Mahmoud},
  doi          = {10.1016/j.engappai.2023.106388},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106388},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning model for intelligent home energy management system using renewable energy},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-based prediction of preplaced aggregate
concrete characteristics. <em>EAAI</em>, <em>123</em>, 106387. (<a
href="https://doi.org/10.1016/j.engappai.2023.106387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preplaced-Aggregate Concrete (PAC) is a type of preplaced concrete where coarse aggregate is placed in the mold and a Portland cement-sand grout with admixtures is injected to fill the voids. Due to the complex nature of PAC, many studies were conducted to determine the effects of admixtures and the compressive and tensile strengths of PAC. Considering that a prediction tool is needed to estimate the compressive and tensile strengths of PAC, this research developed 12 supervised Machine Learning (ML) algorithms in Python software to provide estimations for civil engineers. To prepare the training and testing datasets, a comprehensive investigation was performed to prepare experimental studies on the compressive and tensile strengths of PAC. Then, according to the features of the dataset, four scenarios were defined based on the input features. The capability of ML algorithms was investigated in each scenario. Results showed that the ETR, RDF, and BR algorithms achieved the prediction accuracy of 98.3%, 95.3% and 94.6%, respectively, for estimating the compressive strength of PAC with input features of Case B. Therefore, due to the performance of the ML models, their generality was investigated by preparing the experimental test of two specimens of PAC and by validating the results. Notably, that the proposed ML models (e.g. BR method) can accurately predict the compressive and tensile strengths of specimens (e.g. with accuracy of 98.4 ∼ 99.7%, respectively) and can be used to facilitate and reduce the experimental tests as well as the experimental efforts.},
  archive      = {J_EAAI},
  author       = {Farzam Omidi Moaf and Farzin Kazemi and Hakim S. Abdelgader and Marzena Kurpińska},
  doi          = {10.1016/j.engappai.2023.106387},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106387},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based prediction of preplaced aggregate concrete characteristics},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Service quality evaluation of crowdsourcing logistics
platform based on fermatean fuzzy TODIM and regret theory.
<em>EAAI</em>, <em>123</em>, 106385. (<a
href="https://doi.org/10.1016/j.engappai.2023.106385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The service quality valuation of crowdsourcing logistics platforms can be considered as a typical multi-index evaluation issue. Fermatean fuzzy numbers can fully express uncertain and blurry information for service quality evaluation. Hence, considering that evaluator has limited rationality, with the psychology of loss aversion and regret avoidance in the evaluation process, this article constructs a Fermatean fuzzy TODIM model combined with regret theory to assess the service quality of crowdsourcing logistics platforms. Of note, the range maximum method is utilized to calculate the weight of index, which avoids the influence of the information fluctuation of the weight obtained by the simple weighted summation of subjective and objective weights on the final consequence. Finally, the effectiveness and superiority of the proposed method are verified using a realistic example and comparison analysis.},
  archive      = {J_EAAI},
  author       = {Yan Pan and Shouzhen Zeng and Wendi Chen and Jiaxing Gu},
  doi          = {10.1016/j.engappai.2023.106385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Service quality evaluation of crowdsourcing logistics platform based on fermatean fuzzy TODIM and regret theory},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-spatial normalized transformer for image captioning.
<em>EAAI</em>, <em>123</em>, 106384. (<a
href="https://doi.org/10.1016/j.engappai.2023.106384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-attention modules have shown dominance in image captioning. However, current self-attention modules insufficiently consider spatial correlations between objects in an image and easily suffer from distribution shifts. In this work, we aim to improve self-attention modules in two ways to solve the above problems. We first propose a Spatial-Enhanced Attention (SEA) module, which incorporates dual spatial encodings to enhance geometric correlations between visual instances. We further introduce a Gated-Normalized Attention (GNA) module to fix the distributions inside self-attention module. GNA module also smooths gradients and reduces misleading information. To prove our designs, we apply SEA module and GNA module to the standard Transformer to construct a novel Dual-Spatial Normalized Transformer (DSNT), which captures a more accurate spatial representations and improves performance of image captioning. Extensive experiments are conducted to verify the effectiveness of our proposal. Compared to non-pretrained state-of-the-art methods, quantitative results on the MSCOCO dataset show that our DSNT achieves competitive performance on both the offline and online test sets, i.e., 134.8% CIDEr score on the Karpathy split and 134.0% CIDEr score on the official split. Our source code is available at https://github.com/TBI805/DSNT .},
  archive      = {J_EAAI},
  author       = {Juntao Hu and You Yang and Yongzhi An and Lu Yao},
  doi          = {10.1016/j.engappai.2023.106384},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106384},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-spatial normalized transformer for image captioning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft-margin ellipsoid generative adversarial networks.
<em>EAAI</em>, <em>123</em>, 106383. (<a
href="https://doi.org/10.1016/j.engappai.2023.106383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) are of great significance for synthetizing realistic images. However, GANs are potentially unstable during the training process, posing some challenges for their development. By defining an integral probability metric (IPM) on the hypersphere, Sphere GAN enforces the discriminator to satisfy Lipschitz continuity and stabilizes the training process. Developed from Sphere GAN, a soft-margin Ellipsoid GAN is proposed for improving the quality of generated samples and the stability of training process. In the presented method, the geometric moment difference defined on the hypersphere is generalized to the hyperellipsoid. The hyperellipsoid is realized to relax the upper bound of the IPM by extending measurable functions space, thus the quality of generated samples can be improved. Furthermore, a nonlinear separating hyperellipsoid is designed to prevent the discriminator from gradient vanishing and exploding on the classification boundary. The proposed soft-margin Ellipsoid GAN is proved theoretically to have a global optimal solution, i.e., the probability density of generated samples approaches to that of real samples infinitely when both the discriminator and the generator are optimal. The CIFAR10 and LSUN-bedrooms datasets are selected to evaluate the performance of the proposed methods. The quantitative results show that the proposed approach decreases the Fréchet inception distance (FID) on the two datasets by 8.2% and 16.0%, respectively. The qualitative results show that the proposed soft-margin mechanism improves the stability of the training process.},
  archive      = {J_EAAI},
  author       = {Zheng Jiang and Bin Liu and Weihua Huang},
  doi          = {10.1016/j.engappai.2023.106383},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106383},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soft-margin ellipsoid generative adversarial networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pre-clustering active learning method for automatic
classification of building structures in urban areas. <em>EAAI</em>,
<em>123</em>, 106382. (<a
href="https://doi.org/10.1016/j.engappai.2023.106382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the structures of buildings in urban areas is a prerequisite for robust urban planning and regeneration. Owing to the diverse structural designs of urban buildings, automated approaches are required to classify building structures. Supervised machine learning is usually employed to classify various building characteristics. However, this approach requires significant labeling effort. Therefore, this paper proposes a new pre-clustering active learning method for building structure classification. The proposed method captures the statistical characteristics of samples and enhances the recognition of the most valuable training samples, thereby substantially reducing the labeling workload and improving the efficiency and effectiveness of classification. This method was tested via the classification of 3718 buildings in Beijing, China, into five common structures. The results showed that the proposed method could reduce labeling effort by 60% while achieving a promising 90% F1 score for overall classification performance, thus indicating its effectiveness.},
  archive      = {J_EAAI},
  author       = {Peng Zhou and Tongxin Zhang and Liwen Zhao and Yifan Qi and Yuan Chang and Lu Bai},
  doi          = {10.1016/j.engappai.2023.106382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pre-clustering active learning method for automatic classification of building structures in urban areas},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel multiclass-based framework for p300 detection in BCI
matrix speller: Temporal EEG patterns of non-target trials vary based on
their position to previous target stimuli. <em>EAAI</em>, <em>123</em>,
106381. (<a
href="https://doi.org/10.1016/j.engappai.2023.106381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interface (BCI) provides a new communication pathway for severely disabled people and enables them to communicate with external world using only their brain activity. P300-based BCI speller helps patients spell words using their brain signals. Until now, binary-classification-based approaches have been used for P300 detection. This study demonstrates that binary-classification-based approaches may not be appropriate for P300 detection. We proved that temporal EEG patterns of non-target trials are different based on their position to previous target stimuli. Therefore, considering all non-target trials in only one group makes distinguishing target from non-target components difficult for machine learning algorithms and, consequently, deteriorate character recognition accuracy. This study introduced a novel approach for P300 detection in BCI spellers. In this study, we first divided non-target trials into several groups according to their temporal patterns in training stage. Then, we introduced a multiclass-based framework for P300 detection. Proposed approach is evaluated with three public datasets, BCI competition II, BCI competition III and the BNCI Horizon. In all three datasets, proposed multi-class approach outperformed common binary-classification-based approach in the same conditions. In addition, multiclass-based approach reached the highest accuracy (100%) in the 3th sequence for BCI competition II, for BCI competition III achieved an average accuracy of 74% and 98% in 5th and 15th sequences and, for the BNCI Horizon dataset achieved an average accuracy of 77.50% and 97.49% in 5th and 10th sequences, respectively. That means our proposed approach, regardless of its simplicity, achieved state-of-the-art character recognition performance in the existing methods. The results confirmed that binary-classification based methods is not appropriate for P300 detection in BCI spellers.},
  archive      = {J_EAAI},
  author       = {Mohammad Norizadeh Cherloo and Amir Mohammad Mijani and Liang Zhan and Mohammad Reza Daliri},
  doi          = {10.1016/j.engappai.2023.106381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multiclass-based framework for p300 detection in BCI matrix speller: Temporal EEG patterns of non-target trials vary based on their position to previous target stimuli},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Numerical simulation of ozonation in hollow-fiber membranes
for wastewater treatment. <em>EAAI</em>, <em>123</em>, 106380. (<a
href="https://doi.org/10.1016/j.engappai.2023.106380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we developed a comprehensive modeling framework for simulation of ozonation process using combination of artificial intelligence and computational fluid dynamics (CFD). The process is carried out in a hollow-fiber membrane contactor in which the concentration data of ozone was obtained by solution of mass transfer equations, and then the results were used for artificial intelligence modeling. We used three different machine learning models to predict concentration of ozone ( C ) in a system based on its coordinates, i.e., r and z . The models were optimized using the Bat Algorithm (BA) and were trained on a dataset consisting of over 10,000 data points. The three models developed were Support Vector Regression (SVR), Decision Tree Regressor, and Orthogonal Matching Pursuit (OMP). These models were evaluated using three common metrics — Mean Squared Error (MSE), R-squared (R 2 ), and Mean Absolute Error (MAE). Our results indicated that the SVR model overperformed the other two models in terms of all evaluation metrics. Specifically, the SVR model achieved an MSE of 0.003, an R 2 of 0.998, and an MAE of 0.046. The Decision Tree Regressor and OMP models achieved less favorable results with MSEs of 0.007 and 0.221, R 2 scores of 0.996 and 0.878, and MAEs of 0.056 and 0.359, respectively.},
  archive      = {J_EAAI},
  author       = {Xiang Wang and Wei Ping and Ahmed Salah Al-Shati},
  doi          = {10.1016/j.engappai.2023.106380},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106380},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Numerical simulation of ozonation in hollow-fiber membranes for wastewater treatment},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable incomplete multi-view clustering via tensor
schatten p-norm and tensorized bipartite graph. <em>EAAI</em>,
<em>123</em>, 106379. (<a
href="https://doi.org/10.1016/j.engappai.2023.106379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based incomplete multi-view clustering (IMVC) methods have drawn considerable attention due to their good performance in exploring the nonlinear structure of data. However, they still have the following shortcomings. First, graph construction and eigen decomposition of the Laplacian matrix included in the IMVC methods generally have high computational complexity. Second, most methods do not consider the impact of missing views and neglect the potential relationships between different views. Third, few algorithms consider both intra-view and inter-view information for clustering. Therefore, we innovatively propose a scalable incomplete multi-view clustering via the tensor Schatten p -norm and tensorized bipartite graph (SIMVC/TSTBG) method, which combines tensorized bipartite graph, graph completion, and tensor low-rank constraint into a joint framework. Concretely, we first construct bipartite graphs based on the selected m anchor points and the n data points, reducing the size of the graph from n × n to n × m ( m &lt;&lt; n ), which considerably reduces the computational complexity. Second, we adaptively complete the missing bipartite graph, which reduces the effect of missing view information on the clustering results. Third, to explore connections between missing views and mine high-order information between views, we splice the bipartite graphs into a tensor and impose a tensor low-rank constraint, i.e., the tensor Schatten p -norm, on it. At the same time, we also design an efficient algorithm to solve SIMVC/TSTBG. To our knowledge, we are the first successful practice to integrate the tensor technique with the scalable IMVC method. Compared with other IMVC methods, the results on seven datasets fully show the high efficiency and effectiveness of SIMVC/TSTBG.},
  archive      = {J_EAAI},
  author       = {Guangyan Ji and Gui-Fu Lu and Bing Cai},
  doi          = {10.1016/j.engappai.2023.106379},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106379},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scalable incomplete multi-view clustering via tensor schatten p-norm and tensorized bipartite graph},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronous spatio-temporal signature verification via
fusion triplet supervised network. <em>EAAI</em>, <em>123</em>, 106378.
(<a href="https://doi.org/10.1016/j.engappai.2023.106378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten signature has been regarded as one of the most accepted and practical means of person verification since ancient times. Unlike existing methods to trace the signer only considering a single spatial or temporal information, in this paper, we propose to combine two forms of signature data (stroke images and sensor signals) to realize person verification using the novel Fusion Triplet Supervised Network (fuseTSN). First, the Electronic Handwritten Signature Acquisition System 1.0 (EHS-AS 1.0) connected to the Wacom tablet is developed to construct a synchronous static–dynamic Chinese signature dataset (SynCS) and to transform existing dynamic signature datasets into static–dynamic datasets. Then, the hybrid feature extractor (ResCNN-BiLSTM with attention) as the backbone is embedded into the fuseTSN model, mapping the images and time-series signal into a common hyperspace. Furthermore, the similarity of the input [Anchor, Positive, Test] is measured to produce the final output. Finally, the proposed fuseTSN is tested on three public datasets and also evaluated on our SynCS dataset comprised of 24000 unique triplet label samples. The results show that the accuracy of the fuseTSN model is at least 5.01% higher than that of a unimodal system with only stroke image or sensor data on the SynCS dataset and outperforms the current state-of-the-art multimodal methods for writer-independence (WI) verification on public datasets. In addition, we present the fuseTSN’s reliable judgment basis for spatial strokes in the heat-map and further find that the combination of time attributes (OA and OE) can significantly improve the model performance.},
  archive      = {J_EAAI},
  author       = {Liyang Xie and Zhongcheng Wu and Xian Zhang and Yong Li},
  doi          = {10.1016/j.engappai.2023.106378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synchronous spatio-temporal signature verification via fusion triplet supervised network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automatic classifier for monitoring applied behaviors of
cage-free laying hens with deep learning. <em>EAAI</em>, <em>123</em>,
106377. (<a
href="https://doi.org/10.1016/j.engappai.2023.106377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Poultry behavior is an important indicator of their welfare, health, and production performance. The welfare of layers and broilers such as walking ability, breast blisters, hock burn, and heart failures are measurable through behavior monitoring. In the previous research, most of laying hen studies focused on basic behaviors such as drinking, feeding, and walking of broilers. However, with the transition to the cage-free houses, more natural behaviors need to be monitored for welfare assessment. In this study, a six-behavioral classifier (i.e., feeding, drinking, walking, perch, dust bathing, and nesting) was developed based on multiple CNN models (e.g., efficientNetV2 and YOLOv5-cls). The classifier is one of the first model included perching, dust bathing, and nesting behaviors, which are special characters that reflect basic welfare of cage-free birds. Furthermore, a cage-free birds’ dataset containing 12,000 pictures was collected and annotated in a lifespan scale (e.g., from 1 week to 50 weeks of old), from which 9,600 images were used as training dataset and the rest were used for validation. The best performance model YOLOv5-cls-m achieved an average accuracy of 95.3%, which is 5.01% higher than that of efficientNetV2-l. Drinking behavior of chicks was monitored with the highest accuracy (97.8%) while nesting behavior had a detection precision of 92.5%. In terms of chickens’ age, the classifier has a better accuracy for smaller chicks (&lt; 10 days) than larger chickens older than 10 days (96.4% vs 94.3%). The results show that the classifier is a useful tool to segregate cage-free bird behaviors in various life periods and environments.},
  archive      = {J_EAAI},
  author       = {Xiao Yang and Ramesh Bist and Sachin Subedi and Zihao Wu and Tianming Liu and Lilong Chai},
  doi          = {10.1016/j.engappai.2023.106377},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106377},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An automatic classifier for monitoring applied behaviors of cage-free laying hens with deep learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-in-the-loop for computer vision assurance: A survey.
<em>EAAI</em>, <em>123</em>, 106376. (<a
href="https://doi.org/10.1016/j.engappai.2023.106376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-in-the-loop (HITL), a key branch of Human–Computer Interaction (HCI), is increasingly proposed in the research literature as a key assurance method for automated analyses and predictive application designs. As the need increases to improve methods in Artificial Intelligence (AI) model training, optimize systems performance, provide AI explainability, and monitor AI system operations, the concept of HITL is gaining traction due to its value in solving these challenges. This survey of existing works on HITL from a computer vision system design perspective focuses on the following AI assurance principles: (1) improved data assurance, such as data preparation or automated data labeling; (2) algorithmic assurance, such as managing uncertainty and AI trustworthiness; and (3) critical limitations and capabilities introduced by HITL into a system’s operational efficiency. We survey prior work within these foci, including technical strengths and weaknesses of novel approaches and ongoing research. This review of the state of the art in HITL computer vision research supports an informed discussion of considerations and future opportunities in this critical space.},
  archive      = {J_EAAI},
  author       = {Matthew Wilchek and Will Hanley and Jude Lim and Kurt Luther and Feras A. Batarseh},
  doi          = {10.1016/j.engappai.2023.106376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human-in-the-loop for computer vision assurance: A survey},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new approach based on hybrid ant colony
optimization-artificial bee colony algorithm for multi-objective
electric vehicle routing problems. <em>EAAI</em>, <em>123</em>, 106375.
(<a href="https://doi.org/10.1016/j.engappai.2023.106375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-life, routing plans try to optimize multiple objectives without relying on just one. So, this paper introduces three multi-objective electric vehicle routing problems (MOEVRP) that consider different charging strategies and electric vehicle (EV) charger types while optimizing five conflicting objectives: a total minimization cost of recharging, the number of vehicles required, a total travel distance, load-dependent energy consumption, and the total number of charging stations required. We develop a new hierarchical approach consisting of two phases: a Hybrid Ant Colony Optimization (HACO) and an Artificial Bee Colony Algorithm (ABCA). In the first phase, an initial solution is obtained using a HACO that integrates local search algorithms and simulated annealing (SA) to reduce the solution time. Then in the second phase, the problem is solved using an ABCA considering the initial solution obtained from the first phase. Using the proposed HACO-ABCA as the search engine, two posteriors’ methods, namely the weighted-sum method (WSM) and the conic method (CM), are applied to scalarize the five objectives. The effectiveness of the proposed hierarchical approach is examined on well-known test-based instances and obtained the best new results in most instances. Additionally, the proposed solution is applied to a real-life case study. The results show that multi-objective traditional methods give more effective results than multi-objective evolutionary algorithms, regardless of the MOEVRP problem type. We can also conclude that the partial recharge and multiple recharge technology options can significantly improve the route decisions of logistic companies.},
  archive      = {J_EAAI},
  author       = {Serap Ercan Comert and Harun Resit Yazgan},
  doi          = {10.1016/j.engappai.2023.106375},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106375},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new approach based on hybrid ant colony optimization-artificial bee colony algorithm for multi-objective electric vehicle routing problems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Abnormal sitting posture recognition based on multi-scale
spatiotemporal features of skeleton graph. <em>EAAI</em>, <em>123</em>,
106374. (<a
href="https://doi.org/10.1016/j.engappai.2023.106374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To fuse the spatial dimension, temporal dimension, and whole-body skeleton features of human abnormal sitting posture to improve the recognition accuracy, we propose an abnormal sitting posture recognition method based on the multi-scale spatiotemporal features of skeleton graph (ASPR) from the perspective of changes of human posture. Firstly, we build a human abnormal sitting posture dataset (HASP) with multidimensional features. Then, based on the structure of high-to-low resolution subnetworks, we use the spatiotemporal graph convolution module as the feature extraction unit A multiple scale spatiotemporal feature extraction model based on graph convolutional network (M2SGCN) is proposed. It is used to capture the spatiotemporal features. Next, a feature extraction model of local skeletal angles based on recurrent neural network is proposed to capture the change rule of skeletal angles of human sitting posture. Finally, we investigate the optimal parameters of ASPR by checking its performance with different human skeleton combination schemes and different features fusion coefficient. Experiment results show that ASPR achieves excellent performance compared with four state-of-the-art models and their combined models. ASPR shows an average recognition accuracy, a recall rate, an F1 score, and average time of 95.24%, 95.61%, 95.14%, and 7.094 ms, respectively.},
  archive      = {J_EAAI},
  author       = {Linhan Li and Guanci Yang and Yang Li and Dongying Zhu and Ling He},
  doi          = {10.1016/j.engappai.2023.106374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Abnormal sitting posture recognition based on multi-scale spatiotemporal features of skeleton graph},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comparative neural networks and neuro-fuzzy based REBA
methodology in ergonomic risk assessment: An application for service
workers. <em>EAAI</em>, <em>123</em>, 106373. (<a
href="https://doi.org/10.1016/j.engappai.2023.106373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-ergonomic working conditions are the leading causes of musculoskeletal disorders that seriously affect human health. REBA is widely used tool due to its convenience and consideration of all body parts. However, it heavily relies on the subjective judgments of the assessor, leading to inconsistencies in results, and lacks sensitivity in detecting small changes in ergonomic risk factors. Therefore, there is a need to improve the REBA method by integrating it with new technologies. While a few studies have proposed integrating ergonomic risk measurement tools with ANNs, there is a research gap in comparing different types of neural networks and membership functions to determine the most effective approach for improving the performance of REBA. Additionally, there is a need to apply these integrations to real-life case studies to demonstrate their effectiveness in practice. This study proposes a comparative neural network and neuro-fuzzy-based REBA method that includes various types of neural networks and membership functions. The proposed method is applied to service employee who have experienced increased workloads due to the Covid-19 pandemic. The results show that the neuro-fuzzy method is more accurate than the REBA and provides greater flexibility in defining which member belongs to which risk level cluster. This study is critical because it addresses research gaps in integrating neural networks and REBA and applies these integrations to a real-life case study. By comparing different types of neural networks and membership functions, the study provides insights into which approaches are most effective for improving the performance of REBA.},
  archive      = {J_EAAI},
  author       = {Bahar Yalcin Kavus and Pelin Gulum Tas and Alev Taskin},
  doi          = {10.1016/j.engappai.2023.106373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comparative neural networks and neuro-fuzzy based REBA methodology in ergonomic risk assessment: An application for service workers},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature optimization method for white feather broiler health
monitoring technology. <em>EAAI</em>, <em>123</em>, 106372. (<a
href="https://doi.org/10.1016/j.engappai.2023.106372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing research on white feather broiler health monitoring technology concentrate on the selection of classification algorithms and optimization of internal parameters, ignoring the white feather broiler sound signal data set (abbr. signal data set) and internal features for training classifiers. In this paper, the authors shifted the research focus to the signal data set, and proposed an applicable feature optimization method in order to improve the practicality and stability of broiler health monitoring technology. First, for outliers in the signal data set, the boxplot was used to detect them, and they were transformed into missing values. For all missing values in the signal data set, six missing value processing methods were used to process them, respectively. The optimal decision tree classifier (abbr. DT classifier) filling was determined. Second, three normalization methods were used to process the signal data set, respectively, and the optimal min–max normalization method was determined. Then, the Pearson correlation coefficient and the p -value were used to perform correlation tests on features and labels in the signal data set, then the linear–nonlinear-fusion-based (abbr. LNLF-based) feature selection method was newly proposed to select those features that have a great influence on the classification effect of the random forest classifier (abbr. RF classifier). Multiple tests had verified its superiority. Finally, ten white feather broiler sound signal validation data sets (abbr. validation data sets) were used to verify the proposed feature optimization method. It shows that the average classification accuracy achieved by the RF classifier on the signal data set before and after feature optimization improved from 72.85% to 85.28%, with an improvement of 12.43%. The average G-mean achieved by the RF classifier improved from 0.828 to 0.939, with an improvement of 0.111. The average classification accuracy and average G-mean achieved by the RF classifier on the validation data set before and after feature optimization improved significantly, with an average improvement of 13.26% and 0.093, respectively. This method improves the reliability of the existing classifiers in another way, which is an important supplement to the feature engineering study, and promotes the research progress of the existing white feather broiler health monitoring technology.},
  archive      = {J_EAAI},
  author       = {Weige Tao and Guotao Wang and Zhigang Sun and Shuyan Xiao and Lingjiao Pan and Quanyu Wu and Min Zhang},
  doi          = {10.1016/j.engappai.2023.106372},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106372},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature optimization method for white feather broiler health monitoring technology},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning approaches for fuzzy cognitive maps to
support clinical decision-making in dengue. <em>EAAI</em>, <em>123</em>,
106371. (<a
href="https://doi.org/10.1016/j.engappai.2023.106371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed machine learning approach developed to guarantee the privacy and security of data stored on local devices. In healthcare, specifically in diseases of public health interest such as dengue, it is necessary to develop strategies that guarantee such data properties. Therefore, the aim of this work was to develop three federated learning approaches for fuzzy cognitive maps for the prediction of mortality and the prescription of treatment of severe dengue. The validation of the approaches was performed on severe dengue datasets from two dengue endemic regions in Colombia. According to the results, the use of federated learning significantly improves the performance of models developed in centralized environments. Additionally, the use of federated learning allows guaranteeing the privacy and security of each client’s data due to the local training of the models. Federated learning is a useful tool in healthcare because it guarantees the privacy and security of patient data. Our results demonstrated the ability of aggregated models to predict mortality and prescribe treatment for severe dengue.},
  archive      = {J_EAAI},
  author       = {William Hoyos and Jose Aguilar and Mauricio Toro},
  doi          = {10.1016/j.engappai.2023.106371},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106371},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated learning approaches for fuzzy cognitive maps to support clinical decision-making in dengue},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks (GNNs) based accelerated numerical
simulation. <em>EAAI</em>, <em>123</em>, 106370. (<a
href="https://doi.org/10.1016/j.engappai.2023.106370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite element method (FEM) based high-fidelity simulation can be computationally demanding and time-consuming as engineering problems become more complicated. It is thus necessary to develop a surrogate model that only requires a small amount of computational time but retains sufficient accuracy. A graph neural network (GNN) based framework is proposed as a general surrogate model for FEM to simulate the Von Mises stress distribution. The mesh body is embedded to a graph and a novel global attribute representation is introduced to capture the geometry and boundary conditions while overcoming the common problem of over smoothing in graph deep learning. The challenge to deal with varying geometry and boundary conditions is overcome by the proposed model and thus it outperforms existing methods such as proper orthogonal decomposition (POD) and greedy algorithm in terms of generalization. Numerical experiments are given to demonstrate the capability of the model developed and the results show that the proposed model not only accurately predicts the stress distribution but also speed-ups hundreds of times faster compared to a FEM-based simulator, enabling real-time structural response analysis for the application of digital twin and structural health monitoring. It is indicated that GNNs can be a powerful tool for resolving complex physical problems, thereby assisting in advancing science and enhancing engineering productivity.},
  archive      = {J_EAAI},
  author       = {Chunhao Jiang and Nian-Zhong Chen},
  doi          = {10.1016/j.engappai.2023.106370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural networks (GNNs) based accelerated numerical simulation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enriched multi-scale cascade pyramid features and guided
context attention network for industrial surface defect detection.
<em>EAAI</em>, <em>123</em>, 106369. (<a
href="https://doi.org/10.1016/j.engappai.2023.106369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection is a very important technique to guarantee product quality in industrial fields. However, the detection of multi-scale defects and defects with poor visibility is still a challenging problem. To address this issue, we propose a novel network by collaborating multi-scale cascade pyramid features and a guided context attention mechanism for the pixel-wise defection of surface defects, called MPA-Net. The MPA-Net is a full y-convolutional network (FCN) with an encoder–decoder architecture, which can integrate multi-scale features and merge them into the different stages of the decoder for generating the defect segmentation map. Specifically, the proposed guided context attention module (GCA) is used to transmit the global context information from the large scale to the small scale, which can promote the initial recovery capability of the decoder, and thus help to locate defects with different sizes and defects with poor visibility. Moreover, the proposed pyramid feature fusion and enrichment module (FFEM) is employed to aggregate low-level coarse features and high-level semantic features in each scale, so as to increase the ability of defect feature representation. The aggregation features at different scales are then fused to the different layers of the decoder, which is beneficial to recover the details of defects gradually. The evaluation results on four public datasets demonstrate that the proposed method has excellent performances on mean intersection of union (DAGM2007: 64.94%, KolektorSSD: 77.90%, RSDDs-I: 86.63%, RSDDs-II: 80.62%, FID: 96.98%) and mean pixel accuracy (DAGM2007: 67.97%, KolektorSSD: 85.01%, RSDDs-I: 94.13%, RSDDs-II: 88.53%, FID: 98.71%).},
  archive      = {J_EAAI},
  author       = {Linhao Shao and Erhu Zhang and Jinghong Duan and Qiurui Ma},
  doi          = {10.1016/j.engappai.2023.106369},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106369},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enriched multi-scale cascade pyramid features and guided context attention network for industrial surface defect detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine coordinate attention for surface defect detection.
<em>EAAI</em>, <em>123</em>, 106368. (<a
href="https://doi.org/10.1016/j.engappai.2023.106368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection remains a challenging task due to issues such as inconspicuous targets, significant variations among identical defects, and minimal differences between distinct defects. To address these challenges, a Fine Coordinate Attention (FCA) block is proposed in this paper, which encodes both average and salient information in two coordinate directions, so that the spatial dependence can be captured and the long-range interaction can be achieved. And such localization-friendly information is crucial for industrial surface defect images with subtle targets. Specifically, the FCA block can recalibrate feature maps of a surface defect image through three steps: coordinate information aggregation, cross-dimension interaction, and attention generation. It can be embedded into any convolutional neural network (CNN) structure to improve performance. Additionally, two resistance spot welding (RSW) surface defect datasets are published in this paper: an image classification dataset RSW-C and an object detection dataset RSW-D. Experimental results for image classification and object detection demonstrate that the FCA block outperforms existing attention mechanisms. The code is available at , while the two RSW datasets can be found at www.kaggle.com/datasets/alfredzimmer/rswdatasets .},
  archive      = {J_EAAI},
  author       = {Meng Xiao and Bo Yang and Shilong Wang and Zhengping Zhang and Yan He},
  doi          = {10.1016/j.engappai.2023.106368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fine coordinate attention for surface defect detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing an evolutionary deep learning framework with
random forest feature selection and improved flow direction algorithm
for NOx concentration prediction. <em>EAAI</em>, <em>123</em>, 106367.
(<a href="https://doi.org/10.1016/j.engappai.2023.106367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous change of load makes it difficult for the power plant to control the emission of pollutants. A reliable NOx concentration prediction model is important to energy conservation and emission reduction. In this study, an evolutionary deep learning framework is proposed to predict the NOx emission of coal fired boiler. In the process of NOx emission, several variables will affect the emission concentration. Therefore, firstly, the variables with high importance to NOx emission are selected through random forest (RF), and the initial input data is filtered to obtain a new input data. Secondly, the convolutional neural network (CNN) is used to further extract the deep characteristics of the new data set. Thirdly, Using Chaos strategy and iterative local search (ILS) method to improve flow direction algorithm (FDA) and enhance the optimization ability of the algorithm. Finally, the improved FDA (IFDA) is used to optimize the hyperparameters of Bi-directional gated recurrent unit (BiGRU), and the optimized BiGRU model is used to forecast the NOx emission concentration. Three different data sets from coal-fired power plants were obtained to verify the proposed hybrid RF-CNN-FDA-BiGRU model. Experimental results show that the proposed model can accurately predict NOx concentration and has better prediction performance.},
  archive      = {J_EAAI},
  author       = {Huixin Ma and Tian Peng and Chu Zhang and Chunlei Ji and Yiman Li and Muhammad Shahzad Nazir},
  doi          = {10.1016/j.engappai.2023.106367},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106367},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Developing an evolutionary deep learning framework with random forest feature selection and improved flow direction algorithm for NOx concentration prediction},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning framework-based 3D shape reconstruction of
tanks from a single RGB image. <em>EAAI</em>, <em>123</em>, 106366. (<a
href="https://doi.org/10.1016/j.engappai.2023.106366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, complicated three-dimensional shape reconstruction from a single RGB image has become a crucial technology in many industries such as Automotive, Healthcare, and Military. It is particularly challenging to reconstruct the complex shape of a military tank. Former methods infer 3D information from 2D images via shape deformation from ellipsoids, which has the problems of local adhesion, uneven surfaces, and distortion of the structure. This study introduces a new single-view 3D shape reconstruction (SVSR) framework with multi-scale feature extraction that splits shape reconstruction into three tasks—camera parameter prediction, initial shape construction, and deformation prediction. The shape-initialization module provides a variable initial shape by predicting the stretch and displacement parameters of each geometric component based on their topological relationships. The shape-deformation module predicts the directional deformation of each vertex. These two modules are dedicated separately to avoid shape adhesion and improve the local detail performance. Silhouette images of the tank’s overall shape and local geometric components are employed to eliminate the impact of component shielding and avoid structural distortion via both pixel loss and perceptual loss. Experiments on the main battle tank dataset demonstrate that our method can predict complicated 3D shapes with a low Chamfer distance value (0.0017). Our approach outperforms the other state-of-the-art methods in terms of Chamfer distance and F-score with at least a 10% improvement, with more realistic overall contours and part details. It has huge application prospects in dealing with other complex shape predictions by modifying the shape-initialization module.},
  archive      = {J_EAAI},
  author       = {Jincheng Chen and Feiding Zhu and Yuge Han and Dengfeng Ren},
  doi          = {10.1016/j.engappai.2023.106366},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106366},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning framework-based 3D shape reconstruction of tanks from a single RGB image},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective flood prediction model based on twitter text and
image analysis using BMLP and SDAE-HHNN. <em>EAAI</em>, <em>123</em>,
106365. (<a
href="https://doi.org/10.1016/j.engappai.2023.106365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, social media platforms such as Twitter have garnered a lot of interest as a new source of text data for quick flood awareness and effective prediction. Hence various types of research were made on flood prediction using Twitter data but it only focuses on classifying the text data as relevant or irrelevant, thereby loss of semantic information from longer phrases while extracting important information from Twitter text data and resulting in low accuracy of text classification. Hence, a novel BMLP and SDAE-HHNN has been proposed. This approach comprises BMLP and SDAE-HHNN techniques has been developed for effective flood prediction based on Twitter text data and image analysis. To classify the text data into two/six different classes, BERT is used to preprocess the text data from Twitter. To achieve high levels of precision, the Rule-Based Matching technique extracts specific place entities from the Named Entity Recognition. To predict the high probability location affected by flood from the place entity, bi-directional MLP (BMLP) is used which is made up of a finite number of sequential layers in its most basic form. Then images are extracted from this particular location and these images are processed to predict flood level but existing techniques cannot provide sufficient information to map the flood area and object detection due to real field data collection. Hence, a novel SDAE with HHNN has been developed in which SDAE removes noise from the specified extracted location and HHNN is used to classify the image into flood or non-flood. Then plot this sufficient predicted information related to flood level in the google map. The proposed model is implemented in the Python platform and the result obtained shows that the proposed has a maximum recall of 96%, maximum precision of 95%, accuracy of 97%, and an F1 score of 96%.},
  archive      = {J_EAAI},
  author       = {Supriya Kamoji and Mukesh Kalla},
  doi          = {10.1016/j.engappai.2023.106365},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106365},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Effective flood prediction model based on twitter text and image analysis using BMLP and SDAE-HHNN},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-domain adaptation for cross-domain semantic slot
filling. <em>EAAI</em>, <em>123</em>, 106364. (<a
href="https://doi.org/10.1016/j.engappai.2023.106364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slot filling is a crucial sub-task in the field of Spoken Language Understanding and aims to match the corresponding semantic slot for each word in the sequence. Slot prediction in an unknown domain requires a large amount of data in the domain for training, but in reality, there is often a lack of trainable samples in the unknown domain, which makes it difficult for the model to predict new domains. This is the biggest challenge of the cross-domain slot filling task. In recent years, the idea of transfer learning has been applied to cross-domain slot filling tasks. The current training method directly mixes the source domain data samples without considering the differences between the various domains in the source domain, which ignores the domain-invariant features contained in the source domain. In this paper, we proposed a cross-domain slot filling model based on multi-domain adaptation. First, we used the domain-adaptive domain projection layer to let the feature learner classify the domain-invariant information and domain-exclusive information into the specified dimension part of the vector, so as to realize the extraction of domain-invariant feature information, and then used the trainable linear transformation matrix to relieve the generalization burden of the feature learner. Experimental results show that our proposed models significantly outperform other methods on average F1-score.},
  archive      = {J_EAAI},
  author       = {Yuhui Zhang and Li Chen and Shenggen Ju and Gaoshuo Liu},
  doi          = {10.1016/j.engappai.2023.106364},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106364},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-domain adaptation for cross-domain semantic slot filling},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning under concept drift and non-stationary noise:
Introduction of the concept of persistence. <em>EAAI</em>, <em>123</em>,
106363. (<a
href="https://doi.org/10.1016/j.engappai.2023.106363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from noisy data is a challenging task especially when the system under consideration has a non-stationary nature. The source of the noise is often assumed to be stationary, however the severity or characteristics of noise may also be time-varying, which causes multiple sources of drift in the collected data. This study introduces a novel adaptive learning rate approach to improve learning when the observations from a non-stationary system is altered by an also non-stationary source of noise. As an example to this approach, we propose Persistence Aware Robust Learner (PeARL), an online learning method that utilizes a novel concept called persistence , which is a local noisiness estimation metric to measure the correspondence of a signal to discrete white noise. Making use of this metric, PeARL is able to adaptively adjust the learning rate for each observation during learning to reduce the effect of noise. With this level of control on the learning rate, noisy instances have less disruptive effect on the maintained estimate. We experimentally evaluate PeARL on (a) systematically generated synthetic data and (b) real-world data, including accelerometer readings collected from people ( HASC2010corpus ) and current measurements from electric motors collected within the scope of EU-funded research project iRel40. The experiments reveal a favorable region of noise rate, in which the proposed method achieves up to 40% reduction in mean absolute error (MAE).},
  archive      = {J_EAAI},
  author       = {Kutalmış Coşkun and Borahan Tümer},
  doi          = {10.1016/j.engappai.2023.106363},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106363},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning under concept drift and non-stationary noise: Introduction of the concept of persistence},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-driven lossy image compression: A comprehensive
survey. <em>EAAI</em>, <em>123</em>, 106361. (<a
href="https://doi.org/10.1016/j.engappai.2023.106361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of image processing and computer vision (CV), machine learning (ML) architectures are widely used. Image compression problems can be solved using convolutional neural networks (CNNs). As a result of bandwidth and memory constraints, compression of images is a necessity. There are three types of information found in images: useful, redundant, and irrelevant. In this survey, we will discuss how ML is used to compress lossy images. Firstly, we describe the background of lossy image compression. Next, we classify ML-based image compression frameworks into subgroups based on their architectures. Auto-encoders (AEs), variational auto-encoders (VAEs), CNNs, recurrent neural networks (RNNs), long short-term memories (LSTMs), gated recurrent units (GRUs), generative adversarial networks (GANs), transformers, principal component analysis (PCA) and fuzzy means clustering are among these subgroups. By analyzing learning-driven image compression frameworks, we present pros and cons of each subgroup. Lastly, we outline several research gaps and future research directions in the field of ML-based image compression.},
  archive      = {J_EAAI},
  author       = {Sonain Jamil and Md. Jalil Piran and MuhibUr Rahman and Oh-Jin Kwon},
  doi          = {10.1016/j.engappai.2023.106361},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106361},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning-driven lossy image compression: A comprehensive survey},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient thermal infrared tracking with cross-modal
compress distillation. <em>EAAI</em>, <em>123</em>, 106360. (<a
href="https://doi.org/10.1016/j.engappai.2023.106360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key issue of thermal infrared tracking is to use neural networks to represent the target effectively and efficiently in the thermal infrared domain. The lack of thermal infrared trainable datasets makes it difficult to train a robust infrared object tracker from scratch, and the time-consuming convolution operations also make the tracking slow. To address the above problems, we proposed cross-modal compression distillation to represent thermal infrared objects for tracking, by leveraging an off-the-shelf RGB model with knowledge distillation. Specifically, cross-modal distillation is performed to effectively transfer knowledge from RGB modality to thermal infrared modality by inputting paired RGB and thermal infrared images into two branches of a Siamese network. Additionally, based on the teacher–student model architecture, the feature extractor is compressed into a lightweight model by model pruning and multi-level deep feature matching. Experimental results on LSOTB-TIR and PTB-TIR datasets show that the thermal infrared object tracking models distilled by our proposed method achieved faster tracking speed with better performance than the baseline RGB tracker by gaining an improvement of 1.5% Success Rate, 2.2% Precision, and 1.9% Normalized Precision, 58 frames per second (FPS) on LSOTB-TIR dataset, respectively.},
  archive      = {J_EAAI},
  author       = {Hangfei Li and Yufei Zha and Huanyu Li and Peng Zhang and Wei Huang},
  doi          = {10.1016/j.engappai.2023.106360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient thermal infrared tracking with cross-modal compress distillation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PCB defects target detection combining multi-scale and
attention mechanism. <em>EAAI</em>, <em>123</em>, 106359. (<a
href="https://doi.org/10.1016/j.engappai.2023.106359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of PCB defect quality plays an important role in PCB fabrication. However, the size of the PCB defects is too small to identify. In order to improve the detection efficiency of existing algorithms, a joint multiscale PCB defect target detection and attention mechanism, which named RAR-SSD, was proposed. By using lightweight receptive field block module (RFB-s) with an attention mechanism module, we built a wider range of effective focused features, which exploited the importance of different features in different channels without increasing the computing power of the network. In addition, we built a feature fusion module to efficiently fuse low-level feature information with high-level feature information to produce a more complete feature map and improve the accuracy of fault recognition. The proposed network improved the fault recognition accuracy of PCBs by 2.23% over the original SSD algorithm, with a recall rate of 6.51% and an F1 value of 4.85%, the model has greatly improved in terms of detection performance. The optimized algorithm has significant speed and accuracy advantages over the algorithms YOLOv3 and YOLOv5. Experimental results show that the proposed RAR-SSD model has good performance in detecting small and medium size targets for defects in the PCB manufacturing process and is of some guidance for the subsequent detection of PCB defects.},
  archive      = {J_EAAI},
  author       = {Wujin Jiang and Taifu Li and Shaolin Zhang and Wenbin Chen and Jie Yang},
  doi          = {10.1016/j.engappai.2023.106359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PCB defects target detection combining multi-scale and attention mechanism},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Short-range air combat maneuver decision of UAV swarm based
on multi-agent transformer introducing virtual objects. <em>EAAI</em>,
<em>123</em>, 106358. (<a
href="https://doi.org/10.1016/j.engappai.2023.106358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Unmanned Aerial Vehicle (UAV) swarm technology, there has been a growing interest in using Artificial Intelligence (AI) to drive UAV swarms for short-range air combat. However, due to the complexity of situation information in UAV swarm air combat, making accurate air combat decisions based on air combat situation information has become a challenge. In this paper, we propose the multi-agent Transformer introducing virtual objects (MTVO) to address this issue. First, the proposed approach designs a multi-agent Transformer network structure by exploiting the homogeneity feature of the UAV state information in the swarm. This structure enables the structured processing of complex situation information. Specifically, the local situation information of each UAV is calculated by self-attention, which reduces the size of the swarm situation information while retaining the information of key UAVs. This approach reduces the difficulty of processing UAV swarm situation information. Moreover, we add a virtual object to the UAV swarm information to assist in calculating the weight distribution of the local situation. The weighted fusion of local situations allows us to obtain a more effective representation of the global situation, which serves as the basis for more accurate air combat maneuver decisions. We demonstrate the performance of the proposed method through air combat simulation results using Reinforcement Learning (RL) methods, and validate the applicability and effectiveness of the MTVO network for the short-range air combat problem of UAV swarms.},
  archive      = {J_EAAI},
  author       = {Feilong Jiang and Minqiang Xu and Yuqing Li and Hutao Cui and Rixin Wang},
  doi          = {10.1016/j.engappai.2023.106358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Short-range air combat maneuver decision of UAV swarm based on multi-agent transformer introducing virtual objects},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memristive hyperchaotic system-based complex-valued
artificial neural synchronization for secured communication in
industrial internet of things. <em>EAAI</em>, <em>123</em>, 106357. (<a
href="https://doi.org/10.1016/j.engappai.2023.106357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a memristive hyperchaotic system-based complex-valued Artificial Neural Network (ANN) synchronization for secured communication between Industrial Internet of Things (IIoT) nodes is proposed. The IIoT, an extension of the Internet of Things (IoT), has significant promise for resource use in the industrial sector and intelligent transformation. Security and privacy issues exist when industrial data is sent over an open network via sensor devices. For this, a secure key exchange protocol is necessary. Synchronized key exchange using an ANN is one of the solutions. Additionally, there is a dearth of research on the reciprocating training of ANNs and the use of a robust Pseudo-Random Number Generator (PRNG) to generate a shared input. This study explains how to use a hyperchaotic environment to swiftly assess how well ANNs finalize their coordination and synchronize for session key switch over. Reciprocating learning is used to synchronize two neural networks and transfer the ANN’s output across a public channel. When the ANNs have produced the same outputs in previous iterations, coordination is tested using that function. The proposed technique has lot of benefits, like: (1) using a hyperchaotic-guided PRNG to produce the ANN input sequences; (2) generating the session key via the public network using a reciprocal neuronal alignment of complex ANNs; and (3) allowing two communicating partners to identify complete synchronization more quickly when compared to earlier methodologies. The tested proposed technique outperforms comparable strategies in the literature, according to the results.},
  archive      = {J_EAAI},
  author       = {Mohammad Zubair Khan and Arindam Sarkar and Abdulfattah Noorwali},
  doi          = {10.1016/j.engappai.2023.106357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Memristive hyperchaotic system-based complex-valued artificial neural synchronization for secured communication in industrial internet of things},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive reinforcement learning interval type II fuzzy
fractional nonlinear observer and controller for a fuzzy model of a wind
turbine. <em>EAAI</em>, <em>123</em>, 106356. (<a
href="https://doi.org/10.1016/j.engappai.2023.106356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an innovative control technique for doubly fed induction generator (DFIG) based wind turbine. A DFIG equation is initially presented using fractional order Takagi and Sugeno interval type II fuzzy modeling. Moreover, fault and disturbance are considered in the DFIG model. Then, to design an observer that estimates both fault and disturbance, the fuzzy model of DFIG is decoupled into three subsystems using a different linear coordinate transformation: the state subsystem without disturbance and fault, the subsystem of fault without disturbance, and the subsystem of disturbance without fault. In the following, using the state subsystem, an adaptive reinforcement learning TS interval type II fuzzy fractional sliding mode observer is introduced. The observer gains are adjusted by applying proximal policy optimization, which is a new application of reinforcement learning. Robustness against uncertainties, fast convergence speed of estimation, high degree of freedom and precise estimation are among features of the suggested observer. In addition, only by utilizing the estimated state subsystem and obtained mathematical relationships, the actuator faults and disturbance are estimated. A fractional order sliding mode controller is proposed for the DFIG speed controller. Low chattering characteristics and accurate response are achieved owing to the fractional speed controller. Also, to compensate the influence of disturbances and faults, an adaptive interval type II fuzzy fractional sliding mode controller is used for rotor current regulations, which employs the estimated fault and disturbance. High robustness, fast response time, low tracking error and chattering are some of the advantages of the proposed fault tolerant controller (FTC). The closed-loop stability of controllers is proved by using the Lyapunov theorem. Simulations is accomplished to evaluate the effectiveness of the proposed method. The proposed controller is compared with other controllers. Robustness against parameter uncertainty is also investigated.},
  archive      = {J_EAAI},
  author       = {Hadi Delavari and Ali Sharifi},
  doi          = {10.1016/j.engappai.2023.106356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive reinforcement learning interval type II fuzzy fractional nonlinear observer and controller for a fuzzy model of a wind turbine},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized morse wavelets parameter selection and transfer
learning for pavement transverse cracking detection. <em>EAAI</em>,
<em>123</em>, 106355. (<a
href="https://doi.org/10.1016/j.engappai.2023.106355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring road surface anomalies is crucial to avoid potential harm to pedestrians, vehicles, and vehicle users. These factors have motivated the development of systems that employ signal processing and machine learning algorithms to detect these irregularities automatically by sensing the vehicle’s vibration. The wavelet transform (WT) has been frequently used for signal representation and feature extraction to solve signal classification problems. However, selecting a mother wavelet to perform the WT is challenging due to the need for methods that help to validate the time–frequency representation. Furthermore, machine learning algorithms require a sizeable sample size to train them, and setting their parameters is considered a time-consuming task. This paper proposes to compute the Continuous Wavelet Transform (CWT) through Generalized Morse Wavelets (GMWs) on vehicle’s vertical acceleration data for pavement transverse cracking detection. The parameters gamma and beta of the GMWs and the CWT’s voices per octave (VPO) were selected based on two metrics, the Heisenberg area and the Average Reconstruction Mean Squared Error. The scalogram generated through the CWT and GMWs was used to fine-tune pre-trained convolutional neural networks (CNNs) through transfer learning, such as GoogLeNet, SqueezeNet, and ResNet18. The proposed methodology set 1 VPO for the CWT, while the parameters gamma and beta of GMWs were set as 3 and 1.3333, respectively. The 5-fold cross-validation results of fine-tuning the CNNs showed that SqueezeNet provided a higher average validation sensitivity (84.3290 ± 5.5704) than GoogLeNet and ResNet18; however, the average validation specificity of SqueezeNet (92.7061 ± 7.2403) was lower.},
  archive      = {J_EAAI},
  author       = {Erick Axel Martinez-Ríos and Rogelio Bustamante-Bello and Sergio A. Navarro-Tuch},
  doi          = {10.1016/j.engappai.2023.106355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generalized morse wavelets parameter selection and transfer learning for pavement transverse cracking detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-fidelity surrogate modeling for temperature field
prediction using deep convolution neural network. <em>EAAI</em>,
<em>123</em>, 106354. (<a
href="https://doi.org/10.1016/j.engappai.2023.106354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature field prediction is of great importance in the thermal design of systems engineering, and building a surrogate model is an effective method for the task. Ensuring a high prediction performance for the surrogate models, especially deep learning models with high representational power and numerous parameters, typically requires a significant amount of labeled data. However, obtaining labeled data, particularly high-fidelity data can be prohibitively expensive. To solve this problem, this paper proposes a novel deep multi-fidelity modeling method for temperature field prediction, which takes advantage of low-fidelity data to boost performance with less high-fidelity data. First, a pithy pre-train and fine-tune paradigm is proposed for constructing the deep multi-fidelity model, which is straightforward and efficient, allowing for the effective utilization of information from various fidelity levels. Then, a physics-driven self-supervised learning method is proposed to learn the deep multi-fidelity model, which fully utilizes the physics characteristics of the heat transfer system and further reduces the dependence on large amounts of labeled low-fidelity data in the training process. Two diverse temperature field prediction problems are presented to validate the effectiveness of the proposed method. The results show that our approach can significantly improve the model’s accuracy, reducing the required high-fidelity data for model construction.},
  archive      = {J_EAAI},
  author       = {Yunyang Zhang and Zhiqiang Gong and Weien Zhou and Xiaoyu Zhao and Xiaohu Zheng and Wen Yao},
  doi          = {10.1016/j.engappai.2023.106354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-fidelity surrogate modeling for temperature field prediction using deep convolution neural network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A control system of rail-guided vehicle assisted by
transdifferentiation strategy of lower organisms. <em>EAAI</em>,
<em>123</em>, 106353. (<a
href="https://doi.org/10.1016/j.engappai.2023.106353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail-guided vehicle is a logistics management device widely used to perform various material handling operations instead of manual labor. In processing scenarios, the dimensions of the material transfer path of a rail-guided vehicle are typically very large, which makes the optimization of the material transfer path very difficult. The transdifferentiation behavior of lower organisms was introduced into the evolutionary algorithm, and a large-scale differential evolution algorithm based on the transdifferentiation strategy was proposed, for achieving high-efficiency processing. This strategy makes it possible for some individuals with poor fitness to reach maturity again and be selected for the next iteration after losing some information and returning to their juvenile stage, which helps maintain the diversity of the population. Simulation results show that the proposed algorithm not only achieves an average 25.68% higher output rate than the comparison algorithms on the test cases but also has an excellent and stable effect distribution level on the extended problem space, which shows that the superiority of the proposed algorithm is not affected by the processing parameters. This research is expected to provide technical guidance for the processing of key components in the ship and aviation manufacturing industries. The code with a 31-page manual is available on our project homepage https://github.com/MLNST-JUST/DE-TS .},
  archive      = {J_EAAI},
  author       = {Yuan-Hao Jiang and Shang Gao and Yu-Hang Yin and Zi-Fan Xu and Shao-Yong Wang},
  doi          = {10.1016/j.engappai.2023.106353},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106353},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A control system of rail-guided vehicle assisted by transdifferentiation strategy of lower organisms},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning and ensemble deep learning for circRNA-RBP
interaction prediction in the last decade: A review. <em>EAAI</em>,
<em>123</em>, 106352. (<a
href="https://doi.org/10.1016/j.engappai.2023.106352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular ribonucleic acids (circRNAs) are widely expressed in cells and tissues and play vital roles in cellular physiological processes. Their expressions are associated with clinicopathological features in cancer patients. Thus, they act as molecular biomarkers for tumor diagnosis, non-invasive monitoring, prognosis, and therapeutic intervention. Recent research has shown that circRNAs can interact with RNA-binding proteins (RBPs), which is a critical aspect for understanding circRNA functions. In this paper, we review the state-of-the-art deep learning and ensemble deep learning methods highlighting their strengths and weaknesses in circRNA-RBP interaction prediction. We further discuss new strategies for improving the existing methods. The existing circRNA-RBP interaction prediction methods are further classified as deep learning or ensemble deep learning. Moreover, we elaborate on the critical factors for cicRNA-RBP interactions, which can help the development of prediction models by providing necessary clarifications. This review further presents the benefits of using ensemble deep learning methods over single deep learning methods. Prediction performance improvements of ensemble deep learning methods over single deep learning methods are observed and the reasons for those improvements are discussed. Furthermore, this review discusses open problems of this research field and provides recommendations on future research directions.},
  archive      = {J_EAAI},
  author       = {Dilan Lasantha and Sugandima Vidanagamachchi and Sam Nallaperuma},
  doi          = {10.1016/j.engappai.2023.106352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning and ensemble deep learning for circRNA-RBP interaction prediction in the last decade: A review},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-vehicle clustered traveling purchaser problem using a
variable-length genetic algorithm. <em>EAAI</em>, <em>123</em>, 106351.
(<a href="https://doi.org/10.1016/j.engappai.2023.106351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multi-vehicle clustered traveling purchaser problem (MVCluTPP). Here, two types of procurement planning are proposed. In the first setup, the purchaser visits the markets clusterwise and, after satisfying the demand, returns to the depot with the purchased products, which are carried on the same path using a different vehicle. The other set up, in which products are purchased clusterwise and transported directly from the center of the cluster to the depot, but with the mandate that the purchaser visits the markets clusterwise. One of the multi-pronged aims of the model is to select the clusters and identify which markets to visit, determine the amount of procurement available in each market in a cluster, and develop an optimal routing plan in such a way that the overall system cost is minimized. The clusters are generated using k-means algorithm, and a variable-length chromosome genetic algorithm (VLC-GA) is proposed to optimize the cluster paths and to use a local heuristic to link the clusters to minimize the system cost. Furthermore, the superiority of the VLC-GA has been established through standard TPP and TSP instances, compared with exact methods, and some statistical tests are presented.},
  archive      = {J_EAAI},
  author       = {Arindam Roy and Samir Maity and Ilkyeong Moon},
  doi          = {10.1016/j.engappai.2023.106351},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106351},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-vehicle clustered traveling purchaser problem using a variable-length genetic algorithm},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty management in electricity demand forecasting
with machine learning and ensemble learning: Case studies of COVID-19 in
the US metropolitans. <em>EAAI</em>, <em>123</em>, 106350. (<a
href="https://doi.org/10.1016/j.engappai.2023.106350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving load forecasting is becoming increasingly crucial for power system management and operational research. Disruptive influences can seriously impact both the supply and demand sides of power. This work examines the impact of the coronavirus on power usage in two US states from January 2020 to December 2020. A wide range of machine learning (ML) algorithms and ensemble learning are employed to conduct the analysis. The findings showed a surprising increase in monthly power use changes in Florida and Texas during the COVID-19 pandemic, in contrast to New York, where usage decreased over the same period. In Texas, the quantity of power usage rises from 2% to 6% practically every month, except for September, when it decreased by around 1%. For Florida, except for May, which showed a fall of roughly 2.5%, the growth varied from 2.5% to 7.5%. This indicates the need for more extensive research into such systems and the applicability of adopting groups of algorithms in learning the trends of electric power demand during uncertain events. Such learning will be helpful in forecasting future power demand changes due to especially public health-related scenarios.},
  archive      = {J_EAAI},
  author       = {Mohammed Rashad Baker and Kamal H. Jihad and Hussein Al-Bayaty and Ahmed Ghareeb and Hessein Ali and Jun-Ki Choi and Qiancheng Sun},
  doi          = {10.1016/j.engappai.2023.106350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty management in electricity demand forecasting with machine learning and ensemble learning: Case studies of COVID-19 in the US metropolitans},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on uncertain multiple attribute decision making
based on improved possibility degree relation model and its application.
<em>EAAI</em>, <em>123</em>, 106349. (<a
href="https://doi.org/10.1016/j.engappai.2023.106349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we mainly focus on the triangular fuzzy number-based uncertain multiple attribute decision making problem, which not only attribute weights are unknown but also preference for decision-making objects do not exist, and give a new decision-making approach and consistency test method based on the improved possibility relation model. This method fully considers the influence of the comparison possibility degree measurement information between the measured values of the indicator attribute itself in the course of processing uncertain reasoning such as fuzziness and randomness, reconstructs a new and more optimized triangular fuzzy number-based decision making object improved possibility degree relation model (TFN-DMOIPDRM) to determine the attribute weight vector, and creatively designs a general formula to test the consistency of the improved possibility degree relation matrix. Next the criterion of consistency test is given to solve the remaining problem of the lack of consistency test in the construction of fuzzy number possibility degree relation model and fuzzy complementary judgment matrix. Moreover, another major contribution of this paper is to present the improved possibility degree relation theory of triangular fuzzy numbers on the basis of defining the comparative possibility degree of triangular fuzzy numbers, and fully study a series of its relevant properties and conclusions, as well as its application in constructing model to determine the attribute weight. By aggregating the improved possibility degree information measured by pairwise comparing decision objects, the overall improved possibility degree value of each decision object is obtained, and a new algorithm of the improved possibility relation model for triangular fuzzy number multi-attribute decision object is given, which improves and expands the application of fuzzy number possibility theory in the field of fuzzy uncertainty reasoning and intelligent computing of artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Zhili Huang and Hongge Yue and Qiang He},
  doi          = {10.1016/j.engappai.2023.106349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on uncertain multiple attribute decision making based on improved possibility degree relation model and its application},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information complementary attention-based multidimension
feature learning for person re-identification. <em>EAAI</em>,
<em>123</em>, 106348. (<a
href="https://doi.org/10.1016/j.engappai.2023.106348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the need for criminal investigation technology and the development of deep learning, the task of person re-identification has gradually become a research hotspot. Recently, various neural network-based person re-identification technologies designed by researchers have shown excellent results. However, most of the frameworks focus on complex structural design or redundant networks to guide model construction, which hugely increases the cost of train and application cost. In addition, the correlation between the channel information and spatial information on the pedestrian feature map is also relatively lacking. Therefore, we design a lightweight attention module to address the lack of correlation question response. The proposed module sequentially extracts person images’ channel and spatial features and effectively associates the two kinds of information through sequential connections. The proposed attention module has a simple structure, and the parameter increase in the backbone network is tiny. We place the fuse module in each feature extraction layer to focus on the pedestrian information extracted by each layer. To solve the problem of complex model structure, we choose the residual network as the backbone network and the attention mechanism to extract person features without using pose point estimation or additional network assistance to reduce model complexity. We adjust the drop rate of the person classification layer to improve the model’s generalization ability. We estimate the performance of our method on three public datasets: Market-1501, DukeMTMC-reID, and CUHK03 (both detected and labeled) demonstrate the proposed method’s effectiveness and obtain highly competitive performance on the three datasets.},
  archive      = {J_EAAI},
  author       = {Mingyang Wang and Hui Ma and Yiwei Huang},
  doi          = {10.1016/j.engappai.2023.106348},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106348},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Information complementary attention-based multidimension feature learning for person re-identification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective fruit fly optimization algorithm for the
distributed permutation flowshop scheduling problem with total flowtime.
<em>EAAI</em>, <em>123</em>, 106347. (<a
href="https://doi.org/10.1016/j.engappai.2023.106347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed permutation flowshop scheduling problem (DPFSP) has always been a hot issue. The optimization goal of minimizing the total flowtime is of great significance to the environment of multi-factory. In this paper, a discrete fruit fly optimization algorithm (DFFO) is proposed to solve the DPFSP with the total flowtime criterion. In the proposed DFFO, an initialization method considering the population quality and diversity is adopted. In the smell-based search stage, three perturbation operators, the Shift-based operator, the Exchange-based operator and the Hybrid operator are designed respectively, and each fruit fly improves its state through a specific neighborhood strategy. In addition, we propose an improved reference local search (MRLS) method to enhance the exploitation ability of fruit flies. In the vision-based search stage, fruit flies use a well-designed combination update mechanism to lead fruit flies to more potential areas. In order to enhance the exploration ability, we use random reinforcement method for the population. The parameters are evaluated using an orthogonal experimental design to determine the appropriate values of the key parameters. In addition, we test the DFFO and the state-of-art algorithms from the literature on 720 large-scale instances. The experimental results show that DFFO is a very effective metaheuristic.},
  archive      = {J_EAAI},
  author       = {Heng-Wei Guo and Hong-Yan Sang and Xu-Jin Zhang and Peng Duan and Jun-Qing Li and Yu-Yan Han},
  doi          = {10.1016/j.engappai.2023.106347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective fruit fly optimization algorithm for the distributed permutation flowshop scheduling problem with total flowtime},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilization of adaptive swarm intelligent metaheuristic in
designing an efficient photovoltaic interfaced static synchronous series
compensator. <em>EAAI</em>, <em>123</em>, 106346. (<a
href="https://doi.org/10.1016/j.engappai.2023.106346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To cope with the growing load demand of power system due to world’s rapid socio-economic growth, the system compels to run with increased load. Hence, the system must sustain at maximum loading level, termed as the Maximum Loadability Limit (MLL) of the system, without violating its security limits. To increase the system-MLL further the Static Synchronous Series Compensator (SSSC) among existing Flexible AC Transmission Systems (FACTS) devices has been preferred here for its capability of compensating the real and reactive power losses simultaneously. Initially, the SSSC parameters are optimized which are further validated through the dynamic model of the Photovoltaic (PV) interfaced SSSC (PV-SSSC) in MATLAB/SIMULINK. To make the PV-SSSC more efficient, firstly, the maximum feasible power can be acquired from PV system using a robust Maximum Power Point Tracking (MPPT) technique. Secondly, Firing Angle Optimization (FAO) can improve the output power quality of the inverter in SSSC. Thus, this research handles three optimization problems separately i.e., the SSSC parameter optimization, the FAO (minimization), and the MPPT (maximization) problems. For solving such complex, nonlinear, and nonconvex engineering optimization problems, a recently developed swarm-based metaheuristic namely Levy Flight motivated Adaptive Particle Swarm Optimization (APSOLF) technique is employed. Moreover, the superiority of APSOLF is justified over contemporary state-of-the-art techniques using statistical analyses. The APSOLF-based-MPPT can achieve tracking-efficiency above 99.8% and the lowest settling-time. The APSOLF-based-FAO attains 6.7148% THD satisfying the IEEE-519 standard without any filter circuit The MLL point enhancement and bus voltage profile improvement are also the notable observations.},
  archive      = {J_EAAI},
  author       = {Debanjan Mukherjee and Sourav Mallick},
  doi          = {10.1016/j.engappai.2023.106346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Utilization of adaptive swarm intelligent metaheuristic in designing an efficient photovoltaic interfaced static synchronous series compensator},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ICA and IVA bounded multivariate generalized gaussian
mixture based hidden markov models. <em>EAAI</em>, <em>123</em>, 106345.
(<a href="https://doi.org/10.1016/j.engappai.2023.106345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML), a branch of artificial intelligence (AI), is an area of computational science that is concerned with the analysis and interpretation of patterns and structures in data to enable learning and decision-making without the participation of a human. Hidden Markov models (HMMs), which have been acknowledged for decades but have recently made a significant revival in machine learning, are one of the most impressively powerful probabilistic models. HMMs are frequently employed in machine learning to model heterogeneous time series data. In this paper, we integrate independent component analysis (ICA) and ICA with a bounded multivariate generalized Gaussian mixture model (ICA-BMGGMM) into the HMM approach. One limitation of ICA is that it assumes the sources to be independent from each other. This assumption can be relaxed by combining independent vectors analysis (IVA) and IVA with the BMGGMM (IVA-BMGGMM) into the HMM approach to improve their modeling capability. We validate our proposed models using a variety of applications, such as human action recognition, speech recognition, and energy disaggregation. The results presented in the paper demonstrate the effectiveness of the proposed approaches for modeling different types of data. These data include KTH and Weizmann datasets for human action recognition, TIMIT and SDR for speech recognition, REDD dataset for energy disaggregation and EEG dataset for elliptic seizure classification. For all conducted experiments, our proposed models outperform other comparing models for all performance metrics such as accuracy, sensitivity, and precision. The best detection results were found using the IVABMGGMM-HMM for the reported experiments.},
  archive      = {J_EAAI},
  author       = {Ali H. Al-gumaei and Muhammad Azam and Manar Amayri and Nizar Bouguila},
  doi          = {10.1016/j.engappai.2023.106345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ICA and IVA bounded multivariate generalized gaussian mixture based hidden markov models},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automatic complex event processing rules generation
system for the recognition of real-time IoT attack patterns.
<em>EAAI</em>, <em>123</em>, 106344. (<a
href="https://doi.org/10.1016/j.engappai.2023.106344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has grown rapidly to become the core of many areas of application, leading to the integration of sensors, with IoT devices. However, the number of attacks against these types of devices has grown as fast as the paradigm itself. Certain inherent characteristics of the paradigm, as well as the limited computational capabilities of the devices involved, make it difficult to deploy security measures. This is why it is necessary to design, implement and study new solutions in the field of cybersecurity. In this paper, we propose an architecture that is capable of generating Complex Event Processing (CEP) rules automatically by integrating them with machine learning technologies. While the former is used to automatically detect attack patterns in real time, the latter, through the use of the Principal Component Analysis (PCA) algorithm, allows the characterization of events and the recognition of anomalies. This combination makes it possible to achieve efficient CEP rules at the computational level, with the results showing that the CEP rules obtained using our approach substantially improve upon the performance of the standard CEP rules, which are rules that are not generated by our proposal but can be defined independently by an expert in the field. Our proposal has achieved an F1-score of 0.98 on average, a 76 percent improvement in throughput over standard CEP rules, and a reduction in the network overhead of 86 percent over standard simple events, which are the simple events that are generated when our proposal is not used.},
  archive      = {J_EAAI},
  author       = {José Roldán-Gómez and Juan Boubeta-Puig and Javier Carrillo-Mondéjar and Juan Manuel Castelo Gómez and Jesús Martínez del Rincón},
  doi          = {10.1016/j.engappai.2023.106344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An automatic complex event processing rules generation system for the recognition of real-time IoT attack patterns},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time propeller fault detection for multirotor drones
based on vibration data analysis. <em>EAAI</em>, <em>123</em>, 106343.
(<a href="https://doi.org/10.1016/j.engappai.2023.106343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Fault Detection (FD) method to deal with propeller faults on multirotor drones in real-time. Several solutions have been proposed in the literature, however, they depend on additional sensors and/or dedicated hardware to deal with heavy computational complexity. So, they cannot be implemented in off-the-shelf commercial devices, i.e., without the aid of additional on-board sensors and/or extra computational power. The proposed method, instead, requires the on-board Inertial Measurement Unit (IMU) data only: by combining Finite Impulse Response (FIR), together with sparse classifiers, only a subset of the features is actually needed online and the FD is thus feasible in real-time. Design and tests are based on real flight data from a hexarotor, equipped with a conventional ArduPilot-based controller. The classification accuracy in testing is up to 93.37% (98.21%) with a binary tree (Linear Support Vector Machine (LSVM)). Moreover, the space and time complexity of the proposed method is low: on a PixHawk Cube flight controller, it requires less than 2% of the cycle time, and can then run in real-time. Finally, the proposed fault detection solution is model-free and it can be easily generalized to other multirotor vehicles.},
  archive      = {J_EAAI},
  author       = {Alessandro Baldini and Riccardo Felicetti and Francesco Ferracuti and Alessandro Freddi and Sabrina Iarlori and Andrea Monteriù},
  doi          = {10.1016/j.engappai.2023.106343},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106343},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time propeller fault detection for multirotor drones based on vibration data analysis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault-tolerant control for second-order nonlinear systems
with actuator faults via zero-sum differential game. <em>EAAI</em>,
<em>123</em>, 106342. (<a
href="https://doi.org/10.1016/j.engappai.2023.106342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stable operations of control systems play a vital role in mission accomplishments of the second-order nonlinear systems, such as six-axis robots used in intelligent production lines, industrial equipment and control systems. In this paper, a fault-tolerant control scheme is developed for a class of second-order nonlinear control system under actuator bias faults and loss of effectiveness faults via the zero-sum differential game method. Based on the backstepping method, a controller is designed to ensure system tracking performance. Then by the zero-sum differential game method, a fault-tolerant controller is designed for the equivalent error system. Simulation results show the validity of the designed fault-tolerant control scheme.},
  archive      = {J_EAAI},
  author       = {Yajie Ma and Qingyuan Meng and Bin Jiang and Hao Ren},
  doi          = {10.1016/j.engappai.2023.106342},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106342},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault-tolerant control for second-order nonlinear systems with actuator faults via zero-sum differential game},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification of grape leaf diseases based on VN-BWT and
siamese DWOAM-DRNet. <em>EAAI</em>, <em>123</em>, 106341. (<a
href="https://doi.org/10.1016/j.engappai.2023.106341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grape disease image identification plays a crucial role in the field of agricultural production. A grape leaf disease classification architecture was proposed for the problems of complex backgrounds and tiny inter-class differences in natural scene images. First, the binary wavelet transform combined with variable threshold method and NL-means improved MSR algorithm (VN-BWT) was used to enhance the grape leaf image to effectively retain more detailed information. Then, the novel Siamese network (Siamese DWOAM-DRNet) based on the combination of diverse-branch residual module (DRM) and the double-factor weight optimization attention mechanism (DWOAM) was proposed for grape leaf diseases classification. In Siamese DWOAM-DRNet, the DWOAM was designed to assign weights according to different strategies in vertical and horizontal directions, which can effectively improve the disease feature extraction ability and reduce the influence of complex background. Then, the diverse branch block (DBB) was used to build the DRM with residual connection strategy to enrich the feature space and improve the response of the network to the features. Finally, the Siamese network with the joint loss function was proposed to accelerate the convergence of the network and solve the problem of high disease similarity that makes the model difficult to distinguish. Experimental results show that the recognition accuracy of Siamese DWOAM-DRNet reached 93.26%, which outperformed other current identification networks in the comparison experiments. The method also performed well on other datasets, proving that the method has excellent generalization performance, which can be applied to identification of grape leaf diseases and realize their prevention and control.},
  archive      = {J_EAAI},
  author       = {Chuang Cai and Qifan Wang and Weiwei Cai and Yixin Yang and Yahui Hu and Liujun Li and Yanfeng Wang and Guoxiong Zhou},
  doi          = {10.1016/j.engappai.2023.106341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of grape leaf diseases based on VN-BWT and siamese DWOAM-DRNet},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransCFD: A transformer-based decoder for flow field
prediction. <em>EAAI</em>, <em>123</em>, 106340. (<a
href="https://doi.org/10.1016/j.engappai.2023.106340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational fluid dynamics (CFD) method is computationally intensive and costly, and evaluating aerodynamic performance through CFD is time-consuming and labor-intensive. For the design and optimization of aerodynamic shapes, it is essential to obtain aerodynamic performance efficiently and accurately. This paper proposed TransCFD, a Transformer-based decoding architecture for flow field prediction. The aerodynamic shape is parameterized and used as input to the decoder, which learns an end-to-end mapping between the shape and the flow fields. Compared with the CFD method, the TransCFD was evaluated to have a mean absolute error (MAE) of less than 1%, increase the speed by three orders of magnitude, and perform very well in generalization capability. The method simplifies the input requirements compared to most existing methods. Although the object of this work is a two-dimensional airfoil, the setup of this scheme is very general. TransCFD is promising for rapid aerodynamic performance evaluation, with potential applications in accelerating the aerodynamic design.},
  archive      = {J_EAAI},
  author       = {Jundou Jiang and Guanxiong Li and Yi Jiang and Laiping Zhang and Xiaogang Deng},
  doi          = {10.1016/j.engappai.2023.106340},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106340},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TransCFD: A transformer-based decoder for flow field prediction},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DBE: Dynamic belief entropy for evidence theory with its
application in data fusion. <em>EAAI</em>, <em>123</em>, 106339. (<a
href="https://doi.org/10.1016/j.engappai.2023.106339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Belief entropy is an effective uncertainty measurement in Dempster–Shafer evidence theory. However, the weight ratio between discord and non-specificity in the belief entropy is static and cannot be further modified according to different environments. To overcome this issue, this paper proposes dynamic belief entropy (DBE), which is a generalization of belief entropy by introducing a dynamic parameter. Compared with belief entropy, DBE can be flexibly modified based on the dynamic parameter, so as to improve the performance of measuring uncertainty in different environments. Besides, some properties of DBE are presented and illustrated with examples. Also, we design a dynamic data fusion method based on DBE. Compared with the existing methods, the proposed method utilizes DBE-based dynamic techniques, thereby enhancing the classification performance. Moreover, to illustrate the general applicability, the proposed method is verified on classification problems. The experimental results show that the proposed method outperforms the existing methods with a classification accuracy of 95.93% and an F1 score of 96.08%, demonstrating the effectiveness of our method.},
  archive      = {J_EAAI},
  author       = {Jixiang Deng and Yong Deng},
  doi          = {10.1016/j.engappai.2023.106339},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106339},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DBE: Dynamic belief entropy for evidence theory with its application in data fusion},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SkyWords: An automatic keyword extraction system based on
the skyline operator and semantic similarity. <em>EAAI</em>,
<em>123</em>, 106338. (<a
href="https://doi.org/10.1016/j.engappai.2023.106338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a hybrid keyword extraction method called SkyWords . It implements a novel supervised step based on the skyline operator and the majority voting principle for high-quality candidate keyword selection and an unsupervised step based on contextual semantics for the candidate keyword ranking. To achieve this, firstly, we build a feature vector database using the features of known keywords and then apply the skyline operator to retrieve the dominating feature vectors. To select the candidate keywords of a document, we compare each word of the document against the dominating feature vectors and assume the words that are as good as the majority of the dominating feature vectors as candidate keywords. To obtain the final set of keywords, we rank the candidate keywords based on their semantic similarity to the document based on their vector representation using the MPNet sentence transformer. We conducted experiments on six benchmark scholarly datasets to evaluate the performance of SkyWords and compared the results against eleven baseline keyword extraction systems. The experimental results show that the proposed novel keyword selection algorithm reduced the number of candidate keywords by several folds. Moreover, SkyWords achieved statistically significant improvements over the baseline methods in precision, recall, and F1 score. Compared to the baseline regarding ranking-based metrics, SkyWords achieved the highest mean average precision score for all datasets and the highest mean reciprocal rank score for all datasets but one. Furthermore, SkyWords extracted more relevant keywords than the baseline methods.},
  archive      = {J_EAAI},
  author       = {Furkan Goz and Alev Mutlu},
  doi          = {10.1016/j.engappai.2023.106338},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106338},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SkyWords: An automatic keyword extraction system based on the skyline operator and semantic similarity},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Surface topography characterization using a simple optical
device and artificial neural networks. <em>EAAI</em>, <em>123</em>,
106337. (<a
href="https://doi.org/10.1016/j.engappai.2023.106337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art methods for quantifying wear in cylinder liners of large internal combustion engines for stationary power generation require disassembly and cutting of the examined liner. This is followed by laboratory-based high-resolution microscopic surface depth measurement that quantitatively evaluates wear based on bearing load curves (also known as Abbott-Firestone curves). Such reference methods are destructive, time-consuming and costly. The goal of the research presented here is to develop nondestructive yet reliable methods for quantifying the surface topography. A novel machine learning framework is proposed that allows prediction of the bearing load curves representing the depth profiles from reflection RGB images of the liner surface. These images can be collected with a simple handheld microscope. A joint deep learning approach involving two neural network modules optimizes the prediction quality of surface roughness parameters as well. The network stack is trained using a custom-built database containing 422 perfectly aligned depth profile and reflection image pairs of liner surfaces of large gas engines. The observed success of the method suggests its great potential for on-site wear assessment of engines during service.},
  archive      = {J_EAAI},
  author       = {Christoph Angermann and Markus Haltmeier and Christian Laubichler and Steinbjörn Jónsson and Matthias Schwab and Adéla Moravová and Constantin Kiesling and Martin Kober and Wolfgang Fimml},
  doi          = {10.1016/j.engappai.2023.106337},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106337},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surface topography characterization using a simple optical device and artificial neural networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSENet: Mean and standard deviation based ensemble network
for cervical cancer detection. <em>EAAI</em>, <em>123</em>, 106336. (<a
href="https://doi.org/10.1016/j.engappai.2023.106336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is one of the most concerning carcinogenic diseases among women worldwide. The condition is especially bad in low- or middle-income countries due to the lack of medical facilities. In such situations, computer-aided diagnosis (CAD) systems can alleviate the need to a large extent. However, sometimes a single learning model may not be effective enough to capture relevant information for accurate prediction of diseases from complex data. To this end, we propose an ensemble of deep learning models, called Mean and Standard Deviation-based Ensemble Network (MSENet), for detecting cervical cancer from Pap smear images. Our ensemble model consists of three standard base classifiers, namely Xception, Inception V3, and VGG-16. We further improve the classification abilities of these models by implementing a novel probability enhancement scheme that takes into account the mean and standard deviation of the confidence scores. This technique enables the overall framework to capture complementary information offered by the base classifiers and is tailored to the characteristics of deep learners. Finally, we use the product rule to aggregate the obtained outcomes and get final predictions. The proposed MSENet has been evaluated on a standard public benchmark dataset, called SIPaKMeD. With a classification accuracy of 97.21% using a 5-fold cross-validation scheme, the MSENet outperforms many state-of-the-art methods. The source codes are made public in the following Github repository https://github.com/rishavpramanik/msenet .},
  archive      = {J_EAAI},
  author       = {Rishav Pramanik and Bihan Banerjee and Ram Sarkar},
  doi          = {10.1016/j.engappai.2023.106336},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106336},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MSENet: Mean and standard deviation based ensemble network for cervical cancer detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review of artificial intelligence and internet of things
technologies in land and water management research during 1991–2021: A
bibliometric analysis. <em>EAAI</em>, <em>123</em>, 106335. (<a
href="https://doi.org/10.1016/j.engappai.2023.106335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenges of urbanization, land degradation, water scarcity, and climate change are threatening agricultural systems and food security. Therefore, it is essential to manage land and water resources sustainably to improve productivity and address these challenges. Digital agriculture, which involves the use of smart systems and advanced farming practices incorporating Artificial Intelligence (AI) and Internet of Things (IoT) technologies, can provide solutions for sustainable agriculture and climate change adaptation. This study aims to fill the research gap by understanding the recent pulse and current trends of significant works published on AI and IoT-assisted land and water management (LWM) research. A bibliometric analysis of 436 English language articles published over the last three decades (1991–2021) was conducted. The study revealed a significant shift in research trends in 2010, with over 60 AI techniques utilized under different AI and IoT frameworks for LWM. The highly adopted AI techniques include Artificial Neural Networks (ANN—9.85%), Adaptive Neuro-Fuzzy Inference System (ANFIS —5.98%), Support Vector Regression (SVR—3.87%), Random Forest (RF—3.16%),​ and Multilayer Perceptron-ANN (MLP-ANN—2.81%). China, India, Iran, Australia, and the USA were identified as pioneers in the field, while Italy, Spain, and Saudi Arabia showed potential as emerging countries but with low collaboration links. The study also discussed the current limitations and challenges of AI and IoT technologies. Future research focus areas for AI and IoT were identified, and it was recommended to conduct comparative evaluations of AI techniques to determine the most effective approach for specific LWM domains.},
  archive      = {J_EAAI},
  author       = {Abhishek Patel and Ajaykumar Kethavath and N.L. Kushwaha and Anandkumar Naorem and Manisha Jagadale and Sheetal K.R. and Renjith P.S.},
  doi          = {10.1016/j.engappai.2023.106335},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106335},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review of artificial intelligence and internet of things technologies in land and water management research during 1991–2021: A bibliometric analysis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe semi-supervised clustering based on dempster–shafer
evidence theory. <em>EAAI</em>, <em>123</em>, 106334. (<a
href="https://doi.org/10.1016/j.engappai.2023.106334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a safe semi-supervised clustering algorithm based on Dempster–Shafer (D–S) evidence theory. The motivation is that D–S evidence theory can be used to fuse multiple base clustering results and obtain robust confidence estimations of mislabeled samples. Firstly, the proposed algorithm constructs multiple base clusters using fuzzy c -means and kernel fuzzy c -means. Base clusters with good performance are selected according to a clustering validity function. Then, D–S evidence theory is used to fuse the results of the selected base clusters, and the confidence of labeled samples is calculated based on the fused results. Finally, we construct a p -nearest neighbor graph to limit the outputs of labeled samples with low confidence to be those of the p nearest unlabeled samples. It is desired to reduce the negative influence of labeled samples with low confidence and achieve safe exploitation. To verify the effectiveness of the proposed algorithm, we compare it to several unsupervised and semi-supervised clustering algorithms. The results demonstrate that our algorithm yields higher accuracy and is more stable.},
  archive      = {J_EAAI},
  author       = {Haitao Gan and Zhi Yang and Ran Zhou and Li Guo and Zhiwei Ye and Rui Huang},
  doi          = {10.1016/j.engappai.2023.106334},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106334},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safe semi-supervised clustering based on Dempster–Shafer evidence theory},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSLEFC: A low-frequency focused underwater acoustic signal
classification and analysis system. <em>EAAI</em>, <em>123</em>, 106333.
(<a href="https://doi.org/10.1016/j.engappai.2023.106333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many feature extraction techniques are employed to study the classification of underwater acoustic, however, most of these techniques result in the loss of detailed information in this field. A Multi-scale short-time Fourier transform (MS-STFT) method was proposed to improve the low-frequency information and maintain the detailed information by increasing the number of channels. An effective data augmentation approach was proposed and a Ladder-like Encode (LE) architecture was built to increase the generalizability of the model and the classification accuracy for the features extracted. Finally, A Frequency-CAM (FC) method is proposed to analyze the frequency band locations that the neural network is interested in when conducting classification tasks on various classes of data. The integration of the above technologies is called MSLEFC. The performance of this system has been tested on two ship radiation noise datasets and obtained 82.94% and 96.06% accuracy, respectively. On the ShipsEar dataset, the proposed method increases the accuracy by 0.7% over the previous state-of-the-art method. The proposed model architecture has significant improvements in parameter size and computation compared to ResNet50.},
  archive      = {J_EAAI},
  author       = {Yunqi Zhang and Qunfeng Zeng},
  doi          = {10.1016/j.engappai.2023.106333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MSLEFC: A low-frequency focused underwater acoustic signal classification and analysis system},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SENE: A novel manifold learning approach for distracted
driving analysis with spatio-temporal and driver praxeological features.
<em>EAAI</em>, <em>123</em>, 106332. (<a
href="https://doi.org/10.1016/j.engappai.2023.106332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there are many studies conducted on distracted driving, the growing number of accidents on roads demands further serious attention. The majority of the distracted driving-related data in real life are unlabeled and higher dimensional, leading to complex analyses. There is a lack of existence of proper indices for understanding the perilousness due to distracted driving, which makes it very difficult to understand which road or neighborhood has a higher risk of accidents. Despite earlier studies have focused on either spatiotemporal or praxeological factors separately, they have not considered both factors together. Moreover, crisp rule extraction and interpretation are lacking in the literature. Therefore, to deal with such issues, we have proposed a new methodology which: (i) develops Schrodinger Eigenmap Neighborhood Embedding (SENE) manifold learning for dimensionality reduction, followed by K-means clustering, (ii) develops road perilousness index (RPI) and neighborhood PI (NPI) to explain dangerousness of roads or neighborhoods, (iii) uses both spatiotemporal and driver praxeological factors, and (iv) develops Tolerance Rough Set Approach (TRSA) for crisp rules generation and interpretation. Road accident data from the Nevada Department of Transportation is used as a case study. Besides, a total of four benchmark datasets from the University of California Irvine repository are also used for comparative study to prove the superiority of our proposed methodology over some state-of-the-art. Experimental results reveal that the proposed methodology outperforms others by providing the highest clustering accuracy with four clusters. Finally, a set of 16 crisp rules are extracted and interpreted from clusters using TRSA.},
  archive      = {J_EAAI},
  author       = {Subhajit Bag and Rahul Golder and Sobhan Sarkar and Saptashwa Maity},
  doi          = {10.1016/j.engappai.2023.106332},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106332},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SENE: A novel manifold learning approach for distracted driving analysis with spatio-temporal and driver praxeological features},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Backtracking search algorithm with dynamic population for
energy consumption problem of a UAV-assisted IoT data collection system.
<em>EAAI</em>, <em>123</em>, 106331. (<a
href="https://doi.org/10.1016/j.engappai.2023.106331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, collecting data from IoT devices by unmanned aerial vehicles (UAVs) has become a very hot research topic. This paper focuses on the energy consumption problem of a UAV-based IoT data collection system. To solve the considered energy consumption problem, this paper proposes a new population-based optimization algorithm called the backtracking search algorithm with dynamic population (BSADP), which can determine the optimal number and locations of stop points of the UAV simultaneously. In addition, BSADP has a simple framework, which consists of the proposed enhanced backtracking search algorithm (EBSA) and the designed population adjustment mechanism with opposition-based learning (PAMOBL). In the search process, the population is regarded as the entire deployment of the UAV. BSADP firstly generates the trail deployment of the UAV by EBSA and then the next generation deployment of the UAV is produced based on the trail deployment and PAMOBL. The performance of BSADP is investigated by two energy consumption formulations. Experimental results support the superiority of BSADP in optimizing the deployment of the UAV and prove the application value of BSADP in the real scenario. The source code of the proposed algorithm can be found from: https://github.com/jsuzyy/BSADP .},
  archive      = {J_EAAI},
  author       = {Yiying Zhang and Chao Huang and Hailong Huang},
  doi          = {10.1016/j.engappai.2023.106331},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106331},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Backtracking search algorithm with dynamic population for energy consumption problem of a UAV-assisted IoT data collection system},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method supporting fault-tolerant optical text recognition
from video sequences recorded with handheld cameras. <em>EAAI</em>,
<em>123</em>, 106330. (<a
href="https://doi.org/10.1016/j.engappai.2023.106330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper a method supporting the optical character recognition from video sequences recorded with cameras without good stabilization is proposed. Due to the presence of various distortions, such as motion blur, shadows, lossy compression artifacts, auto-focusing errors, etc., the quality of individual video frames, e.g., recorded by a smartphone camera, differs noticeably, influencing the results of text recognition, causing the presence of additional errors that may be unacceptable even in fault-tolerant applications. Although the quality of individual video frames may be assessed using state-of-the-art no-reference image quality metrics, the obtained results, particularly using the relatively fast metrics, are poorly correlated with recognition results. Therefore, a novel hybrid approach to image quality assessment supporting fault-tolerant optical character recognition is proposed, making it possible to select automatically the video frames leading to the smallest number of errors. Since the data extraction is rarely perfect, the proposed method may be particularly useful in systems where users should identify the faults defined as a too high number of text recognition errors. The proposed method makes it possible to eliminate low quality fragments of video sequences from further analysis, reducing the overall computational burden. It may also be useful in industrial OCR applications based on offline video recording with memory constraints where the use of online OCR services is not possible.},
  archive      = {J_EAAI},
  author       = {Krzysztof Okarma and Piotr Lech},
  doi          = {10.1016/j.engappai.2023.106330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A method supporting fault-tolerant optical text recognition from video sequences recorded with handheld cameras},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of a novel mixed interval type-2 fuzzy logic
controller for 2-DOF robot manipulator with payload. <em>EAAI</em>,
<em>123</em>, 106329. (<a
href="https://doi.org/10.1016/j.engappai.2023.106329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a novel coupling-based mixed interval type-2 fuzzy logic controller (MIT2FLC) for trajectory tracking problems of highly nonlinear and complex robot manipulator plants. The major impediment for these types of plants is coupling between the robotic links at the time of operation. In addition, the performances of these plants are adversely affected by parameter uncertainties, random noise and external disturbances. Therefore, the MIT2FLC approach with an additional degree of freedom in the membership functions is proposed to efficiently deal with the problem of uncertainty and provide robust performance. The Grey wolf optimization (GWO) is implemented to calculate the optimal parameters of the proposed controller. For checking the performance, the MIT2FLC approach is compared with its type-1 fuzzy counterparts, namely mixed type-1 fuzzy logic controller (MT1FLC), type-1 fuzzy logic controller (T1FLC) and PID controllers. Robustness analysis of the proposed controller is investigated for external disturbances, varying system parameters, and random noise.},
  archive      = {J_EAAI},
  author       = {Anupam Kumar and Ritu Raj and Amit Kumar and Bharat Verma},
  doi          = {10.1016/j.engappai.2023.106329},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106329},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design of a novel mixed interval type-2 fuzzy logic controller for 2-DOF robot manipulator with payload},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Firefly search algorithm based on leader strategy.
<em>EAAI</em>, <em>123</em>, 106328. (<a
href="https://doi.org/10.1016/j.engappai.2023.106328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the firefly search algorithm, individuals will move toward a brighter direction according to the light intensity factor in the iteration, which has a high convergence speed. It faces the problem of unbalanced exploration and exploitation. At the same time, the diversity of the algorithm is insufficient. Especially when dealing with complex benchmark functions or engineering problems, it cannot show excellent performance. This paper proposes a firefly search algorithm based on the leader and follower population model and combines the Brownian motion strategy and Levy flight strategy (FA-BMLA). Using the different performances of the Brownian motion strategy and Levy flight strategy in exploration and exploitation, adding an adaptive parameter switching that the FA-BMLA can accord to different situations change its strategy. By testing 20 benchmark functions such as single-mode, multi-mode, and CEC2014, the results are compared with advanced algorithms such as the firefly search algorithm and its variants, whale optimization algorithm, and salp swarm algorithm, and the results are evaluated by the nonparametric test method. Numerical results and statistical experiments show that the FA-BMLA has better solution quality, convergence accuracy, and stability. The FA-BMLA is applied to solve the three engineering problems of pressure vessel, welding beam, and rolling bearing. The data results and experimental comparisons show that FA-BMLA can obtain an accurate solution to engineering problems.},
  archive      = {J_EAAI},
  author       = {Xuncai Zhang and Shida Wang},
  doi          = {10.1016/j.engappai.2023.106328},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106328},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Firefly search algorithm based on leader strategy},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comparison of EMG-based hand gesture recognition systems
based on supervised and reinforcement learning. <em>EAAI</em>,
<em>123</em>, 106327. (<a
href="https://doi.org/10.1016/j.engappai.2023.106327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand gesture recognition (HGR) based on electromyography signals (EMGs) has been one of the most relevant research topics in the human–machine interfaces field in recent years. The HGR systems are aimed at identifying the moment in which a hand gesture was performed as well as the gesture category. To date, several HGR state-of-the-art methods are based mainly on supervised machine learning (ML) techniques. However, the use of reinforcement learning (RL) approaches to classify EMGs has not yet been thoroughly evaluated. Moreover, the behavior of HGR systems based on ML and RL methods on large datasets for user-general HGR systems is still an open research problem. In the present work, we compare a supervised learning with a reinforcement learning HGR system, which are composed of the following stages: pre-processing, feature extraction, classification, and post-processing. We compared the performance of using both a supervised and a reinforcement learning method to classify and recognize EMGs for six different hand gestures. We performed experiments by using training, validation, and test sets on the EMG-EPN-612 public dataset, and the results were evaluated for user-general HGR models. The final accuracy results on the test set demonstrate that the best model was obtained for the supervised learning method, reaching up to 90 . 49 % ± 9 . 7 % and 86 . 83 % ± 11 . 30 % for classification and recognition accuracy respectively. The results obtained in this work demonstrated that supervised learning methods outperform reinforcement learning methods for user-general HGR systems based on EMGs for the EMG-EPN-612 dataset distribution.},
  archive      = {J_EAAI},
  author       = {Juan Pablo Vásconez and Lorena Isabel Barona López and Ángel Leonardo Valdivieso Caraguay and Marco E. Benalcázar},
  doi          = {10.1016/j.engappai.2023.106327},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106327},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comparison of EMG-based hand gesture recognition systems based on supervised and reinforcement learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying novelties and anomalies for incremental learning
in streaming time series forecasting. <em>EAAI</em>, <em>123</em>,
106326. (<a
href="https://doi.org/10.1016/j.engappai.2023.106326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data can be defined as a chronological sequence of observations on a variable of interest. A streaming time series is a time series that arrives continuously at high speed and has a data distribution that may change over time. Streaming time series data usually comes from electronic devices such as sensors and many of the applications dealing with streaming data in Industry 4.0 require real-time responses. Performing real-time forecasting offers the possibility to consider new types of patterns in the incoming streaming data, which is not possible when working with batch models. This paper presents a new approach to detect novelties and anomalies in real-time using a nearest-neighbors based forecasting algorithm. The algorithm works with an offline base model that is updated as stream data arrives following an incremental learning approach. It detects unknown patterns called novelties and anomalies. Novelties are included in the model in an online way and anomalies trigger an alarm as they present unexpected behaviors that need to be specifically analyzed. The algorithm has been tested with Spanish electricity demand data. Results show that the prediction errors obtained when the model is updated considering novelties and anomalies are lower than the errors obtained when the model is not updated. Thus, the model adjusts in real-time to the new patterns of data providing accurate errors and real-time predictions.},
  archive      = {J_EAAI},
  author       = {Laura Melgar-García and David Gutiérrez-Avilés and Cristina Rubio-Escudero and Alicia Troncoso},
  doi          = {10.1016/j.engappai.2023.106326},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106326},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying novelties and anomalies for incremental learning in streaming time series forecasting},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Introduction to the special issue on intelligent control and
optimisation. <em>EAAI</em>, <em>123</em>, 106325. (<a
href="https://doi.org/10.1016/j.engappai.2023.106325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Seán McLoone ( The guest editors ) and Kevin Guelton and Thierry Guerra and Gian Antonio Susto and Juš Kocijan and Diego Romeres},
  doi          = {10.1016/j.engappai.2023.106325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Introduction to the special issue on intelligent control and optimisation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-branch network for change detection of remote sensing
image. <em>EAAI</em>, <em>123</em>, 106324. (<a
href="https://doi.org/10.1016/j.engappai.2023.106324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change detection is important in remote sensing image analysis. In recent years, significant breakthroughs have been made in change detection algorithms based on deep learning. However, due to continuous downsampling, the detection results of these algorithms still have serious detection errors, detection omissions and edge blurring. Aiming at these problems, this paper proposes a dual-branch network for change detection. The network has two branches, which are used to extract the depth-variant semantic features of the multi-temporal image pairs and the respective features of each image respectively. In addition, we designed a Multi-scale Strip Convolution Module (MSCM) to extract the multi-scale features of the image, a new Spatial Attention Module (SAM) to strengthen the feature representation of changing regions, and a Feature Fusion Network (FFN) to guide the fusion between multiple features of the two branches. Experimental results show that the proposed method substantially mitigates detection errors, detection omissions and obtains sharper edges, it outperforms other current algorithms.},
  archive      = {J_EAAI},
  author       = {Chong Ma and Liguo Weng and Min Xia and Haifeng Lin and Ming Qian and Yonghong Zhang},
  doi          = {10.1016/j.engappai.2023.106324},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106324},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-branch network for change detection of remote sensing image},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Feature pre-inpainting enhanced transformer for video
inpainting. <em>EAAI</em>, <em>123</em>, 106323. (<a
href="https://doi.org/10.1016/j.engappai.2023.106323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based video inpainting methods aggregate coherent contents into missing regions by learning dependencies spatial–temporally. However, existing methods suffer from the inaccurate self-attention calculation and excessive quadratic computational complexity, due to uninformative representations of missing regions and inefficient global self-attention mechanisms, respectively. To mitigate these problems, we propose a Feature pre-Inpainting enhanced Transformer (FITer) video inpainting method, in which the feature pre-inpainting network (FPNet) and local–global interleaving Transformer are designed. The FPNet pre-inpaints missing features before the Transformer by exploiting spatial context, and the representations of missing regions are thus enhanced with more informative content. Therefore, the interleaving Transformer can calculate more accurate self-attention weights and learns more effective dependencies between missing and valid regions. Since the interleaving Transformer involves both global and window-based local self-attention mechanisms, the proposed FITer method can effectively aggregate spatial–temporal features into missing regions while improving efficiency. Experiments on YouTube-VOS and DAVIS datasets demonstrate that the FITer method outperforms previous methods qualitatively and quantitatively.},
  archive      = {J_EAAI},
  author       = {Guanxiao Li and Ke Zhang and Yu Su and Jingyu Wang},
  doi          = {10.1016/j.engappai.2023.106323},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106323},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature pre-inpainting enhanced transformer for video inpainting},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-driven spiking neural network based on membrane
potential modulation for remote sensing image classification.
<em>EAAI</em>, <em>123</em>, 106322. (<a
href="https://doi.org/10.1016/j.engappai.2023.106322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural network (SNN) based on sparse triggering and event-driven is a hardware-friendly model. SNN can provide an ultra-low power alternative for the deep neural network (DNN) to process remote sensing images. Brain information processing depends on the action potential of neurons. Therefore, the biological rationality of the artificial neural network (ANN) has been questioned. SNN is a more suitable model for brain information processing mechanisms. At present, the SNN obtained by ANN conversion has achieved the best performance in the current image processing tasks. However, the method based on ANN to SNN will have performance loss in the conversion process. Herein, we proposed a spiking neuron threshold-following reset (TF-reset) method and a membrane potential modulation method to reduce the loss of network conversion. We theoretically analyzed the proposed TF-reset and deduced the relationship between spike firing rate and neuron activation. In the experiment, we used an improved VGG-15 architecture combined with the method of transfer learning to apply the model to the classification task of remote sensing images. SNN-VGG-15 based on TF-reset and membrane potential modulation algorithm achieved a classification accuracy of 99.14%, 94.54%, and 95.00% on UCM, RSSCN7, and AID. Our algorithm can not only realize the lossless conversion of SNN but also outperforms the original network in classification performance on UCM and RSSCN7. In addition, our model also has advantages in energy consumption and noise robustness. The algorithm in this paper can provide a reference for the research remote sensing images procession using SNN.},
  archive      = {J_EAAI},
  author       = {Li-Ye Niu and Ying Wei and Yue Liu},
  doi          = {10.1016/j.engappai.2023.106322},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106322},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Event-driven spiking neural network based on membrane potential modulation for remote sensing image classification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Keypoint-enhanced adaptive weighting model with effective
frequency channel attention for driver action recognition.
<em>EAAI</em>, <em>123</em>, 106321. (<a
href="https://doi.org/10.1016/j.engappai.2023.106321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents caused by distracted driving have become a threat to people’s lives and properties, so it is necessary to recognize driver actions for early warning effectively. Since it is sometimes impossible to distinguish similar activities only by global driving image features, we explicitly extract the action-related keypoint features and propose a keypoint-enhanced model for classification. Specifically, we construct an effective frequency channel attention module to generate discriminative global representations. Considering the diversity of keypoint information, we design an adaptive weighted residual bottleneck to make the model weights of the input keypoint features dynamic. Furthermore, we propose a keypoint-guided conditional computation module. Under the guidance of keypoint features, the expert weights generated by conditional computation enable the model to adapt to different categories of driving images. Essentially, the model generates keypoint-enhanced attention to scale the classification feature channels. We also propose a model backbone training strategy combining self-supervised and supervised contrastive learning so that the model can achieve better results without large-scale labeled driver behavior data.},
  archive      = {J_EAAI},
  author       = {Mingqi Lu and Xiaobo Lu},
  doi          = {10.1016/j.engappai.2023.106321},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106321},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Keypoint-enhanced adaptive weighting model with effective frequency channel attention for driver action recognition},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Electric vehicle charging and discharging scheduling
strategy based on dynamic electricity price. <em>EAAI</em>,
<em>123</em>, 106320. (<a
href="https://doi.org/10.1016/j.engappai.2023.106320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth in the number of electric vehicles (EVs) has significantly increased the demand for electricity for residents. In addition, because the charging time of EVs highly coincides with the peak period of user electricity consumption, the disorderly charging of EVs will lead to the overload of the power grid transformer. Traditional control methods lack certain robustness and do not fully consider the uncertainty of EVs. As a result, the V2G participation rate of electric vehicles cannot be determined, and the control reliability is low. To solve the above problems, this paper designs a reinforcement learning framework of Long Short-Term Memory network and Improved Linear programming algorithm (LSTM-ILP) to control the V2G of EVs.This paper comprehensively considers the overall electric vehicle charging demand, discharge potential, large grid electricity price, aggregator, and users’ interests demands. Firstly, aiming to minimize the charging and discharging fee of EVs and the load peak-to-valley difference of the power grid, a dynamic electricity price based on Long Short-Term Memory neural network (LSTM) is established. Then, the improved linear programming algorithm (ILP) is used to solve the charging and discharging optimization problem of EV, and the results are fed back to the input of the next iterative update of the LSTM, and finally, the optimal electricity price and EV charging and discharging schedule are achieved. The simulation results show that the LSTM-ILP framework can not only reduce the charging fee of electric vehicles, but also achieve the Peak and valley trimming of the grid load. Charging costs for EV users were reduced by 42.1% compared with unordered charging, and by 22% percent compared with orderly charging.},
  archive      = {J_EAAI},
  author       = {Lina Ren and Mingming Yuan and Xiaohong Jiao},
  doi          = {10.1016/j.engappai.2023.106320},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106320},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Electric vehicle charging and discharging scheduling strategy based on dynamic electricity price},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated FMEA framework considering expert reliability
for classification and its application in aircraft power supply system.
<em>EAAI</em>, <em>123</em>, 106319. (<a
href="https://doi.org/10.1016/j.engappai.2023.106319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The risk assessment of the integrated drive generator (IDG) is a significant problem in flight safety that directly affects the operation of the aircraft power system However, the current IDG risk assessment methods still have many limitations, leading to risk identification and classification that is not accurate and scientific. Therefore, this paper constructs a failure mode and effect analysis (FMEA) framework for IDG risk identification and classification considering expert reliability in unbalanced hesitant fuzzy linguistic term sets (UHFLTSs) environment. First, since the UHFLTSs can effectively describe uncertain and imprecise linguistic information of decision makers (DMs) and adapt it to practical applications, it is specially chosen to depict the evaluation of DMs. Second, the importance of experts is fully assessed by combining expert reliability and expert weight since the variation in expert reliabilities may have a substantial impact on the final sorting outcomes. In addition, the group best–worst method (GBWM) is combined with the entropy method to determine the risk factor weight. Third, to build up the accuracy and stability of classification, a new integrated TOPSIS-ELECTRE TRI decision framework is proposed to classify failure modes more rationally. The sensitivity analysis of parameters demonstrates the robustness of the proposed method. Meanwhile, the effectiveness and superiority of the method are verified both qualitatively and quantitatively. By comparing with several typical sorting methods, the proposed method has more realistic and stable classification results.},
  archive      = {J_EAAI},
  author       = {Zhengmin Liu and Yingjie Zhao and Peide Liu},
  doi          = {10.1016/j.engappai.2023.106319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated FMEA framework considering expert reliability for classification and its application in aircraft power supply system},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-based UAV navigation framework with digital twin
technology for mobile target visitation. <em>EAAI</em>, <em>123</em>,
106318. (<a
href="https://doi.org/10.1016/j.engappai.2023.106318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Air Vehicles (UAVs), i.e. drones, have become a key enabler technology of many reconnaissance applications in different fields, such as military, maritime, and transportation. UAVs offer several benefits, such as affordability and flexibility in deployment. However, their limited flight time due to energy consumption is one of the key limitations. Therefore, it is crucial to ensure that UAVs can complete the mission while consuming the least energy possible. In this paper, we propose a novel framework for UAV smart navigation to minimize the time and energy of planning mobile targets visitation. We develop a Deep Reinforcement Learning (DRL) approach to allow the drone to learn the targets’ mobility pattern and build its least energy scanning strategy accordingly. We conduct an initial evaluation of the system and our proposed DRL model policy using simulation. Then, to overcome the time-consuming exploration phase of DRL, we develop a Digital Twin (DT) environment of 3D physics-based simulator, which can be used to train the DRL agent efficiently. We also developed a testbed based on hardware integration with the parrot ANAFI drone to verify the feasibility of the proposed methodology. Our findings confirm that the DRL-based agent can achieve performance close to that of a benchmark policy. Moreover, the testbed experiment validates the practicality of utilizing the DT environment for DRL exploration.},
  archive      = {J_EAAI},
  author       = {Abdulrahman Soliman and Abdulla Al-Ali and Amr Mohamed and Hend Gedawy and Daniel Izham and Mohamad Bahri and Aiman Erbad and Mohsen Guizani},
  doi          = {10.1016/j.engappai.2023.106318},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106318},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AI-based UAV navigation framework with digital twin technology for mobile target visitation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An immune-based multi-agent system for flexible job shop
scheduling problem in dynamic and multi-objective environments.
<em>EAAI</em>, <em>123</em>, 106317. (<a
href="https://doi.org/10.1016/j.engappai.2023.106317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a biological immune-based multi agent system (IMAS) is developed to overcome the multi-objectivity and dynamicity of the multi-objective dynamic flexible job shop scheduling (MODFJSS) problem. In modeling the MODFJSS problem, four objectives, i.e., makespan, total weighted tardiness, maximal machine workload, and schedule stability, are considered for simultaneous optimization. In the proposed IMAS architecture, immune agents are coordinated to identify the environment, generate a set of non-dominated schedules, and select a utility optimal schedule. In addition, these agents have the ability of self-adaptation and flexible coordination to adapt to the environment of MODFJSS problem. The performance of the proposed method was evaluated on dynamic versions of the five commonly used benchmark instance sets in comparison with three state-of-the-art algorithms. The obtained results showed that the proposed IMAS outperformed the competitors in most of the experiments conducted in this study.},
  archive      = {J_EAAI},
  author       = {Seyed Ruhollah Kamali and Touraj Banirostam and Homayun Motameni and Mohammad Teshnehlab},
  doi          = {10.1016/j.engappai.2023.106317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An immune-based multi-agent system for flexible job shop scheduling problem in dynamic and multi-objective environments},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel building heat pump system semi-supervised fault
detection and diagnosis method under small and imbalanced data.
<em>EAAI</em>, <em>123</em>, 106316. (<a
href="https://doi.org/10.1016/j.engappai.2023.106316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faulty heat pump system operating can cause excessive energy consumption and an uncomfortable indoor environment. Data-driven method is one of the most widely studied Fault Detection and Diagnosis (FDD) methods in building heat pump systems. However, the fault data is difficult to collect and label, which makes it a significant challenge to apply a data-driven method. Therefore, a novel semi-supervised FDD method that could utilize small labelled and unlabelled fault data was proposed, considering unknown fault detection in unlabelled data. The fundamental model consisted of four parts: encoder, double discriminators, generator, and bagging classifiers, and all networks were integrated to train simultaneously. Additionally, batch nuclear-norm maximization and pseudo-label were utilized to improve the model. The proposed method could realize data augmentation, pseudo-label utilization, and FDD in one end-to-end model. Normal and fault data were collected from a variable refrigerant flow heat pump system to verify this method. The proposed method was compared with several methods in previous studies. The performance indexes showed that the proposed method had averaged 65.56%, 75.50%, 82.25%, 83.30%, and 86.26% overall accuracy under each training labelled group, respectively. The unlabelled data could improve the model effectively, and the averaged detection rate of unknown fault could reach 98.00%, 98.82%, 98.88%, 98.66%, 98.94%, and 98.82%, respectively, under different numbers of unlabelled data. Additionally, the analysis of unknown fault diagnosis results indicated that faults with different severities had similar operating characteristics.},
  archive      = {J_EAAI},
  author       = {Jianxin Zhang and Yuanyi Xu and Huanxin Chen and Lu Xing},
  doi          = {10.1016/j.engappai.2023.106316},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106316},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel building heat pump system semi-supervised fault detection and diagnosis method under small and imbalanced data},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SUNET: Speaker-utterance interaction graph neural network
for emotion recognition in conversations. <em>EAAI</em>, <em>123</em>,
106315. (<a
href="https://doi.org/10.1016/j.engappai.2023.106315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion Recognition in Conversations (ERC) can capture the speakers’ emotional changes in multiple rounds of conversation, so it has a wide range of applications. In recent years, Graph Neural Networks have been naturally used in ERC tasks due to their ability to capture complex non-Euclidian spatial features. However, how to model conversations easily and effectively to improve the effect of ERC in the complex interaction mode still needs to be explored. To this end, we propose a new approach to construct a speaker-utterance interactive heterogeneous network that effectively models context while taking into account the global characteristics of speakers. On this basis, we propose a graph neural network based on the speaker and the corresponding utterances interactions, which dynamically updates the representations of utterances and speakers according to the order in which the speakers talk. We formulate different update methods for utterance and speaker nodes to ensure that the particularity of the heterogeneous network is fully explored. We conduct extensive experiments on four ERC benchmark datasets, and our approach achieves an average 0.7% performance improvement over the most advanced methods, which validates the effectiveness of properly modeling speakers in ERC tasks.},
  archive      = {J_EAAI},
  author       = {Rui Song and Fausto Giunchiglia and Lida Shi and Qiang Shen and Hao Xu},
  doi          = {10.1016/j.engappai.2023.106315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SUNET: Speaker-utterance interaction graph neural network for emotion recognition in conversations},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Day ahead carbon emission forecasting of the regional
national electricity market using machine learning methods.
<em>EAAI</em>, <em>123</em>, 106314. (<a
href="https://doi.org/10.1016/j.engappai.2023.106314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of regional electrical grid carbon emissions is an essential part of demand response programs for emissions reduction. Most existing research for short-term (day ahead) forecasting focuses on the use of variations of recurrent neural networks, in particular, the Long–Short​ Term Memory (LSTM) cells. This research proposes a Particle Swarm Optimised-extremely randomised trees (PSO-ERT) regressor model for day ahead forecasting of the emissions intensity of the Australian National Electricity Market (NEM). The PSO-ERT model is compared with LSTM, another method known as Extreme Learning Machine (ELM), and also with two classic machine learning algorithms, Multi-layer perceptron (MLP) and Decision Tree (DT). Models are trained using 1.5 years of weather, demand and generation data collected from the five NEM regions. Results show that the ERT model performs better than both LSTM and ELM with Root Mean Squared Error (RMSE) of 42.9, 109.8, 165.7, 25.4 and 74.1 for New South Wales, Tasmania, South Australia, Queensland and Victoria, respectively. For all models, forecasting performance was better for regions with less renewable generation and for times when renewable generation was a smaller percentage of demand suggesting that the addition of weather forecasts in the predictor feature set would further improve performance.},
  archive      = {J_EAAI},
  author       = {Vahid Aryai and Mark Goldsworthy},
  doi          = {10.1016/j.engappai.2023.106314},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106314},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Day ahead carbon emission forecasting of the regional national electricity market using machine learning methods},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Statistical analysis and neural network modeling of
functionally graded porous nanobeams vibration in an elastic medium by
considering the surface effects. <em>EAAI</em>, <em>123</em>, 106313.
(<a href="https://doi.org/10.1016/j.engappai.2023.106313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The natural frequency of a clamped–clamped functionally graded porous (FGP) nanobeam is predicted in this study. Material distribution is considered based on monotonous, symmetric, and non-symmetric patterns in the thickness direction. This paper deals with governing equations of nanobeams based on third-order shear deformation beam theory in conjunction with nonlocal strain gradient theory (NSGT) and surface effects. Artificial neural network (ANN) is utilized to predict the effect of eight parameters including temperature gradient, residual surface stress, porosity distribution pattern, porosity parameter, nonlocal and material length scale parameters, and elastic and shear coefficients of Pasternak foundation on the fundamental frequency of FGP nanobeam. Different training methods are selected to simulate input and output dependency. Results show that the dependency of the natural frequency is inverse to the temperature gradient and nonlocal parameter in the sense that increasing these factors will decrease the natural frequency. Also, increasing the material length scale parameter grows the effect of the nonlocal parameter. Residual surface stress, material length scale, and Pasternak foundation parameters have a direct effect on the output and among them; the material length scale parameter has a more noticeable effect. Finally, it was found that by increasing the porosity parameter value, the diversity of natural frequency levels up drastically},
  archive      = {J_EAAI},
  author       = {Xiaofei Cheng and Sara Hakem Al-Khafaji and Mohammad Hashemian and Mariem Ahmed and S. Ali Eftekhari and Ali Ihsan Alanssari and Nabaa Muhammad diaa and Manal Morad Karim and Davood Toghraie and Ahmed Hussien Alawadi},
  doi          = {10.1016/j.engappai.2023.106313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Statistical analysis and neural network modeling of functionally graded porous nanobeams vibration in an elastic medium by considering the surface effects},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel unsupervised anomaly detection method for rotating
machinery based on memory augmented temporal convolutional autoencoder.
<em>EAAI</em>, <em>123</em>, 106312. (<a
href="https://doi.org/10.1016/j.engappai.2023.106312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the operation of rotating machinery, the occurrence of unknown fault types makes it impossible for the artificial intelligence-based fault diagnosis model to distinguish. Furthermore, due to the excessive generalization capability of the autoencoder, the unsupervised anomaly detection method based on the autoencoder is difficult to effectively distinguish normal and abnormal samples. To address the above problem, this paper proposed an unsupervised anomaly detection method based on memory augmented temporal convolutional autoencoder (MATCAE). Firstly, a novel temporal convolutional autoencoder model is constructed based on dilated causal convolution, skip connection and autoencoder to facilitate the model to learn the temporal features of the input data, thereby enhancing the model’s ability to capture the complex structure of the data. Then, a memory augmented module is designed using a memory matrix and an attention mechanism to expand the distribution interval between the reconstructed samples of normal and abnormal samples and reduce the sample capacity in the overlapping area. Finally, an anomaly detection module based on Euclidean distance, cosine distance and absolute mean square error is designed to improve the reliability of the metric between the input and reconstructed samples. To verify the effectiveness of the proposed method, experimental validation is carried out on a gearbox anomaly detection dataset. The experimental results show that the proposed method has higher anomaly detection accuracy and better noise robustness than other advanced anomaly detection methods, where the average performance metric is improved by 26.86% at the highest and 2.80% at the lowest.},
  archive      = {J_EAAI},
  author       = {Wanxiang Li and Zhiwu Shang and Jie Zhang and Maosheng Gao and Shiqi Qian},
  doi          = {10.1016/j.engappai.2023.106312},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106312},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel unsupervised anomaly detection method for rotating machinery based on memory augmented temporal convolutional autoencoder},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logistics box recognition in robotic industrial
de-palletising procedure with systematic RGB-d image processing
supported by multiple deep learning methods. <em>EAAI</em>,
<em>123</em>, 106311. (<a
href="https://doi.org/10.1016/j.engappai.2023.106311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an automated box de-palletisation system that utilises robots, vision-based box recognition on the pallet plays the main role in providing picking guidelines. The complexity of the working condition and the target object, particularly the cluttered arrangement and various outer surfaces of the boxes, significantly affect the quality of the outcome. Typically, a large-scale vision dataset is required to train a deep learning object-detection model. However, considerable effort and time is required to achieve this. Therefore, this study proposes a Mask R-CNN-based detection approach for box objects, which is supported by a cycle generative adversarial network (Cycle GAN). The purpose of the Cycle-GAN is to optimise the outer surfaces of boxes by automatically erasing tags, stickers, labels, and symbols that exist on the boxes before loading them to the Mask R-CNN for detection. Subsequently, the obtained result was combined with the output from the developed boundary-enhancing technique that was applied to a depth map. Consequently, the box detection performance was significantly improved, and it was confirmed through experiments with a practical robot system in picking tasks. In the experiments, the success rate of the proposed method was validated using 200 cases of orderly and disorderly arrangements of boxes, respectively. Furthermore, the metric of the mean absolute error between the predicted picking point and the ground truth values for the test cases in the implementation process for the robot operation was also researched.},
  archive      = {J_EAAI},
  author       = {Jonghun Yoon and Jooyeop Han and Thong Phi Nguyen},
  doi          = {10.1016/j.engappai.2023.106311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Logistics box recognition in robotic industrial de-palletising procedure with systematic RGB-D image processing supported by multiple deep learning methods},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepValve: Development and experimental testing of a
reinforcement learning control framework for occupant-centric heating in
offices. <em>EAAI</em>, <em>123</em>, 106310. (<a
href="https://doi.org/10.1016/j.engappai.2023.106310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space heating controls in offices usually follow static schedules detached from actual occupancy, which results in energy waste by unnecessarily heating vacant offices. The uniqueness of stochastic occupancy profile and thermal response time of each office are two main challenges in hard-programming a transferrable control logic that can adapt space heating schedule to the occupancy profile. This study proposes a Reinforcement Learning-based control framework (called DeepValve ) that learns by itself how to adapt the space heating schedule to the occupancy profile in each office to save energy while maintaining comfort. All the aspects of the proposed framework (design, training, hardware setup, etc.) are centered on ensuring that it can be implemented on many offices in practice. The methodology includes three main steps: training on a wide variety of simulated offices with real-world occupancy data, month-long tests on three simulated offices, and day-long experimental tests in an environmental chamber. Results indicate that the agent can quickly adapt to new offices and save energy (40% reduction in total temperature increment) while maintaining occupant comfort. The results highlight the importance of occupant-centric control in offices.},
  archive      = {J_EAAI},
  author       = {Amirreza Heidari and Dolaana Khovalyg},
  doi          = {10.1016/j.engappai.2023.106310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DeepValve: Development and experimental testing of a reinforcement learning control framework for occupant-centric heating in offices},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decoupling thermal effects in GaN photodetectors for
accurate measurement of ultraviolet intensity using deep neural network.
<em>EAAI</em>, <em>123</em>, 106309. (<a
href="https://doi.org/10.1016/j.engappai.2023.106309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise and reliable monitoring systems under various harsh conditions are important to realize an overall future automation system for diverse industries. In this study, a facile fabrication method for a gallium nitride (GaN)-based ultraviolet (UV) photodetector was developed as a system-on-chip decoupling system, and a novel decoupling system was proposed to separate the thermal effects from the GaN-based sensor using a deep neural network (DNN)-based regression model. To predict the true values of UV intensity, the currents of both UV- and thermal-responsive GaN film and thermal-responsive copper film were used as input features without additional measurement devices. In addition, the performance of the DNN regression model was evaluated using the mean absolute percentage error. Consequently, the proposed model showed a prediction accuracy of ∼ 97.86% with two input features. Furthermore, the thermal decoupling method using the proposed sensor was successfully demonstrated, even when the thermal conditions changed significantly. These results support a novel decoupling method for reliable real-time monitoring systems for various harsh environmental industries, such as aerospace, ocean, subterranean, power plants, and combustion engines.},
  archive      = {J_EAAI},
  author       = {Keuntae Baek and Sanghun Shin and Hongyun So},
  doi          = {10.1016/j.engappai.2023.106309},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106309},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Decoupling thermal effects in GaN photodetectors for accurate measurement of ultraviolet intensity using deep neural network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RoAN: A relation-oriented attention network for temporal
knowledge graph completion. <em>EAAI</em>, <em>123</em>, 106308. (<a
href="https://doi.org/10.1016/j.engappai.2023.106308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, the availability of temporal knowledge graphs (TKGs), which associate time information for each event, increased the need for completing in these TKGs. In order to solve the completion problem, the existing efforts extend static knowledge graph completion models to handle time-dependent representations, or encode the structural information of events for passing temporal message. However, the above efforts mostly construct TKGs in the form of multi-edges mesh and focus on entity features. They do not explore the power of relations for TKG completion task. In this paper, we introduce a form of relational multi-chains to reconstruct TKGs and propose a relation-oriented attention mechanism for embedding the features of relations. According to our attention mechanism, we build a Relation-oriented Attention Network (RoAN) to model temporal embeddings of relations. It is worth noting that our approach is model-agnostic and can be potentially combined with most existing TKG completion models. Experimental results show that our approach can be coupled with previous TKGC methods and can increase their performance accordingly. In addition, the analysis reveals the principle of our relation-oriented attention mechanism.},
  archive      = {J_EAAI},
  author       = {Luyi Bai and Xiangnan Ma and Xiangxi Meng and Xin Ren and Yujing Ke},
  doi          = {10.1016/j.engappai.2023.106308},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106308},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RoAN: A relation-oriented attention network for temporal knowledge graph completion},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local sensitive discriminative broad learning system for
hyperspectral image classification. <em>EAAI</em>, <em>123</em>, 106307.
(<a href="https://doi.org/10.1016/j.engappai.2023.106307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, broad learning system (BLS) has been widely used in hyperspectral image (HSI) classification with its excellent learning performance and generalization ability. However, BLS only focuses on the separability of various samples, ignoring the relative relationship between samples and the discriminative information. To some extent, it limits the performance of BLS. Therefore, we propose a local sensitive discriminative broad learning system (LSDBLS) for HSI classification. LSDBLS considers the discriminative information of labeled samples and the local manifold structure of data samples by introducing local sensitive discriminant analysis, and construct intra-class and inter-class graphs by labeled samples to representation the relative relationship between data samples. On this basis, the intra-class graph and the inter-class graph are introduced into the objective function of the broad learning system. By minimizing the intra-class graph and maximizing the inter-class graph, the samples of the same class are aggregated as much as possible, and the samples of different classes are as much as possible, so as to enhances the discriminative ability of LSDBLS for data features. Experimental results on three HSI datasets show that LSDBLS achieves good performance.},
  archive      = {J_EAAI},
  author       = {Heling Cao and Changlong Song and Yonghe Chu and Chenyang Zhao and Miaolei Deng and Guangen Liu},
  doi          = {10.1016/j.engappai.2023.106307},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106307},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Local sensitive discriminative broad learning system for hyperspectral image classification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CariesFG: A fine-grained RGB image classification framework
with attention mechanism for dental caries. <em>EAAI</em>, <em>123</em>,
106306. (<a
href="https://doi.org/10.1016/j.engappai.2023.106306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental caries is one of the most prevalent oral diseases, and deep learning methods have been used for caries diagnosis in large populations by leveraging RGB images. The existing attention-based fine-grained image classification methods have the problem of underutilization of features and easy interference by background and irrelevant information. To tackle these issues, we propose a fine-grained RGB image classification framework with attention mechanism for dental caries (CariesFG). Specifically, it consists of 4 components: (1) Multi-Spectral channel Attention Module (MSAM), which can retain the useful frequency components in the feature map. (2) Position Attention Module (PAM), which captures feature dependencies in the spatial dimension. (3) Discriminative Point Selection strategy (DPS), which can find the most discriminative feature points. (4) Graph Convolution and Aggregation module (GCA), which aims to aggregate discriminative feature points at different scales of feature maps. To enhance the ability to extract the discriminative features, PAM and MSAM are integrated into the backbone network to consist of feature extraction networks incorporating attention mechanism. Discriminative feature points at different scales of feature maps are extracted by DPS and aggregated as global discriminative features by GCA. By testing on a caries fine-grained classification dataset, CariesFG achieved an accuracy of 68.36%, an f1-score of 66.77% and a specificity of 84.17%, respectively, significantly outperforming state-of-the-art methods. Moreover, visualization results on attention parts show that CariesFG can effectively learn discriminative features and discriminative parts.},
  archive      = {J_EAAI},
  author       = {Hao Jiang and Peiliang Zhang and Chao Che and Bo Jin and Yongjun Zhu},
  doi          = {10.1016/j.engappai.2023.106306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CariesFG: A fine-grained RGB image classification framework with attention mechanism for dental caries},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthetic aperture radar image analysis based on deep
learning: A review of a decade of research. <em>EAAI</em>, <em>123</em>,
106305. (<a
href="https://doi.org/10.1016/j.engappai.2023.106305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence research in the area of computer vision teaches machines to comprehend and interpret visual data. Machines can properly recognize and classify items using digital images captured by cameras and videos, deep learning models, and then respond to what they observe. Similarly, artificial intelligence has also been able to learn complex images captured by Synthetic Aperture Radar (SAR) that are widely used for various purposes but still leave room for improvements. Researchers have proposed numerous approaches in this field, from SAR target detection to SAR target recognition. This paper presents a survey on the different techniques and architectures proposed in the literature for various SAR image applications. The paper covers a survey on target detection models and target recognition models and their respective workflow to analyze the techniques involved and the performances of these models. This paper makes novel discussions, comparisons, and observations. It highlights the advantages and disadvantages of different approaches to give researchers the idea of how each technique can influence the performance for adoption in the future. The potential future directions along with hybrid models on each processing method are also highlighted based on the study.},
  archive      = {J_EAAI},
  author       = {Alicia Passah and Samarendra Nath Sur and Ajith Abraham and Debdatta Kandar},
  doi          = {10.1016/j.engappai.2023.106305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic aperture radar image analysis based on deep learning: A review of a decade of research},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DCServCG: A data-centric service code generation using deep
learning. <em>EAAI</em>, <em>123</em>, 106304. (<a
href="https://doi.org/10.1016/j.engappai.2023.106304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern software development paradigms, including Service-Oriented Architecture (SOA), tend to make use of available services e.g., web service Application Programming Interfaces (APIs) to generate new software. Thus, for the further advancement of SOA, the development of accurate automatic tasks, such as service discovery and composition, is necessary. Most of these automated tasks rely heavily on web service metadata annotation. The lack of machine-readable documentation and structured metadata reduces the accuracy and volume of automatic data annotation, negatively affecting the performance of automated SOA tasks. This study aims to propose automatic code completion for improving web service-based systems by identifying and capturing service usage collected from public repositories that share Open Source Software (OSS). To this end, a Data-Centric Service Code Generation ( DCServCG ) model is proposed to improve old-fashioned, general-purpose code generators that neglect essential service-based code characteristics e.g., sequence overlap and bias issues. DCServCG takes advantage of the data-centric concept, i.e., conditional text generation, to overcome the mentioned issues. We have evaluated the approach from the point of view of language modeling metrics. The obtained results indicate that the usage of the data-centric approach reduces perplexity by 1.125. Moreover, the DCServCG model uses de-noising and conditional text generation, which is trained on the transformer by distilling the knowledge, DistilGPT2 (82M parameters) trained faster and its perplexity is 0.363 lower than ServCG (124M parameters) without de-noising and conditional text generation, which lower perplexity value indicates better model generalization performance.},
  archive      = {J_EAAI},
  author       = {Zakieh Alizadehsani and Hadi Ghaemi and Amin Shahraki and Alfonso Gonzalez-Briones and Juan M. Corchado},
  doi          = {10.1016/j.engappai.2023.106304},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106304},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DCServCG: A data-centric service code generation using deep learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time consideration in machine learning models for train
comfort prediction using LSTM networks. <em>EAAI</em>, <em>123</em>,
106303. (<a
href="https://doi.org/10.1016/j.engappai.2023.106303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety and passengers’ comfort affect directly the reliability and availability of trains. Therefore, appropriate monitoring of the variables influencing those two concepts is mandatory for good operation and maintenance costs reduction. Moreover, operators and rail manufacturers are evolving to a condition-based maintenance strategy (CBM). For this purpose, machine learning is being used to predict early main component’s failures, avoiding a loss of reliability or availability during commercial operation. From the passengers’ point of view, punctuality and comfortability are two of the most relevant factors when evaluating a railway transport service. Comfort is mainly based on the availability of all services in the train, but it is also related to the accelerations received through the car body to the passengers. More precisely, the lateral car body acceleration (Ayc variable in this paper) is a key variable related to comfort perception and it is therefore important to be monitored and controlled. Rolling, suspension, and damping elements must be kept in perfect conditions during operation to achieve a smooth train movement. In this paper, an optimized model based on Long Short Term Memory networks (LSTM) is designed and trained to predict lateral car body accelerations using only the train accelerometers and with no additional sensoring for this specific experiment. This model will be compared with artificial neural networks (ANN) models to evaluate the relevance of time dependency for this purpose. The optimal time frame to group data is a key characteristic of the neural network training process and is also determined in this paper. The model is trained with data corresponding to the correct dynamic behavior of the train. To test the reliability of this method, a real case of excessive train movement is tested. In these situations, an alert could be sent to the operator or the maintainer for a not-programmed maintenance inspection at the depot (predictive maintenance), avoiding future passenger complaints for the loss of comfort or, in extreme cases, speed limitations due to safety reasons for excessive accelerations. The main contributions of this work are the following: - A LSTM-based neural network, predicting lateral car body accelerations achieving better results than a plain ANN for this dataset: 0.0335 m/s 2 MAE and a 12% gain on extreme axles. - An optimization of the time frame to group the measurements in this algorithm that is considering as an input the time variable: 5 s. - A real use case of the model in which monitoring the deviation would have helped to take an early maintenance adjustment on the suspension or damping elements to prevent the loss of comfort. - The p-value used to reduce the uncertainty of the results obtained in the real use case is reaching over 0.95 in the coaches with good dynamic behavior and less than 0.15 in the coaches where a dynamic problem related to comfort loss is detected.},
  archive      = {J_EAAI},
  author       = {Pablo Garrido Martínez-Llop and Juan de Dios Sanz Bobi and Manuel Olmedo Ortega},
  doi          = {10.1016/j.engappai.2023.106303},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106303},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time consideration in machine learning models for train comfort prediction using LSTM networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drill-rep: Repetition counting for automatic shot hole depth
recognition based on combined deep learning-based model. <em>EAAI</em>,
<em>123</em>, 106302. (<a
href="https://doi.org/10.1016/j.engappai.2023.106302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problems of low efficiency and dependability of human experience in shot hole depth recognition by manual interpretation of the massive drilling videos, this paper proposed a repetition counting framework from the perspective of representation object motion, and firstly studied and realized the automatic shot hole depth recognition by adopting the proposed framework by combining multiple deep learning-based models. Firstly, the periodic motion characteristics of the objects in the drilling video were analyzed, and the motion extraction model of the representative object was established based on YOLOv5 and Deep SORT algorithm to obtain the spatiotemporal sequence. Then, the sequence noise and redundant information were filtered according to the spatiotemporal relationship between the drill pipes and workers, to obtain a coherent, smooth, and clean motion sequence. On this basis, a drill pipe motion counting model was established by using the YOLOv5 network to detect the temporal boundary and repetition number of the drill pipe motion. Finally, combined with the pipe motion extraction model and counting model, the comprehensive reliable recognition method of shot hole depth was presented. The shot hole depth recognition trial was carried out on 1029 drilling videos from the Bureau of Geophysical Prospecting INC. The proposed method achieved 90.5% recognition accuracy (Acc) and 0.027 mean absolute error (MAE) with 64 frames per second (FPS) and 0.39 average recognition time ratio (R t ). Therefore, the proposed repetition counting framework solved the problem of efficient and intelligent drilling depth recognition of massive drilling videos and thus provided a new idea for repetition counting.},
  archive      = {J_EAAI},
  author       = {Yongcan Yu and Jianhu Zhao and Changhua Yi and Xinyu Zhang and Chao Huang and Weiqiang Zhu},
  doi          = {10.1016/j.engappai.2023.106302},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106302},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Drill-rep: Repetition counting for automatic shot hole depth recognition based on combined deep learning-based model},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analytical and deep learning approaches for solving the
inverse kinematic problem of a high degrees of freedom robotic arm.
<em>EAAI</em>, <em>123</em>, 106301. (<a
href="https://doi.org/10.1016/j.engappai.2023.106301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse kinematics is the basis for controlling the motion of robotic manipulators. It defines the required joint variables for the robotic end-effector accurately reach the desired location. Due to the derivation difficulty, computation complexity, singularity problem, and redundancy, analytical Inverse kinematics solutions pose numerous challenges to the operation of many robotic arms, especially for a manipulator with a high degree of freedom. This paper develops different Deep Learning networks for solving the Inverse kinematics problem of six- Degrees of Freedom robotic manipulators. The implemented neural architectures are Artificial Neural Network, Convolutional Neural Network, Long–Short Term Memory, Gated Recurrent Unit, and Bidirectional Long–Short Term Memory. In this context, we associate the proposed results with a specific tuning of Deep Learning network hyper-parameters (number of hidden layers, learning rate, Loss function, optimization algorithm, number of epochs, etc.). The Bidirectional Long–Short Term Memory network outperformed all proposed architectures. To be close as possible to the experimental results, we have included two types of noise in the training data set to validate which of the five proposed neural networks is more efficient. Furthermore, in this study, we compare the performance of analytical and soft computing solutions in generating robots’ trajectories. We include this scenario, focusing on the advantage of implementing neural networks in avoiding the singularity problem that can occur using the analytical approach. In addition, we used the RoboDK simulator to show simulation results with real-world meaning. The performance of Deep Learning models depends on the complexity of the posed problem. Moreover, the complexity of the Inverse Kinematics problem is related to the number of Degrees of Freedom. At the end of this work, we evaluate the influence of the complexity of robotic manipulators on the proposed Deep Learning networks’ performance. The results show that the implemented Deep Learning mechanisms performed well in reaching the desired pose of the end-effector. The proposed inverse kinematics strategies apply to other manipulators with different numbers of Degrees of Freedom.},
  archive      = {J_EAAI},
  author       = {Nesrine Wagaa and Hichem Kallel and Nédra Mellouli},
  doi          = {10.1016/j.engappai.2023.106301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analytical and deep learning approaches for solving the inverse kinematic problem of a high degrees of freedom robotic arm},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-GNAS: Meta-reinforcement learning for graph neural
architecture search. <em>EAAI</em>, <em>123</em>, 106300. (<a
href="https://doi.org/10.1016/j.engappai.2023.106300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural architecture search (GNAS) has shown great success in designing many prominent models on non-Euclidean data. However, the existing GNAS methods need to search from scratch on new tasks, which is time-consuming and inefficient in real application scenarios. In this paper, we propose a meta-reinforcement learning method for Graph Neural Architecture Search (Meta-GNAS) to improve the learning efficiency on new tasks by leveraging the knowledge learned from previous tasks. As far as we know, it is the first work that applies meta-learning to GNAS tasks. Moreover, to further improve the efficiency in tackling a new task, we use a predictive model to evaluate the accuracy of sampled graph neural architecture, instead of training it from scratch. The experiment results demonstrate that the architecture designed by Meta-GNAS outperforms the state-of-art manually designed architectures, and the search speed is faster than other search methods, with an average search time of fewer than 210 GPU seconds on 6 datasets.},
  archive      = {J_EAAI},
  author       = {YuFei Li and Jia Wu and TianJin Deng},
  doi          = {10.1016/j.engappai.2023.106300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Meta-GNAS: Meta-reinforcement learning for graph neural architecture search},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the trade-off between performance and annotation
complexity in semantic segmentation. <em>EAAI</em>, <em>123</em>,
106299. (<a
href="https://doi.org/10.1016/j.engappai.2023.106299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image semantic segmentation, a fundamental computer vision task, performs the pixel-wise classification of an image seeking to group pixels that share some semantic content. One of the main issues in semantic segmentation is the creation of fully annotated datasets where each image has one label per pixel. These annotations are highly time-consuming and, the more the labelling increases, the higher the percentage of human-entered errors grows. Segmentation methods based on less supervision can reduce both labelling time and noisy labels. However, when dealing with real-world applications, it is far from trivial to establish a method that minimizes labelling time while maximizing performance. Our main contribution is to present the first comprehensive study of state-of-the-art methods based on different levels of supervision. Image processing baselines, unsupervised, weakly supervised and supervised approaches have been evaluated. We aim to guide anyone approaching a new real-world use case by providing a trade-off between performance and supervision complexity on datasets from different domains, such as street scenes (Camvid), microscopy (MetalDAM), satellite (FloodNet) and medical images (NuCLS). Our experimental results suggest that: (i) unsupervised and weak learning perform well on majority classes, which helps to speed up labelling; (ii) weakly supervised can outperform fully supervised methods on minority classes; (iii) not all weak learning methods are robust to the nature of the dataset, especially those based on image-level annotations; and (iv) among all weakly supervised methods, point-based are the best-performing ones, even competing with fully supervised methods. The code is available at https://github.com/martafdezmAM/lessen_supervision .},
  archive      = {J_EAAI},
  author       = {Marta Fernández-Moreno and Bo Lei and Elizabeth A. Holm and Pablo Mesejo and Raúl Moreno},
  doi          = {10.1016/j.engappai.2023.106299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring the trade-off between performance and annotation complexity in semantic segmentation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time series classification based on convolutional network
with a gated linear units kernel. <em>EAAI</em>, <em>123</em>, 106296.
(<a href="https://doi.org/10.1016/j.engappai.2023.106296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data are ubiquitous in human society and nature, and classification is one of the most significant problems in the field of time series mining. Although it has been intensively studied, and has achieved significant results and successful applications, it is still a challenging problem, which requires capturing of multi-scale features of one-dimensional or multi-dimensional time series in variable length. In this paper, we propose a novel time series feature extraction block named Convolutional Gated Linear Units (CGLU), which is a combination of convolutional operations and Gated Linear Units for adaptively extracting local temporal features of time series. Combined with a temporal maxpooling block, it can extract global temporal features. To capture more diverse features, the Inception architecture is adopted to organize the CGLUs with different convolution kernel sizes, which result in the Convolutional GLU network. In order to evaluate the performance, we conduct extensive experiments on the UCR time series datasets (one-dimension) and UEA datasets (multi-dimension). Compared with baselines, our model obtains best results in terms of classification accuracy and training speed, which demonstrate effectiveness and efficiency of CGLUs and Conv-GLU network on time series classification tasks.},
  archive      = {J_EAAI},
  author       = {Chen Liu and Juntao Zhen and Wei Shan},
  doi          = {10.1016/j.engappai.2023.106296},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106296},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time series classification based on convolutional network with a gated linear units kernel},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Development of a deep learning platform for sheet stamping
geometry optimisation under manufacturing constraints. <em>EAAI</em>,
<em>123</em>, 106295. (<a
href="https://doi.org/10.1016/j.engappai.2023.106295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sheet stamping is a widely adopted manufacturing technique for producing complex structural components with high stiffness-to-weight ratios. However, designing such components is a non-trivial task that requires careful consideration of manufacturing constraints to avoid introducing defects in the final product. To address this challenge, this research introduces a novel deep-learning-based platform that optimises 3D component designs by considering manufacturing capabilities. This platform was realised by developing a methodology to combine two neural networks that handle non-parametric geometry representations, namely a geometry generator based on Signed Distance Fields (SDFs) and an image-based manufacturability surrogate model. This combination enables the optimisation of complex geometries that can be represented using various parameterisation schemes. The optimisation approach implemented in the platform utilises gradient-based techniques to update the inputs to the geometry generator based on manufacturability information from the surrogate model. The platform is demonstrated using two geometry classes, Corners and Bulkheads, each having three geometry subclasses, with four diverse case studies conducted to optimise these geometries under post-stamped thinning constraints. The case studies demonstrate how the platform enables free morphing of complex geometries, while also guiding manufacturability-driven geometric changes in a direction that leads to significant improvements in component quality. For instance, one of the cases shows that optimising the complex component geometry can reduce the maximum thinning from 45% to satisfy the thinning constraint of 10%. By utilising the proposed platform, designers can identify optimal component geometries that ensure manufacturing feasibility for sheet stamping, reducing design development time and design costs.},
  archive      = {J_EAAI},
  author       = {Hamid Reza Attar and Alistair Foster and Nan Li},
  doi          = {10.1016/j.engappai.2023.106295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of a deep learning platform for sheet stamping geometry optimisation under manufacturing constraints},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantitative land price analysis via computer vision from
street view images. <em>EAAI</em>, <em>123</em>, 106294. (<a
href="https://doi.org/10.1016/j.engappai.2023.106294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land price is an important economic factor in producing meaningful references for regional planners by assisting them in urban planning, economic decision-making, and land resource allocation. However, related studies in land price analysis were mainly focused on the factors of site area and plot ratio, analysis of the potential impact of streetscape factors and human subjective perception on the land price has been lacking, regardless of the impact on supply and demand relationship. Therefore, this study developed a new approach for estimating and analyzing land prices through deep learning that considered the streetscape and human subjective perception factors. In the estimation part, we developed a fine-grained end-to-end deep learning model, the input is street view images, and the output is land prices. In the analysis part, we extracted the semantic segmentation results and human subjective perception scores from the images and combined them with the results of land price estimation. We then introduced a combination of quantitative analysis using the gradient-weighted class activation mapping and L1-based sparse linear regression to model the relationship between the streetscape and the human subjective perception quantitatively. The gradient-weighted class activation mapping was used to determine which categories of pixels deep learning relied on to output the results of land price estimation quantitatively. Combined with segmentation results, we implemented L1-based sparse linear regression and quantitatively determined the importance of the streetscape factors for land prices. Overall, our deep learning model achieved 77.99 % accuracy by only using street views in estimating the land price, and we illustrated the impacts of the streetscape and perception on the land price by showing that perception scores are more important than streetscape factors such as road and mountain in the streetscape. Comfortable, lived-in feel in perception have the most important impact on land price estimation.},
  archive      = {J_EAAI},
  author       = {Chenbo Zhao and Yoshiki Ogawa and Shenglong Chen and Takuya Oki and Yoshihide Sekimoto},
  doi          = {10.1016/j.engappai.2023.106294},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106294},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantitative land price analysis via computer vision from street view images},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GA-ABC hybridization for profit maximization of green 4DTSPs
with discrete and continuous variables. <em>EAAI</em>, <em>123</em>,
106293. (<a
href="https://doi.org/10.1016/j.engappai.2023.106293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A medical or business representative visits and spends some time (termed ‘stay time’) at different cities(nodes) for optimum return. With the rapid development of infrastructures worldwide, several vehicles and routes are available for transport between nodes. Road logistic transportation contributes 10.5% of the total emitted carbon emission (CE) 1 , 2 , 3 . Heuristic method is applied to solve NP-hard problems with continuous/discrete variables. With these facts, here, CE/tour-time constrained profit maximization of green four-dimensional Travelling Salesman Problems (PMG4DTSPs) with both discrete (travel times between nodes) and continuous (stay-times at nodes) variables are formulated. A travelling salesman visits all cities using the appropriate routes and conveyances, spend some time at each node, and some revenues are earned and spent depending upon the stay time at those visiting places. There are toll plazas on the roads, where three types of fixed charges (online, offline, mixed online–offline) are collected as road taxes to maintain the roads. A green constraint is incorporated in the form of limited emission. Several connecting routes between the cities and conveyances at each city are available for travel. Thus, these (PMG4DTSPs) are mixed integer linear programming problems (NP-hard), and to solve them, two hybrid heuristic methods, GA-ABC and GA-PSO, are developed and used. Here, GA and ABC/PSO are used for optimum routing plan and stay time, respectively. The models are illustrated numerically. Multi-path justification, online payment advantage and tour time limitation effect on profit are presented. Some behavioural studies of Green models and managerial decisions are presented.},
  archive      = {J_EAAI},
  author       = {Shovan Roy and Aditi Khanra and Samir Maity and Rajat Kumar Pal and Manoranjan Maiti},
  doi          = {10.1016/j.engappai.2023.106293},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106293},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GA-ABC hybridization for profit maximization of green 4DTSPs with discrete and continuous variables},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving the performance of automatic short answer grading
using transfer learning and augmentation. <em>EAAI</em>, <em>123</em>,
106292. (<a
href="https://doi.org/10.1016/j.engappai.2023.106292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of grading answers ranging from one phrase to one paragraph using computational techniques is known as Automated Short Answer Grading (ASAG). The performance of existing systems is not good enough due to limited data and the lack of availability of data in many domains. Many ASAG systems were developed as an outcome of the active research in this field. This study builds an effective system for grading short answers in the programming domain by leveraging Pre-trained Language Models and Text Augmentation. We fine-tuned three-sentence transformer models on the SPRAG corpus with five different augmentation techniques: viz., Random Deletion, Synonym Replacement, Random Swap, Backtranslation, and NLPAug. The SPRAG corpus contains student responses involving keywords and special symbols. We experimented with four different data sizes with the augmented data to determine the impact of training data on the fine-tuned sentence transformer model. this paper provides an exhaustive analysis of fine-tuning pretrained sentence transformer models with varying sizes of data by applying text augmentation techniques. we found that applying random swap and synonym replacement techniques together while fine-tuning has given a significant improvement, With a 4.91% increase in accuracy and a 3.36% increase in the F1-score. All the trained models are publicly available 1 .},
  archive      = {J_EAAI},
  author       = {Sridevi Bonthu and S. Rama Sree and M.H.M. Krishna Prasad},
  doi          = {10.1016/j.engappai.2023.106292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving the performance of automatic short answer grading using transfer learning and augmentation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trajectory planning based on spatio-temporal reachable set
considering dynamic probabilistic risk. <em>EAAI</em>, <em>123</em>,
106291. (<a
href="https://doi.org/10.1016/j.engappai.2023.106291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory planning in complex traffic situations has always been a challenging task for intelligent vehicles. Comparing to the decoupling method, the spatio-temporal trajectory planning method owns more flexibility and reasonability due to the combination of lateral and longitudinal motion. However, it still has some shortcomings, such as unreasonable risk assessment, high computational complexity and heavy dependence on other models for generating target points. Therefore, a novel spatio-temporal based trajectory planning framework considering probability risk is proposed in this paper. Firstly, a GNN-LSTM based on trajectory prediction algorithm is presented in terms of risk analysis, and particularly the predicted trajectories and the vehicle dynamic model are combined for risk assessment. Secondly, a rough-fine hierarchical planning framework based on reachable set and dynamic programming is proposed. In this framework, the reachable set is taken as spatio-temporal node to reduce the computational costs and dynamic programming can help the algorithm to eliminate the dependence of other models in evaluating target points. Finally, a traffic scenario with random interactive obstacles is built and tested on a HIL platform. The experimental results show that compared with other typical algorithms, the average driving efficiency, driving risk behavior and driving comfort of the vehicle are significantly improved.},
  archive      = {J_EAAI},
  author       = {Xinkang Zhang and Bo Yang and Xiaofei Pei and Songxin Lu},
  doi          = {10.1016/j.engappai.2023.106291},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106291},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trajectory planning based on spatio-temporal reachable set considering dynamic probabilistic risk},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph neural networks and implicit neural representation for
near-optimal topology prediction over irregular design domains.
<em>EAAI</em>, <em>123</em>, 106284. (<a
href="https://doi.org/10.1016/j.engappai.2023.106284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a deep neural network-based topology optimization acceleration method for irregular design domains that predicts (near-)optimal topologies. A topology optimization problem is a complex non-Euclidean data, which can be embedded in a graph form, and a graph neural network encodes it to Euclidean data such as vectors and matrices. The encoded information is applied to a multi-layer perceptron-based implicit neural representation model, and the multi-layer perceptron approximator predicts the compliance optimal material distribution. The prediction performance of the proposed encoder-approximator architecture is evaluated for several topology optimization problems. The trained network provides 96.6% compliance accuracy, except for 8.0% of the outliers. The two criteria have been investigated to estimate potential outliers, and post-optimization can resolve the outlier within fewer iterations than the original optimization.},
  archive      = {J_EAAI},
  author       = {Minsik Seo and Seungjae Min},
  doi          = {10.1016/j.engappai.2023.106284},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106284},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural networks and implicit neural representation for near-optimal topology prediction over irregular design domains},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). No-reference image quality assessment of magnetic resonance
images with multi-level and multi-model representations based on fusion
of deep architectures. <em>EAAI</em>, <em>123</em>, 106283. (<a
href="https://doi.org/10.1016/j.engappai.2023.106283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate quality assessment of Magnetic Resonance (MR) images is essential for effective medical diagnostics, as it impacts the time spent on image acquisition and image interpretation by radiologists. Therefore, this study aims to provide a novel deep learning-based No-Reference (NR) MR Image Quality Assessment (IQA) method for the quality prediction of MR images. Therefore, in this work, an internal fusion of two complementary deep learning architectures is introduced that offers MR-specific quality-aware features. Apart from obtaining multi-level image representations of joint networks, to further enhance the quality prediction performance, features from re-trained single deep learning architectures are also used. Finally, as one of the main findings of this study, the quality assessment is performed by a high-level quality model trained on scores of quality models obtained for layers of the networks. The superiority of the method against the state-of-the-art techniques is verified by using two publicly available MRIQA benchmarks containing MR images and subjective scores provided by a large number of radiologists. As reported, the method offers superior IQA of MR images as the obtained scores are highly correlated with subjective opinions of medical specialists. It is characterized by the weighted average values of the Spearman Rank-order Correlation Coefficient, Kendall Rank-order Correlation Coefficient, and Pearson Linear Correlation Coefficient of 0.8754, 0.7185, and 0.9062, respectively.},
  archive      = {J_EAAI},
  author       = {Igor Stępień and Mariusz Oszust},
  doi          = {10.1016/j.engappai.2023.106283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {No-reference image quality assessment of magnetic resonance images with multi-level and multi-model representations based on fusion of deep architectures},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal and multi-product hierarchical hub location
problem with fuzzy demands. <em>EAAI</em>, <em>123</em>, 106282. (<a
href="https://doi.org/10.1016/j.engappai.2023.106282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hub location is a major problem in the systems with high dependence on the transportation of goods, information, and passengers between the constituent parts. The present study is aimed to introduce a multi-commodity multi-model hierarchical hub location problem with uncertain demand. Thus, it is estimated by intuitionistic fuzzy variables. The objective function in the present problem is to minimize the total transportation costs in the network to determine the optimal hub location, allocate non-hub nodes to the hubs and the ground hubs to the air hubs, and identify the type of vehicles required in each route. The model has a hierarchical structure consisting of a three-echelon network (i.e., central hubs, non-central hubs, and demand nodes) connected in the star-tour-star form. A four-index mathematical model was presented and solved by GAMS optimization software. The results indicated that the objective function (cost) has a descending trend with increasing the number of hubs which can be assigned to the decline in the transportation costs. The costs increased by a decrease in the maximum delivery time which could be due to the selection method of the transportation mode. In the multi-product case, the costs declined by increasing the number of hubs as these hubs decremented the network complexity. Regarding the NP-Hard nature of the hub problems, a genetic meta-heuristic algorithm was proposed in the MATLAB software to solve the large-scale problem. According to the results, this algorithm offered close-optimal solutions. Noteworthy, this study employed known AP datasets.},
  archive      = {J_EAAI},
  author       = {Alireza Eydi and Pardis Shirinbayan},
  doi          = {10.1016/j.engappai.2023.106282},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106282},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modal and multi-product hierarchical hub location problem with fuzzy demands},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning compensated coordination control of
multiple mobile manipulators for tight cooperation. <em>EAAI</em>,
<em>123</em>, 106281. (<a
href="https://doi.org/10.1016/j.engappai.2023.106281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a coordinated control method based on reinforcement learning for multiple mobile manipulators when strong constraints and close coupling are involved in the tightly cooperative tasks. The reinforcement learning strategy is specifically designed to deal with the unknown vibrations between the mobile manipulators and the common object. Firstly, the problem is converted into a Markov decision process. Next, the grasping forces of the end-effectors are regarded as the parameters to be optimized, and the system states and learning framework are described based on advantage actor–critic algorithm. Thirdly, an agent is trained through interacting with the environment based on a proposed reward policy. To eliminate joint dynamic errors caused by trajectories tracking, an adaptive controller is designed for each mobile manipulator. For the simulations and experiments, two mobile manipulators are employed for transporting a common plate under various conditions. The results demonstrate that the proposed method has better control effects than well-known controllers. This study combines the advantages of both reinforcement learning and model-based method via a coordinated controller designed with the characteristics of tight cooperation.},
  archive      = {J_EAAI},
  author       = {Pengjie Xu and Yuanzhe Cui and Yichao Shen and Wei Zhu and Yiheng Zhang and Bingzheng Wang and Qirong Tang},
  doi          = {10.1016/j.engappai.2023.106281},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106281},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning compensated coordination control of multiple mobile manipulators for tight cooperation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A particle swarm inspired approach for continuous
distributed constraint optimization problems. <em>EAAI</em>,
<em>123</em>, 106280. (<a
href="https://doi.org/10.1016/j.engappai.2023.106280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed Constraint Optimization Problems (DCOPs) are a widely studied framework for coordinating interactions in cooperative multi-agent systems. In classical DCOPs, variables owned by agents are assumed to be discrete. However, in many applications, such as target tracking or sleep scheduling in sensor networks, continuous-valued variables are more suitable than discrete ones. To better model such applications, researchers have proposed Continuous DCOPs (C-DCOPs), an extension of DCOPs, that can explicitly model problems with continuous variables. The state-of-the-art approaches for solving C-DCOPs experience either onerous memory or computation overhead and are unsuitable for non-differentiable optimization problems. To address this issue, we propose a new C-DCOP algorithm, namely Particle Swarm Optimization Based C-DCOP (PCD), which is inspired by Particle Swarm Optimization (PSO), a well-known centralized population-based approach for solving continuous optimization problems. In recent years, population-based algorithms have gained significant attention in classical DCOPs due to their ability in producing high-quality solutions. Nonetheless, to the best of our knowledge, this class of algorithms has not been utilized to solve C-DCOPs and there has been no work evaluating the potential of PSO in solving classical DCOPs or C-DCOPs. In light of this observation, we adapted PSO, a centralized algorithm, to solve C-DCOPs in a decentralized manner. The resulting PCD algorithm not only produces good-quality solutions but also finds solution without any requirement for derivative calculations. Moreover, we design a crossover operator that can be used by PCD to further improve the quality of solutions found. Finally, we theoretically prove that PCD is an anytime algorithm and empirically evaluate PCD against the state-of-the-art C-DCOP algorithms in a wide variety of benchmarks.},
  archive      = {J_EAAI},
  author       = {Moumita Choudhury and Amit Sarker and Samin Yaser and Md. Maruf Al Alif Khan and William Yeoh and Md. Mosaddek Khan},
  doi          = {10.1016/j.engappai.2023.106280},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106280},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A particle swarm inspired approach for continuous distributed constraint optimization problems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of machine learning models for the prediction of
binary diffusion coefficients of gases. <em>EAAI</em>, <em>123</em>,
106279. (<a
href="https://doi.org/10.1016/j.engappai.2023.106279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion coefficient (D 12 ) is an important transport property in the petrochemical and pharmaceutical industries for the design and optimization of processes. The process of measuring the D 12 for gas mixtures via an experimental approach is time-consuming and technically challenging. Consequently, many empirical models have been developed to circumvent these challenges. Though these models exhibit good agreement with the experiment, nonetheless, improvement is still needed in terms of increasing the model performance, and the flexibility of their applications because some of these models require extensive calculations to obtain their input parameters. Motivated by this, the work presents a simple and accurate approach for the estimation of diffusion coefficient using machine learning (ML) algorithms. This study employs support vector regression (SVR), Gaussian process regression (GPR), and artificial neural networks (ANN) to estimate the D 12 of molecular gas systems over a wide range of temperature (293- 313K), and pressure (0.05–12.0 MPa). The proposed ML models were built using simple descriptors such as temperature, pressure, molar masses of constituent mixtures, and mole fractions of the gases. On the testing dataset, the following overall correlation coefficients were obtained 90.7 %, 99.1 %, and 99.97 % percent for the SVR, GPR, and ANN, respectively. The ANN model did better than the other ML algorithms presented in terms of its generalization capability. The authors believe that the ANN model presented is a viable alternative for the evaluation of the binary diffusion coefficient of gases due to the simplicity of the descriptors.},
  archive      = {J_EAAI},
  author       = {Ismail Adewale Olumegbon and Ibrahim Olanrewaju Alade and Mojeed Opeyemi Oyedeji and Talal F. Qahtan and Aliyu Bagudu},
  doi          = {10.1016/j.engappai.2023.106279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of machine learning models for the prediction of binary diffusion coefficients of gases},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Possibilistic simulation based interactive fuzzy MAGDM under
discrimination q-rung picture linguistic information. Application in
educational programs efficiency evaluation. <em>EAAI</em>, <em>123</em>,
106278. (<a
href="https://doi.org/10.1016/j.engappai.2023.106278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In certain Multi-Attribute Group Decision-Making (MAGDM) approaches an aggregation of decision-making matrices of experts’ evaluations/ratings of possible alternatives by their attributes into an etalon decision-making matrix is an important task. Based on possible great experience and deep knowledge of the subject, the expert tries to dominate other experts in the decision-making process. Besides, every expert has a possibility of a certain degree to influence on the decision-making process. In such cases experts’ evaluations aggregation into an etalon matrix by the additive or linear aggregation instruments is unacceptable. We present a new two-stage MAGDM approach to solve this task. On the first stage: In the evidence theory environment the connection between experts’ pair interaction indexes and possibility levels of their influence on decision-making process is constructed. For this, a Monte-Carlo simulation algorithm is created, the result of which is the estimated class of associated probabilities of the possibility distribution. Experts’ evaluations in decision-making matrixes are represented by the q-rung orthopair fuzzy numbers (q-ROFNs). Before aggregation of experts’ data into an etalon decision-making matrix, evaluations are transformed into discrimination q-rung picture linguistic numbers (q-RPLNs). New definitions are introduced for the Score and Accuracy functions of the q-rung picture linguistic numbers. q-rung picture linguistic numbers contain as well quantitative as qualificative information on experts’ reflections on objects, while discrimination q-rung picture linguistic numbers describe interactive phenomena between arguments. Based on constructed possibility distribution on the experts’ group, the ordered weighted averaging (OWA) and Choquet averaging (CA) aggregation operators under q-rung picture linguistic environment are extended (q-RPLOWA and q-RPLCA, respectively). By the q-RPLOWA and q-RPLCA operators decision-making matrices of experts’ evaluations/ratings are condensed into an etalon decision-making matrix. On the second stage: The concept of Euclidean distance and the entropy of De Luca–Termini are defined for q-rung picture linguistic set. The new relative closeness parameter for the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) approach under q-rung picture linguistic information is also defined. The technique for the TOPSIS approach for the ranking of possible alternatives in MAGDM by aggregating discrimination q-rung picture linguistic data of etalon matrix is developed. For illustration of the obtained results, Educational Programs Efficiency Evaluation problem is considered. Our constructed MAGDM approach complies with the principle of expertise in educational programs evaluation commission. The numerical results obtained for the q-RPLNs environment and the ranking of alternatives are compared with the numerical results and the ranking of alternatives obtained by the same approach for the initial expert data in q-ROFNs environment. A comparison with the results obtained by other existing methods is given.},
  archive      = {J_EAAI},
  author       = {Gia Sirbiladze and Janusz Kacprzyk and Bidzina Midodashvili and Manana Khachidze and Levan Midodashvili and Irakly Parshutkin},
  doi          = {10.1016/j.engappai.2023.106278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Possibilistic simulation based interactive fuzzy MAGDM under discrimination q-rung picture linguistic information. application in educational programs efficiency evaluation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A parallel approach for user-centered QoS-aware services
composition in the internet of things. <em>EAAI</em>, <em>123</em>,
106277. (<a
href="https://doi.org/10.1016/j.engappai.2023.106277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) refers to an infrastructure of interconnected smart devices that aim to provide various services. The proliferation of IoT objects and devices offering functionally equivalent services but differing in their quality of service (QoS) levels makes the issue of services composition one of the biggest challenges for the service computing community. Various evolutionary-based approaches have been proposed in the literature to find sub-optimal service compositions in a reasonable computation time. However, most of these approaches have high composition time and/or a limited composition quality as they rely on a sequential exploration of the composition search space using a fixed size population. To address these limitations, a parallel differential evolution-based approach with population size reduction for QoS-aware service composition (PDE-QSC) is proposed in this paper. Unlike existing evolutionary-based approaches, the proposed approach is characterized by a parallel exploration of the composition space through a population size reduction strategy. Specifically, in this approach, the composition population is divided into two sub-populations. To reduce the composition time and improve the quality of the composition, the composition sub-populations evolve simultaneously using different evolution processes and are then merged to form a single population, thus increasing the population diversity. To further improve the performance in terms of composition time and composition quality, a linear reduction strategy is proposed to adaptively reduce the size of the composition population by eliminating compositions that do not meet the QoS requirements. Simulations based on real datasets demonstrate the superiority of the PDE-QSC approach over five baseline approaches and its suitability for large-scale IoT environments.},
  archive      = {J_EAAI},
  author       = {Asma Cherifi and Mohamed Essaid Khanouche and Yacine Amirat and Zoubeyr Farah},
  doi          = {10.1016/j.engappai.2023.106277},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106277},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A parallel approach for user-centered QoS-aware services composition in the internet of things},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning for automatic tumor lesions delineation and
prognostic assessment in multi-modality PET/CT: A prospective survey.
<em>EAAI</em>, <em>123</em>, 106276. (<a
href="https://doi.org/10.1016/j.engappai.2023.106276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tumor lesion segmentation and staging in cancer patients are one of the most challenging tasks for radiologists to recommend better treatment planning like radiation therapy, personalized medicine, and surgery. Recently, Deep Learning (DL) has emerged as an assistive technology to help radiologists to characterize the biology of tumors and manage cancer patients. Positron Emission Tomography/Computed Tomography (PET/CT) multi-modality image-based tumor segmentation has gained tremendous attraction. However, the fusion of PET and CT information exposes numerous serious challenges including intra-class variability, contrast issues, modality discrepancy (difference in shape, and size of tumor), and the blurred boundaries between tumor and normal tissues (low specificity). To address these challenges, various DL-based tumor auto-segmentation methods have been proposed to consider complementary and contradictory anatomical and functional information of multi-modality PET/CT. This survey paper provides an in-depth exploration of these auto-segmentation methods. First, we discuss PET, CT weaknesses, the need for PET/CT, and the challenge of multi-modality PET/CT images. Second, we provide a detailed discussion of the parameters used to evaluate the achievements and limitations of the reviewed methods. Third, we classify the existing solutions into three major groups based on the model architecture design such as single network, multiple networks, and hybrid network models. The multiple networks are further divided into ensembles, multi-task, and Generative Adversarial Network (GAN) models. Furthermore, we present a discussion on these solutions to improve segmentation performance along with their strengths and weaknesses. Finally, we present a discussion on open research challenges and recommend potential future directions.},
  archive      = {J_EAAI},
  author       = {Muhammad Zubair Islam and Rizwan Ali Naqvi and Amir Haider and Hyung Seok Kim},
  doi          = {10.1016/j.engappai.2023.106276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning for automatic tumor lesions delineation and prognostic assessment in multi-modality PET/CT: A prospective survey},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Plan commitment: Replanning versus plan repair.
<em>EAAI</em>, <em>123</em>, 106275. (<a
href="https://doi.org/10.1016/j.engappai.2023.106275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While executing its plan in a dynamic environment where multiple agents are operating, an autonomous agent may suffer a failure due to discrepancies between the expected and actual context and thus must replace its obsolete plan. In its endeavour to fix the failure and reach its original goals, the agent may unknowingly disrupt other agents executing their plans in the same environment. We present a property for plan repair called plan commitment to ensure a responsible repair policy among agents that aims to minimise the negative impact on others. We present arguments to support the claim that plan commitment is a valuable property when an agent may have made bookings and commitments to others. We then propose C-TFLAP , an implementation of a plan repair heuristic that allows adapting a failed plan to the new context while committing as much as possible to the original plan. We demonstrate empirically that: (1) our plan repair achieves more committed plans than plan-stability repair when an agent has made bookings and commitments to others, and (2) compared to typical replanning and plan-stability repair, it can reduce the revisions among agents when failures are avoidable and can decrease the time-loss otherwise. In addition, to demonstrate extensibility, we integrate context-aware knowledge extension with committed repairing to increase the agent’s chances of repairing.},
  archive      = {J_EAAI},
  author       = {Mohannad Babli and Óscar Sapena and Eva Onaindia},
  doi          = {10.1016/j.engappai.2023.106275},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106275},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Plan commitment: Replanning versus plan repair},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online learning compensation control of an electro-hydraulic
shaking table using echo state networks. <em>EAAI</em>, <em>123</em>,
106274. (<a
href="https://doi.org/10.1016/j.engappai.2023.106274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electro-hydraulic shaking table (EHST) is widely used to simulate earthquake excitation in structural seismic tests. However, the nonlinear characteristics of the EHST, such as oil flow, friction, and dead zone, often lead to the distortion of seismic wave acceleration tracking and even cause the failure of the test. This paper describes the first application of Echo-State Networks (ESNs) to achieve high-precision seismic acceleration tracking of the EHST. The nonlinear control ability of the conventional three-variable control (TVC) algorithm in the EHST is discussed. An online learning compensation control framework using ESNs for “Transfer System” (The “Transfer System” denotes the nonlinear EHST controlled by TVC) is proposed. The least mean square (LMS) algorithm based on filtered-X is used to train the “ESN-Controller” online, and the initial transients of the “ESN-Controller” are reduced by using an estimation model of the actual “Transfer System” and a conditional switch. The offline iterative control (OIC) and nonlinear signal-based control (NSBC) are taken as the baseline algorithms of the proposed online learning compensation control. Simulation results show that the proposed online learning compensation control achieved excellent control with Pearson correlation coefficients of reference and responses above 99.6%, whereas the OIC and NSBC provided insufficient control. Moreover, the proposed online learning compensation control can also reduce the control error caused by the non-optimal TVC gains in the linear part of the EHST. This work throws new light on the study of the online learning control algorithm of the EHST.},
  archive      = {J_EAAI},
  author       = {Jianwen Liang and Zhen Ding and Qinghua Han and Hao Wu and Jinbao Ji},
  doi          = {10.1016/j.engappai.2023.106274},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106274},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online learning compensation control of an electro-hydraulic shaking table using echo state networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). An improved temporal convolutional network with attention
mechanism for photovoltaic generation forecasting. <em>EAAI</em>,
<em>123</em>, 106273. (<a
href="https://doi.org/10.1016/j.engappai.2023.106273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting renewable energy generation is challenging due to non-stationary and intricate stochastic properties, with a significant impact on grid operation. Although various methods have been developed for this purpose, the abundance of noise in original data limits the models’ ability to successfully model different features and make accurate predictions. Furthermore, current research tends to prioritize accuracy over usability. To address this, our paper proposes a novel multivariate time series forecasting model comprising temporal convolutions with residual structures, where the channel attention mechanism recalibrates important differences among features, and traditional convolution is improved to depth-wise convolution and the latest network architecture. The model enhances the accuracy of predictions while significantly lowering processing costs, making it suitable for deployment on various devices. The proposed model outperforms competing models in a variety of validation tests, according to experiments, with a significant 55% reduction in the mean squared error ( MSE ) compared to the best-competing model in the photovoltaic generation data set.},
  archive      = {J_EAAI},
  author       = {Ziyuan Zhang and Jianzhou Wang and Danxiang Wei and Yurui Xia},
  doi          = {10.1016/j.engappai.2023.106273},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106273},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved temporal convolutional network with attention mechanism for photovoltaic generation forecasting},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Detection algorithm of abnormal flow state fluid on closed
vibrating screen based on improved YOLOv5. <em>EAAI</em>, <em>123</em>,
106272. (<a
href="https://doi.org/10.1016/j.engappai.2023.106272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the difficulty of observing the interior of the closed vibrating screen and the difficulty of realizing automatic unmanned observation, this paper proposes a closed vibrating screen detection algorithm based on improved YOLOv5. A new bounding box loss function α -DEIoU l o s s was designed according to the motion characteristics of the fluid on the vibrating screen. Secondly, in order to enhance the ability of the network to extract feature information, the convolution in the C3 module of the Backbone part is replaced by Involution. Finally, in order to enable the network to focus on extracting the feature information of the target area, a CBAM module is added to the Neck part. The experimental results show that using the improved bounding box loss function can improve the network’s mAP, Precision and Recall by 5.6%, 1.3% and 2.3%, respectively. In addition, compared with the existing YOLOv5, the method proposed in this paper achieves a significant improvement in detection accuracy at a minimal cost, meeting the requirements of real-time detection. Through experimental comparison and research, the effectiveness and superiority of the proposed method are demonstrated.},
  archive      = {J_EAAI},
  author       = {Guorong Wang and Shuaiyu Chen and Gang Hu and Dongxiao Pang and Zhimin Wang},
  doi          = {10.1016/j.engappai.2023.106272},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106272},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection algorithm of abnormal flow state fluid on closed vibrating screen based on improved YOLOv5},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). THFE: A triple-hierarchy feature enhancement method for tiny
boat detection. <em>EAAI</em>, <em>123</em>, 106271. (<a
href="https://doi.org/10.1016/j.engappai.2023.106271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In boat navigation, especially in complex sea conditions, the detection performance of the tiny boat is related to the safety of boat sailing. However, due to the tiny boat occupying fewer pixels, the effective features of the tiny boat are difficult to obtain. Current tiny object detection methods focus primarily on dataset size matching, feature fusion, and label assignment, lack of attention to texture and detail information loss, and insufficient semantic utilization. Here, we propose a Triple-hierarchy Feature Enhancement (THFE) method to detect tiny boats. The core idea behind THFE is to enhance the semantic information from different layers to supplement the effective features of tiny boats. It consists of three spaces: the super-resolution enhancement space, the semantic enhancement space, and the hierarchical enhancement space. In THFE, sub-pixel convolution, sparse self-attention mechanism, channel attention mechanism, and spatial attention mechanism are adopted to hierarchically enhance each layer’s high-level and low-level semantic features. Finally, each layer’s high-level and low-level semantic features are adaptively fused so that each feature map contains richer high-level and low-level semantic information. Experiments show that our proposed THFE method achieves impressive gains in detection performance. For example, in terms of A P 50 t i n y , our method outperforms state-of-the-art methods by 1 . 7 % on the TinyBoats dataset, 3 . 1 % on the TinyPersons Dataset and 3 . 9 % on the Tiny CityPersons Dataset. To further study the detection of tiny boats, we introduce a tiny boat dataset that will be publicly accessible.},
  archive      = {J_EAAI},
  author       = {Yinsai Guo and Hang Yu and Liyan Ma and Liang Zeng and Xiangfeng Luo},
  doi          = {10.1016/j.engappai.2023.106271},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106271},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {THFE: A triple-hierarchy feature enhancement method for tiny boat detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MIVAE: Multiple imputation based on variational
auto-encoder. <em>EAAI</em>, <em>123</em>, 106270. (<a
href="https://doi.org/10.1016/j.engappai.2023.106270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the issue of MV imputation has become one of the research hotspots in the field of data quality, since the missing values (MVs) are prevalent in real-world datasets and bring challenges to advanced data analytics algorithms. To impute the MVs, most existing approaches directly derive one estimation for each MV, which is categorized as the single imputation (SI). However, the SI ignores the uncertainty of the MVs, and thereby usually derive unsatisfactory imputation results compared to the Multiple imputation (MI). To extract the uncertainty of the MVs, the MI algorithms derive multiple candidate estimations for each MV. Nevertheless, existing MI approaches are few due to the complicated data-handling process. Accordingly, in this paper, by exploring the Variational Auto-Encoder (VAE) model, we propose a new MI approach, namely MIVAE (Multiple Imputation based on Variational Auto-Encoder) to impute MVs for the tabular data. In MIVAE, we first add a corrupted input layer (where the synthetic MVs are introduced) adjacent to the original input layer to make the model capable of MV issue. Then, we obtain multiple rather than single candidate estimations for each data sample from the posterior distribution of the latent variables learned by our designed model. In such way, the multiple imputation is effectively implemented where the uncertainty of the MVs are extracted perfectly. Next, to obtain satisfactory imputation results, we add a data analysis layer at the end of the network to integrate multiple candidate estimations intelligently. Finally, the experimental results over four real-world datasets demonstrate that MIVAE achieves significantly higher imputation accuracy compared to existing solutions, and MIVAE are capable of handling both numerical and categorized tabular data. For example, the imputation accuracy based on MIVAE improves up to about 40% and 30% compared with PMM and MIWAE (which are the state-of-the-art MI approach) over the CropMapping dataset, respectively. Moreover, we train a MIVAE model over three datasets containing MVs, respectively. By leveraging the trained MIVAE, the classification performance over the imputed data is similar to that over the complete data.},
  archive      = {J_EAAI},
  author       = {Qian Ma and Xia Li and Mei Bai and Xite Wang and Bo Ning and Guanyu Li},
  doi          = {10.1016/j.engappai.2023.106270},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106270},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MIVAE: Multiple imputation based on variational auto-encoder},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An automatic machine vision-based algorithm for inspection
of hardwood flooring defects during manufacturing. <em>EAAI</em>,
<em>123</em>, 106268. (<a
href="https://doi.org/10.1016/j.engappai.2023.106268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hardwood flooring products are popular construction materials because of their aesthetics, durability, low maintenance requirements, and affordability. To ensure product quality during manufacturing, common defects such as cracks, chips, or stains are typically detected and classified manually, but this process can decrease productivity. The aim of this study was to develop an automatic machine vision-based inspection system with a robust algorithm for inspecting small hardwood flooring defects in a production line. This defect-inspection algorithm is based on image-processing techniques, including background elimination, boundary approximation, and defect inspection of photographs. The YOLOv5 deep-learning algorithm for object detection was applied to detect surface defects. The resulting algorithm identified the quality of each specimen (i.e., either good or defective). The influences of colour and surface patterns on defect inspection were experimentally investigated under light conditions. The algorithm was adaptable to specimens with different colours and patterns under various conditions, demonstrating the potential of this approach in practical situations.},
  archive      = {J_EAAI},
  author       = {Van Doi Truong and Jiaping Xia and YuHyeong Jeong and Jonghun Yoon},
  doi          = {10.1016/j.engappai.2023.106268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An automatic machine vision-based algorithm for inspection of hardwood flooring defects during manufacturing},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven methods for stress field predictions in random
heterogeneous materials. <em>EAAI</em>, <em>123</em>, 106267. (<a
href="https://doi.org/10.1016/j.engappai.2023.106267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting full-field stress responses is of fundamental importance to assessing materials failure and has various engineering applications in design optimization, manufacturing process control, and structural health monitoring. This article develops and evaluates different data-driven methods for efficient and accurate predictions of full stress fields in random heterogeneous materials. The first approach integrates model order reduction of proper orthogonal decomposition (POD) with classical machine learning techniques (K-nearest neighbors, random forest, and artificial neural networks) to predict full-field responses based on POD-reduced coefficients. However, this strategy shows limitations in predicting full stress fields, especially for heterogeneous material inclusions of small size or being close to the domain boundary. After that, two computer vision-based deep learning approaches were developed for full-field predictions. The first one uses a Resnet-based Convolutional Neural Network (CNN), and the second is based on a modified conditional Generative Adversarial Network (cGAN). Two representative example problems were studied: a random heterogeneous material inclusion or a void varying in size and location. In contrast to POD-based classical machine learning, almost invisible differences were found between the entire stress fields in finite element simulations and computer vision-based deep learning (CNN/cGAN) predictions, with significantly reduced mean squared error (MSE) and correlation values (R2) mostly above 0.99. On the other hand, the proposed cGAN provides more accurate predictions than CNN with fewer epochs.},
  archive      = {J_EAAI},
  author       = {Enjamamul Hoq and Osama Aljarrah and Jun Li and Jing Bi and Alfa Heryudono and Wenzhen Huang},
  doi          = {10.1016/j.engappai.2023.106267},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106267},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven methods for stress field predictions in random heterogeneous materials},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crude oil price forecasting with machine learning and google
search data: An accuracy comparison of single-model versus
multiple-model. <em>EAAI</em>, <em>123</em>, 106266. (<a
href="https://doi.org/10.1016/j.engappai.2023.106266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has shown that introducing online data can significantly improve forecasting ability. This study considers several popular single-model machine learning methods and a stacking multiple-model ensemble learning strategy. These are used with online data from Google Trends to forecast crude oil prices. The study first selects dozens of alternative Google Trends, which may capture crude oil price fluctuations. A co-integration test and Granger causality analysis are used to investigate the effect of Google Trends on crude oil prices. Then, the multiple-model methods are compared with several popular single-model machine learning methods that are used to forecast crude oil prices. These methods are used with Google Trends that have a significant relationship with the crude oil price. Experimental results indicate that introducing Google Trends can improve the forecasting performance; multiple-model methods also outperform several popular single-model machine learning methods in terms of prediction accuracy.},
  archive      = {J_EAAI},
  author       = {Quande Qin and Zhaorong Huang and Zhihao Zhou and Chen Chen and Rui Liu},
  doi          = {10.1016/j.engappai.2023.106266},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106266},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Crude oil price forecasting with machine learning and google search data: An accuracy comparison of single-model versus multiple-model},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). C3DBed: Facial micro-expression recognition with
three-dimensional convolutional neural network embedding in transformer
model. <em>EAAI</em>, <em>123</em>, 106258. (<a
href="https://doi.org/10.1016/j.engappai.2023.106258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial micro-expression is often used for emotional recognition of people in a high-risk or pressure scene, which may reflect genuine emotions due to the low intensity of facial action units. Current methods focus on locating regions with emotional changes and cropping these regions for local feature extraction. However, these methods may lead to the problem of information redundancy caused by overlapping cropped regions. This paper proposes a novel three-dimensional convolutional neural network embedding in the transformer model (C3DBed). This model learns the attention weight of each local region of the micro-expression image, thereby perceiving the detail changes of the facial image and extracting robust local detail features. Solve the problem of model complexity and information redundancy caused by low-intensity local area positioning of facial muscle movement. The experiment results demonstrated that the proposed C3DBed model achieved competitive performance with accuracy rates of 78.04%, 77.64%, and 75.73% on SMIC, CASME II, and SAMM datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Hang Pan and Lun Xie and Zhiliang Wang},
  doi          = {10.1016/j.engappai.2023.106258},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106258},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {C3DBed: Facial micro-expression recognition with three-dimensional convolutional neural network embedding in transformer model},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-agent framework for collaborative geometric modeling
in virtual environments. <em>EAAI</em>, <em>123</em>, 106257. (<a
href="https://doi.org/10.1016/j.engappai.2023.106257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of collaborative applications in which several individuals interact to solve a problem is an important strategy both in educational settings as well as professional environments. Virtual Reality (VR) technology, in particular, has acquired a predominant role in many industries. However, as the level of immersion and realism of the VR experience increases, so does the demand for computational resources, as rendering processes become increasingly intensive and can negatively affect other communication processes that are critical in collaborative environments. In this paper, we present a software framework based on multi-agent systems that enables the separation of rendering processes from internal data management tasks and communication processes between users, which are prevalent in collaborative virtual reality applications. The results of our validation studies show that, compared to other techniques based on protocol or network enhancements, the proposed architecture can significantly improve collaborative processes in general, and virtual reality-based applications in particular.},
  archive      = {J_EAAI},
  author       = {J. Conesa and F.J. Mula and M. Contero and J.D. Camba},
  doi          = {10.1016/j.engappai.2023.106257},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106257},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-agent framework for collaborative geometric modeling in virtual environments},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Photo-realistic 3D model based accurate visual positioning
system for large-scale indoor spaces. <em>EAAI</em>, <em>123</em>,
106256. (<a
href="https://doi.org/10.1016/j.engappai.2023.106256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel and reliable visual positioning system (VPS), KR-Net, for kidnap recovery tasks, which predicts an accurate position when a robot is first initiated. KR-Net is based on a hierarchical visual localization method and demonstrates significant robustness in large-scale indoor environments. The proposed VPS utilizes a photo-realistic 3D model to generate a dense database of any camera pose and incorporates a novel global descriptor for indoor spaces, i-GeM, that outperforms existing methods in terms of robustness. Additionally, the proposed combinatorial pooling approach overcomes the limitations of previous single image-based predictions in large-scale indoor environments, allowing for accurate discrimination between similar locations. Extensive evaluations were performed on six large-scale indoor datasets to demonstrate the contributions of each component. To the best of our knowledge, KR-Net is the first system to estimate wake-up positions with a near 100 % confidence level within a 1.0 m distance error threshold.},
  archive      = {J_EAAI},
  author       = {Janghun Hyeon and Bumchul Jang and Hyunga Choi and Joohyung Kim and Dongwoo Kim and Nakju Doh},
  doi          = {10.1016/j.engappai.2023.106256},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106256},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Photo-realistic 3D model based accurate visual positioning system for large-scale indoor spaces},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved assessment model for health-care waste management
based on dual 2-tuple linguistic rough number clouds. <em>EAAI</em>,
<em>123</em>, 106255. (<a
href="https://doi.org/10.1016/j.engappai.2023.106255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The management of medical waste disposal is a major challenge faced by different cities in developing countries. The choice of optimal medical waste treatment technology is a complex multi-criteria group decision-making problem that requires consideration of multiple alternatives against conflicting criteria. Decision makers evaluating disposal municipalities may conduct random evaluations from different linguistic term sets according to different preferences and contexts. Various fuzzy numbers based approaches have been studied in HCWM (health-care waste management) process, however they have certain limitations such as lacking manipulation tools of diverse information, additional adjustments and suppositions, ignoring randomness and multi-granularity in experts’ judgements. In response, this research article proposes a novel mathematical models by integrating 2-tuple linguistic setting into rough approximations and cloud theory. First, three novel linguistic manipulation models, namely, 2-tuple linguistic clouds, 2-tuple linguistic rough numbers and dual 2-tuple linguistic rough number (D2tLRN) clouds are developed to handle uncertainty with randomness and multi-granularity simultaneously. Secondly, a hybrid weighting scheme is utilized to evaluate the relative importance of waste factors using both subjective and objective aspects of uncertainty. Thirdly, the proposed D2tLRN cloud model is integrated with the technique for order of preference by similarity to ideal solution (TOPSIS) method to design an evaluation approach for the selection of HCWM technologies. Finally, the application of the proposed method is studied with an empirical case study of health care waste management in the most crowded municipality. The sensitivity analysis of the proposed approach is also discussed in detail to study the effect of various parameters on the results. The out-performance and significance of the proposed D2tLRN cloud TOPSIS method is illustrated by comparing it with existing approaches.},
  archive      = {J_EAAI},
  author       = {Musavarah Sarwar},
  doi          = {10.1016/j.engappai.2023.106255},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106255},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved assessment model for health-care waste management based on dual 2-tuple linguistic rough number clouds},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The promise of convolutional neural networks for the early
diagnosis of the alzheimer’s disease. <em>EAAI</em>, <em>123</em>,
106254. (<a
href="https://doi.org/10.1016/j.engappai.2023.106254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s Disease (AD) is one of the most devastating neurologic disorders, if not the most, as there is no cure for this disease, and its symptoms eventually become severe enough to interfere with daily tasks. The early diagnosis of AD, which might be up to 8 years before the onset of dementia symptoms, comes with many promises. To this end, we propose a novel Convolutional Neural Network (CNN) as a cheap, fast, yet accurate solution. First, a gold-standard dataset, namely DARWIN , that was proposed for the detection of AD through handwriting and consisted of 1 D features, was used to generate the 2 D features, which were yielded into the proposed novel model. Then, the proposed novel model was trained and evaluated on this dataset. According to the experimental result, the proposed novel model obtained an accuracy as high as 90.4%, which was higher than the accuracies obtained by the state-of-the-art baselines, which covered a total of 17 widely-used classifiers.},
  archive      = {J_EAAI},
  author       = {Pakize Erdogmus and Abdullah Talha Kabakus},
  doi          = {10.1016/j.engappai.2023.106254},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106254},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The promise of convolutional neural networks for the early diagnosis of the alzheimer’s disease},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploration of deep learning models for localizing bare-hand
in the practical environment. <em>EAAI</em>, <em>123</em>, 106253. (<a
href="https://doi.org/10.1016/j.engappai.2023.106253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection and tracking of the bare-hand are vital for gesture-based human–computer interaction systems. To detect and track the bare-hand efficiently in successive frames is challenging when the motion blur occurs due to the speed or acquisition device. In addition, the variations like pose, position, scale, rotation, illumination, occlusion, speed, and impostors make detection more complex. The traditional bare-hand detectors utilize rectangular windows to train the detector, which results in the background feature domination effect. We present a holistic approach to DAWT for bare-hand localization by combining detection and tracking to overcome this. This combination reduces the system’s computational time and provides near-real-time performance. In the detection module, HandSNet, and YOLO-H are implemented by customizing the SqueezeNet network. This network contains only 0.35 million parameters. Followed by that, the Kalman filter and point tracker are utilized in the tracking module. For the depth analysis of the deep architecture models on the bare-hand, we have also implemented DCNN, RCNNs, and YOLO models. This comparative analysis gives a brief overview of the various deep learning models’ performance for bare-hand detection. To evaluate the ability and robustness of the proposed models, the NITS hand gesture database, OUHands, EgoHands, Oxford hand, and EgoGesture database are considered.},
  archive      = {J_EAAI},
  author       = {Kuldeep Singh Yadav and Anish Monsley K. and Rabul Hussain Laskar and Naseem Ahmad},
  doi          = {10.1016/j.engappai.2023.106253},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106253},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploration of deep learning models for localizing bare-hand in the practical environment},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global e-commerce (GeC) theory by intuitionistic fuzzy
γ-submodule. <em>EAAI</em>, <em>123</em>, 106252. (<a
href="https://doi.org/10.1016/j.engappai.2023.106252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy set (IFS) theory can be applied for multi-aspect systems due to its capability to address uncertainty and incomplete information in terms of membership and non-membership degrees. Unfortunately, classical Γ -structures cannot handle fuzzy and imprecise information in real problems. In fact, there is no rigorous base to practically express the effectiveness of multi-attribute systems in IFS environment. Here, we develop a generalized IFS with the notion of Γ -module called intuitionistic fuzzy Γ -submodule (IF Γ M) to establish a novel “ Global electronic ( e )-Commerce (GeC) Theory ”. To simplify the analysis of parameters, ( α , β ) -cut representation is proposed in terms of comprehensive distribution of fuzzy number for the classification of components. On the other hand, Cartesian product is implemented to correspond the elements. Substantial properties of IF Γ M including ( α , β ) -cut, Cartesian product and t -intuitionistic fuzzy Γ -submodule ( t -IF Γ M) are characterized with illustrative examples to extend the framework of IF Γ M, where ( α , β ) -cut and support t -IF Γ M are verified to be Γ -submodules based on the properties of IF Γ M. Through Γ -module homomorphism, image and inverse image, the parametric connections between ( α , β ) -cuts are systematically investigated. In addition, a mathematical relationship between the Cartesian product and ( α , β ) -cut is determined. The overlapping intersection of a collection of t -IF Γ M is proved to be t -IF Γ M, and the image and inverse image are preserved under Γ -module homomorphism. As global e -trades are increasingly expanding after the recent coronavirus disease 2019 (COVID-19) hit, with the growth of 26.7-trillion dollars, businesses are required to transform their traditional functional natures to online (or blended) strategies for cost efficiency and self-survival in the present competitive environment. Therefore, compared to recent studies on IFS in the context of Γ -structures, the main contribution of this study is to provide a theoretical basis for the establishment of a new GeC Theory through the developed IF Γ M method and Γ -module M which targets the purchasing rate of customers through e -commerce companies. In the end, the performance of the proposed method in terms of upper and lower cut, t -intuitionistic fuzzy set, support and IF Γ M model, is analyzed in the developed GeC Theory . The proposed GeC Theory is validated using real datasets of e -commerce mega companies, i.e., Amazon, Alibaba, eBay, Shopify. They are characterized based on the amount of online shopping by samples (individuals). Compared to the existing methods, the GeC approach is an effective IFS-based method for complex systems with uncertainty.},
  archive      = {J_EAAI},
  author       = {Narjes Firouzkouhi and Abbas Amini and Fadi Alkhatib and Ahmed Bani-Mustafa and Chun Cheng and Bijan Davvaz},
  doi          = {10.1016/j.engappai.2023.106252},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106252},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Global e-commerce (GeC) theory by intuitionistic fuzzy Γ-submodule},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Genetic algorithm-based optimal design of modular robot
topology based on distributed parallel kinematic modeling and analysis.
<em>EAAI</em>, <em>123</em>, 106251. (<a
href="https://doi.org/10.1016/j.engappai.2023.106251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-oriented design of modular robot topology is a crucial issue to be solved in modular robot research. In this paper, a Genetic algorithm-based optimal design strategy for the modular robot topology is proposed. Four tuples are used to represent the modular robot topology. By establishing a database of motion transmission forms for a modular unit, a distributed parallel kinematic modeling and analysis method for modular robots is introduced. Taking the four-tuple representation of the modular robot topology as decision variables, an optimization model of the topology design for modular robots is established. To solve the model, under the framework of the Genetic algorithm, the genotype and genetic operations are designed to improve the effectiveness of individual generating in the optimization process. Finally, a modular robot is taken as an example to carry out simulations. It indicates that the modular robot under the designed topology can successfully execute tasks with as few modular units as possible, and the computing time for the kinematics modeling and analysis of modular robots can be reduced by at least an order of magnitude.},
  archive      = {J_EAAI},
  author       = {Junting Fei and Qingxuan Jia and Gang Chen and Tong Li and Ruiquan Wang and Xiaodong Zhang},
  doi          = {10.1016/j.engappai.2023.106251},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106251},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Genetic algorithm-based optimal design of modular robot topology based on distributed parallel kinematic modeling and analysis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A model adaptive updating kernel correlation filter tracker
with deep CNN features. <em>EAAI</em>, <em>123</em>, 106250. (<a
href="https://doi.org/10.1016/j.engappai.2023.106250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tracker based on correlation filter shows excellent performance in tracking accuracy and running speed. However, the models of correlated filter trackers are always updated with fixed weights, which can degrade the tracking performance when the target in a variety of challenging scenarios. In this paper, we present a model adaptive updating method based on a fuzzy system, which can set different updating weights on each frame to effectively deal with the challenging scenarios in the tracking process. Attractively, this method can be perfectly used in all trackers based on correlation filtering. In addition, we combine deep CNN features that can describe target semantics with HOG features that have spatial descriptions. Using their complementarity to target descriptions, we establish HOG-based filter model and CNN-based filter model. To two response maps of the models, we propose a different fusion strategy based on quality measurement of tracking results, which can balance the accuracy and robustness of the tracker. Experiments on OTB-2013, OTB-2015, benchmark videos, and VOT2018 dataset show that our tracker (called MACF) is effective and exhibits competitive results compared with the recent state-of-the-art (SOTA) trackers.},
  archive      = {J_EAAI},
  author       = {Zhigang Feng and Peng Wang},
  doi          = {10.1016/j.engappai.2023.106250},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106250},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A model adaptive updating kernel correlation filter tracker with deep CNN features},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient hybrid optimization method for fuzzy flexible
job-shop scheduling problem: Steady-state performance and analysis.
<em>EAAI</em>, <em>123</em>, 106249. (<a
href="https://doi.org/10.1016/j.engappai.2023.106249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the uncertainty pervasive in manufacturing and production systems, a crisp processing time is no longer appropriate. Thus, the flexible job-shop scheduling issue comes with fuzzy processing times. Fuzzy numbers are used to depict the uncertainty associated with processing times. This paper proposes a Hybrid Fuzzy Flexible job-shop Scheduling Approach (HFFSA) for addressing the Fuzzy Flexible Job-Shop Scheduling Problem (FFJSSP). An encoding-and-decoding scheme is employed for initializing the population. HFFSA incorporates four operators to enhance the quality of solutions: the Different Positions Shuffling (DPS) operator, the Randomly Selected Positions Shuffling (RSPS) operator, the Block Shuffling (BS) operator and the Inversion Mutation (IM) operator. The DPS operator shuffles the different positions between a randomly generated solution and the current one. On the other hand, the RSPS shuffles random positions to maintain population diversity. The BS and IM work on a subset of positions from the current solution to obtain near-optimal solutions. Furthermore, we integrate the pair-wise local search strategy with HFFSA to improve the best solution. HFFSA is compared to twenty-five algorithms using Lei and remanufacturing benchmarks. Several statistical measures are employed, like the CPU time, best, average and worst fuzzy makespan values, boxplots and the Wilcoxon signed-rank test. The statistical analyses affirm the superiority of the proposed HFFSA.},
  archive      = {J_EAAI},
  author       = {Mohamed Abdel-Basset and Reda Mohamed and Doaa El-Shahat and Karam M. Sallam},
  doi          = {10.1016/j.engappai.2023.106249},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106249},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient hybrid optimization method for fuzzy flexible job-shop scheduling problem: Steady-state performance and analysis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty-aware credit card fraud detection using deep
learning. <em>EAAI</em>, <em>123</em>, 106248. (<a
href="https://doi.org/10.1016/j.engappai.2023.106248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Countless research works of deep neural networks (DNNs) in the task of credit card fraud detection have focused on improving the accuracy of point predictions and mitigating unwanted biases by building different network architectures or learning models. Quantifying uncertainty accompanied by point estimation is essential because it mitigates model unfairness and permits practitioners to develop trustworthy systems which abstain from suboptimal decisions due to low confidence. Explicitly, assessing uncertainties associated with DNNs predictions is critical in real-world card fraud detection settings for characteristic reasons, including (a) fraudsters constantly change their strategies, and accordingly, DNNs encounter observations that are not generated by the same process as the training distribution, (b) owing to the time-consuming process, very few transactions are timely checked by professional experts to update DNNs. Therefore, this study proposes three uncertainty quantification (UQ) techniques named Monte Carlo dropout, ensemble, and ensemble Monte Carlo dropout for card fraud detection applied on transaction data. Moreover, to evaluate the predictive uncertainty estimates, UQ confusion matrix and several performance metrics are utilized. Through experimental results, we show that the ensemble is more effective in capturing uncertainty corresponding to generated predictions. Additionally, we demonstrate that the proposed UQ methods provide extra insight to the point predictions, leading to elevate the fraud prevention process.},
  archive      = {J_EAAI},
  author       = {Maryam Habibpour and Hassan Gharoun and Mohammadreza Mehdipour and AmirReza Tajally and Hamzeh Asgharnezhad and Afshar Shamsi and Abbas Khosravi and Saeid Nahavandi},
  doi          = {10.1016/j.engappai.2023.106248},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106248},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty-aware credit card fraud detection using deep learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local–global lightweight ViT model for mini/micro-LED-chip
defect recognition. <em>EAAI</em>, <em>123</em>, 106247. (<a
href="https://doi.org/10.1016/j.engappai.2023.106247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the miniaturization of the light-emitting diodes (LEDs), it is a challenge to detect the defective LED-chip with neural networks. Convolution neural networks (CNNs) can capture local information, but the deeper or wider layer with a higher computational cost is required to achieve a stronger model capacity. Additionally, the vision transformer (ViT) is able to extract global information at the cost of large datasets, extensive data augmentation and computational complexity. To solve the aforementioned issues, this paper proposes a local–global lightweight ViT model based on Convmixer for mini/micro-LED-chip defect recognition, which combines the advantages of CNNs and ViT to capture both detailed and global information and is suitable for resource-constrained embedded or mobile devices. A fine-coarse-grained convolutional block is proposed to capture different sizes of features in the spatial dimension with depth-wise convolution. Then, the multi-mode and cross-channel information is extracted by the point-wise convolution. Finally, a position attention module embedded with the long-range relationship is presented to highlight the important patches and captures global information. Besides, the structure of the proposed model is plain so that the detailed information is preserved. Experiments show that the proposed model achieves a higher accuracy of 96.17% with fewer parameters and of 0.038M and a lower computational cost of 0.138G, which outperforms the state-of-the-art.},
  archive      = {J_EAAI},
  author       = {Linyu Wei and Jueping Cai and Kailin Wen and Chengkai Zhang},
  doi          = {10.1016/j.engappai.2023.106247},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106247},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Local–global lightweight ViT model for mini/micro-LED-chip defect recognition},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An evolutionary approach comprising tailor-made variation
operators for rescue unit allocation and scheduling with fuzzy
processing times. <em>EAAI</em>, <em>123</em>, 106246. (<a
href="https://doi.org/10.1016/j.engappai.2023.106246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the rescue unit allocation and scheduling problem ( RUASP ) with fuzzy processing times through an evolutionary approach. The goal of RUASP is to efficiently assign and schedule the rescue units to process the incidents in the event of a natural disaster. This problem can be considered as a variant of the unrelated parallel-machine scheduling problem with sequence and machine-dependent setup times. A steady-state grouping genetic algorithm ( SSGGA ) approach is presented to minimize the total weighted completion time of the incidents, where the weights correspond to the severity levels of the incidents. The crossover and mutation operators used in this approach are designed as per the characteristics of RUASP and its objective. The proposed approach uses a combination of greedy and random heuristics while generating the initial solutions, thereby yielding superior quality diverse initial solutions. The performance of the proposed approach is compared with the state-of-the-art approach available in the literature. The proposed approach always yields better results in much shorter execution times in comparison to the state-of-the-art approach. Moreover, the robustness analysis test demonstrates the proposed approach to be more robust in comparison to the state-of-the-art approach.},
  archive      = {J_EAAI},
  author       = {Gaurav Srivastava and Alok Singh},
  doi          = {10.1016/j.engappai.2023.106246},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106246},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An evolutionary approach comprising tailor-made variation operators for rescue unit allocation and scheduling with fuzzy processing times},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep transfer learning-based damage detection of composite
structures by fusing monitoring data with physical mechanism.
<em>EAAI</em>, <em>123</em>, 106245. (<a
href="https://doi.org/10.1016/j.engappai.2023.106245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Damage detection of carbon fiber reinforced plastics (CFRP) composites is a challenging issue owing to their intrinsic high degree of anisotropy with complex failure modes. Data-driven approaches have great potential in damage detection for CFRP composites. However, the lack of physical interpretability makes data-driven methods highly dependent on the amount of data, which involves significant effort in experiment and is impractical to obtain for all damage conditions. To overcome the above challenges, a robust and generalizable framework for damage detection of CFRP composite structures is proposed by fusing monitoring data with physical mechanisms. In this framework, the numerical method is leveraged to build physical models of the composite structures to generate data under various damage conditions. Then, a deep transfer learning-based model is applied in the fusion of experiment and simulation data, which mitigates the discrepancy between the physical model and real experiment. With the combination of domain adaptation and domain adversarial training in the model, the domain invariant features can be generalized from the source domain (simulation data) to the target domain (experiment data). Therefore, the physical interpretability is supplemented in the data-driven model. To verify the adaptability of the method, different transfer tasks based on the accelerated aging experiments are performed. The results show that the proposed method can reduce the dependence of the data-driven methods on real monitoring data and prevails in all evaluation indicators than other methods. Eventually, this method can reduce the experiment effort of damage detection for composites while holding a great detection accuracy.},
  archive      = {J_EAAI},
  author       = {Cheng Liu and Xuebing Xu and Jun Wu and Haiping Zhu and Chao Wang},
  doi          = {10.1016/j.engappai.2023.106245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep transfer learning-based damage detection of composite structures by fusing monitoring data with physical mechanism},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthesis of multilevel knowledge graphs: Methods and
technologies for dynamic networks. <em>EAAI</em>, <em>123</em>, 106244.
(<a href="https://doi.org/10.1016/j.engappai.2023.106244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs is one of the most popular techniques for knowledge-based modelling in various subdomains of modern AI technologies ranging from natural language processing to e-commerce recommendations and cyberphysical systems. Even complex technical systems like telecommunication networks could be modelled by means of Knowledge Graphs. However, there are serious challenges when we deal with such systems having a huge number of interconnected elements (e.g. technical objects and their groups) that change over time. Thus, up-to-date there is no adequate solution for not only telecommunication networks but for any complex dynamic systems where inductive and deductive synthesis of large Knowledge Graph based models that are easily reconfigurable and scalable is required. We state and solve the problem of building such models for one of the most common types of objects where models can be represented as hierarchical re-configurable structures. This representation enables recent advances in multilevel inductive–deductive synthesis for model building. From a methodological viewpoint, we propose a novel complex approach to multilevel synthesis for objects with dynamic hierarchical structure based on modified methods for inductive and deductive synthesis of Knowledge Graphs. From a practical perspective we present a real case-study on an interactive service for digital cable TV networks – which is especially interesting for data engineers and scientists – where various problems ranging from network health monitoring to channel advertising can be solved with the same hierarchical model. We release an openly available domain benchmark, which features two realistic datasets (namely, for SPARQL querying performance analysis, and for our case study on dynamic network monitoring). Last but not least, our experiments with recent state-of-the-art approaches to knowledge graph querying Abdelaziz et al. (2017) show that the developed models of multilevel synthesis reduce the time complexity up to 73% on practice compared to the baselines, and are lossless and able to beat their competitors based on parallel knowledge graph processing from 4% to 91% in terms of computational time (depending on the query type). Further parallelisation of our multilevel models is even more efficient (the reduction of query processing time is about 40%–45%) and opens promising prospects for the creation and exploitation of dynamic Knowledge Graphs in practice.},
  archive      = {J_EAAI},
  author       = {Tianxing Man and Alexander Vodyaho and Dmitry I. Ignatov and Igor Kulikov and Nataly Zhukova},
  doi          = {10.1016/j.engappai.2023.106244},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106244},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthesis of multilevel knowledge graphs: Methods and technologies for dynamic networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analysing effectiveness of grey theory-based feature
selection for meteorological estimation models. <em>EAAI</em>,
<em>123</em>, 106243. (<a
href="https://doi.org/10.1016/j.engappai.2023.106243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grey theory is capable of representing uncertainty and has proved its applicability in prioritizing features for estimation problems and various decision-making problems. This study analyses the effectiveness of the application of grey theory in feature selection for daily dew point temperature (DPT) and daily pan-evaporation (PAN-EVP) estimation models. Feature subset identified by grey theory and subsets selected based on very high, high, medium, and low Pearson correlation coefficient (PCC) slabs are compared and analysed. Random Forest (RF) and Extreme gradient Boosting (XgBoost) are used for modelling. The performance of the models is evaluated using the root mean squared error (RMSE), mean absolute error (MAE), and coefficient of determination (R 2 ). The results showed that high PCC feature subset models underperformed on both datasets. The models with features selected using grey theory and medium PCC slab performed identically for both datasets. For the PAN-EVP dataset, the size of the grey theory-based subset is larger, both RF and XgBoost models with this scenario gave accuracy measures within the calculated average, unlike medium PCC slab subset. For the DPT dataset, the size of the grey theory-based subset is smaller and RF model with this scenario gave accuracy measures within the calculated average, unlike medium PCC slab subset. Grey theory and medium PCC slab subsets gave accuracy measures close to the calculated average for DPT estimation using XgBoost model. The study concludes that the models using grey theory-based feature selection demonstrated average or above-average performances and therefore is an effective feature selection technique.},
  archive      = {J_EAAI},
  author       = {Kshema Shaju and Sherin Babu and Binu Thomas},
  doi          = {10.1016/j.engappai.2023.106243},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106243},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analysing effectiveness of grey theory-based feature selection for meteorological estimation models},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven tracking control design with reinforcement
learning involving a wastewater treatment application. <em>EAAI</em>,
<em>123</em>, 106242. (<a
href="https://doi.org/10.1016/j.engappai.2023.106242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of urbanization rate, the problem of water shortage and pollution is more and more serious. It is important to improve the efficiency of wastewater treatment to protect the urban ecological environment. The wastewater treatment process involves a variety of biochemical reactions and has strong time-vary dynamics. The concentration design in the wastewater treatment process can be regarded as a tracking control problem for a class of nonlinear systems. In order to solve this problem, this paper develops an intelligent control method with tracking goal representation heuristic dynamic programming (T-GrHDP) by combining the GrHDP with a novel tracking framework. A model network is built by using a dataset consisting of real input and output data of the controlled object, which can overcome the dependence on the system dynamic. In order to improve the learning efficiency of the proposed algorithm, we introduce the goal network to provide more effective information for the critic network. The classical actor-critic scheme in reinforcement learning is used to obtain the approximate optimal control strategy. By introducing some necessary lemmas and assumptions, the convergence of the proposed algorithm is proved. Finally, the T-GrHDP method is successfully applied in two industrial simulations including the wastewater treatment system.},
  archive      = {J_EAAI},
  author       = {Ding Wang and Xin Li and Lingzhi Hu and Junfei Qiao},
  doi          = {10.1016/j.engappai.2023.106242},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106242},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven tracking control design with reinforcement learning involving a wastewater treatment application},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification and rating of steel scrap using deep
learning. <em>EAAI</em>, <em>123</em>, 106241. (<a
href="https://doi.org/10.1016/j.engappai.2023.106241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issues of high human interference and low efficiency in traditional manual methods for classifying and rating steel scrap, we propose the development of CSBFNet, a deep learning-based model for multi-category steel scrap classification and rating. Firstly, we built a 1:3 physical model of steel scrap quality inspection to simulate the unloading of a truck. We used a high-resolution vision sensor to capture the morphological characteristics of various steel scraps. Next, we trained the CSBFNet model using this data to obtain characteristic information for classifying and judging various types of scrap steel. Finally, we tested and improved the CSBFNet model at a Chinese steel mill. The results demonstrate that the model can effectively determine the automatic rating for different grades of scrap. The average accuracy rate of all types of steel scrap reaches 92.4% for the full category, with an mAP of 90.7%. Compared to traditional artificial quality detection methods, it has clear advantages in accuracy and fairness. This model solves the problem of evaluating the quality of steel scrap in the recycling process.},
  archive      = {J_EAAI},
  author       = {Wenguang Xu and Pengcheng Xiao and Liguang Zhu and Yan Zhang and Jinbao Chang and Rong Zhu and Yunfeng Xu},
  doi          = {10.1016/j.engappai.2023.106241},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106241},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Classification and rating of steel scrap using deep learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-based online learning control design with eligibility
trace for discrete-time unknown nonlinear systems. <em>EAAI</em>,
<em>123</em>, 106240. (<a
href="https://doi.org/10.1016/j.engappai.2023.106240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a heuristic algorithm to solve the nonlinear optimal control problem, adaptive dynamic programming is commonly constructed from one-step temporal difference learning. Eligibility trace can effectively speed up controller learning by considering the multi-step information in reinforcement learning. However, eligibility trace will bring in additional computational consumption and increase the learning burden. This paper attempts to take advantage of eligibility trace and avoids the high learning consumption at the same time. Therefore, an event-based neural dynamic programming ( λ ) [ENDP( λ )] algorithm via the actor–critic framework is constructed to solve the near-optimal control problem of unknown discrete-time systems. First, the modified forward view with eligibility trace is derived, which is suitable for engineering practice. Second, based on the event-triggered mechanism, ENDP( λ ) is designed to relieve the pressure of communication consumption. Then, the event-based system is proven to ensure the input-to-state stability under a suitable triggering condition. Moreover, three neural networks are given to approximate the one-step cost function, the n -step cost function, and the control law, respectively. Finally, two typical experimental simulation examples are presented to verify the effectiveness of the ENDP( λ ) algorithm.},
  archive      = {J_EAAI},
  author       = {Ding Wang and Jiangyu Wang and Lingzhi Hu and Mingming Zhao},
  doi          = {10.1016/j.engappai.2023.106240},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106240},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Event-based online learning control design with eligibility trace for discrete-time unknown nonlinear systems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep reinforcement learning approach to energy management
control with connected information for hybrid electric vehicles.
<em>EAAI</em>, <em>123</em>, 106239. (<a
href="https://doi.org/10.1016/j.engappai.2023.106239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the importance of the energy management strategy for hybrid electric vehicles, this paper is aiming at addressing the energy optimization control issue using reinforcement learning algorithms. Firstly, this paper establishes a hybrid electric vehicle power system model. Secondly, a hierarchical energy optimization control architecture based on networked information is designed, and a traffic signal timing model is used for vehicle target speed range planning in the upper system. More specifically, the optimal vehicle speed is optimized by a model predictive control algorithm. Thirdly, a mathematical model of vehicle speed variation in connected and unconnected states is established to analyze the effect of vehicle speed planning on fuel economy. Finally, three learning-based energy optimization control strategies, namely Q-learning, deep Q network (DQN), and deep deterministic policy gradient (DDPG) algorithms, are designed under the hierarchical energy optimization control architecture. It is shown that the Q-learning algorithm is able to optimize energy control; however, the agent will meet the ”dimension disaster” once it faces a high-dimensional state space issue. Then, a DQN control strategy is introduced to address the problem. Due to the limitation of the discrete output of DQN, the DDPG algorithm is put forward to achieve continuous action control. In the simulation, the superiority of the DDPG algorithm over Q-learning and DQN algorithms in hybrid electric vehicles is illustrated in terms of its robustness and faster convergence for better energy management purposes.},
  archive      = {J_EAAI},
  author       = {Peng Mei and Hamid Reza Karimi and Hehui Xie and Fei Chen and Cong Huang and Shichun Yang},
  doi          = {10.1016/j.engappai.2023.106239},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106239},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep reinforcement learning approach to energy management control with connected information for hybrid electric vehicles},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-lane detection by combining line anchor and feature
shift for urban traffic management. <em>EAAI</em>, <em>123</em>, 106238.
(<a href="https://doi.org/10.1016/j.engappai.2023.106238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection is a fundamental task in urban traffic management. Like lane detection for automatic driving, lane detection for traffic management will be faced with common challenges including fog, night, shadow, no line and etc. Meanwhile, it will be faced with new and unique challenges including variable number of lanes, blocked lanes due to oversize vehicles and color interference. In this paper, we propose a multi-lane detection method by combining the line anchor and feature shift (MLD-LAFS) to cope with these challenges. The proposed method features a two-branch neural network structure based on the line anchor. The first branch is the feature shift branch incorporating spatial attention, which is designed to enhance the local features of lanes. The second branch is the global information branch incorporating channel attention and cross attention, which is designed to establish the long-distance connection of lane features. The channel attention can obtain the global channel information. The uncoupled feature shift cross attention can obtain the global spatial information. The feature map containing the global information can be obtained by fusing the feature maps of the first and second branches. The line anchor is used as the supervision information to generate the predicted lane and realize multi-lane detection. The feature shift is used to solve the problems of lane line being blocked and color interference. We perform the performance evaluation on three datasets, including CULane, TuSimple and a newly constructed dataset MonitorLane. Experimental results show that the proposed MLD-LAFS achieves remarkable results on the CULane and the TuSimple dataset. Moreover, the proposed MLD-LAFS achieves the highest grading in F1-score on the MonitorLane dataset, compared to existing solutions, including LaneATT, PolyLaneNet, Lane Shape Prediction with Transformers (LSTR) and etc.},
  archive      = {J_EAAI},
  author       = {Jianqi Liu and Bin Deng and Caifeng Zou and Bi Zeng and Weiwen Zhang and Jianxin Tan},
  doi          = {10.1016/j.engappai.2023.106238},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106238},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-lane detection by combining line anchor and feature shift for urban traffic management},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced ensemble deep random vector functional link
network for driver fatigue recognition. <em>EAAI</em>, <em>123</em>,
106237. (<a
href="https://doi.org/10.1016/j.engappai.2023.106237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigated the use of an ensemble deep random vector functional link (edRVFL) network for electroencephalogram (EEG)-based driver fatigue recognition. Against the low feature learning capability of the edRVFL network from raw EEG signals, two strategies were exploited in this work. Specifically, the first one was to exploit the advantages of the feature extractor module in CNNs, i.e. , use CNN features as the input of the edRVFL network. The second one was to improve the feature learning capability of the edRVFL network. An enhanced edRFVL network named FGloWD-edRVFL was proposed, in which four enhancements were implemented, including random forest-based F eature selection, Glo bal output layer, W eighting and entropy-based D ynamic ensemble. The proposed FGloWD-edRVFL network was evaluated on the challenging cross-subject driver fatigue recognition tasks. The results indicated that the proposed model could boost the recognition performance, significantly outperforming all strong baselines. The step-wise analysis further demonstrated the effectiveness of the proposed enhancements in the edRVFL network.},
  archive      = {J_EAAI},
  author       = {Ruilin Li and Ruobin Gao and Liqiang Yuan and P.N. Suganthan and Lipo Wang and Olga Sourina},
  doi          = {10.1016/j.engappai.2023.106237},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106237},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced ensemble deep random vector functional link network for driver fatigue recognition},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locally informed gravitational search algorithm with
hierarchical topological structure. <em>EAAI</em>, <em>123</em>, 106236.
(<a href="https://doi.org/10.1016/j.engappai.2023.106236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, gravitational search algorithm (GSA) has been successfully applied to solve various optimization problems. However, GSA tends to fall into local optimum because it ignores the environmental heterogeneity of agents. Therefore, locally informed gravitational search algorithm (LIGSA) based on neighborhood structure is proposed to balance exploration and exploitation. However, LIGSA ignores the differences in the evolutionary states between agents in the same neighborhood, and also ignores the differences in the evolutionary states between neighbors, which affects the performance of the algorithm. Therefore, a hierarchical locally informed gravitational search algorithm (HLIGSA) is proposed in this paper. This algorithm designs a hierarchical topology. In the lower layer, there are several non-overlapping neighborhoods, which constitute the whole population. Each agent in the neighborhood adaptively adjusts the gravitational constant according to its evolutionary state, so as to fully search the region of the neighborhood. The upper layer is a population composed of the best agents in each neighborhood, which performs gravity strategy or merging strategy for those neighborhoods that have lost the evolutionary capability, so as to balance the algorithm’s exploration and exploitation. The two layers work together to complete the entire search process. Experimental results show that HLIGSA outperforms many variants of GSA and many current state-of-the-art heuristic algorithms.},
  archive      = {J_EAAI},
  author       = {Leyi Xiao and Chaodong Fan and Zhaoyang Ai and Jie Lin},
  doi          = {10.1016/j.engappai.2023.106236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Locally informed gravitational search algorithm with hierarchical topological structure},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BGC: Belief gravitational clustering approach and its
application in the counter-deception of belief functions. <em>EAAI</em>,
<em>123</em>, 106235. (<a
href="https://doi.org/10.1016/j.engappai.2023.106235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counter-deception information fusion is a significant issue in Dempster–Shafer evidence theory (DST). How to effectively counter the deception is the key problem in belief function. Limited work has been presented, of which the negation view, degree of falsity view, and the minimum conflict view are popular ones. However, previous work may suffer from combinatorial explosion or be limited to simple practical application. Based on our previous belief universal gravitation (BUG) model, a simple belief gravitational clustering (BGC) is proposed to model the evidential clustering process. Some goals, like no parameter adjustment, no initial condition, objective and unique cluster number, and robustness are achieved. Furthermore, BGC-based fusion strategy is ulteriorly raised to determine whether the evidence should be fused, which fully considers the abnormal feature of the body of evidence and the nature of the combination rule to perceive the deception. Both theoretical analysis and experimental results demonstrate the accuracy and flexibility of the proposed work.},
  archive      = {J_EAAI},
  author       = {Huizi Cui and Huaqing Zhang and Yuhang Chang and Bingyi Kang},
  doi          = {10.1016/j.engappai.2023.106235},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106235},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BGC: Belief gravitational clustering approach and its application in the counter-deception of belief functions},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quaternion convolutional neural networks for hyperspectral
image classification. <em>EAAI</em>, <em>123</em>, 106234. (<a
href="https://doi.org/10.1016/j.engappai.2023.106234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternion convolutional neural networks (QCNNs) can capture quaternion features, which contain not only the contextual information among quaternion feature units but also utilize the quaternion algebra inside the quaternion feature units to express structural information. However, building efficient QCNNs for hyperspectral image (HSI) classification is a challenge due to the lack of methods to map real features into quaternion features and the missing key quaternion modules. This paper proposes methodologies to build QCNNs specifically for HSI classification and designs several key quaternion modules. Firstly, a novel quaternion feature encoder is presented to map real HSI features into quaternion features. Secondly, a paradigm is designed to conveniently modify classical convolutional neural networks to implement QCNNs for HSI classification. Thirdly, we propose a new separable quaternion convolutional neural network (SQNet) based on presented advanced quaternion modules, such as separable quaternion convolutions and quaternion attention mechanisms. In addition, the computational rules in quaternion neurons are improved to enhance the adaptability of QCNNs. Experiments conducted on four widely used HSI datasets indicate that the implemented QCNNs and the proposed SQNet achieve satisfactory results for HSI classification with limited training samples.},
  archive      = {J_EAAI},
  author       = {Heng Zhou and Xin Zhang and Chunlei Zhang and Qiaoyu Ma},
  doi          = {10.1016/j.engappai.2023.106234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quaternion convolutional neural networks for hyperspectral image classification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RETRACTED: Optimal infrastructure in microgrids with diverse
uncertainties based on demand response, renewable energy sources and
two-stage parallel optimization algorithm. <em>EAAI</em>, <em>123</em>,
106233. (<a
href="https://doi.org/10.1016/j.engappai.2023.106233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article has been retracted: please see Elsevier Policy on Article Withdrawal ( https://www.elsevier.com/locate/withdrawalpolicy ). This article has been retracted at the request of the Editor-in-Chief. Post-publication, the editors discovered suspicious changes in authorship between the original submission and the revised version of this paper. In summary, the paper was submitted by a sole author, Laleh Shahabi. During revision, the author name Yue Yu was added to the revised paper (as a new First and Corresponding Author) without explanation and without exceptional approval by the journal editor, which is contrary to the journal policy on changes to authorship. The editors reached out to the authors for an explanation, but they failed to provide a satisfactory explanation to these changes. In addition, it appears that Laleh Shahabi was claiming an affiliation with Sun-life Company, Baku, Azerbaijan. When questioned, the author was unable to provide convincing evidence of the existence and nature of this company. Overall, the editors feels that the findings of the manuscript cannot be relied upon and that the article needs to be retracted.},
  archive      = {J_EAAI},
  author       = {Yue Yu and Laleh Shahabi},
  doi          = {10.1016/j.engappai.2023.106233},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106233},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RETRACTED: Optimal infrastructure in microgrids with diverse uncertainties based on demand response, renewable energy sources and two-stage parallel optimization algorithm},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A storage-efficient SNN–CNN hybrid network with
RRAM-implemented weights for traffic signs recognition. <em>EAAI</em>,
<em>123</em>, 106232. (<a
href="https://doi.org/10.1016/j.engappai.2023.106232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic Signs Recognition (TSR) is a key technology to implement Automatic Driving System (ADS) and Advanced Driver Assistant System (ADAS). Numerous efforts have been endeavored to improve the TSR accuracy and speed, and Convolution Neural Networks (CNN) are usually employed. However, most of the existing works require large network scale and thus suffer from the drawback of high computation and power consumption. To alleviate this issue, in this paper, we propose an SNN–CNN hybrid network with RRAM-implemented weights to improve the storage and computing efficiency of TSR. Specifically, we utilize SNN to quickly determine the superclass that a traffic sign belongs to. Then utilize CNNs to determine the subclass accurately, thus the complex TSR task is decomposed into multiple simple tasks. Finally, the network weights are binarized to alleviate the implementation of the hybrid network on RRAM-based accelerators, which have higher power efficiency than CMOS logic based ones. Experimental results indicate that, when compared with state of the art CNN method, the SNN–CNN hybrid network can achieve similar accuracy with less weight scale (−69.21%) and lower power consumption (−81.55%). Binarizing the hybrid network can further reduce the weights storage requirement by another 96.875% with only 1.518% accuracy loss. When the network weights are implemented with state of the art RRAM array (resistance variation is 5%), the proposed network can achieve a mean accuracy of 96.47% with 95% ∼ 97.5% confidence interval.},
  archive      = {J_EAAI},
  author       = {Yufei Zhang and Hui Xu and Lixing Huang and Changlin Chen},
  doi          = {10.1016/j.engappai.2023.106232},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106232},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A storage-efficient SNN–CNN hybrid network with RRAM-implemented weights for traffic signs recognition},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When content-centric networking meets multi-criteria group
decision-making: Optimal cache placement policy achieved by MARCOS with
q-rung orthopair fuzzy set pair analysis. <em>EAAI</em>, <em>123</em>,
106231. (<a
href="https://doi.org/10.1016/j.engappai.2023.106231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the cache placement policy (CPP) is a crucial step in the deployment process of content-centric networking (CCN), which is still an open question. In this paper, assessing the CPP is formulated to be a multi-criteria group decision-making (MCGDM) issue since it involves the consideration of multiple experts, and a new aggregated MCGDM algorithm is presented for dealing with this issue. On that account, an assessment criteria system is to formulate to portray these experts’ considerations for assessing CPPs, and then the concepts of q-rung orthopair fuzzy set (q-ROFS) and set pair analysis (SPA) are presented to directly and indirectly define the group preference information of CPPs with respect to the criteria, respectively. Later, some revised aggregation operators are employed for aggregating the group preference information. Then, a new integrated objective criteria weights (IOCW) method based on score value and combined criteria weights based on non-linear comprehensive method are given for determining the important degrees of criteria. Based on IOCW method, non-linear comprehensive method, score function, distance measure, and aggregation operators, a new integrated q-rung orthopair fuzzy MCGDM model based on MARCOS (Measurement of Alternatives and Ranking according to COmpromise Solution) method is developed to rank CPPs. Finally, an example is given to illustrate the evaluation process of CPP, and the advantages of developed method are verified by comparative analysis.},
  archive      = {J_EAAI},
  author       = {Xindong Peng and Harish Garg and Zhigang Luo},
  doi          = {10.1016/j.engappai.2023.106231},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106231},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {When content-centric networking meets multi-criteria group decision-making: Optimal cache placement policy achieved by MARCOS with q-rung orthopair fuzzy set pair analysis},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A q-learning artificial bee colony for distributed assembly
flow shop scheduling with factory eligibility, transportation capacity
and setup time. <em>EAAI</em>, <em>123</em>, 106230. (<a
href="https://doi.org/10.1016/j.engappai.2023.106230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed assembly flow shop scheduling problem (DAFSP) has been considered; however, DAFSP with factory eligibility,transportation capacity and setup time is seldom studied even though these three constraints often exist simultaneously in real-life multi-factory assembly production processes. In this study, DAFSP with P m → 1 layout, factory eligibility, transportation capacity and setup time is proposed and a Q-learning artificial bee colony (Q-LABC) is presented to minimize both makespan and total tardiness. A heuristic is designed to produce initial solution. In employed bee phase, factory set based heuristic is developed, population is divided into two parts by non-dominated sorting and two global search operators are applied in two parts respectively. A Q-learning algorithm has a fixed Q-table when a given condition is met, and is used to dynamically decide the way of selecting food source and the number of the selected food source for onlooker bee. Extensive experiments on 90 instances are conducted to show the effectiveness of new strategies and compare Q-LABC with two comparative algorithms. The computational results demonstrate that the new strategies of Q-LABC are effective and Q-LABC performs better than its comparative algorithms on at least 83.33% and 94.44% instances, respectively.},
  archive      = {J_EAAI},
  author       = {Jing Wang and Hongtao Tang and Deming Lei},
  doi          = {10.1016/j.engappai.2023.106230},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106230},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A Q-learning artificial bee colony for distributed assembly flow shop scheduling with factory eligibility, transportation capacity and setup time},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent based scheduling method for tandem automated
guided vehicle systems. <em>EAAI</em>, <em>123</em>, 106229. (<a
href="https://doi.org/10.1016/j.engappai.2023.106229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the scheduling method that allows to minimize the traveling time of a AGV (and thus energy consumption) at each of zones, while to minimize the waiting time of the automated guided vehicles (AGVs) and/or containers for pickup and delivery (PD) at the transfer points (TPs) installed between adjacent zones in tandem systems. Scheduling for these tandem AGV systems is often not possible from a single point by a single intelligent agent. Intead, scheduling has to be performed using multiple intelligent agents. We consider the cooperative multi-agent scheduling (CMAS) scheme in which each agent employs a multi-offspring genetic algorithm. Coordination between the agents is used to improve their schedulings. This coordination can be in the form of serial scheme. We propose a novel CMAS method based on Lagrange theory and compare this to a non-cooperative scheduling approach between agents. The proposed method is verified at AGV system for a book printing process in Pyongyang Textbook Print Shop as the real-world experiment and it is shown that the CMAS method for tandem AGV system is effective.},
  archive      = {J_EAAI},
  author       = {Ji Chol and Cha Ryong Gun},
  doi          = {10.1016/j.engappai.2023.106229},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106229},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-agent based scheduling method for tandem automated guided vehicle systems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal production scheduling with multi-round information
interaction for demander-dominated decentralized scheduling problem.
<em>EAAI</em>, <em>123</em>, 106228. (<a
href="https://doi.org/10.1016/j.engappai.2023.106228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demander-dominated market scenarios are becoming increasingly common owing to the emergence of alternative service providers and competitive market environment. However, these scenarios have not been considered in previous studies pertaining to decentralized scheduling problems. Thus, service providers cannot formulate optimal production scheduling schemes for such scenarios. In this study, we investigate a demander-dominated decentralized scheduling problem in which the demander can adopt the private-strategic behavior of transferring partial orders towards its alternative service providers. The aim of this study is to provide guidance to service providers for developing high-quality production scheduling solutions under asymmetric information. First, we design a multi-round information interaction mechanism with a learning strategy to realize information interaction. Subsequently, a metaheuristic algorithm termed MAM is developed based on the multi-round information interaction mechanism to solve the proposed problem. A problem-dependent initialization method and a solution generation method integrating the learning strategy are developed to improve the search efficiency. Experimental results indicate the usefulness of the initialization method and learning strategy. Based on a comparison with two well-established adapted algorithms, the effectiveness of the proposed algorithm is confirmed, particularly for instances with loose due dates. Furthermore, we analyze the effect of MAM on both the service provider and the demander by comparing it with traditional centralized approaches. Statistical results show that the proposed algorithm yields high-quality solutions for the service provider and that maintaining the confidentiality of private information is conducive to the demander, particularly when the due dates are tight.},
  archive      = {J_EAAI},
  author       = {Like Zhang and Qianwang Deng and Xiaoyu Wen and Yan Zhao and Guiliang Gong},
  doi          = {10.1016/j.engappai.2023.106228},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106228},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal production scheduling with multi-round information interaction for demander-dominated decentralized scheduling problem},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extracting geometric and semantic point cloud features with
gateway attention for accurate 3D object detection. <em>EAAI</em>,
<em>123</em>, 106227. (<a
href="https://doi.org/10.1016/j.engappai.2023.106227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection using point clouds has received a lot of attention in autonomous vehicles, robotics, and virtual reality. However, feature learning for 3D object detection from point cloud is very challenging due to the irregularity and sparsity of 3D point cloud data. Grid-based methods convert irregular point clouds into regular 2D views or 3D voxels and then use 2D CNN or 3D CNN for feature learning, but the point cloud transformation process will inevitably cause quantization loss. Point-based methods use the PointNet network to directly learn the features of the point cloud, but the semantic information obtained by PointNet may be incomplete. To address the above issues, we propose a novel Gateway Attention-based Point Set Abstraction 3D object detector (GAPSA) to learn geometric and semantic point cloud features. Specifically, the framework utilizes set abstraction downsampling points and performs local feature extraction on the sampling points through the proposed gateway attention pooling module to learn more discriminative point cloud features. Given the high-quality 3D proposals generated by attention-based backbone networks, we design a RoI multi-pooling head to adaptively learn features for sparse points of interest within proposals, so as to encode richer contextual information and obtain fine-grained features to accurately estimate object confidence and location. Compared with advanced point-based 3D object detectors, experimental results demonstrate that our attention-based point set abstraction 3D object detector has the best detection performance on KITTI and NuScenes datasets. The code is available at https://github.com/liuhuaijjin/GAPSA .},
  archive      = {J_EAAI},
  author       = {Huaijin Liu and Jixiang Du and Yong Zhang and Hongbo Zhang},
  doi          = {10.1016/j.engappai.2023.106227},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106227},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Extracting geometric and semantic point cloud features with gateway attention for accurate 3D object detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model predictive control when utilizing LSTM as dynamic
models. <em>EAAI</em>, <em>123</em>, 106226. (<a
href="https://doi.org/10.1016/j.engappai.2023.106226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction model is the most important part of an MPC strategy. The accuracy of such a model influences the quality of predictions and control performance of the algorithm. In some practical cases, a model based on physical equations is not available, or is not easy to get all parameters, or its complexity could affect the real-time computation of the control signal. For this reason, the use of black-box models within a MPC framework becomes attractive, since to fit such models only input and output data are needed. Questions like: “Is it possible to use LSTM’s as predictors?” , “How to implement it?” , “What is the best way to compute derivatives?” , “Which solvers and tools are recommendable?” , “How to ensure the real-time capability?” are discussed in this work.},
  archive      = {J_EAAI},
  author       = {Marvin Jung and Paulo Renato da Costa Mendes and Magnus Önnheim and Emil Gustavsson},
  doi          = {10.1016/j.engappai.2023.106226},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106226},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Model predictive control when utilizing LSTM as dynamic models},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ranking teaching–learning-based optimization algorithm to
estimate the parameters of solar models. <em>EAAI</em>, <em>123</em>,
106225. (<a
href="https://doi.org/10.1016/j.engappai.2023.106225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most promising renewable energies, solar energy can be converted to electricity through photovoltaic (PV) systems. It is indispensable to identify the parameters of PV systems with the aim of controlling and simulating. Thanks to the complexity of PV systems, parameter identification is still a challenging task. In this paper, we develop a Ranking Teaching–Learning-Based​ Optimization (RTLBO) to solve the problem, in which Teaching–Learning-Based​ Optimization (TLBO) is a population-based swarm algorithm and mimics the learning process in a classroom. RTLBO ranks learners into superior and inferior groups, in which the outstanding learners learn from the top three agents to boost the local search. In contrast, the low learners learn from each other by guidance. The two phases are in parallel to balance the local and global search. The proposed RTLBO is used to extract parameters of different models, including the single diode model, double diode model and three PV module models. TLBO, four TLBO variants, and fifteen meta-heuristic algorithms are selected as the rivals of RTLBO. Several experiments have shown that our method is a reliable and effective algorithm when addressing the parameters of PV systems.},
  archive      = {J_EAAI},
  author       = {Xiaobing Yu and Zhengpeng Hu and Xuming Wang and Wenguan Luo},
  doi          = {10.1016/j.engappai.2023.106225},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106225},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ranking teaching–learning-based optimization algorithm to estimate the parameters of solar models},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bubble detection in photoresist with small samples based on
GAN augmentations and modified YOLO. <em>EAAI</em>, <em>123</em>,
106224. (<a
href="https://doi.org/10.1016/j.engappai.2023.106224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoresist coating is a key procedure in semiconductor wafer surface processing, and bubbles in a photoresist dropper usually affect the uniformity of photoresist film, which seriously reduces the etching quality of semiconductor wafer surface. However, the problems of blurred edges of photoresist bubbles and complex corrugations in photoresist itself make the automatic detection of photoresist bubbles very challenging. To overcome this problem, a high-precision photoresist bubble detection method based on deep learning is proposed in this paper. First, aiming at the problem that the photoresist bubble samples are extremely lacking and cannot meet the requirement of deep learning model training, this paper proposes a sample automatic generator bubbleGAN based on the adversarial generative network, so as to effectively increase the number of photoresist bubble samples with better diversity of the target to be detected, thus improving the performance of the detection model; Second, aiming at the challenges of target detection caused by the blurred edges of photoresist bubbles and the complex ripples of photoresist itself, this paper proposes a novel bubble detection method mYOLO. Based on the recently developed high-performance target detection method YOLOX, we optimize its structure and activation function to reduce the difficulty of model training, solve the dead zone problem of activation function, and improve the accuracy of model detection. The experimental results on the dataset collected by the actual rotary coating machine prove the effectiveness of the proposed algorithm. In addition, we further compare the impact of different manual data augmentation methods on the detection model.},
  archive      = {J_EAAI},
  author       = {Guang Yang and Chunhe Song and Zhijia Yang and Shuping Cui},
  doi          = {10.1016/j.engappai.2023.106224},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106224},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bubble detection in photoresist with small samples based on GAN augmentations and modified YOLO},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Object detection in hospital facilities: A comprehensive
dataset and performance evaluation. <em>EAAI</em>, <em>123</em>, 106223.
(<a href="https://doi.org/10.1016/j.engappai.2023.106223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting objects in hospital indoor environments is critical for scene understanding and can have various applications in healthcare. Deep learning algorithms have proven to be effective in object recognition from images or videos, but the availability of annotated datasets plays a crucial role in their successful application. However, there is a shortage of datasets for object detection in hospital settings, hindering the advancement of hospital indoor object detection algorithms. In this paper, we present the Hospital Indoor Object Detection (HIOD) dataset, consisting of 4,417 images covering 56 object categories. The HIOD dataset represents the frequently encountered objects in hospitals and comprises 51,869 annotated objects. The dataset is characterized by dense annotation, with an average of 11.7 objects and 6.8 object categories per image. An object detection benchmark was established using the HIOD dataset and eight state-of-the-art object detectors. The benchmark provides a comprehensive evaluation of the performance of the selected object detectors on a large and diverse set of images of objects commonly seen in hospital environments. The results of the benchmark can be used to compare and analyze the performance of different object detectors and identify their strengths and weaknesses for use in hospital environments. In the benchmark, one-stage detectors have shown superior performance compared to two-stage detectors of similar parameter sizes. In particular, YOLOv6-L was able to attain a mean Average Precision (mAP) of 51.7% while operating at a detection speed of 255 FPS. The benchmark and dataset can serve as a valuable resource for researchers and practitioners in the field of computer vision and robotics, helping to advance the development of more effective and efficient object detection algorithms for developing automated operations in hospitals such as robotic disinfection and patient assistance.},
  archive      = {J_EAAI},
  author       = {Da Hu and Shuai Li and Mengjun Wang},
  doi          = {10.1016/j.engappai.2023.106223},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106223},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Object detection in hospital facilities: A comprehensive dataset and performance evaluation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MLOps in freight rail operations. <em>EAAI</em>,
<em>123</em>, 106222. (<a
href="https://doi.org/10.1016/j.engappai.2023.106222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railways are essential for freight transport due to their operational reliability advantages, but maintaining this advantage requires optimised railway infrastructure. Previous research has developed models to predict freight rail disruptions/disturbances and their associated delay times, in order to better understand the impact of multiple factors on them. However, because these models are built on static datasets, extracting real value from a model in a production environment remains difficult. This paper presents a methodology that demonstrates the potential of MLOps in automating the entire workflow, from data extraction to model deployment for real-time delay predictions in freight rail operations, including good practices of Continuous-Integration, Continuous-Delivery, and Continuous-Training, as well as a tool list for each process. Our research advances the field of railway operations by developing an entire MLOps workflow using data from the freight rail operations of the Luxembourgish National Freight Railway Company over a seventeen-month period. Furthermore, we employed a LightGBM model that had previously performed well in another study. This workflow can be automatically triggered to develop the processes and thus maintain an ML model capable of predicting delay times for CFL Multimodal operations in real-time. Our findings demonstrate that MLOps have the potential to automate the entire process, opening up new avenues for future research in this field. Although the methodology presented is intended to optimise freight rail operations for a specific company, it can be easily transferable to other railway companies or other transportation industries, such as aviation, shipping, and trucking.},
  archive      = {J_EAAI},
  author       = {Juan Pineda-Jaramillo and Francesco Viti},
  doi          = {10.1016/j.engappai.2023.106222},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106222},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MLOps in freight rail operations},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequent pattern mining-based log file partition for process
mining. <em>EAAI</em>, <em>123</em>, 106221. (<a
href="https://doi.org/10.1016/j.engappai.2023.106221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining is a technique for exploring models based on event sequences, growing in popularity in the process industry. Process mining algorithms assume that the processed log files contain events generated by only one unknown process, which can lead to extremely complex and inaccurate models when this assumption is not met. To address this issue, this article proposes a frequent pattern mining-based method for log file partitioning, allowing for the exploration of parallel processes. The key idea is that frequent pattern mining can identify grouped events and generate sub-logs of overlapping sub-processes. Thanks to the pre-processing of the log files, more compact and interpretable process models can be identified. We developed a set of goal-oriented metrics to evaluate the complexity of process mining problems and the resulting models. The applicability and effectiveness of the method are demonstrated in the analysis of process alarms of an industrial plant. The results confirm that the proposed method enables the discovery of targeted sub-process models by partitioning the log file using frequent pattern mining, and the effectiveness of the method increases with the number of parallel processes stored in the same log file. We recommend applying the method in every case where there is no clear start and end of the logged events so that the log file can describe different processes.},
  archive      = {J_EAAI},
  author       = {László Bántay and János Abonyi},
  doi          = {10.1016/j.engappai.2023.106221},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106221},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Frequent pattern mining-based log file partition for process mining},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning asymmetric encryption using adversarial neural
networks. <em>EAAI</em>, <em>123</em>, 106220. (<a
href="https://doi.org/10.1016/j.engappai.2023.106220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a multi-agent adversarial neural networks model where a sender (Alice) and a receiver (Bob) are able to learn to use a pair of public/private keys in order to protect their communication from one or more attackers/eavesdroppers. Existing work in the field required shared symmetric information between Alice and Bob before initiating the training process. To the best of our knowledge, this is the first work in which Alice and Bob with asymmetric information can train themselves to protect their communication. Our initial model setup contains five agents: sender Alice, receiver Bob, eavesdropper Eve and two neural networks (we call them public keys generator and private keys generator) that, based on a (secret) random noise from Bob, will generate a pair of public/private keys that allows Alice to encrypt a message with the public key and Bob to decrypt the message with the private key while preventing Eve from decrypting the secret message using the public key. We show that the neural networks are able to establish a communication and secure it from Eve. Finally, we consider adversaries stronger than Eve to model leakage attacks, chosen plaintext attacks (CPA) and test the distinguishability between ciphertexts. The last three experiments show that neural networks (with asymmetric information) can secure the communication providing stronger security guarantees and resilience to leakage attacks which may include leakage from the private key.},
  archive      = {J_EAAI},
  author       = {Ishak Meraouche and Sabyasachi Dutta and Haowen Tan and Kouichi Sakurai},
  doi          = {10.1016/j.engappai.2023.106220},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106220},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning asymmetric encryption using adversarial neural networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural age screening on question answering communities.
<em>EAAI</em>, <em>123</em>, 106219. (<a
href="https://doi.org/10.1016/j.engappai.2023.106219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For online social networks, demographic analysis is absolutely essential for improving their services in many ways. It is instrumental in understanding their different audiences, members and competitors. As well as that, it is pivotal in designing effective personalization and contextualization strategies, especially for displaying and creating better content. There is, for this reason, a great bulk of research into how demographic variables are characterized and how they impact online platforms such as Facebook and Twitter. But surprisingly, only a handful of works delve into their characterization and effect on community Question-Answering (cQA) websites. In this particular context, the subject of age demographics remains largely unexplored. This paper takes the lead on interpreting automatic age recognition on CQAs (a.k.a. age screening) as a regression task. To this effect, it compares state-of-the-art graph-based neural network regression and embedding models on a massive activity-graph encompassing ca. 16 and 837 million nodes (members) and edges, respectively. For this study, a large-scale subset of ca. 657,000 community fellows was automatically associated with their age via aligning their profile texts with a limited number of linguistic patterns. In short, our results show that Node2vec significantly outperforms other embeddings regardless of the regression model used for casting predictions. When this embedding is combined with Artificial Neural Network Regressions, we obtained our best configuration scoring a Root Mean Square Error (RMSE) of 8.39. An interesting qualitative feature of this embedding space is that age-based centroid vectors tend to form a trail ordered by age. Lastly, our outcomes also signal that activity graph based models can rival its counterparts based on image and textual inputs, paving the way for constructing effective multi-modal approaches.},
  archive      = {J_EAAI},
  author       = {Mohan Timilsina and Alejandro Figueroa},
  doi          = {10.1016/j.engappai.2023.106219},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106219},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural age screening on question answering communities},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). DR-CapsNet with CAEMRA: Looking deep inside instance for
boosting object detection effect. <em>EAAI</em>, <em>123</em>, 106218.
(<a href="https://doi.org/10.1016/j.engappai.2023.106218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capsule Network (CapsNet) has shown better representability especially in the parsing of part-whole correlation which is indispensable for object detection. However, since low-level capsules vote in favor of every high-level capsule irrespective of their interrelationship, such blindly fully-connected routing manner is at the risk of misassignments. In fact, the higher the relevancy of capsules across two consecutive layers, the higher the likelihood of being routed together. Inspired by this, we propose to steer capsule assignment by employing such correlations to constrain the bottom-up voting scope, hoping the ”fragile” votes are eliminated. We formula such pipeline as a Dual-Restricted Capsule Network (DR-CapsNet) with Correlation-Aware Expectation–Maximum​ Routing-by-Agreement (CAEMRA) for boosting object detection effect. Four constraints, dubbed Intra-Object Cohesiveness Quantification (IOCQ), Part Backtracking (PB), Vote Screening (VS), and Feature Correlation Reevaluation (FCR), are customized and embedded into CAEMRA to restrain the voting scope. They stipulate that only these primary capsules (representing components) meeting the criteria of both internal consistency and external association are permissible to update entity capsules (representing the whole/composites). As a result, the capsule assignment is achieved by routing highly correlated capsules during bottom-up ”part backtracking” procedure, whilst the part-object relationships among captured entities are refined for object detection. CAEMRA enables high-level capsules to optionally aggregate projection from non-spatially-fixed sets of low-level capsules. Quantitative and ablation verifications on VOC2007, VOC2012, OICOD18, ILSVRC17, and COCO18 reveal the superiority of DR-CapsNet over the state-of-the-art models.},
  archive      = {J_EAAI},
  author       = {Zhongqi Lin and Zengwei Zheng and Jingdun Jia and Wanlin Gao and Feng Huang},
  doi          = {10.1016/j.engappai.2023.106218},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106218},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DR-CapsNet with CAEMRA: Looking deep inside instance for boosting object detection effect},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight object detection algorithm for robots with
improved YOLOv5. <em>EAAI</em>, <em>123</em>, 106217. (<a
href="https://doi.org/10.1016/j.engappai.2023.106217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot object detection is important for the realisation of robot intelligence. Currently, deep learning-based object detection algorithms are used for robotic object detection. However, it faces some challenges in practical applications, such as the fact that robots frequently use resource-constrained devices, resulting in detection algorithms with long computation times and undesired detection rates. In order to address these concerns, this paper proposes a lightweight object detection algorithm for robots with an improved YOLOv5. To reduce the amount of processing required for feature extraction and increase the speed of detection, the C3Ghost and GhostConv modules have been introduced into the YOLOv5 backbone. The DWConv module was used in conjunction with the C3Ghost module in the YOLOv5 neck network to further reduce the number of model parameters and maintain accuracy. The CA (Coordinated Attention) module is also introduced to improve the extraction of features from detected objects and suppress irrelevant features, thus improving the algorithm’s detection accuracy. To verify the performance of the method, we tested it with a self-built dataset (4561 robot images in total) and the PascalVOC dataset respectively. The results show that compared with the YOLOv5s on the self-built dataset, the algorithm has a 54% decrease in FLOPs and a 52.53% decrease in the number of model parameters without a decrease in mAP (0.5). The effectiveness and superiority of the algorithm is demonstrated through case studies and comparisons.},
  archive      = {J_EAAI},
  author       = {Gang Liu and Yanxin Hu and Zhiyu Chen and Jianwei Guo and Peng Ni},
  doi          = {10.1016/j.engappai.2023.106217},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106217},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight object detection algorithm for robots with improved YOLOv5},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Super-resolution network with dynamic cleanup and
temporal–spatial attention for compressed videos. <em>EAAI</em>,
<em>123</em>, 106216. (<a
href="https://doi.org/10.1016/j.engappai.2023.106216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video super-resolution methods focus on restoring high-resolution video frames from low-resolution videos with pre-defined degradations, and few consider compression. However, the videos on the Internet are compressed to reduce the massive size of video data. Thus, they also contain visual noises and artifacts due to the lossy compression. In this paper, we propose a video super-resolution model specific for compressed videos to suppress artifacts and restore high-resolution contents. We propose a two-stage super-resolution network for compressed videos that contains three new modules: cleanup and local alignment in the first stage, 3D-convolution temporal–spatial attention in the second stage. Specifically, the cleanup module is designed in stage-1 to suppress the artifacts and noises of low-quality inputs. The subsequent local alignment is designed to aggregate adjacent frames to maintain high-frequency details. The 3D-convolution attention is used in stage-2 to refine the weights of the feature maps. In addition, we propose the new CrfVideos dataset to facilitate fair comparisons, containing HEVC/H.265 compressed videos of different compression levels. Extensive experiments substantiate that our method outperforms state-of-the-art methods on the HEVC/H.265 compressed benchmark with medium to high compression rates by 0.3–0.7 dB in terms of PSNR and exceeds state-of-the-art methods on benchmark Vid4 by 0.2–0.8 dB. The code will be released at https://github.com/cvygkhv/decompression .},
  archive      = {J_EAAI},
  author       = {Guoping Li and Zhenting Zhou and Xiwu Shang and Guozhong Wang},
  doi          = {10.1016/j.engappai.2023.106216},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106216},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Super-resolution network with dynamic cleanup and temporal–spatial attention for compressed videos},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive dynamic multi-swarm particle swarm optimization
with stagnation detection and spatial exclusion for solving continuous
optimization problems. <em>EAAI</em>, <em>123</em>, 106215. (<a
href="https://doi.org/10.1016/j.engappai.2023.106215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is a simple and efficient optimization method that has been used in many fields. However, PSO has some flaws including premature convergence and poor population diversity. To solve these problems of PSO, an adaptive dynamic multi-swarm particle swarm optimization with stagnation detection and spatial exclusion (ADPSO) is proposed. The newly proposed ADPSO is based on a dynamic multi-swarm PSO framework that cooperates with stagnation detection mechanism (SDM) and spatial exclusion strategy (SES). Firstly, the whole population is divided into multiple equal sub-swarms, which can be regrouped during evolution. The best particle of each sub-swarm, lbest , is used to evaluate the evolutionary state of each sub-swarm. If the lbest cannot improve its solution continuously without reaching the regroup period, the SDM will be triggered. In this case, a vitality particle is generated to help the stagnant sub-swarm to search for promising areas again. To keep the population diversity, the vitality particle is constructed according to the excellent historical information of all particles in the whole population. Secondly, to enhance the diversity of the population, the SES is proposed to avoid premature adsorption of all sub-swarms. Finally, the effect of ADPSO is evaluated using CEC2013, CEC2017 and four engineering optimization problems. The results shows that the proposed ADPSO is suitable for solving most optimization problems, and ADPSO has better results compared to the state-of-the-art PSO variants (i.e., MSCPSO, HCDMPS) and other popular evolutionary algorithms.},
  archive      = {J_EAAI},
  author       = {Xu Yang and Hongru Li and Youhe Huang},
  doi          = {10.1016/j.engappai.2023.106215},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106215},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive dynamic multi-swarm particle swarm optimization with stagnation detection and spatial exclusion for solving continuous optimization problems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient parameter tuning of neural foundation models for
drug perspective prediction from unstructured socio-medical data.
<em>EAAI</em>, <em>123</em>, 106214. (<a
href="https://doi.org/10.1016/j.engappai.2023.106214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenal popularity of social media platforms over the past decade has accelerated the development of intelligent applications that leverage social media data for informed decision-making in diverse domains like finance, education, public policy and healthcare management practices. While understanding the colloquial language of users on social media remains a challenging problem, access to users’ medical perspectives that conversationally divulge healthcare-related experiences and insights can help reshape healthcare ecosystems like chronic disease management, pandemics, public health, pharmacovigilance and more. Most existing models are constrained to a particular dataset while neglecting model adaptability across data sources and domains. Model generalization across variable data sizes also has received very little research attention. Conventional foundation models can be fine-tuned by adding additional model heads or by appending contributing network layers, however, there has been very little focus on effective parameter calibration for adapting neural foundation models to a specific task. In this study, an Adaptive Learning mechanism for Socio-Medical data (AL4SM) built on generic foundation neural models with efficient parameter learning is proposed, to categorize users’ perspectives on prescription drug-related experiences and adapt to diverse socio-medical data sources of variable sizes. AL4SM aims to lighten the over-parameterized mechanisms adopted by existing foundational techniques by efficiently learning latent medical information based on optimized parameter calibration and weight reinitialization techniques. Comprehensive cross-domain and cross-data analyses are undertaken to explore specific user perspectives related to prescription effectiveness and side effects. Validation experiments conducted on standard datasets obtained from Drugs.com and Druglib.com revealed that the proposed AL4SM outperformed state-of-the-art models, achieving an improvement of 6.06% in accuracy and 7.62% in F1-score for 3-class and 2% in F1-score for 10-class drug perspective categorization. The cross-data experiments further emphasized the superiority of the proposed model, with improved accuracy of 17% on Drugs.com and 9% on Druglib.com datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Reshma Unnikrishnan and Sowmya Kamath S. and Ananthanarayana V.S.},
  doi          = {10.1016/j.engappai.2023.106214},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106214},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient parameter tuning of neural foundation models for drug perspective prediction from unstructured socio-medical data},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MFBGR: Multi-scale feature boundary graph reasoning network
for polyp segmentation. <em>EAAI</em>, <em>123</em>, 106213. (<a
href="https://doi.org/10.1016/j.engappai.2023.106213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, adding Transformer to CNN has promoted the rapid development of colorectal polyp image processing. However, from the perspective of multi-scale feature interaction and boundary coherence, there are mainly some limitations: (1) ignore the local and global correlation within the scale feature, which may cause the missed detection of tiny polyps, (2) lack of multi-scale features to explore the target region, which hinders the learning of multi-variant polyps, and (3) the semantic connection between the target area and the boundary is ignored, cause incoherent segmentation boundaries. In this regard, we design a multi-scale feature boundary graph inference network for polyp segmentation, namely MFBGR. First, the Transformer block captures local–global cues inside the multi-scale information learned by the CNN branches. Second, for the multi-scale global information generated by the Transformer block, we design a cross-scale feature fusion module (CSFM). CSFM performs scale-variation interaction and cascaded fusion to capture the correlation between features across scales and solve the scale-variation problem of segmented objects. Finally, the traditional boundary refinement or enhancement idea is generalized to the graph convolutional reasoning layer (BGRM). BGRM receives CNN’s low-level feature information and CSFM’s fusion features, or intermediate prediction results, and propagates cross-domain feature information between graph vertices, explores information between target regions and boundary regions, and achieves more accurate boundary segmentation. On the CVC-300, CVC-ClinicDB, CVC-ColonDB, Kvasir-SEG, ETIS datasets, MFBGR and mainstream polyp segmentation networks were compared and tested. MFBGR achieved good results, and Dice, IOU, BAcc, and Haudo were the best. The values reached 94.16%, 89.35% and 97.42%, 3.7442, and the segmentation accuracy of colorectal polyp images has been improved to a certain extent.},
  archive      = {J_EAAI},
  author       = {Fangjin Liu and Zhen Hua and Jinjiang Li and Linwei Fan},
  doi          = {10.1016/j.engappai.2023.106213},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106213},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MFBGR: Multi-scale feature boundary graph reasoning network for polyp segmentation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Document-level relation extraction with multi-layer
heterogeneous graph attention network. <em>EAAI</em>, <em>123</em>,
106212. (<a
href="https://doi.org/10.1016/j.engappai.2023.106212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction is an essential task in natural language understanding and requires the ability to fully learn different representations of entities and multi-hop reasoning across multiple sentences. Most existing methods use graph neural networks to extract multi-hop relations. They only focus on the role of edge types and ignore node types when obtaining node representations. In addition, it is difficult for them to adequately capture the complex interactions in a document when converting a document into a graph. These problems will affect the performance of relation extraction. To solve the above problems, this paper proposes a document-level relation extraction model based on a multi-layer heterogeneous graph neural network (MHGNN). Different from previous methods that only focus on edge types between two nodes, a node type and edge type oriented heterogeneous graph attention network (NEHGAN) is proposed to further learn rich node representations. In addition, the model constructs three graphs, namely a word-level graph, a mention-level graph and an entity-level graph, for capturing the complex interactions between words, between mentions and between entities in the whole document. Experimental results demonstrate that MHGNN can effectively improve the performance of document-level relation extraction, and outperforms the state-of-the-art model by 1.04%, 1.03%, 1.69% and 0.6% in F1 on the development set and the test set of two public datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Nianbin Wang and Tiantian Chen and Chaoqi Ren and Hongbin Wang},
  doi          = {10.1016/j.engappai.2023.106212},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106212},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Document-level relation extraction with multi-layer heterogeneous graph attention network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization of the model predictive control meta-parameters
through reinforcement learning. <em>EAAI</em>, <em>123</em>, 106211. (<a
href="https://doi.org/10.1016/j.engappai.2023.106211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model predictive control (MPC) is increasingly being considered for control of fast systems and embedded applications. However, MPC has some significant challenges for such systems, such as its high computational complexity. Further, the MPC parameters must be tuned, which is largely a trial-and-error process that affects the control performance, the robustness, and the computational complexity of the controller to a high degree. This paper presents a multivariate optimization method based on reinforcement learning (RL) that automatically tunes the control algorithm’s parameters from data to achieve optimal closed-loop performance. The main contribution of our method is the inclusion of state-dependent optimization of the meta-parameters of MPC, i.e. parameters that are non-differentiable wrt. the MPC solution. Our control algorithm is based on an event-triggered MPC, where we learn when the MPC should be re-computed, and a dual-mode MPC and linear state feedback control law applied in between MPC computations. We formulate a novel mixture-distribution RL policy determining the meta-parameters of our control algorithm and show that with joint optimization we achieve improvements that do not present themselves with univariate optimization of the same parameters. We demonstrate our framework on the inverted pendulum control task, reducing the total computation time of the control system by 36% while also improving the control performance by 18.4%.},
  archive      = {J_EAAI},
  author       = {Eivind Bøhn and Sebastien Gros and Signe Moe and Tor Arne Johansen},
  doi          = {10.1016/j.engappai.2023.106211},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106211},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization of the model predictive control meta-parameters through reinforcement learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Investigating the best automatic programming method in
predicting the aerodynamic characteristics of wind turbine blade.
<em>EAAI</em>, <em>123</em>, 106210. (<a
href="https://doi.org/10.1016/j.engappai.2023.106210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic programming (AP) is a subfield of artificial intelligence (AI) that can automatically generate computer programs and solve complex engineering problems. This paper presents the accuracy of four different AP methods in predicting the aerodynamic coefficients and power efficiency of the AH 93-W-145 wind turbine blade at different Reynolds numbers and angles of attack. For the first time in the literature, Genetic Programming (GP) and Artificial Bee Colony Programming (ABCP) methods are used for such predictions. In addition, Airfoil Tools and JavaFoil are utilized for airfoil selection and dataset generation. The Reynolds number and angle of attack of the wind turbine airfoil are input parameters, while the coefficients C L , C D and power efficiency are output parameters. The results show that while all four methods tested in the study accurately predict the aerodynamic coefficients, Multi Gene GP (MGGP) method achieves the highest accuracy for R Train 2 and R Test 2 ( R 2 values in C D Train: 0.997-Test: 0.994, in C L Train: 0.991-Test: 0.990, in P E Train: 0.990-Test: 0.970). By providing the most precise model for properly predicting the aerodynamic performance of higher cambered wind turbine airfoils, this innovative and comprehensive study will close a research gap. This will make a significant contribution to the field of AI and aerodynamics research without experimental cost, labor, and additional time.},
  archive      = {J_EAAI},
  author       = {Sibel Arslan and Kemal Koca},
  doi          = {10.1016/j.engappai.2023.106210},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106210},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Investigating the best automatic programming method in predicting the aerodynamic characteristics of wind turbine blade},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced tensor multi-view clustering via dual constraints.
<em>EAAI</em>, <em>123</em>, 106209. (<a
href="https://doi.org/10.1016/j.engappai.2023.106209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is to divide data into distinct clusters according to their different features. Tensor-based multi-view clustering can capture higher order connections between various views for better clustering results. However, they have limitations: (1) the higher-order local geometric structure in non-linear subspaces is not considered; (2) significant differences in singular values are not reflected. To resolve the above issues, we introduce a novel method called Enhanced Tensor Multi-view Clustering via Dual Constraints(ETMC-DC). ETMC-DC utilizes Hyper-Laplacian regularization to maintain higher-order local geometric structure in the raw space. The Schatten-p norm is used to the tensor stacked by the obtained affinity matrix to process unequal singular values, and larger singular values carry more structural information, and vice versa. Moreover, the complexity of the model is reduced by the rotation of the tensors constructed from Markov transition probabilities. Finally, an iterative update technique is used for optimizing the presented ETMC-DC. We have conducted extensive experiments on real-world datasets in various forms to demonstrate that ETMC-DC can perform exceptionally well in comparison to other multi-view clustering approaches.},
  archive      = {J_EAAI},
  author       = {Wenzhe Liu and Luyao Liu and Yong Zhang and Lin Feng},
  doi          = {10.1016/j.engappai.2023.106209},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106209},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced tensor multi-view clustering via dual constraints},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Operating performance assessment method for industrial
process with slowness principle-based LSTM network. <em>EAAI</em>,
<em>123</em>, 106208. (<a
href="https://doi.org/10.1016/j.engappai.2023.106208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and accurate performance assessment and non-optimal regulation of industrial processes can effectively guarantee product quality. Most industrial processes are highly nonlinear and dynamic, so long short-term memory (LSTM) network is suitable for industrial performance assessment. However, in the network learning, the typical LSTM network focuses on the representation learning of input variables, lacks the representation of comprehensive economic indexes (CEI), and cannot selectively learn essential features, which increases the computational burden and easily mixes redundant information. Thus, a supervised slow feature analysis (SFA)-based LSTM (SSFALSTM) network is proposed for industrial operating performance assessment. By utilizing CEI information and SFA constraints, the network is guided to simultaneously learn features related to CEI and slow-changing features that reflect the inherent dynamics of the process. Further, cascade performance recognition model to construct the complete performance assessment framework. For the non-optimal performance, a reconstruction-based contribution plot method is proposed to identify the main cause variables and guide adjustment operations. Finally, the effectiveness of the proposed method is validated on the dense medium coal preparation process.},
  archive      = {J_EAAI},
  author       = {Fei Chu and Shuangshuang Liao and Lili Hao and Pei Wang and Yan Liu and FuLi Wang},
  doi          = {10.1016/j.engappai.2023.106208},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106208},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Operating performance assessment method for industrial process with slowness principle-based LSTM network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolving marine predators algorithm by dynamic foraging
strategy for real-world engineering optimization problems.
<em>EAAI</em>, <em>123</em>, 106207. (<a
href="https://doi.org/10.1016/j.engappai.2023.106207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Marine Predators Algorithm (MPA) is a novel hunting-based optimizer. The MPA’s central concept is based on the well-known Lévy Flight (LF) and Brownian Motion (BM) strategies as well as a simple transition model between these two strategies. The canonical MPA proposes three static steps to tune the transition behavior between the LF and BM strategies. Although MPA provides exemplary performance in many test functions, the discrete transition between the two mentioned phases causes it to get stuck in local optima when faced with real-world optimization problems. In order to address this shortcoming, this paper proposes a soft dynamic transition between LF and BM to model this encounter naturally, considering the continuous nature of the transition between LF and BM in marine predators’ real life. In order to evaluate the performance of the developed Dynamic Foraging Strategy MPA (DFSMPA), twenty-nine optimization test functions, thirty complex CEC-BC-2017 functions, ten benchmarks of CEC06-2019 test suit, and ten real applicable engineering problems, including power system design, synthesis and process design, industrial chemical producer, power-electronic design, mechanical design, and animal feed ratio, are employed. The DFSMPA is evaluated against four groups of standard optimization approaches, including (1) Arithmetic Optimization Algorithm (AOA), Slime Mould Algorithm (SMA), Equilibrium Optimizer (EO), Niching Chimp Optimization Algorithm (ChOA), Henry Gas Solubility Optimization (HGSO) as recent optimization algorithms, (2) Lévy Flight GWO (LGWO) and Evolutionary Algorithms with Adaptive Lévy Mutations (EALM) as the two best dynamic Lévy-based optimization algorithms, (3) SHADE, CMA-ES, and LSHADESPACMA as the three state-of-the-art optimization algorithms, and jDE100, DISHchain1e+12, CIPDE, and EBOwithCMAR as best performing algorithms in IEEE CEC06-2019 competition. Three non-parametric statistical tests, including the Wilcoxon rank-sum, Bonferroni–Dunn and Holm, and Friedman average rank tests, are utilized to perform a comprehensive assessment. The results show that the DFSMPA achieved the first rank among 46 out of 70 benchmark functions and engineering problems and exhibited similar results compared with SHADE and CMA-ES in other benchmarks. The statistical analysis demonstrated that DFSMPA is a significantly superior optimizer than the three first categories’ benchmark algorithms, while its result is statistically similar to jDE100, DISHchain1e+12.},
  archive      = {J_EAAI},
  author       = {Baohua Shen and Mohammad Khishe and Seyedali Mirjalili},
  doi          = {10.1016/j.engappai.2023.106207},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106207},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evolving marine predators algorithm by dynamic foraging strategy for real-world engineering optimization problems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A non-stationary channel prediction method for UAV
communication network with error compensation. <em>EAAI</em>,
<em>123</em>, 106206. (<a
href="https://doi.org/10.1016/j.engappai.2023.106206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an unmanned aerial vehicle (UAV) communication network, especially for mission-critical applications, ultra-reliable and low-latency communication (URLLC) of the control links has essential implications for realizing collision avoidance and real-time control of UAVs. However, the UAVs’ mobility and the channel environment’s variability may make the wireless channels highly non-stationary. Real-time and accurate Channel Status Information (CSI) acquisition is a critical challenge to implementing URLLC for UAV control links. Predicting the characteristics of non-stationary channels is profitable for formulating communication strategies to mitigate the effects of future channel fading. Nevertheless, the difficulty lies in extracting accurate prediction models for non-stationary channels to obtain accurate CSI. This paper proposes a more precise prediction by utilizing the CSI obtained as feedback from the receiver and introducing error correction. The method contains three stages, CSI collection and processing, channel tracking, and error correction. First, the transmitter collects the CSI feedback from the receiver and converts it to a stationary series. Secondly, the recent historical CSIs are used to track the time evolution of the channel based on an autoregressive integrated moving average (ARIMA) model. Next, the Gaussian process regression (GPR) model is used to establish the prediction error regression model and obtain a more accurate prediction. Finally, the effectiveness of the proposed method is verified based on a UAV wireless communication network application scenario in an urban environment. Simulation results show that the proposed method outperforms other methods regarding RMSE and reliability in high-dynamic UAV communication scenarios. Significantly when the channel changes rapidly, this method can respond to the changes faster and predict the CSI more accurately.},
  archive      = {J_EAAI},
  author       = {Qiuyun Zhang and Tingting Yang and Chun Wu and FanRong Shi and Hong Jiang and Qiumei Guo and Liping Deng and Ying Luo},
  doi          = {10.1016/j.engappai.2023.106206},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106206},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A non-stationary channel prediction method for UAV communication network with error compensation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the effects of data normalization for domain adaptation
on EEG data. <em>EAAI</em>, <em>123</em>, 106205. (<a
href="https://doi.org/10.1016/j.engappai.2023.106205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Machine Learning (ML), a well-known problem is the Dataset Shift problem where the data in the training and test sets can follow different probability distributions, leading ML systems toward poor generalization performances. This problem is intensely felt in Brain-Computer Interfaces (BCIs), where bio-signals as Electroencephalographic (EEG) are often used. Indeed, EEG signals are highly non-stationary both over time and between different subjects. To overcome this problem, several solutions are based on transfer learning approaches such as Domain Adaption (DA). In several cases, however, the actual causes of the improvements remain ambiguous. This paper focuses on the impact of data normalization strategies applied together with DA methods. In particular, using SEED , DEAP , and BCI Competition IV 2a EEG datasets, we experimentally evaluated the impact of different normalization strategies applied with and without several well-known DA methods. It results that the choice of the normalization strategy plays a key role on the classifier performances in DA scenarios, and, often, the use of only an appropriate normalization schema outperforms the DA technique. For SEED and BCI Competition IV 2a, a proper normalization strategy alone in a cross-subject context allows to reach accuracy of 81 . 52 ± 7 . 26 % and 68 . 52 ± 11 . 35 % , respectively. In a cross-session context, the accuracy of 86 . 56 ± 8 . 15 % and 67 . 82 ± 12 . 48 % for SEED and BCI Competition can be reached, respectively. For DEAP, the best cross-subject performance achieved using only normalization was 39 . 33 ± 14 . 08 % . All these results are comparable with the performance obtained by several well-known DA strategies.},
  archive      = {J_EAAI},
  author       = {Andrea Apicella and Francesco Isgrò and Andrea Pollastro and Roberto Prevete},
  doi          = {10.1016/j.engappai.2023.106205},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106205},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On the effects of data normalization for domain adaptation on EEG data},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision-based automatic order check method for online
medicine dispensing cabinet under incomplete data. <em>EAAI</em>,
<em>123</em>, 106204. (<a
href="https://doi.org/10.1016/j.engappai.2023.106204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, computer vision technology has been increasingly used in the retail industry, especially in unmanned retail. In the online medicine dispensing cabinet where the order images are captured along with the customer’s online order information, an automatic order check method is needed to verify whether the picked items match the order information and avoid the mis-dispensing of medicines. Well-built images dataset and annotations are needed for the task. However, it is difficult to construct datasets with fine annotations and keep the images up-to-date in the application scenario. Automatic order check is facing the problems of small samples, diverse and dynamic categories, weak supervision, and domain gaps. To deal with the order check task under incomplete data in real scenarios, we carried out the following works: (1) We proposed a framework for automatic order check (AOC), and collected an incomplete dataset in natural scenes. (2) We proposed a foreground detection method based on conventional image processing. Image matching methods based on local descriptors and text recognition were designed for classification. (3) We proposed a data simulation pipeline for rotated object detection model training with weak supervision. Our methods showed promising results on our challenging dataset.},
  archive      = {J_EAAI},
  author       = {Yanchang Niu and Lishuang Wang and Zhenjun Yu and Jiaqi Huang and Biqing Huang and Yisong Su},
  doi          = {10.1016/j.engappai.2023.106204},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106204},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vision-based automatic order check method for online medicine dispensing cabinet under incomplete data},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing motion visual cues for self-supervised video
representation learning. <em>EAAI</em>, <em>123</em>, 106203. (<a
href="https://doi.org/10.1016/j.engappai.2023.106203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building the general feature from unlabeled videos is the core of self-supervised video representation learning. However, recent research on video representation focuses on static visual pixel information, which makes these models unable to capture the dynamics in the temporal dimension. In order to solve the aforementioned issue and improve the generalization of the model, we propose an enhanced motion visual cue (EMVC) method for self-supervised video representation learning to reduce the background bias and increase the motion information. Our EMVC includes a background replacing module and a foreground fixing module that leverages the foreground and background of the original video sequence to make the background of same-action videos less identical and their motion cues more distinct. Experimental results show that the proposed method effectively reduces the biases in the background and significantly improves the video’s ability to comprehend motion information, leading to an increase in recognition accuracy. Specifically, the EMVC method achieved an accuracy of 84.6%, 53.1%, and 68.3% on the UCF101, HMDB51, and Diving48 datasets, respectively, outperforming the existing algorithms. Additionally, significant improvements were obtained in the video retrieval task on benchmark datasets, with an average improvement of over 14.6%.},
  archive      = {J_EAAI},
  author       = {Mu Nie and Zhibin Quan and Weiping Ding and Wankou Yang},
  doi          = {10.1016/j.engappai.2023.106203},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106203},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing motion visual cues for self-supervised video representation learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic event detection as a slot filling problem.
<em>EAAI</em>, <em>123</em>, 106202. (<a
href="https://doi.org/10.1016/j.engappai.2023.106202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms, such as Twitter, can be used to extract information related to traffic events. Previous works focused mainly on classifying tweets into predefined categories (i.e., traffic or non-traffic) without many details of traffic events. However, extracting traffic-related fine-grained information from tweets is essential to build an intelligent transportation system. In this work, we address for the first time the problem of detecting traffic events using Twitter as two subtasks: (i) identifying whether a tweet is traffic-related or not as a text classification subtask, and (ii) extracting more fine-grained information (i.e., “what”, “when”, “where”, and the “consequence” of the traffic event) as a slot filling subtask. We also publish two Dutch Traffic Twitter datasets from Belgium and the Brussels capital region. We propose using deep learning based methods that process the two subtasks separately or jointly. Experimental results indicate that the proposed architectures achieve high performance scores (i.e., more than 95% F 1 score) on the constructed datasets for both subtasks, even in a transfer learning scenario. In addition, incorporating tweet-level information in each of the tokens comprising the tweet (for the BERT-based model) can lead to a performance improvement for the joint setting. Our datasets and code are available on GitHub. 1},
  archive      = {J_EAAI},
  author       = {Xiangyu Yang and Giannis Bekoulis and Nikos Deligiannis},
  doi          = {10.1016/j.engappai.2023.106202},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106202},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Traffic event detection as a slot filling problem},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation-driven subdomain adaptation network for bearing
fault diagnosis with missing samples. <em>EAAI</em>, <em>123</em>,
106201. (<a
href="https://doi.org/10.1016/j.engappai.2023.106201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been employed widely in bearing fault diagnosis. However, in industry, sufficient and complete fault samples are hard to acquire and the working conditions vary frequently, which result in significant diagnosis performance deterioration. To solve these problems, a fully dynamic model and subdomain adaptation based intelligent fault diagnosis framework is proposed. Firstly, the fully dynamic bearing models are used to fill in some missing fault samples. Then, a simple but effective subdomain adaptation method is developed to align class-level subdomain distributions of source and target domains with consideration of samples transferability. Contrast experiments on two bearing test rigs are carried out to verify the proposed method, which contain different working conditions and missing fault types. Experimental results indicate that the proposed method is superior to non-adapted and four widely used transfer learning models, which is promising for real industrial applications.},
  archive      = {J_EAAI},
  author       = {Jianing Liu and Hongrui Cao and Shuaiming Su and Xuefeng Chen},
  doi          = {10.1016/j.engappai.2023.106201},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106201},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simulation-driven subdomain adaptation network for bearing fault diagnosis with missing samples},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid partial-constrained learning with orthogonality
regularization for unsupervised person re-identification. <em>EAAI</em>,
<em>123</em>, 106200. (<a
href="https://doi.org/10.1016/j.engappai.2023.106200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-ID) aims at determining whether there is a specific person in image sets or videos via computer vision technology. State-of-the-art unsupervised re-ID methods extract image features through CNNs-based networks and store these extracted features in memory for identity matching. However, extracted global features of these methods ignore the problem of information redundancy and the influence of the constraints between the internal features. To overcome these problems, a Hybrid Partial-constrained Learning (HPcL) network with orthogonality regularization is proposed to learn a discriminative visual representation by generating hybrid features. Specifically, the hybrid features are generated by our designed Dynamic Fusion Module (DFM) to initialize the memory dictionary and match the identity, which can constrain each part of the features extracted by our proposed Multi-Scale (M-S) module and learn robust visual representations. In addition, a new orthogonal regularization method is introduced to constrain orthogonality of the kernel weights and features, which reduces the correlations among features. Extensive experimental results on Market-1501, DukeMTMC-reID, PersonX, and MSMT17 datasets demonstrate that our method is effective and superior to the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Jiazuo Yu and Jinjia Peng and Kai Li and Huibing Wang},
  doi          = {10.1016/j.engappai.2023.106200},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106200},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid partial-constrained learning with orthogonality regularization for unsupervised person re-identification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving the accuracy of daily solar radiation prediction
by climatic data using an efficient hybrid deep learning model: Long
short-term memory (LSTM) network coupled with wavelet transform.
<em>EAAI</em>, <em>123</em>, 106199. (<a
href="https://doi.org/10.1016/j.engappai.2023.106199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate daily solar radiation prediction is a crucial task for the management and generation of solar energy as one of the alternatives to fossil fuels. In this study, the prediction accuracy of new machine learning methods, wavelet long short-term memory (WLSTM), wavelet multi-layer perceptron artificial neural network (WMLPANN), long short-term memory (LSTM), multi-layer perceptron artificial neural network (MLPANN), and multivariate adaptive regression splines (MARS), was assessed for modeling daily solar radiation using various input combinations of climatic data of maximum and minimum relative humidity, potential evapotranspiration, maximum and minimum temperature, precipitation and wind speed from two stations, Brownstown and Carbondale located in Illinois, USA. For accurate assessment of prediction accuracy of the proposed models, four reliable statistical metrics, root mean squared error (RMSE), Nash–Sutcliffe efficiency coefficient (NSE), coefficient of determination (R 2 ), and One-Tailed Wilcoxon Signed-Rank Test were employed. Comparison of results, based on the RMSE values, indicated that the WLSTM method performed better than the WMLPANN, LSTM, MLPANN and MARS methods in the estimation of solar radiation values at both stations. The average RMSE values of WMLPANN, LSTM, MLPANN, and MARS approaches was decreased by 6%, 4%, 7.3%, and 13.5% using WLSTM method at Brownstown Station, by 6%, 5.2%, 13.2%, and 14.3% at Carbondale Station, respectively. The overall results during the testing phase of both stations revealed the successful application of hybridization of the LSTM model with the wavelet transform technique for improving the prediction accuracy of solar radiation based on climatic parameters.},
  archive      = {J_EAAI},
  author       = {Meysam Alizamir and Jalal Shiri and Ahmad Fakheri Fard and Sungwon Kim and AliReza Docheshmeh Gorgij and Salim Heddam and Vijay P. Singh},
  doi          = {10.1016/j.engappai.2023.106199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving the accuracy of daily solar radiation prediction by climatic data using an efficient hybrid deep learning model: Long short-term memory (LSTM) network coupled with wavelet transform},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved spherical evolution with enhanced exploration
capabilities to address wind farm layout optimization problem.
<em>EAAI</em>, <em>123</em>, 106198. (<a
href="https://doi.org/10.1016/j.engappai.2023.106198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of metaheuristics for optimizing wind farm layouts (WFLOP) has emerged as a popular research area in recent years. However, effectively screening and improving metaheuristics to obtain optimal layouts remain a challenging task. Traditional metaheuristic screening methods require testing numerous algorithms, resulting in high computational resource consumption and trial-and-error costs due to the lack of theoretical guidance. To overcome this challenge, this study proposes a complex network-based metaheuristic screening method. Population interaction networks are utilized to classify metaheuristics into two categories: biased exploitation and biased exploration. The results of several metaheuristics on WFLOP suggest that exploration-biased algorithms generally outperform exploitation-biased ones. This discovery holds great significance as it has the potential to predict the performance of various algorithms on WFLOP to a certain degree. Additionally, it provides valuable suggestions for algorithm selection and improvement. Building upon this new methodology, we screen and improve the spherical evolution algorithm to enhance its exploration capabilities. Experimental results demonstrate that the improved spherical evolution algorithm significantly outperforms its competitors on WFLOP.},
  archive      = {J_EAAI},
  author       = {Haichuan Yang and Shangce Gao and Zhenyu Lei and Jiayi Li and Yang Yu and Yirui Wang},
  doi          = {10.1016/j.engappai.2023.106198},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106198},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved spherical evolution with enhanced exploration capabilities to address wind farm layout optimization problem},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered reconfigurable reinforcement learning
motion-planning approach for mobile robot in unknown dynamic
environments. <em>EAAI</em>, <em>123</em>, 106197. (<a
href="https://doi.org/10.1016/j.engappai.2023.106197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) is an essential technique for autonomous motion planning of mobile robots in dynamic and uncertain environments. In attempting to acquire a satisfactory DRL-based motion planning strategy, the mobile robots encountered several difficulties, including poor convergence, insufficient sample information, and low learning efficiency. These problems not only consume plenty of training time, but also bring a negative impact on motion planning performance. One promising research direction is to provide a more effective network framework for DRL-based policies. Along this line of thinking, our paper presents a novel DRL-based motion planning approach called Reconfigurable Structure of Deep Deterministic Policy Gradient (RS-DDPG) for mobile robots. To account for the poor convergence, the proposed approach first introduces an event-triggered reconfigurable actor–critic network framework for motion policy that adaptively changes its network structure to suppress the overestimation of action value. Then, the time convergence of the motion policy can be enhanced based on the value actions with minor valuation deviation. Afterwards, an adaptive reward mechanism is designed for reconfigurable networks to compensate for the lack of sample information. To deal with the problem of low learning efficiency, we developed a sample pretreatment method for the experience samples, which employs three novel techniques to improve the sample utilization, including a double experience memory buffer, a variable proportional sampling principle, and a similarity judgment mechanism. In extensive experiments, the proposed method outperforms the compared approaches.},
  archive      = {J_EAAI},
  author       = {Huihui Sun and Changchun Zhang and Chunhe Hu and Junguo Zhang},
  doi          = {10.1016/j.engappai.2023.106197},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106197},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Event-triggered reconfigurable reinforcement learning motion-planning approach for mobile robot in unknown dynamic environments},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-stage underwater image aesthetic enhancement
algorithm based on a generative adversarial network. <em>EAAI</em>,
<em>123</em>, 106196. (<a
href="https://doi.org/10.1016/j.engappai.2023.106196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing underwater image enhancement algorithms rely on paired datasets, which enhance underwater images by learning the mapping relationship between low-quality and high-quality data. However, currently, high-quality data (which are called real data) are artificially selected by the dataset builders from the results of previous algorithms, and there are no real paired data in the true sense. In this paper, we used CycleGAN for underwater image enhancement, which is unsupervised learning. We designed the aesthetic loss and style consistency loss to constrain the generated image to make it more consistent with perception by human eyes and to improve the contrast. We used a two-stage generative network structure to compensate for the loss of information during the enhancement process and enhanced the details. We verified the superiority of our algorithm in the subjective and aesthetic aspects through a large number of comparative and ablation experiments as well as subjective and objective analyses.},
  archive      = {J_EAAI},
  author       = {Kai Hu and Chenghang Weng and Chaowen Shen and Tianyan Wang and Liguo Weng and Min Xia},
  doi          = {10.1016/j.engappai.2023.106196},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106196},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-stage underwater image aesthetic enhancement algorithm based on a generative adversarial network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Identification of tomato leaf diseases based on LMBRNet.
<em>EAAI</em>, <em>123</em>, 106195. (<a
href="https://doi.org/10.1016/j.engappai.2023.106195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomato disease image identification plays a very important role in the field of agricultural production. Aiming at the problems of large intraclass differences, small inter-class differences and difficult feature extraction of some tomato leaf diseases, this paper proposes an identification of tomato leaf diseases based on LMBRNet. Firstly, a comprehensive grouped differentiated residual (CGDR) is built,The multi-branch structure of CGDR is used to capture the diversified feature information of tomato leaf diseases in different dimensions and receptive fields. then, a multiple residual connection scheme is adopted,using residuals to connect all layers, to ensure the maximum information transmission between layers in the network and to solve the problems of network degradation and gradient disappearance in the network training process. Secondly,the visual enhancement effectively fuses the results obtained by three different downsampling strategies using average pooling, max pooling, and 1*1 convolution. Avoid the loss of information caused by downsampling and improve the accuracy of the network. Moreover, deep separable convolution is used to optimize the network structure, reduce the amount of model parameters and reduce the computational resources occupied by training and deploying the model.we found that the depthwise separable convolution with a kernel size of 1*1 can slightly improve the efficiency of the model under the premise that it has little effect on the number of model parameters. The application results of more than 8000 images show that the overall identification accuracy is about 99.7%,higher than ResNet50(97.48%),GoogleNet(98.96%) etc. conventional models. The parameter amount of LMBRNet is 4.1M. Less than ResNet50(23M),GoogleNet(5.7M) etc. conventional models. It is worth noting that the accuracy of LMBRNet(99.7%) is similar to that of InceptionResNetV2(99.68%), but the amount of parameters of LMBRNet(4.1M) is much lower than that of InceptionResNetV2(54M). Moreover, the parameter amount of LMBRNet (4.1M) is slightly lower than that of MobileNetV2(2.2M), but the accuracy rate of LMBRNet(99.7%) is higher than that of MobileNetV2(97.87%). LMBRNet was tested on RS, SIW, Plantvillage-corn public datasets, all obtained high recognition accuracy, 82.32% on RS, 88.37% on SIW and 97.25% on Plantvillage-corn, indicating that LMBRNet has good generalization. Compare LMBRNet with advanced methods. In four different classification tasks, the performance of LMBRNet is similar to ResMLP12 and DCCAM-MRNet, and the difference of recognition accuracy between LMBRNet and ResMLP12 and DCCAM-MRNet is not more than 1%. However, the parameters of LMBRNet (4.1M) are lower than ResMLP12 (14.94M) and DCCAM MRNet (22.8M). LMBRNet is compared with MobileNetV3, an advanced lightweight classification model. LMBRNet(88.37% on SIW,82.32% ON RS) is used on certain datasets and performs better than MobileNetV3S(83.76% on SIW,75 on RS) and MobileNetV3L(84.34 on SIW,73.39 on RS). The parameters of LMBRNet(4.1M) are lower than MobileNetV3L(5.4M) and slightly higher than MobileNetV3S(2.9M). This indicates that LMBRNet has good generality even though it has a small number of parameters.},
  archive      = {J_EAAI},
  author       = {Mingxuan Li and Guoxiong Zhou and Aibin Chen and Liujun Li and Yahui Hu},
  doi          = {10.1016/j.engappai.2023.106195},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106195},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification of tomato leaf diseases based on LMBRNet},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypoglycaemia prediction using information fusion and
classifiers consensus. <em>EAAI</em>, <em>123</em>, 106194. (<a
href="https://doi.org/10.1016/j.engappai.2023.106194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommendation that there must be a balance between insulin, food, and exercise to keep diabetes under control provides an opportunity for developing mobile applications for self-management of the disease. Real predictions can improve the quality of patients’ lives by avoiding unwanted events, namely, hypoglycaemia. We proposed a hypoglycaemia prediction approach combining information fusion and classifiers consensus to predict the risk of hypoglycaemia in a 24-h window. First, we train a multi-classifiers system from different sources of different patients. After using data from a unique patient, we performed the prediction of the risk of hypoglycaemia and evaluate the consensus decision of the single models resulting from the learning process. The predictions were performed for 54 patients from the University of California Irvine diabetes dataset. The results from classifiers consensus decision provide very promising results, which are acceptable considering that we used sparse data and data from self-monitoring blood glucose. Our approach shows that with a 24-h window is possible to catch appropriate patterns associated with the risk of hypoglycaemia and proposed a solution that can improve the hypoglycaemia prediction with a higher specificity, i.e. less false alarms, when compared with similar literature.},
  archive      = {J_EAAI},
  author       = {Virginie Felizardo and Nuno M. Garcia and Imen Megdiche and Nuno Pombo and Miguel Sousa and František Babič},
  doi          = {10.1016/j.engappai.2023.106194},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106194},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hypoglycaemia prediction using information fusion and classifiers consensus},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Switching synthesizing-incorporated and cluster-based
synthetic oversampling for imbalanced binary classification.
<em>EAAI</em>, <em>123</em>, 106193. (<a
href="https://doi.org/10.1016/j.engappai.2023.106193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oversampling is a popular yet useful method to fulfill the binary classification of imbalanced data, however many existing results of oversampling are very likely to generate redundant/unsafe/noise samples due primarily to the inadequate consideration of the data distribution. To address this issue, we propose a novel oversampling approach, namely Switching Synthesizing-Incorporated and Cluster-Based Synthetic Oversampling (SSI-CBSO). The core idea of SSI-CBSO is four-fold: (1) noise samples are removed by using K nearest neighbor strategy and Fuzzy C-Means clustering is adopted for the filtered data in the minority class; (2) the number of samples that need to be synthesized is adaptively assigned to each cluster concerning the inter-class distance and the intra-cluster similarity; (3) to better reflect the data distribution, a new method in terms of the concept of the hypersphere is put forward to measure the cluster density in a high dimensional; and (4) a new principle based on the Mahalanobis distance is provided for a better selection of the target sample. Then, a switching synthesizing strategy is established to guarantee the safety of the synthesized samples. Finally, experiments on 13 binary imbalanced data sets by using five evaluation metrics with four classifiers verify that our proposed SSI-CBSO approach can obtain desirable results.},
  archive      = {J_EAAI},
  author       = {Jun Dou and Zihan Gao and Guoliang Wei and Yan Song and Ming Li},
  doi          = {10.1016/j.engappai.2023.106193},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106193},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Switching synthesizing-incorporated and cluster-based synthetic oversampling for imbalanced binary classification},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Engineering applications of multi-objective evolutionary
algorithms: A test suite of box-constrained real-world problems.
<em>EAAI</em>, <em>123</em>, 106192. (<a
href="https://doi.org/10.1016/j.engappai.2023.106192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, the performance of novel multi-objective optimization algorithms is evaluated on artificial test problems, which are constructed under the consideration of some features observed in real-world problems. However, artificial test problems do not possess all the properties that real-world applications have. Therefore, the evaluation of algorithms on artificial test problems can overestimate the conclusions of an algorithm regarding its performance in real-world applications. In this respect, this paper presents a collection of multi-objective real-world problems taken from different disciplines. The multi-objective problems are suggested to complement the performance evaluation of evolutionary algorithms considering real-life applications without the need to be an expert on the concerned disciplines in which they lie. This study analyzes the conflict between objectives from the correlation point of view of each real-world problem. Notably, this investigation inquires on the real-world multi-objective problems regarding the Pareto front shapes, which have been one of the main difficulties for selection mechanisms in multi-objective evolutionary algorithms. Additionally, the performance of nine state-of-the-art multi-objective evolutionary algorithms based on the main principles of evolutionary computation is analyzed. Although it is impractical to evaluate all the existing algorithms available in the multi-objective evolutionary community, this investigation gives insights into the performance of the main multi-objective approaches considered in this study.},
  archive      = {J_EAAI},
  author       = {Saúl Zapotecas-Martínez and Abel García-Nájera and Adriana Menchaca-Méndez},
  doi          = {10.1016/j.engappai.2023.106192},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106192},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Engineering applications of multi-objective evolutionary algorithms: A test suite of box-constrained real-world problems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). LOSN: Lightweight ore sorting networks for edge device
environment. <em>EAAI</em>, <em>123</em>, 106191. (<a
href="https://doi.org/10.1016/j.engappai.2023.106191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based intelligent ore sorting technology has been widely applied in current mining production, a trend further facilitated by the emergence of deep learning. However, most available implementations are still based on image classification, i.e., dividing the overall sorting task into two processes: classification and localization, without end-to-end integration. Meanwhile, harsh sorting scenarios make edge computing devices the primary candidate for model deployment, with more stringent limitations for model size, computational complexity, and inference speed. Therefore, this study proposes to integrate the operating processes to locate and classify the ores particles simultaneously. The lightweight structures, attention mechanisms, and multi-scale feature fusion strategies are applied in the architecture design to meet the deployment requirements of edge device environments and achieve a preferred accuracy–efficiency tradeoff, which leads to a new lightweight ore sorting networks called LOSN. In the case study, LOSN has the highest accuracy in multi-type and multi-class ore sorting tasks (78.87% and 80.64% in the gas coal and anthracite dataset, respectively) with fewer parameters (5.970M), lower GFLOPs (6.829G) and higher FPS (89.92), which is superior to commonly used high-performance object detection architectures (e.g., Yolo series, EfficientDet, Faster-RCNN, and CenterNet). Grad-CAM visualizations also demonstrate the feature extraction capability of LOSN.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Xueyi Wang and Zelin Zhang and Fang Deng},
  doi          = {10.1016/j.engappai.2023.106191},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106191},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LOSN: Lightweight ore sorting networks for edge device environment},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emergency response scheme selection with t-spherical
hesitant probabilistic fuzzy TODIM-TPZSG approach. <em>EAAI</em>,
<em>123</em>, 106190. (<a
href="https://doi.org/10.1016/j.engappai.2023.106190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to investigate an innovative framework to handle emergency response scheme selection (ERSS) issues by integrating TODIM and TPZSG (two-person zero-sum game) methods under novel T-spherical hesitant probabilistic fuzzy set (T-SHPFS) environments. First, T-SHPFS is defined as an extension of the existing tools, which can depict the complex assessment information including several possible values of the various membership functions’ degrees and the associated statistical uncertainty information. Concomitantly, T-SHPFS’s normalization method, comparison laws, operation rules, cross-entropy measure and Hausdorff distance are explored. Then, an objective attribute weight determining model is constructed, considering the credibility of T-SHPF evaluations and the divergence degrees between attribute assessments simultaneously. Next, an integrated TODIM-TPZSG decision-making approach is developed to select the most desirable emergency response scheme. Finally, an illustrative example concerning the selection of the best medical waste disposal method during the COVID-19 epidemic is conducted to verify the effectiveness of the proposed TODIM-TPZSG method. Sensitivity analysis and comparisons between the TODIM-TPZSG and other representative methods are also provided to demonstrate the superiorities of the proposed method. The results reveal that the developed T-SHPFSs give DMs more assessment freedom; the proposed TODIM-TPZSG approach considers the decision makers’ psychological behaviors; the ranking results of the proposed method can reflect the specific divergence degrees among the alternatives; and the needed computation burden and computational complexity are low and less affected by the number of alternatives and criteria than most current ERSS methods.},
  archive      = {J_EAAI},
  author       = {Yu-Dou Yang and Xue-Feng Ding},
  doi          = {10.1016/j.engappai.2023.106190},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106190},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emergency response scheme selection with T-spherical hesitant probabilistic fuzzy TODIM-TPZSG approach},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On semi-automated extraction of causal networks from raw
text. <em>EAAI</em>, <em>123</em>, 106189. (<a
href="https://doi.org/10.1016/j.engappai.2023.106189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rule-based framework, named SCANER (Semi-automated CAusal Network Extraction from Raw text) is presented. SCANER converts raw text into causal networks using a set of natural language processing rules. The raw textual data that contains useful information for informing future decisions and developing strategies in various critical domains must be converted into useful, understandable models. However, building such models manually from raw text is a labor-intensive and time-consuming process and needs to be automated. The automated extraction of causality from raw text, however, has its own set of challenges due to the linguistic complexity and ambiguity of the texts. It can also be argued that for complicated scenarios and critical domains subject matter experts cannot rely solely on such automatically generated models without sound reasoning to support them. This implies the need for a semi-automated human-in-the-loop approach. This research, therefore, is focused on combining the strengths of both manual and automated approaches and on developing a framework for a rule-based semi-automated approach to generate causal networks from raw text. SCANER is evaluated on three collections of raw text from political, food insecurity, and medical domains using F-Score as the evaluation metric. The ground truth for the causal links is generated after incorporating feedback from a group of three human judges. A comparative analysis with Eidos, an open-source causality extraction system, demonstrates the advantages of SCANER in generating dense and accurate causal networks from the raw text.},
  archive      = {J_EAAI},
  author       = {Solat J. Sheikh and Sajjad Haider and Alexander H. Levis},
  doi          = {10.1016/j.engappai.2023.106189},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106189},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On semi-automated extraction of causal networks from raw text},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-learning swimming of a three-disk microrobot in a
viscous and stochastic environment using reinforcement learning.
<em>EAAI</em>, <em>123</em>, 106188. (<a
href="https://doi.org/10.1016/j.engappai.2023.106188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is a novel and fascinating tool in the control of robots. In this study, using a reinforcement learning approach, we have trained an artificial three-disk microrobot in order to learn how to swim at low Reynolds number flow ( Re ≪ 1 ) like the behavior of young microorganisms. Here, as the first contribution, we introduced a discrete model of a novel microswimmer. As the second contribution, we demonstrated that, using the proposed intelligent method, the microswimmer will be able to not only escape the physical constraints of swimming in a viscous medium, but also find the best sequence of actuation to reach the target point in a stochastic environment. The proposed reinforcement learning strategy can be applied to any other type of self-propelled microswimmers consisting of disks and actuators, which swim with continuous state space in a perturbed environment. In the end, we investigated the effect of learning hyperparameters on the performance of the swimmer’s training, and showed that, in the current agent and environment, the optimal values for the discount factor γ and learning rate α are 0.7 and 0.001 respectively which should be properly set for other types of mechanisms and environments.},
  archive      = {J_EAAI},
  author       = {Hossein Abdi and Hossein Nejat Pishkenari},
  doi          = {10.1016/j.engappai.2023.106188},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106188},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-learning swimming of a three-disk microrobot in a viscous and stochastic environment using reinforcement learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A practical approach to explaining defect proneness of code
commits by causal discovery. <em>EAAI</em>, <em>123</em>, 106187. (<a
href="https://doi.org/10.1016/j.engappai.2023.106187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable software defect prediction is practical for software quality assurance. However, it is hard to explain the predictions made by obscure machine learning models because of the lack of transparency and the unreliability of the explanations for such predictions from existing explanation methods. To provide a better understanding of the causes of defect proneness of code commits, we propose an approach called CausalDefect to construct a causal graph of defects, which provides a visual way to understand the causal relationships between different features of defects. Based on the transparent causal graph, software engineers can naturally predict defect proneness of code commits, explain the resulting predictions, and finally take feasible action to reduce defect proneness. To verify the usefulness of the generated causal graph, we conduct evaluations, and the evaluation results suggest that our causal graph can effectively and efficiently predict defect proneness of code commits and explain the resulting predictions, even if the graph is not optimized for specific software projects. Most importantly, CausalDefect is the first attempt to employ causal discovery algorithms to investigate the explainability of defect proneness by establishing a causal graph of software defects.},
  archive      = {J_EAAI},
  author       = {Yamin Hu and Wenjian Luo and Zongyao Hu},
  doi          = {10.1016/j.engappai.2023.106187},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106187},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A practical approach to explaining defect proneness of code commits by causal discovery},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A framework to estimate generating capacities of PV systems
using satellite imagery segmentation. <em>EAAI</em>, <em>123</em>,
106186. (<a
href="https://doi.org/10.1016/j.engappai.2023.106186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing interest in global warming has led to various efforts to rely on new renewable energy such as solar power. More accurate energy generation calculation is on-demand with the rise of publicly accessible residential photovoltaic (PV) panels. PV panel area computation is the first step towards the image-based estimation of energy generation from the residential solar arrays. Satellite image segmentation provides a low-cost and simple solution to calculate solar panel area installed on rooftops and the ground. The most relevant approach is to acquire high-quality labels rather than network architectures in many scenarios. This research aims to estimate potential solar energy from satellite images using deep learning segmentation techniques. We compared five architectures such as UNet, UNet++, Feature Pyramid Network (FPN), Pyramid Scene Parsing Network (PSPNet), and DeepLabV3, with different encoders. We converted segmented image pixels into square meters regarding the average slope of panels. We considered the average solar panel efficiency, global tilted irradiation, and the loss coefficient to estimate the annual energy output from the calculated area. UNet with the EfficientNetB7 encoder performed the best with a dice similarity coefficient of 0.9982 for segmentation and a Mean Absolute Percentage Error (MAPE) of 3.5 for energy output estimation.},
  archive      = {J_EAAI},
  author       = {Dadajon Jurakuziev and Sherozbek Jumaboev and Malrey Lee},
  doi          = {10.1016/j.engappai.2023.106186},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106186},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A framework to estimate generating capacities of PV systems using satellite imagery segmentation},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image segmentation of adhesive ores based on MSBA-unet and
convex-hull defect detection. <em>EAAI</em>, <em>123</em>, 106185. (<a
href="https://doi.org/10.1016/j.engappai.2023.106185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ore particle size information is a crucial indicator to evaluate the crushing quality and judge whether there are oversized ores on the conveyor belt. Accurately separating each ore is a critical prerequisite for obtaining high-precision particle size measurement (PSM) results. However, the large size variance and natural adhesion between ores pose a huge challenge to this task, imposing under-segmentation. Hence, this study proposes an automatic method that combines semantic segmentation and morphological operations to measure the ore particle size. Specifically, a novel multi-scale connection and boundary-aware U-Net model (MSBA-Unet) that classifies boundary pixels between adhesive ores more accurately is developed to segment ore images. Second, the convex-hull defect detection (CDD) method that divides the adhesive ores with a deep concave shape into two pieces is adopted to process the predicted masks further. The experimental results demonstrate that the MSBA-Unet architecture design and the CDD method can significantly improve the performance of separating adhesive ores of different sizes. Therefore, the under-segmentation problem is tremendously alleviated, and the ore PSM results agree well with the ground truth.},
  archive      = {J_EAAI},
  author       = {Wei Wang and Qing Li and Dezheng Zhang and Jiawei Fu},
  doi          = {10.1016/j.engappai.2023.106185},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106185},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image segmentation of adhesive ores based on MSBA-unet and convex-hull defect detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level learning counting via pyramid vision transformer
and CNN. <em>EAAI</em>, <em>123</em>, 106184. (<a
href="https://doi.org/10.1016/j.engappai.2023.106184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe scale variation has become a challenging issue for hindering the improvement of accuracy in crowd counting task. To tackle the problem, we propose a Pyramid Transformer CNN Network (PTCNet), an effective combination of the transformer and the CNN, which possesses both the global receptive fields and the locality to deal with the severe scale variation problems and boost the prediction accuracy. Firstly, we utilize the pyramid vision transformer to extract multi-level global context information of the crowd, aiming at different head scales. And then, the multi-level information is fully fused in the multi-level feature aggregation module where detailed crowd characteristics from all feature spaces are preserved to be further processed. Finally, we design a multi-branch regression head to enrich the crowd features for strong representations and regress the density maps. Extensive experiments on challenging datasets with complex scenarios and multiple scales demonstrate the effectiveness of the our method. The proposed method achieves competitive results comparing with the state-of-the-art approaches and achieves state-of-the-art results(MAE:51.7, RMSE:79.6) on ShanghaiTech Part_A dataset.},
  archive      = {J_EAAI},
  author       = {Jiayu Liu and He Li and Weihang Kong},
  doi          = {10.1016/j.engappai.2023.106184},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106184},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-level learning counting via pyramid vision transformer and CNN},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alternative prioritization of freeway incident management
using autonomous vehicles in mixed traffic using a type-2 neutrosophic
number based decision support system. <em>EAAI</em>, <em>123</em>,
106183. (<a
href="https://doi.org/10.1016/j.engappai.2023.106183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic incident management is combining the assets of authorities to identify, deal with, and manage traffic problems as rapidly as possible while providing the safety of on-scene responders and the traveling public. The advancement of autonomous vehicles is an opportunity for enhancing incident management implementations. This study aims to provide policymakers with four main alternatives to control freeway incidents using autonomous vehicles in mixed traffic. The presented alternatives are namely autonomous vehicles behaving as human-driven vehicles, ones connected, ones using an algorithm for incident management, and ones used in the traditional incident management methodology. The study also aims to introduce an integrated decision-making tool that is comprehendible for policymakers and mobility experts. It is based on the integration of an Entropy-based approach and the complex proportional assessment (COPRAS) method under the type-2 neutrosophic number (T2NN) environment. T2NN can represent uncertainties such as uncertainty, inconsistency, and inconsistency in real-world problems. T2NN-Entropy is presented to reveal the objective importance of evaluation criteria for freeway incident management. T2NN-COPRAS is proposed to order alternatives when deciding on the behavior of autonomous vehicles. The comparative investigation shows the superiority of the T2NN-Entropy-COPRAS model. Its major advantages are high robustness in making real-world multi-criteria decisions due to the triple-normalization backbone, and high flexibility in solving complex decision-making problems. The research findings show that using an algorithm for incident management is the best alternative to solve problems during and after an incident in mixed traffic, while autonomous vehicles that act like human-driven vehicles are the least advantageous.},
  archive      = {J_EAAI},
  author       = {Ilgin Gokasar and Vladimir Simic and Muhammet Deveci and Tapan Senapati},
  doi          = {10.1016/j.engappai.2023.106183},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106183},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Alternative prioritization of freeway incident management using autonomous vehicles in mixed traffic using a type-2 neutrosophic number based decision support system},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mining periodic high-utility itemsets with both positive and
negative utilities. <em>EAAI</em>, <em>123</em>, 106182. (<a
href="https://doi.org/10.1016/j.engappai.2023.106182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining high-utility patterns in databases containing items with both positive and negative profits is useful in market basket databases, since negative profits are common in the real world. Obviously, in the market basket database, patterns with stable long-term profits have more meaning. The discovery of itemsets with a consistent high frequency is known as periodic frequent pattern mining. Therefore, mining periodic high-utility patterns in a database containing items with both positive and negative profits is an interesting and useful task. However, this task has two main challenges. First, the utility measure does not have the download closure property. Second, the huge search space needs to be pruned more effectively. In this paper, we propose a vertical data structure-based algorithm called PHMN to discover periodic high-utility patterns (PHUPs) or itemsets in a transaction database with both positive and negative utilities. To be more efficient, we propose a new upper bound to prune the search space and an improved algorithm to discover the PHUPs. Finally, experiments are conducted to verify the effectiveness and efficiency of algorithms.},
  archive      = {J_EAAI},
  author       = {Fuyin Lai and Xiaojie Zhang and Guoting Chen and Wensheng Gan},
  doi          = {10.1016/j.engappai.2023.106182},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106182},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mining periodic high-utility itemsets with both positive and negative utilities},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Multi-scale split dual calibration network with periodic
information for interpretable fault diagnosis of rotating machinery.
<em>EAAI</em>, <em>123</em>, 106181. (<a
href="https://doi.org/10.1016/j.engappai.2023.106181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional intelligent fault diagnosis algorithms based on signal processing and pattern recognition have high demands on expert experience and poor generalization performance, which may not have good fault diagnosis performance in complex industrial fields. Meanwhile, the data acquisition system may suffer from cyber attacks when collecting vibration signals. The vibration signal has a very low signal-to-noise ratio (SNR), which seriously affects the accuracy of fault diagnosis. Aiming at the problem of fault diagnosis under low SNR, a new fault diagnosis framework based on a Multi-scale Split Dual Calibration Network with Periodic Information (PI-MSDCN) is proposed in this paper. In the fault diagnosis framework, a periodic block is constructed to automatically learn the periodic information of vibration signals through the neural network. The learned periodic information and raw vibration signal are used as the input data of MSDCN. Specifically, MSDCN uses convolution kernels of different sizes for different channels of input features to generate multi-scale features, and obtain mixed domain attention features for features with different scales respectively. Then, the attention feature is used as the threshold to remove the redundant information in the multi-scale feature adaptively. Finally, in order to calibrate the contribution of different scale features to fault diagnosis, the mixed-domain attention coefficients are applied to the corresponding features to obtain richer multi-scale attention features. The experimental studies under different levels of interference are performed to demonstrate the average accuracy of the proposed method is 92.91% ( ± 5 . 08 % ), which is superior to other existing results in literature.},
  archive      = {J_EAAI},
  author       = {Yongyi Chen and Dan Zhang and Hongjie Ni and Jun Cheng and Hamid Reza Karimi},
  doi          = {10.1016/j.engappai.2023.106181},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106181},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale split dual calibration network with periodic information for interpretable fault diagnosis of rotating machinery},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty quantification in molecular property prediction
through spherical mixture density networks. <em>EAAI</em>, <em>123</em>,
106180. (<a
href="https://doi.org/10.1016/j.engappai.2023.106180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As uncertainty quantification is crucial for determining undesirable inputs and improving decisions made by a system to acquire accurate evaluations, it has received much attention in recent years. Motivated by the fact that probability is one of the most effective ways to estimate uncertainty, in this work we propose an effective probabilistic model for quantifying predictive uncertainty in the task of predicting chemical molecular properties. Our model is formulated by developing a spherical mixture density network that is composed of von Mises-Fisher kernel distributions to model graph-structured molecule representations. Furthermore, an ensemble framework for spherical mixture density networks is developed, which can yield high quality predictive uncertainty estimates and obtain better confidence intervals reflecting the sources of these uncertainties in predictions. The effectiveness of our approach in modeling the output predictive uncertainty is validated through empirical analysis on molecular property prediction tasks with two publicly available chemical molecule data sets. Comparing with the current state-of-the-art baselines, our model can better model predictive uncertainty in terms of higher log-likelihood of the data, and reveal that there might be more than one acceptable chemical property associated with an input molecule representation.},
  archive      = {J_EAAI},
  author       = {Wentao Fan and Lidan Zeng and Tian Wang},
  doi          = {10.1016/j.engappai.2023.106180},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106180},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty quantification in molecular property prediction through spherical mixture density networks},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaze-aware hand gesture recognition for intelligent
construction. <em>EAAI</em>, <em>123</em>, 106179. (<a
href="https://doi.org/10.1016/j.engappai.2023.106179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advances in construction robotics in recent decades has been a powerful driver of construction automation. User-friendly interfaces to support human–robot work collaboration are critical for increasing adoption of construction robots. Among different interfaces, hand gesture is an effective and reliable interaction cue in the noisy construction environment. This paper proposes a novel human gaze-aware hand gesture recognition framework as a human–robot interface for intelligent construction. The proposed framework relies on an eye tracker to visually detect and track robotic machines in the first-person view. Then, the machine-of-interest is determined based on the bounding boxes of machines and gaze points. Finally, a hand gesture recognition architecture is incorporated with the machine information for conveying messages to the machine-of-interest. This approach was tested through a framework validation test and achieved precision and recall of 93.8% and 95.0%, respectively. A pilot study was conducted to demonstrate interaction with a robotic excavator and a dump truck, and the results illustrated that the proposed framework could serve as an effective interface for one-to-many human–robot collaborations in construction.},
  archive      = {J_EAAI},
  author       = {Xin Wang and Dharmaraj Veeramani and Zhenhua Zhu},
  doi          = {10.1016/j.engappai.2023.106179},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106179},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gaze-aware hand gesture recognition for intelligent construction},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A feedback-enhanced two-stage framework for judicial machine
reading comprehension. <em>EAAI</em>, <em>123</em>, 106178. (<a
href="https://doi.org/10.1016/j.engappai.2023.106178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Reading Comprehension (MRC) is the task of teaching machines to understand and answer questions based on a given text. In the judicial domain, MRC has garnered attention as a novel strategy for addressing a variety of legal issues. Judicial MRC generally requires interpretability, meaning that the model should not only answer the question correctly but also provide supporting evidence sentences. A straightforward approach is to handle the two tasks separately, which ignores the relation between the two tasks and leads to the loss of annotated information. To make better use of the limited judicial MRC annotation data, we simulate the strategies used by humans in solving MRC problems and propose the Feedback-Enhanced Two-Stage Framework for Machine Reading Comprehension (FETSF-MRC). This framework consists of two cascaded modules: (a) a scanning module that identifies evidence sentences and (b) a detailed reading module that focuses on the evidence to identify candidate answers and provides feedback to the scanning module. Experiments on two Chinese judicial reading comprehension datasets (CJRC, CAIL2020) and an open-domain English dataset HotpotQA show that FETSF-MRC achieves superior performance compared to several baselines. FETSF-MRC outperforms the best baseline by 1.12% and 1.49% in joint F1 score on the CJRC and CAIL2020 datasets, respectively, and achieves 73.74% joint F1 score on the HotpotQA.},
  archive      = {J_EAAI},
  author       = {Zhiqiang Lin and Fan Yang and Xuyang Wu and Jinsong Su and Xiaoyue Wang},
  doi          = {10.1016/j.engappai.2023.106178},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106178},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A feedback-enhanced two-stage framework for judicial machine reading comprehension},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An interval-valued neutrosophic based MAIRCA method for
sustainable material selection. <em>EAAI</em>, <em>123</em>, 106177. (<a
href="https://doi.org/10.1016/j.engappai.2023.106177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A plethora of Multi-Criteria Decision-Making (MCDM) methods is available for selecting an optimal material for a design problem with quantitative measurements. However, little research has been conducted on material selection methods in an interval neutrosophic environment to address uncertainty. In this research paper, a unique framework is presented that combines Interval-Valued Neutrosophic Sets (IVNSs) with the entropy–MultiAtributive Ideal-Real Comparative Analysis (MAIRCA) framework with the aim of simultaneously handling the objective criteria with crisp inputs and subjective criteria with ambiguous or uncertain information. To demonstrate the applicability of the proposed approach, a wing-spar of a Human-Powered Aircraft (HPA) is considered. At first, a panel of three subject experts makes judgments on the alternatives or criteria linguistically through IVNSs. Next, the skill level of each expert involved in the decision-making process is assessed using a novel weighting approach with linguistic information. After obtaining the objective criteria weights using the entropy weighting method, the performance of candidate materials for the HPA spar is evaluated using the MAIRCA method. The results indicate that S-glass70%-Epoxy Continuous Fibers, Ti-2Fe-3Al-10V and Al-7075 T6 are the top-ranked alternatives for spar application. The strong correlation of the proposed approach with other extant MCDM techniques demonstrates the reliability of the results obtained. In addition, the efficacy and practicality of the material selection tool is also validated with an outranking method in a simplified neutrosophic environment.},
  archive      = {J_EAAI},
  author       = {Rana Sami Ul Haq and Maryam Saeed and Noman Mateen and Faisal Siddiqui and Sohail Ahmed},
  doi          = {10.1016/j.engappai.2023.106177},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106177},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An interval-valued neutrosophic based MAIRCA method for sustainable material selection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EPT: A data-driven transformer model for earthquake
prediction. <em>EAAI</em>, <em>123</em>, 106176. (<a
href="https://doi.org/10.1016/j.engappai.2023.106176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The leading causes of earthquakes are crustal movements, plate movements, and collisions. In recent years, many researchers in earthquake prediction have been predicting earthquakes from historical seismic data in local areas. This approach ignores the underlying internal patterns of crustal motion, plate movement, and collisions. This paper proposes a purely data-driven deep learning model called EPT. The model uses gated feature extraction blocks (GFEB) to mine potential crustal motion and plate movement patterns from global historical seismic catalog data. It uses them to aid mainshock prediction in each local, provincial region. Experiments show that this approach improves model prediction accuracy by up to 50 percent. We also use multi-headed self-attention for the first time to capture long-term dependencies within regional time series, highlighting links between focal features and compensating for the difficulty of focusing on longer-term information in long-term time series with long short-term memory networks (LSTM). In addition, we also use the gradient harmonization mechanism classification (GHMC) loss function for the first time in earthquake prediction, effectively addressing the problem of uneven data distribution across different earthquake magnitude ranges. Finally, we validated the effectiveness of the EPT model in five provincial datasets in mainland China, and the experimental results all achieved an accuracy of over 90 percent.},
  archive      = {J_EAAI},
  author       = {Bo Zhang and Ziang Hu and Pin Wu and Haiwang Huang and Jiansheng Xiang},
  doi          = {10.1016/j.engappai.2023.106176},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106176},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EPT: A data-driven transformer model for earthquake prediction},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransCNN: Hybrid CNN and transformer mechanism for
surveillance anomaly detection. <em>EAAI</em>, <em>123</em>, 106173. (<a
href="https://doi.org/10.1016/j.engappai.2023.106173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surveillance video anomaly detection (SVAD) is a challenging task due to the variations in object scale, discrimination and unexpected events, the impact of the background, and the wide range of definitions of anomalous events in different surveillance contexts. In this work, we introduce an end-to-end hybrid convolution neural network (CNN) and vision transformer-based framework for anomaly detection. The proposed framework uses spatial and temporal information from a surveillance video to detect anomalous events and operates in two steps: in the first step, an efficient backbone CNN model is used for spatial feature extraction, while in the second step, these features are passed from the transformer-based model to learn the long-term temporal relationships between various complex surveillance events. The features from the backbone model are fed to a sequential learning model in which temporal self-attention is utilised to generate an attention map; this allows the proposed framework to learn the spatiotemporal features effectively and to detect anomalous events. Our experimental results on various benchmark VAD datasets prove the validity of the proposed framework, which outperforms other state-of-the-art approaches by achieving high AUC values of 94.6 %, 98.4 %, and 89.6 % on the ShanghaiTech, UCSD Ped2 and CUHK avenue datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Waseem Ullah and Tanveer Hussain and Fath U Min Ullah and Mi Young Lee and Sung Wook Baik},
  doi          = {10.1016/j.engappai.2023.106173},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106173},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TransCNN: Hybrid CNN and transformer mechanism for surveillance anomaly detection},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visual domain adaptation through locality information.
<em>EAAI</em>, <em>123</em>, 106172. (<a
href="https://doi.org/10.1016/j.engappai.2023.106172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional machine learning methods have always performed the learning tasks solely. The models of these conventional methods have to be built from scratch. The idea of domain adaptation can overcome this learning procedure by adapting the knowledge gained from one domain to another. With datasets from several domains, this research proposes a novel strategy for unsupervised visual domain adaptation. Existing transfer learning approaches try to reduce the domain shift using maximum mean discrepancy metric. We propose a combined framework termed Visual Domain Adaptation through Locality Information (DALI) that lowers the geometrical distance between the domains while probabilistically addressing the shortcomings. The proposed approach employs the input data features to develop a technique that assists in inducing the transfer of information from one domain to another. Extensive experimental findings demonstrate that the proposed method DALI excels over traditional domain adaptation algorithms as well as CNN architectures on a variety of cross-domain object, facial, and digit recognition tasks including Office-Caltech, Office-Home, PIE and COIL datasets. Our proposed model has improved the mean accuracy to 69.69%, exceeding the most recent state-of-the-art techniques when performed a comprehensive analysis on the Office-Home data.},
  archive      = {J_EAAI},
  author       = {Devika A.K. and Rakesh Kumar Sanodiya and Babita Roslind Jose and Jimson Mathew},
  doi          = {10.1016/j.engappai.2023.106172},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106172},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Visual domain adaptation through locality information},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Neural message-passing for objective-based uncertainty
quantification and optimal experimental design. <em>EAAI</em>,
<em>123</em>, 106171. (<a
href="https://doi.org/10.1016/j.engappai.2023.106171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various real-world scientific applications involve the mathematical modeling of complex uncertain systems with numerous unknown parameters. Accurate parameter estimation is often practically infeasible in such systems, as the available training data may be insufficient and the cost of acquiring additional data may be high. In such cases, based on a Bayesian paradigm, we can design robust operators retaining the best overall performance across all possible models and design optimal experiments that can effectively reduce uncertainty to enhance the performance of such operators maximally. While objective-based uncertainty quantification (objective-UQ) based on MOCU (mean objective cost of uncertainty) provides an effective means for quantifying uncertainty in complex systems, the high computational cost of estimating MOCU has been a challenge in applying it to real-world scientific/engineering problems. In this work, we propose a novel scheme to reduce the computational cost for objective-UQ via MOCU based on a data-driven approach. We adopt a neural message-passing model for surrogate modeling, incorporating a novel axiomatic constraint loss that penalizes an increase in the estimated system uncertainty. As an illustrative example, we consider the optimal experimental design (OED) problem for uncertain Kuramoto models, where the goal is to predict the experiments that can most effectively enhance robust synchronization performance through uncertainty reduction. We show that our proposed approach can accelerate MOCU-based OED by four to five orders of magnitude, without any visible performance loss compared to the state-of-the-art. The proposed approach applies to general OED tasks, beyond the Kuramoto model.},
  archive      = {J_EAAI},
  author       = {Qihua Chen and Xuejin Chen and Hyun-Myung Woo and Byung-Jun Yoon},
  doi          = {10.1016/j.engappai.2023.106171},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106171},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural message-passing for objective-based uncertainty quantification and optimal experimental design},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The appropriation of blockchain implementation in the supply
chain of SMES based on fuzzy LMAW. <em>EAAI</em>, <em>123</em>, 106169.
(<a href="https://doi.org/10.1016/j.engappai.2023.106169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the adoption of blockchain technology in small and medium-sized enterprises’ (SMEs) supply chains. Blockchain has been deemed a “Game Changer” for its potential benefits but also has several limitations due to its properties and SMEs’ limited resources. Small and medium-sized companies (SMEs) have more problems employing Industry 4.0 Technologies in practice than larger companies. So, the employment of BC in SMEs’ supply chains, as the economy’s backbone, deserves a full investigation which has been addressed in this paper. We use the Technology–Organization–Environment framework to examine both positive and negative factors affecting blockchain adoption in SMEs. A Delphi method was used to refine a list of 42 factors down to the 22 most essential ones. These factors were then prioritized using the Fuzzy Logarithmic Additive Weights Methodology based on expert preferences. The findings indicate that while financial factors play a crucial role in adoption, transparency, and traceability are significant benefits that motivate organizations to adopt blockchain. The organizational dimension also has a substantial impact on decision-making. In this study, we conclude that SMEs must carefully consider their circumstances before adopting blockchain technology, given its infancy state. The barriers to adoption are just as significant as incentives, and SMEs must weigh the financial and organizational factors before making the decision. This study extends the literature by comprehensively looking at all possible factors influencing BC adoption by SMEs. Furthermore, we have highlighted valuable insights for policymakers and SME owners to make the best decision.},
  archive      = {J_EAAI},
  author       = {Mandana Asadi and Sarfaraz Hashemkhani Zolfani and Dragan Pamucar and Jalil Salimi and Sara Saberi},
  doi          = {10.1016/j.engappai.2023.106169},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106169},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The appropriation of blockchain implementation in the supply chain of SMES based on fuzzy LMAW},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Automatic polyp segmentation via image-level and
surrounding-level context fusion deep neural network. <em>EAAI</em>,
<em>123</em>, 106168. (<a
href="https://doi.org/10.1016/j.engappai.2023.106168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than 95% of colorectal cancers are gradually transformed from polyps, so regular colonoscopy polyp examination plays an important role in cancer prevention and early treatment. However, automatic polyp segmentation remains a challenging task due to the low-contrast tissue environment and the small size and variety ( e.g. , shape, color, texture) of polyps. In this case, the rich context information in colonoscopy images is worth exploring to address the above issues. On the one hand, the image-level context with a global receptive field can be used to enhance the discrimination between the foreground and the background to alleviate the occult and indistinguishability of polyps in colonoscopy images. On the other hand, the surrounding-level context focused on the surrounding pathological region of the polyp has more detailed features that are beneficial for polyp segmentation. Therefore, we propose a novel network named ISCNet that aims to fuse image-level and surrounding-level context information for polyp segmentation. Specifically, we first introduce the Global-Guided Context Aggregation (GGCA) module to explicitly model the foreground and background of polyp segmentation through image-level context, thereby flexibly enhancing polyp-related features and suppressing background-related features. Then, we design the Diverse Surrounding Context Focus (DSCF) module to focus on the surrounding area of the polyp to extract diverse local contexts to refine the segmentation results. Finally, we fuse the feature maps derived from these two modules so that our ISCNet can enjoy the facilitation of both the image-level and surrounding-level context information. To verify the effectiveness of our method, we conduct comprehensive experimental evaluations on three challenging datasets. The quantitative and qualitative experimental results confirm that our ISCNet outperforms current state-of-the-art methods by a large margin. Our code is available at https://github.com/vvmedical/ISCNet .},
  archive      = {J_EAAI},
  author       = {Changwei Wang and Rongtao Xu and Shibiao Xu and Weiliang Meng and Xiaopeng Zhang},
  doi          = {10.1016/j.engappai.2023.106168},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106168},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic polyp segmentation via image-level and surrounding-level context fusion deep neural network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A deep multi-instance neural network for dyeing-free
inspection of yarn dyeing uniformity. <em>EAAI</em>, <em>123</em>,
106159. (<a
href="https://doi.org/10.1016/j.engappai.2023.106159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dyeing evenness is a decisive factor influencing the commercial values of polyester yarn. Thus, the inspection of yarn dyeing uniformity plays a vital role in the textile community. Due to the inefficiency of dyeing process, the traditional dyeing-based inspection methods are both laborious and time-consuming. To improve efficiency, this study attempts to develop a fast dyeing-free method for dyeing uniformity inspection based on imaging spectrometer and multi-instance learning (MIL). The relevant properties of yarn samples are first recorded in the hyperspectral images (HSIs). As the available labels are ambiguous, classifying the collected HSIs has become a MIL problem. Meanwhile, the correlation between the spectral pixels and the sample labels might be sophisticated. It might be difficult for the existing MIL methods to learn such data. In this paper, a deep Fisher score-based multi-instance neural network (DFSNet) is also proposed for classifying the captured HSIs. The DFSNet is able to learn a sophisticated correlation between deep instance features and bag representation. Specifically, a Fisher score-based MIL pooling layer is first developed to convert the instance-level features into bag-level features. The DFSNet is then developed with a ladder structure and the Fisher score-based MIL pooling layer. The proposed dyeing-free method and DFSNet are evaluated using the actual polyester samples. Moreover, the proposed DFSNet and the spectral range of HSI are further analyzed. The experiment results have indicated that the proposed method could achieve satisfactory performance, providing a potential solution to fast dyeing uniformity inspection.},
  archive      = {J_EAAI},
  author       = {Shiluo Huang and Zheng Liu and Wei Jin and Ying Mu},
  doi          = {10.1016/j.engappai.2023.106159},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106159},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep multi-instance neural network for dyeing-free inspection of yarn dyeing uniformity},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical federated learning with local model embedding.
<em>EAAI</em>, <em>123</em>, 106148. (<a
href="https://doi.org/10.1016/j.engappai.2023.106148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning can synergize the local model training with private data samples from geo-distributed users. Nevertheless, the unification process of a comprehensive global model through periodical parameter sharing can be time-consuming at a high cost. On the one hand, the data samples are collected from users with diverse preferences, and the data distribution can be non-independent and identically distributed (non-IID). On the other hand, the consequent model trained locally needs to communicate with a remote parameter server periodically for parameter synchronization, which leads to overwhelming communication and synchronization overhead given heterogeneous device capacities and network conditions of end-users. Generally, a hierarchical system design with a clustered group is ideal for accommodating diversity. Actually, it is still challenging to maintain the relationship of the local model training without knowing the data samples in advance for privacy concerns. Therefore, we present hierarchical federated model embedding to formulate the relationship between local data distributions. Initially, the local models are embedded through the global shared dataset to obtain feature latent representation vectors. The cloud server groups the clients according to the vectors, making clients with similar data distribution train collaboratively in a same group. Then, these vectors are used to train the predictor on the cloud server, which is utilized for efficient group assignment when new clients join the system. Compared with the baseline, the accuracy of the group model can be improved by 1 . 22 % ∼ 5 . 63 % and that of the global model can be improved by 3 . 97 % ∼ 14 . 25 % on different datasets.},
  archive      = {J_EAAI},
  author       = {Yunlong He and Dandan Yan and Fei Chen},
  doi          = {10.1016/j.engappai.2023.106148},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106148},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical federated learning with local model embedding},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-fault diagnosis of industrial rotating machines using
data-driven approach: A review of two decades of research.
<em>EAAI</em>, <em>123</em>, 106139. (<a
href="https://doi.org/10.1016/j.engappai.2023.106139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 4.0 is an era of smart manufacturing. Manufacturing is impossible without the use of machinery. The majority of these machines comprise rotating components and are called rotating machines. The engineers’ top priority is to maintain these critical machines to reduce the unplanned shutdown and increase the useful life of machinery. Predictive maintenance is the current trend of smart maintenance, followed by most maintenance engineers. The challenging task in predictive maintenance is to diagnose the type of fault. With Artificial Intelligence (AI) advancement, a data-driven approach for predictive maintenance is taking a new flight towards smart manufacturing. Several researchers have published work related to fault diagnosis in rotating machines, mainly exploring a single type of fault. However, a consolidated review of literature that focuses more on the “multi-fault diagnosis” aspect of rotating machines is lacking. There is a need for a study that would systematically cover all the aspects right from sensor selection, data acquisition, feature extraction, multi-sensor data fusion to the systematic review of AI techniques employed in multiple fault diagnosis. In this regard, this paper attempts to achieve the same by implementing a systematic literature review on a Data-driven approach for multi-fault diagnosis of Industrial Rotating Machines using the “Preferred Reporting Items for Systematic Reviews and Meta-Analysis” (PRISMA) method. The PRISMA method is a collection of guidelines for the composition and structure of systematic reviews and other meta-analyses. This paper identifies the foundational work done in the field and gives a comparative study of different aspects related to multi-fault diagnosis of industrial rotating machines. The paper also identifies the major challenges, research gap. It gives solutions using recent advancements in AI in implementing multi-fault diagnosis, giving a strong base for future research in this field.},
  archive      = {J_EAAI},
  author       = {Shreyas Gawde and Shruti Patil and Satish Kumar and Pooja Kamat and Ketan Kotecha and Ajith Abraham},
  doi          = {10.1016/j.engappai.2023.106139},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106139},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-fault diagnosis of industrial rotating machines using data-driven approach: A review of two decades of research},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving question answering performance using knowledge
distillation and active learning. <em>EAAI</em>, <em>123</em>, 106137.
(<a href="https://doi.org/10.1016/j.engappai.2023.106137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary question answering (QA) systems, including Transformer-based architectures, suffer from increasing computational and model complexity which render them inefficient for real-world applications with limited resources. Furthermore, training or even fine-tuning such models requires a vast amount of labeled data which is often not available for the task at hand. In this manuscript, we conduct a comprehensive analysis of the mentioned challenges and introduce suitable countermeasures. We propose a novel knowledge distillation (KD) approach to reduce the parameter and model complexity of a pre-trained bidirectional encoder representations from transformer (BERT) system and utilize multiple active learning (AL) strategies for immense reduction in annotation efforts. We show the efficacy of our approach by comparing it with four state-of-the-art (SOTA) Transformers-based systems, namely KroneckerBERT, EfficientBERT, TinyBERT, and DistilBERT. Specifically, we outperform KroneckerBERT 21 and EfficientBERT TINY by 4.5 and 0.4 percentage points in EM, despite having 75.0% and 86.2% fewer parameters, respectively. Additionally, our approach achieves comparable performance to 6-layer TinyBERT and DistilBERT while using only 2% of their total trainable parameters. Besides, by the integration of our AL approaches into the BERT framework, we show that SOTA results on the QA datasets can be achieved when we only use 40% of the training data. Overall, all results demonstrate the effectiveness of our approaches in achieving SOTA performance, while extremely reducing the number of parameters and labeling efforts. Finally, we make our code publicly available at https://github.com/mirbostani/QA-KD-AL .},
  archive      = {J_EAAI},
  author       = {Yasaman Boreshban and Seyed Morteza Mirbostani and Gholamreza Ghassem-Sani and Seyed Abolghasem Mirroshandel and Shahin Amiriparian},
  doi          = {10.1016/j.engappai.2023.106137},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106137},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving question answering performance using knowledge distillation and active learning},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An ALBERT-based TextCNN-hatt hybrid model enhanced with
topic knowledge for sentiment analysis of sudden-onset disasters.
<em>EAAI</em>, <em>123</em>, 106136. (<a
href="https://doi.org/10.1016/j.engappai.2023.106136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sudden-onset disasters put forward new requirements for on the state authorities’ ability to analyze public opinion sentiment. However, traditional sentiment analysis methods ignore the contextual semantic relationships and out-of-vocabulary words, and their computational resource utilization is excessive compared to their expected accuracy. In this paper, an ALBERT-based model combined with a text convolution neural network, a hierarchical attention mechanism and the latent Dirichlet allocation is proposed to create a hybrid model enhanced with topic knowledge for sentiment analysis of sudden-onset disasters. Weibo text data from a rainstorm disaster in China are used to evaluate the model’s performance. Compared with the XLNet, DistilBERT and RoBERTa models, the experimental results demonstrate that the proposed approach is capable of achieving better performance by incorporating external topic knowledge into the language representation model to compensate for the limited vocabulary data.},
  archive      = {J_EAAI},
  author       = {Xinsheng Zhang and Yulong Ma},
  doi          = {10.1016/j.engappai.2023.106136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An ALBERT-based TextCNN-hatt hybrid model enhanced with topic knowledge for sentiment analysis of sudden-onset disasters},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A combination-based machine learning algorithm estimating
impacts of social, economic, and environmental on resident health—on
china’s provincial panel data. <em>EAAI</em>, <em>123</em>, 106135. (<a
href="https://doi.org/10.1016/j.engappai.2023.106135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The factors influencing residents health have become complex and intertwined with the development of economy and society. Traditional research with a single factor on health will not provide an accurate picture of the situation. This paper collects data on economic, environmental and social factors to estimate their impact on regional health. Considering the data is multi-source and complex, this paper proposes a combined feature importance algorithm, which weighted the feature importance of RF, XGB and SOIL. The algorithm does not depend on the data and adaptively approximates the true results. The results show that economic factors have a significant and direct impact on health, environmental factors have a lag correlation with health level, and social factors have a more complicated effect on health. Finally, we provide policy suggestions for health on economic, environmental, and social development.},
  archive      = {J_EAAI},
  author       = {Li Wen and Wei Pan and Shujie Liao and Wulin Pan and Hui Xu and Cheng Hu},
  doi          = {10.1016/j.engappai.2023.106135},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106135},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combination-based machine learning algorithm estimating impacts of social, economic, and environmental on resident health—on china’s provincial panel data},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Image caption generation using a dual attention mechanism.
<em>EAAI</em>, <em>123</em>, 106112. (<a
href="https://doi.org/10.1016/j.engappai.2023.106112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to create a statement that accurately captures the main idea of an ambiguous visual, which is said to be a significant and demanding task? Conventional image captioning schemes are categorized into 2 classes: retrieval-oriented schemes and generation-oriented schemes. The image caption generating system should provide precise, fluid, natural, and informative phrases as well as accurately identify the content of the image, such as scene, object, relationship, and properties of the object in the image. However, it can be challenging to accurately express the image’s content when creating image captions because not all visual information can be used. In this article, a new image captioning model is introduced that includes 3 main phases like (1) Extraction of Inception V3 features (2) Dual (Visual and Textual) attention generation and (3) generation of image caption. Convolutional Neural Network (CNN) is used to generate visual attention after first deriving initial V3 features. The input texts for the associated images, on the other hand, are analyzed and given to LSTM for the creation of textual attention. To create image captions, Bidirectional LSTM (BI-LSTM) is used to combine textual and visual attention. The Self Improved Electric Fish Optimization (SI-EFO) algorithm is used in particular to optimize the weights of the BI-LSTM. In the end, several measures confirm that the implemented system has improved. The adopted model is 35.21%, 33.76%, 39.52%, 29.69%, 30.12%, 21.49%, and 31.71% better than GAN-RL, LSTM, GRU, EC + GOA, EC + CMBO, EC + DA, EC + EFO models.},
  archive      = {J_EAAI},
  author       = {Roshni Padate and Amit Jain and Mukesh Kalla and Arvind Sharma},
  doi          = {10.1016/j.engappai.2023.106112},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106112},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Image caption generation using a dual attention mechanism},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepDrive: A braking decision making approach using
optimized GAN and deep CNN for advanced driver assistance systems.
<em>EAAI</em>, <em>123</em>, 106111. (<a
href="https://doi.org/10.1016/j.engappai.2023.106111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reduction of the number of traffic accidents is a vital requirement in many countries over the world. In these circumstances, the Human–Robot Interaction (HRI) mechanisms utilization is currently exposed as a possible solution to recompense human limits. It is crucial to create a braking decision-making model in order to produce the optimal decisions possible because many braking decision-making approaches are launched with minimal performance. An effective braking decision-making system, named Optimized Deep Drive decision model is developed for making braking decisions. The video frames are extracted and the segmentation process is done using a Generative Adversarial Network (GAN). GAN is trained using the newly developed optimization technique known as the Autoregressive Anti Corona Virus Optimization (ARACVO) algorithm. ARACVO is created by combining the Conditional Autoregressive Value at Risk by Regression Quantiles (CAViaR) and Anti Corona Virus Optimization (ACVO) models. After retrieving the useful information for processing, the Deep Convolutional Neural Network (Deep CNN) is next used to decide whether to apply the brakes. The proposed approach improved performance by achieving maximum values of 0.911, 0.906, 0.924, and 0.933 for segmentation accuracy, accuracy, sensitivity, and specificity.},
  archive      = {J_EAAI},
  author       = {S. Veluchamy and K. Michael Mahesh and Pon Bharathi A. and Paul T. Sheeba},
  doi          = {10.1016/j.engappai.2023.106111},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106111},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DeepDrive: A braking decision making approach using optimized GAN and deep CNN for advanced driver assistance systems},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HINNet: Inertial navigation with head-mounted sensors using
a neural network. <em>EAAI</em>, <em>123</em>, 106066. (<a
href="https://doi.org/10.1016/j.engappai.2023.106066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human inertial navigation systems have been developing rapidly in recent years, and it has shown great potential for applications within healthcare, smart homes, sports, and emergency services. Placing inertial measurement units on the head for localisation is relatively new. However, it provides a very interesting option, as there are several everyday head-worn items that could easily be equipped with sensors. Yet, there remains a lack of research in this area and currently no localisation solutions have been offered that allow for free head-rotations during long periods of walking. To solve this problem, we present HINNet, the first deep neural network (DNN) pedestrian inertial navigation system allowing free head movements with head-mounted inertial measurement units (IMUs), which deploys a 2-layer bi-directional LSTM. A new ’peak ratio’ feature is introduced and utilised as part of the input to the neural network. This information can be leveraged to solve the issue of differentiating between changes in movements related to the head and those that are associated with the walking pattern. A dataset with 8 subjects totalling 528 min has been collected on three different tracks for training and verification. The HINNet could effectively distinguish head rotations and changes in walking direction with a distance percentage error of 0.46%, a relative trajectory error of 3.88 m, and a absolute trajectory error of 5.98 m, which outperforms the current best head-mounted Pedestrian Dead Reckoning (PDR) method.},
  archive      = {J_EAAI},
  author       = {Xinyu Hou and Jeroen H.M. Bergmann},
  doi          = {10.1016/j.engappai.2023.106066},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {106066},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HINNet: Inertial navigation with head-mounted sensors using a neural network},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intrusion detection system using exponential henry gas
solubility optimization based deep neuro fuzzy network in MANET.
<em>EAAI</em>, <em>123</em>, 105969. (<a
href="https://doi.org/10.1016/j.engappai.2023.105969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smoothness and dynamic nature of the exploitation are significantly influenced by Mobile Ad hoc Networks (MANETs). The wireless and active environments, on the other hand, are vulnerable to a range of threats. Enhancing the reliable intrusion detection model is crucial to safeguarding the MANET from various malicious attacks. In this paper, an effective intrusion detection method for MANET is presented based on a Deep Neuro Fuzzy Network based on Exponential-Henry Gas Solubility Optimization (EHGSO). The newly designed EHGSO algorithm is used to select the optimal routes in the early phases of safe routing. The fitness metrics that define this approach include energy, distance, neighbourhood quality, and link quality. The proposed EHGSO combines the Henry Gas Solubility Optimization (HGSO) with Exponential Weighted Moving Average (EWMA). The second phase, in which the conveyed data packets are altered and the Knowledge discovery in databases (KDD) features are extracted, starts the intrusion detection phase at the base station. Following the extraction of the KDD features, data augmentation is performed. The Deep Neuro Fuzzy Network is trained using the suggested EHGSO method before performing intrusion detection. The proposed method demonstrates higher performance when compared to all other existing technologies. In without attacks scenario, the values achieved by the proposed method considering the metrics, such as energy, throughput, packet drop, jitter, Performance and Development Review (PDR), precision, and recall is 0.342 J, 134975 kbps, 4.123, 0.086, 95.877%, 0.950, and 0.924, respectively.},
  archive      = {J_EAAI},
  author       = {Dr. S.B. Ninu},
  doi          = {10.1016/j.engappai.2023.105969},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {105969},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intrusion detection system using exponential henry gas solubility optimization based deep neuro fuzzy network in MANET},
  volume       = {123},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Retraction notice to “a comparative study on end-to-end
deep learning methods for electroencephalogram channel selection” [eng.
Appl. Artif. Intell. 122 (2023) 106122]. <em>EAAI</em>, <em>122</em>,
106456. (<a
href="https://doi.org/10.1016/j.engappai.2023.106456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Abdullah and Ibrahima Faye and Md Rafiqul Islam},
  doi          = {10.1016/j.engappai.2023.106456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Retraction notice to “A comparative study on end-to-end deep learning methods for electroencephalogram channel selection” [Eng. appl. artif. intell. 122 (2023) 106122]},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel multivariable grey differential dynamic prediction
model with new structures and its application to carbon emissions.
<em>EAAI</em>, <em>122</em>, 106174. (<a
href="https://doi.org/10.1016/j.engappai.2023.106174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate prediction of carbon emissions is of great significance for countries to implement scientific and effective policies and measures. In this paper, a novel multivariable grey differential dynamic prediction model is established to analyse and forecast China’s carbon emissions. The differential term of the correlation variables is introduced to consider the influence of the rate of change of the related factors on the system. The linear correction term and grey action are introduced to increase the stability and adaptability of the model. The whitening differential equation of the model is solved by the Sadik transform, and the time response of the model is obtained. In the case study, the model used China’s carbon emissions and related data from 2004 to 2019 to calculate four cases. Its minimum simulation and prediction errors are 1.4435% and 3.1739%, respectively. Compared with the other four models, this model has better simulation and prediction accuracy, which proves the model’s effectiveness. Finally, the model forecasts China’s carbon emissions from 2020 to 2024, and some suggestions are put forwards based on the predicted results.},
  archive      = {J_EAAI},
  author       = {Weige Nie and Huiming Duan},
  doi          = {10.1016/j.engappai.2023.106174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel multivariable grey differential dynamic prediction model with new structures and its application to carbon emissions},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new markov–dubins hybrid solver with learned decision
trees. <em>EAAI</em>, <em>122</em>, 106166. (<a
href="https://doi.org/10.1016/j.engappai.2023.106166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the applicability of machine learning models and techniques to the Markov–Dubins path planning problem have been explored. Machine learning techniques are already applied to several fields, which range from computer vision, to physics simulation, to item recommendation, to user profiling. This pervasiveness has led to marked improvements in the implementation and support for applying machine learning models, in particular for specialised use cases such as low-power devices, embedded hardware, and real-time applications. On the other hand, the Markov–Dubins path planning problem, which is central in robotic nonholonomic trajectory design, is already covered by established numerical and optimisation techniques. However, the benefits of applying machine learning approaches to this problem remain to be investigated. In particular, there is the need to research potential speed-ups or application domains that would be better solved by a machine learning approach compared to the traditional algorithmic approaches. In this study, we train a state-of-the-art machine learning model in a supervised setting on Markov–Dubins and use it in two different ways: to directly predict the solution, and to filter candidate solutions. Also, a comparison of the quality of these predictions with a state-of-the-art Markov–Dubins solver is made. The results obtained indicate that machine learning approaches are comparable to state-of-the-art solutions: our bare model, directly predicting the solution, appears to be 8.3 times faster than the current standard, sacrificing the accuracy, which amounts to a value close to 92%; the hybrid model that filters the solutions prior to finding the best candidate runs in times that are comparable to the classical solver (58 ms) and has over 98% accuracy. A further comparison with alternative solvers and techniques, such as Optimal Control, NonLinear Programming and Mixed Integer NonLinear Programming has been made, confirming the benefits of the machine learning approach over these, for which the computational times are in the range of seconds. This opens new avenues for interdisciplinary applications of machine learning to more general planning problems (e.g., the same problem in 3D), where the number of possible manoeuvres is large and the computation of each of them requires a considerable computational effort, which makes the brute force trial-and-error infeasible.},
  archive      = {J_EAAI},
  author       = {Cristian Consonni and Martin Brugnara and Paolo Bevilacqua and Anna Tagliaferri and Marco Frego},
  doi          = {10.1016/j.engappai.2023.106166},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106166},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new Markov–Dubins hybrid solver with learned decision trees},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated detection of scaphoid fractures using deep neural
networks in radiographs. <em>EAAI</em>, <em>122</em>, 106165. (<a
href="https://doi.org/10.1016/j.engappai.2023.106165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scaphoid is one of the most common carpal bone fractures diagnosed using radiographs. However, occult scaphoid fractures not visible on radiographs make early diagnosis and treatment difficult. Hence, the objective of this study was to develop a high-performing deep-learning model for the detection of apparent fracture and non-apparent occult scaphoid fractures using only plain wrist radiographs. This work used 525 x-ray images, 250 of which were normal scaphoids, 219 were fractured scaphoids, and 56 were occult fracture X-rays. These X-ray images were obtained from the Department of Orthopaedics, Kasturba Medical College’s (KMC), Manipal. A CNN-based deep learning model was developed for two classes (normal VS fracture) and three classes (normal VS fracture VS occult). For fracture localization, gradient-weighted class activation mapping (Grad-CAM) was used. For two-class classification, the proposed CNN model achieved sensitivity, specificity, accuracy and AUC of 92%, 88%, 90% and 0.95, respectively. For three-class classification, the proposed model achieved an overall performance of 85% sensitivity, 91% specificity, 90% accuracy and 0.88 AUC. Wrist radiograph images used to train the model did not undergo a segmentation process, saving time and improving efficiency if implemented in a hospital setting.},
  archive      = {J_EAAI},
  author       = {Amanpreet Singh and Ali Abbasian Ardakani and Hui Wen Loh and P.V. Anamika and U. Rajendra Acharya and Sidharth Kamath and Anil K. Bhat},
  doi          = {10.1016/j.engappai.2023.106165},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106165},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated detection of scaphoid fractures using deep neural networks in radiographs},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel failure mode and effect analysis method with
spherical fuzzy entropy and spherical fuzzy weight correlation
coefficient. <em>EAAI</em>, <em>122</em>, 106163. (<a
href="https://doi.org/10.1016/j.engappai.2023.106163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a proactive reliability analysis technique, the purpose of failure mode and effect analysis (FMEA) is the detection of all failures and their effects within a system, and the determination of the causes of these failures. However, the traditional FMEA method shows some important drawbacks regarding failure mode evaluations, risk factor weights and risk priority ranking, etc. This paper aims to develop a novel FMEA to improve the performance of FMEA by using spherical fuzzy sets (SFSs) and spherical fuzzy weight correlation coefficient (SF-WCC). The method mainly includes three stages. The SFS is applied to capture risk evaluation information because it comprehensively considers the information expression in different scenarios in the first stage. A spherical fuzzy projection model is introduced to calculate the expert weights objectively for reducing the information difference caused by experience, psychology and other cognitive factors of experts in the second stage. Meanwhile, the spherical fuzzy entropy is defined to determine the incomplete weights of risk factors by constructing an optimization model in the second stage. The SF-WCC is proposed to prioritize the failure modes to avoid the prioritization controversy of failure modes by using different distance formulas in the third stage. In the experiment, a practical example is presented to illustrate the applicability and effectiveness of the proposed method, and results show that the proposed approach offers a reliable tool for practical FMEA problems. The conclusion is that the proposed method is applicable to multiple actual scenarios as a reliable risk assessment technology.},
  archive      = {J_EAAI},
  author       = {Qian-Xia Ma and Xiao-Min Zhu and Kai-Yuan Bai and Run-Tong Zhang and Dong-Wei Liu},
  doi          = {10.1016/j.engappai.2023.106163},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106163},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel failure mode and effect analysis method with spherical fuzzy entropy and spherical fuzzy weight correlation coefficient},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Process optimization for textile industry-based wastewater
treatment via ultrasonic-assisted electrochemical processing.
<em>EAAI</em>, <em>122</em>, 106162. (<a
href="https://doi.org/10.1016/j.engappai.2023.106162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The treatment of industrial wastewater at a reasonable cost and in a sustainable approach is a major challenge. The primary objective of this study is to perform textile wastewater treatment by exploring the ultrasonic-assisted electrochemical (UEC) process with parameter optimization. Statistical modeling has been carried out in order to investigate the influence of operating parameters, including pH (4–10), current density (5–20 mA/cm 2 ), electrolysis time (10–30 min), and ultrasonic power (0–500 watt) on color, chemical oxygen demand (COD), and turbidity removal efficiency. The combination of response surface methodology (RSM) and artificial neural network (ANN) based statistical models are applied to predict and examine the reliance of the operating parameters on removal efficiencies. The results validate that at optimal operating condition (pH 7.3, current density 15.7 mA/cm 2 , processing duration 21.5 min, and ultrasonic power 420 W), the actual removal efficiencies of color, COD, and turbidity was 97%, 66%, and 79% respectively. The central composite design (CCD) based RSM model predicts the removal efficiencies of color, COD, and turbidity was 93.9 %, 63.6 %, and 77.1 %, respectively. In contrast, the ANN model predicts removal efficiencies of color, COD, and turbidity of 99.3%, 82.1%, and 78.7%, respectively at optimized operating conditions. The results indicated that the ANN model had a greater coefficient of determination (R 2 ) value and smaller mean square error (MSE) than RSM model, showing that ANN is preferable at forecasting response, while RSM accurately predicts impacts of operating parameters. The present manufacturing process with statistical optimization techniques may be envisioned for the large-scale treatment of industrial wastewater.},
  archive      = {J_EAAI},
  author       = {Prince Kumar Rai and Vishav Kant and Rakesh Kumar Sharma and Ankur Gupta},
  doi          = {10.1016/j.engappai.2023.106162},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106162},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Process optimization for textile industry-based wastewater treatment via ultrasonic-assisted electrochemical processing},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep neural network-based model for OSA severity
classification using unsegmented peripheral oxygen saturation signals.
<em>EAAI</em>, <em>122</em>, 106161. (<a
href="https://doi.org/10.1016/j.engappai.2023.106161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive sleep apnea (OSA) is a common type of sleep-related breathing disorder, and polysomnography (PSG) remains the gold standard for its diagnosis. However, it takes a significant amount of time to perform PSG in a well-equipped laboratory, and patients typically have to wait a long time for a PSG test. In view of this, over recent years portable and even wearable tools for OSA classification have been developed as a low-cost and easy-to-use alternative to PSG. In this paper, a deep neural network (DNN)-based model was developed to classify OSA severity using peripheral oxygen saturation (SpO 2 ) signals; it showed the following advantages. First, the presented model takes unsegmented SpO 2 signals recorded overnight as its input, and OSA severity is then classified as one of four levels as the output. Consequently, there is obviously no need to label segmented signals, and the tremendous amount of effort spent on signal segmentation and then annotation can be completely saved. Second, a high generalization ability is provided since the largest amount of data were used to test the model. This feature gives the model an improved reliability for clinical use. Notably, the outperformance of this work is highlighted in a two-level classification case (with a cutoff apnea–hypopnea index of 5), where the accuracy and the sensitivity increased to above 91% and 95%, respectively.},
  archive      = {J_EAAI},
  author       = {Jeng-Wen Chen and Chia-Ming Liu and Cheng-Yi Wang and Chun-Cheng Lin and Kai-Yang Qiu and Cheng-Yu Yeh and Shaw-Hwa Hwang},
  doi          = {10.1016/j.engappai.2023.106161},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106161},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep neural network-based model for OSA severity classification using unsegmented peripheral oxygen saturation signals},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing electrode positions on forearm to increase SNR
and myoelectric pattern recognition performance. <em>EAAI</em>,
<em>122</em>, 106160. (<a
href="https://doi.org/10.1016/j.engappai.2023.106160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in electromyography-based human–computer interaction, particularly in myoelectric prosthetic hands, the position of electromyography electrodes has gained less attention from researchers. However, the performance of hand movement recognition significantly varies with the change of electrode position around the forearm muscles and along the length of the forearm muscles. To find the robust position on the forearm, this study performs a comprehensive and systematic investigation of the feasibility of hand movement recognition using electromyogram (EMG) signals concurrently recorded for sixteen electrode arrays on the forearm. The obtained results indicate that the electrode array placed on the middle of the extensor digitorum communis and extensor digiti minimi performs better than other electrode positions around the forearm. In addition, multiple electrode arrays placed near to elbow joint achieve a significantly higher signal to noise ratio and signal to movement artifact ratio. In addition to improved EMG signal quality, the recommended positions on the forearm significantly overperform in hand movement recognition and it is validated with five well-known feature extraction methods, various window sizes, and three classification algorithms. In this study, the electrode arrays near to elbow joint on the forearm achieve an F1 score of 98.28% to 98.80% with a linear discriminant analysis classifier. Therefore, this study clearly demonstrates the feasibility of recommended forearm positions for hand movement recognition. As these electrode positions are near to elbow joint, so, it is expected that these positions will be available in most amputees and utilized for improved hand movement recognition.},
  archive      = {J_EAAI},
  author       = {Md. Johirul Islam and Shamim Ahmad and Arifa Ferdousi and Fahmida Haque and Mamun Bin Ibne Reaz and Mohammad Arif Sobhan Bhuiyan and Md. Rezaul Islam},
  doi          = {10.1016/j.engappai.2023.106160},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106160},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing electrode positions on forearm to increase SNR and myoelectric pattern recognition performance},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A large-scale MAGDM model based on SKNN and weighted
clustering under incomplete information. <em>EAAI</em>, <em>122</em>,
106158. (<a
href="https://doi.org/10.1016/j.engappai.2023.106158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity of multi-attribute group decision-making(MAGDM) problems, decision-makers frequently provide incomplete and hesitant evaluation information. How to make a valid decision based on incomplete and hesitant information is an important issue in MAGDM problems. Firstly, we novelly introduce a sequential K-nearest neighbor(SKNN) interpolation method to estimate the missing values based on the order of missing information proportions. When seeking the k-nearest neighbors of a decision-maker, an improved similarity measurement is proposed by considering the fuzzy-value similarity and the hesitation similarity between decision-makers simultaneously. Secondly, a K-means clustering algorithm based on attribute weighting is proposed to make the collective evaluation information more representative, and the attribute weights are obtained by constructing a mathematical model based on the minimum discrimination principle which can synthesize the subjective and objective weights information. Finally, an illustrative example and comparison analysis are demonstrated to show the validity and superiority of the proposed model.},
  archive      = {J_EAAI},
  author       = {Qianqian Wu and Donghong Tian and Ruike Lan and Min Li},
  doi          = {10.1016/j.engappai.2023.106158},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106158},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A large-scale MAGDM model based on SKNN and weighted clustering under incomplete information},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved LSTM-based deep learning model for COVID-19
prediction using optimized approach. <em>EAAI</em>, <em>122</em>,
106157. (<a
href="https://doi.org/10.1016/j.engappai.2023.106157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals in any country are badly impacted both economically and physically whenever an epidemic of infectious illnesses breaks out. A novel coronavirus strain was responsible for the outbreak of the coronavirus sickness in 2019. Corona Virus Disease 2019 (COVID-19) is the name that the World Health Organization (WHO) officially gave to the pneumonia that was caused by the novel coronavirus on February 11, 2020. The use of models that are informed by machine learning is currently a major focus of study in the field of improved forecasting. By displaying annual trends, forecasting models can be of use in performing impact assessments of potential outcomes. In this paper, proposed forecast models consisting of time series models such as long short-term memory (LSTM), bidirectional long short-term memory (Bi-LSTM), generalized regression unit (GRU), and dense-LSTM have been evaluated for time series prediction of confirmed cases, deaths, and recoveries in 12 major countries that have been affected by COVID-19. Tensorflow1.0 was used for programming. Indices known as mean absolute error (MAE), root means square error (RMSE), Median Absolute Error (MEDAE) and r2 score are utilized in the process of evaluating the performance of models. We presented various ways to time-series forecasting by making use of LSTM models (LSTM, BiLSTM), and we compared these proposed methods to other machine learning models to evaluate the performance of the models. Our study suggests that LSTM based models are among the most advanced models to forecast time series data.},
  archive      = {J_EAAI},
  author       = {Luyu Zhou and Chun Zhao and Ning Liu and Xingduo Yao and Zewei Cheng},
  doi          = {10.1016/j.engappai.2023.106157},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106157},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved LSTM-based deep learning model for COVID-19 prediction using optimized approach},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid gaussian mutation PSO with search space reduction
and its application to intelligent selection of piston seal grooves for
homemade pneumatic cylinders. <em>EAAI</em>, <em>122</em>, 106156. (<a
href="https://doi.org/10.1016/j.engappai.2023.106156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make the motion tracking control of the homemade pneumatic cylinder as accurate as possible, it is necessary to properly match the seal groove and seal ring on the piston to generate the appropriate friction. However, since the relationship between friction and motion control accuracy is not yet clear, and the friction affected by many factors cannot be accurately modeled, it is impossible to design the optimal seal groove with the highest possible motion control accuracy for pneumatic cylinder through theoretical calculation or simulation optimization. For this reason, an experimental optimization method is considered to select the optimal one from the six empirically designed seal grooves through a particle swarm optimization (PSO) algorithm. To cope with the shortcomings of slow convergence rate and the tendency to fall into local optimum of the basic PSO algorithm (BPSO), three improved PSO algorithms (HGMPSO-0, HGMPSO and HGMPSO-SSR) are successively proposed in this study. The first two improved algorithms are compared with other PSO variants on 23 benchmark functions tested, and the results show that HGMPSO has better overall performance. To significantly improve the search space search efficiency and make the algorithm converge faster, the search space contraction mechanism is introduced into the HGMPSO algorithm to form the HGMPSO-SSR algorithm. The experimental results show that the HGMPSO-SSR algorithm significantly outperforms other PSO variants used for comparison and successfully achieves intelligent selection of piston seal grooves for the designed homemade pneumatic cylinder.},
  archive      = {J_EAAI},
  author       = {Pengfei Qian and Hui Luo and Lei Liu and Pansong Lv and Chenwei Pu and Deyuan Meng and Luis Miguel Ruiz Páez},
  doi          = {10.1016/j.engappai.2023.106156},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106156},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid gaussian mutation PSO with search space reduction and its application to intelligent selection of piston seal grooves for homemade pneumatic cylinders},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized uncertainty in surrogate models for concrete
strength prediction. <em>EAAI</em>, <em>122</em>, 106155. (<a
href="https://doi.org/10.1016/j.engappai.2023.106155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applied soft computing has been widely used to predict material properties, optimal mixture, and failure modes. This is challenging, especially for the highly nonlinear behavior of brittle materials such as concrete. This paper proposes three surrogate modeling techniques (i.e., polynomial chaos expansion, Kriging, and canonical low-rank approximation) in concrete compressive strength regression analysis. A benchmark database of high-performance concrete is used with over 1,000 samples, and various sources of uncertainties in surrogate modeling are quantified, including meta-modeling assumptions, solvers, and sampling size. Two generalized extreme value distributional models are developed for error metrics using an extensive database of collected data in the literature. Bias and dispersion in the developed surrogate models are empirically compared with those distributions to quantify the overall accuracy and confidence level. Overall, the Kriging-based surrogate models outperform 80%–90% of the existing predictive models, and they illustrate more stable results. The selection of a proper optimization algorithm is the most important factor in surrogate modeling. For any practical purposes, the Kriging regression outperforms the polynomial chaos expansion and the low-rank approximation. The Kriging model is reliable for the pilot database and is less sensitive to modeling uncertainties. Finally, a series of composite error metrics is discussed as a decision-making tool that facilitates the selection of the best surrogate model using multiple criteria.},
  archive      = {J_EAAI},
  author       = {Mohammad Amin Hariri-Ardebili and Golsa Mahdavi},
  doi          = {10.1016/j.engappai.2023.106155},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106155},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generalized uncertainty in surrogate models for concrete strength prediction},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AMCC-net: An asymmetric multi-cross convolution for skin
lesion segmentation on dermoscopic images. <em>EAAI</em>, <em>122</em>,
106154. (<a
href="https://doi.org/10.1016/j.engappai.2023.106154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an encoder–decoder-based skin lesion segmentation approach is proposed with a new asymmetric multi-cross convolution (AMCC) along with a boundary-guided segmentation module. The AMCC employs a combination of convolution kernels, including 1 × 1 , 3 × 3 , 5 × 5 , and 7 × 7 with each of these k × k kernel operations subdivided into two parts: k × 1 convolution followed by one 1 × k . The proposed AMCC is designed to integrate both local and context feature information using these spatial kernels while requiring a reduced number of model parameters. The kernel outputs are permuted in different orders with their neighboring scale kernels through multi-cross convolutions, resulting in the fusion of discriminative information. The use of multi-size kernels creates a non-linear network and prevents the model from overfitting. In addition, the guided block simultaneously learns and aligns edges by refining misaligned boundaries, forming an effective attention-based framework for the execution of multi-level feature fusion. These two novel factors in the proposed methods can lead to a higher segmentation accuracy with a significantly reduced number of model parameters. The proposed AMCC model shows improved segmentation accuracy with a significantly reduced number of model parameters on the publicly accessible PH2 and ISIC-2018 datasets while achieving an accuracy of 96 %, a Dice score of 92 %, and a Jaccard index of 89% on average, only with 0.8 million parameters. These results are 2.5 times fewer parameters and up to 5% higher in accuracy compared to other state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Chaitra Dayananda and Nagaraj Yamanakkanavar and Truong Nguyen and Bumshik Lee},
  doi          = {10.1016/j.engappai.2023.106154},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106154},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AMCC-net: An asymmetric multi-cross convolution for skin lesion segmentation on dermoscopic images},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust one-class classification with support vector data
description and mixed exponential loss function. <em>EAAI</em>,
<em>122</em>, 106153. (<a
href="https://doi.org/10.1016/j.engappai.2023.106153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector data description (SVDD) has received a lot of attention due to its outstanding performance to perform one-class classification or novelty detection tasks. However, the same weight is directly imposed on all slack variables in the process of modeling, which may result in degraded learning performance when training data are contaminated by some outliers or mislabeled observations. In this paper, an extended SVDD model is therefore proposed by reformulating the original optimization problem of SVDD with a mixed exponential loss function. Since this loss function can emphasize the importance of the samples that tend to be the target class, and weaken the influence of those tending to be outliers, it can be viewed as a weighted SVDD. However, the weights in the new model are automatically calculated rather than being calculated in advance using some specific manners. To solve the optimization problem of the proposed model effectively, the half-quadratic optimization technique has been adopted to perform the optimization, generating a dynamic optimization algorithm. Meanwhile, the convergence and computational complexity of this dynamic optimization algorithm are analyzed from a theoretical respective. Experimental results on a synthetic data set and some publicly available real world data sets are reported to demonstrate the performance superiority of the new method in comparison with SVDD and other competitive SVDD variants.},
  archive      = {J_EAAI},
  author       = {Yunfei Zheng and Shiyuan Wang and Badong Chen},
  doi          = {10.1016/j.engappai.2023.106153},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106153},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust one-class classification with support vector data description and mixed exponential loss function},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining 2D encoding and convolutional neural network to
enhance land cover mapping from satellite image time series.
<em>EAAI</em>, <em>122</em>, 106152. (<a
href="https://doi.org/10.1016/j.engappai.2023.106152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of high spatial resolution Satellite Image Time Series (SITS) provides an opportunity for a wide spectrum of Earth surface monitoring applications such as Land Use/Land Cover (LULC) mapping. Whereas the majority of Time Series (TS) classification literature concentrates on the analysis of raw 1D signals, here, we investigate a framework for LULC mapping based on 2D encoded multivariate SITS data to enhance their classification performances. In this novel approach, multivariate SITS data are transformed from 1D signals to 2D images using several encoding techniques namely Gramian Angular Summation field (GASF), Gramian angular difference field (GADF), Markov Transition Field (MTF), and Recurrence Plot (RP). Successively, a new multi-band image is derived and it is used as input to a state-of-the-art convolutional neural network (CNN) classification model. The possibility to effectively encode multivariate TS data into 2D representations paves the way to reuse the huge amount of research findings coming from the general field of computer vision and build on reliable and robust methods that have been demonstrated their quality in a multitude of downstream applications. Experiments carried out on three real-world benchmarks covering large spatial areas with contrasted land cover features, namely: Dordogne department in France, Reunion Island an oversee French territory and Koumbia municipality in Burkina Faso, underline the quality of the proposed framework when compared to standard approaches for land cover mapping from SITS and recent methods for multivariate TS classification. Matter of fact, our new framework outperforms the classification performances of standard land cover classification strategies based on the raw TS information achieving an average F1-score of 89.34%, 90.26% and 78.94% for the Reunion Island, Dordogne and Koumbia study site, respectively with an increasing of at least 2.5 points w.r.t. the best competing approach.},
  archive      = {J_EAAI},
  author       = {Azza Abidi and Dino Ienco and Ali Ben Abbes and Imed Riadh Farah},
  doi          = {10.1016/j.engappai.2023.106152},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106152},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combining 2D encoding and convolutional neural network to enhance land cover mapping from satellite image time series},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-attention causal dilated convolutional neural network
for multivariate time series classification and its application.
<em>EAAI</em>, <em>122</em>, 106151. (<a
href="https://doi.org/10.1016/j.engappai.2023.106151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time Series Classification (TSC) in data mining is gradually developing as an important research direction. Many researchers have developed an extensive interest in Multivariate Time Series Classification (MTSC). The Self-Attention Causal Dilated Convolutional Neural Network (SACDCNN) is proposed to address the limitations of existing models that perform poorly on classification tasks. It designs the residual and dense blocks based on Causal Dilated Convolution based on the traditional residual and dense networks that still have superior performance after deepening the network hierarchy and the dependence of time series on long-range information. A Self-Attention mechanism (SA) is also incorporated to extract the internal autocorrelation of time series features. Comparison experiments on 20 benchmark University of California, Riverside (UCR) and University of California, Irvine (UCI) datasets with eight high-performance classification models show that the method can improve the classification accuracy of time series datasets. Finally, it was applied to petroleum logging reservoir recognition, and a comparison experiment was conducted on two wells. The results show that SACDCNN is effective and significantly superior. It overcomes the shortcomings of traditional logging interpretation techniques and improves the efficiency and success rate of oil and gas exploration.},
  archive      = {J_EAAI},
  author       = {Wenbiao Yang and Kewen Xia and Zhaocheng Wang and Shurui Fan and Ling Li},
  doi          = {10.1016/j.engappai.2023.106151},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106151},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-attention causal dilated convolutional neural network for multivariate time series classification and its application},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer-based deep reverse attention network for
multi-sensory human activity recognition. <em>EAAI</em>, <em>122</em>,
106150. (<a
href="https://doi.org/10.1016/j.engappai.2023.106150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s era, one of the important applications of Artificial Intelligence (AI) is Human Activity Recognition (HAR). It has a wide range of applicability in health monitoring for patients with chronic diseases, gaming consoles for gesture recognition, etc. Sensor-based HAR systems use signals collected over a period of time to label an activity. When we design an efficient sensor-based HAR system, a model requires learning an optimal association of spatial and temporal features. In this article, we propose a sensor-based HAR technique using the deep learning approach. We present a deep reverse transformer-based attention mechanism to guide the side residual features Unlike the conventional bottom-up approaches for feature fusion, we exploit a top-down feature fusion approach. The reverse attention is self-calibrated throughout the course of learning, which regularizes the attention modules and dynamically adjusts the learning rate. The overall framework outperforms several state-of-the-art methods and is shown to be statistically significant against these methods on five publicly available sensor-based HAR datasets, namely, MHEALTH, USC-HAD, WHARF, UTD-MHAD1, and UTD-MHAD2. Further, we conduct an ablation study to showcase the importance of each of the components of the proposed framework. Source code of this work is available at https://github.com/rishavpramanik/RevTransformerAttentionHAR .},
  archive      = {J_EAAI},
  author       = {Rishav Pramanik and Ritodeep Sikdar and Ram Sarkar},
  doi          = {10.1016/j.engappai.2023.106150},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106150},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer-based deep reverse attention network for multi-sensory human activity recognition},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel approach for quality control of automated production
lines working under highly inconsistent conditions. <em>EAAI</em>,
<em>122</em>, 106149. (<a
href="https://doi.org/10.1016/j.engappai.2023.106149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When addressing product quality standards in manufacturing lines, a critical issue is the identification of the parameters that define the quality of the final product and their tracking. The problem of process control under inconsistent working condition of an automatic machinery, i.e. when some parameters are highly variable, is still quite unexplored in literature. This objective becomes even more challenging when the most important process variables are not directly measurable. This paper demonstrates that it is possible to achieve quality control by coupling a soft sensor, whose predictive model is a neural network, with an anomaly detector. The methodology has been applied to automatic machinery placed in a manufacturing line, where high variability in production rate has an important effect on the measured physical variables. This makes automated and accurate quality control difficult, due to the fact that in this test case the data collected are accelerometers signals, extremely sensible to variation in machine productivity by definition. It is shown that this approach outperforms many other classification methods (Support Vector Machines, Ensemble Bagged Tree, Discriminant Analysis, K-nearest neighbours and the direct application of a Neural Network) proposed in the past, achieving satisfactory results evaluated on the basis of four metrics (Accuracy, precision, recall and F 1 -score), even if anomalous data have been collected in a limited number of machine’s working points. In particular, an accuracy over 92% has been reached also for production rates where only nominal conditions are collected. This procedure exceeds the direct training of a neural network (accuracy of 57.6% at new production rates), as well as the application of shallow methods based on the extraction of dimensionless features (around 35% in accuracy at new production rates).},
  archive      = {J_EAAI},
  author       = {F.M. Bono and L. Radicioni and S. Cinquemani},
  doi          = {10.1016/j.engappai.2023.106149},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106149},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel approach for quality control of automated production lines working under highly inconsistent conditions},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust deep learning-based detection and classification
system for chipless arabic RFID letters. <em>EAAI</em>, <em>122</em>,
106147. (<a
href="https://doi.org/10.1016/j.engappai.2023.106147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work demonstrates a novel approach for reliable and robust identification and detection of realized chipless RFID Arabic alphabets using deep learning (DL) method. The undertaken classification problem of Arabic RFID tags of various fonts and sizes requires a classification technique that can learn long-term dependencies. Hence, a Bi-Long Short-Term Memory (BiLSTM) model is developed to classify 28 chipless Arabic RFID letters of different font types and sizes using their back scattered dual-polarized radar cross section (RCS) characteristics. The RCS frequency response of each Arabic letter tag reflects its signature electromagnetic characteristics that vary with the change in its shape (variations in font type and size). Firstly, an RCS dataset of 28 Arabic alphabet tags with three different font types (Arial, Calibri, and Times New Roman) and 13 different font sizes (16 mm–28 mm with a step size of 1 mm) are generated using Finite-Difference Time-Domain (FDTD) method in the frequency range of 1–12 GHz (1001 steps). The dimensions of the resulting dataset are [28 (letters) × 13 (font sizes) × 1001 (frequency steps) × 2 (polarizations)] × 3 (font types). Multi-class classification of the frequency-series data of all realized 28 alphabet tags of various font types and sizes makes the problem challenging and novel. The developed BiLSTM model can accurately classify the particular letter tag with specific font type and size based on the optimized network with employed Leave-One-Out Cross-Validation (LOOCV). The achieved accuracy with only Arial ([(28 × 13 × 1001 × 2)]), Calibri ([(28 × 13 × 1001 × 2)]), Times New Roman ([(28 × 13 × 1001 × 2)]), and combined data set ([(28 × 13 × 1001 × 2)] × 3) is 75%, 74%, 75%, and 89% respectively. The proposed Bi-LSTM model is shown superior when compared to other methods such as SVM, decision trees, and KNN, as it classifies the data with much higher accuracy for the considered multi-class data. The obtained accuracies of the compared models are 6.4% (SVM), 17.30% (tree) and 27.4% (KNN) respectively, while the developed Bi-LSTM model with optimized hyperparameters achieved an accuracy of 96%.},
  archive      = {J_EAAI},
  author       = {Jawad Yousaf and Abdelrahman M.A. Abed and Huma Zia and Eqab Almajali and Farooq A. Tahir and Hatem Rmili},
  doi          = {10.1016/j.engappai.2023.106147},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106147},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust deep learning-based detection and classification system for chipless arabic RFID letters},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved undamaged-to-damaged acceleration response
translation for structural health monitoring. <em>EAAI</em>,
<em>122</em>, 106146. (<a
href="https://doi.org/10.1016/j.engappai.2023.106146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpaired image-to-image translation is a popular research topic in computer vision and graphics. Recently, the authors of this paper took a similar approach and translated the domain of acceleration responses collected from a steel grandstand structure. In doing so, the undamaged response is translated to damaged, and the damaged response to undamaged. For that, a variant of the CycleGAN model is trained with undamaged (bolt tightened at the joint) and damaged (bolt loosened at the joint) responses from a single joint in the structure. However, the success of the domain translation on the test joints was very limited. Thus, this study investigates improvements to the model and the training procedure for further accuracy. First, the model in this study gets a more extensive training procedure to increase the model’s domain knowledge. During the training, a novel signal coherence-based index is considered to account for the similarity of frequency domains of the original and the translated data. Second, the Gated Linear Units, skip-connections, and Mish activation function are used to minimize the gradient loss and to learn the broader features in the data. Third, the total loss function of the generator is supplemented with a new frequency domain-based loss to better capture the frequency content of the data. Fourth, random decaying noise is added to the inputs for better generalization in the test data. Last, the model is evaluated using modal parameters such as natural frequencies, damping ratios, and singular value decomposition of the estimated spectral densities. The improvements presented in this study demonstrate a successful domain translation of acceleration responses for the tested joints compared to past study. The findings of this paper show that domain translation can be advantageous in Structural Health Monitoring applications, such as having access to the damaged or undamaged response of the structure while it is in pristine or unhealthy condition.},
  archive      = {J_EAAI},
  author       = {Furkan Luleci and Onur Avci and F. Necati Catbas},
  doi          = {10.1016/j.engappai.2023.106146},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106146},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved undamaged-to-damaged acceleration response translation for structural health monitoring},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating PCA and structural model decomposition to
improve fault monitoring and diagnosis with varying operation points.
<em>EAAI</em>, <em>122</em>, 106145. (<a
href="https://doi.org/10.1016/j.engappai.2023.106145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and efficient fault monitoring and diagnostics methods are essential for fault diagnosis and prognosis tasks in Health Monitoring Systems. These tasks are even more complicated when facing dynamic systems with multiple operation points. This article introduces a symbiotic solution for fault detection and isolation, based on the integration of two complementary techniques: Possible Conflicts (PCs), a model-based diagnosis technique from the Artificial Intelligence (AI) community, and Principal Component Analysis (PCA), a Multivariate Statistical Process Control (MSPC) technique. Our proposal improves the PCA-based fault detection in systems with multiple operation points and transient states and provides a straightforward fault isolation stage for PCA. At the same time, the proposal increases the robustness for fault detection using PCs through the application of PCA to the residual signals. PCA has the ability to filter out residual deviations caused by model uncertainties that can lead to a high number of false positives. The proposed method has been successfully tested in a real-world plant with accurate fault detection results. The plant has noisy sensors and a system model without the same accuracy at each operation point and transient states.},
  archive      = {J_EAAI},
  author       = {D. Garcia-Alvarez and A. Bregon and B. Pulido and C.J. Alonso-Gonzalez},
  doi          = {10.1016/j.engappai.2023.106145},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106145},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating PCA and structural model decomposition to improve fault monitoring and diagnosis with varying operation points},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monitoring industrial control systems via spatio-temporal
graph neural networks. <em>EAAI</em>, <em>122</em>, 106144. (<a
href="https://doi.org/10.1016/j.engappai.2023.106144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive amounts of industrial data, which are often gathered by industrial control systems (ICS), have been generated by the fast growth of industrial intelligence. One of the hottest topics in ICS is how to extract the most useful information from industrial ”Big Data” and provide a more comprehensive service for monitoring the condition of industrial production processes. As the industrial environment gets increasingly complicated, production tasks change often and malicious attacks are on the rise. It remains a grand challenge to perform fine-grained anomaly detection in high-dimensional, noisy industrial data. In response to this problem, we propose a spatio-temporal graph neural network-based anomaly detection framework for fine-grained state monitoring of ICSs. First, based on prior knowledge, we propose a method for feature dimensionality reduction and dynamic graph modeling. After that, the variational mode decomposition (VMD) module is then utilized to remove noise from industrial data. Finally, we propose a spatio-temporal feature extraction module for fine-grained anomaly detection. Numerical experiments are conducted on a real-world ICS dataset called HAI. The results demonstrate that the proposed framework can effectively deal with high-dimensional, high-noise, and imbalanced industrial data. The framework’s concepts are interconnected and extensible to various industrial scenarios, including metallurgy, smart shop floors, etc. In terms of recall, precision, and F 1 -Score, a comparison between the proposed framework and eight representative methods reveals the merits of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Yue Wang and Hao Peng and Gang Wang and Xianghong Tang and Xuejian Wang and Chunyang Liu},
  doi          = {10.1016/j.engappai.2023.106144},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106144},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Monitoring industrial control systems via spatio-temporal graph neural networks},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-powered health monitoring of anode baking furnace pits in
aluminum production using autonomous drones. <em>EAAI</em>,
<em>122</em>, 106143. (<a
href="https://doi.org/10.1016/j.engappai.2023.106143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial health monitoring in factories is essential for quality assurance, energy and cost reduction, and health and safety. In aluminum factories, anode furnace pits’ flue walls deform over time due to cyclic heating and cooling. They are inspected and classified using manually acquired measurements in a process that takes several hours and is done under high temperatures using specialized equipment. We propose an end-to-end AI-powered system for automated inspection using drones. We fly a drone carrying color and depth cameras to film and navigate a 50-pit furnace floor autonomously in a GPS-denied environment. We then mosaic the recorded videos to produce color and depth mosaics using frame-to-frame motion parameters estimated using the color videos and applied to both. We finish the mosaics using depth-to-color mosaic registration based on maximizing mutual information on gradients. We extract pit images from the mosaics using a YOLOv5 object detection initially trained using a physical floor model with a proposed data augmentation scheme and then fine-tuned for the on-site environment. We achieve a mean average precision of 94.7%. Once pit images are detected and initially classified, we propose a dual-stage segmentation algorithm using the Hough transform and a semantic segmentation network trained using probabilistic feature images with a precision of 96.67%. Segmented pits with depth information allow us to produce 3D models of pits to aid in temporal monitoring and diagnosis confirmation. Our system is cost-effective and reduces inspection downtime by 87%, eliminating the need for human intervention.},
  archive      = {J_EAAI},
  author       = {Tasnim Basmaji and Maha Yaghi and Marah Alhalabi and Abdallah Rashed and Huma Zia and Mohamed Mahmoud and Pragasan Palavar and Sara Alkhadhar and Halima Alhmoudi and Mohammad Alkhedher and Ayman Elbaz and Mohammed Ghazal},
  doi          = {10.1016/j.engappai.2023.106143},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106143},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AI-powered health monitoring of anode baking furnace pits in aluminum production using autonomous drones},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid deep learning pavement crack semantic segmentation.
<em>EAAI</em>, <em>122</em>, 106142. (<a
href="https://doi.org/10.1016/j.engappai.2023.106142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic pavement crack segmentation plays a critical role in the field of defect inspection. Although recent segmentation-based CNNs studies showed a promising pavement crack segmentation performance, a challenging task is still remaining due to the inhomogeneity of crack intensity, the complexity of pavement environments, a limited number of labeled training datasets, and the presence of noise in the majority of images in the crack dataset, which makes it difficult to distinguish the cracks from the noise. To overcome these challenges, this study aims to exploit the inherent relationship between classification and segmentation tasks to improve pavement crack segmentation. A hybrid deep learning pavement crack semantic segmentation is proposed based on knowledge transfer among the Class Activation Maps (KTCAM) and the encoder–decoder segmentation network (KTCAM-Net) via the capability of the revised CAM strategy. An adopted trained pavement crack classification network is used to produce high-quality crack localization maps. These localization abilities are fused with the encoder’s image features and fed into the decoder network to provide an accurate pavement crack segmentation. Furthermore, a hybrid loss function is developed to optimize the segmentation network, capture information about thin cracks, and tackle the problem of class imbalance. Afterward, a novel refinement process is applied to purify the segmented crack boundaries. A comprehensive experimental comparison is conducting using four benchmark datasets: DeepCrack, Crack500, CFD, and CrackSC. The proposed KTCAM-Net demonstrates the state-of-the-art segmentation results.},
  archive      = {J_EAAI},
  author       = {Zaid Al-Huda and Bo Peng and Riyadh Nazar Ali Algburi and Mugahed A. Al-antari and Rabea AL-Jarazi and Donghai Zhai},
  doi          = {10.1016/j.engappai.2023.106142},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106142},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid deep learning pavement crack semantic segmentation},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised structure subdomain adaptation based the
contrastive cluster center for bearing fault diagnosis. <em>EAAI</em>,
<em>122</em>, 106141. (<a
href="https://doi.org/10.1016/j.engappai.2023.106141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Unsupervised Domain Adaptation (UDA) as one of the transfer learning can handle the different data distributions and has been utilized in mechanical fault diagnosis under various working conditions successfully. However, most of them have only regarded two distributions as a global domain adaptation and ignored the subdomain adaptation issue, i.e., there is a subdomain distribution discrepancy between the two same categories. Additionally, most marking pseudo label approaches do not consider the influences of noise in pseudo labels. To circumvent the aforementioned challenges, firstly, a dropout trick has been developed and explored to filter the noisy pseudo label for obtaining the higher confident pseudo labels. Furthermore, a novel subdomain alignment method named Contrastive Cluster Center (CCC) has been proposed for pushing away the different domain cluster centers and bringing closer the same domain cluster centers for bridging the subdomain gap. Finally, the findings of the comparative experiments have demonstrated that the proposed method could boost the average accuracy of 2.2% and 3% on PU and LZUT bearing datasets than the state-of-art methods, respectively. Moreover, convergence analysis also suggests that the proposed method has superior robustness.},
  archive      = {J_EAAI},
  author       = {Pengfei Chen and Rongzhen Zhao and Tianjing He and Kongyuan Wei and Jianhui Yuan},
  doi          = {10.1016/j.engappai.2023.106141},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106141},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised structure subdomain adaptation based the contrastive cluster center for bearing fault diagnosis},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning approach for predicting lymph node metastasis
in non-small cell lung cancer by fusing image–gene data. <em>EAAI</em>,
<em>122</em>, 106140. (<a
href="https://doi.org/10.1016/j.engappai.2023.106140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The determination of lymph node metastasis is critical to the selection of treatment options for non-small cell lung cancer. Invasive pathological examinations cannot be performed frequently in clinical practice, thus non-invasive and reproducible methods are needed. The current research on non-invasive prediction methods based on image and genetic information has shortcomings such as small data sample size, high data dimension, and poor multimodal fusion effect. In this research, we propose a method for predicting lymph node metastasis in non-small cell lung cancer by fusing imaging data and genetic data to overcome these challenges. An attention-based multimodal information fusion module is designed to fuse image data and genetic data in the mid-fusion, and a bilinear fusion module based on Tucker decomposition is inserted into the model for late fusion, which significantly improves the performance of multimodal fusion. The 3D spiral transformation method is used to extract 2D images from 3D data, and the transformed images inherit and retain the spatial correlation of the original texture and edge information while increasing the image data sample size for subsequent prediction. The random forest method of important measurement is used for feature selection, and redundant data in gene information is eliminated. The experiments are carried out on the NSCLC-Radiogenomics dataset. The accuracy and AUC of the proposed model are 0.968 and 0.963, respectively. The experimental results show that the model is ideal performance in predicting lymph node metastasis, providing a new method for non-invasive lymph node metastasis prediction, which is beneficial to the application of precision medicine.},
  archive      = {J_EAAI},
  author       = {Guojie Hou and Liye Jia and Yanan Zhang and Wei Wu and Lin Zhao and Juanjuan Zhao and Long Wang and Yan Qiang},
  doi          = {10.1016/j.engappai.2023.106140},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106140},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning approach for predicting lymph node metastasis in non-small cell lung cancer by fusing image–gene data},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Multi-view rotating machinery fault diagnosis with adaptive
co-attention fusion network. <em>EAAI</em>, <em>122</em>, 106138. (<a
href="https://doi.org/10.1016/j.engappai.2023.106138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis is an intriguing topic, attracting increasing interest in safe and reliable industrial production. Tremendous progress has been made in recent years in developing better fault diagnosis methods. Nevertheless, most methods rely on an individual vibration signal while ignoring the consensus and complementary between different views of the signal. Towards this end, we propose a novel method named COFU, i.e., a multi-view learning model with CO-attention FUsion network for rotating machinery fault diagnosis, which primarily exploits consensus and complementary across multiple views. Specifically, we first utilize three different encoders to construct high-level feature spaces of multiple views. Then the adaptive co-attention fusion network is designed to learn an integrated representation where rich associations among these feature spaces are fully considered. Finally, the fault detector fed by the fused representation is devised to diagnose the fault category. To affirm the efficacy of the proposed approach, a comprehensive evaluation has been conducted on the CWRU, SEU_bearing, and SEU_gear datasets. The results indicate that the accuracy of the COFU method is 100%, 99.95%, and 100%, respectively. Encouraging findings demonstrate that our method outperforms all the baseline methods. Furthermore, it is observed that the COFU method demonstrates improved performance when applied in noisy environments. This study offers a promising solution that ensures the great potential of multi-view fusion in rotating machinery fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Xiaorong Liu and Jie Wang and Sa Meng and Xiwei Qiu and Guilin Zhao},
  doi          = {10.1016/j.engappai.2023.106138},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106138},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-view rotating machinery fault diagnosis with adaptive co-attention fusion network},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PCovNet+: A CNN-VAE anomaly detection framework with LSTM
embeddings for smartwatch-based COVID-19 detection. <em>EAAI</em>,
<em>122</em>, 106130. (<a
href="https://doi.org/10.1016/j.engappai.2023.106130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world is slowly recovering from the Coronavirus disease 2019 (COVID-19) pandemic; however, humanity has experienced one of its According to work by Mishra et al. (2020), the study’s first phase included a cohort of 5,262 subjects, with 3,325 Fitbit users constituting the majority. However, among this large cohort of 5,262 subjects, most significant trials in modern times only to learn about its lack of preparedness in the face of a highly contagious pathogen. To better prepare the world for any new mutation of the same pathogen or the newer ones, technological development in the healthcare system is a must. Hence, in this work, PCovNet+, a deep learning framework, was proposed for smartwatches and fitness trackers to monitor the user’s Resting Heart Rate (RHR) for the infection-induced anomaly. A convolutional neural network (CNN)-based variational autoencoder (VAE) architecture was used as the primary model along with a long short-term memory (LSTM) network to create latent space embeddings for the VAE. Moreover, the framework employed pre-training using normal data from healthy subjects to circumvent the data shortage problem in the personalized models. This framework was validated on a dataset of 68 COVID-19-infected subjects, resulting in anomalous RHR detection with precision, recall, F-beta, and F-1 score of 0.993, 0.534, 0.9849, and 0.6932, respectively, which is a significant improvement compared to the literature. Furthermore, the PCovNet+ framework successfully detected COVID-19 infection for 74% of the subjects (47% presymptomatic and 27% post-symptomatic detection). The results prove the usability of such a system as a secondary diagnostic tool enabling continuous health monitoring and contact tracing.},
  archive      = {J_EAAI},
  author       = {Farhan Fuad Abir and Muhammad E.H. Chowdhury and Malisha Islam Tapotee and Adam Mushtak and Amith Khandakar and Sakib Mahmud and Anwarul Hasan},
  doi          = {10.1016/j.engappai.2023.106130},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106130},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PCovNet+: A CNN-VAE anomaly detection framework with LSTM embeddings for smartwatch-based COVID-19 detection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sampling and noise filtering methods for recommender
systems: A literature review. <em>EAAI</em>, <em>122</em>, 106129. (<a
href="https://doi.org/10.1016/j.engappai.2023.106129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of online business, many e-commerce sites have evolved which recommend items according to one’s needs and interests. Plenty of data is available to be processed to make the recommender systems work effectively and efficiently. But, processing the entire dataset is a cumbersome process. So, there is a need to select a part of the data to be processed easily. Sampling is a way to select a subset of the entire dataset which contains all the attributes that the database can represent. It is important to understand which type of sampling method is suitable for a particular application in recommender systems. Thus, there is a need to study various sampling methods previously used in recommender systems. Also, before processing the data, we need to clean it up as it contains a certain amount of noise. This noise is described as either malicious noise or natural noise. Malicious noise is implicitly inserted in the system to alter the behavior of the system. This type of noise is termed as shilling attack. Natural noise enters the systems unknowingly due to the reluctance of users in giving proper ratings to the items. So, there is a need to filter these types of noise before making the data suitable for processing. In this paper, we have provided a review of 80 papers including both sampling and noise filtering methods. This is the first paper to the best of our knowledge, combining a literature review of both sampling and noise filtering methods.},
  archive      = {J_EAAI},
  author       = {Kirti Jain and Rajni Jindal},
  doi          = {10.1016/j.engappai.2023.106129},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106129},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sampling and noise filtering methods for recommender systems: A literature review},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resilient backstepping control for a class of switched
nonlinear time-delay systems under hybrid cyber-attacks. <em>EAAI</em>,
<em>122</em>, 106128. (<a
href="https://doi.org/10.1016/j.engappai.2023.106128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present investigation, the tracking control problem is being addressed for a switched time-delay nonlinear nonstrict-feedback cyber-physical systems (CPSs). Since modern infrastructure applications depend greatly on cyber technologies, these CPSs are exposed to two types of collusive network attacks, including unknown false data injection (FDI) and denial-of-service (DoS) attacks. When a DoS attack is active, state variables are unavailable. Furthermore, when an FDI attack is launched, the general state is manipulated by the attacker. Inspired by these complications, a Lyapunov–Krasovskii (LK) candidate is employed to handle time delays, a neural network (NN) switched observer is applied to approximate unavailable system states under attacks, and a Nussbaum gain approach is implemented to deal with the unknown sign of the attack function. By using the common Lyapunov function, it is proved that all closed-loop system signals and tracking errors are bounded by the proposed resilient control. Eventually, two practical and numerical examples to corroborate the capability of the proposed scheme, are presented.},
  archive      = {J_EAAI},
  author       = {Elham Akbari and Seyyed Mostafa Tabatabaei and Mojtaba Barkhordari Yazdi and Mohammad Mehdi Arefi and Jinde Cao},
  doi          = {10.1016/j.engappai.2023.106128},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106128},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resilient backstepping control for a class of switched nonlinear time-delay systems under hybrid cyber-attacks},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequency-domain physical constrained neural network for
nonlinear system dynamic prediction. <em>EAAI</em>, <em>122</em>,
106127. (<a
href="https://doi.org/10.1016/j.engappai.2023.106127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current use of physical constraints as prior knowledge of neural network models is a new frontier for artificial intelligence to solve complex nonlinear system predictions. Aiming at the problems of limited feature expression and low time-domain computational efficiency of existing physical-constrained neural networks, a physical informed neural network (PINN) modeling approach in frequency domain for nonlinear system dynamic prediction is proposed. First, the frequency-domain physics-constrained neural network (FPNN) framework is constructed, which mainly consists of CliqueNet and Fourier spectral method (FSM). Then, the CliqueNet with convolution feature cyclic structure for high dimensional sequential data is designed. There are forward and backward connections between any two layers of the network to improve the cross-level information flow of the deep network. Finally, FSM is utilized to inform the neural network of physical states by learning specific initial conditions without training data. Simulation results show that FPNN can effectively achieve Kuramoto–Sivashinsky complex system state prediction, with higher computational efficiency and faster learning efficiency compared with SOTA approaches.},
  archive      = {J_EAAI},
  author       = {Kui Qian and Lei Tian and Jiatong Bao},
  doi          = {10.1016/j.engappai.2023.106127},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106127},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Frequency-domain physical constrained neural network for nonlinear system dynamic prediction},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vision transformers in medical computer vision—a
contemplative retrospection. <em>EAAI</em>, <em>122</em>, 106126. (<a
href="https://doi.org/10.1016/j.engappai.2023.106126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformers (ViTs), with the magnificent potential to unravel the information contained within images, have evolved as one of the most contemporary and dominant architectures that are being used in the field of computer vision. These are immensely utilized by plenty of researchers to perform new as well as former experiments. Here, in this article, we investigate the intersection of vision transformers and medical images. We proffered an overview of various ViT based frameworks that are being used by different researchers to decipher the obstacles in medical computer vision. We surveyed the applications of Vision Transformers in different areas of medical computer vision such as image-based disease classification, anatomical structure segmentation, registration, region-based lesion detection, captioning, report generation, and reconstruction using multiple medical imaging modalities that greatly assist in medical diagnosis and hence treatment process. Along with this, we also demystify several imaging modalities used in medical computer vision. Moreover, to get more insight and deeper understanding, the self-attention mechanism of transformers is also explained briefly. Conclusively, the ViT based solutions for each image analytics task are critically analyzed, open challenges are discussed and the pointers to possible solutions for future direction are deliberated. We hope this review article will open future research directions for medical computer vision researchers.},
  archive      = {J_EAAI},
  author       = {Arshi Parvaiz and Muhammad Anwaar Khalid and Rukhsana Zafar and Huma Ameer and Muhammad Ali and Muhammad Moazam Fraz},
  doi          = {10.1016/j.engappai.2023.106126},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106126},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vision transformers in medical computer vision—A contemplative retrospection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of high-definition map creation methods for
autonomous driving. <em>EAAI</em>, <em>122</em>, 106125. (<a
href="https://doi.org/10.1016/j.engappai.2023.106125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving has been among the most popular and challenging topics in the past few years. Among all modules in autonomous driving, High-definition (HD) map has drawn lots of attention in recent years due to its high precision and informative level in localization. Since localization is a significant module for automated vehicles to navigate an unknown environment, it has immediately become one of the most critical components of autonomous driving. Big organizations like HERE, NVIDIA, and TomTom have created HD maps for different scenes and purposes for autonomous driving. However, such HD maps are not open-source and are only available for internal research or automotive companies. Even though researchers have proposed various methods to create HD maps using different types of sensor data, there are few papers that review and summarize those methods. New researchers do not have a clear insight into the current state of HD map creation methods to work on their HD map research. Due to the reason above, reviewing, classifying, comparing, and summarizing the state-of-the-art techniques for HD map creation is necessary. This paper reviews recent HD map creation methods that leverage both 2D and 3D map generation. This review introduces the concept of HD maps and their usefulness in autonomous driving and gives a detailed overview of HD map creation methods. We will also discuss the limitations of the current HD map creation methods to motivate future research. Additionally, a chronological overview is created with the most recent HD map creation methods in this paper.},
  archive      = {J_EAAI},
  author       = {Zhibin Bao and Sabir Hossain and Haoxiang Lang and Xianke Lin},
  doi          = {10.1016/j.engappai.2023.106125},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106125},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of high-definition map creation methods for autonomous driving},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep gaussian mixture adaptive network for robust soft
sensor modeling with a closed-loop calibration mechanism. <em>EAAI</em>,
<em>122</em>, 106124. (<a
href="https://doi.org/10.1016/j.engappai.2023.106124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process drift leads to an out-of-distribution problem between historical training data and online deployment data, which deteriorates the performance of soft sensors. Unfortunately, few existing deep learning soft sensors have calibration mechanisms to deal with the process drift. To this end, this article proposes a robust Deep Gaussian Mixture Adaptive Network (DGMAN)-based soft sensor with a closed-loop calibration mechanism. First, a Gaussian Mixture Conditional Variational Autoencoder (GMCVAE) is presented, with the ability to capture the multimodality in industrial data. Afterwards, we propose a novel semi-supervised Gaussian mixture domain adaptation to perform conditional and marginal probability distribution alignment in the Gaussian mixture probabilistic latent space created by GMCVAE, using both labeled and unlabeled target samples. Theoretically, two kinds of process drift, including concept drift and virtual drift, could be alleviated by conditional distribution adaptation and marginal distribution adaptation, respectively. In addition, a new closed-loop calibration mechanism is deployed in a pre-training and fine-tuning fashion. Finally, robust analysis in theory and experimental results on the gas turbine dataset demonstrate that the proposed DGMAN-based soft sensor with robustness against process drift can maintain long-term validity in real industrial processes. Calibrated by only 100 labeled samples per year, the RMSE of DGMAN is 5.55 ± 0.32 after three years of deployment in the power plant, outperforming all comparison methods.},
  archive      = {J_EAAI},
  author       = {Xiangrui Zhang and Chunyue Song and Jun Zhao and Zuhua Xu},
  doi          = {10.1016/j.engappai.2023.106124},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106124},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep gaussian mixture adaptive network for robust soft sensor modeling with a closed-loop calibration mechanism},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking vision transformer through human–object
interaction detection. <em>EAAI</em>, <em>122</em>, 106123. (<a
href="https://doi.org/10.1016/j.engappai.2023.106123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works have shown that Vision Transformer models (ViT) can achieve comparable or even superior performance on image- and region-level recognition tasks, i.e., image recognition and object detection. However, can Vision Transformer perform region-level relationship reasoning with minimal information about the spatial geometry formation of input images? To answer this question, we propose the Region-level Relationship Reasoning Vision Transformer (R3ViT), a family of human–object interaction detection models based on the vanilla Vision Transformer with the fewest possible revisions, common region priors, as well as inductive biases of the objective task. Specifically, we first divide the input images into several local patches, replace the specialized [CLS ] token in vanilla ViT with extra relationship semantics carrier tokens in the entanglement-/pair-/triplet-wise manner and calculate both representations and their relevance. We assign each extra token with an individual supervision and compute the training loss in a dense manner. We find the vision transformer simply adjusted by the novel paradigm can already reason about the region-level visual relationship, e.g., R3ViT can achieve quite excellent performance on the challenging human–object interaction detection benchmark. We also discuss the impacts of adjustment schemes and model scaling strategies for Vision Transformer through R3ViT. Numerically, extensive experiments on several benchmarks demonstrate that our proposed framework outperforms most existing methods and achieves the impressive performance of 28.91 mAP on HICO-DET and 56.8 mAP on V-COCO dataset, respectively.},
  archive      = {J_EAAI},
  author       = {Yamin Cheng and Zitian Zhao and Zhi Wang and Hancong Duan},
  doi          = {10.1016/j.engappai.2023.106123},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106123},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rethinking vision transformer through human–object interaction detection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). RETRACTED: A comparative study on end-to-end deep learning
methods for electroencephalogram channel selection. <em>EAAI</em>,
<em>122</em>, 106122. (<a
href="https://doi.org/10.1016/j.engappai.2023.106122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article has been retracted: please see Elsevier Policy on Article Withdrawal ( https://www.elsevier.com/about/policies/article-withdrawal ). This article has been retracted at the request of the Editor-in-Chief. Similarities have been detected with a paper that had already appeared in the Journal of Neural Engineering, Volume 18, Number 4, DOI https://doi.org/10.1088/1741-2552/ac115d . One of the conditions of submission of a paper for publication is that authors declare explicitly that their work is original and has not appeared in a publication elsewhere. Re-use of any data should be appropriately cited. This article did not sufficiently meet these criteria. The scientific community takes a very strong view on this matter and apologies are offered to readers of the journal that this was not detected during the submission process.},
  archive      = {J_EAAI},
  author       = {Abdullah and Ibrahima Faye and Md Rafiqul Islam},
  doi          = {10.1016/j.engappai.2023.106122},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106122},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RETRACTED: A comparative study on end-to-end deep learning methods for electroencephalogram channel selection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of the natural survivor method (NSM) for
designing an updating mechanism in metaheuristic search algorithms.
<em>EAAI</em>, <em>122</em>, 106121. (<a
href="https://doi.org/10.1016/j.engappai.2023.106121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristic search algorithms (MHSs) are methods that take their inspiration from nature. However, the fitness value information used in the design of the update mechanism in MHSs is insufficient to represent the concept of adaptation to the environment and the ability to survive in nature. This causes problems in the selection of survivors and the premature convergence in the search process. This article introduces the Natural Survivor Method (NSM), developed as a design for population management as it occurs in nature, depending on analytical relationships and environmental factors. In the NSM, scores representing the adaptability of individuals to nature are calculated in order to determine the survivors. In this proposed method, the update mechanism is designed using NSM scores instead of fitness values. The NSM is the first study presented to the literature on this subject since the 1980s, when the meta-heuristics was introduced. The NSM was used for survivor selection by applying it to three different types of MHS algorithms based on physics (SFS), biology (TLABC), and evolution (LSHADE-SPACMA). Thirty-nine global optimization problems in the IEEE CEC 2017/2020 benchmark suites and ten constrained real-world engineering problems were used in the experimental studies. Data obtained from experimental studies were analyzed by using non-parametric statistical test methods. Among the 25 competing algorithms according to Friedman scores, the rankings of the three algorithms with NSM and their original versions are as follows: While TLABC is 18th, NSM-TLABC is 9th, SFS is 10th, NSM-SFS is 6th, LSHADE-SPACMA is 3rd, NSM-LSHADE-SPACMA is 1st. According to the results of the Wilcoxon pairwise comparison test between the original and NSM versions of the algorithms, the NSM versions have a clear advantage in finding optimal solutions. However, the drawback of the proposed method is that it increases the computational complexity of the algorithms. The source codes of the NSM (NSM-LSHADE_SPACMA, NSM-TLABC and NSM-SFS) can be accessed at this link: https://www.mathworks.com/matlabcentral/fileexchange/126050-natural-survivor-method-nsm-for-metaheuristic-algorithms .},
  archive      = {J_EAAI},
  author       = {Hamdi Tolga Kahraman and Mehmet Katı and Sefa Aras and Durdane Ayşe Taşci},
  doi          = {10.1016/j.engappai.2023.106121},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106121},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of the natural survivor method (NSM) for designing an updating mechanism in metaheuristic search algorithms},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RANCOM: A novel approach to identifying criteria relevance
based on inaccuracy expert judgments. <em>EAAI</em>, <em>122</em>,
106114. (<a
href="https://doi.org/10.1016/j.engappai.2023.106114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of the criteria relevance from the expert in the multi-criteria problem could be a challenging task. It is important to provide simple and intuitive techniques that reflect the expert knowledge effectively. When the problem includes many criteria, it is possible to occur some probability of error in determining the criteria relevance. However, most subjective weighting methods perform correctly when the experts do not hesitate, are repeatable, and are very precise. Consequently, there is interest in improving the currently used approaches to handle expert hesitation more effectively. To fill this gap, we propose the RANking COMparison (RANCOM) method, which can be used to determine criteria weights based on expert knowledge. Its performance is based on defining the criteria ranking order to obtain the weights vector. The illustrative example and a comparative analysis of the selected subjective weighting methods show that the proposed approach provides reliable results, highly correlated with the existing approaches. However, it offers a simple manner of use, adjusted for less and more experienced users. The comparison of the RANCOM and AHP methods shows that when a slight probability of error in expert judgments occurs, the RANCOM method proves to be a more suitable solution to handle the expert inaccuracies for the problems with 5 or more criteria. Performed experiments showed that the RANCOM method is a repeatable and more consistent method regarding possible judgment errors. The obtained results showed that the RANCOM method guarantees more repeatable results than the AHP method, especially for a greater number of criteria.},
  archive      = {J_EAAI},
  author       = {Jakub Więckowski and Bartłomiej Kizielewicz and Andrii Shekhovtsov and Wojciech Sałabun},
  doi          = {10.1016/j.engappai.2023.106114},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106114},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RANCOM: A novel approach to identifying criteria relevance based on inaccuracy expert judgments},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing an IoT-enabled supply chain network considering
the perspective of the fifth industrial revolution: Application in the
medical devices industry. <em>EAAI</em>, <em>122</em>, 106113. (<a
href="https://doi.org/10.1016/j.engappai.2023.106113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of technology, environmental concerns, and disruptions caused by the COVID-19 pandemic have led researchers to pay more attention to an emerging concept called the fifth industrial revolution (I5.0). Despite the high importance of the I5.0, the literature shows that no study investigated the supply chain network design problem based on the I5.0 pillars. Hence, this research develops a multi-stage decision-making framework to configure a closed-loop supply chain based on I5.0 dimensions to cover this gap. In the first stage, the score of technologies that utilized in the supply chain is calculated using the analytic hierarchy process method. Afterwards, in the second stage, a mathematical model is proposed to configure the supply chain. Then, Furthermore, an efficient solution method, named the fuzzy lexicographic multi-choice Chebyshev goal programming method, is developed to obtain the optimal solution. In general, the main contributions of the current study can be divided into two major parts as follows: (i) the current study is the first research that incorporates the dimensions of the I5.0 into the supply chain network design problem, and (ii) this work develops a novel and efficient solution method. In this regard, the major problems and challenges that existed include the limitation of available resources in relation to Industry 5, especially in the field of the supply chain, as well as quantifying the elements of Industry 5.0 in the form of a mathematical programming model.},
  archive      = {J_EAAI},
  author       = {Sina Nayeri and Zeinab Sazvar and Jafar Heydari},
  doi          = {10.1016/j.engappai.2023.106113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Designing an IoT-enabled supply chain network considering the perspective of the fifth industrial revolution: Application in the medical devices industry},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intuitionistic fuzzy representation based software bug
severity prediction approach for imbalanced severity classes.
<em>EAAI</em>, <em>122</em>, 106110. (<a
href="https://doi.org/10.1016/j.engappai.2023.106110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve software reliability and quality, the triager must assess the severity of the software bug and allocate suitable resources on time. However, the triager faces many difficulties in understanding various software bugs that involve lots of uncertainty and irregularities. Additionally, it can be challenging for the triager to determine the severity of bugs that are semantically close to multiple severity labels. To address these problems, a topic modeling and intuitionistic fuzzy similarity measure-based software bug severity prediction technique (IFSBSP) is proposed in this paper. Initially, the Synthetic Minority Oversampling Technique (SMOTE) is applied to balance the severity classes in software bug repositories. Then topic modeling is used to generate topics based on the probability of underlying uncertainty in software bugs. Using these topics, the intuitionistic fuzzy membership, non-membership, and hesitancy membership degrees of a software bug are calculated for multiple severity labels. Then, 15 IFS techniques are investigated for a new bug in order to compute its similarity to multiple severity labels. The Eclipse, Mozilla, Apache, and NetBeans software bug repositories are used to evaluate the performance of IFSBSP and the state-of-the-art models. On these software bug repositories, the IFSBSP model outperforms state-of-the-art models by achieving accuracy of 91.6%, 90.9%, 88.1%, and 92.9% and an F-measure of 90.7%, 91.1%, 89.3%, and 91.7%, respectively.},
  archive      = {J_EAAI},
  author       = {Rama Ranjan Panda and Naresh Kumar Nagwani},
  doi          = {10.1016/j.engappai.2023.106110},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106110},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intuitionistic fuzzy representation based software bug severity prediction approach for imbalanced severity classes},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain adaptation via transferable swin transformer for tire
defect detection. <em>EAAI</em>, <em>122</em>, 106109. (<a
href="https://doi.org/10.1016/j.engappai.2023.106109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data-driven tire defect detection, scarce defect samples and the poor transferability of models make the defect detection a time-consuming and expensive process. In recent years, domain adaptation methods have been applied to solve the cross-domain defect detection problems. However, previous works mainly assume that all regions in the image are equally transferable and align global features of the source and target domains with the same weight, which will fail for such a complex scenario. To this end, with the consideration of variability of transferability in different image regions, this paper presents Transferable Swin Transformer (TST), focusing the proposed method on region-based adversarial alignment and the semantic-based subdomain adaptation, simultaneously. Meanwhile, the subdomain adaptation benefits from the designed region-level weighting mechanism. The above strategies enable TST to learn both transferable and discriminative features in defect detection under domain shifts. Six transfer tasks constructed by different tire quality inspection X-ray image machines and a benchmark dataset are processed to demonstrate the effectiveness and generalization of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yulong Zhang and Yilin Wang and Zhiqiang Jiang and Li Zheng and Jinshui Chen and Jiangang Lu},
  doi          = {10.1016/j.engappai.2023.106109},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106109},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Domain adaptation via transferable swin transformer for tire defect detection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human–machine interaction controller of upper limb based on
iterative learning method with zeroing neural algorithm and disturbance
observer. <em>EAAI</em>, <em>122</em>, 106108. (<a
href="https://doi.org/10.1016/j.engappai.2023.106108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an iterative learning controller with zeroing neural algorithm and disturbance observer is proposed to solve the conflicting of human–machine interaction and disturbances in system. This paper presents a theoretical framework, which is able to process rigorous stability analysis of human–machine interaction control. The iterative learning controller is suitable for repetitive upper limb rehabilitation training. Combining tracking error dependent weight vector with zeroing neural algorithm is aimed to reduce the conflicts in various operations of motions between upper limb and machine. The disturbance observer is used to deal with eliminating the disturbance. In addition, simulations of the controller can effectively and safety assist upper limb movement in different training stages.},
  archive      = {J_EAAI},
  author       = {Yuanyuan Chai and Keping Liu and Xiaoqin Duan and Jiang Yi and Ruiling Sun and Jiacong Li},
  doi          = {10.1016/j.engappai.2023.106108},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106108},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human–machine interaction controller of upper limb based on iterative learning method with zeroing neural algorithm and disturbance observer},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using gaussian process regression (GPR) models with the
matérn covariance function to predict the dynamic viscosity and torque
of SiO2/ethylene glycol nanofluid: A machine learning approach.
<em>EAAI</em>, <em>122</em>, 106107. (<a
href="https://doi.org/10.1016/j.engappai.2023.106107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying the dynamic viscosity (DV) is a key factor to determine the nanofluids’ hydrodynamic behavior (NFs). In this research, the effect of volume fraction ( φ ), shear rate (SR), and temperature (T) on the DV, and torque of SiO 2 nanoparticles (NPs)/ Ethylene glycol (EG) nanofluid (NF) are studied with an artificial neural network (ANN). Different machine learning (ML) models are examined to predict the rheological properties, and then the best model is selected for prediction. The results show that the torque mostly increased linearly with the SR in all samples. The slope of this enhancing trend is higher for lower T. The Gaussian Process Regression (GPR) models with the Matérn covariance function provided the best results on both datasets to predict the DV. The correlation results provided by this method to predict the DV in terms of Pearson’s Linear Correlation Coefficient (PLCC), and Spearman’s Rank Order Correlation Coefficient (SROCC) were 0.999 and 1, respectively. R squared (R 2 ) was 0.996 and, the Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE) values of about 0.24 and 1.61 represented the accuracy and power of this method to predict the DV values unseen data by the model. The GPR torque predictor model performed very well by providing a correlation of about 0.98 and an RMSE of about 4. Matérn covariance functions that used separate length scales per predictor with ν = 3 / 2 (ardmatern 32) and ν = 5 / 2 (ardmatern52) were superior to other functions. All 100 models trained on each dataset were well-trained and quite reliable. The trained models were accurate enough to be used in related applications.},
  archive      = {J_EAAI},
  author       = {Xiaohong Dai and Hamid Taheri Andani and As’ad Alizadeh and Azher M. Abed and Ghassan Fadhil Smaisim and Salema K. Hadrawi and Maryam Karimi and Mahmoud Shamsborhan and D. Toghraie},
  doi          = {10.1016/j.engappai.2023.106107},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106107},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Using gaussian process regression (GPR) models with the matérn covariance function to predict the dynamic viscosity and torque of SiO2/Ethylene glycol nanofluid: A machine learning approach},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent forecasting model of stock price using
neighborhood rough set and multivariate empirical mode decomposition.
<em>EAAI</em>, <em>122</em>, 106106. (<a
href="https://doi.org/10.1016/j.engappai.2023.106106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent forecasting model of stock price is an effective way to obtain ideal investment returns. Due to the impact of quantitative transactions, traditional forecasting methods face challenges and pressures. How to find a reliable forecasting model and improve the forecasting accuracy will be a scientific problem worthy of further discussion. This paper proposes an intelligent forecasting model of stock price based on neighborhood rough set (NRS) and multivariate empirical mode decomposition (MEMD) by means of the ideal of “granular computing” and “decomposition ensemble”. Firstly, the multiscale permutation entropy (MPE) method is conducted to determine decision features, which can improve the stability of permutation entropy. Then, a new feature selection method, fusing mutual information (MI) and the NRS, is proposed to automatically capture and select the condition features from the stock market. Subsequently, aiming on revealing the more detailed feature information and maintaining relevance between features, the MEMD is utilized to simultaneously decompose all features. Finally, the decomposed features are inputted into the long short-term memory (LSTM) network to train the intelligent forecasting model and provide the forecasting results of stock price. The validity of our proposed model is assessed through the stocks of Shanghai and Shenzhen markets. The results show that our proposed intelligent forecasting model of stock price makes a beneficial attempt and discussion for the integration of “granular computing” and “decomposition ensemble”. And it will provide scientific support and reference for investors’ actual investment decisions.},
  archive      = {J_EAAI},
  author       = {Juncheng Bai and Jianfeng Guo and Bingzhen Sun and Yuqi Guo and Qiang Bao and Xia Xiao},
  doi          = {10.1016/j.engappai.2023.106106},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106106},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent forecasting model of stock price using neighborhood rough set and multivariate empirical mode decomposition},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Q-rung orthopair fuzzy aczel–alsina aggregation operators
with multi-criteria decision-making. <em>EAAI</em>, <em>122</em>,
106105. (<a
href="https://doi.org/10.1016/j.engappai.2023.106105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {q-rung orthopair fuzzy sets (q-ROFSs) are advantageous for accurately expressing the preferences of decision-makers (DMs) due to their membership and non-membership degrees. This paper presents new q-rung orthopair fuzzy aggregation operators (AOs) that are based on Aczel–Alsina (AA) operations. These operators offer several advantages when dealing with real-world problems. The paper introduces new q-ROFS operations, such as the Aczel–Alsina product, sum, exponent, and scalar multiplication. We developed many AOs namely, the “q-rung orthopair fuzzy Aczel–Alsina weighted averaging (q-ROFAAWA) operator”, “q-rung orthopair fuzzy Aczel–Alsina ordered weighted averaging (q-ROFAAOWA) operator”, “q-rung orthopair fuzzy Aczel–Alsina hybrid averaging (q-ROFAAHA) operator”, “q-rung orthopair fuzzy Aczel–Alsina weighted geometric (q-ROFAAWG) operator,” the “q-rung orthopair fuzzy Aczel–Alsina ordered weighted geometric (q-ROFAAOWG) operator”, and the “q-rung orthopair fuzzy Aczel–Alsina hybrid geometric (q-ROFAAHG) operator”. Various attributes of these operators have been defined, including monotonicity, boundary, idempotency and commutativity. The paper demonstrates these properties for the suggested AOs. An algorithm for multi-criteria decision-making has been developed using the proposed aggregation operators with multiple evaluations by DMs and partial weight information under q-ROFSs. To demonstrate the effectiveness of the proposed approach, the paper uses a scenario for selecting the best green supplier. Additionally, the paper provides sensitivity analysis and compares the proposed technique with existing approaches.},
  archive      = {J_EAAI},
  author       = {Hafiz Muhammad Athar Farid and Muhammad Riaz},
  doi          = {10.1016/j.engappai.2023.106105},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106105},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Q-rung orthopair fuzzy Aczel–Alsina aggregation operators with multi-criteria decision-making},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Z-numbers based novel method for assessing groundwater
specific vulnerability. <em>EAAI</em>, <em>122</em>, 106104. (<a
href="https://doi.org/10.1016/j.engappai.2023.106104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Groundwater vulnerability assessment systems are developed to achieve a suitable method for protecting groundwater resources from contaminants. One of the well-known approaches for determining groundwater susceptibility is the DRASTIC method. This method considers seven effective parameters to evaluate groundwater vulnerability. Since groundwater contamination is often associated with uncertainty, this study applied the concept of the Z-number as a new generation of Fuzzy Logic (FL) to estimate the specific vulnerability of the aquifers. Unlike conventional FL models, which do not incorporate reliability, the Z-numbers include information constraint and reliability and can effectively explain uncertainty in human knowledge. To highlight this approach, the DRASTIC parameters (inputs) and nitrate concentration values (output) were used through two scenarios to estimate the specific vulnerability of the Ardabil and the Qorveh-Dehgolan plains (QDP) and the obtained results were compared with DRASTIC model as a benchmark model. The analysis of the results showed that the Z-number Based Modeling (ZBM), in addition to superiority to DRASTIC model, improved the quality of results compared to the classic FL by 53% (using seven inputs), 184% (using four inputs) in the Ardabil plain, and 127% (using seven inputs), 311% (using four inputs) in the QDP due to the consideration of data reliability and appropriate weighting of the rules. Also, the quality of the extracted Z-number-based rules in plains with high CV may be lower (such as the high CV of the Ardabil compared to the QDP). Therefore, the results of ZBM may not show a significant improvement over the conventional FL.},
  archive      = {J_EAAI},
  author       = {Sana Maleki and Vahid Nourani and Hessam Najafi and Aida Hosseini Baghanam and Chang-Qing Ke},
  doi          = {10.1016/j.engappai.2023.106104},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106104},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Z-numbers based novel method for assessing groundwater specific vulnerability},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning based techniques for neuro-degenerative
disorders detection. <em>EAAI</em>, <em>122</em>, 106103. (<a
href="https://doi.org/10.1016/j.engappai.2023.106103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental disorders are neural issues that influence brain cognition and social connectivity. The significant increase in mental disorders needs prompt detection for effective treatment. Psychiatric disorders can be partially diagnosed with constant counseling by using anti-depressants and other inhibitors. However, this is a laborious and also time-consuming process. This leads to investigating the computational techniques that can be applied to detect psychiatric illness in its premature phases. Various works are proposed to detect mental disorders from four data forms: neuro-images, EEG signals, textual data, and gene data. The researchers aim to investigate various models that can detect mental illness using advanced deep learning techniques. Through exploring authoritative databases, the authors gathered papers and studied classic machine learning and primary deep learning techniques for anticipating mental health issues. As the results of various models, the study also presented the difficulties and constraints that machine learning researchers have encountered while studying psychological disorders. The collected articles are categorized into four forms based on the data type used for the analysis. This paper proposes four different hybrid models to detect mental disorders in the early stages from four different data forms. Standardized metrics like area under the receiver operating characteristic curve (AUC–ROC) score and average classification accuracy (ACA) are used to evaluate the models. The proposed models outperformed all the state-of-the-art models in disorder prediction. Furthermore, the study discusses specific suggestions for future studies and development in the use of learning algorithms in the field of mental health.},
  archive      = {J_EAAI},
  author       = {L.V.S.K.B. Kasyap Varanasi and Chandra Mohan Dasari},
  doi          = {10.1016/j.engappai.2023.106103},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106103},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning based techniques for neuro-degenerative disorders detection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neural network based efficient leader–follower formation
control approach for multiple autonomous underwater vehicles.
<em>EAAI</em>, <em>122</em>, 106102. (<a
href="https://doi.org/10.1016/j.engappai.2023.106102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript proposes an efficient and novel method for the leader–follower formation control of multiple autonomous underwater vehicles. The goal is to efficiently allow the follower to follow the desired formation that the leader has presented. It is noteworthy how the model-dependent and model-free control schemes are combined to achieve this goal. The dynamical model of the system always contains inherent uncertainties, so the model-based control technique is incapable to manage these systems. Due to uncertainties and external disturbances, it is impossible to have complete knowledge of the system’s dynamic model in real-world applications. Therefore, whatever the partial information about the dynamic model is available has been used in the design of the controller. The approximation ability of the neural network is used to enhance the inefficiency of the model-based control strategy. The unknown dynamics of the system is estimated via a radial basis function neural network. An adaptive compensator is introduced to the controller’s part to counteract the effects of neural network reconstruction errors as well as those of external disturbances. After that, a Lyapunov function makes use of the online adaptive laws for the parameter vector as well as for the weights of neural network which ensures that the system is stable. As a result, by Barbalat’s lemma, formation errors not only stay inside the desired levels but also converge to a small neighbourhood of zero asymptotically. At long last, contrastive MATLAB simulations are conducted to affirm the capability and superiority of the suggested technique.},
  archive      = {J_EAAI},
  author       = {Manju Rani and Naveen Kumar},
  doi          = {10.1016/j.engappai.2023.106102},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106102},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A neural network based efficient leader–follower formation control approach for multiple autonomous underwater vehicles},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning vehicle trajectory uncertainty. <em>EAAI</em>,
<em>122</em>, 106101. (<a
href="https://doi.org/10.1016/j.engappai.2023.106101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel approach for vehicle tracking using a hybrid adaptive Kalman filter is proposed. The filter utilizes recurrent neural networks to learn the vehicle’s geometrical and kinematic features, which are then used in a supervised learning model to determine the actual process noise covariance in the Kalman framework. This approach addresses the limitations of traditional linear Kalman filters, which can suffer from degraded performance due to uncertainty in the vehicle kinematic trajectory modeling. Our method is evaluated and compared to other adaptive filters using the Oxford RobotCar dataset, and has shown to be effective in accurately determining the process noise covariance in real-time scenarios. Overall, this approach can be implemented in other estimation problems to improve performance.},
  archive      = {J_EAAI},
  author       = {Barak Or and Itzik Klein},
  doi          = {10.1016/j.engappai.2023.106101},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106101},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning vehicle trajectory uncertainty},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent fault diagnosis scheme for rotating machinery
based on momentum contrastive bi-tuning framework. <em>EAAI</em>,
<em>122</em>, 106100. (<a
href="https://doi.org/10.1016/j.engappai.2023.106100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing fine-tuning methods mainly leverage the discriminative knowledge and discard the intrinsic structure of data. In this paper, we propose a novel framework Momentum Contrastive Bi-Tuning (MCBiT) for intelligent diagnosis of rotating machinery, which can fully exploit both the discriminative knowledge of labels and the intrinsic structure of target data in a boosting fine-tuning way. One-dimensional vibration signals are transformed by Gramian Angular Difference Field (GADF) and fed into MCBiT, which enhances the conventional fine-tuning by integrating two branches on the ImageNet-pretrained backbone: a classifier with an instance-contrastive cross-entropy loss to better exploit label knowledge; and a projector with a categorical contrastive learning loss to mining the intrinsic structure of data. Our proposed approach outperforms state-of-the-art methods on six publicly available rotating machinery fault diagnosis datasets and our experimental-collected dataset at different data scales. The promising performance of our proposed MCBiT contributes toward more practical data-driven approaches that can realize timely deployment under challenging real-world environments.},
  archive      = {J_EAAI},
  author       = {Jiankang Zhong and Hanling Mao and Weili Tang and Aisong Qin and Kuangchi Sun},
  doi          = {10.1016/j.engappai.2023.106100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent fault diagnosis scheme for rotating machinery based on momentum contrastive bi-tuning framework},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trajectory planning for a 6-axis robotic arm with particle
swarm optimization algorithm. <em>EAAI</em>, <em>122</em>, 106099. (<a
href="https://doi.org/10.1016/j.engappai.2023.106099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arms, which are favored for usage in both large- and small-scale industrial regions, run into issues with numerous limits between the starting and ending locations in the working space when attempting to complete a particular task. With the solution to one of these problems, trajectory planning, the robotic arm manipulator can move from the starting point to the target point vibration-free, without hitting obstacles, and by choosing the shortest way. In this study, a robotic arm with 6 degrees of freedom, which is in the Mechatronics Engineering laboratory of Isparta University of Applied Sciences and whose prototype was realized by Acrome company, was used. In the study, the trajectory planning of the robotic arm was carried out using the MATLAB program and particle swarm optimization (PSO). Trajectory planning is developed using the PSO algorithm to determine the position of the robot at each point as it moves from its starting point to its target. Thus, time optimization was achieved by choosing the shortest path between the two points. Trajectory planning in joint space is aimed to ensure that the position, speed, and acceleration between the starting and ending points are continuous by using the fifth-order polynomial. The instant values of the joint variables used to determine the points followed by the manipulator were obtained by forward kinematics through the MATLAB program. Using forward kinematics, the position information of the manipulator was obtained by providing a transition from joint space to Cartesian space.},
  archive      = {J_EAAI},
  author       = {Özge Ekrem and Bekir Aksoy},
  doi          = {10.1016/j.engappai.2023.106099},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106099},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trajectory planning for a 6-axis robotic arm with particle swarm optimization algorithm},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards realizing a visual UAV flying environment: A novel
approach based aerial imagery to construct a dataset for visual
servoing. <em>EAAI</em>, <em>122</em>, 106098. (<a
href="https://doi.org/10.1016/j.engappai.2023.106098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realizing a visual flying environment in various scenarios is an instrumental key to establishing visual hardware-in-the-loop (HIL) simulation for flying UAVs. To simulate a desired UAV flying mission for a specific building landing in arbitrary geodetic coordinates, a new approach is presented. The approach fulfills the UAV landing HIL via three key elements: Building, Training, and Servoing. Building a flying dynamic scene which is not limited to a certain scenario, but can be utilized for generating different aerial remote sensing scenes according to desired geodetic coordinates (location-free), flying mission, perspective angles, and approaching velocities. The dynamic scene is constructed via RHINO graphics software based on georeferenced images taken at different altitudes. Training a deep detection framework on the extracted dataset from each constructed scene to localize a specific building as a landing platform. Servoing a pan–tilt camera on an embedded system by a pure image-based visual servoing (IBVS) method to coincide the detected building center with the acquired frame center during the flight. Tiny-YOLOv4 is picked as a light detector that runs on Nvidia nano with a servo kit and achieves a satisfactory result even with two wind disturbances models in a real-time condition. Thus, verifying a successful UAV landing on a specific building approach is accomplished.},
  archive      = {J_EAAI},
  author       = {A.M. Awed and Ali Maher and Mohammed A.H. Abozied and Yehia Z. Elhalwagy},
  doi          = {10.1016/j.engappai.2023.106098},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106098},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards realizing a visual UAV flying environment: A novel approach based aerial imagery to construct a dataset for visual servoing},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Voice feature description of parkinson’s disease based on
co-occurrence direction attribute topology. <em>EAAI</em>, <em>122</em>,
106097. (<a
href="https://doi.org/10.1016/j.engappai.2023.106097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incipient diagnosis of Parkinson’s disease (PD) helps to control the disease as early as possible and dysphonia is one of the early symptoms of PD. Therefore, the construction of effective voice features is of great significance. To distinguish PD patients from healthy controls, combined with the idea of formal structure analysis, a voice feature description method of co-occurrence direction attribute topology (CDAT) is proposed in this paper. Firstly, the formal context is established according to the direction information statistically obtained in the sub-region of the spectrogram to describe the correspondence between energy points and their direction attributes. Then the CDAT is constructed to obtain the coupling information between the direction attributes in the formal context. Finally, the number of connected domains in the CDAT indicating the degree of nodal coupling is extracted as structural features and input to multiple classifiers for validation. Test and cross-corpora experiments are conducted on two different Parkinsonian sustained vowel datasets, CPPDD and SPDD, achieving the best average classification accuracies of 95.84% and 93.90% with random forest, respectively. The proposed features highlight the variation of energy direction derivatives in the spectrograms through the attribute topology. The results indicate that the proposed method has good classification accuracy on different native language datasets and cross-corpora experiments, which outperforms or is comparable to the performance of latest methods used for PD classification.},
  archive      = {J_EAAI},
  author       = {Tao Zhang and Liqin Lin and Jing Tian and Zaifa Xue and Xiaonan Guo},
  doi          = {10.1016/j.engappai.2023.106097},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106097},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Voice feature description of parkinson’s disease based on co-occurrence direction attribute topology},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collaboration methods for ensembles of dispatching rules for
the dynamic unrelated machines environment. <em>EAAI</em>, <em>122</em>,
106096. (<a
href="https://doi.org/10.1016/j.engappai.2023.106096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic scheduling represents an important combinatorial optimisation problem that often appears in the real world. The difficulty in solving these problems arises from their dynamic nature, which limits the applicability of improvement based metaheuristics. Dynamic problems are usually solved using dispatching rules (DRs), which iteratively construct the schedule. Recently, such heuristics have been constructed using various hyperheuristic methods, most notably genetic programming. Although automatically designed DRs achieve good performance, it is still very difficult to design a single DR that would perform a good decision at every decision point. As a remedy, DRs were combined into ensembles to improve their performance. For that purpose it is required to define how ensembles are constructed and how DRs in the ensemble collaborate. This paper proposes a novel ensemble collaboration method based on a similar method applied for static scheduling problems and adapts it for dynamic problems. The goal is to obtain a collaboration method that produces better results than standard collaboration methods. Additionally, the paper investigates the application of novel ensemble construction methods for dynamic scheduling. The proposed methods are validated on dynamic unrelated machines scheduling problem and compared with existing ensemble construction and collaboration methods. The obtained results demonstrate that the proposed collaboration method performs better than standard ones. Further analyses provide additional insights into the proposed methods and outline several potential research directions in the area of hyper-heuristic ensemble construction.},
  archive      = {J_EAAI},
  author       = {Marko Đurasević and Francisco Javier Gil-Gala and Lucija Planinić and Domagoj Jakobović},
  doi          = {10.1016/j.engappai.2023.106096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Collaboration methods for ensembles of dispatching rules for the dynamic unrelated machines environment},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated interval type-2 fuzzy BWM-MARCOS model for
location selection of e-scooter sharing stations: The case of a
university campus. <em>EAAI</em>, <em>122</em>, 106095. (<a
href="https://doi.org/10.1016/j.engappai.2023.106095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scooter sharing has gained tremendous popularity among university campuses as in other places with many visitors. In practice, shared dockless scooters are more widely used than dock-based scooters. However, dockless scooters can cause inefficient mobility in case of the needs such as recharging and finding the nearest scooter among scattered ones in various places. Since the scooter-sharing literature still has significant knowledge gaps regarding identifying an optimal deployment of scooter-sharing stations, this paper aims to determine the necessary criteria to be considered while deploying scooter-sharing stations and identifying the best locations based on a university campus case using an integrated interval type-2 fuzzy BWM-MARCOS model. This study focuses on a university case that can be exemplary for other universities and similar locations, including many people in their various parts. Universities are bounded areas, and their visitors are mostly the same people for a long time. Therefore, first location selection and corrective actions in time may give more traceable and precise results. This research identifies the main criteria and presents a systematic road map for location selection of shared e-scooter stations, applying ITF2-BWM to determine the importance weights of the location selection criteria and employing IT2F-MARCOS to select the most optimal shared e-scooter stations. Hence, the current paper differs from past studies concerning the studied case and the proposed integrated model. A comparative study with IT2F-TOPSIS is employed to strengthen the accuracy of the results produced by the proposed model. Also, a sensibility analysis of the results was performed to test how changes in criteria weights would affect the final scores of alternative locations.},
  archive      = {J_EAAI},
  author       = {B. Can Altay and Erkan Celik and Abdullah Okumus and Abit Balin and Muhammet Gul},
  doi          = {10.1016/j.engappai.2023.106095},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106095},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated interval type-2 fuzzy BWM-MARCOS model for location selection of e-scooter sharing stations: The case of a university campus},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Texture-aware gray-scale image colorization using a bistream
generative adversarial network with multi scale attention structure.
<em>EAAI</em>, <em>122</em>, 106094. (<a
href="https://doi.org/10.1016/j.engappai.2023.106094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various methods based on deep neural networks have been proposed to generate color images from gray-scale images, meanwhile, Generative adversarial networks (GANs) are also gradually applied to image colorization. However, the existing methods are texture-unaware, resulting in dullish color and color bleeding artifacts in the output images. This paper attempt to integrate a novel texture-aware bistream GAN into the conventional encoder–decoder structure for image colorization. In this study, the proposed bistream feature extraction module (BSFEM) and the feature boosting module (FBM), extract the global and local features from two parallel encoders and fuse them via a novel hybrid attention structure, this novel structure could emphasize the importance of certain channels and locations of features that may potentially benefit image colorization. In addition, the texture colors can be better recovered though the proposed multi-scale feature attention module (MSFAM). The quantitative experiments demonstrate that, compared to the state-of-the-art approaches, the proposed method has improved the PSNR and SSIM metrics by 18% and 8% respectively. Moreover, the qualitative results show that this method is capable of producing visually pleasant color images especially in terms of recovering texture details and eliminating color bleeding along the edges. The source code and data are available online at https://github.com/JarryZang/Image-Colorization- .},
  archive      = {J_EAAI},
  author       = {Shengrui Zang and Min Chen and Zhenhua Ai and Jieru Chi and Guowei Yang and Chenglizhao Chen and Teng Yu},
  doi          = {10.1016/j.engappai.2023.106094},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106094},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Texture-aware gray-scale image colorization using a bistream generative adversarial network with multi scale attention structure},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel aeroengine fault diagnosis method based on feature
amplification. <em>EAAI</em>, <em>122</em>, 106093. (<a
href="https://doi.org/10.1016/j.engappai.2023.106093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven fault diagnosis methods have high requirements for data samples. The ideal state is that the input samples have good separability. However, because of the harsh working environment and complex operating conditions, the collected data are highly nonlinear inseparability. The existing methods often cannot achieve a good classification effect. To solve this problem, two feature amplification methods that make full use of the useful information from the aeroengine service data are proposed. One is a high-dimensional mapping method based on explicit mapping of kernel function to amplify features. The other is an experiential method to amplify features. Both methods map the input samples to high-dimensional space to make them more separable in high-dimensional space and retain the useful information of raw data. Each feature after feature amplification still covers strong independent information that can describe fault feature information from different dimensions. Then, four deep learning algorithms that have a good effect on processing time-series data are selected as the classifier. The aeroengine service dataset and the bearing vibration dataset from Case Western University are used to verify the effectiveness of the two feature amplification methods. The experimental results show that the fault diagnosis accuracy can be improved if sample features after high-dimensional mapping possess good orthogonality, otherwise, the accuracy will be reduced.},
  archive      = {J_EAAI},
  author       = {Lin Lin and Wenhui He and Song Fu and Changsheng Tong and Lizheng Zu},
  doi          = {10.1016/j.engappai.2023.106093},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106093},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel aeroengine fault diagnosis method based on feature amplification},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance evaluation of LSTM and bi-LSTM using
non-convolutional features for blockage detection in centrifugal pump.
<em>EAAI</em>, <em>122</em>, 106092. (<a
href="https://doi.org/10.1016/j.engappai.2023.106092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockages in the suction or discharge side of the pump adversely affect the pump’s performance by reducing the flow rate and head, increasing vibration, noise, and overheating. Thus, diagnosing pump blockages accurately and quickly is vital. In this study, a test rig is developed to detect blockages in the pump (suction, discharge, and simultaneous) at three levels of severity. Initially, a non-convolutional feature layer is developed to extract sets of statistical features (SF), entropy-based parameters, and Holder’s exponent (HE). Next, two sequential learners, LSTM and Bi-LSTM, are trained with statistical parameters and tuned using grid-search optimization. Model with least validation loss is chosen as the base model. Subsequently, the process is repeated with only non-linear features, combination of SF with HE, and combination of all three sets of features. Thus, eight different models are trained (four each for LSTM and Bi-LSTM). To eradicate the impact of random variations, these models are trained ten times and the average values of performance metrics (precision, recall, and F1score) are noted. It is found that LSTM trained with all sets of features is most accurate at 99.01% with F1 score of 98.95%. Although LSTM is superior, it is marginally ahead of Bi-LSTM, but LSTM consumes almost 40% lesser time for training. Toward the end, the ablation study of LSTM is performed to analyze the effects of the most influencing parameters. Thus, the present study emphasizes an automated and robust method for maintenance engineers to diagnose the blockages in the pump with severities of blockages.},
  archive      = {J_EAAI},
  author       = {Nagendra Singh Ranawat and Jatin Prakash and Ankur Miglani and Pavan Kumar Kankar},
  doi          = {10.1016/j.engappai.2023.106092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Performance evaluation of LSTM and bi-LSTM using non-convolutional features for blockage detection in centrifugal pump},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LayoutQT—layout quadrant tags to embed visual features for
document analysis. <em>EAAI</em>, <em>122</em>, 106091. (<a
href="https://doi.org/10.1016/j.engappai.2023.106091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relative position of text blocks plays a crucial role in document understanding. However, the task of embedding layout information in the representation of a page instance is not trivial. Computer Vision and Natural Language Processing techniques have been advancing in extracting content from document images considering layout features. We propose a set of Layout Quadrant Tags (LayoutQT) as a new way of encoding layout information in textual embedding. We show that this enables a standard NLP pipeline to be significantly enhanced without requiring expensive mid or high-level multimodal fusion. Given that our focus is on developing a low computational cost solution, we focused our experiments on the AWD-LSTM neural network. We evaluated our method for page stream segmentation and document classification tasks on two datasets, Tobacco800 and RVL-CDIP. In the former, our method improved the F1 score from 97.9% to 99.1% and in the latter the F1 score went from 80.4% to 83.6%. Similar levels of performance improvement were also obtained when we applied LayoutQT with BERT.},
  archive      = {J_EAAI},
  author       = {Patricia Medyna Lauritzen de Lucena Drumond and Lindeberg Pessoa Leite and Teofilo E. de Campos and Fabricio Ataides Braz},
  doi          = {10.1016/j.engappai.2023.106091},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106091},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LayoutQT—Layout quadrant tags to embed visual features for document analysis},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SEA-net: Sequence attention network for seismic event
detection and phase arrival picking. <em>EAAI</em>, <em>122</em>,
106090. (<a
href="https://doi.org/10.1016/j.engappai.2023.106090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic seismic phase detection and phase arrival time picking are always fundamental tasks in seismology. With the emergence of machine learning, and deep learning in particular, a number of neural network architectures are being used to explore the correlations between seismic waveforms and hidden information of interest. In this paper, we present a sequential attention (SEA) module that can learn both local and long-distance corrections to effectively extract sequential features. This module is lightweight and plug-in-play. Based on the SEA module, a fully convolutional neural network with sequential attention mechanism was constructed to detect seismic events and determine the arrival time of phases. Further experiments on STEAD dataset, in comparison with existing methods, show that our proposed model outperforms other algorithms with a higher F1-score (100% for seismic detection, 98.8% for P arrival picking, and 89.0% for S arrival picking) and fewer residual errors. Comparatively, our model has a quarter of the model parameters and computational complexity as well as a 36.7% reduction in processing time compared to the current state-of-the-art method. This demonstrates that the proposed architecture is effective for seismic sequential learning tasks and, as a result, can serve as an improved alternative backbone.},
  archive      = {J_EAAI},
  author       = {Xiaoming Hou and Yu Zheng and Ming Jiang and Shengli Zhang},
  doi          = {10.1016/j.engappai.2023.106090},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106090},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SEA-net: Sequence attention network for seismic event detection and phase arrival picking},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Some applications in decision-making using cosine maps and
the relevance of the pythagorean fuzzy. <em>EAAI</em>, <em>122</em>,
106089. (<a
href="https://doi.org/10.1016/j.engappai.2023.106089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The non-classical set, generally known as Pythagorean fuzzy (PF), is one of mathematics’ most essential and it is used in our approach, which is crucial and useful, because it can handle more uncertainty than intuitionistic fuzzy sets and others non-classical sets, so has a wider range of applications. In nature, the periodicity and symmetry are provided by the well-known cosine trigonometric function, meeting decision-makers’ expectations for multi-time process parameters. Introduce the new cosine trigonometric operational laws ( C T O L s ) with ( P F ) structure, keeping the peculiarities of the cosine function and the relevance of the Pythagorean fuzzy set (PFS) in mind. New cosine trigonometric Pythagorean fuzzy ( C T P F ) aggregation operators are created on the basis of these ( C T O L s ) . The main focus of the research is on a decision-making algorithm for multi-attribute decision-making situations. It is based on a planned aggregating operation employing unknown weight information for the specified standards. In the end, to demonstrate the effectiveness, an example of internet finance soft power evaluation (IFSPE) is offered. Sensibility and comparison analyses are also used to evaluate the method’s stability and validity.},
  archive      = {J_EAAI},
  author       = {Shuker Mahmood Khalil and Moataz Sajid Sharqi},
  doi          = {10.1016/j.engappai.2023.106089},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106089},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Some applications in decision-making using cosine maps and the relevance of the pythagorean fuzzy},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-class learning for fake news detection through
multimodal variational autoencoders. <em>EAAI</em>, <em>122</em>,
106088. (<a
href="https://doi.org/10.1016/j.engappai.2023.106088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods to detect fake news typically use textual features and Binary or Multi-class classification. However, accurately labeling a large news set is still a very costly process. On the other hand, one of the prominent approaches is One-Class Learning (OCL). OCL requires only the labeling of fake news, minimizing data labeling efforts. Although we eliminate the need to label non-interest news, the efficiency of OCL algorithms depends directly on the data representation model adopted. Most existing methods in the OCL literature explore representations based on one modality to detect fake news. However, different text features can be the reason for the news to be fake, such as topic or linguistic features. We model this behavior as different modalities for news to represent different textual feature sets. Thus, we present the MVAE-FakeNews, a multimodal method to represent the texts in the fake news detection through OCL that learns a new representation from the combination of promising modalities for news data: text embeddings, topic, and linguistic information. We used real-world fake news datasets in Portuguese and English in the experimental evaluation. Results show that MVAE-FakeNews obtained a better F 1 -Score and AUC-ROC, outperforming another fourteen methods in three datasets and getting competitive results on the other three. Moreover, our MVAE-FakeNews, with only 3% of labeled fake news, obtained comparable or higher results than other methods. To improve the experimental evaluation, we also propose the Multimodal LIME for OCL to identify how each modality is associated with the fake news class.},
  archive      = {J_EAAI},
  author       = {Marcos Paulo Silva Gôlo and Mariana Caravanti de Souza and Rafael Geraldeli Rossi and Solange Oliveira Rezende and Bruno Magalhães Nogueira and Ricardo Marcondes Marcacini},
  doi          = {10.1016/j.engappai.2023.106088},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106088},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {One-class learning for fake news detection through multimodal variational autoencoders},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A systematic survey on explainable AI applied to fake news
detection. <em>EAAI</em>, <em>122</em>, 106087. (<a
href="https://doi.org/10.1016/j.engappai.2023.106087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential proliferation of fake news in recent years has emphasized the demand for automated fake news detection. Several techniques for detecting fake news have yielded encouraging results. However, these detection systems lack explainability i.e., providing the reason for their prediction. The critical advantage of explainability is the identification of bias and discrimination in detection algorithms. There are very few surveys conducted on the area of explainable AI applied to fake news detection. All of theses surveys summarize the existing methods in this area. Most of them are limited to the discussion of specific topics like datasets, evaluation methods, and potential future applications. In contrast, this survey looks at existing explainable AI methods and highlights the current state of the art in explainable fake news detection. We identify and enumerate a few open research problems based on our review of the existing explainable fake news detection techniques. We group the existing work in this area, by viewing it from four different perspectives: features used for the classification, explanation type, explainee type, and the metric used for explainability evaluation. The potential research topics in the above four groups which are unexplored so far and which need attention are also listed in this paper.},
  archive      = {J_EAAI},
  author       = {Athira A.B. and S.D. Madhu Kumar and Anu Mary Chacko},
  doi          = {10.1016/j.engappai.2023.106087},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106087},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic survey on explainable AI applied to fake news detection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing digital twin design for enhanced productivity of
an automated anodizing industry and process prediction using hybrid deep
neural network. <em>EAAI</em>, <em>122</em>, 106086. (<a
href="https://doi.org/10.1016/j.engappai.2023.106086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automation is beneficial when implemented in challenging environments requiring less human effort or reducing human effort. Employee safety is a concern to increase productivity, delivery and achieve the required quality. The present research investigates the possibility of installing an automation procedure in an anodizing industry called GOLDEN ANODIZER, which is situated in Coimbatore, India. During the preliminary analysis at the specified industry premises, there was a reduction in productivity, quality and customer delivery due to manual operations, including some health issues were identified. And hence the present investigation analyses the possibility of installation of an automation system for the anodizing process. For such reason, the digital twin of an automation system is first designed, developed and tested using Siemens NX software. The anodizing factors such as Anodizing medium temperature (K), Acid Concentration (wt%), applied voltage (V) and Responses Surface Finish (Ra), Film Thickness (tf) and Time Duration (T) were optimized for improved productivity and quality. Prediction results and RMSE analysis show that the proposed hybrid PSO-LFA algorithm has outperformed all modern algorithms. The proposed algorithm optimized the anodizing parameters and suggested 3650.7 s as a new cycle time. Also, the improved cycle time can boost the plant outcome by 182% and reduce the manpower by 46% through the proposed Automation system.},
  archive      = {J_EAAI},
  author       = {Vinodh Kumar P. and Manikandan V. and Manavaalan G. and Elango S.},
  doi          = {10.1016/j.engappai.2023.106086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Developing digital twin design for enhanced productivity of an automated anodizing industry and process prediction using hybrid deep neural network},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving routing problems for multiple cooperative unmanned
aerial vehicles using transformer networks. <em>EAAI</em>, <em>122</em>,
106085. (<a
href="https://doi.org/10.1016/j.engappai.2023.106085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missions involving Unmanned Aerial Vehicle usually consist of reaching a set of regions, performing some actions in each region, and returning to a determined depot after all the regions have been successfully visited or before the fuel/battery is totally consumed. Hence, planning a route becomes an important task for many applications, especially if a team of Unmanned Aerial Vehicles is considered. From this team, coordination and cooperation are expected to optimize results of the mission. In this paper, a system for managing multiple cooperative Unmanned Aerial Vehicles is presented. This system divides the routing problem into two stages: initial planning and routing solving. Initial planning is a first step where the regions to be visited are grouped in multiple clusters according to a distance criterion, with each cluster being assigned to each of the Unmanned Aerial Vehicles. Routing solving computes the best route for every agent considering the clusters of the initial planning and a variant of the Orienteering Problem. This variant introduces the concept of shared regions, allowing an Unmanned Aerial Vehicle to visit regions from other clusters and compensating for the suboptimal region clustering of the previous stage. The Orienteering Problem with shared regions is solved using the deep learning architecture Transformer along with a deep reinforcement learning framework. This architecture is able to obtain high-quality solutions much faster than conventional optimization approaches. Extensive results and comparison with other Combinatorial Optimization algorithms, including cooperative and non-cooperative scenarios, have been performed to show the benefits of the proposed solution.},
  archive      = {J_EAAI},
  author       = {Daniel Fuertes and Carlos R. del-Blanco and Fernando Jaureguizar and Juan José Navarro and Narciso García},
  doi          = {10.1016/j.engappai.2023.106085},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106085},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving routing problems for multiple cooperative unmanned aerial vehicles using transformer networks},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Airport detection in remote sensing real-open world using
deep learning. <em>EAAI</em>, <em>122</em>, 106083. (<a
href="https://doi.org/10.1016/j.engappai.2023.106083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing real-open world of large-scare areas brings a high false alarm rate to object detection because of highly complex backgrounds. In this study, we constructed a two-stage extraction framework candidate region extraction (CRE)–multi-core binary analysis (MCBA) (CRE-MCBA) to improve the correct detection rate (DR) and reduce the error DR for airport extraction in large-scale remote sensing real-open areas. First, global sample labeling and large-scale runway CRE were conducted. Open-sourced data were applied to match the detection results spatially, and the MCBA was built for the issue of unbalanced positive and negative samples to mine potential airports. The minimum penalty term δ was also introduced into focal loss to improve detection ability in a remote sensing real-open world area. In the 219,041 km 2 study area at the Yangtze River Delta in China, the detection and error reduction rates were 100% and 97.3%, respectively. A total of 37 airports with prominent runway characteristics were detected, with 9 newly added airports. We also test the CRE-MCBA framework in Japan, Korean Peninsula, and Madhya Pradesh of India. Compared with other detection methods, ours has more robust regional adaptability and generalization ability and realizes the practical mining of potential objects.},
  archive      = {J_EAAI},
  author       = {Ning Li and Liang Cheng and Chen Ji and Hui Chen and WanXuan Geng and WeiMing Yang},
  doi          = {10.1016/j.engappai.2023.106083},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106083},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Airport detection in remote sensing real-open world using deep learning},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DL-PR: Generalized automatic modulation classification
method based on deep learning with priori regularization. <em>EAAI</em>,
<em>122</em>, 106082. (<a
href="https://doi.org/10.1016/j.engappai.2023.106082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic modulation classification (AMC) is an essential and indispensable topic in the development of cognitive radios. It is the cornerstone of adaptive modulation and demodulation capabilities to perceive and understand surrounding environments and make corresponding decisions. In this paper, we propose a priori regularization method in deep learning (DL-PR) for guiding loss optimization during model training process. The regularization factor designed by the combination of inter-class confrontation factor, global and dimensional divergence can help increase the inter-class distance and reduce the intra-class distance of samples. While preserving the original information of received signals as much as possible, it makes full use of the prior knowledge in the signal transmission process and ultimately helps deep learning models to be well generalized on signals with various signal-to-noise ratios (SNRs). As far as we know, this is the first attempt to regularize deep learning models based on SNR distribution of samples to improve AMC accuracy. Moreover, it can be proved that priori regularization can be interpreted as implicit data augmentation and model ensemble methods. By comparing with a series of state-of-the-art AMC methods and different regularization techniques on the public dataset RadioML 2016.10a, experimental results of multiple deep learning models illustrate the superiority of DL-PR, including CNN with accuracy of 62.6% and inference time of 0.82 ms per signal, LSTM with 61.8% and 0.87 ms, and hybrid CNN–LSTM with 64.2% and 0.94 ms. In practical applications, DL-PR can be also easily applied to complex environments due to its robustness to hyper-parameters and SNR estimation.},
  archive      = {J_EAAI},
  author       = {Qinghe Zheng and Xinyu Tian and Zhiguo Yu and Hongjun Wang and Abdussalam Elhanashi and Sergio Saponara},
  doi          = {10.1016/j.engappai.2023.106082},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106082},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DL-PR: Generalized automatic modulation classification method based on deep learning with priori regularization},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The development of a road network flood risk detection model
using optimised ensemble learning. <em>EAAI</em>, <em>122</em>, 106081.
(<a href="https://doi.org/10.1016/j.engappai.2023.106081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Floods are natural phenomena that invade different parts of the globe annually, leaving severe adverse effects on the natural landscape, particularly in areas where humans practice large-scale urban development activities. Inadequate corporate strategic stormwater management or maintenance plans make the issue even worse. Therefore, efforts have been consolidated to confront flood hazards by incorporating precautious and proactive strategies toward better forecasting and preventing flood disasters or even mitigating the damage if it occurs. Further, there is inadequacy in incorporating computational intelligence techniques to detect flood susceptibility in road networks. This paper proposes a data-driven flood risk areas detection model incorporating various ensemble and generic machine learning techniques as well as autoML tools. A systematic and iterative approach is followed to examine different solutions to tackle the data balancing problem, including oversampling and undersampling techniques. Also, hyperparameter optimisation is undertaken using both grid search and genetic algorithms, and the models’ performance using each designated strategy is reported and assessed. The empirical results from the experiments indicate that the optimised ensembled Extremely Randomized Trees classifier proves an ability to perform well on the given dataset with an averaged ROC AUC value of 90% and outperforms several state-of-the-art generic, ensembled, and autoML classifiers in all evaluation measures. The proposed framework could be possibly generalised to other road networks in similar topographical and geological regional areas.},
  archive      = {J_EAAI},
  author       = {Bilal Abu-Salih and Pornpit Wongthongtham and Kevin Coutinho and Raneem Qaddoura and Omar Alshaweesh and Mohammad Wedyan},
  doi          = {10.1016/j.engappai.2023.106081},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106081},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The development of a road network flood risk detection model using optimised ensemble learning},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Glee: A granularity filter for feature selection.
<em>EAAI</em>, <em>122</em>, 106080. (<a
href="https://doi.org/10.1016/j.engappai.2023.106080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of Granular Computing (GrC), feature selection is an attractive task. Some basics of GrC such as information granulation and granularity have well guided the explorations of feature selection technique. Nevertheless, some challenges to perform feature selection such as high computational costs of repeating information granulation and multi-granularity structure in the process of searching qualified features may also arise. In this study, to improve the efficiency and effectiveness of feature selector, a novel framework named Glee : Granularity fiLter for fEature sElection , is reported. Firstly, the value of granularity related to each feature is calculated. Secondly, all features are reordered by the corresponding values of granularity. Finally, following such a derived sequence, features will be added into the selection pool one by one until the termination condition is achieved. Glee can not only eliminate the iterative calculations of information granulation in the whole process of selecting, but also provide sequence of features which may be insensitive to data perturbation. It should also be emphasized that Glee is a general framework, and most existing termination conditions to feature selection can be embedded into it. To validate the effectiveness of Glee , it is compared with several well-established feature selection schemes in elapsed time of selecting features, stability of selected features and classification performance. Experimental results over 20 UCI datasets with both raw features and 3 different ratios of noisy features demonstrate that our framework is superior as it yields better robustness with satisfactory elapsed time.},
  archive      = {J_EAAI},
  author       = {Jing Ba and Pingxin Wang and Xibei Yang and Hualong Yu and Dongjun Yu},
  doi          = {10.1016/j.engappai.2023.106080},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106080},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Glee: A granularity filter for feature selection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Photon/electron classification in liquid argon detectors by
means of soft computing. <em>EAAI</em>, <em>122</em>, 106079. (<a
href="https://doi.org/10.1016/j.engappai.2023.106079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of Particle Physics, the behaviors of elementary particles differ among themselves on subtle details that need to be identified to further our understanding of the universe. Machine learning is being increasingly applied in order to solve this task by extracting and extrapolating patterns from detector data. This paper tackles the classification of simulated traces from a liquid argon container into photon- or electron-induced events. Several viable dataset representations are proposed and evaluated on nine supervised learning algorithms to find promising combinations. After that, a hyperparameter optimization step is applied on some of the classifiers to try to maximize their accuracy. Random Forest and XGBoost achieve the best results with roughly 88% test-set accuracy, which shows the potential of machine learning to solve a significant research question in a subfield that is expected to keep growing in the coming years.},
  archive      = {J_EAAI},
  author       = {Javier León and Juan José Escobar and Marina Bravo and Bruno Zamorano and Alberto Guillén},
  doi          = {10.1016/j.engappai.2023.106079},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106079},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Photon/electron classification in liquid argon detectors by means of soft computing},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PrecTime: A deep learning architecture for precise time
series segmentation in industrial manufacturing operations.
<em>EAAI</em>, <em>122</em>, 106078. (<a
href="https://doi.org/10.1016/j.engappai.2023.106078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fourth industrial revolution creates ubiquitous sensor data in production plants. To generate maximum value out of these data, reliable and precise time series-based machine learning methods like temporal neural networks are needed. This paper proposes a novel sequence-to-sequence deep learning architecture for time series segmentation called PrecTime which tries to combine the concepts and advantages of sliding window and dense labeling approaches. The general-purpose architecture is evaluated on a real-world industry dataset containing the End-of-Line testing sensor data of hydraulic pumps. We are able to show that PrecTime outperforms five implemented state-of-the-art baseline networks based on multiple metrics. The achieved segmentation accuracy of around 96% shows that PrecTime can achieve results close to human intelligence in operational state segmentation within a testing cycle.},
  archive      = {J_EAAI},
  author       = {Stefan Gaugel and Manfred Reichert},
  doi          = {10.1016/j.engappai.2023.106078},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106078},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PrecTime: A deep learning architecture for precise time series segmentation in industrial manufacturing operations},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A modified GNN architecture with enhanced aggregator and
message passing functions. <em>EAAI</em>, <em>122</em>, 106077. (<a
href="https://doi.org/10.1016/j.engappai.2023.106077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNN) uphold the essence of irregularly structured information embedded in a graph via message passing among the nodes and aggregating the node features at various levels of the graph. In the past, researchers have extensively used the GNN models for several semi-supervised node classification tasks. Existing GNN models do not use nodes’ information sufficiently. The use of inter-node feature-level correlational information with the existing GNN models might lead to more powerful learning models. Here, a weighting scheme has been developed for message passing and aggregation functions. This model has been named “Vector GNN”, or in short, “VecGNN”, due to its relationship with vector space. VecGNN takes into consideration the relative position of a node with respect to its neighboring nodes in the feature space, which influences the weight of features passed to the information aggregation phase. These weights are assigned using two different statistical measures: Jaccard’s coefficient and Cosine similarity. The proposed weighting scheme uses a generalized approach that can be easily incorporated into several GNN frameworks. VecGNN is evaluated using three citation datasets: Citeseer, Pubmed, and Cora. On these datasets, three sets of experiments have been conducted with varying numbers of training and testing nodes. We have used training, validation, and test set nodes with ratios of 1:1:8, 2:1:7, and 3:1:6. Experimenting on these, we observe an improvement of 2%–4% over the baseline models: Graph Convolution Network (GCN), Graph Attention Network (GAT), and Jumping Knowledge Networks (JKNets). The source code is available at the link https://github.com/sourodeeproy/VecGNN .},
  archive      = {J_EAAI},
  author       = {Debjit Sarkar and Sourodeep Roy and Samir Malakar and Ram Sarkar},
  doi          = {10.1016/j.engappai.2023.106077},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106077},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A modified GNN architecture with enhanced aggregator and message passing functions},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TALK: Tracking activities by linking knowledge.
<em>EAAI</em>, <em>122</em>, 106076. (<a
href="https://doi.org/10.1016/j.engappai.2023.106076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dependable and accurate monitoring of elderly at home becomes crucial to limit both the costs and human efforts of following up elderly for establishing a healthy care system. Human Activity Recognition (HAR) tools, based on sensors installed in smart homes, will become an important tool to provide useful information to the caregiver when something happens in the house of an elderly and care is required. The current available detection tools either exist out of interpretable knowledge-driven techniques or scalable data-driven ones. In this paper, a hybrid methodology that combines both approaches is designed and evaluated to Track Activities by Linking Knowledge (TALK). Both sensor data and their link to the relevant domain knowledge about where those sensors are installed, the performed activities that occur, and how the household is constructed, are generalized in a specific knowledge graph (KG) structure to represent continuous events. The interpretable knowledge graph embedding technique Instance Neighboring using Knowledge (INK) is then used to transform these events inside the KG to a tabular format, which can be used by any traditional machine learning classifier to create a HAR tool. The TALK methodology is evaluated on two HAR datasets and shows (a) that TALK outperforms both traditional automated data-driven as well as knowledge-driven techniques in terms of predictive performance, and (b) how TALK can be easily used in a more out of lab environment. All these results and the interpretable aspects show that TALK can become an important tool to monitor elderly in their homes efficiently, effectively and with less intrusive techniques.},
  archive      = {J_EAAI},
  author       = {Bram Steenwinckel and Mathias De Brouwer and Marija Stojchevska and Filip De Turck and Sofie Van Hoecke and Femke Ongenae},
  doi          = {10.1016/j.engappai.2023.106076},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106076},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TALK: Tracking activities by linking knowledge},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controlling fracture propagation using deep reinforcement
learning. <em>EAAI</em>, <em>122</em>, 106075. (<a
href="https://doi.org/10.1016/j.engappai.2023.106075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical discontinuity embedded in a material plays an essential role in determining the bulk mechanical, physical, and chemical properties. The ability to control mechanical discontinuity is relevant for industries dependent on natural, synthetic and composite materials, e.g. construction, aerospace, oil and gas, ceramics, metal, and geothermal industries, to name a few. The paper is a proof-of-concept development of a reinforcement learning framework to control the propagation of mechanical discontinuity. The reinforcement learning framework is coupled with an OpenAI-Gym-based environment that uses the mechanistic equation governing the propagation of mechanical discontinuity. Learning agent does not explicitly know about the underlying physics of propagation of discontinuity; nonetheless, the learning agent can infer the control strategy by continuously interacting the environment. The design of Markov decision process, which includes state, action and reward, is crucial for robust control. The deep deterministic policy gradient (DDPG) algorithm is implemented for learning continuous actions. It is also observed that the training efficiency is strongly determined by the formulation of reward function. The reward function that forces the learning agent to stay on the shortest linear path between crack tip and goal point performs much better than the reward function that aims to reach closest to the goal point in minimum number of steps. After close to 500 training episodes, the reinforcement learning framework successfully controlled the propagation of discontinuity in a material despite the complexity of the propagation pathway determined by multiple goal points.},
  archive      = {J_EAAI},
  author       = {Yuteng Jin and Siddharth Misra},
  doi          = {10.1016/j.engappai.2023.106075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Controlling fracture propagation using deep reinforcement learning},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hesitant t-spherical fuzzy linear regression model based
decision making approach using gradient descent method. <em>EAAI</em>,
<em>122</em>, 106074. (<a
href="https://doi.org/10.1016/j.engappai.2023.106074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hesitant fuzzy set based linear regression model is used to solve decision making problems, where each element is assessed with multiple membership grades. However, in order to handle uncertainty properly, non-membership and abstinence degrees of each elements are also considered as equally significant, which are not captured by hesitant fuzzy set. To resolve these limitations of hesitant fuzzy set based model, this paper proposes hesitant t-spherical fuzzy linear regression model, where hesitant t-spherical fuzzy set can efficiently handle both non-membership and abstinence degrees along with membership degree. The regression model is used to determine the imprecise functional relationship between the dependent and independent variables which are represented using hesitant t-spherical fuzzy set. We apply gradient descent technique to estimate the optimal coefficients of the variables used in the proposed regression model. Finally, the residuals of the regression are computed for the purpose of decision making. The proposed approach has been illustrated using three real life applications (robot selection, revenue generation, and material selection) and compared with the existing approaches. Moreover, we have used sensitivity analysis and weighted spearman’s rank correlation coefficient metrics to demonstrate that the outcome of the proposed model is more consistent and reliable to rank its best alternative compared to existing approaches, which shows its capability to solve real life uncertain decision-making problems.},
  archive      = {J_EAAI},
  author       = {G. Punnam Chander and Sujit Das},
  doi          = {10.1016/j.engappai.2023.106074},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106074},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hesitant t-spherical fuzzy linear regression model based decision making approach using gradient descent method},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nested physics-informed neural network for analysis of
transient flows in natural gas pipelines. <em>EAAI</em>, <em>122</em>,
106073. (<a
href="https://doi.org/10.1016/j.engappai.2023.106073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gas pipeline systems are commonly designed under the assumption of constant supply and demand flow conditions. This is while gas flows are transient because of the compression stations, presence of gas storage facilities and fluctuating supply and consumer demands. Analyzing such transient flows substantially benefits design, control, and monitoring of natural gas pipeline systems. The nonlinear partial differential equations describing the physics of transient flows in pipelines are solved using conventional methods, which are computationally demanding especially for uncertainty quantification purposes where many simulations are required. In this study, we propose an alternative physics-informed neural network (PINN) framework for the transient analysis of pipeline networks that can perform transient flow analysis in natural gas pipelines that the original PINNs cannot solve due to the high complexity of the problem. We propose a nested structure for the PINNs with a loss model that greatly reduces the number of tasks in the emergent complex multi-task learning process. We also integrate an adaptive weights approach that tackles the imbalanced gradients caused by the extremely large coefficients in the equations of the natural gas pipeline problem. The proposed framework, for the first time, can produce accurate results for the complex natural gas pipeline network problem using PINNs. Furthermore, we investigate the parameterization of the nested PINNs as a surrogate model for the natural gas pipeline system. With merely 26% more training costs, the surrogate model can perform the transient flow analysis given thousands of realizations of parameters in a split millisecond, while the costs of performing the same simulations using conventional methods can be prohibitively expensive. This can greatly boost the efficiency of complex many-query analyses such as sensitivity analysis, uncertainty propagation and design optimization.},
  archive      = {J_EAAI},
  author       = {Chi Zhang and Abdollah Shafieezadeh},
  doi          = {10.1016/j.engappai.2023.106073},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106073},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nested physics-informed neural network for analysis of transient flows in natural gas pipelines},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RSHAN: Image super-resolution network based on residual
separation hybrid attention module. <em>EAAI</em>, <em>122</em>, 106072.
(<a href="https://doi.org/10.1016/j.engappai.2023.106072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer has become one of the main architectures in deep learning, showing impressive performance in various vision tasks, especially for image super-resolution (SR). However, due to the usage of high-resolution input images, most current Transformer-based image super-resolution models have a large number of parameters and high computational complexity. Moreover, some components employed in the Transformer may be redundant for SR tasks, which may limit the SR performance. In this work, we propose an efficient and concise model for image super-resolution tasks termed Residual Separation Hybrid Attention Network (RSHAN), which aims to solve the problems of redundant components and insufficient ability to extract high-frequency information of Transformer. Specifically, we present the Residual Separation Hybrid Attention Module (RSHAM) which fuses the local features extracted by the convolutional neural network (CNN) branch and the long-range dependencies extracted by Transformers to improve the performance of RSHAN. Extensive experiments on numerous benchmark datasets show that the proposed method outperforms state-of-the-art SR methods by up to 0.11 dB in peak signal-to-noise ratio (PSNR) metric, while the computational complexity and the inference time is reduced by 5% and 10%, respectively.},
  archive      = {J_EAAI},
  author       = {Ying Shen and Weihuang Zheng and Liqiong Chen and Feng Huang},
  doi          = {10.1016/j.engappai.2023.106072},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106072},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RSHAN: Image super-resolution network based on residual separation hybrid attention module},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Classification technique and its combination with clustering
and association rule mining in educational data mining — a survey.
<em>EAAI</em>, <em>122</em>, 106071. (<a
href="https://doi.org/10.1016/j.engappai.2023.106071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational data mining (EDM) is the application of data mining in the educational field. EDM is used to classify, analyze, and predict the students’ academic performance, and students’ dropout rate, as well as instructors’performance in order to improve teaching–learning process. This review article discusses the detailed analysis of 142 research articles from publication year 2010-2020 downloaded from the research databases such as IEEE, Springer, ACM, and Elsevier. Also this review article contains the current happenings related to EDM in year 2021 and 2022. In this review article, the use of classification techniques and classification techniques along with other data mining techniques such as clustering algorithm, association rule algorithms, regression techniques and ensemble techniques in EDM are presented thoroughly. The comparative study is considered for Classification Techniques; Classification and Clustering Technique; Classification ans Association Rule Mining; Classification, Clustering and Association rule mining; Classification, Regression, and Clustering; and Classification, and Ensemble. Analysis in terms of Yearwise Number of Research Articles employing Classification Techniquein EDM; Classification with other Data Mining Technique used in EDM; classifier as per Weka Tool; Classification Techniques; Clustering Techniques; Association Rule Techniques; Selecting the best Classification Technique; Classification performance metric; software used in EDM; Sampling Period; size of dataset; and data mining tools are illustrated. From review of 142 research articles, it is noted that classification techniques are mostly used technique for analyzing students’ performance in EDM. Also classification technique along with clustering techniques are applied to predict the performance of students. It is found that Naïve Bays, Random Forest, Support vector machine and J48 are mostly considered classification techniques while in classification along with clustering techniques, K-means clustering algorithm is used with classification algorithms. The classification algorithms such as Naïve Bays, Random Forest and Support Vector Machine are noted to be the best classification algorithms after comparing various classification algorithms based on various performance parameters. Among various performance parameters, the parameters accuracy, precision, recall, f-measures and k-fold value found to be used by most of the research articles. Programming languages used to build the model in EDM for analyzing the students’ dataset from educational setting, are Java, R and Python programming languages while data mining tools considered to evaluate the performance of classification or clustering or association rule algorithms are Weka, and RapidMiner. Classification algorithms under the classifiers as per Weka tool such as Tree, Bays, Function and PMML classifier are applied in most of the research articles. In addition to comparative analysis and analysis based on various factors, research gaps are also identified and mentioned the same in this article. Future direction for researcher working in EDM related to building the model on the dataset obtained from educational setting to predict students’ performance are discussed so that work in EDM can be carried out to improve the teaching–learning process.},
  archive      = {J_EAAI},
  author       = {Sunita M. Dol and Pradip M. Jawandhiya},
  doi          = {10.1016/j.engappai.2023.106071},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106071},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Classification technique and its combination with clustering and association rule mining in educational data mining — a survey},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A property perceived service quality evaluation method for
public buildings based on multisource heterogeneous information fusion.
<em>EAAI</em>, <em>122</em>, 106070. (<a
href="https://doi.org/10.1016/j.engappai.2023.106070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The basic information of property perceived service quality (PPSQ) evaluation for public buildings is characterized by multisource heterogeneity, which cannot be achieved using the existing evaluation methods. Based on the classical linear programming technique for multidimensional analysis of preference (LINMAP), a multiobjective LINMAP model is constructed, and a new PPSQ evaluation method is proposed to solve the above problem. Constructing the multiobjective LINMAP model is the core of the new PPSQ evaluation method design. The proposed multiobjective LINMAP model includes the following: First, multisource heterogeneous evaluation information is collected by the generalized multi-index multi-scale (MIMS) method, and normalized by the TOPSIS method. Then, the LINMAP model is extended by the objective function, which is constructed with the minimum mean standard deviation (MMSD) between multiple information sources. Finally, the source weight and index weight are determined by the above model, the ranking order of each property service project is calculated, and the comprehensive value of the property service project is obtained. The example study verifies the feasibility and effectiveness of the multiobjective LINMAP model which is suitable for the new requirement of comprehensively and objectively evaluating PPSQ for public buildings.},
  archive      = {J_EAAI},
  author       = {Wenjin Zuo and Lijun Liu and Qiang Hu and Shouzhen Zeng and Zhiming Hu},
  doi          = {10.1016/j.engappai.2023.106070},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106070},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A property perceived service quality evaluation method for public buildings based on multisource heterogeneous information fusion},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal non-autonomous area coverage control with adaptive
reinforcement learning. <em>EAAI</em>, <em>122</em>, 106068. (<a
href="https://doi.org/10.1016/j.engappai.2023.106068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Area coverage control with multi-agent systems is formulated here in the framework of Bellman’s optimality. In the literature, optimal configurations are obtained by Lloyd’s algorithm, which iteratively converges the agents to centroidal Voronoi configurations that correspond to local maxima of a coverage metric, where metric sub-domains are assigned to each agent according to Voronoi tessellations. In this work, optimal tracking is achieved by an adaptive control policy using an actor–critic neural network-based reinforcement learning technique, which rewards actions that decrease a Lyapunov function based on the area coverage metric to drive the error dynamics to zero, and uses a feed-forward neural network to approximate the tracking control signal. The implementation of the area-coverage control is model-free in the sense that it relies on neural networks that interpolate local data gathered and shared by each agent, without relying on a global model of the system. We prove that optimality is achieved when the agents converge to Voronoi centroids, therefore maximizing the coverage metric, with the important implication that the obtained class of solutions is consistent with the ones obtained with Lloyd’s algorithm and its extension to non-autonomous systems.},
  archive      = {J_EAAI},
  author       = {Farzan Soleymani and Md Suruz Miah and Davide Spinello},
  doi          = {10.1016/j.engappai.2023.106068},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106068},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal non-autonomous area coverage control with adaptive reinforcement learning},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Condition-based maintenance with reinforcement learning for
refrigeration systems with selected monitored features. <em>EAAI</em>,
<em>122</em>, 106067. (<a
href="https://doi.org/10.1016/j.engappai.2023.106067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worldwide, buildings are responsible for almost 30% of energy consumption, and those buildings that intensively use refrigeration systems, such as supermarkets and grocery stores, are also among the most energy-intensive consumers. Refrigeration devices, either commercial or residential, are responsible for a significant part of net emissions. Based on careful measurements, it is possible to reduce energy consumption in these devices by up to 15% only by improving the fault detection and diagnosis techniques. Thus, improving maintenance programs has become a crucial area in energy management in recent years. Nowadays, the market has experienced a hike after smart systems and new network interfaces applied to smart buildings that have allowed previously isolated devices to become smart devices, interacting with control algorithms smartly and, to some extent, autonomously. Here, we propose a reinforcement learning framework to develop a maintenance policy for mechanical compression refrigeration devices. Firstly, a test bench is built in which each component is assigned to be individually repairable and individually degradable in parallel and interconnected processes. Then, the degradation of the components is combined to formulate the system degradation, and the optimal maintenance policy is modeled via Markov decision processes and solved by a reinforcement learning algorithm. The agent-proposed maintenance program if compared to corrective maintenance, managed to reduce energy use and emissions by around 6% while avoiding shortfalls, as well as about the preventive program, where the agent managed to accomplish the same level of energy efficiency while reducing the maintenance costs by 31% and the time under maintenance in 10%. It was found that the reinforcement learning frameworks applied to maintenance have a series of challenges but are innovative and can show promising results compared to traditional maintenance techniques, such as preventive and corrective ones.},
  archive      = {J_EAAI},
  author       = {Caio Filipe de Lima Munguba and Gustavo de Novaes Pires Leite and Alvaro Antonio Villa Ochoa and Enrique Lopez Droguett},
  doi          = {10.1016/j.engappai.2023.106067},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106067},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Condition-based maintenance with reinforcement learning for refrigeration systems with selected monitored features},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic commodity price projections for unbiased
techno-economic analyses. <em>EAAI</em>, <em>122</em>, 106065. (<a
href="https://doi.org/10.1016/j.engappai.2023.106065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Techno-economic analysis is a core methodology for assessing the feasibility of new technologies and processes. The outcome of an analysis is largely dictated by the product’s price, as selected by the practitioner. Representative future price distributions are required as inputs to investment, sensitivity, and uncertainty analyses across the 20 to 25 year plant life. However, current price selection procedures are open to subjective judgment, not adequately considered, or neglected by calculating a minimum selling price. This work presents a machine learning methodology to produce unbiased projections of future price distributions for use in a techno-economic analysis. The method uses an ensemble of 100 neural network models with Long Short-Term Memory layers. The models are trained on the Energy Information Administration’s (EIA) long-term crude oil projections and a commodity’s historic price data. The proposed method is demonstrated by projecting the price of five commodity chemicals 26 years into the future using 12 years of historic data. Alongside the economic outlook extracted from the EIA projections, the five commodity price distributions capture stochastic and deterministic elements specific to each commodity. A statistically significant difference was observed when using the price projections to revise the Net Present Value distributions for two previous techno-economic analyses. This suggests that relying on heuristics when selecting price ranges and distributions is unrepresentative of a commodity’s price uncertainty. The novelty of this work is the presentation of an unbiased machine learning approach to project long-term probabilistic prices for techno-economic analyses, emphasising the pitfalls of less rigorous approaches.},
  archive      = {J_EAAI},
  author       = {Sarah Rodgers and Alexander Bowler and Fanran Meng and Stephen Poulston and Jon McKechnie and Alex Conradie},
  doi          = {10.1016/j.engappai.2023.106065},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106065},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic commodity price projections for unbiased techno-economic analyses},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of collaborative decision-making: Bibliometrics,
preliminaries, methodologies, applications and future directions.
<em>EAAI</em>, <em>122</em>, 106064. (<a
href="https://doi.org/10.1016/j.engappai.2023.106064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex and uncertain decision-making environment increasingly requires the collaborations of participants, the exchange and interaction of knowledge of different actors can effectively promote and improve the decision-making process. Collaborative decision-making (CDM), a prevailing decision-making method, is extensively studied by scholars, in which different actors can communicate mutually and then reach a common goal. Hence, in view of the advantages and usefulness of CDM, an overview is conducted for showing the state of the art of CDM, pointing out the current issues and indicating the future research directions. To achieve those goals, firstly, the bibliometric analysis is implemented to briefly review the previous research topics. Then, the definitions, comparisons, weights and consensus concerning CDM are recalled, which are followed by the summarization of methodologies used for solving CDM problems. Subsequently, the current research directions and popular application areas are highlighted. Finally, the challenges and potential research directions are concluded from five perspectives.},
  archive      = {J_EAAI},
  author       = {Yuhang Cai and Feifei Jin and Jinpei Liu and Ligang Zhou and Zhifu Tao},
  doi          = {10.1016/j.engappai.2023.106064},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106064},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A survey of collaborative decision-making: Bibliometrics, preliminaries, methodologies, applications and future directions},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leakage detection in water distribution networks via 1D CNN
deep autoencoder for multivariate SCADA data. <em>EAAI</em>,
<em>122</em>, 106062. (<a
href="https://doi.org/10.1016/j.engappai.2023.106062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leakages are undesirable events in water distribution networks (WDNs) with mostly unknown incident time making it extremely difficult to accurately label leaks in distribution systems. This study proposes a one-dimensional convolutional neural network (1D CNN) deep autoencoder (AE) that is trained in a semi-supervised fashion to detect and localize leaks using multivariate timeseries data in a bid to mitigate the adverse impact of random noise. A leakage identification framework based on Pruned Exact Linear Time (PELT) multiple change point detector and alarm correlation is proposed. Additionally, a novel localization framework is proposed based on the relative percentage deviation of 1D CNN deep AE reconstruction error of pressure sensors in a district metering area (DMA). The leak localization framework outputs a sensor priority list based on the proximity of the pressure sensor to the leaky pipe thereby significantly reducing the search area for a leakage. The proposed leakage identification and localization framework is validated on a benchmark WDN, the L-TOWN. The results indicate the ability of the proposed method to identify 16 of the 19 leaks in 2019 and accurately localize 13 of the 16 identified leaks within the maximum allowable leak search radius of 300 m without recourse to a hydraulic model. Minimal identification lag was recorded for abrupt leakages whiles incipient leaks require longer identification time due to gradual leak growth rate.},
  archive      = {J_EAAI},
  author       = {Hoese Michel Tornyeviadzi and Razak Seidu},
  doi          = {10.1016/j.engappai.2023.106062},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106062},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leakage detection in water distribution networks via 1D CNN deep autoencoder for multivariate SCADA data},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Demand response method considering multiple types of
flexible loads in industrial parks. <em>EAAI</em>, <em>122</em>, 106060.
(<a href="https://doi.org/10.1016/j.engappai.2023.106060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the energy internet, the proportion of flexible loads in smart grid is getting much higher than before. It is highly important to model flexible loads based on demand response. Therefore, a new demand response method considering multiple flexible loads is proposed in this paper to character the integrated demand response (IDR) resources. Firstly, a physical process analytical deduction (PPAD) model is proposed to improve the classification of flexible loads in industrial parks. Scenario generation, data point augmentation, and smooth curves under various operating conditions are considered to enhance the applicability of the model. Secondly, in view of the strong volatility and poor modeling effect of Wasserstein-generative adversarial networks (WGAN), an improved WGAN-gradient penalty (IWGAN-GP) model is developed to get a faster convergence speed than traditional WGAN and generate higher quality samples. Finally, the PPAD and IWGAN-GP models are jointly implemented to reveal the degree of correlation between flexible loads. Meanwhile, an intelligent offline database is built to deal with the impact of nonlinear factors in different response scenarios. Compared with Fourier, SVM, and BP-NET, the root mean square error is reduced by 2.854MW, 3.576MW, and 3.507MW, respectively. The relative error of the amount of unresponsiveness has been reduced significantly by over 25% compared to the traditional methods. Numerical examples have been performed with the results proving that the proposed method is significantly better than the existing technologies in reducing load modeling deviation and improving the responsiveness of park loads.},
  archive      = {J_EAAI},
  author       = {Jia Cui and Mingze Gao and Xiaoming Zhou and Yang Li and Wei Liu and Jiazheng Tian and Ximing Zhang},
  doi          = {10.1016/j.engappai.2023.106060},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106060},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Demand response method considering multiple types of flexible loads in industrial parks},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive knowledge integrated graph neural networks for
chinese medical text classification. <em>EAAI</em>, <em>122</em>,
106057. (<a
href="https://doi.org/10.1016/j.engappai.2023.106057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at medical text classification, where texts describe medicines, diseases, or other medical topics. This field is still challenging since medical texts contain intensive specialization and terminology, which require professional semantic and structured knowledge to classify. Based on our observations, medical knowledge graph (KG) can provide such knowledge although they may be ambiguous. To this end, we propose contrastive knowledge integrated graph neural networks (ConKGNN) to make full use of the above knowledge. Specifically, the proposed method builds two graphs for a medical text, i.e. text graph and text-specific subgraph, containing the text information and relevant KG information, respectively. Two graphs are merged into a united graph, which is jointly modeled by graph neural networks (GNN). In this way, our approach adequately learns interactions between neighbors. Meanwhile, it promotes the mutual influences between text and KG. We further propose graph-based supervised contrastive learning. By randomly cutting off nodes from the text graph, an augmented united graph is obtained. Learning it in a contrastive way could enhance the robustness of introducing KG information. Comprehensive experiments are conducted on five Chinese medical datasets and experimental results show our model outperforms strong baselines remarkably. Consequently, our model can serve as an efficient medical text classifier with excellent performance. We release the code at https://github.com/nolongernome/ConKGNN .},
  archive      = {J_EAAI},
  author       = {Ge Lan and Mengting Hu and Ye Li and Yuzhi Zhang},
  doi          = {10.1016/j.engappai.2023.106057},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106057},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive knowledge integrated graph neural networks for chinese medical text classification},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced incremental deep reinforcement learning based on
variational autoencoder data augmentation for customer credit scoring.
<em>EAAI</em>, <em>122</em>, 106056. (<a
href="https://doi.org/10.1016/j.engappai.2023.106056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental deep reinforcement learning has been successfully applied to different fields in the real-world. However, training deep reinforcement learning models with the data set generated in a certain stage may lead to catastrophic forgetting of trained models, that is, when training models on the new data set, the performance of models will be seriously degraded on the old data set. Therefore, we construct the balanced incremental deep Q-network based on variational autoencoder data augmentation (BIDQN-VADA) model for customer credit scoring. First, the original training set is processed by the random undersampling method to obtain the balanced training set, in which the initial deep Q-network model is trained. Then, the balanced training subset with a fixed number of samples is selected from the original training set, and these samples are augmented by the variational autoencoder data augmentation technology to obtain the balanced augmented training subset. Finally, the balanced training subset and balanced augmented training subset are stored in data stream cache according to the first-in first-out principle for incrementally updating parameters of the deep Q-network model. In order to verify the performance of the model, we conduct a series of experiments on eight real-world customer credit scoring data sets. The experimental results show that the BIDQN-VADA model can achieve the best customer credit scoring performance by combining the balance, incremental and data augmentation process at the same time. More importantly, the performance of the BIDQN-VADA model is significantly better than the other seven classification models.},
  archive      = {J_EAAI},
  author       = {Yadong Wang and Yanlin Jia and Yu Zhong and Jing Huang and Jin Xiao},
  doi          = {10.1016/j.engappai.2023.106056},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106056},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Balanced incremental deep reinforcement learning based on variational autoencoder data augmentation for customer credit scoring},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). T-distributed stochastic neighbor embedding echo state
network with state matrix dimensionality reduction for time series
prediction. <em>EAAI</em>, <em>122</em>, 106055. (<a
href="https://doi.org/10.1016/j.engappai.2023.106055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo state network (ESN), a novel type of recurrent neural network, possesses high nonlinear mapping capability, which is particularly appropriate for time series prediction. However, the huge reservoir may lead to ill-conditioned solutions in the output weight matrix, reducing the generalization ability and prediction performance of the network. To address this issue, a t-distributed stochastic neighbor embedding ESN (TESN) is proposed in this paper to replace the initial large-scale reservoir state matrix with a low-dimensional manifold. By maintaining the local neighbor relationship of the data in the original high-dimensional space, the ill-conditioned dilemma of the output weight matrix is successfully solved. Moreover, the proposed TESN has a strong ability to preserve the global features of the data, which effectively improves the prediction performance of the network. The superiority of the TESN model is demonstrated through two benchmark prediction tasks and a practical application.},
  archive      = {J_EAAI},
  author       = {Jian Huang and Fan Wang and Liang Qiao and Xu Yang},
  doi          = {10.1016/j.engappai.2023.106055},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106055},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {T-distributed stochastic neighbor embedding echo state network with state matrix dimensionality reduction for time series prediction},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling and control of wastewater treatment process with
time delay based on event-triggered recursive least squares.
<em>EAAI</em>, <em>122</em>, 106052. (<a
href="https://doi.org/10.1016/j.engappai.2023.106052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate control of dissolved oxygen (DO) concentration is the key to ensuring the quality of effluent from the wastewater treatment process (WWTP). However, the delay disturbance caused by the hydraulic retention time (HRT) hinders the accurate control of DO concentration. To solve this problem, an event-triggered recursive least squares-based sliding mode control (ETRLS-SMC) is proposed to overcome the obstacles caused by the delay disturbance for accurate control of DO concentration. First, a differential equation with a delay disturbance term is established to describe the dynamic process of the system. Then, the delay disturbance is explicitly depicted to lay the foundation for the controller design considering delay disturbance variables. Second, an RLS identification algorithm is used to online obtain the model parameters of the system. In particular, an event-triggered mechanism is designed to reduce the number of model updates with guaranteed accuracy. Third, combined with the ETRLS identification algorithm, an SMC method is introduced to control the DO concentration with delay disturbance variables. Then, the control law is computed to achieve stable control of the system. Finally, the performance of ETRLS-SMC is verified on the benchmark simulation model 1 (BSM1). The results show that the proposed method can reduce ISE by 0.0014 and 0.0128 when the threshold is 2.5% in two cases, including the reference value being fixed and changed, compared with the case without considering the delay disturbance. The results of trigger mechanism test further demonstrate the effectiveness of event-triggered mechanism.},
  archive      = {J_EAAI},
  author       = {Hong-Gui Han and Shi-Jia Fu and Hao-Yuan Sun and Chen-Hui Qin and Jun-Fei Qiao},
  doi          = {10.1016/j.engappai.2023.106052},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106052},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modeling and control of wastewater treatment process with time delay based on event-triggered recursive least squares},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data-driven physics-constrained deep learning
computational framework for solving von mises plasticity. <em>EAAI</em>,
<em>122</em>, 106049. (<a
href="https://doi.org/10.1016/j.engappai.2023.106049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current work presents an efficient data-driven Physics Informed Neural Networks (PINNs) computational framework for the solution of elastoplastic solid mechanics. To incorporate physical information for the elastoplastic problem, a multi-objective loss function has been carefully designed consisting of the residual of governing partial differential equation (PDE), constitutive relations, flow rules, consistency conditions, and various boundary conditions. In addition, data-driven physical knowledge fitting terms from the high-fidelity Finite Element Method (FEM) solutions for various elastoplastic field variables have been included for the construction of the total loss function. Utilizing multiple densely connected independent ANNs, the model obtains the elastoplastic solution by minimizing the proposed loss function. To demonstrate the strength of the proposed model, two test cases including von Mises perfectly plastic and isotropic linear hardening models are solved under plane-strain condition. Performance in terms of accuracy and robustness illustrates the superiority of the current framework showing excellent agreement with numerical solutions. Furthermore, for better accuracy of field variables with a lesser degree of data-driven estimate and accelerated training, the applicability of transfer learning (TL)-based approach has been illustrated to extend the solution for different sets of boundary conditions and material parameters. The present work highlights an efficient application of the custom-design PINNs model that leverage features from the data-driven solutions to guide the construction of an accurate and robust neural network for the solution of elastoplastic problems.},
  archive      = {J_EAAI},
  author       = {Arunabha M. Roy and Suman Guha},
  doi          = {10.1016/j.engappai.2023.106049},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106049},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven physics-constrained deep learning computational framework for solving von mises plasticity},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Optimization of high-performance concrete mix ratio design
using machine learning. <em>EAAI</em>, <em>122</em>, 106047. (<a
href="https://doi.org/10.1016/j.engappai.2023.106047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-durability concrete is required in extremely cold or ocean environments, making the design of concrete mixes highly important and complicated. In this study, a hybrid intelligent framework for multi-objective optimization based on random forest (RF) and the non-dominated sorting genetic algorithm version II (NSGA-II) is developed to efficiently predict concrete durability and optimize the concrete mix ratio. The relative dynamic elastic modulus of concrete after 300 freeze–thaw cycles and the chloride ion permeability coefficient at 28 days are defined as the standard measures of durability. The concrete mix ratio is taken as the influencing parameter, and orthogonal test data and engineering practice data are collected as the datasets. The proposed framework is applied to a realistic expressway project in a cold region of China. The results demonstrate that (1) a hybrid intelligent framework based on RF-NSGA-II can effectively predict concrete durability and optimize the mix ratio. (2) The developed RF model has an excellent regression learning ability, while the goodness of fit (R2) of concrete durability reaches 0.9503 and 0.9551, respectively, with root mean square error (RMSE) values of only 0.096 and 0.043, the mean absolute percentage error (MAPE) values of 2.54% and 2.17%. (3) After optimization, the concrete durability reaches a high standard, with a frost resistance of &gt;95% and a chloride ion permeability coefficient of &lt;3*10 − 8 cm 2 /s, at a unit volume cost of only 376.77 yuan. Hence, the proposed framework can be used to effectively optimize the concrete mix design and provide guidance for similar projects.},
  archive      = {J_EAAI},
  author       = {Bin Chen and Lei Wang and Zongbao Feng and Yang Liu and Xianguo Wu and Yawei Qin and Lingyu Xia},
  doi          = {10.1016/j.engappai.2023.106047},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106047},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization of high-performance concrete mix ratio design using machine learning},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A kriging model-based evolutionary algorithm with support
vector machine for dynamic multimodal optimization. <em>EAAI</em>,
<em>122</em>, 106039. (<a
href="https://doi.org/10.1016/j.engappai.2023.106039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multimodal optimization problems (DMMOPs) have to search multiple global optimal solutions with the objectives and constraints dynamically changing over time. In recent years, dynamic optimization problems and multimodal optimization problems have been extensively studied in the field of evolutionary computation. However, DMMOPs have not yet been paid significant attention and only a few studies have been designed for dynamic multimodal optimization. The key issue in optimizing DMMOPs is to address the challenges induced by both the multimodal nature and the dynamic nature. Existing works perform poorly in locating all global optima in static environments and tracking global optima with various change modes. Therefore, in this paper, a Kriging Model-based Evolutionary Algorithm with Support Vector Machine called KMEA-SVM is proposed for tackling DMMOPs. Two important operators are designed in this algorithm, including a Kriging-based preselection and a support vector machine (SVM)-based prediction. The aim of Kriging-based preselection is to search all global optimal solutions more efficiently by preselecting promising solutions with a trained Kriging model, while the purpose of SVM-based prediction is to predict more outstanding solutions as the initial population for new environment when the environment changes. The proposed KMEA-SVM is compared with several state-of-the-art evolutionary algorithms on twenty-four test DMMOPs and the experimental results validate the advantages of KMEA-SVM on seeking more multiple optima in dynamic environments.},
  archive      = {J_EAAI},
  author       = {Xunfeng Wu and Qiuzhen Lin and Wu Lin and Yulong Ye and Qingling Zhu and Victor C.M. Leung},
  doi          = {10.1016/j.engappai.2023.106039},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106039},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A kriging model-based evolutionary algorithm with support vector machine for dynamic multimodal optimization},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anomaly detection of train wheels utilizing short-time
fourier transform and unsupervised learning algorithms. <em>EAAI</em>,
<em>122</em>, 106037. (<a
href="https://doi.org/10.1016/j.engappai.2023.106037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection of train wheels helps railway operators to find wheel defects and save cost by enabling condition-based maintenance. Existing approaches focus on applications on freight trains and use supervised data-driven methods which need substantial volume of fault data. This is often unavailable in passenger railways that normally provide reliable services. In this regard, this paper reports an unsupervised data-driven approach for anomaly detection of passenger train wheels. Particularly, short-time Fourier transform (STFT) is used to extract time–frequency features from the vibration signal collected with a pair of fiber Bragg grating (FBG) sensors during normal operating hours. Then, four common unsupervised learning algorithms, namely, non-negative matrix factorization (NMF), one-class support vector machine (OC-SVM), multilayer perceptron autoencoder (MLP-AE), and convolutional neural network autoencoder (CNN-AE), are used to derive five health indexes for monitoring the health condition of the train wheels. The proposed workflow is tested against a dataset complied with respect to the wheel turning record. Our results show that the health indexes obtained from the proposed workflow lead to improved correlation with the condition of train wheels compared with existing health metric. In addition, comparison of the four learning algorithms indicates that NMF and MLP-AE outperformed OC-SVM and CNN-AE.},
  archive      = {J_EAAI},
  author       = {Ting Hei Wan and Chi Wai Tsang and King Hui and Edward Chung},
  doi          = {10.1016/j.engappai.2023.106037},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106037},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Anomaly detection of train wheels utilizing short-time fourier transform and unsupervised learning algorithms},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A comparative study of deep learning and internet of things
for precision agriculture. <em>EAAI</em>, <em>122</em>, 106034. (<a
href="https://doi.org/10.1016/j.engappai.2023.106034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision farming is made possible by rapid advances in deep learning (DL) and the internet of things (IoT) for agriculture, allowing farmers to upgrade their agriculture operations to sustainably fulfill the future food supply. This paper presents a comprehensive overview of recent research contributions in DL and IoT for precision agriculture. This paper surveys the diverse research on DL applications in agriculture, such as detecting pests, disease, yield, weeds, and soil, including fundamental DL techniques. Also, the work describes the IoT architecture and analyzes sensor categorization, agriculture sensors, and unmanned arial vehicles (UAVs) used in recent research. Besides that, data acquisition, annotation, and augmentation for agriculture datasets were covered, and a few widely used datasets were listed. This work also discusses some challenges and issues that DL and IoT face. Furthermore, the research proposed a bootstrapping approach of Transfer learning where fine-tuned VGG16 is fused with optimized and improved newly built fully connected layers for pest detection. The performance of the proposed model is evaluated and compared with other models, such as custom VGG16 as a classifier; fine-tuned VGG16 is optimized with other optimizers like SGD, RMSProp, and Adam. The results show that the proposed model for pest detection outperforms all other models with an accuracy of 96.58 % and a loss of 0.15%. The review and the proposed work presented in this paper will significantly direct researchers toward DL and IoT for intelligent farming.},
  archive      = {J_EAAI},
  author       = {T. Saranya and C. Deisy and S. Sridevi and Kalaiarasi Sonai Muthu Anbananthen},
  doi          = {10.1016/j.engappai.2023.106034},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106034},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comparative study of deep learning and internet of things for precision agriculture},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of machine learning techniques for enhanced energy
efficient 5G and 6G communications. <em>EAAI</em>, <em>122</em>, 106032.
(<a href="https://doi.org/10.1016/j.engappai.2023.106032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular technologies have evolved continuously from the 1st to the 5th generation (5G) to meet the exponentially growing needs of bandwidth, throughput and latency. However, the energy consumption experienced a proportional rise generation-wise when new hardware to support additional applications were incorporated. 5G, which already consumes four times more energy than 4G, is expected to bring about a significant spike in the conventional trajectory of energy consumption. 5G is therefore triggering a major concern for energy efficiency and with an even higher technical and network complexity, 6G will pause an unprecedented challenge to energy efficiency and sustainability. This paper focuses on the energy consumption at the base station and access network levels, which amount to around 80% of energy consumption in mobile networks. Machine learning techniques can be employed in several ways to improve the energy efficiency in these components. In this paper, efficient base station deployment strategies and adaptive operational modes as well as access network technologies such as massive MIMO and millimeter waves, which employ machine learning to enhance the energy efficiency, have been reviewed in depth. Since existing research works have focused mostly on a single optimization strategy at either the base station or access network level, this paper proposes a framework, which combines efficient base station deployment methods and machine learning-based switching between different operation modes based on traffic load. Moreover, an adaptive beamforming methodology through identification of hotspots and user association, sub-channel and power allocation in heterogeneous networks is discussed in detail.},
  archive      = {J_EAAI},
  author       = {Tulsi Pawan Fowdur and Bhuvaneshwar Doorgakant},
  doi          = {10.1016/j.engappai.2023.106032},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106032},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of machine learning techniques for enhanced energy efficient 5G and 6G communications},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ML-based vehicle downtime reduction: A case of air
compressor failure detection. <em>EAAI</em>, <em>122</em>, 106031. (<a
href="https://doi.org/10.1016/j.engappai.2023.106031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the critical issue of reducing the downtime of vehicles by using machine learning (ML) techniques and full life cycle data. The study tests the failure prediction of one major automotive system, air compressors in long-distance trucks. To validate the learning capabilities of ML models, three different algorithms such as C5.0, C5.0 with boosting and classification and regression tree (CART) are used. The findings suggest that the C5.0 model with boosting provides a better prediction of air compressor failure than other decision trees such as CART and C5.0. The diagnostic trouble codes (DTCs) and the vehicle operational variables are important indicators of the air compressor failure whereas the vehicle configuration data are not meaningful. A hybrid model which includes both DTCs and vehicle operational data is able to generate superior prediction results.},
  archive      = {J_EAAI},
  author       = {Chakradhara Panda and Tilak Raj Singh},
  doi          = {10.1016/j.engappai.2023.106031},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106031},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ML-based vehicle downtime reduction: A case of air compressor failure detection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel deep learning-based approach for malware detection.
<em>EAAI</em>, <em>122</em>, 106030. (<a
href="https://doi.org/10.1016/j.engappai.2023.106030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware detection approaches can be classified into two classes, including static analysis and dynamic analysis. Conventional approaches of the two classes have their respective advantages and disadvantages. For example, static analysis is faster but cannot detect the malware variants generated through code obfuscation, whereas dynamic analysis can effectively detect variants generated through code obfuscation but is slower and requires intensive resources. This paper proposes a novel deep learning-based approach for malware detection. It delivers better performance than conventional approaches by combining static and dynamic analysis advantages. First, it visualises a portable executable (PE) file as a coloured image. Second, it extracts deep features from the colour image using fine-tuned deep learning model. Third, it detects malware based on the deep features using support vector machines (SVM). The proposed method combines deep learning with machine learning and eliminates the need for intensive feature engineering tasks and domain knowledge. The proposed approach is scalable, cost-effective, and efficient. The detection effectiveness of the proposed method is validated through 12 machine learning models and 15 deep learning models. The generalisability of the proposed framework is validated on various benchmark datasets. The proposed approach outperformed with an accuracy of 99.06% on the Malimg dataset. The Wilcoxon signed-rank test is used to show the statistical significance of the proposed framework. The detailed experimental results demonstrate the superiority of the proposed method over the other state-of-the-art approaches, with an average increase in accuracy of 16.56%. Finally, to tackle the problems of imbalanced data and the shortage of publicly available datasets for malware detection, various data augmentation techniques are proposed, which lead to improved performance. It is evident from the results that the proposed framework can be useful to the defence industry, which will be helpful in devising more efficient malware detection solutions.},
  archive      = {J_EAAI},
  author       = {Kamran Shaukat and Suhuai Luo and Vijay Varadharajan},
  doi          = {10.1016/j.engappai.2023.106030},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106030},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep learning-based approach for malware detection},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time measurement-driven reinforcement learning control
approach for uncertain nonlinear systems. <em>EAAI</em>, <em>122</em>,
106029. (<a
href="https://doi.org/10.1016/j.engappai.2023.106029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces an interactive machine learning mechanism to process the measurements of an uncertain, nonlinear dynamic process and hence advise an actuation strategy in real-time. For concept demonstration, a trajectory-following optimization problem of a Kinova robotic arm is solved using an integral reinforcement learning approach with guaranteed stability for slowly varying dynamics. The solution is implemented using a model-free value iteration process to solve the integral temporal difference equations of the problem. The performance of the proposed technique is benchmarked against that of another model-free high-order approach and is validated for dynamic payload and disturbances. Unlike its benchmark, the proposed adaptive strategy is capable of handling extreme process variations. This is experimentally demonstrated by introducing static and time-varying payloads close to the rated maximum payload capacity of the manipulator arm. The comparison algorithm exhibited up to a seven-fold percent overshoot compared to the proposed integral reinforcement learning solution. The robustness of the algorithm is further validated by disturbing the real-time adapted strategy gains with a white noise of a standard deviation as high as 5%.},
  archive      = {J_EAAI},
  author       = {Mohamed Abouheaf and Derek Boase and Wail Gueaieb and Davide Spinello and Salah Al-Sharhan},
  doi          = {10.1016/j.engappai.2023.106029},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106029},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time measurement-driven reinforcement learning control approach for uncertain nonlinear systems},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information measures based on similarity under neutrosophic
fuzzy environment and multi-criteria decision problems. <em>EAAI</em>,
<em>122</em>, 106026. (<a
href="https://doi.org/10.1016/j.engappai.2023.106026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neutrosophic fuzzy set (NF-set) is a unique hybrid structure that combines the essence of the fuzzy and neutrosophic sets. It is an effective mathematical tool for dealing with indeterminate and inconsistent information in situations where the data are imprecise or vague. This paper defines the concepts of similarity-based information measures, including entropy and cross-entropy, between NF-sets. It is the first time these concepts have been introduced since the NF-sets were defined. We provide their interesting properties through well-proven theorems. In addition, we also propose a novel and efficient algorithm to make multi-criteria decision(s) using these information measures with a clear step-by-step illustration. It overcomes the limitations of the original algorithm when evaluating the criteria in two aspects: qualitative and quantitative. A real-world experiment is then conducted to assist students in choosing the optimal subject group(s) for the Vietnamese national high school graduation examination. Experimental results show that our method outperforms the previous original method when giving recommendations with sixteen correct cases, three acceptable cases, and one noisy case out of twenty real-life cases. Finally, the experimental results are presented visually, analyzed rigorously, and discussed carefully, intending to verify the validity and feasibility of the proposed algorithm. The Python source code for experiments is publicly available on Github.},
  archive      = {J_EAAI},
  author       = {Quang-Thinh Bui and My-Phuong Ngo and Vaclav Snasel and Witold Pedrycz and Bay Vo},
  doi          = {10.1016/j.engappai.2023.106026},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106026},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Information measures based on similarity under neutrosophic fuzzy environment and multi-criteria decision problems},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactual-based minority oversampling for imbalanced
classification. <em>EAAI</em>, <em>122</em>, 106024. (<a
href="https://doi.org/10.1016/j.engappai.2023.106024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge of oversampling in imbalanced classification is that the generation of new minority samples often neglects the usage of majority classes, resulting in most new minority sampling spreading the whole minority space. In view of this, we present a new oversampling framework based on the counterfactual theory. Our framework introduces a counterfactual objective by leveraging the rich inherent information of majority classes and explicitly perturbing majority samples to generate new samples in the territory of minority space. It can be analytically shown that the new minority samples satisfy the minimum inversion. Therefore, most of them are located near the decision boundary. The empirical evaluation of the six benchmark datasets shows that our approach clearly outperforms the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Shu Wang and Hao Luo and Shanshan Huang and Qingsong Li and Li Liu and Guoxin Su and Ming Liu},
  doi          = {10.1016/j.engappai.2023.106024},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106024},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Counterfactual-based minority oversampling for imbalanced classification},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A sub-region unet for weak defects segmentation with global
information and mask-aware loss. <em>EAAI</em>, <em>122</em>, 106011.
(<a href="https://doi.org/10.1016/j.engappai.2023.106011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, diverse detection methods have been proposed to achieve highly accurate image segmentation. However, low contrast and background noise interference still pose challenges to defect detection. Existing deep learning-based methods for defect detection mostly learn rich features on the whole image. This can lead to overfitting as the parameters get bigger, and it also loses the spatial connection. In order to solve this problem, we suggest a network based on spatial sub-region feature extraction and mask-aware loss that can detect metal surface defects. In this network framework, we obtain the contextual information of each region through two streams: one branch encodes the spatial sub-region information and reduces the effect of geometric and illumination deformation under u-shape architecture. A skip-connected structure in another stream is designed to learn global information and compensate for boundary features. Next, we propose a mask-aware loss to reduce background noise interference further. Finally, we validate the effectiveness of our method on two challenging datasets, reaching 88.45% and 79.16% on the NEU-Seg and USB-Seg datasets, respectively. Also, our model is only 5.48 MB, and can achieve 172 fps for processing images with 200 × 200 size defects.},
  archive      = {J_EAAI},
  author       = {Wenbin Zhu and Rui Liang and Jiangxin Yang and Yanlong Cao and Guizhong Fu and Yanpeng Cao},
  doi          = {10.1016/j.engappai.2023.106011},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106011},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A sub-region unet for weak defects segmentation with global information and mask-aware loss},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). International roughness index prediction for flexible
pavements using novel machine learning techniques. <em>EAAI</em>,
<em>122</em>, 106007. (<a
href="https://doi.org/10.1016/j.engappai.2023.106007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {International Roughness Index (IRI) is an important pavement performance indicator that is widely used to reflect existing pavement condition and ride quality. Due to the importance of this significant index, the current research aims to develop a precise IRI prediction model using the Gaussian Process Regression (GPR) and Locally Weighted Polynomials (LWP). The long-term pavement performance (LTPP) datasets of pavement age, initial IRI, alligator, longitudinal and transverse cracks, standard deviation of rutting, and subgrade plasticity index variables are employed in predicting IRI. These datasets are collected from 126 different flexible pavement sections of the LTPP specific pavement studies (SPS-1) located in different climatic zones in the US. The total number of IRI measurements in the collected database is 925 which covers a wide range of IRI values. Multiple linear regression (MLR) is firstly applied to classify the input variables. Then the MLR model is compared with four machine learning techniques which are GPR, LWP, Particle Swarm Optimization-Adaptive Network based Fuzzy Inference System (PSO-ANFIS) and PSO-Artificial Neural Networks (PSO-ANN). The developed models’ performance is validated using different statistical indices, including the coefficient of determination ( R 2 ). The results demonstrate that the GPR ( R 2 = 0 . 93 ) and LWP ( R 2 = 0 . 90 ) outperformed the PSO-ANFIS ( R 2 = 0 . 65 ) and PSO-ANN ( R 2 = 0 . 52 ) in predicting IRI. Thus, the GPR model is found to be more accurate for IRI modeling compared to the hybrid investigated models.},
  archive      = {J_EAAI},
  author       = {Mosbeh R. Kaloop and Sherif M. El-Badawy and Jong Wan Hu and Ragaa T. Abd El-Hakim},
  doi          = {10.1016/j.engappai.2023.106007},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106007},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {International roughness index prediction for flexible pavements using novel machine learning techniques},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Natural gas consumption forecasting using an optimized grey
bernoulli model: The case of the world’s top three natural gas
consumers. <em>EAAI</em>, <em>122</em>, 106005. (<a
href="https://doi.org/10.1016/j.engappai.2023.106005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate and reasonable prediction of natural gas consumption is important for enhancing national energy security and alleviating the environmental problems caused by energy consumption. Starting with the traditional nonlinear grey Bernoulli model, in this paper, we expand the development coefficient a and grey action quantity b, propose a new self-adaptive time-varying grey Bernoulli prediction model, deduce the time response formula of the model, and explore the relationship between model parameters and model accuracy. Then, the nonlinear parameter and power parameter coefficient of the new model are optimized by a genetic algorithm, and the effectiveness of the model is analyzed by the natural gas consumption of China, the United States, and Russia. The results show that, compared with other traditional grey prediction models, the new model has a better simulation effect, higher prediction accuracy, and stronger applicability. Meanwhile, the model was used to forecast the natural gas consumption of China, the United States, and Russia in the period from 2022 to 2026. The prediction results show that China’s natural gas consumption will continue to steadily increase in the future, which is consistent with the global goal of adhering to the orderly development of natural gas. The prediction results can provide a theoretical basis for relevant departments to formulate relevant natural gas policies.},
  archive      = {J_EAAI},
  author       = {Mingyu Tong and Fuli Qin and Jingrong Dong},
  doi          = {10.1016/j.engappai.2023.106005},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {106005},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Natural gas consumption forecasting using an optimized grey bernoulli model: The case of the world’s top three natural gas consumers},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward complete coverage planning using deep reinforcement
learning by trapezoid-based transformable robot. <em>EAAI</em>,
<em>122</em>, 105999. (<a
href="https://doi.org/10.1016/j.engappai.2023.105999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape-shifting robots are the feasible solutions to solve the Complete Coverage Planning (CCP) problem. These robots can extend the covered areas by reconfiguring their shape to different forms according to space conditions. Since energy usage while navigating is constrained by the number of shape-shifting, it is desirable to cover the confined areas by trajectory using minimal robot actions within finite states. This paper presents a CCP method using deep reinforcement learning (DRL) for a reconfigurable robot with a trapezoid shape called Transbot. The framework derives optimal action policy for robot trajectory within the grid-based workspace. DRL model relies on Convolutional Neural Networks (CNNs) with Long Short Temporary Memory (LSTM) layers using Actor-Critic with Experience Replay (ACER) as the decision layers. The trained DRL model simultaneously generates robot shapes and directions with optimal energy cost by maximizing the cumulative reward representing the Transbot actions. By creating the trajectory with less 28.95% energy and 19.42% time in tested simulation and real-world experiments, the proposed CCP framework outperforms the existing tiling-based heuristic optimization techniques.},
  archive      = {J_EAAI},
  author       = {Dinh Tung Vo and Anh Vu Le and Tri Duc Ta and Minh Tran and Phan Van Duc and Minh Bui Vu and Nguyen Huu Khanh Nhan},
  doi          = {10.1016/j.engappai.2023.105999},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {105999},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward complete coverage planning using deep reinforcement learning by trapezoid-based transformable robot},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A geometry-aware deep network for depth estimation in
monocular endoscopy. <em>EAAI</em>, <em>122</em>, 105989. (<a
href="https://doi.org/10.1016/j.engappai.2023.105989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular depth estimation is critical for endoscopists to perform spatial perception and 3D navigation of surgical sites. However, most of the existing methods ignore the important geometric structural consistency, which inevitably leads to performance degradation and distortion of 3D reconstruction. To address this issue, we introduce a gradient loss to penalize edge fluctuations ambiguous around stepped edge structures and a normal loss to explicitly express the sensitivity to frequently small structures, and propose a geometric consistency loss to spreads the spatial information across the sample grids to constrain the global geometric anatomy structures. In addition, we develop a synthetic RGB-Depth dataset that captures the anatomical structures under reflections and illumination variations. The proposed method is extensively validated across different datasets and clinical images and achieves mean RMSE values of 0.066 (stomach), 0.029 (small intestine), and 0.139 (colon) on the EndoSLAM dataset. The generalizability of the proposed method achieves mean RMSE values of 12.604 (T1-L1), 9.930 (T2-L2), and 13.893 (T3-L3) on the ColonDepth dataset. The experimental results show that our method exceeds previous state-of-the-art competitors and generates more consistent depth maps and reasonable anatomical structures. The quality of intraoperative 3D structure perception from endoscopic videos of the proposed method meets the accuracy requirements of video-CT registration algorithms for endoscopic navigation. The dataset and the source code will be available at https://github.com/YYM-SIA/LINGMI-MR .},
  archive      = {J_EAAI},
  author       = {Yongming Yang and Shuwei Shao and Tao Yang and Peng Wang and Zhuo Yang and Chengdong Wu and Hao Liu},
  doi          = {10.1016/j.engappai.2023.105989},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {105989},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A geometry-aware deep network for depth estimation in monocular endoscopy},
  volume       = {122},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). MIANet: Multi-level temporal information aggregation in
mixed-periodicity time series forecasting tasks. <em>EAAI</em>,
<em>121</em>, 106175. (<a
href="https://doi.org/10.1016/j.engappai.2023.106175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular human activities generate a large number of time series with mixed periodicity that can reflect human behavior patterns and the societal working mechanism. When forecasting these time series, nonlinear neural networks often encounter some limitations, such as utilizing mixed-periodic patterns, balancing multi-level information, incorporating future vision, forecasting delays and scale insensitivity, which affect the forecasting accuracy. To address these problems, we propose the Multi-level Information Aggregation Network (MIANet), a novel neural network with four key characteristics: (i) a novel folded recurrent structure that dynamically updates the local and mini-local information at a global range in a compact manner; (ii) a new recurrent unit called Folded Convolution Aggregation Temporal Memory (FCATM) that extracts and aggregates neighbor-trends in local and mini-local data; (iii) a fusing decoder structure that promotes the sharing of forward–backward future information and adaptively adjusts relationships among adjacent points; and (iv) a new Skip-Autoregressive (SAR) linear strategy that addresses scale sensitivity issues. The SAR can be embedded as a plug-and-play component into other deep learning (DL) models. Compared with other baseline methods, MIANet obtains statistically significant improvements on six real-world datasets, as demonstrated by conducting two-sample t-tests, indicating that the MIANet can be applied to various predictive scenarios, such as road occupancy, electricity consumption, pedestrian flow and urban noise.},
  archive      = {J_EAAI},
  author       = {Sheng Wang and Xi Chen and Dongliang Ma and Chen Wang and Yong Wang and Honggang Qi and Gongjian Zhou and Qingli Li and Min Liu},
  doi          = {10.1016/j.engappai.2023.106175},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106175},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MIANet: Multi-level temporal information aggregation in mixed-periodicity time series forecasting tasks},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Two-rank multi-attribute group decision-making with
linguistic distribution assessments: An optimization-based integrated
approach. <em>EAAI</em>, <em>121</em>, 106170. (<a
href="https://doi.org/10.1016/j.engappai.2023.106170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real life, two-rank multi-attribute decision-making (MADM), in which all alternatives are divided into two preference-ordered categories, is common. In this paper, we investigate two-rank multi-attribute group decision-making (MAGDM) with linguistic distribution assessments (LDAs). A challenge when tackling such two-rank problems is establishing an LDAs-based two-rank model that maintains a balance between classification accuracy and computational complexity. When neither the threshold nor the number of alternatives within each category is specified in advance, determining individual two-rank results and subsequently aggregating the two-rank results for each decision-maker to resolve conflicts within the group is another challenge. Given these, we aim to propose a novel approach for two-rank MAGDM with LDAs. The main innovations and contributions of this paper are as follows. (a) From the perspective of linguistic scale function (LSF)-based cumulative expectations, we present a new LDAs-based distance measure that exhibits several desirable properties. A new score function for comparing LDAs is subsequently proposed using the new distance and the idea of the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS). (b) Using the minimum intensity of reversed rankings combined with the misclassification ratio of alternatives as an integrated objective function, we construct two 0-1 integer programming models incorporating constraints associated with the centers and priorities of categories to determine the optimal individual and group two-rank results of alternatives, respectively. (c) We apply our method to two-rank MAGDM associated with short video placement platforms. Comparing the proposed approach with other two-rank MAGDM approaches further demonstrates its effectiveness and rationality.},
  archive      = {J_EAAI},
  author       = {Shitao Zhang and Lei Hu and Zhenzhen Ma and Xiaodi Liu},
  doi          = {10.1016/j.engappai.2023.106170},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106170},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-rank multi-attribute group decision-making with linguistic distribution assessments: An optimization-based integrated approach},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a muscle electrical stimulation parameter
selection method with an intelligent system. <em>EAAI</em>,
<em>121</em>, 106167. (<a
href="https://doi.org/10.1016/j.engappai.2023.106167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a methodology for the selection of electrical stimulation parameters for muscle rehabilitation. This methodology uses a particle swarm optimizer to find a set of parameters that maximizes the muscle contraction force during the stimulation session. The optimization makes use of a previously validated mathematical muscle contraction model. To adjust the model to this application, we propose a series of adaptations to the model, such as the inclusion of a muscle fatigue function and different levels of muscle atrophy representations thru parametric variation. We based our model adaptations on the results of parametric sensitivity analysis and the qualitative changes in muscle properties during atrophy and fatigue described in the current literature. With the fatigue function, we successfully recreated the qualitative behavior reported in the literature for muscle fatigue caused by electrical stimulation. The parametric variations proposed following the sensitivity analysis are consistent with the physiological changes occurring during muscle atrophy, and the simulations with the model supported our hypothesis. Finally, we showed that with the model and the particle swarm optimizer, it is possible to find a set of electrical stimulation parameters that maximize the muscle contraction force during the stimulation session.},
  archive      = {J_EAAI},
  author       = {Rogelio García-Aguirre and Luis Torres-Treviño and Griselda Quiroz-Compeán and Angel Rodríguez-Liñan},
  doi          = {10.1016/j.engappai.2023.106167},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106167},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of a muscle electrical stimulation parameter selection method with an intelligent system},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clustering ensemble-based novelty score for outlier
detection. <em>EAAI</em>, <em>121</em>, 106164. (<a
href="https://doi.org/10.1016/j.engappai.2023.106164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, One-class classification algorithms have been successfully used for outlier detection problems in several industrial fields. However, in case of that the target class has complex structures, single outlier detection model with one-class classifier often poorly performs because it cannot appropriately reflect intrinsic data structures. To address this limitation, we propose a clustering ensemble-based novelty score algorithm. The proposed algorithm calculates novelty score from the mixture of multiple clustering solutions generated by both random subspace and random- K ensemble approaches. Then, final ensemble novelty score is defined by summarizing multiple novelty scores obtained from individual clustering results. Because these multiple novelty scores are computed from many possible characteristics of target class information, the proposed ensemble novelty score can appropriately reflect the inherent structures of target class. Experiments were conducted on various benchmark datasets to compared with existing methods and investigate the properties of the proposed algorithm. The experimental results confirm that the proposed algorithm outperforms existing one-class classification methods in various cases.},
  archive      = {J_EAAI},
  author       = {Jaehong Yu and Jihoon Kang},
  doi          = {10.1016/j.engappai.2023.106164},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106164},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clustering ensemble-based novelty score for outlier detection},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of feature extraction method based on
interval-valued pythagorean fuzzy decision theory. <em>EAAI</em>,
<em>121</em>, 106084. (<a
href="https://doi.org/10.1016/j.engappai.2023.106084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction is an important step in image processing and the accuracy of the extraction affects the result of subsequent target detection. There are many feature extraction algorithms, but there are few theories and methods about the accuracy of the extraction. Moreover, most of the existing extraction methods are computationally complex, and they will expose deficiencies once they encounter a large number of standard cases. In order to fill this gap, this study proposes a new soft computing multi-criteria group decision-making (MCGDM) method based on interval-valued Pythagorean fuzzy set information to deal with situations where multiple criteria are involved in complex decisions. Thus, the power average operator is used to eliminate the effects of unreasonable input arguments on decision-making results, and the Maclaurin symmetric mean operator is used to comprehensively consider the mutual relationship between input arguments in this article. Combining with the concept of IVPFS, the interval-valued Pythagorean fuzzy power Maclaurin symmetric mean (IVPFPMSM) operator and weighted IVPFPMSM operator are proposed. Then, the TOPSIS method is used to determine the weight vector of decision-making set, and a MCGDM method is developed under the interval-valued Pythagorean fuzzy framework. Next, aiming at the defects of the existing evaluation criteria, we consider the different ranges of membership degree and non-membership degree to propose a new evaluation criterion of MCGDM method. Finally, the proposed method is applied to the optimal selection of characteristic interval of foreign fibers to verify its practicability and effectiveness. The proposed method has certain guiding significance for the extension of decision-making fuzzy operators and the exploration of feature extraction methods.},
  archive      = {J_EAAI},
  author       = {Weijia Ren and Yuhong Du and Ronglu Sun and Yuqin Du},
  doi          = {10.1016/j.engappai.2023.106084},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106084},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of feature extraction method based on interval-valued pythagorean fuzzy decision theory},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extraction of vascular wall in carotid ultrasound via a
novel boundary-delineation network. <em>EAAI</em>, <em>121</em>, 106069.
(<a href="https://doi.org/10.1016/j.engappai.2023.106069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound imaging plays an essential role in the diagnosis of vascular lesions. Accurate segmentation of the vascular wall is important for preventing, diagnosing, and treating vascular diseases. However, existing methods have inaccurate localization of the vascular wall boundary. Segmentation errors occur in discontinuous vascular wall boundaries and dark boundaries. To overcome these problems, we propose a new boundary-delineation network (BDNet). First, we design the feature extraction module to prevent the feature information loss of low-quality images by multi-scale information fusion and multi-receptive field feature fusion. Secondly, we generate the initial coarse prediction results based on the extracted features. Based on the coarse prediction results, we use the boundary refinement module to obtain the boundary point locations and re-delineate the boundary points to prevent the boundary points from the offset. Finally, we use region mutual information loss and our designed global pixel relationship loss to model the relationship between pixels from global and neighbourhood aspects using the structural features of the vessel wall to help the model extract important structured information. To facilitate clinical applications, we design the model to be lightweight. Experimental results show that our model achieves the best segmentation results and significantly reduces memory consumption compared to existing models.},
  archive      = {J_EAAI},
  author       = {Qinghua Huang and Lizhi Jia and Guanqing Ren and Xiaoyi Wang and Chunying Liu},
  doi          = {10.1016/j.engappai.2023.106069},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106069},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Extraction of vascular wall in carotid ultrasound via a novel boundary-delineation network},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). B-SMART: A reference architecture for artificially
intelligent autonomic smart buildings. <em>EAAI</em>, <em>121</em>,
106063. (<a
href="https://doi.org/10.1016/j.engappai.2023.106063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasive application of artificial intelligence and machine learning algorithms is transforming many industries and aspects of the human experience. One very important industry trend is the move to convert existing human dwellings to smart buildings, and to create new smart buildings. Smart buildings aim to mitigate climate change by reducing energy consumption and associated carbon emissions. To accomplish this, they leverage artificial intelligence, big data, and machine learning algorithms to learn and optimize system performance. These fields of research are currently very rapidly evolving and advancing, but there has been very little guidance to help engineers and architects working on smart buildings apply artificial intelligence algorithms and technologies in a systematic and effective manner. In this paper we present B-SMART: the first reference architecture for autonomic smart buildings. B-SMART facilitates the application of artificial intelligence techniques and technologies to smart buildings by decoupling conceptually distinct layers of functionality and organizing them into an autonomic control loop. We also present a case study illustrating how B-SMART can be applied to accelerate the introduction of artificial intelligence into an existing smart building.},
  archive      = {J_EAAI},
  author       = {Mikhail Genkin and J.J. McArthur},
  doi          = {10.1016/j.engappai.2023.106063},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106063},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {B-SMART: A reference architecture for artificially intelligent autonomic smart buildings},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rank based iterative clustering (RBIC) for indoor
localization. <em>EAAI</em>, <em>121</em>, 106061. (<a
href="https://doi.org/10.1016/j.engappai.2023.106061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era, technological advancements have resulted in a spike in various sensor data-intensive applications including indoor localization services. WiFi fingerprint-based localization for large indoor areas is primarily contingent on laborious site surveys. To ease the flow of research, grossly labeled data collected using a crowd-sourced method could be clustered. However, for a real-time localization approach, the challenge is to generate the clusters containing data samples that are really physically close. In this paper, a two-phase semi-supervised localization approach has been proposed, which is general enough to be applied to indoor localization datasets. In the offline phase, a Rank-Based Iterative Clustering (RBIC) algorithm has been proposed that generates a clustered dataset with a negligible chance of containing physically apart location points within a common cluster. RBIC can be viewed as a clustering ensemble model. Different clustering algorithms are selected as baseline algorithms and assigned unique ranks depending on well-known clustering scores to be fed as input to RBIC. In the online phase, the users’ location is estimated using machine learning (ML) classifiers based on the dynamic received signal strength indicator (RSSI) vector received through its handheld device transceiver. The system is evaluated with three benchmark datasets for WiFi based indoor localization. For the first dataset, JUIndoorLoc, 94% to 99% localization accuracy is achieved for individual supervised classifiers. For the second and third datasets, the ranges of obtained localization accuracies are 96% to 99% and 95% to 98% respectively.},
  archive      = {J_EAAI},
  author       = {Manjarini Mallik and Sanchita Das and Chandreyee Chowdhury},
  doi          = {10.1016/j.engappai.2023.106061},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106061},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rank based iterative clustering (RBIC) for indoor localization},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semantic robotic grasping framework based on multi-task
learning in stacking scenes. <em>EAAI</em>, <em>121</em>, 106059. (<a
href="https://doi.org/10.1016/j.engappai.2023.106059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robotic grasping is an essential skill for service robots to perform specified tasks in unstructured scenarios. Previous work focus on simple pick-and-place tasks, and it is not satisfactory for real-world scenes that have requirements for manipulation. In this paper, we present a modular intelligent robot architecture via multi-task convolutional neural network which can be used for specific object grasping and manipulation in a stacked and cluttered environment. Firstly, an end-to-end, multi-task semantic grasping convolutional neural network (MSG-ConvNet) that simultaneously outputs the results of grasp detection and semantic segmentation is proposed to recognize the affiliations between objects and grasps in cluttered scenarios. Secondly, we propose a post-processing method which allows the robot to select an optimal grasping area in an active perception way through simply reasoning on the multi-modal information output by the proposed model. The proposed multi-task network has a great improvement in both recognition accuracy and detection speed on the public multi-object dataset GraspNet-1Billion compared with the benchmark. The proposed grasp detection method also yields state-of-the-art performance with accuracies of 95.06% and 98.6% on the public single-object Jacquard Dataset and Cornell Dataset, respectively. In addition, the experiments in a real-world scene demonstrate that our proposed method has stronger robustness and adaptability than the simple direct grasping strategy in the environment with higher mutual occlusion.},
  archive      = {J_EAAI},
  author       = {Shengqi Duan and Guohui Tian and Zhongli Wang and Shaopeng Liu and Chenrui Feng},
  doi          = {10.1016/j.engappai.2023.106059},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106059},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A semantic robotic grasping framework based on multi-task learning in stacking scenes},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum hybrid algorithm for solving SAT problem.
<em>EAAI</em>, <em>121</em>, 106058. (<a
href="https://doi.org/10.1016/j.engappai.2023.106058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial problems usually have a large search space, and almost all classical algorithms for solving this class of problems are inefficient for real-life input sizes. Quantum algorithms have been introduced with the aim of reducing computational time. In addition, to speed up the computation while solving combinatorial problems, another approach is to reduce the search space and focus on a restricted area. In this work, we study a parameter that helps reduce the search space for the solution to the satisfiability problem (SAT). We propose an approach based on Grover’s algorithm that considers the defined parameter to reduce the search space for the solution of the SAT problem. Our algorithm has a complexity of the order O ( N / S ) , or O ( N / l S ) if there are l good solutions among the initial solutions, with N the number of potential solutions and S the reduction or subdivision factor of the space.},
  archive      = {J_EAAI},
  author       = {Charles Moudina Varmantchaonala and Jean Louis Kedieng Ebongue Fendji and Jean Pierre Tchapet Njafa and Marcellin Atemkeng},
  doi          = {10.1016/j.engappai.2023.106058},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106058},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantum hybrid algorithm for solving SAT problem},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gaussian processes and fast marching square based
informative path planning. <em>EAAI</em>, <em>121</em>, 106054. (<a
href="https://doi.org/10.1016/j.engappai.2023.106054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploration of unknown environments is a challenge in robotics. The proposed method approaches this problem by combining the Fast Marching Square path planning technique with the machine learning method called Gaussian processes (GP). The Fast Marching Square method is used to determine the most unexplored areas of the environment and to plan the path of the vehicle from the current position to the selected point. The GP model is used to obtain predictions about the unexplored regions of the environment based on the collected data so far during the exploration. The use of Unmanned Aerial Vehicles (UAVs) for exploration and surveillance has increased exponentially in the recent years, due to their sensor equipment capabilities and their versatility for flying over difficult terrain. By defining the weight each method has on the selection of the next point to explore, we can focus the UAV on the points with more interesting data defined by the user ( i.e. bodies of water), the most unexplored regions, or a combination of both. We present an study on the influence of these weights on the mean absolute error (MAE) and predictive variance obtained from the GP model and test the algorithm on a real environment obtained from a satellite image. We show that we are able to generate an accurate depiction of the environment way faster than traditional methods such as the Boustrophedon.},
  archive      = {J_EAAI},
  author       = {Javier Muñoz and Blanca López and Fernando Quevedo and Santiago Garrido and Concepción A. Monje and Luis E. Moreno},
  doi          = {10.1016/j.engappai.2023.106054},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106054},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gaussian processes and fast marching square based informative path planning},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized predictive control using improved recurrent
fuzzy neural network for a boiler-turbine unit. <em>EAAI</em>,
<em>121</em>, 106053. (<a
href="https://doi.org/10.1016/j.engappai.2023.106053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultra supercritical (USC) for the boiler-turbine unit has become an advanced power generation technology due to its high combustion efficiency and low-carbon emission. Considering the complex nonlinearity and uncertainty in USC boiler-turbine units, a novel recurrent fuzzy neural network (RFNN) is produced to model dynamic responses of nonlinear systems and improve the control performance of the outputs in the boiler-turbine unit. However, the number of fuzzy rules in previous networks is mostly predefined with experts’ experience, which contributes to the decline in the generalization and efficiency of system modeling. This challenge is tackled in this paper by a subtractive clustering (SC) algorithm, which can determine the optimal number of fuzzy sets in the proposed RFNN. Additionally, aiming at minimizing the tracking errors of the outputs in the boiler-turbine unit, a global generalized predictive control (GPC) strategy is further designed to control the fuel flow, the feedwater flow, and the steam governor valve in the boiler-turbine unit. With the real-time data generated in a 1000MW USC boiler-turbine unit, the proposed SC-RFNN-based GPC can achieve a testing root mean-square-error (RMSE) of 0.0411 as well as the lower integral absolute error (IAE) values of system outputs.},
  archive      = {J_EAAI},
  author       = {Min Zhao and Jin Wan and Chen Peng},
  doi          = {10.1016/j.engappai.2023.106053},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106053},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generalized predictive control using improved recurrent fuzzy neural network for a boiler-turbine unit},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AnoFed: Adaptive anomaly detection for digital health using
transformer-based federated learning and support vector data
description. <em>EAAI</em>, <em>121</em>, 106051. (<a
href="https://doi.org/10.1016/j.engappai.2023.106051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In digital healthcare applications, anomaly detection is an important task to be taken into account. For instance, in ECG (Electrocardiogram) analysis, the aim is often to detect abnormal ECG signals that are considered outliers. For such tasks, it has been shown that deep learning models such as Autoencoders (AEs) and Variational Autoencoders (VAEs) can provide state-of-the-art performance. However, they suffer from certain limitations. For example, the trivial method of threshold selection does not perform well if we do not know the reconstruction loss distribution in advance. In addition, since healthcare applications rely on highly sensitive personal information, data privacy concerns can arise when data are collected and processed in a centralized machine-learning setting. Hence, in order to address these challenges, in this paper, we propose AnoFed, a novel framework for combining the transformer-based AE and VAE with the Support Vector Data Description (SVDD) in a federated setting. It can enhance privacy protection, improve the explainability of results and support adaptive anomaly detection. Using ECG anomaly detection as a typical application of the framework in healthcare, we conducted experiments to show that the proposed framework is not only effective (in terms of the detection performance) but also efficient (in terms of computational costs), compared with a number of state-of-the-art methods in the literature. AnoFed is very lightweight in terms of the number of parameters and computation, hence it can be used in applications with resource-constrained edge devices.},
  archive      = {J_EAAI},
  author       = {Ali Raza and Kim Phuc Tran and Ludovic Koehl and Shujun Li},
  doi          = {10.1016/j.engappai.2023.106051},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106051},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AnoFed: Adaptive anomaly detection for digital health using transformer-based federated learning and support vector data description},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforcement learning approach to automatic voltage
regulator system. <em>EAAI</em>, <em>121</em>, 106050. (<a
href="https://doi.org/10.1016/j.engappai.2023.106050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Automatic Voltage Regulator (AVR) system utilized to keep the terminal voltage of a synchronous generator at the desired level has received much attention among researchers. Designing an efficient and robust control scheme for the AVR system to maintain a specified voltage level is an important research area. From the control area perspective, reinforcement learning, an adaptive optimal control method, has received increasing attention in reference tracking problems. This article discusses a reinforcement learning approach to an AVR system and its experimental validation. A deep deterministic policy gradient (DDPG) agent working in continuous-time is designed offline to improve dynamic system characteristics of the AVR system besides its robustness against load disturbance, parameter uncertainties, and reference change. In the DDPG agent design process, the limits of the produced control signal are taken into account to perform a feasible simulation similar to a real-time application. The performance of the proposed learning-based controller is analyzed in three categories: transient and steady-state responses, stability analysis, and robustness analysis against parameter uncertainties, reference change, and load disturbance. A comparison with recently published papers employing Fuzzy-PID, PID-F, PI λ DND 2 N 2 , PIDD 2 ,and PID controllers in which various heuristic optimization algorithms were employed to optimally tune the controller parameters is made. Furthermore, to demonstrate that the behavior of the learning-based approach provides a stable and satisfactory performance, it is analyzed for a real synchronous generator connected to a 230 kV network using Matlab/Simulink environment. The results presented in this paper indicate that the proposed learning-based controller ensures the stability of the AVR system, significantly improves the regulating performance, and most impressively, is robust against parameter uncertainties, reference change, and load disturbance.},
  archive      = {J_EAAI},
  author       = {Mustafa Sinasi Ayas and Ali Kivanc Sahin},
  doi          = {10.1016/j.engappai.2023.106050},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106050},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reinforcement learning approach to automatic voltage regulator system},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-based padding: From connectivity on data borders to
data padding. <em>EAAI</em>, <em>121</em>, 106048. (<a
href="https://doi.org/10.1016/j.engappai.2023.106048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Padding is employed vastly in convolutional neural networks (CNNs) to maintain the output size. In current padding schemes, the input feature maps are padded using quite simple strategies, e.g., constant zero values in zero padding, which is the most common padding choice. In this work, we propose to use learning-based paradigms to calculate the padding data from the connectivity of the input images on the data borders. Two different modules, i.e., learning-based padding by convolution (LPC) and learning-based padding by attention (LPA), are designed to obtain the padding data from the interdependencies of the image border data along the channel and spatial dimensions, respectively. The designed LPC or LPA is formulated as a generic, plug-and-play unit, which can be a direct replacement for the conventional padding technique. Extensive experiments on image classification and semantic segmentation tasks show that the proposed padding schemes can consistently obtain higher accuracy than standard padding schemes, in various deep network backbones. The codes and trained modules are available at https://github.com/ICSResearch/LP .},
  archive      = {J_EAAI},
  author       = {Chao Ning and Hongping Gan and Minghe Shen and Tao Zhang},
  doi          = {10.1016/j.engappai.2023.106048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning-based padding: From connectivity on data borders to data padding},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MA-GCN: A memory augmented graph convolutional network for
traffic prediction. <em>EAAI</em>, <em>121</em>, 106046. (<a
href="https://doi.org/10.1016/j.engappai.2023.106046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is a particularly challenging and important application direction in the field of spatial–temporal prediction. However, it is difficult for existing models to accurately capture the long time dependence of traffic data and the complex spatial dependence of road network. To solve these two issues, in this work, we propose a new deep learning framework — Memory Augmented Graph Convolutional Network (MA-GCN), which combines graph convolutional network (GCN) with differential neural computer (DNC). In the model, GCN is used to learn the complex road network structure to capture the spatial dependence, while DNC is applied to learn the long-term dynamic changes of traffic data to capture the long time dependence. Based on this, the traffic prediction is implemented, and the experimental evaluation is carried out on two public datasets, PeMSD4 and PeMSD8. The results show that the MA-GCN model is superior to the comparative models on several evaluation metrics.},
  archive      = {J_EAAI},
  author       = {Dunlu Peng and Yongsheng Zhang},
  doi          = {10.1016/j.engappai.2023.106046},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106046},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MA-GCN: A memory augmented graph convolutional network for traffic prediction},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locating the source of self-potential using few-shot
learning. <em>EAAI</em>, <em>121</em>, 106045. (<a
href="https://doi.org/10.1016/j.engappai.2023.106045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-potential method has the advantages of convenience, rapidity and sensitivity. It has many applications in geophysical exploration. Therefore, the inversion problem of self-potential is very important. In order to obtain the location of the source, we propose a new self-potential inversion method based on few-shot learning. Firstly, a fully-connected neural network is used to extract the features of self-potential data and the data of well-surface pole–pole device method, and then the cosine distance is used to calculate the similarity between them. So, we can transform the positioning problem on the two-dimensional (2D) profile into the classification problem in two directions. In order to verify the feasibility of this method, we carried out a simulated landfill leakage experiment and a field saline water diffusion experiment, and both achieved good results. Compared with self-potential tomography method, the positioning accuracy of our method is increased by about 10.42%. Compared with traditional deep learning methods, we combine multimodal data to make the results more interpretable. In addition, the results of the two experiments also prove that our method has strong generalization ability, which provides a new idea to solve the differences between the simulation model and the actual field.},
  archive      = {J_EAAI},
  author       = {Lin-Jin Yang and Chang-Xin Nai and Guo-Bin Liu and Kai-Lun Lai and Shuo-Yang Gao and Kai-Da Zheng},
  doi          = {10.1016/j.engappai.2023.106045},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106045},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Locating the source of self-potential using few-shot learning},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial–temporal complex graph convolution network for
traffic flow prediction. <em>EAAI</em>, <em>121</em>, 106044. (<a
href="https://doi.org/10.1016/j.engappai.2023.106044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction remains an ongoing hot topic in the field of Intelligent Transportation System. The state-of-the-art traffic flow prediction models can effectively extract both spatial and temporal features of traffic flow data, but ignore the correlation and external interference between traffic nodes. To this end, this paper proposes a novel method based on Spatial–Temporal Complex Graph Convolution Network (ST-CGCN) for traffic flow prediction. Specifically, we first constructs the distance matrix, the data correlation matrix, and the comfort measurement matrix according to the geographical locations, the historical data record, and the external interference between traffic nodes. Then, these three matrices are fused into a complex correlation matrix by introducing self-learning dynamic weights to improve the joint modeling ability of spatial–temporal features and external factors. Next, a spatial feature extraction module and a temporal feature extraction module are designed to characterize dynamic spatial–temporal features. The spatial feature extraction module consists of a graph convolution operator with a proposed complex correlation matrix and a residual unit. The temporal feature extraction module consists of a 3D convolution operator and a Long Short-Term Memory (LSTM). Experiments constructed on five real-world datasets demonstrate that the new proposed ST-CGCN is more effective than several existing deep learning based traffic flow prediction models. The key source code and data are available at https://github.com/Bounger2/ST-CGCN .},
  archive      = {J_EAAI},
  author       = {Yinxin Bao and Jiashuang Huang and Qinqin Shen and Yang Cao and Weiping Ding and Zhenquan Shi and Quan Shi},
  doi          = {10.1016/j.engappai.2023.106044},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106044},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatial–Temporal complex graph convolution network for traffic flow prediction},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Semi-supervised non-negative matrix tri-factorization with
adaptive neighbors and block-diagonal learning. <em>EAAI</em>,
<em>121</em>, 106043. (<a
href="https://doi.org/10.1016/j.engappai.2023.106043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-regularized non-negative matrix factorization (GNMF) is proved to be effective for the clustering of nonlinear separable data. Existing GNMF variants commonly improve model performance by adding different additional constraints or refining the model factorization form, which can lead to problems such as increased algorithm complexity or insufficient performance release. In this paper, we propose semi-supervised non-negative matrix tri-factorization with adaptive neighbors and block-diagonal (ABNMTF). Different from existing methods, in ABNMTF the similarity graph matrix is learned from the original data by adaptive neighbors k -nearest model, and a block diagonal matrix is constructed based on a few labeled data to update the similarity matrix. Our approach reconstructs the block diagonal structure into the adaptive similarity matrix, which enables simultaneous learning of the similarity matrix and label binding during factorization, engendering a distinguishable subspace representation matrix and therefore improving the clustering performance without significantly increasing the complexity of the algorithm. We also represent an optimization method to solve the ABNMTF and provide analyses of convergence and computational complexity. Extensive experiments on 8 real image datasets show that the proposed algorithm reports superior performance against several state-of-the-art approaches. Code has been made available at: https://github.com/LstinWh/ABNMTF .},
  archive      = {J_EAAI},
  author       = {Songtao Li and Weigang Li and Hao Lu and Yang Li},
  doi          = {10.1016/j.engappai.2023.106043},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106043},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised non-negative matrix tri-factorization with adaptive neighbors and block-diagonal learning},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). CLformer: Locally grouped auto-correlation and
convolutional transformer for long-term multivariate time series
forecasting. <em>EAAI</em>, <em>121</em>, 106042. (<a
href="https://doi.org/10.1016/j.engappai.2023.106042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the performance of long-term time series forecasting is important for real-world applications. Recently, Transformer-based models have achieved significant performance gains in long-term time series prediction. However, these models are memory-intensive and cannot capture temporal patterns at multiple scales. To this end, we propose to integrate the time series decomposition method in the Transformer framework to enable the model to extract short- and long-term time patterns in more predictable seasonal and trend components. In this paper, we propose a Transformer-based model named CLformer. Different from previous methods, we exploit dilated convolutional networks to capture and refine multiple temporally repeated patterns in time series before time series decomposition. To enable the model to capture the dependencies at multiple scales, we propose a local group autocorrelation (LGAC) mechanism. The LGAC mechanism calculates autocorrelation within time series segments, strengthening the model’s ability to capture the local temporal dynamics of series. The stacking of multiple LGAC layers enables the model to capture multi-scale dependencies, which in turn improves the model’s predictive performance. The CLformer outperforms models using the global autocorrelation mechanism and self-attention in both efficiency and accuracy. Experimental results on six benchmark datasets show that our model obtains a relative performance improvement of 11.75% compared to the state-of-the-art methods. In addition, CLformer achieves a relative performance improvement of 18.89% on two datasets without apparent periodicity, demonstrating the effectiveness of our model on time series without significant periodicity.},
  archive      = {J_EAAI},
  author       = {Xingyu Wang and Hui Liu and Junzhao Du and Zhihan Yang and Xiyao Dong},
  doi          = {10.1016/j.engappai.2023.106042},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106042},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CLformer: Locally grouped auto-correlation and convolutional transformer for long-term multivariate time series forecasting},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-term traffic flow forecasting using a hybrid CNN-BiLSTM
model. <em>EAAI</em>, <em>121</em>, 106041. (<a
href="https://doi.org/10.1016/j.engappai.2023.106041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase of road traffic in large cities during the last years has produced that long and short-term traffic flow forecasting is a critical need for the authorities. The availability of good traffic flow prediction methods is a must to make informed decisions concerning (punctual) traffic congestions. Previous work has shown that the accuracy of these methods decreases if we consider urban traffic and long-term predictions. In this paper we present a hybrid model, combining a Convolutional Neural Network and a Bidirectional Long–Short-Term Memory network, and apply it to long-term traffic flow prediction in urban routes. This model combines the capability of CNN to extract hidden valuable features from the input model and the capability of BiLSTM to understand the temporal context. In order to assess the usefulness of our model, we considered four streets of the city of Madrid with different characteristics and compared the results of our proposed model with the ones obtained by eight widely used baseline models. The results show that our hybrid model outperforms the baseline models with respect to three metrics commonly used in regression: mean absolute error, root mean squared error and accuracy.},
  archive      = {J_EAAI},
  author       = {Manuel Méndez and Mercedes G. Merayo and Manuel Núñez},
  doi          = {10.1016/j.engappai.2023.106041},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106041},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-term traffic flow forecasting using a hybrid CNN-BiLSTM model},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive position-guided gravitational search algorithm
for function optimization and image threshold segmentation.
<em>EAAI</em>, <em>121</em>, 106040. (<a
href="https://doi.org/10.1016/j.engappai.2023.106040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gravitational search algorithm is a population-based optimization method. To address its low search performance and premature convergence, a novel variant called adaptive position-guided gravitational search algorithm is proposed. It utilizes the best, worst and other particles’ position information to adaptively determine the Kbest particles which provide a good movement direction. The gravitational force is reinforced by Kbest particles and new constructed Dbest particles to improve the exploration and exploitation abilities. Various particles’ position information jointly provide the effective search guideline and accelerate the convergence rate. Validations are conducted to firstly discuss the parameters and strategies of the proposed algorithm. Then, compared with several state-of-the-art gravitational search algorithm variants on CEC2017 benchmark functions, the proposed algorithm proves its superiority. Finally, the proposed algorithm exhibits the good segmentation effect on image threshold segmentation problems.},
  archive      = {J_EAAI},
  author       = {Anjing Guo and Yirui Wang and Lijun Guo and Rong Zhang and Yang Yu and Shangce Gao},
  doi          = {10.1016/j.engappai.2023.106040},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106040},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive position-guided gravitational search algorithm for function optimization and image threshold segmentation},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning techniques for stock price prediction and
graphic signal recognition. <em>EAAI</em>, <em>121</em>, 106038. (<a
href="https://doi.org/10.1016/j.engappai.2023.106038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock market analysis is extremely important for investors because knowing the future trend and grasping the changing characteristics of stock prices will decrease the risk of investing capital for profit. Thereupon, the prediction of stock prices and identifying the graphic signals of candlestick charts, which are two crucial tasks in stock price analysis, attract much attention from investors owing to the returns and risks that coexist in financial markets. To introduce a reliable approach for addressing these challenges, this paper proposes the modeling strategies based on machine learning (ML) techniques. A vector autoregression (VAR)-based rolling prediction model is proposed for forecasting stock prices, and a Gaussian feed-forward neural networks (GFNN)-based graphic signal identification method is introduced to recognize different types of stock price signals. The experimental results demonstrate better performance comparing with the state-of-the-art methods, and it can be successfully applied in real-world stock exchange strategies.},
  archive      = {J_EAAI},
  author       = {Junde Chen and Yuxin Wen and Y.A. Nanehkaran and M.D. Suzauddola and Weirong Chen and Defu Zhang},
  doi          = {10.1016/j.engappai.2023.106038},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106038},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning techniques for stock price prediction and graphic signal recognition},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep learning framework for solving fokker–planck equations
with low-rank separation representation. <em>EAAI</em>, <em>121</em>,
106036. (<a
href="https://doi.org/10.1016/j.engappai.2023.106036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An insightful deep learning framework is proposed to solve the well-known Fokker–Planck (FP) equations that quantify the evolution of the probability density function. It efficiently reduces the demand of training data in acquiring precise integrations of special normalization conditions via neural network (NN). Instead of all hypercubic discrete points, the inputs of each NN only require one-dimensional discrete data, and this also avoids the exponential increase in training data as the dimension increase. Without loss of generality, to solve a d -dimensional FP equation, d NNs are employed and assembled into a low-rank separation representation. The FP equation, boundary conditions, and integral operators are then re-expressed in the sense of the separation representation. It enables the constructed loss function to perform simple vector operations, in that complicated d -dimensional operators are replaced by a set of one dimensional operators. A tractable strategy is presented for the selection of separation rank inspired by the potential function of the given system, although selecting an appropriate separation rank is still an open issue. Typical numerical examples reveal that the proposed algorithm is effective and superior for solving FP equations. The suggested framework could be applied and extended in various areas of engineering and applied sciences.},
  archive      = {J_EAAI},
  author       = {Hao Zhang and Yong Xu and Qi Liu and Yongge Li},
  doi          = {10.1016/j.engappai.2023.106036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning framework for solving Fokker–Planck equations with low-rank separation representation},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Do we need early exit networks in human activity
recognition? <em>EAAI</em>, <em>121</em>, 106035. (<a
href="https://doi.org/10.1016/j.engappai.2023.106035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is nowadays considered state-of-the-art technology in many applications thanks to huge performance capabilities. However, the accuracy levels that can be obtained with these models entail computationally demanding resources. This results in a challenging task when such systems have to be deployed on edge devices with tight computing, memory, and communication requirements and when energy expenditure and inference delays have to be kept under control. Early exit is a design methodology aimed at reducing the burden of neural networks on computational resources, trading off accuracy for latency. In this work, we aim at exploring the use of early exit for human activity recognition tasks. In particular, we propose an experimental assessment of the accuracy–latency trade-off on different deep network architectures across various publicly available datasets. We also evaluate the impact of early exiting in distributed environments by taking into account communication technologies. Experimental results provide evidence of the significant gain provided by early exits in terms of latency (up to 35 × ), without a reduction in accuracy (in most cases), confirming the viability of an adaptive approach. In a distributed environment, early exit results are not beneficial in all situations. In particular, it is not convenient for models that are very fast (with inference latency lower than, or as equal as, that of communication) and for models that are forced to make extensive use of far exit points to satisfy the accuracy requirements. Therefore, communication delays in a distributed environment shape performance in an architecture-dependent way.},
  archive      = {J_EAAI},
  author       = {Emanuele Lattanzi and Chiara Contoli and Valerio Freschi},
  doi          = {10.1016/j.engappai.2023.106035},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106035},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Do we need early exit networks in human activity recognition?},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning of neural network with optimal control tools.
<em>EAAI</em>, <em>121</em>, 106033. (<a
href="https://doi.org/10.1016/j.engappai.2023.106033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any learned artificial neural network on a given set of observations represents a function of several variables with vector values or real values. However, in general it is unknown except very simply cases and we have trouble to tell anything about its properties behind very general results received from learning data. In applications, such as medicine, it needs to say not only that on training data we get some error, we have to know that an error is not greater than some ɛ for all data for which we consider the system. It is well known that the learned neural network define a function. However, we check correctness of it only on finite number of observed data. We develop an optimal control approach allowing to find approximation of an unknown function realizing the given observable data, parametrized by a set of controls and defined as ordinary differential equations. Moreover, to measure discrepancy, of the output of the network we define a functional into which we include probability distribution function estimating distribution of the data. We develop a dual dynamic programming ideas to formulate a new optimization problem. We apply it to derive and to prove sufficient approximate optimality conditions for approximate neural network which should work correctly for given ɛ with respect to built functional, on a data different than the set of observations.},
  archive      = {J_EAAI},
  author       = {Marta Lipnicka and Andrzej Nowakowski},
  doi          = {10.1016/j.engappai.2023.106033},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106033},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning of neural network with optimal control tools},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomization-based neural networks for image-based wind
turbine fault diagnosis. <em>EAAI</em>, <em>121</em>, 106028. (<a
href="https://doi.org/10.1016/j.engappai.2023.106028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the development of wind energy industry, the safe production of wind farms has become an urgent problem. To avoid serious faults and deterioration, building effective diagnostic model for wind turbine (WT) has raised increasing attentions in wind-power industry. However, the challenges like big data of sensors and model construction exist still. In this paper, to achieve better performance and suitable framework, a three channel broad learning system (3-BLS) is proposed for image-based fault diagnosis (FD) on overall WT system. First, multiple sensor series are collected and converted into interpretable RGB images via right-sized sliding window for broader information and grabbing relations; Next, features are extracted in respective RGB channels, and a manual feature layer is added in the 3-BLS, where the structure is temporary non-specific; Finally, with the help of an optimizer, the concrete 3-BLS is auto-built with its structure configured reasonably and the manual features binary-coded and enabled selectively. In addition, an inter-channel attention scheme is formed during 3-BLS dynamic updating process, and several BLS prototypes different in projections are studied. In experiments, the optimized 3-BLS with less parameters got over 10% accuracy gain than adjusted single BLS and achieved over 98% fault detection on actual collected WT data.},
  archive      = {J_EAAI},
  author       = {Junda Wang and Yang Yang and Ning Li},
  doi          = {10.1016/j.engappai.2023.106028},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106028},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Randomization-based neural networks for image-based wind turbine fault diagnosis},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fractal belief KL divergence for decision fusion.
<em>EAAI</em>, <em>121</em>, 106027. (<a
href="https://doi.org/10.1016/j.engappai.2023.106027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer (D–S) evidence theory is useful in the realm of multi-source data fusion. However, a counterintuitive result may be obtained when the belief probability assignments (BPAs) are highly conflicting. To overcome this flaw, in this paper a symmetric fractal-based belief Kullback–Leibler divergence ( F B D S K L ) is proposed. It is used to measure the divergence between BPAs, and is more capable than the existing belief divergence methods in measuring the conflict between two BPAs in numerical examples. Furthermore, the proposed F B D S K L is proved to have desirable properties including nonnegativity, nondegeneracy and symmetry. To apply F B D S K L divergence measure to practical problems, a novel F B D S K L -based multi-source data fusion ( F B D S K L -MSDF) algorithm is designed. Through comparisons with the well-known related methods, the proposed F B D S K L -MSDF algorithm is validated to be superior and more robust. Finally, the proposed F B D S K L -MSDF is applied to two real-world classification problems to verify its high practicability.},
  archive      = {J_EAAI},
  author       = {Jie Zeng and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2023.106027},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106027},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fractal belief KL divergence for decision fusion},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selection of healthcare waste management treatment using
fuzzy rough numbers and aczel–alsina function. <em>EAAI</em>,
<em>121</em>, 106025. (<a
href="https://doi.org/10.1016/j.engappai.2023.106025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic led to an increase in healthcare waste (HCW). HCW management treatment needs to be re-taken into focus to deal with this challenge. In practice, there are several treatments of HCW with their advantages and disadvantages. This study is conducted to select the appropriate treatment for HCW in the Brčko District of Bosnia and Herzegovina. Six HCW management treatments are analyzed and observed through twelve criteria. Ten-level linguistic values were used to bring this evaluation closer to human thinking. A fuzzy rough approach is used to solve the problem of inaccuracy in determining these values. The OPA method from the Bonferroni operator is used to determine the weights of the criteria. The results of the application of this method showed that the criterion Environmental Impact ( C 4 ) received the highest weight, while the criterion Automation Level ( C 8 ) received the lowest value. The ranking of HCW management treatments was performed using MARCOS methods based on the Aczel–Alsina function. The results of this analysis showed that the best-ranked HCW management treatment is microwave (A6) while landfill treatment (A5) is ranked worst. This study has provided a new approach based on fuzzy rough numbers where the Bonferroni function is used to determine the lower and upper limits, while the application of the Aczel–Alsina function reduced the influence of decision-makers on the final decision because this function stabilizes the decision-making process.},
  archive      = {J_EAAI},
  author       = {Dragan Pamučar and Adis Puška and Vladimir Simić and Ilija Stojanović and Muhammet Deveci},
  doi          = {10.1016/j.engappai.2023.106025},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106025},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Selection of healthcare waste management treatment using fuzzy rough numbers and Aczel–Alsina function},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simple and robust depth-wise cascaded network for polyp
segmentation. <em>EAAI</em>, <em>121</em>, 106023. (<a
href="https://doi.org/10.1016/j.engappai.2023.106023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of the polyp region in colonoscopy images is considered difficult due to size, texture, and color variation. To segment polyps successfully, models based on convolutional neural networks (CNN), transformers, and their combinations have been developed. However, these methods are limited in that they can only model the local appearance of polyps or lack multi-level feature representation for spatial dependency in the decoding process. In this paper, we propose a simple, efficient yet powerful polyp segmentation framework that unifies the network with a multiscale cascaded path. The proposed MMS-Net utilizes multiscale and multipath convolutional operations in conjunction with multiple deep feature aggregation. The overall dense empowered features are sufficient for pixel-by-pixel detection of the polyp region. Extensive experiments on two popular benchmark datasets for polyp segmentation (Kvasir and CVC-Clinic DB) and two datasets of other medical applications (DRIVE and MC) are presented. The results show that our MMS-Net performs comparably to or better than other state-of-the-art methods despite having two or even three orders of magnitude fewer trainable parameters.},
  archive      = {J_EAAI},
  author       = {Tariq M. Khan and Muhammad Arsalan and Imran Razzak and Erik Meijering},
  doi          = {10.1016/j.engappai.2023.106023},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106023},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simple and robust depth-wise cascaded network for polyp segmentation},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting the eddy current loss of a large turbo generator
using hybrid ensemble gaussian process regression. <em>EAAI</em>,
<em>121</em>, 106022. (<a
href="https://doi.org/10.1016/j.engappai.2023.106022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the issue that the sample space of wedge winding eddy current losses of large generator does not obey Gaussian distribution, a hybrid ensemble Gaussian process regression (HEGPR) model is proposed in this paper. The HEGPR contains three layers. First, four tree regression models (XGBoost, CatBoost, LGBM and NGBoost) are built. Then, the output of the first layer is taken as the input of multiple Gaussian regression models, so that the input samples of the second layer obey Gaussian distribution, which can effectively improve the generalization ability of Gaussian process regression. The results show that the root mean squared error (RMSE) is 0.0282 and the goodness of fit ( R 2 ) is 0.9973. The model has good prediction performance for the eddy current loss of large turbo generator. Compared with kinds of Gaussian process models and traditional ensemble learning models, the prediction accuracy of this model is higher, and it is more suitable for forecasting eddy current loss of the large generator. HEGPR model can effectively solve the problem of insufficient regression accuracy of Gaussian process when sample space does not obey Gaussian distribution.},
  archive      = {J_EAAI},
  author       = {Jingying Zhao and Yifan Song and Likun Wang and Hai Guo and Fabrizio Marigentti and Xin Liu},
  doi          = {10.1016/j.engappai.2023.106022},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106022},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting the eddy current loss of a large turbo generator using hybrid ensemble gaussian process regression},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe semi-supervised learning for pattern classification.
<em>EAAI</em>, <em>121</em>, 106021. (<a
href="https://doi.org/10.1016/j.engappai.2023.106021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) based on manifold regularization in many fields has attracted widespread attention and research. However, SSL still has two main challenges: On the one hand, studies have shown that unlabeled data may cause performance degradation in semi-supervised classifiers, which means that unlabeled data introduces uncertainty and potential hazards. On the other hand, for samples distributed on different class boundaries, manifold regularization is not necessarily satisfactory, which will result in samples near the boundary that are likely to be misclassified. In response to the above problems, we propose a new SSL framework called safe semi-supervised learning (Sa-SSLJR for short). In Sa-SSLJR, a risk degree regularization term is constructed to estimate the uncertainty and potential risk of unlabeled data in the semi-supervised learning process. Secondly, based on manifold regularization and discriminant regularization, a joint regularization term is developed to solve the second challenge of SSL. Extensive experiments on multiple datasets show that our approach is competitive with state-of-the-art methods in terms of classification performance and feasibility.},
  archive      = {J_EAAI},
  author       = {Jun Ma and Guolin Yu and Weizhi Xiong and Xiaolong Zhu},
  doi          = {10.1016/j.engappai.2023.106021},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106021},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safe semi-supervised learning for pattern classification},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rice leaf disease identification by residual-distilled
transformer. <em>EAAI</em>, <em>121</em>, 106020. (<a
href="https://doi.org/10.1016/j.engappai.2023.106020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the worldwide planting crop, rice feeds nearly half of the world’s population. However, the continuous spread of diseases is threatening rice production. It is of great practical value to identify rice diseases precisely. Recent studies suggest that the computational approaches provide an opportunity for rice leaf disease prediction and achieve a series of achievements. However, the existing works for rice leaf disease identification are still unsatisfactory either in identification accuracy or model interpretability. To address these limitations, a residual-distilled transformer architecture is proposed in this study. Inspired by the early success of transformers in computer vision, the distillation strategy is introduced to distill weights and parameters from the pre-trained vision transformer models. The residual concatenation between vision transformer and the distilled transformer are as residual blocks for features extraction, and then fed them into multi-layer perceptron (MLP) for prediction. Experimental results demonstrate that the presented method achieves 0.89 F1-score and 0.92 top-1 accuracy, outperforms the existing state-of-the-art models on the rice leaf disease dataset which collected in paddy fields. In addition, the proposed architecture provides model interpretability to grasp the key features that are significant for positive prediction results.},
  archive      = {J_EAAI},
  author       = {Changjian Zhou and Yujie Zhong and Sihan Zhou and Jia Song and Wensheng Xiang},
  doi          = {10.1016/j.engappai.2023.106020},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106020},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rice leaf disease identification by residual-distilled transformer},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-based damage localization method for
building structures using correlation of measured structural responses.
<em>EAAI</em>, <em>121</em>, 106019. (<a
href="https://doi.org/10.1016/j.engappai.2023.106019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Buildings deteriorate and suffer from unexpected severe loads, such as earthquakes and typhoons. Damages occurring in these buildings due to such loads can be disastrous. In the field of structural health monitoring, there have been many efforts to prevent disasters by identifying damage in structures. To deal with large quantities of data in responses measured from the structures for damage detection, various techniques based on artificial intelligence have been developed. The most recent methods employ data for damaged states that are usually obtained from numerical analysis as well as data corresponding to future behavioural predictions. Thus, supervised learning-based methods using future or labelled data cannot be applied to real-world situations. In this study, an unsupervised damage identification method is proposed using a convolutional neural network (CNN) trained exclusively with healthy state data. The discrepancy between healthy state data and output data from the CNN with the damaged state response is displayed as damage indicators. The distribution of the indicators is quantitatively analysed using a correlation coefficient (CC). The storey with the lowest correlation, or the storey where the data with a minimum CC value is extracted, is identified as the damage location. The validity of the presented method is examined by numerical and experimental studies.},
  archive      = {J_EAAI},
  author       = {Byung Kwan Oh and Woo Chan Jung and Hyo Seon Park},
  doi          = {10.1016/j.engappai.2023.106019},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106019},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence-based damage localization method for building structures using correlation of measured structural responses},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent replacement analysis using picture fuzzy sets:
Defender-challenger comparison application. <em>EAAI</em>, <em>121</em>,
106018. (<a
href="https://doi.org/10.1016/j.engappai.2023.106018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Replacement analysis is based on the principle that it may be more economical to retirement of an equipment earlier than its physical life. This replacement time, called the economic life, is usually calculated by annual cash flow analysis. These calculations made with deterministic estimations in classical analyzes are not realistic because they do not take into account the uncertainties in their estimations. Picture fuzzy sets (PFSs) introduced to the literature in recent years can provide a more detailed estimation by using the yes, abstain, no, and refusal degrees of the estimations. In this paper, the economic lives of defender and challenger, which are two alternatives of replacement analysis, are calculated using PFSs and a replacement decision was made. Estimates are made by three experts in the PF environment, and these estimates are aggregated by using PF aggregation operators. The optimistic, normal, and pessimistic estimations made with PFSs are converted into ordinary triangular fuzzy sets in the further stages of the analysis, and the economic life is determined for both the defender and the challenger by defuzzification of the triangular fuzzy numbers obtained with the center of gravity method. It has been revealed that the proposed fuzzy replacement analysis can be used as a decision support model for managers under uncertainty. A multi-expert comprehensive example has shown that PFSs can be used successfully in a real replacement application. The robustness of the given decisions by the replacement analysis is confirmed by a sensitivity analysis.},
  archive      = {J_EAAI},
  author       = {Elif Haktanır and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2023.106018},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106018},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent replacement analysis using picture fuzzy sets: Defender-challenger comparison application},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSRA-g: Combination of multi-scale residual attention
network and generative adversarial networks for hyperspectral image
classification. <em>EAAI</em>, <em>121</em>, 106017. (<a
href="https://doi.org/10.1016/j.engappai.2023.106017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based technology has been introduced to increase the classification accuracy of hyperspectral imagery (HSI). Nevertheless, it is still a challenging issue to derive a satisfying classification accuracy from limited training samples. A novel method (MSRA-G) that combines multi-scale residual attention (MSRA) with Generative Adversarial Networks (GANs) was proposed. In view of the low classification accuracy with limited training samples, the is first used to generate more separable synthetic samples. A network is then proposed to extract multi-scale context information for improving HSI classification. The proposed method constructs two multi-scale feature extraction modules to identify high-level spatial–spectral features based on the 3D–2D hybrid network. In addition, the residual connection mode and the attention mechanism are combined to establish the channel and spatial residual attention modules. Different weights are assigned to different features in the channel dimension and spatial dimension, and the features are selectively learned. Furthermore, to verify the performance of MSRA-G, experiments were carried out on three publicly available HSI datasets of Indian Pines, University of Pavia and Salinas Valley. The experimental results show that our proposed MSRA-G is superior to several popular classification models. It can still achieve satisfactory classification accuracies, even in the case of insufficient training samples.},
  archive      = {J_EAAI},
  author       = {Jinling Zhao and Lei Hu and Linsheng Huang and Chuanjian Wang and Dong Liang},
  doi          = {10.1016/j.engappai.2023.106017},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106017},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MSRA-G: Combination of multi-scale residual attention network and generative adversarial networks for hyperspectral image classification},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A full end-to-end deep approach for detecting and
classifying jaw movements from acoustic signals in grazing cattle.
<em>EAAI</em>, <em>121</em>, 106016. (<a
href="https://doi.org/10.1016/j.engappai.2023.106016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the foraging behaviour of ruminants is a key task to improve their productivity and welfare. During the last decades, several monitoring approaches have been proposed based on different types of sensors such as pressure-based, accelerometers and microphones. Among them, microphones have been one of the most promising options because acoustic signals provide comprehensive information about the foraging behaviour. In this work, a fully end-to-end deep architecture is proposed in order to perform both detection and classification tasks of masticatory events in one step, relying only on raw acoustic signals. The main benefit of this novel approach is the substitution of handcrafted preprocessing and feature extraction phases for a pure deep learning approach, which has shown better performance in related fields. Furthermore, different data augmentation techniques have been evaluated to address the data shortness for models development, typical in this field. The results demonstrate that the proposed architecture achieves a F1 score value of 79.82, which represents an increment close to 18% with respect to other state-of-the-art algorithms. Moreover, the proposed data augmentation techniques provide further performance enhancements, emerging as interesting alternatives in this field.},
  archive      = {J_EAAI},
  author       = {Mariano Ferrero and Leandro D. Vignolo and Sebastián R. Vanrell and Luciano S. Martinez-Rau and José O. Chelotti and Julio R. Galli and Leonardo L. Giovanini and H. Leonardo Rufiner},
  doi          = {10.1016/j.engappai.2023.106016},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106016},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A full end-to-end deep approach for detecting and classifying jaw movements from acoustic signals in grazing cattle},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature sampling based on multilayer perceptive neural
network for image quality assessment. <em>EAAI</em>, <em>121</em>,
106015. (<a
href="https://doi.org/10.1016/j.engappai.2023.106015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image quality assessment (IQA) has a vital issue in image processing to measure the perceptual quality of the image. This aims at the human visual system (HVS) by viewing for distorted images from reference images. HVS is the ultimate receiver of visual data in major applications. But, quality assessment is generally a time-consuming and luxurious method. In our work, the novel Bilateral Smoothing Filtered Feature Sampling-Based Tanimoto Index’ve Multilayer Perceptive Neural Network (BSFFS-TIMPNN) technique is developed. The main contribution of the designed BSFFS-TIMPNN technique is for enhancing the quality of the assessment performance with full reference and no reference images with multiple layers. At first, the original and reference image is taken to the input layer and sent to the first hidden layer. Followed by, image preprocessing is performed in the first hidden layer by using the novelty of a nonlinear bilateral smoothing filtering technique for eradicating noisy pixels with a higher-quality image. Next, patch extraction is executed in the second hidden layer with the novelty of the nearest neighbor sampling approach to split images into various patches. Then, the different features of the image such as shape, color, and texture are extracted in the third hidden layer. Finally, classification is carried out output layer by applying the innovation of the Tanimoto similarity index to examine the extracted features for IQA. We estimate the proposed BSFFS-TIMPNN technique on the Tampere Image Database (TID2013) dataset with qualitative and quantitative results analysis. The proposed BSFFS-TIMPNN technique is employed to compute image quality with maximum accuracy and minimum time and memory consumption when compared to other related methods by MATLAB simulator. The observed quantitative result demonstrates the better performance of the proposed BSFFS-TIMPNN technique by full reference and no reference with higher PSNR by 8%, accuracy by 15%, 17%, lesser memory consumption by 15%, 17, and faster prediction time by 9%, 9% than the state of art methods respectively.},
  archive      = {J_EAAI},
  author       = {Dharmalingam Muthusamy and Sathyamoorthy S.},
  doi          = {10.1016/j.engappai.2023.106015},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106015},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature sampling based on multilayer perceptive neural network for image quality assessment},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Β-divergence NMF with biorthogonal regularization for data
representation. <em>EAAI</em>, <em>121</em>, 106014. (<a
href="https://doi.org/10.1016/j.engappai.2023.106014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Negative Matrix Factorization (NMF) has become a commonly used method for data representation. Orthogonal NMF improves the clustering performance by adding orthogonal constraints to the decomposed matrices. The existing orthogonal NMF methods typically use Euclidean distance to measure the difference between before and after factorization for convenience and simplicity. However, limitations of the Euclidean distance can lead to inflexibilities. In addition, failure to consider orthogonality of the decomposed features and sparsity of the data representation can also lead to degraded performance of the algorithm. In order to overcome the above shortcomings, we propose a novel β -divergence-based NMF with biorthogonal regularization (BO- β NMF). Our BO- β NMF method uses generalized β -divergence instead of Euclidean distance to measure the similarity between matrices, and selects an appropriate β for each type of data to obtain a more flexible way of measuring similarity. In addition, we also incorporate biorthogonal constraints into the minimized objective function, which ensures both orthogonality of the decomposed features and sparsity of the data representation. Furthermore, we use trace rather than Euclidean distance to measure the orthogonality of the decomposed matrices, which reduces execution time. Finally, clustering experiments on image datasets show that the overall clustering effect of BO- β NMF is better than state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Ruixue Yuan and Chengcai Leng and Bing Li and Anup Basu},
  doi          = {10.1016/j.engappai.2023.106014},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106014},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {β-divergence NMF with biorthogonal regularization for data representation},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transferable visual pattern memory network for domain
adaptation in anomaly detection. <em>EAAI</em>, <em>121</em>, 106013.
(<a href="https://doi.org/10.1016/j.engappai.2023.106013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection transfer aims to utilize knowledge learned from source anomaly detection task to improve the performance of target anomaly detection task. Conventional methods typically assume that labeled normal or abnormal data are available in the source or target domain. However, many real-world applications do not satisfy this assumption because such labels are hard to collect. This study focuses on the case where anomalous labels are unavailable. More specifically, a rarely studied scenario in which the target domain contains unlabeled normal and abnormal instances, whereas only normal instances are available in the source domain, is addressed. To this end, a transferable visual pattern memory network was designed to transfer knowledge for anomaly detection tasks. The network comprises an adversarial domain adaptation method to extract transferable visual patterns, and a memory module utilized to store these patterns. The model utilizes transferable patterns stored in memory to identify anomalous samples. Moreover, a self-supervised objective is integrated to enhance the discriminability of target abnormal instances, thereby improving the anomaly detection performance. The results of extensive experiments conducted on publicly available anomaly-detection datasets verified the efficacy of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Cangning Fan and Ye Jin and Peng Liu and Wei Zhao},
  doi          = {10.1016/j.engappai.2023.106013},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106013},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transferable visual pattern memory network for domain adaptation in anomaly detection},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anatomically-guided deep learning for left ventricle
geometry generation with uncertainty quantification based on short-axis
MR images. <em>EAAI</em>, <em>121</em>, 106012. (<a
href="https://doi.org/10.1016/j.engappai.2023.106012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have greatly improved the ability to generate analysis models from medical images. In particular, great attention is focused on quickly generating models of the left ventricle from cardiac magnetic resonance imaging (cMRI) to improve the diagnosis and prognosis of millions of patients. However, even state-of-the art frameworks present challenges, such as discontinuities of the cardiac tissue and excessive jaggedness along the myocardial walls. These geometrical features are often anatomically incorrect and may lead to unrealistic results once the geometrical models are employed in computational analyses. In this work, we propose an anatomically-guided deep learning model to overcome these limitations while preserving the advantages of state-of-the-art frameworks, such as computational efficiency, robustness, and generalization capabilities. Our novel anatomically-guided neural networks are formed by a UNet followed by a B-spline head, which acts as a regularization layer during training. The B-spline head aggregates the prediction into a single connected region, removes any undesired tissue islands, and produces a smooth continuous contour. In addition, the introduction of the B-spline head contributes to achieve a robust uncertainty quantification of the left ventricle inner and outer walls. Our results show that the proposed model generates anatomically consistent geometries while achieving an agreement with the ground truth images comparable to state-of-the-art frameworks and simultaneously improving the geometry uncertainty quantification in comparison to classic UNet models. The examples presented here, as well as source codes, are all open-source under the GitHub repository https://github.com/CBL-UCF/unet_ag .},
  archive      = {J_EAAI},
  author       = {Andre Von Zuben and Luigi E. Perotti and Felipe A.C. Viana},
  doi          = {10.1016/j.engappai.2023.106012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Anatomically-guided deep learning for left ventricle geometry generation with uncertainty quantification based on short-axis MR images},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel dynamic distance coding identification method for
oil–gas gathering and transportation process. <em>EAAI</em>,
<em>121</em>, 106010. (<a
href="https://doi.org/10.1016/j.engappai.2023.106010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has become a mainstream method for fault identification in petrochemical processes. However, the high noise and nonlinear coupling of complex data samples have led to different degrees of low accuracy and robustness problems in the method. Meanwhile, the fault cause is difficult to capture due to the complex chemical process operation mechanism. To address this challenge, a novel dynamic distance coding method incorporating DL is proposed to identify anomalies in real time. First, the collected normal process data are smoothed by the Savitzky–Golay filter to build a normal sample set. Then, dynamic coding based on the distance metric is introduced to compute the distribution of normal and real-time samples for extracting the spatial domain features. By a sliding window, dynamic coded maps are generated and analyzed for fault causes. Finally, the time-domain information is extracted by long short-term memory (LSTM) to learn the deep features of the encoded graph for fault identification. The proposed method was applied to an oil–gas gathering and transportation process, which proves its feasibility and effectiveness. Compared with the conventional LSTM, the F1 score of the method is improved by 0.193, reaching 0.986. The obtained visualization information enables explaining the causes and supplements the fault database, providing a valuable reference for workers’ feedback operations.},
  archive      = {J_EAAI},
  author       = {Zijian Liu and Wende Tian and Bin Liu and Zhe Cui},
  doi          = {10.1016/j.engappai.2023.106010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel dynamic distance coding identification method for oil–gas gathering and transportation process},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Method of recognizing sleep postures based on air pressure
sensor and convolutional neural network: For an air spring mattress.
<em>EAAI</em>, <em>121</em>, 106009. (<a
href="https://doi.org/10.1016/j.engappai.2023.106009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study aimed to develop a sleep postures recognition system based on the hardness adjustment system for a specific air spring mattress. To the end, an air spring mattress prototype and its embedded system was manufactured. Then the supine and lateral postures were defined, and the sleep posture images generated by the relative change rate of air pressure matrix were filtered. At last, a convolutional neural network (CNN) model was proposed and analyzed by ablation experiment. Furthermore, the CNN model was compared with a CNN-SVM fusion model and a ResNet50 model to valid the performance. The results indicate that it is feasible to define sleep postures with the air pressure, and the images smoothed by a Gaussian filter contains significant features. The F1-score of the CNN model determined by the ablation experiment is 0.981, while the F1-score values of the CNN-SVM fusion model and the ResNet50 model are 0.932 and 0.954, respectively. Therefore, the generalization ability of the CNN model proposed outperformed the other two. Finally, the F1-score of the SSA-CNN model optimized by Sparrow Search Algorithm (SSA) increased to 0.992. It concludes that sleep posture recognition can be achieved using only the inherent structure of the air spring mattress without additional sensors, reducing the cost and complexity of the system. In addition, the air pressure signal can be processed by the proposed CNN model to recognize sleep postures with a high accuracy.},
  archive      = {J_EAAI},
  author       = {Yao Chao and Tao Liu and Li-Ming Shen},
  doi          = {10.1016/j.engappai.2023.106009},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106009},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Method of recognizing sleep postures based on air pressure sensor and convolutional neural network: For an air spring mattress},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Particle swarm optimization or differential evolution—a
comparison. <em>EAAI</em>, <em>121</em>, 106008. (<a
href="https://doi.org/10.1016/j.engappai.2023.106008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the mid 1990s two landmark metaheuristics have been proposed: Particle Swarm Optimization and Differential Evolution. Their initial versions were very simple, but rapidly attracted wide attention. During the last quarter century hundreds of variants of both optimization algorithms have been proposed and applied in almost any field of science or engineering. However, no broader comparison of performance between both families of methods has been presented so far. In the present paper ten Particle Swarm Optimization and ten Differential Evolution variants, from historical ones from the 1990s up to the most recent ones from 2022, are compared on numerous single-objective numerical benchmarks and 22 real-world problems. On average Differential Evolution algorithms clearly outperform Particle Swarm Optimization ones. Such advantage of Differential Evolution over Particle Swarm Optimization is in contradiction with popularity: In the literature Particle Swarm Optimization algorithms are two–three times more frequently used than Differential Evolution ones. Problems for which Particle Swarm Optimization performs better than Differential Evolution do exist but are relatively few. Although this result may be an effect of the choice of specific variants, experimental settings or problems used for comparison, some re-consideration of algorithmic philosophy may be needed for Particle Swarm Optimization variants to make them more competitive.},
  archive      = {J_EAAI},
  author       = {Adam P. Piotrowski and Jaroslaw J. Napiorkowski and Agnieszka E. Piotrowska},
  doi          = {10.1016/j.engappai.2023.106008},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106008},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Particle swarm optimization or differential Evolution—A comparison},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A collaborative cuckoo search algorithm with modified
operation mode. <em>EAAI</em>, <em>121</em>, 106006. (<a
href="https://doi.org/10.1016/j.engappai.2023.106006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuckoo search (CS) is a nature-inspired algorithm that has shown its favorable potential for solving complex optimization problems. Nevertheless, there is a lack of effective information sharing between individuals in CS, which would doubtless limit its achievable performance. While several CS variants have considered this issue, they commonly strengthen the information sharing in just one of the two search parts (i.e., global and local search parts). In this paper, to further address the above issue and to get a more rational allocation of the workloads of global search and local search, a new CS variant called collaborative CS with modified operation mode (CCSMO) is proposed. One novelty is that a collaborative mechanism is presented to strengthen the information sharing and collaboration between individuals in both search parts, and correspondingly, two new iterative strategies are introduced respectively for global search and local search. Another novelty is that the conventional operation mode adopted by almost all existing CS-based algorithms is modified for more rationally allocating the workloads of global search and local search. To validate the performance of CCSMO, extensive experiments and comparisons between CCSMO and 17 state-of-the-art algorithms are made on two popular test suites from IEEE Conference on Evolutionary Computation (CEC). Besides, the algorithm is also applied to solve three engineering design problems and one large-scale combined heat and power economic dispatch problem. The results demonstrate that CCSMO can offer highly competitive performance. Additionally, the time complexity, search behavior, modification effectiveness, and parameter sensitivity of CCSMO are also evaluated.},
  archive      = {J_EAAI},
  author       = {Qiangda Yang and Huan Huang and Jie Zhang and Hongbo Gao and Peng Liu},
  doi          = {10.1016/j.engappai.2023.106006},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106006},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A collaborative cuckoo search algorithm with modified operation mode},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An enhanced distributed differential evolution algorithm for
portfolio optimization problems. <em>EAAI</em>, <em>121</em>, 106004.
(<a href="https://doi.org/10.1016/j.engappai.2023.106004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The population structure of differential evolution (DE) algorithm cannot maintain the diversity of the population to the greatest extent and help the population avoid to fall into the local optima in time. In this paper, a co-evolutionary multi-swarm adaptive differential evolution algorithm, namely ECMADE is proposed to solve the premature convergence and search stagnation. First of all, in terms of population structure, based on the parallel distributed framework, ECMADE randomly and evenly divides the population into exploration subpopulation, development subpopulation, and auxiliary subpopulation, and introduces an adaptive information exchange mechanism so that subpopulations can escape local optima in time. Then, a multi-operator parallel search strategy is proposed to keep population diversity and meet the optimization needs of different problems. Finally, an adaptive adjustment mechanism of control parameters is developed, through recent elite parameter archive and weight distribution to fully mine successful parameter information, and generate control parameters with a high success rate for the current evolutionary stage. In order to prove the effectiveness of the ECMADE, 10 test functions and portfolio optimization problem are selected in here. The experiment results show that the ECMADE can effectively solve these test functions, the accuracy and efficiency is superior to those of two classical DE algorithms. The actual application results show that the ECMADE can significantly improve the ability of portfolio to resist extreme losses, which proves the effectiveness and feasibility of the ECMADE once again. The ECMADE has better optimization performance by comparing with some well-known algorithms in term of the solution quality, robustness and space distribution. It provides a new algorithm for solving complex optimization problems.},
  archive      = {J_EAAI},
  author       = {Yingjie Song and Gaoyang Zhao and Bin Zhang and Huayue Chen and Wuquan Deng and Wu Deng},
  doi          = {10.1016/j.engappai.2023.106004},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106004},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced distributed differential evolution algorithm for portfolio optimization problems},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a deep learning-based unified approach for
structural damage detection, localisation and quantification.
<em>EAAI</em>, <em>121</em>, 106003. (<a
href="https://doi.org/10.1016/j.engappai.2023.106003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonic guided waves have been extensively employed for characterising structural damage thanks to their sensitivity to defects. Although they are easy to excite and acquire, heavy processing is often required to extract single-valued indicators of damage presence, or damage indices, from the acquired signals. Traditionally, damage indices have been elaborated through tomographic algorithms to generate damage probability maps, even though limitations affect the performance of such approach. Recently, the potentialities of machine learning have been leveraged to improve the accuracy of frameworks processing guided waves for damage diagnosis. However, most methods still require extracting damage indices from the acquired signals, which may bring to loss of diagnostic information and reduced accuracy. Furthermore, damage position and extent are usually roughly estimated through classification, while regression should be employed instead. In this context, this work aims (i) to test the capabilities of different supervised machine learning algorithms to localise and quantify damage through regression and (ii) to carry out a critical discussion about possible limitations of using damage indices instead of unprocessed signals. Results are compared to identify which algorithm performs better and if machine learning can improve the accuracy of damage diagnosis compared to traditional imaging methods. An experimentally validated numerical case study was used to test the capabilities of the proposed machine learning-based framework and to bring evidence of the accuracy of the algorithms involved to characterise damage with properties not seen during training.},
  archive      = {J_EAAI},
  author       = {Luca Lomazzi and Marco Giglio and Francesco Cadini},
  doi          = {10.1016/j.engappai.2023.106003},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106003},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards a deep learning-based unified approach for structural damage detection, localisation and quantification},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction and control of water quality in recirculating
aquaculture system based on hybrid neural network. <em>EAAI</em>,
<em>121</em>, 106002. (<a
href="https://doi.org/10.1016/j.engappai.2023.106002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Recirculating Aquaculture Systems (RAS), the control of water quality indices remains essential to survival and growth of aquaculture objects. This requires effect prediction of future water status in advance, which can be adopted to help the generation of following control strategies. However, conventional methods of water quality prediction were mostly dependent on redundant parameters of model, which leads to inefficiency and low accuracy. In addition, the complexity of the RAS multi-units requires intelligent control of the water quality unit. Thus, a prediction and control framework for predicting water quality in RAS is proposed in this paper. Specifically, a hybrid deep learning structure which combines the Convolutional Neural Network (CNN), Gated Recurrent Unit (GRU) and Attention mechanism is presented. To begin with, the CNN is utilized to extract local features for different timestamped water quality parameter. After the local features have been extracted, the proposed GRU model replicates the global sequential features of the parameters. The attention mechanism is then applied to focus on more critical features to promote the efficiency and accuracy of prediction. Finally, to demonstrate the efficiency and stability of the prediction and control framework with the mixture of CNN, GRU and Attention (PC-CGA), multiple groups of experiments and evaluations are carried out in a medium size RAS.},
  archive      = {J_EAAI},
  author       = {Junchao Yang and Lulu Jia and Zhiwei Guo and Yu Shen and Xianwei Li and Zhenping Mou and Keping Yu and Jerry Chun-Wei Lin},
  doi          = {10.1016/j.engappai.2023.106002},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106002},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction and control of water quality in recirculating aquaculture system based on hybrid neural network},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compared-neighborhood based image dehazing for improved
visibility. <em>EAAI</em>, <em>121</em>, 106001. (<a
href="https://doi.org/10.1016/j.engappai.2023.106001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hazing is the degradation of photographic quality due to light attenuation by mist or suspended particles. This paper presents solutions to two shortcomings of existing haze-removal techniques. One shortcoming is that pixels often get zeroed out in the dehazing process, which suppresses edges and features. The other is that the assumption of homogeneity of features and properties in input images during dehazing reduces the resolution of features and textures. A solution that considers how feature and edge visibility, which are primarily disrupted by noise, is provided. This noise is responsible for the lack of distinction between local and global pixel neighborhoods. An attenuation coefficient that helps to minimize pixel distortion is proposed. This coefficient is sensitive to local relative pixel intensity and prevents the pixels from being zeroed out in the context of certain local or global neighborhoods. The proposed technique is implemented via the existing dual-stream network based on a CNN with the block-greedy algorithm. The qualitative and quantitative evaluation based on 117 images shows 75% improvement in haze density ζ , 90% increase in edge visibility e , and 150% improvement in the peak-signal-to-noise ratio (PNR), and 95% increase in structural similarity index measure (SSIM) compared to the original hazed image. These show a remarkable improvement compared to the existing state-of-the-art methods. The shortcoming is a need for color improvement, which can be studied further in future studies.},
  archive      = {J_EAAI},
  author       = {Fayadh Alenezi},
  doi          = {10.1016/j.engappai.2023.106001},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106001},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Compared-neighborhood based image dehazing for improved visibility},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Condition monitoring of wind turbines with the
implementation of spatio-temporal graph neural network. <em>EAAI</em>,
<em>121</em>, 106000. (<a
href="https://doi.org/10.1016/j.engappai.2023.106000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of wind turbines is critical to ensure their long-term stable operation. With the benefit of deep learning techniques, WTs’ health status information can be mined more fully from supervisory control and data acquisition data. However, these deep learning-based condition monitoring methods have the following limitations. (1) They only can process regularly structured data, such as pictures, rather than general domains. (2) The spatial properties of wind turbines multi-sensor networks, i.e., connectivity and globality, are neglected. To overcome the above limitations, a new condition monitoring network named spatio-temporal graph neural network is proposed in this paper. First, the missing value supplement and the selection of variables with maximal information coefficient are applied. Meanwhile, the top-k nearest neighbors is employed to construct graphs. Then, a spatio-temporal block is established based on graph convolution networks and gated recurrent unit. By stacking multiple spatio-temporal blocks, the monitoring variables are estimated by feeding the learned features to the last prediction layer. Lastly, the proposed spatio-temporal graph neural network is validated using real wind farm supervisory control and data acquisition data. The experimental results indicate that the proposed method can detect the early abnormal operation efficiently and is superior to some existing methods, which can promote the utilization of renewable energy.},
  archive      = {J_EAAI},
  author       = {Jiayang Liu and Xiaosun Wang and Fuqi Xie and Shijing Wu and Deng Li},
  doi          = {10.1016/j.engappai.2023.106000},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {106000},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Condition monitoring of wind turbines with the implementation of spatio-temporal graph neural network},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal fog node selection based on hybrid particle swarm
optimization and firefly algorithm in dynamic fog computing services.
<em>EAAI</em>, <em>121</em>, 105998. (<a
href="https://doi.org/10.1016/j.engappai.2023.105998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing is a qualifiedly roseate technology introduced to support latency-sensitive and mission-critical applications by bringing resources closer to the end users. To exploit the full potentials of this auspicious technology, it is important to select optimal fog nodes for secured service provisioning. Therefore, in this work, an optimal fog node selection is formulated as a multi-objective optimization problem. To solve this problem, an efficient selection strategy based on improved particle swarm optimization (PSO) and modified firefly algorithm (FA) is developed. This study considers two important objectives that have not been optimized in the previous works: trust and rate of sojourn, in addition to remaining node capacity and energy consumption. The linear weighted-sum approach is used to aggregate the individual objective functions, after which the Best–worst method (BWM) is used to determine the weight vector of the aggregated function. The impact of the variation in the weight values of the most sensitive objective indicate that in the worst-case scenario, the proposed model is robust and insensitive with an improvement of about 42.16%–50.02% over the related methods. Moreover, we conduct an experimental simulation of the proposed selection strategy as well as comparative analysis with the state-of-the-art algorithms using six performance metrics. The results show that the proposed hybrid PSO-FA achieves a higher accuracy and faster convergence. The proposed solution also records an improvement of about 18.64%–69.45% in resource utilization, 10.94%–40.45% in energy consumption, 12.50%–75% in trust violation, 4.94%–31.12% in computation delay, and 24.71%–37.7% in makespan over the related advanced algorithms.},
  archive      = {J_EAAI},
  author       = {Sunday Oyinlola Ogundoyin and Ismaila Adeniyi Kamil},
  doi          = {10.1016/j.engappai.2023.105998},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105998},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal fog node selection based on hybrid particle swarm optimization and firefly algorithm in dynamic fog computing services},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy efficiency and delay determinacy tradeoff in energy
harvesting-powered zero-touch deterministic industrial M2M
communications. <em>EAAI</em>, <em>121</em>, 105997. (<a
href="https://doi.org/10.1016/j.engappai.2023.105997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data transmission for Industrial Internet of Things (IIoTs) is of the utmost importance, especially in the Industry 5.0 era, where human–machine collaboration is increasingly intensive. On the one hand, as a key characteristic for Industry 5.0, deterministic transmission aims to ensure the data arrive at destination devices accurately, has attracted remarkable attentions. On the other hand, energy efficiency problem is another major concern in Industry 5.0 since the massive Machine-Type Devices (MTDs). Consequently, in this paper, we investigate the tradeoff between energy efficiency and delay determinacy in energy harvesting-powered Zero-Touch Deterministic Industrial Machine-to-Machine (ZT-DI-M2M) communications. In particular, we first derive the probability of the transmission delay falling within a certain time window to characterize the delay determinacy and then figure out the relationship between delay determinacy and the energy efficiency by taking the system control performance into account. After that, in order to model the uncertainty of the stochastic environment, we formulate the problem as a stochastic game by jointly considering transmission power control, frequency spectrum allocation and the selection of base stations. Afterwards, a random graph-based sparse Long Short-Term Memory (LSTM) network is proposed to solve the optimization problem while reducing the computational complexity. Finally, numerical result demonstrates that the proposed sparse LSTM algorithm enables to achieve a specific delay determinacy with a higher energy efficiency as compared to Deep Q-Learning Network (DQN) and Deep Deterministic Policy Gradient (DDPG) algorithms. In addition, we also analysis the influence of sparse coefficient and the size of time window on the relationship between energy efficiency and delay determinacy.},
  archive      = {J_EAAI},
  author       = {Yi-Han Xu and Qi-Ming Sun and Xiao-Ren Xu and Wen Zhou and Gang Yu},
  doi          = {10.1016/j.engappai.2023.105997},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105997},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy efficiency and delay determinacy tradeoff in energy harvesting-powered zero-touch deterministic industrial M2M communications},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). A sketch semantic segmentation method based on
point-segment level interaction. <em>EAAI</em>, <em>121</em>, 105996.
(<a href="https://doi.org/10.1016/j.engappai.2023.105996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch semantic segmentation is a basic computer vision task, which poses great challenges due to the abstraction of sketches and different drawing styles. In this paper, we propose a sketch semantic segmentation method based on point-segment level interaction. Specifically, an enhanced local feature aggregation (ELFA) module is developed based on two kinds of distance information between the neighboring points/segments (NPs/NSs) and the corresponding center points/segments (CPs/CSs). The ELFA module not only extracts local features adequately, but also takes into account the different effects of the NPs/NSs on the corresponding CPs/CSs. Based on the ELFA module, a point-level branch and a segment-level branch are established to encode the semantics of sketches from a point level and a segment level respectively, which makes the features extracted from the point-level branch complementary to those extracted from the segment-level branch. Further, a point-segment level interaction (PSLI) module is designed to interchange the information of the two levels and to reduce the losing of some important semantic details caused by feature selection of multiple stages. The PSLI module can be placed in several stages, which is beneficial to retain and utilize the useful details. Finally, point-level features and segment-level features are fused to obtain the semantic segmentation result. Extensive experiments on SPG and SketchSeg-150K show that the proposed method achieves state-of-the-art performance.},
  archive      = {J_EAAI},
  author       = {Shihui Zhang and Lei Wang and Xueqiang Han and Shi Wang},
  doi          = {10.1016/j.engappai.2023.105996},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105996},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A sketch semantic segmentation method based on point-segment level interaction},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fusing domain knowledge and reinforcement learning for home
integrated demand response online optimization. <em>EAAI</em>,
<em>121</em>, 105995. (<a
href="https://doi.org/10.1016/j.engappai.2023.105995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electricity–gas integrated household energy systems (HESs) expose obvious system uncertainties, requiring their integrated demand response (IDR) programs to be able to adapt automatically and quickly to system changes. Deep Reinforcement Learning (DRL) methods, though having been proven promising to tackle such problems, are typically not efficient in learning from random explorations. This paper proposes a method based on DRL with HESIDR knowledge penetration. By interpreting the domain IDR knowledge as a set of control rules, the DRL agent gains learning samples from knowledge-based exploration in addition to the traditional exploration–exploitation tradeoff. Correspondingly, we develop a cooperation scheme for action selection and replay sampling, which is based on exponential probability functions to balance the penetration of knowledge-based exploration, random exploration and policy exploitation. We conduct case studies in a typical home multi-energy system environment. After determining parameters in the exponential probability functions, the learning and cost reduction performance of the proposed algorithm was tested. The results show that the method proposed in the present study spends 48.78% less training time than the standard DQN, which enables few-minute optimization on a lightweight PC. Also, the proposed method can further reduce energy bills by 26.17% compared to the uncontrolled scenario and by 9.88% to the integrated rule-based controller.},
  archive      = {J_EAAI},
  author       = {Zhiyao Zhang and Yongxin Su and Mao Tan and Rui Cao},
  doi          = {10.1016/j.engappai.2023.105995},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105995},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fusing domain knowledge and reinforcement learning for home integrated demand response online optimization},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative offensive decision-making for soccer robots
based on bi-channel q-value evaluation MADDPG. <em>EAAI</em>,
<em>121</em>, 105994. (<a
href="https://doi.org/10.1016/j.engappai.2023.105994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of discrete–continuous hybrid action decision-making are more common in real life. However, there are fewer studies on multi-robot deep reinforcement learning based on parameterized action spaces. Cooperative decision-making for soccer robots is the representative task for studying it. In this paper, the reward function is desired to guide the learning of cooperative offensive for soccer robots. Hence, the shooting angle reward is designed to improve the scoring rate based on the basic reward function. Moreover, a MADDPG network structure based on bi-channel Q-value estimation (BI-MAPDDPG) is proposed. Two channels of Critic network with the discrete action weight deal with coupling between the discrete action and continuous action parameters well. Finally, simulation results show that soccer robots’ cooperative offensive decision-making based on BI-MAPDDPG is robust and scalable.},
  archive      = {J_EAAI},
  author       = {Lingli Yu and Keyi Li and Shuxin Huo and Kaijun Zhou},
  doi          = {10.1016/j.engappai.2023.105994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cooperative offensive decision-making for soccer robots based on bi-channel Q-value evaluation MADDPG},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review of wearable sensors based fall-related recognition
systems. <em>EAAI</em>, <em>121</em>, 105993. (<a
href="https://doi.org/10.1016/j.engappai.2023.105993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are an important factor in significantly deteriorating quality of life of older adults, consequently leading to both physical and psychological harm. A wearable-based fall-related recognition system (WFRS) indeed facilitates the prediction, detection, and classification of fall events in helping fallers. Previous studies have provided a relatively comprehensive introduction to WFRSs from the perspective of sensor types and recognition algorithms. However, while these studies provide a clear technical direction, how to choose the appropriate technology for each phase of the experiment is a stumbling block for newly interested researchers. Accordingly, a comprehensive review article covering the mainstream technologies of WFRSs is imperative and meaningful. This review analyzes 48 state-of-the-art researches in WFRSs from three databases (i.e., IEEE Explorer, ScienceDirect, and MDPI) and introduces the pipeline techniques that consist of data acquisition, preprocessing, feature extraction, model training, and evaluation. Specifically, we first analyze the pros and cons of the use of different number of sensors for data collection. We then introduce the widely used preprocessing techniques including filtering and data augmentation. Afterwards, we detail the extraction of various features and illustrate methods for the selection, training, and evaluation of fall recognition models. We finally discuss factors affecting the overall performance of a model and offer suggestions for future research.},
  archive      = {J_EAAI},
  author       = {Jiawei Liu and Xiaohu Li and Shanshan Huang and Rui Chao and Zhidong Cao and Shu Wang and Aiguo Wang and Li Liu},
  doi          = {10.1016/j.engappai.2023.105993},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105993},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of wearable sensors based fall-related recognition systems},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An outranking approach with 2-tuple linguistic fermatean
fuzzy sets for multi-attribute group decision-making. <em>EAAI</em>,
<em>121</em>, 105992. (<a
href="https://doi.org/10.1016/j.engappai.2023.105992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 2-tuple linguistic Fermatean fuzzy set is an effective tool that combines the advantages of the reliable 2-tuple linguistic model with Fermatean fuzzy set. We aim to develop novel decision-making techniques based on 2TLFFS that can handle the situations in which linguistic labels are assigned to given data. The main objective of this study is to investigate ELECTRE II method for group decision-making in 2-tuple linguistic Fermatean fuzzy context and explain its implementation. The first phase employs suitable 2TLFF aggregation operator to assemble the expert’s 2TLFF judgments on each alternative and set of criteria. The method then introduces three different sets (2TLFF concordance, 2TLFF indifferent and 2TLFF discordance sets) by pairwise comparison of alternatives. After that, the strong and weak outranking relations are developed through the comparison of concordance and discordance indices with threshold values (three concordance and two discordance levels). The strong and weak outranking graphs visually represent outranking relations that are ultimately investigated through a systematic iterative process that results in the alternatives’ forward, reverse, and average rankings. A flowchart is developed to comprehend the algorithm of 2TLFF-ELECTRE II conveniently. A numerical example for the selection of optimal Extract, Transform and Load software for business intelligence describes the proposed decision-making technique. A thorough comparison with 2TLFF-CODAS and existing aggregation operators is carried out to illustrate the validity and supremacy of the proposed technique.},
  archive      = {J_EAAI},
  author       = {Muhammad Akram and Rabia Bibi and Muhammet Deveci},
  doi          = {10.1016/j.engappai.2023.105992},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105992},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An outranking approach with 2-tuple linguistic fermatean fuzzy sets for multi-attribute group decision-making},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep stacked pinball transfer matrix machine with its
application in roller bearing fault diagnosis. <em>EAAI</em>,
<em>121</em>, 105991. (<a
href="https://doi.org/10.1016/j.engappai.2023.105991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the matrix-based classification methods have played an extremely important role to mechanical fault diagnosis. However, the traditional matrix-based classification methods are mostly shallow classifiers, which are difficult to obtain the deep-seated sensitive features of vibration signals. To learn and extract low-rank structure information, a new deep stacked pinball transfer matrix machine (DSPTMM) is proposed to enhance the performance of traditional shallow matrix-based classifiers, which takes the stacking generalization principle as the main idea. In DSPTMM, a pinball transfer module (PTM) is constructed as the basic module of deep stacking network, in which the pinball loss is used to achieve an enhanced noise robustness. Specifically, PTM performs the function to obtain the weak prediction of the previous module, and the original results of previous weak prediction are modified by random projection and then will be input as a new feature set in the next module. Therefore, DSPTMM has a better classification performance and can modeled without enough annotation samples. Extensive experiments are carried out on two different datasets of roller bearing, and the results of experiment show that the proposed DSPTMM can use limited samples to establish the accurate model.},
  archive      = {J_EAAI},
  author       = {Haiyang Pan and Li Sheng and Haifeng Xu and Jinde Zheng and Jinyu Tong and Limin Niu},
  doi          = {10.1016/j.engappai.2023.105991},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105991},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep stacked pinball transfer matrix machine with its application in roller bearing fault diagnosis},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soil seismic response modeling of KiK-net downhole array
sites with CNN and LSTM networks. <em>EAAI</em>, <em>121</em>, 105990.
(<a href="https://doi.org/10.1016/j.engappai.2023.105990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of soil seismic response is necessary for geotechnical engineering. The conventional physics-based models such as the finite element method (FEM) usually fail to obtain accurate predictions due to the model assumption and parameter uncertainties. And the physics-based models are computationally expensive. This study proposes deep learning models to develop data-driven surrogate models for the prediction of soil seismic response based on the recorded ground motions from KiK-net downhole array sites. Two kinds of advanced neural networks, convolution neural network (CNN) and long short-term memory (LSTM) neural network, are applied in this framework respectively. These models do not rely on any prior knowledge about the soil site. The performance of the deep learning models is demonstrated through both numerical and recorded examples. Compared with the state-of-art FEM models, the proposed models could achieve better prediction performance with higher efficiency. The average prediction error is reduced by more than 40% in time domain and 30% in frequency domain. Even though great variability exists during the propagation of seismic in the reality, the models can still get satisfactory predictions.},
  archive      = {J_EAAI},
  author       = {Lin Li and Feng Jin and Duruo Huang and Gang Wang},
  doi          = {10.1016/j.engappai.2023.105990},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105990},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soil seismic response modeling of KiK-net downhole array sites with CNN and LSTM networks},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The role of artificial intelligence-driven soft sensors in
advanced sustainable process industries: A critical review.
<em>EAAI</em>, <em>121</em>, 105988. (<a
href="https://doi.org/10.1016/j.engappai.2023.105988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the predicted depletion of natural resources and alarming environmental issues, sustainable development has become a popular as well as a much-needed concept in modern process industries. Hence, manufacturers are quite keen on adopting novel process monitoring techniques to enhance product quality and process efficiency while minimizing possible adverse environmental impacts. Hardware sensors are employed in process industries to aid process monitoring and control, but they are associated with many limitations such as disturbances to the process flow, measurement delays, frequent need for maintenance, and high capital costs. As a result, soft sensors have become an attractive alternative for predicting quality-related parameters that are ‘hard-to-measure’ using hardware sensors. Due to their promising features over hardware counterparts, they have been employed across different process industries. This article attempts to explore the state-of-the-art artificial intelligence (Al)-driven soft sensors designed for process industries and their role in achieving the goal of sustainable development. First, a general introduction is given to soft sensors, their applications in different process industries, and their significance in achieving sustainable development goals. AI-based soft sensing algorithms are then introduced. Next, a discussion on how AI-driven soft sensors contribute toward different sustainable manufacturing strategies of process industries is provided. This is followed by a critical review of the most recent state-of-the-art AI-based soft sensors reported in the literature. Here, the use of powerful AI-based algorithms for addressing the limitations of traditional algorithms, that restrict the soft sensor performance is discussed. Finally, the challenges and limitations associated with the current soft sensor design, application, and maintenance aspects are discussed with possible future directions for designing more intelligent and smart soft sensing technologies to cater the future industrial needs.},
  archive      = {J_EAAI},
  author       = {Yasith S. Perera and D.A.A.C. Ratnaweera and Chamila H. Dasanayaka and Chamil Abeykoon},
  doi          = {10.1016/j.engappai.2023.105988},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105988},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The role of artificial intelligence-driven soft sensors in advanced sustainable process industries: A critical review},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wind speed interval prediction based on multidimensional
time series of convolutional neural networks. <em>EAAI</em>,
<em>121</em>, 105987. (<a
href="https://doi.org/10.1016/j.engappai.2023.105987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power, as an economical and clean energy source, has rapidly infiltrated into modern power grids. Wind speed prediction is a pivotal technology for wind power integration, which has attracted much attention from researchers and practitioners. Nevertheless, traditional methods only focus on point prediction, which is far from meeting the requirements of power system risk assessment and risk control. To fill this gap, we propose an interval prediction and analysis system based on data preprocessing, deep learning, convolutional neural networks, and interval prediction. It can effectively predict and analyze the uncertainty in short-term wind speeds. First, an original wind speed sequence is divided into high-frequency and low-frequency data using a data preprocessing strategy. After deleting the high-frequency noise data, the denoised multidimensional time series is entered as input into an optimized convolutional neural network. Subsequently, the lower and upper bounds of the interval prediction are obtained using the interval construction principle and variance of the training data set. To verify the effectiveness of the proposed hybrid system, a 10 min wind speed data set of the Shandong wind farm in China is used as an example for analysis. The experimental results show that the proposed hybrid prediction system can not only effectively predict the variation trend of wind speed series, but also accurately predict the local characteristics and volatility of wind speed with strong randomness.},
  archive      = {J_EAAI},
  author       = {Jiyang Wang and Zhiwu Li},
  doi          = {10.1016/j.engappai.2023.105987},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105987},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wind speed interval prediction based on multidimensional time series of convolutional neural networks},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel fuzzy group decision-making approach based on CCSD
method for thermal insulation board selection problem: A case study.
<em>EAAI</em>, <em>121</em>, 105986. (<a
href="https://doi.org/10.1016/j.engappai.2023.105986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to buildings’ high energy consumption and environmental impacts, selecting an appropriate thermal insulation board is crucial in reducing energy consumption in an existing building. Therefore, thermal insulation board selection has become an important issue. This study presents a combined fuzzy group decision-making approach that consists of the integrated fuzzy analytic hierarchy process and fuzzy technique for order preference by similarity to ideal solution, the integrated intuitionistic fuzzy analytic hierarchy process and intuitionistic fuzzy technique for order preference by similarity to ideal solution, and intuitionistic fuzzy technique for order preference by similarity to ideal solution for effectively evaluating thermal insulation boards. However, since these three fuzzy decision-making methods can produce different rankings, decision-making is a complex and challenging process for decision-makers. In order to overcome this problem, correlation coefficient and standard deviation method is utilized to construct the final ranking by integrating these approaches using regression statistics, standard deviations, and correlation coefficients between the closeness coefficients of each alternative in the relevant approach. The proposed approach provides an accurate ranking of thermal insulation boards validated through a real-world case study. Furthermore, the sensitivity analysis indicates that the combinations of different levels of criteria and approaches affect the final ranking. According to the study’s findings, the gray expanded polystyrene foam is the most suitable thermal insulation board in the combined fuzzy group decision-making approach.},
  archive      = {J_EAAI},
  author       = {Derya Deliktaş and Ömer Şahinöz},
  doi          = {10.1016/j.engappai.2023.105986},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105986},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel fuzzy group decision-making approach based on CCSD method for thermal insulation board selection problem: A case study},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IoT-based pest detection and classification using deep
features with enhanced deep learning strategies. <em>EAAI</em>,
<em>121</em>, 105985. (<a
href="https://doi.org/10.1016/j.engappai.2023.105985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is an essential source of sustenance. Here, pest detection is very helpful in increasing food quality, and also it helps to increase the country’s economy. Moreover, the rapid infestation of pests and insects may face a serious problem in agricultural yield. In existing works, the images are collected from the IoT sensors for pest detection and classification, but it is not satisfactory to acquire higher results regarding accuracy. To solve this issue, a novel pest detection and classification model is suggested. The major intention of the developed method is to detect and identify pests over crops using an object detection model and enhanced classifier. Initially, the IoT platform is included, where the required data is garnered through agriculture-based IoT sensors. The input images are garnered and fed into the subsequent object detection process. Pest detection is obtained through an optimized Yolov3 model. Here, the hidden neurons are optimized by the Adaptive Energy-based Harris Hawks Optimization (AE-HHO) algorithm. The detected pest images are given to the feature extraction process. The deep feature extraction is utilized with the help of Residual Network50 (ResNet50) and Visual Geometry Group16 (VGG16) models. Then, the classification is performed by Weight Optimized Deep Neural Network (WO-DNN) model. Consequently, the WO-DNN of the weight factor is optimized using the AE-HHO algorithm. Finally, the classified outcome is predicted by the AE-HHO algorithm. Hence, the performance is validated with several measures and compared with existing detection methods. Throughout the analysis, the accuracy and F1-score of the designed method attained 96% and 84%. Thus, the results explore that the suggested method proves better efficiency in pest detection and classification.},
  archive      = {J_EAAI},
  author       = {Prasath B. and Dr. M. Akila},
  doi          = {10.1016/j.engappai.2023.105985},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105985},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IoT-based pest detection and classification using deep features with enhanced deep learning strategies},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design data decomposition-based reference evapotranspiration
forecasting model: A soft feature filter based deep learning driven
approach. <em>EAAI</em>, <em>121</em>, 105984. (<a
href="https://doi.org/10.1016/j.engappai.2023.105984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reference evapotranspiration can cause huge discrepancies in soil moisture and runoff which is responsible for uncertainties in drought warning systems. Reference evapotranspiration (ET o ) is one of the major drought elements that leads to soil dryness, vegetation surfaces and transpiration. An innovative strategy is proposed based on Multivariate Variational Mode Decomposition hybridized with Soft Feature Filter and Gated Recurrent Unit to design MVMD-SoFeFilterGRU to forecast one-day daily ET o at (t+1). Initially, the importance of each predictor was determined using correlation matrix to identify significant lags at (t+1). Next, the intrinsic mode functions (IMFs) in terms of signals were obtained via MVMD to decompose the lags. The SoFeFilter approach was employed to select the most relevant IMFs which were then incorporated into the GRU to construct the MVMD-SoFeFilter-GRU model to forecast one-day ahead daily ETo. For comparison, the LSTM, BiLSTM, RNN, BiRNN, and BiGRU models were combined with MVMD and SoFeFilter to create MVMD-SoFeFilterLSTM, MVMD-SoFeFilterBiLSTM, MVMD-SoFeFilterRNN, MVMD-SoFeFilterBiRNN, and MVMD-SoFeFilterBiGRU models. Further, the results were also compared against the standalone GRU, BiGRU, LSTM, BiLSTM, RNN, and BiRNN models based on goodness-of-fit metrics for two stations in Queensland, Australia. For example, in Gympie station, the MVMD-SoFeFilterGRU model produced highest values of WI E = 0 . 9795 , NS E = 0 . 9234 , LM E = 0 . 7645 , and for Redcliffe station, these metrics are WI E = 0 . 9800 , NS E = 0 . 9257 , LM E = 0 . 7580 . The findings confirm that the MVMD-SoFeFilterGRU is the most precise to forecast one-day ahead ET 0 .},
  archive      = {J_EAAI},
  author       = {Zihao Zheng and Mumtaz Ali and Mehdi Jamei and Yong Xiang and Masoud Karbasi and Zaher Mundher Yaseen and Aitazaz Ahsan Farooque},
  doi          = {10.1016/j.engappai.2023.105984},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105984},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design data decomposition-based reference evapotranspiration forecasting model: A soft feature filter based deep learning driven approach},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting of volumetric flow rate of ergene river using
machine learning. <em>EAAI</em>, <em>121</em>, 105983. (<a
href="https://doi.org/10.1016/j.engappai.2023.105983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, the significance of the estimation of physical parameters has considerably increased; for example, the prediction of water flow rate (WFR) is one of the types that will gain a substantial importance among the others. The predictions of WFR of rivers play a prominent role in the plans and constructions of new water dams, or to operate the ones that were formerly constructed. In this study, a variety of machine learning algorithms have been suggested in the estimations of one-ahead instantaneous measurement of river WFR. In this regard, four different prediction algorithms including long short-term memory (LSTM) neural network, adaptive neuro-fuzzy inference system (ANFIS) with fuzzy c-means (FCM), ANFIS with subtractive clustering (SC), and the ANFIS with grid partition (GP) were initially trained and secondly tested. The study region was selected as Inanli measurement station, which is located on the Ergene River. A cumulative of 134 different models were formed using these algorithms. Instantaneous WFR predictions in terms of WFR data have shown that ANFIS-FCM and ANFIS-SC had given the best statistical error outcomes. Accordingly, the values of 0.34 m 3 /s, 0.72 m 3 /s, and 0.9728 have been found as a result of machine learning establishment corresponding to statistical accuracy results of MAE, RMSE, and R values, respectively. Namely, it has been concluded that error values of the ANFIS-FCM and ANFIS-SC computations have outcome to be sufficiently good. Also, it was concluded and shown in the current study that both tools of the ANFIS can be two efficacious methods to WFR forecasting.},
  archive      = {J_EAAI},
  author       = {Akin Ilhan},
  doi          = {10.1016/j.engappai.2023.105983},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105983},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting of volumetric flow rate of ergene river using machine learning},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid VMD-CNN-GRU-based model for short-term forecasting of
wind power considering spatio-temporal features. <em>EAAI</em>,
<em>121</em>, 105982. (<a
href="https://doi.org/10.1016/j.engappai.2023.105982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable short-term forecasting of wind power is vital for balancing energy and integrating wind power into a grid. A novel hybrid deep learning model is designed in this study to increase the prediction accuracy of short-term wind power forecasting on a wind farm in Jiang County, Shanxi, China. The proposed hybrid deep learning model comprises variable mode decomposition (VMD), convolutional neural network (CNN), and gated recurrent unit (GRU). VMD substantially reduces the volatility of wind speed sequences. CNN automatically extracts complex spatial features from wind power data, and GRU can directly extract temporal features from historical input data. The forecasting accuracy of the combined VMD-CNN-GRU model is higher than that of any single model for wind power. The study used data obtained in 15 min intervals from the wind farm to determine the effectiveness of the proposed model against other advanced models. Compared with the other deep learning models, VMD-CNN-GRU is the best at short-term forecasting, with an RMSE of 1.5651, MAE of 0.8161, MAPE of 11.62%, and R 2 of 0.9964. This method is valuable for practical applications and can be used to maintain safe wind farm operations in the future.},
  archive      = {J_EAAI},
  author       = {Zeni Zhao and Sining Yun and Lingyun Jia and Jiaxin Guo and Yao Meng and Ning He and Xuejuan Li and Jiarong Shi and Liu Yang},
  doi          = {10.1016/j.engappai.2023.105982},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105982},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid VMD-CNN-GRU-based model for short-term forecasting of wind power considering spatio-temporal features},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph convolutional network combining node similarity
association and layer attention for personalized recommendation.
<em>EAAI</em>, <em>121</em>, 105981. (<a
href="https://doi.org/10.1016/j.engappai.2023.105981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although current graph convolutional network (GCN) has achieved competitive performance in personalized recommendation systems, most of existing GCN based recommendation methods mainly rely on user–item interaction data and the fixed association weights of the nodes at different layers, which greatly limit them to further effectively learn the final embedding representation of nodes when interaction data is scarce. This paper proposes a GCN based recommendation model combining node similarity association and layer attention mechanism (NSAGCN) for predicting user–item interactions in personalized recommendation. The proposed NSAGCN model integrates the similarity associations of the same type nodes into a heterogeneous network based on the bipartite graph of user–item interaction to enrich semantic information of the original sparse interaction graph and more effectively learn the node embedding features. In addition, a layer attention strategy is used to aggregate the embeddings from different graph convolutional layers with various association weights according to the proximity to the target nodes. Extensive experiments on three public benchmark datasets (ML-100K, ML-1M, and Book-Crossing) show that the proposed NSAGCN model outperforms state-of-the-art models by an average improvement of 8.58%, 6.91%, and 6.33% in Recall , Precision , and Normalized Discounted Cumulative Gain ( NDCG ), respectively.},
  archive      = {J_EAAI},
  author       = {Linqin Cai and Tingjie Lai and Lingjun Wang and Yanan Zhou and Yu Xiong},
  doi          = {10.1016/j.engappai.2023.105981},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105981},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph convolutional network combining node similarity association and layer attention for personalized recommendation},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybridization in nature inspired algorithms as an approach
for problems with multiple goals: An application on
reliability–redundancy allocation problems. <em>EAAI</em>, <em>121</em>,
105980. (<a
href="https://doi.org/10.1016/j.engappai.2023.105980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on approaching reliability–redundancy allocation problems, using hybrid schemes that consist of individual nature inspired algorithms. The aim is to investigate if hybridization is an efficient way to approach problems with multiple goals. Therefore, known algorithms that have been successfully applied to reliability and redundancy allocation problems in literature are implemented as part of hybrid schemes in this study. The idea behind that is to study whether an efficient hybrid scheme is the outcome of the hybridization of (individual) efficient algorithms. The performance of the nine proposed schemes and the individual algorithms is tested on ten well-known artificial and real-world case studies, from the field of reliability engineering. The numerical results are compared to others from literature highlighting the efficiency of the proposed hybrid schemes and consequently, support the hypothesis that hybridization can enhance the performance of optimization methods. The experimental results demonstrate that among the nine hybrid schemes, the one consisting of Bat Algorithm and Firefly Algorithm shows the best performance.},
  archive      = {J_EAAI},
  author       = {Marios Thymianis and Alexandros Tzanetos and Georgios Dounias and Vasilis Koutras},
  doi          = {10.1016/j.engappai.2023.105980},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105980},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybridization in nature inspired algorithms as an approach for problems with multiple goals: An application on reliability–redundancy allocation problems},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computing fortification games in a tri-level stackelberg
markov chains approach. <em>EAAI</em>, <em>121</em>, 105979. (<a
href="https://doi.org/10.1016/j.engappai.2023.105979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes fortification games (FGs), also known as a defender–attacker–defender games model for planning defenses for an infrastructure system, which would increase that system’s resistance against attacks by intelligent attackers. FG is usually described as a tri-level Stackelberg game in which, at the top level, the defenders choose strategies for some assets to be protected from prospective harm. The attackers resolve an interdiction game at the middle level by disabling the defenders’ maneuvers (strategies). In response, the defenders again choose strategies based on the surviving or partially disabled maneuvers at the innermost level. Our contribution consists of a method for dealing with defender–attacker–defender issues. The goal is to find the Stackelberg equilibria for such a game. The individual goal of first-level leaders is to achieve one of the Nash equilibria for any fixed strategy of the followers and any fixed strategy of the leaders at the innermost level, in order to satisfy the system of inequalities connected to the Nash condition. We present a solution for computing the equilibrium point for a class of tri-level optimization problem, all of which are represented by nonlinear programs. The solution approach is based on the extraproximal programming method reformulation for fortification variables. We show that the method converges to one of the Stackelberg equilibrium points. The FG problem is restricted to a class of time-homogeneous, finite, ergodic and controllable Markov games. Finally, we present an example of a mall application where one of the most crucial considerations is to provide customers, especially families, a secure space.},
  archive      = {J_EAAI},
  author       = {Julio B. Clempner},
  doi          = {10.1016/j.engappai.2023.105979},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105979},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Computing fortification games in a tri-level stackelberg markov chains approach},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parametric unsteady flow modeling by using meta learning.
<em>EAAI</em>, <em>121</em>, 105978. (<a
href="https://doi.org/10.1016/j.engappai.2023.105978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametric unsteady flow modeling plays a significant role in the fluid dynamics, since the unsteady flow problems are usually involved with complex physical phenomena. Currently, in the study of data-driven unsteady flow modeling, the convolutional neural network based autoencoder (CNN-AE) model has been widely used. While, its application in engineering field has been limited due to challenges that the CNNs are expensive to be trained and the generalization performance of CNN-AE model needs to be improved. Therefore, based on the CNN-AE model, a meta-learning framework is introduced in the present work for parametric unsteady flow modeling. Specifically, both the model-agnostic meta-learning (MAML) and the reptile methods are used to learn the correlations between flow fields under various physical parameters. First, a meta-initialization CNN-AE model is established, with the training data-set under various physical parameters. Then, for a new physical parameter, the meta-initialization CNN-AE model will be finetuned by using few snapshots in a new task with limited epochs. Finally, the proposed CNN-AE based meta-learning framework is validated in two canonical unsteady flow problems with moving boundaries, including oscillating cylinder and flapping airfoil. The results have shown that the CNN-AE based meta-leaning framework can greatly accelerate the adaptation of CNN-AE model in new physical parameters, which can greatly enhance the generalization performance of CNN-AE model.},
  archive      = {J_EAAI},
  author       = {Xinshuai Zhang and Fangfang Xie and Tingwei Ji and Changdong Zheng and Hongyu Zheng and Yao Zheng},
  doi          = {10.1016/j.engappai.2023.105978},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105978},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parametric unsteady flow modeling by using meta learning},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving energy-efficient fuzzy hybrid flow-shop scheduling
problem at a variable machine speed using an extended NSGA-II.
<em>EAAI</em>, <em>121</em>, 105977. (<a
href="https://doi.org/10.1016/j.engappai.2023.105977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As environmental problems are increasingly challenging and sustainable development win support among the people, the energy-efficient hybrid flow-shop scheduling problem (HFSP), as a scheduling problem with great application value, has been widely concerned. However, most existing research has focused on deterministic cases and uncertainty is rarely considered in energy-efficient HFSP (EHFSP), especially with various machine speed constraints. Uncertainty is often caused by some uncontrollable factors, such as human factors and ignoring uncertainty will greatly reduce the application value of the problem solutions. In this study, an energy-efficient fuzzy HFSP (EFHFSP) at a variable machine speed is considered and the existing non-dominated sorting genetic algorithm-II (NSGA-II) is extended to minimize fuzzy make-span and total fuzzy energy consumption simultaneously. The computation of total fuzzy energy consumption is given and reverse learning is proposed to produce the initial population. ENSGA-II adopts an effective genetic operator and its parameters ( P c and P m ) are adjustive. A novel strategy based on history information is also used to produce high-quality solutions. Extensive experiments are conducted to test the performance of ENSGA-II. ENSGA-II can provide promising results for EFHFSP.},
  archive      = {J_EAAI},
  author       = {Yi-Jian Wang and Gai-Ge Wang and Fang-Ming Tian and Dun-Wei Gong and Witold Pedrycz},
  doi          = {10.1016/j.engappai.2023.105977},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105977},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving energy-efficient fuzzy hybrid flow-shop scheduling problem at a variable machine speed using an extended NSGA-II},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DEM-AIA: Asymmetric inclination-aware trajectory planner for
off-road vehicles with digital elevation models. <em>EAAI</em>,
<em>121</em>, 105976. (<a
href="https://doi.org/10.1016/j.engappai.2023.105976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning safe and effective trajectories for off-road unmanned ground vehicles (UGV) is a critical Artificial Intelligence (AI) challenge that can benefit from recent advances in digital elevation models (DEM) for readily capturing accurate terrain geometry. Considering path slopes is crucial to preserve stability and assess terrain traversability at feasible speeds to optimize travel time, which is highly dependent on direction (i.e., pitch and roll). In this article, we propose a new DEM-based asymmetric inclination-aware (DEM-AIA) trajectory planner for ground vehicles. The planner is an any-angle variant of the A ⋆ algorithm that computes pitch and roll estimations for each segment crossing cell triangles in the line-of-sight. Furthermore, we define a non-linear velocity constraints function that integrates information about tip-over safety limitations, maximum uphill and downhill slopes for the vehicle, and asymmetric modulation of nominal flat-ground velocity for all pitch and roll combinations. The planner produces a time sub-optimal trajectory with feasible speed references for each segment crossing a cell triangle. Moreover, we provide an extensive experimental analysis of inclination-aware performance on simulated and real-world DEMs as well as a comparison with state-of-the-art path planners adapted to travel-time optimization. An executable version of the planner with parameterizable variations is publicly available.},
  archive      = {J_EAAI},
  author       = {Manuel Toscano-Moreno and Anthony Mandow and María Alcázar Martínez and Alfonso García-Cerezo},
  doi          = {10.1016/j.engappai.2023.105976},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105976},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DEM-AIA: Asymmetric inclination-aware trajectory planner for off-road vehicles with digital elevation models},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wavelet integrated attention network with multi-resolution
frequency learning for mixed-type wafer defect recognition.
<em>EAAI</em>, <em>121</em>, 105975. (<a
href="https://doi.org/10.1016/j.engappai.2023.105975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wafer defect recognition has been an important measure in developing the manufacturing process. In real-life manufacturing, however, defects can be complicated, and their wafer maps are often accompanied by noise. This encourages us to build a noise-robust framework with outstanding performance and sound interpretability on defect recognition. Therefore, this paper chooses discrete wavelet transform for its clear physical meaning and ability of frequency learning. Moreover, it outperforms traditional down-sampling operations in the preservation of fringe information. Based on this, we propose a multiresolution wavelet integrated attention network (MRWA-Net). Specifically, we design a learnable discrete wavelet transform layer (DWT-Layer), which expands convolutional neural network’s (CNN’s) feature learning space to the wavelet domain. This helps the framework procure hidden information from different frequency components and their location information. Furthermore, we utilize different levels of wavelet transform to interpret the images with different resolutions, thus learning features from different perspectives. Additionally, we insert a frequency-location attention module (FLA) to select the useful frequency-location information captured by DWT-Layer. The proposed approach is evaluated on a dataset with 38015 subjects and 38 types of defects and reaches 98.84% accuracy. To demonstrate the noise-robustness of our framework, we further compare it with other state-of-the-art methods on wafer maps with different ratios of additional noise. The results show that our framework excels other methods under all noise ratios and exhibits more notable excellence on data accompanied by a higher ratio of noise. Finally, we present visualizing analysis to demonstrate that the proposed DWT-Layer can learn from different frequency bands and retrieve information with multiple resolutions.},
  archive      = {J_EAAI},
  author       = {Yuxiang Wei and Huan Wang},
  doi          = {10.1016/j.engappai.2023.105975},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105975},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wavelet integrated attention network with multi-resolution frequency learning for mixed-type wafer defect recognition},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic similarity for mobile application recommendation
under scarce user data. <em>EAAI</em>, <em>121</em>, 105974. (<a
href="https://doi.org/10.1016/j.engappai.2023.105974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The More Like This recommendation approach is ubiquitous in multiple domains and consists in recommending items similar to the one currently selected by the user, being particularly relevant when user data is scarce. We studied the impact of using semantic similarity in the context of the More Like This recommendation for mobile applications, by leveraging dense representations in order to infer the similarity between applications, based on their textual fields. Our approach was validated by comparing it to the solution currently in use by Aptoide, a mobile application store, since no benchmarks are available for this specific task. To further evaluate the proposed model, we asked 1262 users to compare the results achieved by both approaches, also allowing us to build an annotated dataset of similar applications. Results show that the semantic representations are able to capture the context of the applications, with more useful recommendations being presented to users, when compared to Aptoide’s current solution. For replication and future research, all the code and data used in this study was made publicly available, including two novel datasets (installed applications for more than one million users, and app user-labeled similarity), the fine-tuned model, and the test platform.},
  archive      = {J_EAAI},
  author       = {João Coelho and Diogo Mano and Beatriz Paula and Carlos Coutinho and João Oliveira and Ricardo Ribeiro and Fernando Batista},
  doi          = {10.1016/j.engappai.2023.105974},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105974},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic similarity for mobile application recommendation under scarce user data},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Geometric score function of pythagorean fuzzy numbers
determined by the reliable information region and its application to
group decision-making. <em>EAAI</em>, <em>121</em>, 105973. (<a
href="https://doi.org/10.1016/j.engappai.2023.105973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pythagorean fuzzy number (PFN) is not only a generalization of general intuitionistic fuzzy number (IFN), but also it can deal with multi-attribute group decision-making problems in a wider range, and it has profound geometric meaning and background. The main works of this article are to establish a unified score function through geometric method on some shortcomings of existing ranking criteria for PFNs, so as to clarify the confusion caused by the widely popular PFNs and IFNs independent ranking for a long time, and apply the proposed method to multi-attribute group decision-making problems, which supplies a new thought for further study of large group decision-making and data statistics problems. Firstly, some conflicts between the two existing rankings for PFNs and IFNs are pointed out, and the major reason for the contradiction are analyzed through counterexamples. Secondly, all IFNs are unified into the PFNs environment according to the coordinate transformation, some fuzzy information distribution contained in each PFN is divided into the reliable information region (RIR) and hesitant information region (HIR) by geometric method. A new geometric score function and ranking method are proposed by the area of reliable information region and hesitation degree in the Pythagorean fuzzy environment, the rationality of the ranking criterion is proved, and the basic properties of geometric score function are obtained by partial derivative and monotonicity. Finally, the new ranking method is applied to the practical problem of multi-attribute information group decision-making through case analysis, it is showed that the proposed method not only overcomes some shortcomings of other methods, but also ends the long-term confusion between IFNs and PFNs ranking separately, and some superiorities of the proposed method are explained by comparative analysis of data.},
  archive      = {J_EAAI},
  author       = {Deli Zhang and Guijun Wang},
  doi          = {10.1016/j.engappai.2023.105973},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105973},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Geometric score function of pythagorean fuzzy numbers determined by the reliable information region and its application to group decision-making},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial neural network-based DTC of an induction machine
with experimental implementation on FPGA. <em>EAAI</em>, <em>121</em>,
105972. (<a
href="https://doi.org/10.1016/j.engappai.2023.105972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct Torque Control (DTC) of Induction Machine (IM) has received increasing attention due to its high performance and low dependence on machine parameters. Recently, intelligent approaches have been proposed to improve the DTC performance, in particular the reduction in the torque and the flux ripples. In this paper, an approach for designing DTC for IMs that is based on Neural Network Control (NNC) is proposed. In this method, an artificial neural network, which can better manage the state of switches, is used instead of the switching table and two hysteresis controllers. The improvement is achieved by reducing the stator flux ripples and the torque ripples in the IM drive. The suggested architecture, which is developed using the VHDL, is designed using the modular architecture and the principles of the parallel architecture. The Direct Torque Neural Control (DTNC) simulation and experimental results are compared with those of the conventional DTC. Results of the comparison demonstrate how the DTNC reduces torque ripples and stator flux ripples. Results from simulation and experiment are used to verify how effectively the suggested control works. The ZC702 SOC, which is Xilinx Board based on Zynq FPGA, has been selected for experimental implementation.},
  archive      = {J_EAAI},
  author       = {Soufien Gdaim and Abdellatif Mtibaa and Mohamed Faouzi Mimouni},
  doi          = {10.1016/j.engappai.2023.105972},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105972},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural network-based DTC of an induction machine with experimental implementation on FPGA},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DNoiseNet: Deep learning-based feedback active noise control
in various noisy environments. <em>EAAI</em>, <em>121</em>, 105971. (<a
href="https://doi.org/10.1016/j.engappai.2023.105971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of active noise control/cancelation (ANC) has increased because of the availability of efficient circuits and computational power. However, most ANC systems are based on traditional linear filters with limited efficiency due to the highly nonlinear and nonstationary nature of various noises. This paper proposes an advanced deep learning–based feedback ANC named DNoiseNet that overcomes the limitations of traditional ANCs and addresses primary and secondary path effects, including acoustic delay. Mathematical operators (i.e., atrous convolution, pointwise convolution, nonlinear activation filters, and recurrent neural networks) learn multilevel temporal features under different noises in various environments, such as construction sites, vehicle interiors, and airplane cockpits. Due to the nature of feedback control using a single error sensor, an estimation of the reference noise signal must be regenerated. In this paper, a multilayer perceptron (MLP) neural network–based secondary path estimator is also proposed to improve the performance of DNoiseNet. In extensive parametric and comparative studies, the DNoiseNet with the MLP secondary path estimator exhibited the best performance in root mean square error and noise attenuation metrics.},
  archive      = {J_EAAI},
  author       = {Young-Jin Cha and Alireza Mostafavi and Sukhpreet S. Benipal},
  doi          = {10.1016/j.engappai.2023.105971},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105971},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DNoiseNet: Deep learning-based feedback active noise control in various noisy environments},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced transfer learning method for rolling bearing fault
diagnosis based on linear superposition network. <em>EAAI</em>,
<em>121</em>, 105970. (<a
href="https://doi.org/10.1016/j.engappai.2023.105970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep transfer learning is used to solve the problem of unsupervised intelligent fault diagnosis of rolling bearings. However, when the data distribution between two domains is different, the existing deep transfer learning models which only rely on the domain-invariant features are not enough to complete the target domain data learning. To solve this problem, an enhanced transfer learning method based on the linear superposition network is proposed for rolling bearing fault diagnosis. This method improves the structure of the one-dimensional convolutional neural network (1D-CNN) by constructing linear superposition convolution blocks. At the same time, the loss function of transfer learning is constructed by using the pseudo-label of the target domain from the network, which enhances the ability of rolling bearing fault feature extraction. Compared with the traditional feature-based transfer learning methods, the proposed enhanced transfer learning method based on the linear superposition network can make the network place more stress on the feature learning of the target domain. Experimental results on the Paderborn University (PU) dataset show that, compared with the improved deep adaptation network (DAN) model, the proposed method improves the average diagnosis accuracy by 21% on six transfer tasks, showing improved bearing fault diagnostic precision.},
  archive      = {J_EAAI},
  author       = {Chunran Huo and Quansheng Jiang and Yehu Shen and Qixin Zhu and Qingkui Zhang},
  doi          = {10.1016/j.engappai.2023.105970},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105970},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced transfer learning method for rolling bearing fault diagnosis based on linear superposition network},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized block-coordinate adaptive algorithms for
nonconvex optimization problems. <em>EAAI</em>, <em>121</em>, 105968.
(<a href="https://doi.org/10.1016/j.engappai.2023.105968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonconvex optimization problems have always been one focus in deep learning, in which many fast adaptive algorithms based on momentum are applied. However, the full gradient computation of high-dimensional feature vector in the above tasks become prohibitive. To reduce the computation cost for optimizers on nonconvex optimization problems typically seen in deep learning, this work proposes a randomized block-coordinate adaptive optimization algorithm, named RAda, which randomly picks a block from the full coordinates of the parameter vector and then sparsely computes its gradient. We prove that RAda converges to a δ -accurate solution with the stochastic first-order complexity of O ( 1 / δ 2 ) , where δ is the upper bound of the gradient’s square, under nonconvex cases. Experiments on public datasets including CIFAR-10, CIFAR-100, and Penn TreeBank, verify that RAda outperforms the other compared algorithms in terms of the computational cost.},
  archive      = {J_EAAI},
  author       = {Yangfan Zhou and Kaizhu Huang and Jiang Li and Cheng Cheng and Xuguang Wang and Amir Hussian and Xin Liu},
  doi          = {10.1016/j.engappai.2023.105968},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105968},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Randomized block-coordinate adaptive algorithms for nonconvex optimization problems},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning configurations of wires for real-time shape
estimation and manipulation planning. <em>EAAI</em>, <em>121</em>,
105967. (<a
href="https://doi.org/10.1016/j.engappai.2023.105967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulation of a wire by its ends requires rapid reasoning of its shape in real-time. A recent development of an analytical model has shown that sensing of the force and torque on one end can be used to determine its shape. However, the model relies on assumptions that may not be met in real world wires and do not take into account gravity and non-linearity of the Force/Torque (F/T) sensor. Hence, the model cannot be applied to any wire with accurate shape estimation. In this paper, we explore the learning of a model to estimate the shape of a wire based solely on measurements of F/T states and without any visual perception. Visual perception is only used for off-line data collection. We propose to train a Supervised Autoencoder with convolutional layers that reconstructs the spatial shape of the wire while enforcing the latent space to resemble the space of F/T. Then, the encoder operates as a descriptor of the wire where F/T states can be mapped to its shape. On the other hand, the decoder of the model is the inverse problem where a desired goal shape can be mapped to the required F/T state. With the same collected data, we also learn the mapping from F/T states to grippers poses. Then, a motion planner can plan a path within the F/T space to a goal while avoiding obstacles. We validate the proposed data-based approach on Nitinol and standard electrical wires, and demonstrate the ability to accurately estimate their shapes.},
  archive      = {J_EAAI},
  author       = {Itamar Mishani and Avishai Sintov},
  doi          = {10.1016/j.engappai.2023.105967},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105967},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning configurations of wires for real-time shape estimation and manipulation planning},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A computation offloading algorithm based on multi-objective
evolutionary optimization in mobile edge computing. <em>EAAI</em>,
<em>121</em>, 105966. (<a
href="https://doi.org/10.1016/j.engappai.2023.105966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For computation offloading problem (COP) in mobile edge computing (MEC), the energy consumption of terminal equipments(TEs) and the delay of mobile equipment applications are two optimization goals. In real life, terminal equipment is dynamic, and their number, mobility, and continuous changes in wireless channels will affect the balance between the mentioned energy consumption and delay. Different from available works, we model the COP in MEC as a dynamic multi-objective problem (DMOP) in this paper, and propose an improved dynamic multi-objective evolutionary optimization based on decomposition (DMOEA/D) to solve it, namely DMOEA/D-COPMEC. In the proposed algorithm, the environmental change is detected by a fixed detector, and whether the current change is similar to the historical change is determined. If so, the difference prediction is used to re-locate the population individual in the new MEC environment, otherwise, the memory-based strategy is used to response environmental change. In MOEA/D, an adaptive weight adjustment strategy based on chain segmentation (CS) is adopted to generate a set of uniformly distributed weight vectors. The simulation results show that the proposed algorithm can better balance the application delay and the terminal energy consumption if there is environment change. The solution set is closer to reality and better than the related algorithms.},
  archive      = {J_EAAI},
  author       = {Zheng-Yi Chai and Xu Liu and Ya-Lun Li},
  doi          = {10.1016/j.engappai.2023.105966},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105966},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A computation offloading algorithm based on multi-objective evolutionary optimization in mobile edge computing},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSRConvNet: Classification of railway track defects using
multi-scale residual convolutional neural network. <em>EAAI</em>,
<em>121</em>, 105965. (<a
href="https://doi.org/10.1016/j.engappai.2023.105965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of an automated rail line defect classification system is of great benefit, as railway tracks must be periodically monitored and inspected to guarantee the safety of rail transportation. In this paper, an effective multi-scale residual convolutional network (MSRConvNet) model is proposed to classify the different types of railway track defects. The skip connections with residual learning blocks are used to increase the effectiveness of the network. The multi-scale convolutions are connected with parallel and two skip connections in the structure to distribute detailed feature maps with each other. Therefore, different scale feature maps can be extracted. The data augmentation method is performed to ensure a balanced class distribution and to eliminate the negative effect of the imbalanced dataset. The proposed model is compared with both benchmark deep learning models and the different variations of the designed network. The results verify that the proposed model can reach superior classification fulfillment, and the MSRConvNet provides an overall accuracy of 99.83%, precision of 99.83%, sensitivity of 99.83%, specificity of 99.94%, F1-score of 99.83%, and Matthew’s correlation coefficient of 99.78% for four defect classes.},
  archive      = {J_EAAI},
  author       = {Hakan Acikgoz and Deniz Korkmaz},
  doi          = {10.1016/j.engappai.2023.105965},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105965},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MSRConvNet: Classification of railway track defects using multi-scale residual convolutional neural network},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep-learning approach for predicting water absorption in
composite pipes by extracting the material’s dielectric features.
<em>EAAI</em>, <em>121</em>, 105963. (<a
href="https://doi.org/10.1016/j.engappai.2023.105963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the mass of liquid absorption in laminated composite structures, that have a direct contact surface with working liquid-like pipes, is very important in order to prevent the sudden collapse of the structures because of the degradations in strength and mechanical properties over time. An electrical capacitance sensor technique has been applied for monitoring the mass of liquid absorption, over the time, in laminated composite pipelines by measuring the change of dielectric characteristics of composite pipelines subjected to an internal hydrostatic pressure load of water and thermal effect. Results show the technique is very effective. However, a major difficulty in utilizing this technique is that it is highly time consuming to be used for monitoring, in addition to the detection efforts that it requires to calculate the mass of liquid absorption that exerts high cost and loss of additional time in monitoring. In this paper, a deep neural network model is used to estimate the mass of liquid absorption in glass fiber reinforced epoxy laminated composite pipelines by extracting the features from datasets from experimental and numerical measurements of the electrical capacitance sensor. The experimental and numerical data used in this paper to train and test the new deep neural network model are collected from the literature and the finite element model of the electrical capacitance sensor system respectively. The results show an excellent agreement between the finite element model data, available experimental data, and those predicted by a deep neural network with an average error of 0.067%, and show that the proposed method achieves satisfactory performance with 86.34% accuracy, 82.83% regression rate and 83.74% F-score. The proposed approach overcomes the difficult problem of saving time and effort to accurately detect the mass of liquid absorption over the time, and provides a promising approach for a wider application of this intelligent model.},
  archive      = {J_EAAI},
  author       = {Wael A. Altabey and Mohammad Noori and Zhishen Wu and Mohamed A. Al-Moghazy and Sallam A. Kouritem},
  doi          = {10.1016/j.engappai.2023.105963},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105963},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep-learning approach for predicting water absorption in composite pipes by extracting the material’s dielectric features},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Thermographic fault diagnosis of electrical faults of
commutator and induction motors. <em>EAAI</em>, <em>121</em>, 105962.
(<a href="https://doi.org/10.1016/j.engappai.2023.105962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the author proposes a fault diagnosis technique for the analysis of thermal images of commutator motors (CMs) and single-phase induction motors (SIMs). The aim of scientific research is to confirm the effectiveness of the proposed technique for the analysis of thermal images of electric motors. Original feature extraction methods: DAMOM (Differences of Arithmetic Mean with Otsu’s Method), DAM20HP (Differences of Arithmetic Mean with 20 Highest Peaks), DAMMH (Differences of Arithmetic Mean with Mean of the histogram), IB (Ignore Binarization). The Nearest Neighbor classifier and Long short-term memory (LSTM) classified feature vectors. The thermal imaging camera was moved 0–1 [m/s 2 ] vertically, during the measurements. Thermal imaging measurements with shivering and analysis are a novelty for fault diagnosis methods. The following conditions of motors were analyzed: healthy commutator motor (HCM), broken rotor coil of the commutator motor (BRCoCM), shorted stator coils of the commutator motor (SSCoCM), healthy single-phase induction motor (HSIM), single-phase induction motor with shorted coils of auxiliary winding (SIMwSCoAW), single-phase induction motor with shorted coils of auxiliary winding, and main winding (SIMwSCoAWaMW). The proposed analysis was successful. The value of A M E C M (Arithmetic mean of the efficiency of recognition) was equal to 100% for the analyzed states of the CM. The value of A M E S I M was in the range of 95.33%–100% for the analyzed states of the SIM. The original perspective of the presented study is to develop techniques of thermal imaging diagnostics. Readers can learn about the subject of thermographic diagnostics of electrical motors. Readers also gain knowledge about the processing of thermal images. A literature review on the diagnostics of electric motors was also presented.},
  archive      = {J_EAAI},
  author       = {Adam Glowacz},
  doi          = {10.1016/j.engappai.2023.105962},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105962},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermographic fault diagnosis of electrical faults of commutator and induction motors},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Applications of machine learning in friction stir welding:
Prediction of joint properties, real-time control and tool failure
diagnosis. <em>EAAI</em>, <em>121</em>, 105961. (<a
href="https://doi.org/10.1016/j.engappai.2023.105961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) methods have received immense attention as potential models for modeling different manufacturing systems. This paper presents a comprehensive review on the applications of ML methods in friction stir welding (FSW) field. Five main topics have been discussed: prediction of the joint properties, integration between ML and finite element methods, real-time control of FSW process, tool failure diagnosis, and incorporation between metaheuristic optimization techniques and ML methods. The common used ML methods such as multi-linear regression, K-nearest neighbor, random forest algorithm, Gaussian process regression, artificial neural network, support vector machine, radial basis function neural network, fuzzy system, adaptive neuro-fuzzy inference system, and random vector functional link are explained. Then, different statistical measures used to evaluate the performance of ML methods are presented. Finally, the applications of ML methods in FSW field are discussed. Important conclusions are drawn and future prospects are suggested.},
  archive      = {J_EAAI},
  author       = {Ammar H. Elsheikh},
  doi          = {10.1016/j.engappai.2023.105961},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105961},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Applications of machine learning in friction stir welding: Prediction of joint properties, real-time control and tool failure diagnosis},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A meta-path graph-based graph homogenization framework for
machine fault diagnosis. <em>EAAI</em>, <em>121</em>, 105960. (<a
href="https://doi.org/10.1016/j.engappai.2023.105960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data-driven methods have swept the field of machine fault diagnosis by merits of modeling relationships between samples. Their performance is highly affected by the constructed graphs quality. Compared to the single-sensor data, multi-sensor data can provide more information, so as to construct higher-quality graphs. However, existing graph data-driven diagnosis methods using multiple sensors still have two limitations. Firstly, heterogeneous multi-sensor data are mainly processed as homogeneous data, ignoring the heterogeneity of heterogeneous multi-sensor data. Secondly, the heterogeneous graph is often with a complex graph structure, and consumes much computational cost to learn. To overcome these limitations, A meta-path graph-based graph homogenization framework for machine fault diagnosis is proposed. Heterogeneous multi-sensor data are converted into the heterogeneous graph, modeling the heterogeneity of heterogeneous multi-sensor data. Further, instead of directly inputting the heterogeneous graph into graph deep learning model, a heterogeneous graph homogenization framework is designed to generate a meta-path graph, reducing the complexity of graph structure and improving the graph quality. Finally, a graph convolutional network is used for graph feature learning, obtaining the diagnosis results. Verification experiments show that the proposed method performs better than machine learning-based and graph deep learning-based methods. In addition, discussive experiments show that the meta-path graph is with lower complexity in graph structure and a higher clustering accuracy than single-sensor data-based K-nearest neighborhood graph.},
  archive      = {J_EAAI},
  author       = {Chaoying Yang and Jie Liu and Kaibo Zhou and Xiaohui Yuan and Xingxing Jiang},
  doi          = {10.1016/j.engappai.2023.105960},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105960},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A meta-path graph-based graph homogenization framework for machine fault diagnosis},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SWSEL: Sliding window-based selective ensemble learning for
class-imbalance problems. <em>EAAI</em>, <em>121</em>, 105959. (<a
href="https://doi.org/10.1016/j.engappai.2023.105959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For class-imbalance problems, traditional supervised learning algorithms tend to favor majority instances (also called negative instances). Therefore, it is difficult for them to accurately identify the minority instances (also called positive instances). Ensemble learning is a common method to solve the class-imbalance problem. They build multiple classifier systems on the training dataset to improve the recognition accuracy of minority instances. Sliding window is a commonly used method for processing data stream. Few researchers have used sliding windows to select majority instances and construct ensemble learning models. Traditional ensemble learning methods use some or all of the majority instances for modeling by oversampling or undersampling. However, they also inherit the drawbacks of the preprocessing methods. Therefore, in this paper, we try to use similarity mapping to construct pseudo-sequences of majority instances. Then, according to the sliding window idea, we fully use all existing majority instances, and a novel sliding window-based selective ensemble learning method (SWSEL) is proposed to deal with the class-imbalance problem. This method uses the idea of distance alignment in multi-view alignment to align the centers of the minority instances with the majority instances, and slide to select the majority instances on the sequence of pseudo-majority instances. In addition, to prevent too many classifiers from leading to long running times, we use distance metric to select a certain number of base classifiers to build the final ensemble learning model. Extensive experimental results on various real-world datasets show that using SVM, MLP and RF as the base classifier, SWSEL achieves a statistically significant performance improvement on two evaluation metrics, AUC and G-mean, compared to state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Qi Dai and Jian-wei Liu and Jia-Peng Yang},
  doi          = {10.1016/j.engappai.2023.105959},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105959},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SWSEL: Sliding window-based selective ensemble learning for class-imbalance problems},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced tunicate swarm algorithm for optimizing shape of c2
RQI-spline curves. <em>EAAI</em>, <em>121</em>, 105958. (<a
href="https://doi.org/10.1016/j.engappai.2023.105958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shape optimization of interpolation curves is a crucial and intractable technique in scientific visualization, data analysis, manufacturing and computer-aided design and is potentially used in many engineering fields involving geometric modeling. In this paper, an enhanced hybrid tunicate swarm algorithm (TSA) is used to optimize the shape of complex rational quartic interpolation spline (RQI-spline, for short) curves. Firstly, to modify the shape of the interpolation curve more flexibly, a novel multi-parameter RQI-spline curve with local and global shape parameters is presented. Then the corresponding combined RQI-spline curves with 2th-order parametric continuity denoted C 2 are constructed. In addition, considering that the optimization of shape parameters for RQI-spline curves is a complex optimization problem, an enhanced hybrid version of TSA called DQTSA is developed. The introduction of differential evolution and quadratic interpolation strategies enhances the ability of the TSA to jump out of local minima, thus effectively solving the shape parameter optimization of RQI-spline curves. DQTSA and some popular comparison algorithms are used to solve the set of 23 benchmark functions and CEC2019 test functions. The experimental results show that DQTSA performs the best in 7 (30.43%) of the 23 test problems, while DQTSA performs the best in 3 of the 10 CEC2019 suites. Meanwhile, applying DQTSA to three engineering optimization problems, the best value, mean and significantly better than other search algorithms are obtained from 20 optimized designs, which verifies the applicability and stability of DQTSA in solving engineering optimization problems. Finally, the proposed DQTSA is used to solve the shape optimization model for the combined C 2 RQI-spline curve. Numerical results find that DQTSA obtains the optimal RQI-spline curve with minimum energy. Some representative numerical examples illustrate that DQTSA is a potentially excellent algorithm for solving curve optimization.},
  archive      = {J_EAAI},
  author       = {Gang Hu and Jiaoyue Zheng and Xiaomin Ji and Xinqiang Qin},
  doi          = {10.1016/j.engappai.2023.105958},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105958},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced tunicate swarm algorithm for optimizing shape of c2 RQI-spline curves},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantized kernel recursive minimum error entropy algorithm.
<em>EAAI</em>, <em>121</em>, 105957. (<a
href="https://doi.org/10.1016/j.engappai.2023.105957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a online vector quantization (VQ) method based on the kernel recursive minimum error entropy (KRMEE) algorithm. According to information theoretic learning (ITL), the minimum error entropy criterion (MEE) is robust and can effective resistance to non-Gaussian noise. By combining the kernel recursive least squares (KRLS) algorithm with MEE criterion, KRMEE algorithm has been generated, which has excellent performance in non-Gaussian environments. However, with the size of data increases, the computational complexity will raise. We propose a quantized to solve this problem, the input space of the algorithm is quantized to suppress the linear growth radial basis function (RBF) network in kernel adaptive filtering (KAF). The VQ method is different from novelty criterion (NC), approximate linear dependency (ALD) criterion, and other sparsity methods, the online VQ method need to construct the dictionary, and calculate the distance by Euclidean norm. We propose a novel quantized kernel recursive minimum error entropy (QKRMEE) algorithm by combining VQ method with KRMEE algorithm, and update the solution with a recursive algorithm. In Mackey-Glass time series and a real-world datasets, Monte Carlo simulation experiments show that the proposed algorithm achieves better predictive performance in non-Gaussian noise environment. Meanwhile, the algorithm can restrain the growth of RBF network well, thus reducing the computational complexity and memory consumption effectively.},
  archive      = {J_EAAI},
  author       = {Wang Jiang and Yuyi Gao and Yue He and Shanmou Chen},
  doi          = {10.1016/j.engappai.2023.105957},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105957},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantized kernel recursive minimum error entropy algorithm},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A spatial squeeze and multimodal feature fusion attention
network for multiple tumor segmentation from PET–CT volumes.
<em>EAAI</em>, <em>121</em>, 105955. (<a
href="https://doi.org/10.1016/j.engappai.2023.105955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tumor segmentation is a key step in computer-aided diagnosis. The PET–CT co-segmentation method combines the high sensitivity of PET images and the anatomical information of CT images. For whole-body multiple tumors, such as soft tissue sarcoma, lymphoma, etc., due to the different lesion location and size, it is necessary to segment the tumor area according to the whole body anatomical information. How to effectively leverage whole-body contextual information and the fusion of multimodal information is the key to the problem. To address this issue, we propose a spatial squeeze and multimodal feature fusion attention network for whole-body multiple tumors segmentation based on PET–CT volumes. Our proposed method consists of two parts, a Coronal-Spatial Squeeze Attention Extraction Network (CSAE-Net) and a Precise PET–CT Fusion Attention Segmentation Network (PFAS-Net), respectively. In CSAE-Net, we squeeze a 3D PET–CT volume along the coronal plane into m 2D images, and obtain 3D Coronal Spatial Squeeze Attention Volume based on these 2D images. In PFAS-Net, the input is a 2D axial PET–CT slice, and the previously obtained coronal spatial squeeze attention map is used to guide the segmentation. Moreover, a Multimodal Fusion Attention (MFA) module is proposed to fuse the metabolic information of PET and the anatomical information of CT. We perform experiments on PET–CT datasets of two whole-body multiple tumors, Soft Tissue Sarcoma (STS) and Lymphoma. The results show that our proposed method improved Dice values by 8.03% in STS and 1.74% in Lymphoma. Also the visualization results show that our proposed method is able to suppress high-uptake regions of normal tissues.},
  archive      = {J_EAAI},
  author       = {Zhaoshuo Diao and Huiyan Jiang and Tianyu Shi},
  doi          = {10.1016/j.engappai.2023.105955},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105955},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A spatial squeeze and multimodal feature fusion attention network for multiple tumor segmentation from PET–CT volumes},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Green location routing problem with flexible
multi-compartment for source-separated waste: A q-learning and
multi-strategy-based hyper-heuristic algorithm. <em>EAAI</em>,
<em>121</em>, 105954. (<a
href="https://doi.org/10.1016/j.engappai.2023.105954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we extend a novel model for source-separated waste collection and transportation, the green location routing problem with multi-compartment (GLRPFMC), for which we design a Q-learning and multi-strategy-based hyper-heuristic algorithm (QLMSHH). The remarkable merits of this paper can be highlighted as the following threefold: (1) The GLRPFMC is novel in that it constructs a variant of the location routing problem with carbon emissions and flexible multi-compartment sizes that occurs in a source-separated waste transportation context. (2) For the methodological contribution, the QLMSHH is presented to design a hyper-heuristic model by intelligently selecting appropriate high-level heuristic components during different stages of the optimization process. (3) The proposed method incorporates the design of solution representations, evolution-acceptance pairs for high-level heuristic construction, the repairing solution scheme, and the local search strategy. Finally, sufficient experiments are conducted on the benchmark, new instances, and simulation data of GLRPFMC and draw some managerial insights. The satisfactory results highlight the efficiency and universality of the proposed model and method.},
  archive      = {J_EAAI},
  author       = {Chunjian Shang and Liang Ma and Yong Liu},
  doi          = {10.1016/j.engappai.2023.105954},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105954},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Green location routing problem with flexible multi-compartment for source-separated waste: A Q-learning and multi-strategy-based hyper-heuristic algorithm},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Event-triggered impulsive control for stability of
stochastic delayed complex networks under deception attacks.
<em>EAAI</em>, <em>121</em>, 105953. (<a
href="https://doi.org/10.1016/j.engappai.2023.105953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the stability of stochastic complex networks with time-varying delays (SCNTD) under deception attacks, adopting the event-triggered impulsive control (ETIC). A new event-triggered mechanism (ETM) which was used to determine the impulsive instance is given using the topology of networks and the Lyapunov functions of subsystems. For stochastic complex networks, to avoid the Zeno behavior, a positive minimum inter-event time (MIET) is guaranteed. Combining the graph theory and the Lyapunov–Razumikhin method, several criteria for achieving p th moment exponential stability ( p MES) of SCNTD under deception attacks which are related to the topology of networks, the event-triggered parameters and the signal sent by the enemy are obtained. Finally, the theoretical results apply to the stochastic oscillator systems, single-link robot arms systems, and Chua’s circuit systems. The stability of these systems under deception attacks is considered separately, and to show the validity of our theories, numerical simulations are provided.},
  archive      = {J_EAAI},
  author       = {Ni Yang and Shuo Zhang and Huan Su},
  doi          = {10.1016/j.engappai.2023.105953},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105953},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Event-triggered impulsive control for stability of stochastic delayed complex networks under deception attacks},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-view enhancement network for underwater images.
<em>EAAI</em>, <em>121</em>, 105952. (<a
href="https://doi.org/10.1016/j.engappai.2023.105952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single underwater image enhancement remains a challenging ill-posed problem, even with advanced deep learning methods, due to the significant information degeneration and various irrelevant contents. Current deep learning-based underwater image enhancement methods only consider using a single clear image as a positive feature for guiding the training of the enhancement network. However, the limited amount of helpful information constrains the network performance, and irrelevant contents consume many bits. Therefore, it is crucial to efficiently utilize cross-view neighboring features and provide corresponding relevant information for underwater enhancement. To address the challenges of degraded underwater images, we propose a novel cross-domain enhancement network (CVE-Net) that uses high-efficiency feature alignment to utilize neighboring features better. We employ a self-built database to optimize the helpful information and develop a feature alignment module (FAM) to adapt the temporal features. The dual-branch attention block is designed to handle different types of information and give more weight to essential features. Experiments demonstrate that CVE-Net outperforms state-of-the-art (SOTA) underwater vision enhancement methods in terms of both qualitatively and quantitatively results, significantly boosts the performance on underwater image quality, achieving a PSNR of 28.28 dB, which is 25% higher than Ucolor on the multi-view dataset. CVE-Net improves image quality while maintaining a good complexity-performance trade-off.},
  archive      = {J_EAAI},
  author       = {Jingchun Zhou and Dehuan Zhang and Weishi Zhang},
  doi          = {10.1016/j.engappai.2023.105952},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105952},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-view enhancement network for underwater images},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Oil logging reservoir recognition based on TCN and SA-BiLSTM
deep learning method. <em>EAAI</em>, <em>121</em>, 105950. (<a
href="https://doi.org/10.1016/j.engappai.2023.105950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Deep Learning methods to mine useful and critical information from massive and complex logging datasets is of great importance for oil logging reservoir recognition. TCN-SA-BiLSTM was proposed due to the lack of previous studies to mine the internal correlation of the features of the logging dataset. TCN-SA-BiLSTM is a deep learning model that hybridizes Temporal Convolutional Network (TCN), Self-Attention mechanism (SA), and Bidirectional Long Short Term Memory network (BiLSTM). First, for the pre-processed feature data, TCN is used for feature extraction with parallel convolution operation. Then, by exploiting the ability of SA to extract the internal autocorrelation of time series features, this can better capture the dependence of feature data over long distances. Finally, the contextual linkage of the features is further obtained using BiLSTM. The experimental results show that TCN-SA-BiLSTM exhibits excellent performance in comparison with seven competing models on all performance evaluation metrics. It overcomes the deficiencies in capability exhibited by traditional logging interpretation techniques to improve the efficiency and success rate of oil and gas exploration.},
  archive      = {J_EAAI},
  author       = {Wenbiao Yang and Kewen Xia and Shurui Fan},
  doi          = {10.1016/j.engappai.2023.105950},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105950},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Oil logging reservoir recognition based on TCN and SA-BiLSTM deep learning method},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction of viscosity of MWCNT-Al2O3 (20: 80)/SAE40
nano-lubricant using multi-layer artificial neural network (MLP-ANN)
modeling. <em>EAAI</em>, <em>121</em>, 105948. (<a
href="https://doi.org/10.1016/j.engappai.2023.105948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study, a comprehensive study on dynamic viscosity ( μ n f ) of MWCNT-Al 2 O 3 (20:80)/SAE40 nano-lubricant is done with an artificial neural network (ANN). In this research, Multilayer Perceptron-ANN (MLP-ANN) modeling with Levenberg–Marquardt algorithm (MLA) has been used for model of ANN. The optimal method is consists of four hundred different ANN structures on MWCNT-Al 2 O 3 /SAE40 nano-lubricant. It is contain of two hidden layers with ten neurons optimal structure in first layer and ten neurons in second layer. The volume fraction of nanoparticles ( φ ), rate of shear ( γ ̇ ) and temperature have been considered as input parameters and μ n f has been considered an output parameter in the ANN model. The optimal ANN with eight neurons per layer has the minimum square error (MSE) and the maximum regression coefficient R near to one to predict the μ n f . The margin of deviation range (MOD) is −2% &lt; MOD &lt; 2% in the predicted values. A comparison of three groups of lab data, computational and prediction of ANN shows the predicting data predicted by the ANN is much more powerful than a new relation and approximates lab data accurately.},
  archive      = {J_EAAI},
  author       = {Mohammad Hemmat and Davood Toghraie and Fatemeh Amoozad},
  doi          = {10.1016/j.engappai.2023.105948},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105948},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of viscosity of MWCNT-Al2O3 (20: 80)/SAE40 nano-lubricant using multi-layer artificial neural network (MLP-ANN) modeling},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multi-view underwater image enhancement method via embedded
fusion mechanism. <em>EAAI</em>, <em>121</em>, 105946. (<a
href="https://doi.org/10.1016/j.engappai.2023.105946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to wavelength-dependent light absorption and scattering, underwater images often appear with a colour cast and blurry details. Most existing deep learning methods utilize a single input end-to-end network structure, which leads to a single form and content of the extracted features. To address these problems, we present a novel multi-feature underwater image enhancement method via embedded fusion mechanism (MFEF). We find that the quality of reconstruction results is affected by the quality of the input image to some extent, and use pre-processing to obtain high-quality images, which can improve the final reconstruction effect. We introduce the white balance (WB) algorithm and the contrast-limited adaptive histogram equalization (CLAHE) algorithm employing multiple path inputs to extract different forms of rich features in multiple views. To fully interact with features from multiple views, we design a multi-feature fusion (MFF) module to fuse derived image features. We suggest a novel pixel-weighted channel attention module (PCAM) that calibrates the detailed features of the degraded images using a weight matrix to give diverse weights to the encoded features. Ultimately, our network utilizes a fusion mechanism-based encoder and decoder that can be applied to restore various underwater scenes. In the UIEB dataset, our PSNR increased by 10.2% compared to that of Ucolor. Extensive experimental results demonstrate that the MFEF method outperforms other state-of-the-art underwater image enhancement methods in various real-world datasets.},
  archive      = {J_EAAI},
  author       = {Jingchun Zhou and Jiaming Sun and Weishi Zhang and Zifan Lin},
  doi          = {10.1016/j.engappai.2023.105946},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105946},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-view underwater image enhancement method via embedded fusion mechanism},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-varying multi-objective smart home appliances
scheduling using fuzzy adaptive dynamic SPEA2 algorithm. <em>EAAI</em>,
<em>121</em>, 105944. (<a
href="https://doi.org/10.1016/j.engappai.2023.105944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart city is an idea of upcoming revolution in cities, which includes smart home, smart mobility, smart living, and smart environment that can be operated using a smartphone connected to the internet. By adequately scheduling appliances, residential consumers can reduce their electricity expenses while increasing their comfort. Electricity cost and user comfort being conflicting in nature, can be formulated as a dynamic multi-objective optimization problem with varying user priority to use different home appliances at different times. Further to solve this problem, a Fuzzy Adaptive Dynamic SPEA2 with Borda Ranking Method (FDSPEA2-BR) is proposed based on the dynamic modification of popular SPEA2 algorithm. The algorithm includes an improved Borda count method along with Mamdani fuzzy rules to select the best solutions. The changes in crossover and mutation rate in the SPEA2 algorithm is now being controlled with fuzzy rules. Proposed FDSPEA2-BR is validated on fourteen benchmark dynamic multi-objective functions taken from the FDA, JY, dMOP, and DF test suites, results have validated the optimization model’s efficacy. Simulation study is performed on the scheduling of 11 smart home appliances varying over 10 time slots. The results in the form of time varying Pareto Fronts is demonstrated and the schedules corresponding to 5 diversified points on each Pareto Front are reported. The end user can make use of the optimized schedules that were thus obtained to modify his or her patterns of demand and energy use.},
  archive      = {J_EAAI},
  author       = {Vikas Kumar Maurya and Satyasai Jagannath Nanda},
  doi          = {10.1016/j.engappai.2023.105944},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105944},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time-varying multi-objective smart home appliances scheduling using fuzzy adaptive dynamic SPEA2 algorithm},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained document-level financial event argument
extraction approach. <em>EAAI</em>, <em>121</em>, 105943. (<a
href="https://doi.org/10.1016/j.engappai.2023.105943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level financial event argument extraction aims to extract a set of structured financial information related to particular financial events from a financial document. This task is challenging because there is complex fine-grained semantic information between financial event arguments, such as cross-document, inner-sentence and context semantic information. Existing approaches are still unable to capture these fine-grained financial semantic features well, leading to the low performance defects. Different from these existing approaches, we propose an end-to-end fine-grained document-level financial event argument extraction approach (FGD-FEAE), which defines event argument extraction as a sequence tagging task. In the encoder, a novel multiple granularity attention layer and a long-short term memory network (LSTM) extension layer are proposed and designed to effectively capture these fine-grained financial semantic information. In the decoder, to avoid the financial semantic confusion problem, a conditional random field (CRF) layer is constructed to jointly tag the financial event arguments. Finally, FGD-FEAE is tested on the two benchmark financial datasets, Chinese financial annotation dataset (ChiFinAnn) and English financial press releases (EFPR), and our own Chinese financial project dataset (ChiFD). These datasets contain a large amount of financial corpus information and complete financial event arguments and provide a solid foundation for verifying the general applicability of the proposed FGD-FEAE. Experimental results show that FGD-FEAE can achieve the better performance than the state-of-the-art approaches, and the performance is improved by 4.69, 5.01 and 3.78 on the three actual financial datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Ze Chen and Wanting Ji and Linlin Ding and Baoyan Song},
  doi          = {10.1016/j.engappai.2023.105943},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105943},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fine-grained document-level financial event argument extraction approach},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive cylinder vector particle swarm optimization with
differential evolution for UAV path planning. <em>EAAI</em>,
<em>121</em>, 105942. (<a
href="https://doi.org/10.1016/j.engappai.2023.105942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) algorithm has a potential to solve route planning problem for unmanned aerial vehicle (UAV). However, the traditional PSO algorithm is easy to fall into local optimum under the complicated environments with multiple threats. In order to improve the performance in different complicated environments, a novel and effective PSO algorithm with adaptive adjustment of the parameters, cylinder vector and different evolution operator, named ACVDEPSO, is proposed and demonstrated to be effective for route planning problem for UAV. In the proposed ACVDEPSO, the velocity of the particle is converted to its cylinder vector for the convenience of the path search. It is worth highlighting that the parameters of ACVDEPSO algorithm are automatically chosen by the time and the fitness values of the particles. Furthermore, a challenger based on differential evolution operator is introduced to reduce the probability of falling into local optimum and accelerate the algorithm convergence speed. The simulation experiments have been conducted in real digital elevation model (DEM) maps to test the performance of the ACVDEPSO. The experiment results validate that the optimization performance of the ACVDEPSO outperforms the other comparison methods, which can efficiently generate a higher quality path for UAV under the complicated 3D environments.},
  archive      = {J_EAAI},
  author       = {Chen Huang and Xiangbing Zhou and Xiaojuan Ran and Jiamiao Wang and Huayue Chen and Wu Deng},
  doi          = {10.1016/j.engappai.2023.105942},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105942},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive cylinder vector particle swarm optimization with differential evolution for UAV path planning},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hidden-variables genetic algorithm for variable-size design
space optimal layout problems with application to aerospace vehicles.
<em>EAAI</em>, <em>121</em>, 105941. (<a
href="https://doi.org/10.1016/j.engappai.2023.105941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal layout of a complex system such as aerospace vehicles consists in placing a given number of components in a container in order to minimize one or several objectives under some geometrical or functional constraints. This paper presents an extended formulation of this problem as a variable-size design space (VSDS) problem to take into account a large number of architectural choices and components allocation during the design process. As a representative example of such systems, considering the layout of a satellite module, the VSDS aspect translates the fact that the optimizer has to choose between several subdivisions of the components. For instance, one large tank of fuel might be placed as well as two smaller tanks or three even smaller tanks for the same amount of fuel. In order to tackle this NP-hard problem, a genetic algorithm enhanced by an adapted hidden-variables mechanism is proposed. This latter is illustrated on a toy case and an aerospace application case representative to real world complexity to illustrate the performance of the proposed algorithms. The results obtained using the proposed mechanism are reported and analyzed.},
  archive      = {J_EAAI},
  author       = {Juliette Gamot and Mathieu Balesdent and Arnault Tremolet and Romain Wuilbercq and Nouredine Melab and El-Ghazali Talbi},
  doi          = {10.1016/j.engappai.2023.105941},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105941},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hidden-variables genetic algorithm for variable-size design space optimal layout problems with application to aerospace vehicles},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep neural networks for the efficient simulation of
macro-scale hysteresis processes with generic excitation waveforms.
<em>EAAI</em>, <em>121</em>, 105940. (<a
href="https://doi.org/10.1016/j.engappai.2023.105940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An effective and performing hysteresis model, based on a deep neural network, with the capability to reproduce the evolution of magnetization processes under arbitrary waveforms of excitation is here presented. The proposed model consists of a standalone multi-layer feed-forward neural network, with reserved input neurons for the past values of both the input (H) and output (M), aiming at the reproduction of the storage mechanism typical of hysteretic systems. The training set has been opportunely prepared starting from a set of simulations, performed by the Preisach hysteresis model. The optimized training procedure, based on multi-stage check of the model performance, will be comprehensively discussed. The comparative analysis between the neural network-based model, implemented at low level of abstraction, and the Preisach model covers additional hysteresis processes, different from those involved in the training. The mild/moderate memory requirement and the significant computational speed make the proposed approach suitable for a future coupling with finite-element analysis.},
  archive      = {J_EAAI},
  author       = {Simone Quondam-Antonio and Francesco Riganti-Fulginei and Antonino Laudani and Gabriele-Maria Lozito and Riccardo Scorretti},
  doi          = {10.1016/j.engappai.2023.105940},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105940},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep neural networks for the efficient simulation of macro-scale hysteresis processes with generic excitation waveforms},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary design of marginally robust multivariable PID
controller. <em>EAAI</em>, <em>121</em>, 105938. (<a
href="https://doi.org/10.1016/j.engappai.2023.105938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two Margin-based design methods for tuning of decentralized PI controllers for multivariable systems are presented. The first method is predefined marginally robust controller (PMR) which is based on solving a constrained optimization problem to satisfy the desired values of the multivariable phase and gain margins that are set based on the designer’s knowledge of the working condition of the plant. The second method is self-setting marginally robust (SMR) that is an automatic controller design procedure. This method, by solving a many-objective optimization problem (MaOP), sets controller coefficients and finds optimum gain and phase margins. It offers a trade-off between tracking, interaction, and robustness. Evolutionary algorithm is applied to solve the problems and disk margin to define the multivariable stability margins. Proposed methods by combining the simplicity of margin-based design and effectiveness of optimization problems offer a practical solution in tuning the industrial multivariable controllers. Simulation results show that these methods are simple, practical, and at the same time, comparable with other robust multivariable controllers.},
  archive      = {J_EAAI},
  author       = {Arman Javadian and Nader Nariman-zadeh and Ali Jamali},
  doi          = {10.1016/j.engappai.2023.105938},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105938},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evolutionary design of marginally robust multivariable PID controller},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text-based neural networks for question intent recognition.
<em>EAAI</em>, <em>121</em>, 105933. (<a
href="https://doi.org/10.1016/j.engappai.2023.105933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An effective organization of their knowledge bases is pivotal in keeping social networks vibrant, namely in designing successful personalization and contextualization strategies. This way, enhancing dedicated displays and encouraging the production of better content. Particularly for question answering communities, splitting archived material according to their intent is essential to reuse their knowledge and social capital. Recently, deep neural networks have shown breakthrough capabilities on multiple tasks related to language understanding. Thus the main contribution of this work is a thorough comparison of assorted architectures applied to the detection of question intents (i.e., informational and conversational). Evaluated on two collections, DEBERTA and RoBERTa demonstrated to be the best options by finishing with an accuracy of 71.19% and 74.10%, respectively. As for conventional neural networks, RCNNs proven to be the most effective technique. Overall, best models signal the usefulness of both question titles and bodies, and that fusing diverse learning strategies hold promise since they focus on learning different discriminative patterns.},
  archive      = {J_EAAI},
  author       = {Alvaro Trewhela and Alejandro Figueroa},
  doi          = {10.1016/j.engappai.2023.105933},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105933},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Text-based neural networks for question intent recognition},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-stage ANN based intelligent technique for optimal
positioning and sizing of DERs in distribution system. <em>EAAI</em>,
<em>121</em>, 105932. (<a
href="https://doi.org/10.1016/j.engappai.2023.105932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have examined large transformational implications due to integration of highly intermittent renewable sources of energy. Therefore, initiatives must be explored to enhance the operational flexibility of distributed energy resources (DER) for bringing a new viewpoint to the planning and operation of future distribution system. Also, despite the economic, environmental and societal advantages of DERs, their adoption is limited and markets are yet to realize its full potential to address the operational challenges of the system. The solution to these is integration of multiple DERs in the system of appropriate size at optimal location in the system. Currently, numerous optimization methods based on rigorous mathematical calculation are used to solve this issue. This inevitably increases the complexity of such algorithms. Therefore, this paper proposes a two-stage artificial neural network (ANN) based intelligent technique to solve the problem. In this work, first stage ANN is used for screening the critical buses rank wise based on voltage, line and power stability index to find the optimal location. In second stage ANN, screening the size of DER based on the location of critical bus is accomplished to find the optimal sizing of DER. The intelligent technique proposed in this work is applicable to both radial as well as networked system. The solution is extensively evaluated through simulation in MATLab for a set of operational scenarios and performance verification of the proposed technique is provided for IEEE 33 and 69 bus systems for radial and IEEE 14 and 118 bus systems for mesh networked systems. The results validate the efficacy of the proposed technique.},
  archive      = {J_EAAI},
  author       = {Kumari Sandhya and Kalyan Chatterjee},
  doi          = {10.1016/j.engappai.2023.105932},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105932},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-stage ANN based intelligent technique for optimal positioning and sizing of DERs in distribution system},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). An autonomous cooperative system of multi-AUV for
underwater targets detection and localization. <em>EAAI</em>,
<em>121</em>, 105907. (<a
href="https://doi.org/10.1016/j.engappai.2023.105907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a cooperative online target detection methodology by multiple autonomous underwater vehicles (Multi-AUV) equipped with the side-scan sonar (SSS) sensor for real-time, accurate, and efficient underwater target detection and positioning in unknown environments. Due to the existence of unfavorable factors such as severe noises and geometric deformation of SSS images, this study incorporates the prior-based threshold segmentation with multi-scale cascaded networks (MSCNet) to reduce the high false alarm rate significantly. Specifically, to the real-time requirements of the AUVs computational platform, this study proposes the sequentially dual-branch lightweight block (LWBlock) as a baseline to obtain dense feature maps, which provide a good trade-off between accuracy and speed. Meanwhile, this study establishes the comprehensive correction model, which obtains the accurate target positioning information fusing with the predicted results. Furthermore, according to the target information provided by the automatic target recognition (ATR) system, the data-driven behavior-based (DDBB) path re-planning algorithm is performed that endows each AUV to scan above the interest target autonomously and in detail by designed maneuver behavior. Simulation and actual sea trial experimental results show that the proposed method outperforms other state-of-the-art algorithms, and achieves the recognition accuracy of 92.16%, inference speed of 2.45 s, and obtained the best FPR indicator in three SSS targets of 2.54% (metal ball),1.96% (seabed rock) and 1.03% (metal rod), respectively. At the same time, the proposed algorithm can improve detection efficiency by at least 40% compared with a single AUV, which can be widely used in marine mission exploration and resource deployment.},
  archive      = {J_EAAI},
  author       = {Qi Wang and Bo He and Yixiao Zhang and Fei Yu and Xiaochao Huang and Rong Yang},
  doi          = {10.1016/j.engappai.2023.105907},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105907},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An autonomous cooperative system of multi-AUV for underwater targets detection and localization},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Area and power optimization for fixed polarity reed–muller
logic circuits based on multi-strategy multi-objective artificial bee
colony algorithm. <em>EAAI</em>, <em>121</em>, 105906. (<a
href="https://doi.org/10.1016/j.engappai.2023.105906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Area and power optimization of Fixed Polarity Reed–Muller (FPRM) circuits has received a lot of attention. Polarity optimization for FPRM circuits is essentially a binary multi-objective optimization problem. However, the existing area and power optimization approaches for FPRM logic circuits rarely produce a frontier and a greater number of Pareto optimal solutions. In this paper, a Multi-strategy Multi-objective Artificial Bee Colony (MMABC) algorithm is proposed to solve the binary multi-objective optimization problem. The main innovation of MMABC can be summarized as follows: a flexible foraging behavior strategy for employed bees is proposed to improve the searching ability of the algorithm; a genetic retention evolution for onlooker bees is proposed to improve the quality of the population; an efficient transform strategy is proposed to help the algorithm to jump out the local optimal and increase convergence speed. Moreover, we propose an area and power optimization approach for FPRM logic circuits, which uses the MMABC to search for the polarities (i.e., Pareto optimal solutions) with smaller area and lower power. Experimental results demonstrated the effectiveness and superiority of our approach in optimizing area and power of FPRM logic circuits.},
  archive      = {J_EAAI},
  author       = {Dongge Qin and Zhenxue He and Xiaojun Zhao and Jia Liu and Fan Zhang and Limin Xiao},
  doi          = {10.1016/j.engappai.2023.105906},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105906},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Area and power optimization for fixed polarity Reed–Muller logic circuits based on multi-strategy multi-objective artificial bee colony algorithm},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Search-based task and motion planning for hybrid systems:
Agile autonomous vehicles. <em>EAAI</em>, <em>121</em>, 105893. (<a
href="https://doi.org/10.1016/j.engappai.2023.105893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve optimal robot behavior in dynamic scenarios we need to consider complex dynamics in a predictive manner. In the vehicle dynamics community, it is well know that to achieve time-optimal driving on low friction surface, the vehicle should utilize drifting. Hence, many authors have devised rules to split circuits and employ drifting on some segments. These rules are suboptimal and do not generalize to arbitrary circuit shapes (e.g., S-like curves). So, the question “ When to go into which mode and how to drive in it?” remains unanswered. To choose the suitable mode (discrete decision), the algorithm needs information about the feasibility of different modes (continuous motion). This makes it a class of Task and Motion Planning (TAMP) problems, which are known to be hard to solve optimally in real-time. In the AI planning community, search methods are commonly used. However, they cannot be directly applied to TAMP problems due to the continuous component. Here, we present a search-based method that effectively solves this problem and efficiently searches in a highly dimensional state space with nonlinear and unstable dynamics. The space of the possible trajectories is explored by sampling different combinations of motion primitives guided by the search. Our approach allows to use multiple locally approximated models to generate motion primitives (e.g., learned models of drifting) and effectively simplify the problem without losing accuracy. The algorithm performance is evaluated in simulated driving on a mixed-track with segments of different curvatures (right and left). Our code is available at https://git.io/JenvB .},
  archive      = {J_EAAI},
  author       = {Zlatan Ajanović and Enrico Regolin and Barys Shyrokau and Hana Ćatić and Martin Horn and Antonella Ferrara},
  doi          = {10.1016/j.engappai.2023.105893},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105893},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Search-based task and motion planning for hybrid systems: Agile autonomous vehicles},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing a surface mount technology defect detection
system for mounted devices on printed circuit boards using a MobileNetV2
with feature pyramid network. <em>EAAI</em>, <em>121</em>, 105875. (<a
href="https://doi.org/10.1016/j.engappai.2023.105875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a method to develop an innovative robust fully automatic surface mount technology (SMT) defect detection system using MobileNetV2 with Feature Pyramid Network (FPN). The aim of the system is to detect mounted devices on Printed Circuit Boards (PCB) in real-time with good precision and relatively fast detection speed to improve quality control in the production industry. The design of the proposed system consists of data acquisition, data preprocessing, augmentation, labeling, and the detection model. Data acquisition presents the capturing the data, equipment involved and the setup, while data preprocessing explains the techniques employed to improve the quality of the dataset. To create robustness, the data was diversified and multiplied through the process of augmentation, followed by labeling to mark and tag regions of interest with their respective labels. The MobileNetV2 was utilized lastly, concatenated with FPN and a Single Shot MultiBox Detector (SSD). The proposed system displays a strong performance with a precision of 97.9%, recall of 96.3%, and F 1 score of 97.1%. The detection speed is relatively fast at 33.5FPS with an inference time of 30 ms per image. The proposed detection system demonstrates good performance at a competitive speed, and can detect mounted devices on PCBs in real-time with high confidence.},
  archive      = {J_EAAI},
  author       = {Sifundvolesihle Dlamini and Chung-Feng Jeffrey Kuo and Shin-Min Chao},
  doi          = {10.1016/j.engappai.2023.105875},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105875},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Developing a surface mount technology defect detection system for mounted devices on printed circuit boards using a MobileNetV2 with feature pyramid network},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based power prediction aware charge scheduling
approach in cloud based electric vehicular network. <em>EAAI</em>,
<em>121</em>, 105869. (<a
href="https://doi.org/10.1016/j.engappai.2023.105869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicles (EVs) are considered emerging popularity due to their cost-saving and eco-friendliness nature. The charging of EVs with elevated efficiency is a major issue for users as the hardware facilities, like charging stations are limited. Thus, the EV charging scheduling model is required to discover the charging schedule for each EV. An optimization-driven framework for EV charge scheduling in a Vehicular ad hoc network (VANET) topology is presented in this paper. First, the network simulation with the charge station (CS) and the EV locations are performed. The Deep Maxout network (DMN) is employed for predicting the power. To charge at the charging station, the vehicles are scheduled based on various parametric factors. The proposed Fractional Feedback Tree Algorithm (FFTA) is used to schedule charges in the EV network. The Feedback Artificial Tree (FAT) algorithm and fractional calculus (FC) are combined to create the proposed FFTA. Additionally, a new model of the fitness function is created taking into account variables like the average waiting time, the distance, the predicted power, and the quantity of EVs that are requested to be charged. With the shortest distance of 11.00 km, the highest power of 8.17 J, the shortest average waiting time of 0.47 s, and less number of EVs charged at 4.4, the proposed FFTA offered improved performance.},
  archive      = {J_EAAI},
  author       = {Balasubramaniam S and Dr. Mohammad Haider Syed and Nitin S. More and Vijayakumar Polepally},
  doi          = {10.1016/j.engappai.2023.105869},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105869},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based power prediction aware charge scheduling approach in cloud based electric vehicular network},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development and testing of a virtual simulator for a
myoelectric prosthesis prototype – the PRISMA hand II – to improve its
usability and acceptability. <em>EAAI</em>, <em>121</em>, 105853. (<a
href="https://doi.org/10.1016/j.engappai.2023.105853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial limbs can help people missing body parts to restore some of their daily-life activities. However, the user should spend up to a few months to intuitively control the new device. During this period, she/he may suffer pain due to wearing or using the prosthesis inappropriately. This research presents a virtual simulator that allows the user to carry out training sessions for controlling the prosthesis. A set of Surface Electromyographic (sEMG) sensors are used to acquire the signals from user’s muscles and send them to a recognition algorithm that interprets the patient’s intentions. Simultaneously, the patient observes the response of her/his device on the simulator. Two studies are presented: the first study evaluate the performance of three different recognition algorithms i.e., Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and Multi-Layer Perceptron (MLP), based on the successful recognition of the patient’s intentions. The second study investigates the least number of sEMG sensors to be used, as having less components improves the patient’s wearability and decreases the processing time. The developed simulator represents a real prosthetic device, PRISMA hand II. The results showed the superiority of the MLP with 80% of successful recognition when 6-sEMG sensors are used. If a reduced set of gestures is considered (frequently needed by the patient), 90% of successful recognition could be achieved. Less sEMG sensors significantly degraded the performance of the recognition algorithm as only 53.8% of successful recognition could be achieved. All experiments were conducted with the help of a patient with below-elbow amputation.},
  archive      = {J_EAAI},
  author       = {Adriano Leccia and Mohamed Sallam and Stanislao Grazioso and Teodorico Caporaso and Giuseppe Di Gironimo and Fanny Ficuciello},
  doi          = {10.1016/j.engappai.2023.105853},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105853},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development and testing of a virtual simulator for a myoelectric prosthesis prototype – the PRISMA hand II – to improve its usability and acceptability},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pressure and oxygen excess ratio control of PEMFC air
management system based on neural network and prescribed performance.
<em>EAAI</em>, <em>121</em>, 105850. (<a
href="https://doi.org/10.1016/j.engappai.2023.105850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simultaneous control of the pressure and oxygen excess ratio (OER) plays an important role in improving the performance and safety of polymer electrolyte membrane fuel cell (PEMFC). Nevertheless, the coupling characteristics and nonlinearity existing in the PEMFC air management system need to be solved. To this end, the original coupled nonlinear PEMFC air management system is first transformed into the cathode pressure and OER subsystems by using input–output linearization. For the cathode pressure subsystem, the neural network (NN) control scheme is proposed to maintain the stable tracking of cathode pressure. For the OER subsystem, a prescribed performance function (PPF) is proposed and therefore, the overshoot and steady state of OER tracking error is guaranteed within the quantitative boundary. Moreover, the restriction that the initial error is within the performance function bound is relaxed by proposing a tuning function. Finally, the Lyapunov stability theory, numerical simulations and hardware-in-loop (HIL) experiments show the effectiveness of the proposed controller. Compared with the proportional integral derivative (PID) controller, NN controller without PPF and NN controller with conventional PPF, the NN controller with the proposed PPF can realize the quantitative adjustment of OER and give more improvements to the system safety.},
  archive      = {J_EAAI},
  author       = {Yunlong Wang and Yongfu Wang},
  doi          = {10.1016/j.engappai.2023.105850},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {105850},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pressure and oxygen excess ratio control of PEMFC air management system based on neural network and prescribed performance},
  volume       = {121},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-series anomaly detection with stacked transformer
representations and 1D convolutional network. <em>EAAI</em>,
<em>120</em>, 105964. (<a
href="https://doi.org/10.1016/j.engappai.2023.105964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series anomaly detection is a task of detecting data that do not follow normal data distribution among continuously collected data. It is used for system maintenance in various industries; hence, studies on time-series anomaly detection are being carried out actively. Most of the methodologies are based on Long Short-Term Memory (LSTM) and Convolution Neural Network (CNN) to model the temporal structure of time-series data. In this study, we propose an unsupervised prediction-based time-series anomaly detection methodology using Transformer, which shows superior performance to LSTM and CNN in learning dynamic patterns of sequential data through a self-attention mechanism. The prediction model consists of an encoder comprising multiple Transformer encoder layers and a decoder that includes a 1D convolution layer. The output representation of each Transformer layer is accumulated in the encoder to obtain a representation with multi-level, rich information. The decoder fuses this representation through a 1d convolution operation. Consequently, the model can perform predictions considering both the global trend and local variability of the input time-series. The anomaly score is defined as the difference between the predicted and the actual value at the corresponding timestamp, assuming that the trained model produces the predictions that follow the normal data distribution. Finally, the data with an anomaly score above the threshold is detected as an anomaly. Experiments on the benchmark datasets show that the proposed method has performance superior to those of the baselines.},
  archive      = {J_EAAI},
  author       = {Jina Kim and Hyeongwon Kang and Pilsung Kang},
  doi          = {10.1016/j.engappai.2023.105964},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105964},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time-series anomaly detection with stacked transformer representations and 1D convolutional network},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Semi-supervised active learning hypothesis verification for
improved geometric expression in three-dimensional object recognition.
<em>EAAI</em>, <em>120</em>, 105956. (<a
href="https://doi.org/10.1016/j.engappai.2023.105956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient three-dimensional (3D) object recognition plays an important role in the 3D reconstruction of light-field displays. However, presently, the error rate of 3D implicit shape object recognition remains high, because the local features are sparse in the geometric expression of 3D reconstruction. To address this issue, a hypothesis verification method based on semi-supervised active learning-based K-means++ combined with 3D feature extraction is proposed. The proposed approach consists of the offline and online phases. The algorithm time complexity is O ( n ) and O ( n 2 ) , respectively. The offline phase includes keypoint detection, normal estimation, fast point feature histograms (FPFH) descriptor extraction, geometric word weight saving, and indexing structure construction. In addition to the FPFH extraction, the online phase includes nearest geometric word searching, corresponding direction and center voting, and non-maximum suppression. Comparative experiments were conducted in which the models and scenes were tested on the 3D datasets Mian and Tosca that is high-resolution. The experimental results demonstrate that the proposed method resolves the low recognition rate problem of 3D implicit objects, with the highest 3D intersection over union (IoU) reaching 88.89%.},
  archive      = {J_EAAI},
  author       = {Zhenhao Wang and Rui Xu and Tingyuan Nie and Dong Xu},
  doi          = {10.1016/j.engappai.2023.105956},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105956},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised active learning hypothesis verification for improved geometric expression in three-dimensional object recognition},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). PVF-DectNet: Multi-modal 3D detection network based on
perspective-voxel fusion. <em>EAAI</em>, <em>120</em>, 105951. (<a
href="https://doi.org/10.1016/j.engappai.2023.105951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of small objects such as pedestrians still poses challenges to the LiDAR-based 3D object detection due to the sparseness and disorder of point clouds. Conversely, images from cameras can provide rich semantic information, which makes these small-sized objects easy to be detected. To take use of the advantages of both devices to achieve better 3D object detection, research on the fusion of LiDAR and camera information is now being conducted. The existing fusion methods between point clouds and image are normally weighed more on the point clouds. Hence the semantic information of images is not fully utilized. We propose a new fusion method named PVFusion to try to fuse more image features. We first divide each point into a separate perspective voxel and project the voxel onto the image feature maps. Then the semantic feature of the perspective voxel is fused with the geometric feature of the point. A 3D object detection model (PVF-DectNet) is designed using PVFusion. During training we employ the ground truth paste (GT-Paste) data augmentation and solve the occlusion problem caused by newly added object. The KITTI validation set is used to validate the PVF-DectNet, which shows 3.6% AP improvement over the other feature fusion methods in pedestrian detection. On the KITTI test set, the PVF-DectNet outperforms the other multi-modal SOTA methods by 2.2% AP in pedestrian detection. And PVFusion shows better detection performance for sparse point clouds than PointFusion in both car and pedestrian categories. As for 32 beams LiDAR scene, there are 4.2% AP increment in moderate difficulty car category and 5.2% mAP improvement in pedestrian category.},
  archive      = {J_EAAI},
  author       = {Ke Wang and Tianqiang Zhou and Zhichuang Zhang and Tao Chen and Junlan Chen},
  doi          = {10.1016/j.engappai.2023.105951},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105951},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PVF-DectNet: Multi-modal 3D detection network based on perspective-voxel fusion},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep learning based classifier framework for automated
nuclear atypia scoring of breast carcinoma. <em>EAAI</em>, <em>120</em>,
105949. (<a
href="https://doi.org/10.1016/j.engappai.2023.105949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear atypia scoring is an essential procedure in the grading of breast carcinoma. Manual procedure of nuclear atypia scoring is error-prone, and marked by pathologists’ disagreement and low reproducibility. Automated methods are actively attempted by researchers to solve the problems of manual scoring. In this work, we propose a novel deep learning-based framework for automated nuclear atypia scoring of breast cancer from histopathology slide images. The framework consists of three major phases namely preprocessing, deep learning, and postprocessing. The original three-class problem of atypia scoring at slide level is not suitable for direct application of deep learning algorithms. This is due to the large dimensions and structural complexity of slide images, compounded by the small sample size of the available dataset. Redesign of this problem into a six-class nuclei classification problem through a set of preprocessing steps to facilitate effective use of deep learning algorithms, and the flexibility of the proposed three-phase framework to use different algorithms in each phase are the novel aspects of the proposed work. We used the publicly available slide image dataset MITOS-ATYPIA that contains 600 slide images of high spatial dimension for the experiments. A five-fold cross validation with the train-test sample ratio 80:20 in each fold is used for the performance evaluation. The performance of the method based on this framework exceeds the state-of-the-art with the results 0.8766, 0.8760, and 0.8745 for the metrics precision, recall, and F1 score respectively.},
  archive      = {J_EAAI},
  author       = {Tojo Mathew and C.I. Johnpaul and B. Ajith and Jyoti R. Kini and Jeny Rajan},
  doi          = {10.1016/j.engappai.2023.105949},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105949},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning based classifier framework for automated nuclear atypia scoring of breast carcinoma},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Single-image HDR reconstruction by dual learning the camera
imaging process. <em>EAAI</em>, <em>120</em>, 105947. (<a
href="https://doi.org/10.1016/j.engappai.2023.105947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a very challenging problem to reconstruct a high dynamic range (HDR) image from a single exposure image. There exist three problems, i.e., the many-to-many mapping problem between low dynamic range (LDR) images and HDR images, the image quality problem caused by the change of dynamic range and the problem of unpaired LDR–HDR training images. These problems can be solved to some extent through a dual learning framework simultaneously to learn the forward and reverse of camera imaging processes. This procedure is divided into a primary module, to reconstruct HDR from LDR, and a secondary module to reversely mapping the HDR to LDR. The secondary module guides the learning of primary module by constraining the outputs of the primary module. After that, the attention mechanism is used to solve the problem of unnatural perception caused by the change of dynamic range. In the end, with the advantage of our dual learning framework, unpaired data is further explored to train our model, which enriches the training samples. Compared with the state-of-the-art methods, a large number of quantitative and qualitative experiments confirm that our method can achieve better performance.},
  archive      = {J_EAAI},
  author       = {Lei She and Mao Ye and Shuai Li and Yu Zhao and Ce Zhu and Hu Wang},
  doi          = {10.1016/j.engappai.2023.105947},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105947},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Single-image HDR reconstruction by dual learning the camera imaging process},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deep encoder-decoder for surrogate modelling of liquid
moulding of composites. <em>EAAI</em>, <em>120</em>, 105945. (<a
href="https://doi.org/10.1016/j.engappai.2023.105945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a surrogate model for liquid moulding of structural composites. A methodology is presented to simulate the dual-phase Darcy’s flow in a heterogeneous porous medium. The approach is an encoder–decoder that receives as input a matrix of permeabilities and produces two scalar fields that represent the pressure and front flow. This model is trained with synthetic data generated with a computer fluid dynamics simulator. In this context, the lack of robustness of models trained with the popular L 2 and L 1 losses is highlighted and several enhancements to these baseline approaches are introduced. First, the study provides a piece-wise power-logarithmic loss that improves training in the presence of the bimodal distribution of error residuals produced by the dual-phase flow predictions. A non-uniform sampling strategy for the selection of time training snapshots is also included, which contributes to improve the prediction accuracy. The estimation of the front flow field is further refined with a multi-task training strategy. The introduction of these improvements in the baseline models reduce the relative error of the pressure and front flow fields by more than 50%, performing these simulations in a record time of 50 ms. The surrogate model is further evaluated as a digital twin to predict – in a real experiment – the location and spatial extent of race-tracking channels and regions with dissimilar degrees of permeability.},
  archive      = {J_EAAI},
  author       = {J. Fernández-León and K. Keramati and C. Miguel and C. González and L. Baumela},
  doi          = {10.1016/j.engappai.2023.105945},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105945},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep encoder-decoder for surrogate modelling of liquid moulding of composites},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel algorithm for mining maximal frequent gradual
patterns. <em>EAAI</em>, <em>120</em>, 105939. (<a
href="https://doi.org/10.1016/j.engappai.2023.105939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of mining frequent gradual patterns has received important attention within the data mining community, because it has many applications in many domains, such as economy, health, education, market, bio-informatics and web mining. Algorithms to extract frequent gradual patterns in the large databases are greedy in CPU time and memory space and the number of frequent patterns generated by these algorithms is sometimes too large to be fully exploited within a reasonable timeframe. This raises the problem of improving the performances of these algorithms and the problem of exploiting concise representations of frequent gradual patterns. This paper presents a new maximal frequent gradual pattern mining approach that relies on an in-depth traversing of the search space in the lexicographical order and a reduction of the search space and the computational load of fundamental operations. This approach leads to a new, more efficient algorithm called MSGriteMiner. Complexity analysis, in terms of CPU time and memory usage, and experiments carried out on various well-known databases show that MSGriteMiner is better than the previous algorithms and confirm the interest of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Edith Belise Kenmogne and Laurent Cabrel Tabueu Fotso and Clémentin Tayou Djamegni},
  doi          = {10.1016/j.engappai.2023.105939},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105939},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel algorithm for mining maximal frequent gradual patterns},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). ML-CapsNet meets VB-DI-d: A novel distortion-tolerant
baseline for perturbed object recognition. <em>EAAI</em>, <em>120</em>,
105937. (<a
href="https://doi.org/10.1016/j.engappai.2023.105937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suffering from spatiotemporal-varying perturbations (e.g., overexposure, jitter, and motion), the gathered images frequently undergo visual distortions (e.g., shear, defocus blur, affine transformation, and speckle noise). Due to the lack of effective information carriers, prior works cannot extract sufficient original representations of instances from corrupted images, thus fail to extrapolate to various geometric transformations. This paper proposes a Distortion-Tolerant Capsule Network (DT-CapsNet) to realize object detection whilst resisting visual distortions. It first learns the distribution of capsule encoding vectors as a new information carrier by casting a feature extractor dubbed Multi-lane Capsule Network (ML-CapsNet). This model consists of three independent encoder lanes and runs under the support of modified Segment-By-Segment Dynamic Routing Agreement (SBS-DRA). Then the invariant dimension detection and elimination, descriptor generation, and correspondence establishment are conducted on the learned vector distributions by casting a adaptive algorithm dubbed Vector-Based Deformation-Invariant Descriptor (VB-DI-D). Finally, a reliable soft matching with relaxation margins between the patterns of original standard instances and those of disturbed instances. Quantitative and ablation verifications demonstrate that DT-CapsNet can deliver competitive perturbed object detection performance among state-of-the-arts, i.e., achieves the highest testing accuracy (90.86% versus the second highest score 90.53%) on hand-crafted wheat dataset, and achieves the highest average testing accuracy (91.18% versus the second highest score 91.15%) on three public benchmarks (Stanford Cars, Stanford Dogs, CUB-200-2011). The results evidence that DT-CapsNet indeed improves the invariance against numerous encountered geometric distortions.},
  archive      = {J_EAAI},
  author       = {Zhongqi Lin and Zengwei Zheng and Jingdun Jia and Wanlin Gao and Feng Huang},
  doi          = {10.1016/j.engappai.2023.105937},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105937},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ML-CapsNet meets VB-DI-D: A novel distortion-tolerant baseline for perturbed object recognition},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Classification of seed corn ears based on custom
lightweight convolutional neural network and improved training
strategies. <em>EAAI</em>, <em>120</em>, 105936. (<a
href="https://doi.org/10.1016/j.engappai.2023.105936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal ears (containing phenotypic differences in seeds, particularly in color) are manually removed to improve seed purity during seed production in the field or factory. Traditional convolutional neural networks (CNN) have significant parameters and greater network depth, making them unsuitable for deployment in resource-constrained embedded devices. This paper proposes a deep learning model (CornNet) based on custom lightweight CNN and improved training strategies for corn ears classification to address this issue. We improved the structure of VGG16 by reducing the number of convolution layers (Conv) and its channels to change network depth and used the global average pooling layer (GAP) instead of the fully connected layer (FC) to achieve a lightweight model. The Squeeze-and-Excitation network (SE) and Batch Normalization (BN) were used to improve the feature extraction ability and prevent gradient disappearance. The image acquisition environment, similar to the production line, was constructed to obtain images with consistent features to reduce the data required for training. Two training strategies (i.e., data augmentation and dynamic learning rate) were optimized to improve performance. The results showed that CornNet performed well compared to MobileNet, ShuffleNet, VGG16, ResNet50 and AlexNet in terms of accuracy, F1-score, model size, and FLOPs of 98.56 %, 98.93 %, 0.42MB and 0.07G, respectively. The improved training strategies improved accuracy by 3.07% to 16.08% and 0.26% to 30.91%. The CornNet proposed in this paper achieved a good balance between performance and computational cost, and it can obtain better generalization ability on small datasets than the traditional deeper networks model.},
  archive      = {J_EAAI},
  author       = {Xiang Ma and Yonglei Li and Lipengcheng Wan and Zexin Xu and Jiannong Song and Jinqiu Huang},
  doi          = {10.1016/j.engappai.2023.105936},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105936},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Classification of seed corn ears based on custom lightweight convolutional neural network and improved training strategies},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hand bone age estimation using divide and conquer strategy
and lightweight convolutional neural networks. <em>EAAI</em>,
<em>120</em>, 105935. (<a
href="https://doi.org/10.1016/j.engappai.2023.105935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the Bone Age of children is very important for diagnosing growth defects, and related diseases, and estimating the final height that children reach after maturity. For this reason, it is widely used in different countries. Traditional methods for estimating bone age are performed by comparing atlas images and radiographic images of the left hand, which is time-consuming and error-prone. To estimate bone age using deep neural network models, a lot of research has been done, our effort has been to improve the accuracy and speed of this process by using the introduced approach. After creating and analyzing our initial model, we focused on preprocessing and made the inputs smaller, and increased their quality. We selected small regions of hand radiographs and estimated the age of the bone only according to these regions. by doing this we improved bone age estimation accuracy even further than what was achieved in related works, without increasing the required computational resource. We reached a Mean Absolute Error (MAE) of 3.85 months in the range of 0–20 years and an MAE of 3.79 months in the range of 1–18 years on the RSNA test set.},
  archive      = {J_EAAI},
  author       = {Amin Ahmadi Kasani and Hedieh Sajedi},
  doi          = {10.1016/j.engappai.2023.105935},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105935},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hand bone age estimation using divide and conquer strategy and lightweight convolutional neural networks},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative non-autoregressive unsupervised keyphrase
extraction with neural topic modeling. <em>EAAI</em>, <em>120</em>,
105934. (<a
href="https://doi.org/10.1016/j.engappai.2023.105934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised keyphrase extraction (UKE) aims to detect out a set of keyphrases of a document without using any annotation signal for training the UKE model. Existing UKE models however either fail to solve the issue of low keyphrase relevance, or suffer from the problem of unsatisfactory keyphrase coverage. Besides, the current strong-performing neural based UKE methods unfortunately come with the cost of lower decoding efficiency. In this paper we propose a novel framework for UKE. We model the task as a fully generative process with an encoder–decoder framework, which unifies the prediction of both the present and absent keyphrases in an end-to-end manner. We accelerate the decoding by installing a non-autoregressive decoder, which yields all keyphrase extraction in parallel fast. To enhance the keyphrase relevance, we investigate a neural topic module that unsupervisingly learns the latent topic information, aiding the semantic understanding of the input document. To strengthen the keyphrase coverage, we present an anchor-region scheme for the extraction of present keyphrases, which first locates the anchor points of present phrases and then determines the final boundaries of keyphrases. The initial anchor phrases are organized into an anchor-aware graph, which is modeled by our proposed topic-guided graph attention network which captures the document contexts at global level. Over six benchmark datasets of UKE our system shows better experimental results than existing strong-performing baselines, becoming the new state-of-the-art UKE model. Further in-depth analyses show that our model can effectively resolve both the relevance and coverage of keyphrase extraction, meanwhile being faster on decoding.},
  archive      = {J_EAAI},
  author       = {Xun Zhu and Yinxia Lou and Jing Zhao and Wang Gao and Hongtao Deng},
  doi          = {10.1016/j.engappai.2023.105934},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105934},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generative non-autoregressive unsupervised keyphrase extraction with neural topic modeling},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting the consistency improvement and consensus
reaching processes of intuitionistic multiplicative preference
relations. <em>EAAI</em>, <em>120</em>, 105931. (<a
href="https://doi.org/10.1016/j.engappai.2023.105931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic multiplicative preference relation (IMPR) has been successfully and widely used to model the decision makers’ preferences elicited by pairwise comparisons. As the critical links of group decision-making (GDM) procedure, the consistency improvement process (CIP) and consensus reaching process (CRP) have been investigated intensively; nevertheless, the extant methods explored the CIP and CRP of IMPRs without considering the situations of whether decision makers participate in the reassessment task. To overcome the limitation, this paper proposes two novel IMPR-based GDM approaches with CIP and CRP under different situations. First, when decision makers only express their original preferences, the novel consistency index and group consensus measure of IMPRs are defined to construct the CIP and CRP without feedback mechanism, in which the original preferences can be updated automatically. Second, when decision makers are required to modify their opinions, a series of consistency, consensus, and proximity degrees are put forwards to generate the identification and direction rules for improving the inconsistent and conflict preferences. Subsequently, the induced intuitionistic multiplicative ordered geometric averaging operator is constructed to fuse the individual preferences for determining the GDM results, in which the collective IMPR can maintain the acceptable consistency. Finally, a numerical example is applied to illustrate the feasibility and advantages of the proposed methods, which can improve the consistency and consensus levels of IMPRs according to the degrees of decision makers’ involvement in the re-evaluation process.},
  archive      = {J_EAAI},
  author       = {Rui Wang and Zhen-Song Chen and Bin Shuai and Luis Martínez and Wen-Tao Kong and Witold Pedrycz},
  doi          = {10.1016/j.engappai.2023.105931},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105931},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Revisiting the consistency improvement and consensus reaching processes of intuitionistic multiplicative preference relations},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning for energy efficiency improvement in
UAV-BS access networks: A knowledge transfer scheme. <em>EAAI</em>,
<em>120</em>, 105930. (<a
href="https://doi.org/10.1016/j.engappai.2023.105930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently the possibility of forming unmanned aerial vehicle base station (UAV-BS) network systems with energy harvesting capabilities to support persistent wireless access services for pedestrian users has been validated. Due to the need of sustaining wireless access services of the UAV-BSs, we investigate an optimal policy to maximize the overall energy utilization efficiency (renewable energy) of the UAV-BSs during their active in-flight network access operations. Since the natural sources of renewable energy (e.g., solar energy or wind energy harvesting) have stochastic properties with respect to the arrival rate of the dynamics of the unknown environment, we exploit an actor–critic reinforcement learning framework, which considers the continuous-valued states and action space for learning the best policy during interaction with the environment. To enhance and expedite the learning process, a transfer asynchronous advantage actor–critic (TA3C) algorithm is proposed, which enables UAV-BSs to transfer (i.e., share) knowledge gained in historical periods, during parallel task asynchronous executions on multiple instances of the environment. Numerical results reveal that the proposed TA3C algorithm surpasses the classic A3C and A2C algorithms in terms of throughput and optimal energy utilization efficiency.},
  archive      = {J_EAAI},
  author       = {Zhiqun Hu and Yujing Zhang and Hao Huang and Xiangming Wen and Obinna Agbodike and Jenhui Chen},
  doi          = {10.1016/j.engappai.2023.105930},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105930},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning for energy efficiency improvement in UAV-BS access networks: A knowledge transfer scheme},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A block padding approach in multidimensional dependency
missing data. <em>EAAI</em>, <em>120</em>, 105929. (<a
href="https://doi.org/10.1016/j.engappai.2023.105929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Without high-quality data, there will be no high-quality data mining results. Lack of data value is one of the problems often encountered in data analysis. The filling method of missing data under high-dimensional correlation is researched in the paper. Based on rough set theory of artificial intelligence, a new method blocks is proposed for filling missing data, including ideas, definitions, theorems and algorithms. The relationship between variables is used to fill in missing data, reduce the impact of irrelevant data on missing data, and improve data filling accuracy. In order to segment missing data with unknown block state, blocks are clustered based on k-means. The block filling algorithm can be used for gene sequencing data. Simulation experiments and actual dataset experiments show that in the block filling method, the relevant information in the filled data can be effectively used, and the data filling accuracy is improved.},
  archive      = {J_EAAI},
  author       = {Huiyan Xu and Yanli Chen},
  doi          = {10.1016/j.engappai.2023.105929},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105929},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A block padding approach in multidimensional dependency missing data},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Robot suction region prediction method from knowledge to
learning in disordered manufacturing scenarios. <em>EAAI</em>,
<em>120</em>, 105928. (<a
href="https://doi.org/10.1016/j.engappai.2023.105928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suction plays an important role in the disordered manufacturing scenarios because of its single-point contact and reliability. The prediction of suction region is the primary problem needs to be solved in these applications. However, the traditional non-deep learning methods is insufficient for its poor generalization performance, and the deep learning method is inconvenient as it requires manually labeled datasets for training. Therefore, a suction region prediction method from knowledge to learning is proposed to overcome these challenges, which adopts a suction reliability matrix based on the depth image to label the disordered manufacturing datasets without manual labeling, where the effects of suction cup model, part centroid and depth are all considered. The disordered manufacturing dataset annotated is used to train the suction region prediction model based on fully convolutional neural network, which can be customized according to the model of suction cup and parts. Experiments and analysis show that the proposed method has the advantages of short detection time, high robustness and strong generalization ability.},
  archive      = {J_EAAI},
  author       = {Tongjia Zhang and Chengrui Zhang and Shuai Ji and Tianliang Hu},
  doi          = {10.1016/j.engappai.2023.105928},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105928},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robot suction region prediction method from knowledge to learning in disordered manufacturing scenarios},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual learning for neural regression networks to cope
with concept drift in industrial processes using convex optimisation.
<em>EAAI</em>, <em>120</em>, 105927. (<a
href="https://doi.org/10.1016/j.engappai.2023.105927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process models in industrial applications, e.g. predictive maintenance or automation, are subject to both divergence from the underlying system due to their time-variant nature and to high complexity resulting from a wide operational range being covered. Hence, regression models require high accuracy for the present system state and at the same time need to be valid across the whole system operating space. While accuracy for the current system state can be gained by updating the model on the current data, the overall validity must often be retrieved from historical or design data. We propose a method to find an appropriate compromise for these two demands. A pre-trained artificial neural network (ANN) is continually updated on the current sensor data stream using convex optimisation. Thus, a unique and optimal solution is generated in each update step, while robust regression accuracy on the domain that is not covered by the arriving data subset is maintained. This is achieved by introducing a data management system to provide some historical data, constraining the optimisation problem and manipulating the architecture of the ANN. Models updated with this method show reasonable stability but display plastic behaviour at the current operating point.},
  archive      = {J_EAAI},
  author       = {Wolfgang Grote-Ramm and David Lanuschny and Finn Lorenzen and Marcel Oliveira Brito and Felix Schönig},
  doi          = {10.1016/j.engappai.2023.105927},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105927},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continual learning for neural regression networks to cope with concept drift in industrial processes using convex optimisation},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal information balance-aware reasoning network for
image-text retrieval. <em>EAAI</em>, <em>120</em>, 105923. (<a
href="https://doi.org/10.1016/j.engappai.2023.105923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental multimodal task, image-text retrieval bridges the gap between vision and language. Current mainstream methods exploit attention mechanisms to discover potential alignments between visual regions and textual words while ignoring the imbalance of image-text information. To this end, we propose a Cross-modal Information Balance-aware Reasoning Network (CIBRN), adopting information balance and similarity reasoning mechanisms to distinguish matched and unmatched image-text pairs in the paper. Specifically, a two-stage information balance scheme is employed to balance image-text information. In the first stage, a Graph Convolutional Network (GCN) with multiple convolution kernels is used to convert elements that only exist in a single modality into common elements to achieve intra-modal information balance indirectly. In the second stage, we propose an information “ Add-Reduce ” mechanism to realize inter-modal information balance by adding a random feature based on Gaussian distribution to each textual “word” and reducing fixed-length information from each visual “region”. Subsequently, a block-based hierarchical matching method and mean-based fully connected layers are proposed to reason the relevance of images and texts. Extensive experiments on two benchmark datasets, i.e. , Flickr30K and MSCOCO, demonstrate the effectiveness of the proposed model CIBRN and achieve advanced results compared to the state-of-the-art method, with a gain of 7.0% and 3.0% on rSum , respectively.},
  archive      = {J_EAAI},
  author       = {Xueyang Qin and Lishuang Li and Fei Hao and Guangyao Pang and Zehao Wang},
  doi          = {10.1016/j.engappai.2023.105923},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105923},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-modal information balance-aware reasoning network for image-text retrieval},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid method to automatically extract medical document tree
structure. <em>EAAI</em>, <em>120</em>, 105922. (<a
href="https://doi.org/10.1016/j.engappai.2023.105922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A huge and rapidly growing quantity of medical documents is available in an electronic versions. These informing documents mostly have textual content in natural language. These facts can make the documents difficult to read, ambiguous, or even contain mistakes. Consequently, when a doctor decides on treatment, many medical critical errors can happen. The information extraction in unstructured documents can handle this problem. In our paper, we introduce an automatic section detection method in the medical field SDM ( S ection D etection in M edical field) to improve information extraction tasks by providing more context. Accordingly, we have constructed some rules to prepare automatically the training set. Then, we benefit from numerous features such as formatting style, syntactic, and semantic features to train a machine learning model to find titles. Then, a section tree is generated that can be useful for other tasks. As anticipated, our experiments show that merging these features using a Convolutional Neural Network (CNN) can lead to a better result in real medical documents according to the F1-score measure. Thus, we benefit from the layout information and our method can provide the document sections in a tree form. It is worth noting that our method can be easily applied in other fields since it is not strongly dependent on the document type or language.},
  archive      = {J_EAAI},
  author       = {Mohamed Yassine Landolsi and Lobna Hlaoua and Lotfi Ben Romdhane},
  doi          = {10.1016/j.engappai.2023.105922},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105922},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid method to automatically extract medical document tree structure},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An effective iterated local search algorithm for the
distributed no-wait flowshop scheduling problem. <em>EAAI</em>,
<em>120</em>, 105921. (<a
href="https://doi.org/10.1016/j.engappai.2023.105921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The no-wait flowshop scheduling problem (NWFSP) is a variant of the classical flowshop scheduling problem in which the jobs must be processed without any interruption between their operations. The distributed no-wait flowshop scheduling problem (DNWFSP) extends the NWFSP by considering multiple identical factories. The DNWFSP combines two types of decisions, allocating the jobs to the factories and scheduling the set of jobs allocating to the same factory. In this study, an iterated local search (ILS) algorithm is proposed to solve the DNWFSP. The proposed ILS implements a specialized local search in which two variable neighborhood descent (VND) based procedures are incorporated. Moreover, the perturbation strength is adjusted adaptively to the structure of the search space. Another important aspect of our ILS is its simple structure which makes it easy to implement. The performance of ILS is evaluated on a set of benchmark problem instances available in the DNWFSP literature. The results indicate that the developed ILS is able to produce high-quality solutions in short computing times for the DNWFSP.},
  archive      = {J_EAAI},
  author       = {Mustafa Avci},
  doi          = {10.1016/j.engappai.2023.105921},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105921},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective iterated local search algorithm for the distributed no-wait flowshop scheduling problem},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel q-learning-based FKG-pairs approach for extreme
cases in decision making. <em>EAAI</em>, <em>120</em>, 105920. (<a
href="https://doi.org/10.1016/j.engappai.2023.105920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decision-making problems based on fuzzy inference systems have received much attention from the worldwide scientific community. The M-CFIS-FKG model is considered one of the best models to solve classification problems based on uncertain and amplitude input datasets. It can infer and find the output labels of new samples that are not in the fuzzy rule base. Recently, the FKG-Pairs model has been considered an extension of FKG in the M-CFIS-FKG model by combining attribute pairs to infer and find the output labels in the cases of input datasets with incomplete gathering. It has overcome the limitation of the M-CFIS-FKG model. However, with real-time large input datasets or too-small training datasets, the FKG-Pairs model has also revealed limitations as it takes too much time to compute, and the accuracy is still relatively low. This paper has proposed a decision-making model in extreme cases (called FKG-Extreme) by using the Q-learning-based FKG-Pairs approach to enrich the fuzzy rule base after each time step with the cumulative mechanism of new rules. The proposed FKG-Extreme model has overcome the FKG-Pairs model’s limitation in the extreme case. It has significantly improved the system’s accuracy, while the computation time is acceptable. To validate the proposed model, we conducted experiments based on the standard UCI datasets, and the experimental results demonstrated that the system’s performance in terms of accuracy is superior to the other reliable models in case of too small training data. Furthermore, the results of the two-way ANOVA also proved that the FKG-Extreme model is better than the FIS and FKG-Pairs models.},
  archive      = {J_EAAI},
  author       = {Cu Kim Long and Pham Van Hai and Tran Manh Tuan and Luong Thi Hong Lan and Tran Thi Ngan and Pham Minh Chuan and Le Hoang Son},
  doi          = {10.1016/j.engappai.2023.105920},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105920},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel Q-learning-based FKG-pairs approach for extreme cases in decision making},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RGB-t image analysis technology and application: A survey.
<em>EAAI</em>, <em>120</em>, 105919. (<a
href="https://doi.org/10.1016/j.engappai.2023.105919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal infrared (RGB-T) image analysis has been actively studied in recent years. In the past decade, it has received wide attention and made a lot of important research progress in many applications. This paper provides a comprehensive review of RGB-T image analysis technology and application, including several hot fields: image fusion, salient object detection, semantic segmentation, pedestrian detection, object tracking, and person re-identification. The first two belong to the preprocessing technology for many computer vision tasks, and the rest belong to the application direction. This paper extensively reviews 400+ papers spanning more than 10 different application tasks. Furthermore, for each specific task, this paper comprehensively analyzes the various methods and presents the performance of the state-of-the-art methods. This paper also makes an in-deep analysis of challenges for RGB-T image analysis as well as some potential technical improvements in the future.},
  archive      = {J_EAAI},
  author       = {Kechen Song and Ying Zhao and Liming Huang and Yunhui Yan and Qinggang Meng},
  doi          = {10.1016/j.engappai.2023.105919},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105919},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RGB-T image analysis technology and application: A survey},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactive data-driven multiobjective optimization of
metallurgical properties of microalloyed steels using the DESDEO
framework. <em>EAAI</em>, <em>120</em>, 105918. (<a
href="https://doi.org/10.1016/j.engappai.2023.105918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving real-life data-driven multiobjective optimization problems involves many complicated challenges. These challenges include preprocessing the data, modelling the objective functions, getting a meaningful formulation of the problem, and supporting decision makers to find preferred solutions in the existence of conflicting objective functions. In this paper, we tackle the problem of optimizing the composition of microalloyed steels to get good mechanical properties such as yield strength, percentage elongation, and Charpy energy. We formulate a problem with six objective functions based on data available and support two decision makers in finding a solution that satisfies them both. To enable two decision makers to make meaningful decisions for a problem with many objectives, we create the so-called MultiDM/IOPIS algorithm, which combines multiobjective evolutionary algorithms and scalarization functions from interactive multiobjective optimization methods in novel ways. We use the software framework called DESDEO, an open-source Python framework for interactively solving multiobjective optimization problems, to create the MultiDM/IOPIS algorithm. We provide a detailed account of all the challenges faced while formulating and solving the problem. We discuss and use many strategies to overcome those challenges. Overall, we propose a methodology to solve real-life data-driven problems with multiple objective functions and decision makers. With this methodology, we successfully obtained microalloyed steel compositions with mechanical properties that satisfied both decision makers.},
  archive      = {J_EAAI},
  author       = {Bhupinder Singh Saini and Debalay Chakrabarti and Nirupam Chakraborti and Babooshka Shavazipour and Kaisa Miettinen},
  doi          = {10.1016/j.engappai.2023.105918},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105918},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interactive data-driven multiobjective optimization of metallurgical properties of microalloyed steels using the DESDEO framework},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Experimental and artificial intelligence approaches to
measuring the wear behavior of DIN st28 steel boronized by the box
boronizing method using a mechanically alloyed powder source.
<em>EAAI</em>, <em>120</em>, 105910. (<a
href="https://doi.org/10.1016/j.engappai.2023.105910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wear in moving materials in contact with each other is an inevitable cause of damage. To prevent this damage, various processes are applied to the material surfaces. The most widely used method is the surface hardening method. This study aims to examine the wear properties of the samples by forming a hard boride layer on the surface of low-carbon steel such as St28 with experimental and artificial intelligence approaches. In this context, it is aimed to obtain the boride layer at relatively low temperatures by pre-processing the powder mixture to be used as a boron source, such as Mechanical Alloying (MA). The boronizing process was carried out using the box boronizing technique. The wear behavior of the obtained samples was investigated by the block-on-disk method. In artificial intelligence approaches; The dataset is divided into three categories as 10N, 20N, and 40N. There are 39 sample types and attributes in each category. In this study, feature selection algorithms such as linear regression (LR), ridge, recursive feature elimination (RFE), f-regression, and multiple inclusion criterion (MIC) were used to select the most efficient samples. Then the best samples were classified according to their force types. Ensemble learning methods, machine learning methods, and Bayesian neural networks were used in the classification processes. Thanks to the proposed approach and feature selection algorithm, the best performance has been shown up to 10 feature selection. By ignoring 29 inefficient features, classification was performed with 10 efficient features. In the classification process, 100% overall accuracy was achieved.},
  archive      = {J_EAAI},
  author       = {Muhammet Gökhan Albayrak and Ertan Evi̇n and Oktay Yi̇ği̇t and Mesut Toğaçar and Burhan Ergen},
  doi          = {10.1016/j.engappai.2023.105910},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105910},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Experimental and artificial intelligence approaches to measuring the wear behavior of DIN st28 steel boronized by the box boronizing method using a mechanically alloyed powder source},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel three-axis accelerometer-based silent speech interface
using deep neural network. <em>EAAI</em>, <em>120</em>, 105909. (<a
href="https://doi.org/10.1016/j.engappai.2023.105909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silent speech interfaces (SSIs) have been developed as new non-acoustic communication channels for people with speech impairment. Various modalities have been employed to implement SSIs, including ultrasound imaging, electromagnetic articulography, and surface electromyography. In this study, for the first time, we examined the feasibility of implementing an SSI using accelerometers, which have been widely used to acquire motion-related information in human activity recognition. Five accelerometers were attached to the facial surface of participants to measure speech-induced facial movements. A deep neural network architecture combining a one-dimensional (1D) convolutional neural network and bidirectional long short-term memory (1D CNN-bLSTM) was implemented to decode speech-related information contained in the accelerometer signals. In total, 20 healthy individuals participated in the SSI experiments, wherein they were asked to articulate 40 words consisting of 30 Korean words and 10 English Numbers without vocalization. Leave-one-session-out cross-validation was employed to evaluate the classification accuracy of the proposed accelerometer-based SSI. Consequently, an average classification accuracy of 95.58 ± 1.83% was achieved with only four accelerometers, which is significantly higher than that of the conventional sEMG-based SSI (89.68 ± 5.27%, p &lt; 0.0005, Wilcoxon signed-rank test). In addition, the proposed SSI achieved an average classification accuracy of 94.65 ± 2.54% in classifying 40 English words spoken silently. The result demonstrates that accelerometers can be a promising modality to implement SSIs. Considering that accelerometers have multiple advantages over conventional modalities, including non-invasiveness, cost-effectiveness, low power consumption, and portability, it is expected that accelerometer-based SSIs would provide a novel means of communication to those who cannot generate speech signals.},
  archive      = {J_EAAI},
  author       = {Jinuk Kwon and Hyerin Nam and Younsoo Chae and Seungjae Lee and In Young Kim and Chang-Hwan Im},
  doi          = {10.1016/j.engappai.2023.105909},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105909},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel three-axis accelerometer-based silent speech interface using deep neural network},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A physics-informed neural network framework to predict 3D
temperature field without labeled data in process of laser metal
deposition. <em>EAAI</em>, <em>120</em>, 105908. (<a
href="https://doi.org/10.1016/j.engappai.2023.105908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To predict thermal behaviors during the laser metal deposition process, traditional approaches like experiments or finite-element methods(FEM) can be quite time-consuming, while data-driven machine learning models rely on large labeled datasets, which are too expensive to obtain. To fully exploit the potential of machine learning and release it from the dataset dependence, a physics-informed neural network framework that does not require any labeled data to predict 3D temperature field was proposed. The model used customized loss functions by replacing the original data loss with physical losses of heat conduction, convection and radiation.The implementation of nonlinear temperature-dependent material properties and the scaling of model inputs and outputs were involved. By iterative training, the model achieved accurate predictions of approximately 2% maximum relative error compared with FEM results. The transfer learning part was utilized for scenarios of different manufacturing parameters, and took about 1/3 of the calculation time as FEM did without losing accuracy. All the results above validated the high effectiveness and accuracy of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Shilin Li and Gang Wang and Yuelan Di and Liping Wang and Haidou Wang and Qingjun Zhou},
  doi          = {10.1016/j.engappai.2023.105908},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105908},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics-informed neural network framework to predict 3D temperature field without labeled data in process of laser metal deposition},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint image enhancement learning for marine object detection
in natural scene. <em>EAAI</em>, <em>120</em>, 105905. (<a
href="https://doi.org/10.1016/j.engappai.2023.105905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine object detection has received an increasing amount of attention due to its enormous application potential in the field of marine engineering, Remotely Operated Vehicles, and Autonomous Underwater Vehicles. It has made substantial progress in generic object detection with the prevalent trend of deep learning in the past few years. However, marine object detection in natural scenes remains certainly an unsolved problem. The challenges stem from low visibility, small size, serious occlusion, and dense distribution. In this article, we attempt to address the marine object detection problem by presenting a clever joint attention-guided dual-subnet network that can jointly learn both image enhancement and object detection tasks for end-to-end training. JADSNet attains significant performance gains by comprising two subnetworks: an image enhancement subnet and a marine object detection subnet. Essentially, the marine object detection subnet is an extended feature pyramid network with a dual attention-guided module and a multi-term loss function. It takes RetinaNet as a backbone and is responsible for classifying and locating objects. In the image enhancement subnet, feature extraction layers are shared with the marine object detection subnet and a feature enhancement module is used. A multi-term loss function is introduced to reduce false detection and miss detection caused by the mutual occlusion of marine objects. We build a new Marine Object Detection (MOD) dataset that contains more than 25,000 train-val and 3000 test underwater images. The experimental findings demonstrate that our JADSNet realize notable performance and reach 74.41% mAP on the MOD dataset. We also verify that the JADSNet method can be applied to object detection in foggy weather and achieve 49.54% mAP on the foggy dataset.},
  archive      = {J_EAAI},
  author       = {Na Cheng and Hongye Xie and Xuanbing Zhu and Hongyu Wang},
  doi          = {10.1016/j.engappai.2023.105905},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105905},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Joint image enhancement learning for marine object detection in natural scene},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explainable decision support system for predictive
process analytics. <em>EAAI</em>, <em>120</em>, 105904. (<a
href="https://doi.org/10.1016/j.engappai.2023.105904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Process Analytics is becoming an essential aid for organizations, providing online operational support of their processes. However, process stakeholders need to be provided with an explanation of the reasons why a given process execution is predicted to behave in a certain way. Otherwise, they will be unlikely to trust the predictive monitoring technology and, hence, adopt it. This paper proposes a predictive analytics framework that is also equipped with explanation capabilities based on the game theory of Shapley Values. The framework has been implemented in the IBM Process Mining suite and commercialized for business users. The framework has been tested on real-life event data to assess the quality of the predictions and the corresponding evaluations. In particular, a user evaluation has been performed in order to understand if the explanations provided by the system were intelligible to process stakeholders.},
  archive      = {J_EAAI},
  author       = {Riccardo Galanti and Massimiliano de Leoni and Merylin Monaro and Nicolò Navarin and Alan Marazzi and Brigida Di Stasi and Stéphanie Maldera},
  doi          = {10.1016/j.engappai.2023.105904},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105904},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An explainable decision support system for predictive process analytics},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The IoT-enabled sustainable reverse supply chain for
COVID-19 pandemic wastes (CPW). <em>EAAI</em>, <em>120</em>, 105903. (<a
href="https://doi.org/10.1016/j.engappai.2023.105903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chains have been impacted by the COVID-19 pandemic, which is the most recent worldwide disaster. After the world health organization recognized the latest phenomena as a pandemic, nations became incapacitated to provide the required medical supplies. In the current situation, the world seeks an essential solution for COVID-19 Pandemic Wastes (CPWs) by pushing the pandemic to a stable condition. In this study, the development of a supply chain network is contrived for CPWs utilizing optimization modeling tools. Also, an IoT platform is devised to enable the proposed model to retrieve real-time data from IoT devices and set them as the model’s inputs. Moreover, sustainability aspects are appended to the proposed IoT-enabled model considering its triplet pillars as objective functions. A real case of Puebla city and 15 experiments are used to validate the model. Furthermore, a combination of metaheuristic algorithms utilized to solve the model and also seven evaluation indicators endorse the selection of efficient solution approaches. The evaluation indicators are appointed as the inputs of statistical and multicriteria decision-making hybridization to prioritize the algorithms. The result of the Entropy Weights method and Combined Compromise Solution approach confirms that MOGWO has better performance for the medium-sizes, case study and an overall view. Also, NSHHO outclasses the small-size and large-size experiments.},
  archive      = {J_EAAI},
  author       = {Behzad Mosallanezhad and Fatemeh Gholian-Jouybari and Leopoldo Eduardo Cárdenas-Barrón and Mostafa Hajiaghaei-Keshteli},
  doi          = {10.1016/j.engappai.2023.105903},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105903},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The IoT-enabled sustainable reverse supply chain for COVID-19 pandemic wastes (CPW)},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Loop closure detection with patch-level local features and
visual saliency prediction. <em>EAAI</em>, <em>120</em>, 105902. (<a
href="https://doi.org/10.1016/j.engappai.2023.105902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loop closure detection (LCD) is essential in the field of visual Simultaneous Localization and Mapping (vSLAM). In the LCD system, geometrical verification based on image matching plays a crucial role in avoiding erroneous detections. This paper focuses on adopting patch-level local features for image matching to compute the similarity score between the current query image and the candidate images. However, an important factor that may reduce the robustness is that some distracting and dynamic regions in a scene (e.g., the sky, cars, pedestrians, the ground, etc.) are not helpful and may seriously harm the performance. To address this challenge, we first use a newly designed patch descriptor loss to optimize the distance relationship between the patch-level local features. In this way, the patch-level local features extracted from the query/candidate images are more suitable for performing image matching. Moreover, we mimic the visual attention mechanism and propose a patch matching with saliency strategy, which enables local patches in salient regions to play crucial roles in image matching by assigning suitable weights to them. Finally, experiments on several public datasets demonstrate that the proposed LCD system can achieve encouraging improvements over the state-of-the-art approaches regarding recall rates under 100% precision.},
  archive      = {J_EAAI},
  author       = {Sheng Jin and Xuyang Dai and Qinghao Meng},
  doi          = {10.1016/j.engappai.2023.105902},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105902},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Loop closure detection with patch-level local features and visual saliency prediction},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Separable-programming based probabilistic-iteration and
restriction-resolving correlation filter for robust real-time visual
tracking. <em>EAAI</em>, <em>120</em>, 105901. (<a
href="https://doi.org/10.1016/j.engappai.2023.105901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking methods based on correlation filter (CF) are to estimate the location and the scale of tracking object within video sequences. However, there are still several inadequate hypotheses within the CF framework. These inadequate hypotheses include the constant Gaussian label map, the predetermined object location and the insufficient utilization for features. To further address the problems caused by these hypotheses, this paper proposes a novel separable-programming based probabilistic-iteration and restriction-resolving correlation filter (PRCF). The main innovation points of this work are: 1) the separable-programming based tracking framework is adopted to achieve adaptive regulation incorporation and to simultaneously address location prediction and filter training; 2) the probabilistic-iteration scheme is suggested to update the Gaussian label for each frame to solve the problem of ad-hoc label map; 3) the adaptive feature fusion measure is introduced to abate the effects of insufficient utilization for numerous features; 4) the convergence behavior of PRCF is proved and discussed through theoretical analysis and worst-case convergence rate calculation. Experiments have also been conducted to test the efficiency of suggested PRCF on 7 benchmarks: OTB100, TC128, VOT2016, VOT2019, UAV123, NFS and LaSOT. The results have indicated that: 1) the PRCF obtains favorable performances compared with other 15 state-of-the-art (SOTA) CF-based trackers; 2) the PRCF reports comparable results against 4 deep learning based trackers; 3) the PRCF achieves a real-time speed of 52 frames-pre-second (FPS) on 7 benchmarks averagely. Thus, the PRCF is qualified for practical target tracking scenarios such as video surveillance and unmanned aerial vehicles (UAVs).},
  archive      = {J_EAAI},
  author       = {Baiheng Cao and Xuedong Wu and Jianxu Mao and Yaonan Wang and Zhiyu Zhu},
  doi          = {10.1016/j.engappai.2023.105901},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105901},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Separable-programming based probabilistic-iteration and restriction-resolving correlation filter for robust real-time visual tracking},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A swimming crab portunus trituberculatus re-identification
method based on RNN encoding of striped key regions. <em>EAAI</em>,
<em>120</em>, 105900. (<a
href="https://doi.org/10.1016/j.engappai.2023.105900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional tracing system of swimming Portunus trituberculatus uses invasive tags to identify individuals. However, the invasive tags are easily lost and vulnerable. Fortunately, with the development of intelligent imaging devices, these problems never affect the approaches of image-based re-identification (re-ID). Since the white spots on the P. trituberculatus carapace are controlled by genes, the spots can be regarded as the fingerprint of P. trituberculatus . On P. trituberculatus carapace, there are white spots sequentially distributed in some narrow-striped regions. In this paper, in order to identify individuals, we locate the striped key regions (SKRs) and novelly adopt RNN extracting features from SKRs. The process of P. trituberculatus re-ID consists of keypoints detection, SKRs segmentation, SKRs alignment, and SKRs encoding. In terms of keypoints detection and SKRs segmentation, we use Stacked Hourglass to detect keypoints on the P. trituberculatus carapace image. The detected keypoints are utilized to locate and segment 4 SKRs on P. trituberculatus carapace images, and after SKRs alignment being processed, the segmented SKRs are aligned and standardized. As standardized SKRs are narrow stripes, we use RNN to extract SKRs features for representing the SKRs. That is because the features obtained by RNN is verified more practical than CNN. Finally, experimental results show that the method we proposed outperforms other state-of-the-art re-ID algorithms on P. trituberculatus dataset.},
  archive      = {J_EAAI},
  author       = {Kejie Zhang and Yu Xin and Zhijun Xie and Ce Shi},
  doi          = {10.1016/j.engappai.2023.105900},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105900},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A swimming crab portunus trituberculatus re-identification method based on RNN encoding of striped key regions},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Smart farming using artificial intelligence: A review.
<em>EAAI</em>, <em>120</em>, 105899. (<a
href="https://doi.org/10.1016/j.engappai.2023.105899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart farming with artificial intelligence provides an efficient solution to today’s agricultural sustainability challenges. Machine learning, Deep learning, and time series analysis are essential in smart farming. Crop selection, crop yield prediction, soil compatibility classification, water management, and many other processes are involved in agriculture. Machine learning algorithms are used for crop selection and management, Deep learning techniques are used for crop selection and forecasting crop production, and time series analysis is used for demand forecasting of crops, commodity price prediction, and crop yield production forecasting. Crops are chosen using machine learning algorithms and deep learning algorithms based on soil, soil compatibility classification, and other factors. In the agriculture industry, this article offers a thorough review of machine learning and deep learning techniques. Crop data sets can be used to classify soil fertility, crop selection, and many other aspects using machine learning algorithms. Deep learning algorithms can be applied to farming data to do time series analysis and crop selection. Because there is more need for food due to the growing population, crop production forecasting is one of the crucial tasks. Therefore, future crop production must be predicted in order to overcome food insufficiency. In this article, several time series algorithms were reviewed. Suggesting appropriate crop recommendations using machine and deep learning by estimating crop yield by using time series analysis will reduce food insufficiency in the future.},
  archive      = {J_EAAI},
  author       = {Yaganteeswarudu Akkem and Saroj Kumar Biswas ( Ph.D. ) and Aruna Varanasi ( Ph.D. )},
  doi          = {10.1016/j.engappai.2023.105899},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105899},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Smart farming using artificial intelligence: A review},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive iterated stochastic metaheuristic to optimize holes
drilling path in manufacturing industry: The adaptive-dhouib-matrix-3
(a-DM3). <em>EAAI</em>, <em>120</em>, 105898. (<a
href="https://doi.org/10.1016/j.engappai.2023.105898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tool path optimization approaches are often used to reduce production time and cost, energy consumption, etc. on Computer Numerical Control Machines. Thus, several artificial intelligence algorithms based on Traveling Salesman Problem (TSP) have been implemented to optimize tool trajectory length in various production sectors mainly the holes drilling process. In this field, this article exhibits first a related works survey detailing the main used algorithms. Then, it suggests a novel approach for optimizing non-productive tool paths for drilling a hole series. The proposed approach entitled Adaptive-Dhouib-Matrix-3 (A-DM3) is based on combining the iterated stochastic Dhouib-Matrix-3 (DM3) with a tabu memory inspired by Tabu Search (TS) metaheuristic. To confirm its ability and stability to find the shortest drilling tool path, A-DM3 method is tested on six practical case studies of a rectangular matrix of holes. Further, it is compared to some commonly used algorithms such as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and some of its derivates, modified Shuffled Frog Leaping Algorithm (mSFLA), Cuckoo Search (CS), and hybrid Cuckoo Search Genetic Algorithm (CS-GA). Computational results proved the superiority of the proposed A-DM3 compared to these well-known metaheuristics in literature, particularly in a medium and large number of holes. Hence, A-DM3 provided a new shortest path length record with an improvement exceeding 100% in some cases compared to competing algorithms.},
  archive      = {J_EAAI},
  author       = {Souhail Dhouib and Alaeddine Zouari},
  doi          = {10.1016/j.engappai.2023.105898},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105898},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive iterated stochastic metaheuristic to optimize holes drilling path in manufacturing industry: The adaptive-dhouib-matrix-3 (A-DM3)},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel soft attention-based multi-modal deep learning
framework for multi-label skin lesion classification. <em>EAAI</em>,
<em>120</em>, 105897. (<a
href="https://doi.org/10.1016/j.engappai.2023.105897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is one of the fatal cancers worldwide. Early detection of this disease can significantly increase the survival rate. In this study, a multi-modal and soft attention based hybrid deep learning model is proposed for automated and accurate multi-label skin lesion classification. The proposed network includes a multi-branch structure that integrates feature maps from different modalities in a hybrid manner. These branches enable to extract features from multiple modalities separately and learn complex combinations between them. These branches include a modified Xception architecture, a new feature extraction method, as well as soft attention module that is proposed to make the network focus on discriminative parts of skin lesions. The final diagnosis is obtained by the fusion of the predictions from three branches. The proposed framework was evaluated on the publicly available seven-point criteria evaluation dataset, a well-established multi-modality multi-label skin disease dataset. It achieved an average accuracy of 83.04% for multi-label skin lesion classification. It is more accurate than the state-of-the-art methods and improves the average accuracy by more than 2.14% on the test set.},
  archive      = {J_EAAI},
  author       = {Asli Nur Omeroglu and Hussein M.A. Mohammed and Emin Argun Oral and Serdar Aydin},
  doi          = {10.1016/j.engappai.2023.105897},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105897},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel soft attention-based multi-modal deep learning framework for multi-label skin lesion classification},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). New improved CREAM model for human reliability analysis
using a linguistic d number-based hybrid decision making approach.
<em>EAAI</em>, <em>120</em>, 105896. (<a
href="https://doi.org/10.1016/j.engappai.2023.105896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since human errors are the critical factor contributing to accidents in safety-critical industries, human reliability analysis (HRA) becomes significant to improve the reliability of many complex engineering systems. In the real world, the assessment of human errors relies heavily on experts’ knowledge and experience. Moreover, there are challenges regarding the human error probability (HEP) estimation because of state evaluation information uncertainty, multiple common performance conditions (CPCs), and the correlations between CPCs. Therefore, this paper aims to propose a new improved cognitive reliability and error analysis method (CREAM) by integrating linguistic D numbers and the decision-making trial and evaluation laboratory-based analytic network process (DANP) method for the quantitative analysis of human errors. First, the linguistic D numbers are utilized to express the uncertain CPC state evaluations and the direct relations between CPCs provided by experts. Second, the DANP method is incorporated into the CREAM to determine the weights of CPCs considering their interdependencies and interactions. Then, a CPC effect index is introduced to quantify the CPCs’ overall effect upon performance reliability and obtain the HEP estimation. Finally, the feasibility and practicality of the proposed CREAM model are demonstrated through a practical case of the liquefied petroleum gas (LPG) cargo loading process. The results show that the new improved CREAM can effectively capture the uncertain state evaluation information, better depict the interdependences between CPCs, and obtain more reasonable HEP estimation in the HRA.},
  archive      = {J_EAAI},
  author       = {Hua Shi and Jing-Hui Wang and Ling Zhang and Hu-Chen Liu},
  doi          = {10.1016/j.engappai.2023.105896},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105896},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {New improved CREAM model for human reliability analysis using a linguistic d number-based hybrid decision making approach},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A high dimensional features-based cascaded forward neural
network coupled with MVMD and boruta-GBDT for multi-step ahead
forecasting of surface soil moisture. <em>EAAI</em>, <em>120</em>,
105895. (<a
href="https://doi.org/10.1016/j.engappai.2023.105895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study is to develop a novel multi-level pre-processing framework and apply it for multi-step (one and seven days ahead) daily forecasting of Surface soil moisture (SSM) based on the NASA’s Soil Moisture Active Passive (SMAP)-satellite datasets in arid and semi-arid regions of Iran. The framework consists of the Boruta gradient boosting decision tree (Boruta-GBDT) feature selection integrated with the multivariate variational mode decomposition (MVMD) and advanced machine learning (ML) models including bidirectional gated recurrent unit (Bi-GRU), cascaded forward neural network (CFNN), adaptive boosting (AdaBoost), genetic programming (GP), and classical multilayer perceptron neural network (MLP). For this purpose, effective geophysical soil moisture predictors for two arid stations of Khosrowshah and Neyshabur were first filtered among 21 daily input signals from 2015 to 2020 by using the Boruta-GBDT feature selection. The selected signals were then decomposed using the MVMD scheme. In the last pre-processing stage, the most relevant sub-sequences from a large pool in previous process were filtered using the Boruta-GBDT scheme aiming to reduce the computation and enhance the accuracy, before feeding the ML approaches. The comparison of the results from the five hybrid and standalone counterpart models in term of standardized RMSE improvement (SRMSEI) revealed that M V MD - B G - C FNN for SSM(T+1) | 27.13% and SSM (T+7) | 43.55% at Khosrowshah station and SSM(T+1) | 21.16% and SSM (T+7) | 30.10% at Neyshabur station outperformed the other hybrid frameworks, followed by M V MD - B G - B i−GRU , M V MD -BG- A daboost , M V MD - B G - G P , and M V MD - B G - M LP . The accurately forecasted SSM data help improve irrigation scheduling, which is of significant importance in water use efficiency and food security.},
  archive      = {J_EAAI},
  author       = {Mehdi Jamei and Mumtaz Ali and Masoud Karbasi and Ekta Sharma and Mozhdeh Jamei and Xuefeng Chu and Zaher Mundher Yaseen},
  doi          = {10.1016/j.engappai.2023.105895},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105895},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A high dimensional features-based cascaded forward neural network coupled with MVMD and boruta-GBDT for multi-step ahead forecasting of surface soil moisture},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence in healthcare: Review, ethics, trust
challenges &amp; future research directions. <em>EAAI</em>,
<em>120</em>, 105894. (<a
href="https://doi.org/10.1016/j.engappai.2023.105894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of artificial intelligence (AI) in medicine is beginning to alter current procedures in prevention, diagnosis, treatment, amelioration, cure of disease and other physical and mental impairments. In addition to raising concerns about public trust and ethics, advancements in this new emerging technology have also led to a lot of debate around its integration into healthcare. The objective of this work is to introduce researchers to AI and its medical applications, along with their potential pitfalls, in a comprehensive manner. This paper provides a review of current studies that have investigated how to apply AI methodologies to create a smart predictive maintenance model for the industries of the future. We begin with a brief introduction to AI and a decade’s worth of its advancements across a variety of industries, including smart grids, train transportation, etc., and most recently, healthcare. In this paper, we explore the various applications of AI across various medical specialties, including radiology, dermatology, haematology, ophthalmology, etc. along with the comparative study by employing several key criteria. Finally, it highlights the challenges for large-scale integration of AI in medical systems along with a summary of the ethical, legal, trust, and future implications of AI in healthcare.},
  archive      = {J_EAAI},
  author       = {Pranjal Kumar and Siddhartha Chauhan and Lalit Kumar Awasthi},
  doi          = {10.1016/j.engappai.2023.105894},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105894},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence in healthcare: Review, ethics, trust challenges &amp; future research directions},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An extended MARCOS method for MCGDM under 2-tuple linguistic
q-rung picture fuzzy environment. <em>EAAI</em>, <em>120</em>, 105892.
(<a href="https://doi.org/10.1016/j.engappai.2023.105892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current study is mainly devoted to explore and extend the measurement and ranking of alternatives according to the compromise solution under the background of 2-tuple linguistic q -rung picture fuzzy sets. The capability of q -rung picture fuzzy sets to accommodate a broad range of information, and the salient features of 2-tuple linguistic term sets to manage qualitative data motivate us to present the notion of 2-tuple linguistic q -rung picture fuzzy set. The linguistic terms are very useful to deal with the situations where the data providing the assessment of attributes are not easily quantified. This paper proposes and utilizes the Dombi operations to develop certain aggregation operators: 2-tuple linguistic q -rung picture fuzzy Dombi weighted averaging operator and 2-tuple linguistic q -rung picture fuzzy Dombi weighted geometric operator. The presented methodology utilizes the aforementioned operators to handle and aggregate data in decision-making problems. Furthermore, an example to select the best option among the collection of considered projects is handled through the proposed method to substantiate the extended approach. Ultimately, the validation of the developed technique is conducted through a comparative analysis.},
  archive      = {J_EAAI},
  author       = {Muhammad Akram and Ayesha Khan and Anam Luqman and Tapan Senapati and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2023.105892},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105892},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An extended MARCOS method for MCGDM under 2-tuple linguistic q-rung picture fuzzy environment},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-UAV trajectory optimizer: A sustainable system for
wireless data harvesting with deep reinforcement learning.
<em>EAAI</em>, <em>120</em>, 105891. (<a
href="https://doi.org/10.1016/j.engappai.2023.105891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wireless sensor network assisted by multiple autonomous unmanned aerial vehicles (UAVs) is a promising solution for harvesting data and monitoring the circumstance in various applications. However, the complicated path planning problem of each UAV is still problematic. In this paper, we propose an optimal operation strategy based on multi-agent reinforcement learning (MARL) to tackle these hurdles. Various parameters such as the number of deployed UAVs, charging start capacity, and charging complete capacity define a multi-UAV system. This approach is applicable without a time-consuming and costly policy control. We also describe how to balance multiple objectives, such as data harvesting, charging, and collision avoidance, using transfer learning. Finally, learning a policy control that generalizes multiple scenario parameters allows us to analyze the performance of individual parameters in a specific scenario, which helps find the macro-level optimal parameter within a particular scenario. Videos are available at https://github.com/mincheolseong/UAV-Trajectory-Optimizer .},
  archive      = {J_EAAI},
  author       = {Mincheol Seong and Ohyun Jo and Kyungseop Shin},
  doi          = {10.1016/j.engappai.2023.105891},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105891},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-UAV trajectory optimizer: A sustainable system for wireless data harvesting with deep reinforcement learning},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural architecture search algorithm to optimize deep
transformer model for fault detection in electrical power distribution
systems. <em>EAAI</em>, <em>120</em>, 105890. (<a
href="https://doi.org/10.1016/j.engappai.2023.105890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a neural architecture search algorithm for obtaining an optimum Transformer model to detect and localize different power system faults and uncertain conditions, such as symmetrical shunt faults, unsymmetrical shunt faults, high-impedance faults, switching conditions (capacitor switching, load switching, transformer switching, DG switching and feeder switching), insulator leakage and transformer inrush current in a distribution system. The Transformer model was proposed to tackle the high memory consumption of the deep CNN attention models and the long-term dependency problem of the RNN attention models. There exist different types of attention mechanisms and feedforward networks for designing a Transformer architecture. Hand engineering of these layers can be inefficient and time-consuming. Therefore, this paper makes use of the Differential Architecture Search (DARTS) algorithm to automatically generate optimal Transformer architectures with less search time cost. The algorithm achieves this by making the search process differentiable to architecture hyperparameters thus making the network search process an end-to-end problem. The proposed model attempts to automatically detect faults in a bus using current measurements from distant monitoring points. The proposed fault analysis was conducted on the standard IEEE 14 bus distribution system and the VSB power line fault detection database. The proposed model was found to produce better performance on the test database when evaluated using F1-Score (99.4% for fault type classification and 97.7% for fault location classification), Matthews Correlation Coefficient (MCC) (99.3% for fault type classification and 97.6% for fault location classification), accuracy and Area Under the Curve (AUC). The architecture transferability of the proposed method was also studied using real-world power line data for fault detection.},
  archive      = {J_EAAI},
  author       = {Jibin B. Thomas and Shihabudheen K.V.},
  doi          = {10.1016/j.engappai.2023.105890},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105890},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural architecture search algorithm to optimize deep transformer model for fault detection in electrical power distribution systems},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improvement of multi-objective evolutionary algorithm and
optimization of mechanical bearing. <em>EAAI</em>, <em>120</em>, 105889.
(<a href="https://doi.org/10.1016/j.engappai.2023.105889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some algorithms, Euclidean distance is used to calculate the crowded distance between subproblems. When Euclidean distance is used to calculate subproblems, it is found that the distribution of congestion degree is not ideal. Sub-problems with relatively high degree of congestion are often distributed in the center of Pareto frontier, while sub-problems with relatively low degree of congestion are distributed at the edges of Pareto frontier, especially the Pareto frontier shape is convex and reference vectors are constructed from the ideal point using Das and Dennis’s method for generation of points on unit simplex. To solve the above problems, an improved multi-objective evolutionary algorithm is proposed, called MOEA/D-ROE, and a weight vector adjustment strategy based on regional online evaluation is proposed by using the modified form of Tchebycheff function. In MOEA/D-ROE, subproblems with different congestion levels are divided into different areas. By setting corresponding parameters for each region and introducing Pareto advantages, the weights are adjusted regularly. Therefore, the weights of subproblems can be redistributed more evenly to obtain more uniform solutions. Finally, the regional online evaluation strategy is embedded into other algorithms to verify the effectiveness and portability of this strategy, and MOEA/D-ROE algorithm is applied to an application example. At the same time, it is proved that the improvement of the algorithm is meaningful for the optimization of practical problems.},
  archive      = {J_EAAI},
  author       = {Shuzhi Gao and Xuepeng Ren and Yimin Zhang},
  doi          = {10.1016/j.engappai.2023.105889},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105889},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improvement of multi-objective evolutionary algorithm and optimization of mechanical bearing},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non trust detection of decentralized federated learning
based on historical gradient. <em>EAAI</em>, <em>120</em>, 105888. (<a
href="https://doi.org/10.1016/j.engappai.2023.105888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a paradigm of distributed machine learning, federated learning is widely used in various real scenarios due to its excellent privacy protection performance on preventing local data from being disclosed. However, the traditional federated learning has the defect that a third-party server aggregates the models of various users since it’s difficult to guarantee the reliability of the third party, and multicentre phenomena frequently appeared in various applications, such as social networks, banking and finance, medical health, etc. Users can’t be reassured in decentralization setting due to the mixture of malicious and untrustworthy ones among them. Although untrustworthy users are benign, they may be classified as the saboteurs because of poor efficiency performance in decentralized federated learning which is caused by missing or ambiguity of data. In this paper, we propose Decentralized Federated Learning Historical Gradient (DFedHG) approach to distinguish normal users, untrustworthy users and malicious users in the decentralized federated learning setting. Simultaneously, by means of DFedHG, malicious users are sub-divided into targetless attacks and targeted attacks, which is verified by adopting two types of data sets for confirmation. The experimental results show that the proposed approach achieves better performance compared with the conventional decentralized federated learning without untrustworthy users, and further present excellent differentiation of malicious users.},
  archive      = {J_EAAI},
  author       = {Yikuan Chen and Li Liang and Wei Gao},
  doi          = {10.1016/j.engappai.2023.105888},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105888},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non trust detection of decentralized federated learning based on historical gradient},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial theory of mind in contextual automated
negotiations within peer-to-peer markets. <em>EAAI</em>, <em>120</em>,
105887. (<a
href="https://doi.org/10.1016/j.engappai.2023.105887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the sharing economy (eBay, Airbnb, Uber) and peer-to-peer electricity markets, negotiation agents become key to automate trading between prosumers. To be competitive, agents need to develop models of their opponents’ strategic behavior depending on contextual circumstances. However, existent approaches do not account for others’ ways of reasoning about how the context influences opponents’ strategies. In this work, negotiation agents are endowed with artificial Theory of Mind (aToM) to represent mental states of others. Those states include their strategies, beliefs, the context influencing beliefs and the beliefs they may have about the beliefs others have about themselves depending on the context. From prior knowledge that relates private and contextual states with opponent’s plausible strategies, agents build models of different orders of aToM using weighted Gaussian Processes with heteroscedastic noise and adapt their strategies. During a negotiation episode, each agent selects the order of aToM that best accounts for its opponent’s counteroffers based on Bayesian surprise. To assess the proposed approach, a benchmark Smart Grid is used, where energy prosumers negotiate on a peer-to-peer basis to compensate for their energy deficits and sell their surpluses. Results obtained highlight that low orders of aToM increase social welfare at least in a 54% despite the selfish nature of prosumers. Also, more sophisticated aToM abilities increase the individual competitiveness of agents. This is the first work in the related literature that adds aToM abilities to negotiation agents while considering the negotiation context.},
  archive      = {J_EAAI},
  author       = {Dan E. Kröhling and Omar J.A. Chiotti and Ernesto C. Martínez},
  doi          = {10.1016/j.engappai.2023.105887},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105887},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial theory of mind in contextual automated negotiations within peer-to-peer markets},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A low-cost framework for the recognition of human motion
gait phases and patterns based on multi-source perception fusion.
<em>EAAI</em>, <em>120</em>, 105886. (<a
href="https://doi.org/10.1016/j.engappai.2023.105886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing resolution and usage requirements of sensors and the increasing computational cost of algorithms, the application of existing human motion pattern and phase recognition systems in wearable systems is limited. This paper proposes a recognition system framework based on multi-source information fusion for the recognition of human gait patterns and phases. The framework utilizes multi-channel commercial low-cost sensors to obtain human motion information. By applying data fusion methods and preprocessing algorithms, the framework can uniformly process raw signals of uncertain dimensions from an uncertain number of sensors into a valid recognition vector with fixed dimensions. The obtained recognition vector can be used with commonly applied gait recognition algorithms to reduce the computational cost. Support vector machines, Backpropagation neural networks, AlexNet, and LeNet5 algorithms are used to evaluate the performance of the proposed gait recognition framework in recognizing gait phases and patterns. The experimental results show that the four algorithms using fusion signal can achieve a recognition accuracy of 97.7% for gait phases and an average recognition accuracy of over 99.2% for gait patterns, which proves the effectiveness of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Dianbiao Dong and Chi Ma and Miao Wang and Huong Thi Vu and Bram Vanderborght and Yuanxi Sun},
  doi          = {10.1016/j.engappai.2023.105886},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105886},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A low-cost framework for the recognition of human motion gait phases and patterns based on multi-source perception fusion},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bidirectional recursive gated dual attention unit based
RUL prediction approach. <em>EAAI</em>, <em>120</em>, 105885. (<a
href="https://doi.org/10.1016/j.engappai.2023.105885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing requirements for the reliability and safety of high-end equipment, the predictive maintenance of high-end equipment has been indispensable. The remaining useful life (RUL) prediction is a key part of predictive maintenance. Most existing studies regard the process of health degradation as a single-stage process, which demands the RUL prediction model to have high adaptability and generalization performance. However, current RUL prediction models cannot meet this requirement and predict accurately therefore cannot be achieved as expected. In view of that, this paper proposes a stage division method and constructs a powerful RUL prediction model to solve this problem. Firstly, a novel continuous gradient recognition algorithm is developed to identify the degradation initial time, and then the whole health degradation process is divided into two stages, called the normal operation stage and the accelerated degradation stage. Secondly, a bidirectional recursive gated dual attention unit is proposed to predict the RUL during the accelerated degradation stage. It introduces two attention gates into the classical gated recurrent unit and constructs a bidirectional structure to fully learn the forward and backward degradation law of time series as well as the initial hidden state of the forward network is corrected by the final hidden state of the backward network. Two real bearing datasets are analyzed to verify the effectiveness and capability of the proposed method. Finally, the comparative analysis is implemented and the results further show that the proposed method has better performance both in prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Lei Yang (杨磊) and Yuhe Liao (廖与禾) and Rongkai Duan (段蓉凯) and Tao Kang (康涛) and Jiutao Xue (薛久涛)},
  doi          = {10.1016/j.engappai.2023.105885},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105885},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A bidirectional recursive gated dual attention unit based RUL prediction approach},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recognition of oil &amp; gas pipelines operational states
using graph network structural features. <em>EAAI</em>, <em>120</em>,
105884. (<a
href="https://doi.org/10.1016/j.engappai.2023.105884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The monitoring and recognition of operational states pattern is a crucial part for maintaining the safety, reliability and profitability of oil and gas pipeline systems. However, there are fewer methods to monitor the operational status of long-distance pipelines through operational data alone. In this paper, a purely data-driven approach is proposed for detecting and identifying the operational status of pipeline systems based on machine learning methods and the data log of pipelines. Firstly, a logic rule-based method is proposed to enrich the labels for each segment of operational data. Secondly, a change point-based detection model is used to detect the change of operational state in pipeline system or equipment. Then, a framework of oil pipeline operational pattern recognition methods based on graph structural features is proposed. Finally, the proposed model is applied to a real-world data from a pipeline system in China. Both the accuracy and the breadth of the recognition results can be improved by the use of real-time data validation and a human-machine interface. The results show that the precision of a change point-based detection model can reach more than 85% for different scenarios, and a reduction in missed rate of 17%–26%. Compared with the statistical feature-based method, the proposed method has improved the accuracy for all types of scenarios to a certain extent. The most significant improvement in recognition accuracy was achieved in the valve switch state and the combined state, with an increase of 30.8% and 5% respectively.},
  archive      = {J_EAAI},
  author       = {Li Zhang and Laurent Yeh and Huai Su and Karine Zeitouni and Zhiheng Zuo and Miao Li and Luxin Jiang and Lin Fan and Jinjun Zhang},
  doi          = {10.1016/j.engappai.2023.105884},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105884},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recognition of oil &amp; gas pipelines operational states using graph network structural features},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An end-to-end harmful object identification method for sizer
crusher based on time series classification and deep learning.
<em>EAAI</em>, <em>120</em>, 105883. (<a
href="https://doi.org/10.1016/j.engappai.2023.105883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with a maximum annual capacity of 30 million tons in one large coal preparation plant, the corresponding belt speed can reach 7 m/s and the coal layer thickness will be more than 500 mm. These lead to harmful components, such as iron, gangue, and wood, being mixed into the coal and seriously damaging parts of sizer crushers (sizers) during the crushing process. The traditional method for harmful object identification and fault diagnosis is manual feature extraction (MFE), which has drawbacks such as dependence on experience, poor stability, and inflexibility. In this paper, an end-to-end (E2E) harmful object identification model was proposed for sizers based on time series classification (TSC) and deep learning. The model learned features directly from the one-dimensional multi-channel raw signals of sound pressure and vibration without MFE and has been tested on experimental and industrial datasets to validate its effectiveness and flexibility. Results showed that the E2E method proposed in this paper can reach a classification accuracy of 87.42% for feed including coal, iron, and wood. In particular, the identification ability for iron can be outstanding. The industrial testing indicated that the identification precision of iron could be 99.10%. To further improve the model’s classification accuracy, the identification of mixture materials will be a key focus in the future.},
  archive      = {J_EAAI},
  author       = {Yankun Bi and Yongtai Pan and Chao Yu and Mengchao Wang and Tongyu Cui},
  doi          = {10.1016/j.engappai.2023.105883},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105883},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An end-to-end harmful object identification method for sizer crusher based on time series classification and deep learning},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alphabet flatting as a variant of n-gram feature extraction
method in ensemble classification of fake news. <em>EAAI</em>,
<em>120</em>, 105882. (<a
href="https://doi.org/10.1016/j.engappai.2023.105882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of disinformation becomes a significant challenge in the modern world. Most of our communication media and most of the sources of information about reality are located on the distributed network services, where the published content is usually not a subject to any initial verification. One of the few tools that seem to be able to process such large volumes of data efficiently are pattern recognition methods employing extraction of features obtained through the Natural Language Processing models and procedures. The following paper is proposing an Alphabet Flatting – a modification of the preprocessing method for the feature extraction from large language corpora – allowing the construction of diverse classifier ensembles integrated by the support accumulation, the generalization power of which may compete with quality of the state-of-the-art models in environments with strict time constraints. The proposed method has been thoroughly evaluated with the set of computer experiments, the results of which allow us to conclude its potential usefulness in the solutions of the automatic systems for preventing the spread of fake news.},
  archive      = {J_EAAI},
  author       = {Paweł Ksieniewicz and Paweł Zyblewski and Weronika Borek-Marciniec and Rafał Kozik and Michał Choraś and Michał Woźniak},
  doi          = {10.1016/j.engappai.2023.105882},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105882},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Alphabet flatting as a variant of n-gram feature extraction method in ensemble classification of fake news},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy enabled driver behavior analysis in heterogeneous
IoV using federated learning. <em>EAAI</em>, <em>120</em>, 105881. (<a
href="https://doi.org/10.1016/j.engappai.2023.105881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Vehicles (IoV) is a paradigm of ITS that incorporates automobiles, transportation, information sharing, and traffic infrastructure management with the aim to improve safety on roads. Federated learning enables the Internet of Vehicles (IoV) networks with minimal data communication overhead and privacy infringement. The vehicles participate in model training for improving the model accuracy at the global level and enhancing road safety to a great extent. In this paper, we apply federated learning to driver behavior analysis in which the vehicles in the network collaborate to train CNN-LSTM and CNN-Bi-LSTM deep learning models for driver behavior classification (safe, unsafe, or fatigue) without sharing raw data. The CNN-LSTM and CNN-Bi-LSTM models have been implemented and analyzed using real-time driver’s behavior data, collected using inbuilt smartphone sensors or vehicle onboard devices. The proposed model has been evaluated using the performance parameters viz., accuracy, Area Under Curve (AUC), loss, precision, and recall. Both IID and non-IID types of datasets have been considered for analyzing the diversity of the proposed model. It is evident that implementation of federated learning architecture provided similar parametric outcomes on IID and non-IID datasets in comparison to contemporary deep learning implementations on a non-distributed dataset. The proposed work aims towards designing a reliable intelligent transportation system using federated learning.},
  archive      = {J_EAAI},
  author       = {Rishu Chhabra and Saravjeet Singh and Vikas Khullar},
  doi          = {10.1016/j.engappai.2023.105881},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105881},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Privacy enabled driver behavior analysis in heterogeneous IoV using federated learning},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-step unsupervised clustering based on information
theoretic metric and adaptive neighbor manifold regularization.
<em>EAAI</em>, <em>120</em>, 105880. (<a
href="https://doi.org/10.1016/j.engappai.2023.105880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering is a basic subject in the field of machine learning, but most of them still have the following deficiencies. First, the extra discretization procedures leads to instability of the algorithm. In addition, the traditional method of constructing similarity graphs is based on the pairwise distance, so it is extremely sensitive to the original data, and also lacks specific physical meaning from the perspective of probabilistic prediction. Final, the traditional metrics based on Euclidean distance is difficult to tackle non-Gaussian noise. In order to eliminate these limitations, a one-step unsupervised clustering based on information theoretic metric and adaptive neighbor manifold regularization method (ITMNMR) is proposed. (1) The clustering results are directly obtained according to the constructed similarity graph, avoiding extra discretization procedures; (2) A maximum entropy regularization term is introduced into the probabilistic model to avoid trivial similarity distributions. Furthermore, we introduce a Laplacian rank constraint and ℓ 0 -norm to construct adaptive neighbors with sparsity and strength segmentation capabilities; (3) To overcome the impression of noise, reconstruction based on correntropy is introduced to solve the non-Gaussian noise, and graph regularization is performed based on clean data. Furthermore, a half-quadratic optimization method is used to transform the problem into a quadratic form to facilitate subsequent solutions. Finally, our empirical study shows encouraging results of ITMNMR in comparison to classical algorithms and the state-of-the-art algorithms on 9 datasets. The robustness of the proposed method is also demonstrated from three experiments of adding Laplacian noise, salt&amp;pepper noise, and block occlusion.},
  archive      = {J_EAAI},
  author       = {Xinyu Li and Hui Fan and Jinglei Liu},
  doi          = {10.1016/j.engappai.2023.105880},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105880},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {One-step unsupervised clustering based on information theoretic metric and adaptive neighbor manifold regularization},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel group decision-making framework under pythagorean
fuzzy n-soft expert knowledge. <em>EAAI</em>, <em>120</em>, 105879. (<a
href="https://doi.org/10.1016/j.engappai.2023.105879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many scholars have been challenged by multi-attribute group decision-making problems that have stimulated the appearance of increasingly general models. Pythagorean fuzzy sets were a reaction by Yager who in 2013, suggested this model to improve the performance of intuitionistic fuzzy sets. Another hybrid model –soft expert sets– deals with uncertain parameterized information. It considers opinions of different experts, improving the single-agent experience of soft sets. N -soft expert sets and their fuzzy version, namely, fuzzy N -soft expert sets, consider the ratings given to objects by more than one expert with respect to relevant parameters. The arguments supporting the need for independent allocation of membership and non-membership degrees apply to the fuzzy expressions imposed on top of the benefits of the N -soft expert environment. These challenges converge on the formulation of a new hybrid model called Pythagorean fuzzy N-soft expert sets that improves upon Pythagorean fuzzy sets with the benefits of N -soft expert sets. We study their scope of application with practical examples. Afterwards we discuss certain basic operators (subsethood, complement, union and intersection), prove some of their remarkable properties, and provide the concepts of equal, agree, and disagree-Pythagorean fuzzy N -soft expert sets. We present an algorithm for group decision-making problems in this framework and we explore three applications of this methodology, namely, to the analysis of wheat varieties, employee selection, and recovery order of patients suffering COVID-19. In the end, we provide a sensitivity analysis comparing the proposed model with some existing models to guarantee its cogency and feasibility.},
  archive      = {J_EAAI},
  author       = {Muhammad Akram and Ghous Ali and José Carlos R. Alcantud},
  doi          = {10.1016/j.engappai.2023.105879},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105879},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel group decision-making framework under pythagorean fuzzy N-soft expert knowledge},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating machine learning and model predictive control
for automotive applications: A review and future directions.
<em>EAAI</em>, <em>120</em>, 105878. (<a
href="https://doi.org/10.1016/j.engappai.2023.105878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this review paper, the integration of Machine Learning (ML) and Model Predictive Control (MPC) in Automotive Control System (ACS) applications are discussed. ACS can be divided into these three main subsystems: enhancing safety, improving comfort, and reducing fuel consumption and emissions. Due to the development of new technologies such as advancing autonomous and connected vehicles the complexity of these subsystems is increasing. The ACS is meant to encompass the vehicle dynamics, powertrain control, passenger comfort, and accessories. Since vehicle manufacturers must meet stringent performance and emission requirements, optimal control methods for ACS applications are seen as a promising technology. MPC is an optimal control method for closed-loop control applications that allows constraints to be enforced in real-time while an objective function is minimized. The application of MPC in the automotive industry has been shown in the past decade. An important challenge in the design and real-time implementation of MPC is having a accurate predictive model that also does not require excessive real-time computation. Using ML to provide an accurate model at decreased computational cost improves MPC performance of ACS and is the main focus of this paper. How MPC in ML-based ACS applications ensures stability while meeting constraint is also discussed. Method to combine MPC and ML for the ACS subsystems of vehicle dynamics and powertrain control are reviewed and an outlook on future ACS is discussed.},
  archive      = {J_EAAI},
  author       = {Armin Norouzi and Hamed Heidarifar and Hoseinali Borhan and Mahdi Shahbakhti and Charles Robert Koch},
  doi          = {10.1016/j.engappai.2023.105878},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105878},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating machine learning and model predictive control for automotive applications: A review and future directions},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). A cooperative memetic algorithm for energy-aware
distributed welding shop scheduling problem. <em>EAAI</em>,
<em>120</em>, 105877. (<a
href="https://doi.org/10.1016/j.engappai.2023.105877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facing globalization trends and sustainable industrial development, energy-aware distributed manufacturing has become an emerging topic. Meanwhile, welding is a kind of indispensable processing in the development of manufacturing and its effective scheduling can improve production efficiency and reduce energy consumption. However, it is difficult to solve the energy-aware distributed welding shop scheduling problem (EADWSP) due to the characteristics of large scale and multiple objectives. Thus, this paper presents a mathematical model and a cooperative memetic algorithm (CMA) to addresses the EADWSP with minimization both makespan and total energy consumption. To improve the quality and diversity of initial population, a hybrid initialization is developed with a modified NEH based heuristic. Via taking full advantage of historical information, a cooperative search based on feedback is designed and a cooperative selection strategy is employed to balance the exploration and exploitation. In addition, multiple problem-specific operators are presented and a local intensification with Q-learning is designed to enhance exploitation capability. Numerical experiments are carried out and the results demonstrate the effectiveness of the above specific designs. The comparisons to the existing algorithms show superiority of the proposed CMA. Moreover, the application to a real-life case also verifies the effectiveness and practicability in solving the EADWSP.},
  archive      = {J_EAAI},
  author       = {Jing-jing Wang and Ling Wang and Xia Xiu},
  doi          = {10.1016/j.engappai.2023.105877},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105877},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A cooperative memetic algorithm for energy-aware distributed welding shop scheduling problem},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A mixed closed-open multi-depot routing and scheduling
problem for homemade meal delivery incorporating drone and crowd-sourced
fleet: A self-adaptive hyper-heuristic approach. <em>EAAI</em>,
<em>120</em>, 105876. (<a
href="https://doi.org/10.1016/j.engappai.2023.105876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meal delivery services is an enormous competitive market, and the most influential factor in this market is customer experience. As a result, it is crucial to have an efficient delivery system that ensures customer satisfaction regarding on-time, fresh delivery of meals. Accordingly, taking advantage of novel modes of transportation and developing relevant planning approaches can help companies preserve their competitive edge. In this context, the present paper aims to optimize the delivery operations of a homemade meal delivery start-up by adding drones and crowdsourcing, as two innovative modes, to its current system. The addressed problem is an extension of a mixed closed-open pickup and delivery vehicle routing problem. It includes multi-modal transportation fleet and time windows; besides, the meals are time-sensitive and the orders may need to be synchronized. For this purpose, first, a multi-objective mathematical model is devised that considers transportation costs, freshness of the delivered meals, and due-date satisfaction as the objective functions. Afterwards, an efficient self-adaptive hyper-heuristic method is developed to deal with the complexity of the problem. This hyper-heuristic method is based on genetic algorithm and modified particle swarm optimization, and incorporates novel selection and mutation mechanisms. Applying the model to a case study demonstrated that employing drones and crowdsourcing entails 13.7%, 8.5%, and 20.7% improvement in the cost, meal freshness, and weighted due-date satisfaction, respectively.},
  archive      = {J_EAAI},
  author       = {Mahdi Hamid and Mohammad Mahdi Nasiri and Masoud Rabbani},
  doi          = {10.1016/j.engappai.2023.105876},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105876},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A mixed closed-open multi-depot routing and scheduling problem for homemade meal delivery incorporating drone and crowd-sourced fleet: A self-adaptive hyper-heuristic approach},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Experimental evaluation, modeling and sensitivity analysis
of temperature and cutting force in bone micro-milling using support
vector regression and EFAST methods. <em>EAAI</em>, <em>120</em>,
105874. (<a
href="https://doi.org/10.1016/j.engappai.2023.105874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In orthopedic surgeries, examining the effect of machining conditions are very crucial due to the possibility of damage to the bone tissue, and the occurrence of thermal necrosis. Considering that a comprehensive and methodical study based on the design of experiment method, artificial intelligence modeling and sensitivity analysis can complement the previous investigations, so we found this motivation to explore the behavior of the two important variables of cutting force and temperature in the cortical bone micro-milling operation. Accordingly, in this paper, the effect of micro-milling conditions, including feed rate, tool rotational speed, tool diameter, and cutting depth on cutting force and temperature have been investigated simultaneously. For this purpose, based on the design of experiment technique, the set of experimental tests was performed on fresh cortical bone. Next, a machine learning technique known as support vector regression (SVR) is used to model and predict the force and temperature in the machining procedure. Subsequently, based on the attained model, a big dataset is prepared, and by utilizing the extended Fourier amplitude sensitivity test (EFAST), the effectiveness of the output variables on the input parameters was determined. The SVR predictor achieved the root mean square error of (0.329, 2.133), the mean absolute error of (0.277, 1.820), the mean absolute percentage error of (9.266, 5.353), and the correlation factor of (0.971, 0.904) for (force, temperature). Also, it is realized that, feed rate, rotational speed, cutting depth, and tool diameter, affect the (force, temperature) by (46%, 8.9%), (34%, 9.2%), (15%, 1.5%), and (4%, 80.3%), respectively. By using the attained model of bone micro-milling operation, the surgeons can predict the temperature and force under different machining parameters before the surgery, consequently choosing the optimized machining conditions to reduce the temperature and cutting force.},
  archive      = {J_EAAI},
  author       = {Amir Hossein Rabiee and Vahid Tahmasbi and Mahdi Qasemi},
  doi          = {10.1016/j.engappai.2023.105874},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105874},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Experimental evaluation, modeling and sensitivity analysis of temperature and cutting force in bone micro-milling using support vector regression and EFAST methods},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Underground mine truck travel time prediction based on
stacking integrated learning. <em>EAAI</em>, <em>120</em>, 105873. (<a
href="https://doi.org/10.1016/j.engappai.2023.105873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The travel time (TT) prediction of underground mine transport trucks provides essential information for the precise scheduling of mine intelligent dispatching systems. Given the operational requirements and transportation environment of underground mines, in this study, a TT prediction method for underground mine transportation trucks is proposed based on stacking integrated learning. First, depending on the position and status of the transport truck, the truck operation cycle process is broken down into three sections and six stages. The influencing factors of the trucks’ TT in each stage are determined from the perspectives of personnel, equipment, and environment. During the collection process of the influencing factors the road surface roughness data are collected through image processing as part of the influence factor data. The influencing factors’ data are used as input parameters for the stacking integrated learning prediction model. The prediction performance of the fusion model is compared with that of the single models and their pairwise combinations. The final prediction results show that the fusion model performs the best in the drifts, ramps, and ground road sections. The average absolute percentage errors of the predicted values in the three road sections are 2.3091%, 4.3906%, and 4.5583%, respectively, and the corresponding decision coefficients are 0.9890, 0.9801, and 0.9050. These results show that the prediction model based on the stacking integrated framework proposed in this paper has a high prediction accuracy and stability. This accurate model can meet the requirements of intelligent dispatching systems for underground mines.},
  archive      = {J_EAAI},
  author       = {Ning Li and Yahui Wu and Qizhou Wang and Haiwang Ye and Liguan Wang and Mingtao Jia and Shugang Zhao},
  doi          = {10.1016/j.engappai.2023.105873},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105873},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Underground mine truck travel time prediction based on stacking integrated learning},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-input CNN based vibro-acoustic fusion for accurate
fault diagnosis of induction motor. <em>EAAI</em>, <em>120</em>, 105872.
(<a href="https://doi.org/10.1016/j.engappai.2023.105872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Induction motor (IM) is a highly efficient prime mover in industrial applications. To maintain an uninterrupted operation, accurate fault diagnosis system of IM is required. It can help to improve operational safety and prevent unexpected economic losses. The traditional diagnosis methods are less capable of dealing with real-time and varying working environments. This paper presents a vibro-acoustic fusion technique for an accurate fault diagnosis under varying working conditions. The suggested method fuses the features of vibration and acoustic signals using Multi Input-Convolutional Neural Network (MI-CNN) technique. At first, raw vibration and acoustic signals are acquired at varying speeds and converted into a time–frequency spectrum using the Constant Q-Non-Stationary Gabor Transform (CQ-NSGT). Thereafter, a MI-CNN-based vibro-acoustic fusion is adopted for the fusion of vibration and acoustic features. Six distinct motor conditions are utilized to compute the effectiveness of the suggested MI-CNN model. Further, two additional datasets, i.e., bearing and the gearbox datasets, are employed to validate the suggested approach. The experimental results demonstrate that the suggested methodology is accurate and reliable for IMs and other components of rotating machine.},
  archive      = {J_EAAI},
  author       = {Anurag Choudhary and Rismaya Kumar Mishra and Shahab Fatima and B.K. Panigrahi},
  doi          = {10.1016/j.engappai.2023.105872},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105872},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-input CNN based vibro-acoustic fusion for accurate fault diagnosis of induction motor},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RSAL-iMFS: A framework of randomized stacking with active
learning for incremental multi-fidelity surrogate modeling.
<em>EAAI</em>, <em>120</em>, 105871. (<a
href="https://doi.org/10.1016/j.engappai.2023.105871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-fidelity surrogate (MFS) modeling incorporates a large number of low-fidelity (LF) samples with a small size of high-fidelity (HF) samples to obtain accurate HF approximations of unknown inputs. Because they save costs when labeling massive HF samples, MFS modeling techniques have been widely used in many engineering problems such as rapid simulation and mechanism optimization. In this paper, we propose a framework of randomized stacking with active learning for incremental MFS modeling (RSAL-iMFS). The framework contains two parts: randomized stacking for incremental MFS modeling (RS-iMFS) and query-by-committee (QBC)-based active learning for MFS modeling (QBC-AL-MFS). In particular, we first randomly project the inputs of LF samples into different spaces spanned by random projection matrices to form new LF samples and build a series of LF regressors based on the transformed LF samples to capture the LF features from different views. Then, these base LF regressors are stacked to form the inputs of the subsequent incremental Gaussian process regression (iGPR) model for approximating the HF responses. To achieve improved modeling performance, we also adopt the QBC-based active learning (QBC-AL) method to recommend unlabeled inputs from the input pool of candidate HF samples according to their distances, which are weighted by using the divergence of the committee voting results. We then label these recommended inputs to incrementally update the current iGPR model. Numerical experiments validate the proposed framework in incremental MFS modeling tasks and show that (1) RSAL-iMFS outperforms the state-of-the-art models; (2) Gaussian projection matrices (GPMs) can be reasonable choices in most cases; and (3) RSAL-iMFS’s modeling performance has low sensitivity to the choice of the number of base regressors.},
  archive      = {J_EAAI},
  author       = {Zongqi Liu and Xueguan Song and Chao Zhang and Yunsheng Ma and Dacheng Tao},
  doi          = {10.1016/j.engappai.2023.105871},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105871},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RSAL-iMFS: A framework of randomized stacking with active learning for incremental multi-fidelity surrogate modeling},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An optimized grey transition verhulst method. <em>EAAI</em>,
<em>120</em>, 105870. (<a
href="https://doi.org/10.1016/j.engappai.2023.105870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first-order grey model is appropriate for monotonic time series, while the grey Verhulst model is appropriate for periodic time series. The grey Verhulst model is widely used for predicting practical nonlinear time series that contain fluctuations. Despite the successful application of the grey models in practice, researchers show that grey models still have room for improvement. Moreover, recent research shows that grey models are sensitive to initial conditions. In many practical problems, the value of initial conditions is not accurate and suffers from noise or approximation errors, resulting in inaccurate prediction. To address these difficulties, an improved grey Verhulst method using particle swarm optimization is proposed in this paper. The proposed model consists of two stages. In the first stage, a second-order polynomial with unknown coefficients is used to approximate the 1- AGO. In the second stage, the initial element of the time series is modified to improve the accuracy of the prediction. The particle swarm optimization method is used to search for the unknown coefficients. It is found that PSO is a suitable optimization method for the proposed method because it is stable and generates a sequence of points that converges to a globally optimal solution. To demonstrate the efficiency and stability of the proposed method, it was applied to five practical problems, namely, gas production in China, the number of hazardous chemical accidents, CO2 emissions in Russia, the number of domestic tourists in China, and traffic flows in Canada. Numerical results show that the method is more accurate and robust than existing methods.},
  archive      = {J_EAAI},
  author       = {Hanif Heidari and Bo Zeng},
  doi          = {10.1016/j.engappai.2023.105870},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105870},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An optimized grey transition verhulst method},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel self-learning fuzzy predictive control method for
the cement mill: Simulation and experimental validation. <em>EAAI</em>,
<em>120</em>, 105868. (<a
href="https://doi.org/10.1016/j.engappai.2023.105868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality and ratio of clinker, the fineness of cement are key factors affecting the strength of cement. In order to realize the target tracking control of cement strength, a self-learning fuzzy predictive control algorithm is proposed to calculate the adjustment variables of cement grinding process Considering the serious hysteresis of cement strength detection, the 3-day cement strength needs to be predicted, statistical models cannot actually guide the production for the loss of working conditions. In this paper, a 3-day strength prediction model is established based on step response which is trained by difference data. The cement grinding process is a complex industrial process which is composed of multiple sub-processes and the variables are coupled each other, according to the characteristic, a multi-variable distributed fuzzy control algorithm (MVDFC) is proposed, and the fuzzy rules are mined by Apriori algorithm. The verification results from the actual field data demonstrate the effectiveness and superiority of the proposed method, which can completely meet the actual needs of the process.},
  archive      = {J_EAAI},
  author       = {Tianyu Ma and Zhipeng Li and Jinping Liu and Abdulhameed F. Alkhateeb and Hadi Jahanshahi},
  doi          = {10.1016/j.engappai.2023.105868},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105868},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel self-learning fuzzy predictive control method for the cement mill: Simulation and experimental validation},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Randomized learning-based classification of sound quality
using spectrogram image and time-series data: A practical perspective.
<em>EAAI</em>, <em>120</em>, 105867. (<a
href="https://doi.org/10.1016/j.engappai.2023.105867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio classification is an important research topic in the deep learning field, and classification accuracy has developed exponentially. However, as the model performance increases, it becomes difficult to apply it to actual industrial data owing to limitations such as the requirement of a large amount of data or increased training time. In this study, we developed a method for a small dataset with ambiguous classification boundaries, similar to most industrial data. We used randomized learning methods to reduce the training time and the risk of overfitting that required low computing time and few hyperparameters. Vehicle interior noise data were used as industrial data. The data were classified into luxury, powerful, and sporty, according to the human emotional reactions. Data was recorded from approximately 300 vehicles in the same environment and preprocessed into two types: spectrogram images and time-series data. Through deep fuzzy c-means clustering, it was confirmed that the classification boundary of the vehicle interior noise data was ambiguous. We selected the random vector functional link (RVFL), deep RVFL, and random kernel transformation (ROCKET) as randomized learning methods and compared the results with convolutional neural network and long short term memory. RVFL and deep RVFL showed similar classification accuracy to deep learning but significantly reduced training time by approximately 99%. In the case of ROCKET, the training time was reduced by approximately 91% and the classification performance was improved by approximately 3%. In addition, all randomized learning methods have few hyperparameters, which significantly reduces the classification model design time.},
  archive      = {J_EAAI},
  author       = {Yejin Kang and Jongsoo Lee},
  doi          = {10.1016/j.engappai.2023.105867},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105867},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Randomized learning-based classification of sound quality using spectrogram image and time-series data: A practical perspective},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Open-circuit fault diagnosis in voltage source inverter for
motor drive by using deep neural network. <em>EAAI</em>, <em>120</em>,
105866. (<a
href="https://doi.org/10.1016/j.engappai.2023.105866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To increase the reliability of motor drive system, many fault diagnosis approaches have been reported with regard to three-phase Pulse Width Modulation Voltage Source Inverter (PWM-VSI). Based on feature engineering and deep neural network, this paper proposes a fault diagnosis approach for the VSI in three-phase Permanent-magnet Synchronous Motor (PMSM) drive. The three-phase current signals are used for the fault diagnosis of VSI. 10 typical signal features are extracted from the three-phase current signals and used as the input of deep neural network. To improve the diagnostic performance, the network structure of the presented deep neural network is designed like a pyramid. Experimental results show that the presented method can detect not only the single open-circuit faults but also the double open-circuit faults in power switches, with high diagnostic accuracy (more than 95%). Besides, comparison results show that the presented method has strong generalization performance. This paper provides theoretical guidance for the fault diagnosis of VSI in PMSM.},
  archive      = {J_EAAI},
  author       = {Hao Yan and Yumeng Peng and Wenjun Shang and Dongdong Kong},
  doi          = {10.1016/j.engappai.2023.105866},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105866},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Open-circuit fault diagnosis in voltage source inverter for motor drive by using deep neural network},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic waste detection with few annotated samples:
Improving waste management efficiency. <em>EAAI</em>, <em>120</em>,
105865. (<a
href="https://doi.org/10.1016/j.engappai.2023.105865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic waste detection in natural environments exhibits a great potential to improve the efficiency and reduce the labor cost of waste management. Recent deep learning-based waste detectors rely heavily on substantial annotated samples for training, but annotating sufficient samples for various categories of waste is labor-intensive and time-consuming. To address this issue, this paper simulates the visual system of human beings and develops a few-shot waste detection framework. To enable the proposed framework more suitable for waste detection, a waste proposal module using a comprehensive feature fusion manner is designed to allow the features of support images to fully interact with those of query images, guiding the framework to generate more potential region proposals containing waste. Also, a waste classification module using soft attention mechanism and foreground mask is designed to alleviate the issue of spatial misalignment and achieve the fine-grained classification towards waste-related proposals. The proposed framework is a general detection framework which can flexibly detect various categories of waste with few labeled samples (i.e., less than 30 instances per category). Experimental results show that the proposed framework achieves a mean average precision of 31.16% over 12 waste categories when only few samples (i.e., 30 instances per category) are provided, surpassing a state-of-the-art few-shot detector named AFDNet by 1.68%. This data scale-insensitive nature allows humans to reduce the effort and time required for laborious waste image collection and annotation, significantly increasing the flexibility of automatic waste detection and boosting the efficiency of waste management.},
  archive      = {J_EAAI},
  author       = {Wei Zhou and Lei Zhao and Hongpu Huang and Yuzhi Chen and Sixuan Xu and Chen Wang},
  doi          = {10.1016/j.engappai.2023.105865},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105865},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic waste detection with few annotated samples: Improving waste management efficiency},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised rotation-invariant representation learning
for wafer map pattern analysis. <em>EAAI</em>, <em>120</em>, 105864. (<a
href="https://doi.org/10.1016/j.engappai.2023.105864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, data-driven approaches have been widely employed to analyze the defect patterns in wafer maps, which are crucial for identifying the root causes of failures in the semiconductor fabrication process. Representation learning embeds wafer maps into compact vector representations of useful features, based on which various downstream tasks can be performed to efficiently analyze the patterns on a large scale. If wafer maps are annotated with their defect class labels, the learned representations of wafer maps will be more informative and discriminative in defect patterns. However, the manual labeling of all wafer maps by domain experts is difficult due to practical constraints. In this study, we present a semi-supervised representation learning method that fully utilizes the information from both unlabeled and labeled wafer maps to learn better representations of wafer maps with a lower labeling cost. Given a partially labeled dataset, rotation-invariant representations of wafer maps are learned using the following three objectives. First, each unlabeled wafer map is close to any wafer map of a certain class and far from those of other classes. Second, each pair of labeled wafer maps are close to each other if they belong to the same class and are far from each other otherwise. Third, the different rotations of each wafer map are close to each other for both the unlabeled and labeled wafer maps. The effectiveness of the proposed method is demonstrated for various downstream tasks related to wafer map pattern analysis: visualization, clustering, retrieval, and classifier training.},
  archive      = {J_EAAI},
  author       = {Hyungu Kang and Seokho Kang},
  doi          = {10.1016/j.engappai.2023.105864},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105864},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised rotation-invariant representation learning for wafer map pattern analysis},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Empirical study of the modulus as activation function in
computer vision applications. <em>EAAI</em>, <em>120</em>, 105863. (<a
href="https://doi.org/10.1016/j.engappai.2023.105863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we propose a new non-monotonic activation function: the modulus . The majority of the reported research on nonlinearities is focused on monotonic functions. We empirically demonstrate how by using the modulus activation function on computer vision tasks the models generalize better than with other nonlinearities — up to a 15% accuracy increase in CIFAR100 and 4% in CIFAR10 , relative to the best of the benchmark activations tested. With the proposed activation function the vanishing gradient and dying neurons problems disappear, because the derivative of the activation function is always 1 or −1. The simplicity of the proposed function and its derivative make this solution specially suitable for TinyML and hardware applications.},
  archive      = {J_EAAI},
  author       = {Iván Vallés-Pérez and Emilio Soria-Olivas and Marcelino Martínez-Sober and Antonio J. Serrano-López and Joan Vila-Francés and Juan Gómez-Sanchís},
  doi          = {10.1016/j.engappai.2023.105863},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105863},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Empirical study of the modulus as activation function in computer vision applications},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-spectral feature classification combining
3D-convolutional neural networks with long short-term memory for motor
movement/imagery. <em>EAAI</em>, <em>120</em>, 105862. (<a
href="https://doi.org/10.1016/j.engappai.2023.105862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel EEG classification approach based on the Spatio-spectral feature, aiming to design a motor movement/imagery classification model that extracts multi-domain features with promising performance. Firstly, the difference between motor imagery (MI) tasks and real execution tasks was analyzed by calculating complexity measures of different frequency bands. Then, different connection patterns between MI tasks and real execution tasks were investigated by constructing the PLV and PLI networks. The results of the PLV and PLI brain networks showed that real execution tasks’ network connections intensity was stronger than MI tasks, which meant these two networks could be used to distinguish the EEG signal features of different tasks. Afterward, to fully explain the multi-domain features of EEG signals, we fused the Phase Locking Value (PLV) and Phase-Lag Index (PLI) matrices (spatial-domain) under the subsets of frequency bands (frequency-domain) into a 3-D feature, namely the Spatio-spectral feature. Finally, a 3-D convolutional neural network combined with a long short-term memory (3DCNN-LSTM) was utilized to decode the feature. The results showed that the average accuracy of 10 subjects, 20 subjects, 50 subjects, 80 subjects, and 103 subjects was 85.88%, 83.09%, 76.30%, 75.02%, and 74.54%. Taken together, the proposed method provided promising classification accuracies, superior multi-domain features extraction ability, simpler structure, and robustness to classify the different motor movement/imagery tasks. The results contribute to our understanding of applying the deep learning method to decode EEG multi-domain features in the brain-computer interface (BCI) systems (e.g., MI, emotion recognition, and epileptic seizure classification).},
  archive      = {J_EAAI},
  author       = {Wenqie Huang and Wenwen Chang and Guanghui Yan and Yuchan Zhang and Yueting Yuan},
  doi          = {10.1016/j.engappai.2023.105862},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105862},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatio-spectral feature classification combining 3D-convolutional neural networks with long short-term memory for motor movement/imagery},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurodynamics-based configuration transformation with
engineering application to robot manipulators using two intelligent
approaches. <em>EAAI</em>, <em>120</em>, 105861. (<a
href="https://doi.org/10.1016/j.engappai.2023.105861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Before performing various tasks, it is important to transform the robot manipulator from current configuration to the desired initial configuration. Therefore, this paper proposes a jerk-level configuration transformation (JCT) strategy based on neurodynamics, avoiding the joint angle, velocity, acceleration, and jerk physical limits simultaneously. Moreover, two intelligent approaches are designed to solve the JCT strategy, namely dynamic recurrent neural network and intelligent iterative optimizer, and the convergence and computational complexity are analyzed theoretically. In terms of superiority, the JCT strategy is compared with other typical strategies by simulations of a 7-degree-of-freedom manipulator. In experimental verification for engineering applications, the JCT strategy is applied to the space manipulator on the China Space Station, and verified on the ground hardware-in-the-loop experimental system to demonstrate the effectiveness and physical realizability.},
  archive      = {J_EAAI},
  author       = {Boyu Ma and Zongwu Xie and Xiaohang Yang and Yang Liu and Zhengpu Wang and Zainan Jiang},
  doi          = {10.1016/j.engappai.2023.105861},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105861},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neurodynamics-based configuration transformation with engineering application to robot manipulators using two intelligent approaches},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-scale integrated deep self-attention network for
predicting remaining useful life of aero-engine. <em>EAAI</em>,
<em>120</em>, 105860. (<a
href="https://doi.org/10.1016/j.engappai.2023.105860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction is the core research task of aero-engine prognostics health management (PHM), which is crucial to promoting the safety, reliability and economy. Therefore, in this paper, a multi-scale integrated deep self-attention network (MSIDSN) is proposed to process aero-engine multisensory data containing degradation information at different scales and then accurately predict the corresponding RUL of the aero-engine. Firstly, multi-scale blocks with self-attention strategy are constructed to selectively extract multisensory features on different scales. Secondly, an enhanced recurrent neural network module is designed to comprehensively extract the degraded features on multiple temporal scales. Finally, the feature fusion layer fuses the features and outputs the predicted RUL. Furthermore, an efficient loss function is developed to correct for the delay prediction, and avoid accidents. The experimental comparison results with other models verify the superiority of MSIDSN.},
  archive      = {J_EAAI},
  author       = {Ke Zhao and Zhen Jia and Feng Jia and Haidong Shao},
  doi          = {10.1016/j.engappai.2023.105860},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105860},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale integrated deep self-attention network for predicting remaining useful life of aero-engine},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hydrogenerator early fault detection: Sparse dictionary
learning jointly with the variational autoencoder. <em>EAAI</em>,
<em>120</em>, 105859. (<a
href="https://doi.org/10.1016/j.engappai.2023.105859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the continuous health status of a Hydraulic Turbine Generator Unit (HTGU) is a strategic task to prevent any unexpected downtime. In addition to the loss of energy production following a prolonged shutdown, the various maintenance costs represent an undesirable effect due to unanticipated failure. One of the main functions of a condition-based maintenance (CBM), is the early detection of any unexpected changes in a machine behavior. Indeed, being able to detect any drift or change in behavior compared to a reference behavior represents a major challenge in the monitoring of complex machines like a HTGU. In this paper, an early anomaly detection model for HTGU using Variational Autoencoders (VAEs) and Sparse Dictionary Learning (SDL) is proposed. The combined reconstruction error thus obtained from the VAE-SDL model is used as an early fault detection. Experimental tests on vibratory signals show that the two models thus joined increase the sensitivity as well as the robustness of the anomaly detection.},
  archive      = {J_EAAI},
  author       = {Ryad Zemouri and Rony Ibrahim and Antoine Tahan},
  doi          = {10.1016/j.engappai.2023.105859},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105859},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hydrogenerator early fault detection: Sparse dictionary learning jointly with the variational autoencoder},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulation-based multi-objective optimization towards
proactive evacuation planning at metro stations. <em>EAAI</em>,
<em>120</em>, 105858. (<a
href="https://doi.org/10.1016/j.engappai.2023.105858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective evacuation management is crucial in response to an emergency at metro stations. Due to the unpredictability and high complexity at metro stations, great challenges exist for evacuation management. A hybrid approach with the integration of building information modeling (BIM), simulation tool (Anylogic), and machine learning algorithms is proposed in this research to realize the evacuation event simulation and proactive evacuation management. A case study is performed to test the applicability and effectiveness of the proposed approach. It is found in the case study that: (1) The constructed simulation model could successfully perform the prediction of the evacuation process for the target metro station, and numbers of congestion areas can be identified (i.e., 7, 7, 9, 11 congestion areas for the four typical scenarios, respectively); (2) A proactive evacuation guiding strategy is proposed from the hybrid approach, which could realize a much better improvement for the evacuation events (at least 15.3% and 39.3% could be achieved for objectives of the evacuation time and the evacuation over-density rate, respectively), compared to the conventional guiding strategies; (3) The proposed proactive guiding strategy is the only one, in all three guiding strategies, that could shorten the evacuation time to the maximum extent and remove the congestion areas entirely. The novelty of the proposed approach lies in that: (i) The proposed hybrid approach could be able to accurately predict the evacuation conditions under different scenarios by incorporating the LightGBM algorithm; (ii) A proactive guiding strategy, along with the proposal of the innovative over-density rate rule, is provided with the ability of significantly improving the evacuation efficiency. This proposed approach not only presents an efficient tool for the evaluation of evacuations, but also greatly enriches the field of proactive evacuation management at metro stations.},
  archive      = {J_EAAI},
  author       = {Kai Guo and Limao Zhang and Maozhi Wu},
  doi          = {10.1016/j.engappai.2023.105858},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105858},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simulation-based multi-objective optimization towards proactive evacuation planning at metro stations},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Solving floating pollution with deep learning: A novel SSD
for floating objects based on continual unsupervised domain adaptation.
<em>EAAI</em>, <em>120</em>, 105857. (<a
href="https://doi.org/10.1016/j.engappai.2023.105857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent identification and monitoring of floating materials is extremely crucial in water environment management as floating pollution severely damages water ecosystems. However, it remains a challenging problem in practical applications due to high scene complexity, small-scale targets, and model domain shifting. Aimed at this problem, this paper proposes a novel object detector based on a continual unsupervised domain adaptation method, which improves the detection accuracy and generalization capability of the object detector for small floating targets. Specifically, this paper proposes an improved object detection algorithm-single shot multi-Box detector for floating targets to adapt to the detection task of small floating targets. Then, a new paradigm of domain adaptation method-continual unsupervised domain adaptation is proposed to solve the issue of converting data between the source and target domains. Simultaneously, this paper integrates the detector and domain adaptation method to improve the model’s detection accuracy for small floating targets in a new target domain. The proposed method is trained and compared with the state-of-the-art methods based on multiple scenarios. As a result, the detection accuracy of the proposed method using an input image size of 300 × 300 reaches 82.2%, the detection speed can reach 68.5 frames per second under the graphics processing unit, the computation amount of floating-point numbers is reduced to 3.3 billion, and the size of the model is compressed into 25.3 MB. This paper extends the application of floating object detection in water surface vision, which is crucial for the control of water pollution.},
  archive      = {J_EAAI},
  author       = {Renfei Chen and Jian Wu and Yong Peng and Zhongwen Li and Hua Shang},
  doi          = {10.1016/j.engappai.2023.105857},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105857},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving floating pollution with deep learning: A novel SSD for floating objects based on continual unsupervised domain adaptation},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence based real-time earthquake
prediction. <em>EAAI</em>, <em>120</em>, 105856. (<a
href="https://doi.org/10.1016/j.engappai.2023.105856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthquake prediction is considered a vital endeavour for human safety. Effective earthquake prediction can drastically reduce human damage, which is of utmost importance to the community and individuals. In the current research world, there is a boom in scientific interest in the prediction of seismic events. With the technological revolution in data acquisition, communication networks, edge–cloud computing, the Internet of Things (IoT), and big data analysis, it is feasible to develop an intelligent earthquake prediction model for early warnings at vulnerable locations. Conspicuously, a collaborative IoT–Edge-centered smart earthquake monitoring and prediction framework using cloud and edge computing are proposed. IoT technology is utilized to acquire real-time sensor data, which is forwarded to the edge layer for feature classification utilizing a novel bayesian belief model technique. Furthermore, Adaptive Neuro-Fuzzy Inference System (ANFIS) mechanism is employed to forecast the magnitude of earthquakes in the cloud layer. Based on the experimental simulation, enhanced effectiveness is acquired for the presented framework in terms of classification performance (Precision (92.52%), Sensitivity (91.72%), and Specificity (91.01%)). Additionally, results show that the utilization of edge computing significantly reduces computational delay (23.06s). Moreover, enhanced accuracy and throughput are acquired for the presented model in terms of reliability (95.26%) and stability (92.16%).},
  archive      = {J_EAAI},
  author       = {Munish Bhatia and Tariq Ahamed Ahanger and Ankush Manocha},
  doi          = {10.1016/j.engappai.2023.105856},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105856},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence based real-time earthquake prediction},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparative study of orthogonal moments for human postures
recognition. <em>EAAI</em>, <em>120</em>, 105855. (<a
href="https://doi.org/10.1016/j.engappai.2023.105855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human posture recognition has recently attracted a significant attention from the computer vision community. However, as in any pattern recognition problem, the features extracted from human posture images must be relevant; otherwise, the overall performance of the recognition system may be affected. Among the large number of existing features, the orthogonal moments have been successfully used in many image analysis and pattern recognition applications. However, to the best of our knowledge, their performances in human posture recognition have not been yet examined. Thus, the objective in this paper is to evaluate and compare the performances of various types of orthogonal moments, namely, Zernike, pseudo-Zernike, orthogonal Fourier–Mellin, Gegenbauer, exact Legendre, Chebyshev, Krawtchouk and Hahn moments for human postures recognition problem. The performance evaluations of these moments, as well as a comparison between them, are performed on three public datasets, namely Zhao &amp; Chen dataset, URFD dataset and SDUFall dataset. The obtained results showed that, using moments up to order 8 on Zhao &amp; Chen dataset, and up to order 6 on URFD and SDUFall datasets, Krawtchouk moments and Hahn moments outperform all the other moments, reaching an accuracy of about 98.5% to 99%. The robustness of the different orthogonal moments against noise and segmentation errors was also evaluated. The obtained results showed again the outperformance of Krawtchouk and Hahn moments compared to the other moments, with a performance drop of less than 1.46% in the presence of high noise level, and less than 6.2% in the presence of severe segmentation errors.},
  archive      = {J_EAAI},
  author       = {Merzouk Younsi and Moussa Diaf and Patrick Siarry},
  doi          = {10.1016/j.engappai.2023.105855},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105855},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparative study of orthogonal moments for human postures recognition},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage system proposal based on a type-2 fuzzy logic
system for ergonomic control of classrooms and offices. <em>EAAI</em>,
<em>120</em>, 105854. (<a
href="https://doi.org/10.1016/j.engappai.2023.105854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For people who spend a long time indoors during the day, it is incredibly vital that their environmental conditions are ergonomically designed to provide comfort. However, keeping these comfort conditions at optimum limits during the day requires an important control activity. In this study, a two-stage system using type-2 fuzzy logic is proposed for the ergonomic control of indoor environments such as classrooms and offices. This system calculates the effective working time and time-dependent change in carbon dioxide levels in the first stage and evaluates the ergonomic comfort conditions in the second stage. To develop this system, temperature, humidity, and carbon dioxide levels were measured at different times of the day in university classrooms and the rooms of some faculty members. Based on the data obtained from these measurements, the proposed ergonomic control structure was modeled by using both type-1 and type-2 fuzzy logic systems. As a result, although it was seen that both fuzzy logic systems produced the same results in some examples, it was observed that the proposed type-2 fuzzy logic system produced better interpretations than type-1 in some of the others. Therefore, the type-2 fuzzy logic system is recommended for better ergonomic control in extremely fuzzy environments.},
  archive      = {J_EAAI},
  author       = {İhsan Erozan and Emre Özel and Damlanur Erozan},
  doi          = {10.1016/j.engappai.2023.105854},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105854},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage system proposal based on a type-2 fuzzy logic system for ergonomic control of classrooms and offices},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling the relation between the AVR setpoint and the
terminal voltage of the generator using artificial neural networks.
<em>EAAI</em>, <em>120</em>, 105852. (<a
href="https://doi.org/10.1016/j.engappai.2023.105852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with representing the relation between the voltage setpoint of the AVR (Automatic Voltage Regulation) system and the terminal voltage of the synchronous generator using artificial neural networks (ANNs). The training of the ANN is carried out using the Levenberg–Marquardt algorithm that minimizes the mean-square error between actual output data and estimated output. The experiments that serve for the training, as well as the validation of the ANN, are conducted on a real 120 MVA generator in the hydroelectric power plant Piva. Firstly, the ANNs with three different structures are trained and validated, and the optimal structure, i.e., the one that provides the lowest value of mean-square error, is adopted. Secondly, the adopted structure of the trained ANN is compared with other frequently used models, such as NARX (nonlinear autoregression model with exogenous input) and TF (transfer function) model. The validation data are obtained by carrying out experiments that comprise the different values of step disturbances on the AVR setpoint voltage signal. The presented results clearly show that the ANN model proposed in this paper ensures obtaining extremely accurate and precise results, that match almost perfectly with the corresponding experimental results. Comparative analysis proves that the ANN model is superior compared with the other two representative models. Finally, the test procedure required to obtain both training and validation datasets is very simple to conduct, mainly because it only includes adding step disturbance to the setpoint signal. Such a procedure does not have an impact on the normal operation mode of any component of the AVR system, nor does it require disconnection of the generator from the grid.},
  archive      = {J_EAAI},
  author       = {Mihailo Micev and Martin Ćalasan and Dušan Stipanović and Milovan Radulović},
  doi          = {10.1016/j.engappai.2023.105852},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105852},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modeling the relation between the AVR setpoint and the terminal voltage of the generator using artificial neural networks},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal drug-dosing of cancer dynamics with fuzzy
reinforcement learning and discontinuous reward function. <em>EAAI</em>,
<em>120</em>, 105851. (<a
href="https://doi.org/10.1016/j.engappai.2023.105851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a reinforcement learning-based optimal control is developed for the drug administration of biological phenomena in chemotherapy cancer treatment. The treatment is considered as a class of unknown discrete-time systems when the input: drug administration and the output: tumor cells population are only utilized to design the proposed controller. Resulting, a full-state observer is completely neglected. The controller is established by the actor–critic architecture containing two fuzzy-rules emulated networks when IF-THEN rules are imposed by human knowledge according to pharmacokinetic and pharmacodynamic behavior. Furthermore, the discontinuous reward function is proposed to derive the online learning laws that guarantee the robustness and the convergence of adjustable parameters. The validation results are conducted by numerical systems according to the robustness of the group of patients and the closed-loop performance altogether with comparative results.},
  archive      = {J_EAAI},
  author       = {Chidentree Treesatayapun and Aldo Jonathan Muñoz-Vázquez},
  doi          = {10.1016/j.engappai.2023.105851},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105851},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal drug-dosing of cancer dynamics with fuzzy reinforcement learning and discontinuous reward function},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel intelligent monitoring method for the closing time
of the taphole of blast furnace based on two-stage classification.
<em>EAAI</em>, <em>120</em>, 105849. (<a
href="https://doi.org/10.1016/j.engappai.2023.105849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the taphole closing time is an essential task in the blast furnace ironmaking process because the closing time directly affects the efficiency of iron production and the stability of the blast furnace. However, at present, the taphole closing time in most ironmaking plants is judged by on-site workers based on experience, which lacks scientific guidance. To determine the taphole closing time intelligently and accurately, a novel monitoring method is proposed, which innovatively simplifies the monitoring problem of the absolute taphole closing time into a two-stage classification problem of relative tapping state. In the first stage, a classification algorithm SE-ResNeXt, which only takes the molten iron flow image data as the input data, is used to preliminarily determine the current molten iron flow state in the time dimension during tapping. When it is recognized that the molten iron flow is in the last tapping state in the first stage, the second stage is carried out. In the second stage, a novel multimodal data fusion network SENeXt-Decoder consisting of a novel image feature extraction module, a novel fusion module and a multi-head attention decoder is proposed to obtain the exact taphole closing time, which fuses the molten iron flow image data and blast furnace operating state data. The comparison experiment with the actual taphole closing time on site shows that the absolute monitoring error of this method is within 120 s, and the relative monitoring error is within 1.2%, which better meets the factory’s demand for error accuracy.},
  archive      = {J_EAAI},
  author       = {Zhaohui Jiang and Jinzong Dong and Dong Pan and Tianyu Wang and Weihua Gui},
  doi          = {10.1016/j.engappai.2023.105849},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105849},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel intelligent monitoring method for the closing time of the taphole of blast furnace based on two-stage classification},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UInDeSI4.0: An efficient unsupervised intrusion detection
system for network traffic flow in industry 4.0 ecosystem.
<em>EAAI</em>, <em>120</em>, 105848. (<a
href="https://doi.org/10.1016/j.engappai.2023.105848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an Industry 4.0 ecosystem, all the essential components are digitally interconnected, and automation is integrated for higher productivity. However, it invites the risk of increasing cyber-attacks amid the current cyber explosion. The identification and monitoring of these malicious cyber-attacks and intrusions need efficient threat intelligence techniques or intrusion detection systems (IDSs). Reducing the false positive rate in detecting cyber threats is an important step for a safer and reliable environment in any industrial ecosystem. Available approaches for intrusion detection often suffer from high computational costs due to large number of feature instances. Therefore, this paper proposes a novel unsupervised IDS for Industry 4.0 which we term as: Unsupervised Intrusion Detection System for Industry 4.0 (UInDeSI4.0). We have substantiated the proposed UInDeSI4.0 approach through its experimentation on the well-known UNSW-NB15 Industry 4.0 dataset. The proposed UInDeSI4.0 employs feature selection approaches to obtain minimal and optimal features. These features are then used to train isolation forest to detect network traffic threats in an unsupervised manner. Accordingly, the proposed UInDeSI4.0 approach can efficiently differentiate between the normal events and the attacks or intrusions in environments with no label information. Experimental results show that the proposed UInDeSI4.0 provides better accuracy ( ∼ 63%) and a minimal feature set (nine) compared to traditional IDSs. In contrast to deep learning approaches, UInDeSI4.0 generates faster results with minimum features. In conclusion, we establish the superiority of UInDeSI4.0 approach as an accurate and computationally efficient IDS for Industry 4.0.},
  archive      = {J_EAAI},
  author       = {Amit K. Shukla and Shubham Srivastav and Sandeep Kumar and Pranab K. Muhuri},
  doi          = {10.1016/j.engappai.2023.105848},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105848},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {UInDeSI4.0: An efficient unsupervised intrusion detection system for network traffic flow in industry 4.0 ecosystem},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive multispace adjustable sparse filtering: A sparse
feature learning method for intelligent fault diagnosis of rotating
machinery. <em>EAAI</em>, <em>120</em>, 105847. (<a
href="https://doi.org/10.1016/j.engappai.2023.105847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis based on artificial intelligence methods is a promising tool to eliminate reliance on a priori knowledge. Sparsity is an increasingly important topic in the field of artificial intelligence in recent years, but the impact of sparsity on intelligence fault diagnosis of rotating machinery is still rarely explored. Therefore, we propose an intelligent fault diagnosis method based on sparse feature learning called adaptive multispace adjustable sparse filtering (AMSASF). Firstly, the multispace sparse filtering is proposed to automatically capture rich and complementary features under multiple spaces by combining four classical sparse measures. Secondly, the attention mechanism is designed to adaptively assign different importance to different sparse spaces to improve the robustness of the algorithm. Finally, the possible effect of sparsity on the inter-class distance is analysed, and the sparsity is adjusted to increase the inter-class distance using matrix pseudo-norm to obtain more discriminative features. Meanwhile, the characteristics of the objective equation based on the matrix pseudo-norm reconstruction for sparse optimisation are discussed. The proposed method was extensively experimented on a self-generated bearing dataset and a public dataset from Case Western Reserve University, with prediction accuracies of 98.32% and 99.67%, respectively, using only 1% training samples.},
  archive      = {J_EAAI},
  author       = {Guowei Zhang and Xianguang Kong and Jingli Du and Jinrui Wang and Shengkang Yang and Hongbo Ma},
  doi          = {10.1016/j.engappai.2023.105847},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105847},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive multispace adjustable sparse filtering: A sparse feature learning method for intelligent fault diagnosis of rotating machinery},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Underwater self-supervised monocular depth estimation and
its application in image enhancement. <em>EAAI</em>, <em>120</em>,
105846. (<a
href="https://doi.org/10.1016/j.engappai.2023.105846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate depth estimation is necessary for imaging model-based underwater image enhancement. However, limited by the length of baseline, traditional binocular-based methods are not easy to deploy in underwater scenarios, while monocular methods are more appropriate due to their availability and cost. Therefore, we propose a self-supervised model (called UWdepth) to estimate the depth of underwater scenes with monocular sequences. Addressing the challenges posed by the scale of data and the complexity of motion in underwater scenes, we design an iterative pose network and further introduce a depth consistency loss to achieve more accurate inter-frame motion prediction and depth estimation. The predicted depth can be used to precisely enhance the image based on the underwater imaging model. Experiments show that UWdepth outperforms existing depth estimation models in terms of multiple evaluation indexes. Furthermore, by applying UWdepth, we can enhance underwater images with Akkaynak–Treibitz imaging model, achieving better indexes and visual perception quality than existing traditional and deep-learning based underwater image enhancement algorithms.},
  archive      = {J_EAAI},
  author       = {Junting Wang and Xiufen Ye and Yusong Liu and Xinkui Mei and Jun Hou},
  doi          = {10.1016/j.engappai.2023.105846},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105846},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Underwater self-supervised monocular depth estimation and its application in image enhancement},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EBNAS: Efficient binary network design for image
classification via neural architecture search. <em>EAAI</em>,
<em>120</em>, 105845. (<a
href="https://doi.org/10.1016/j.engappai.2023.105845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deploy Convolutional Neural Networks (CNNs) on resource-limited devices, binary CNNs with 1-bit activations and weights prove to be a promising approach. Meanwhile, Neural Architecture Search (NAS), which can design lightweight networks beyond artificial ones, has achieved optimal performance in various tasks. To design high-performance binary networks, we propose an efficient binary neural architecture search algorithm, namely EBNAS. In this paper, we propose corresponding improvement strategies to deal with the information loss due to binarization, the discrete error between search and evaluation, and the imbalanced operation advantage in the search space. Specifically, we adopt a new search space consisting of operations suitable for the binary domain. An L2 path regularization and a variance-based edge regularization are introduced to guide the search process and drive architecture parameters toward discretization. In addition, we present a search space simplification strategy and adjust the channel sampling proportions to balance the advantages of different operations. We perform extensive experiments on CIFAR10, CIFAR100, and ImageNet datasets. The results demonstrate the effectiveness of our proposed methods. For example, with binary weights and activations, EBNAS achieves a Top-1 accuracy of 95.61% on CIFAR10, 78.10% on CIFAR100, and 67.8% on ImageNet. With a similar number of model parameters, our algorithm outperforms other binary NAS methods in terms of accuracy and efficiency. Compared with manually designed binary networks, our algorithm remains competitive. The code is available at https://github.com/sscckk/EBNAS .},
  archive      = {J_EAAI},
  author       = {Chaokun Shi and Yuexing Hao and Gongyan Li and Shaoyun Xu},
  doi          = {10.1016/j.engappai.2023.105845},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105845},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EBNAS: Efficient binary network design for image classification via neural architecture search},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STetro-d: A deep learning based autonomous descending-stair
cleaning robot. <em>EAAI</em>, <em>120</em>, 105844. (<a
href="https://doi.org/10.1016/j.engappai.2023.105844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robots that can perform cleaning in the staircase region are gaining interest and are lined up to release in commercial robot space. Even though several precedents in the literature reported the development of staircase cleaning, their primary focus was on autonomous staircase ascending, which curtails their performance by increasing the power consumption and constraints to achieve full area coverage in a multistory building. The main objective of this research article is to develop a novel autonomous descending staircase-cleaning robot named sTetro-D. The developed robot uses a Deep Convolution Neural Network (DCNN) to autonomously detect a descending staircase, approach it, and perform maximum area coverage. This article presents the technical details of the developed robot and its DCNN-based autonomous descending staircase coverage ability. Also, the developed system was validated in terms of accuracy in detecting the descending staircase, reaching the stairs, and performing maximum area coverage through conducting experimental trials in two real-world scenarios. In all considered scenarios, the developed robotic platform exhibits significantly superior performance in detecting the descending staircase with an average accuracy of 85%, successfully approaching the descending staircase, and achieving 98% area coverage.},
  archive      = {J_EAAI},
  author       = {Veerajagadheswar Prabakaran and Anh Vu Le and Phone Thiha Kyaw and Prathap Kandasamy and Aung Paing and Rajesh Elara Mohan},
  doi          = {10.1016/j.engappai.2023.105844},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105844},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STetro-D: A deep learning based autonomous descending-stair cleaning robot},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prediction based mean-value-at-risk portfolio optimization
using machine learning regression algorithms for multi-national stock
markets. <em>EAAI</em>, <em>120</em>, 105843. (<a
href="https://doi.org/10.1016/j.engappai.2023.105843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The future performance of stock markets is the most crucial factor in portfolio creation. As machine learning technique is advancing, new possibilities have opened up for incorporating prediction concepts into portfolio selection. A hybrid approach that constitutes machine learning algorithms for stock return prediction and a mean–VaR (value-at-risk) model for portfolio selection is illustrated in this paper as a unique portfolio construction technique. Machine learning regression models such as Random Forest, Extreme Gradient Boosting (XGBoost), Adaptive Boosting (AdaBoost), Support Vector Machine Regression (SVR), k-Nearest Neighbors (KNN), and Artificial Neural Network (ANN) are adopted to forecast stock values for the next period. The stocks with greater prospective returns are chosen in the first stage of this affection. Further, the mean–VaR portfolio optimization model is employed for portfolio selection in the second stage. The monthly datasets of the Bombay Stock Exchange (BSE), India, Tokyo Stock Exchange, Japan, and Shanghai Stock Exchange, China, are used as the research sample, and the findings show that the mean–VaR model with AdaBoost prediction outperforms other models.},
  archive      = {J_EAAI},
  author       = {Jyotirmayee Behera and Ajit Kumar Pasayat and Harekrushna Behera and Pankaj Kumar},
  doi          = {10.1016/j.engappai.2023.105843},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105843},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction based mean-value-at-risk portfolio optimization using machine learning regression algorithms for multi-national stock markets},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rotation adaptive grasping estimation network oriented to
unknown objects based on novel RGB-d fusion strategy. <em>EAAI</em>,
<em>120</em>, 105842. (<a
href="https://doi.org/10.1016/j.engappai.2023.105842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate grasping estimation is prerequisite and key to achieving accurate robotic grasping. As common data sources, existing RGB and Depth (RGB-D) fusion strategies hardly fully use the advantages and suppress the disadvantages of both modes. In addition, existing methods mainly rely on data augmentation to achieve spatial and rotation adaptation, which cannot fundamentally solve the problem. Therefore, this paper proposes a framework for rotation adaptive grasping estimation based on a novel RGB-D fusion strategy. Specifically, the RGB-D is fused with shared weights in stages based on the proposed Multi-step Weight-learning Fusion (MWF) strategy. The spatial position is encoding learned autonomously based on the proposed Rotation Adaptive Conjoin (RAC) encoder to achieve spatial and rotational adaptiveness oriented to unknown objects with unknown poses. In addition, the Multi-dimensional Interaction-guided Attention (MIA) decoding strategy based on the fused multiscale features is proposed to highlight the practical elements and suppress the invalid ones. The method has been validated on the Cornell and Jacquard grasping datasets with cross-validation accuracies of 99.3% and 94.6%. The single-object and multi-object scene grasping success rates on the robot platform are 95.625% and 87.5%, respectively. Our performance compares favorably with state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Hongkun Tian and Kechen Song and Song Li and Shuai Ma and Yunhui Yan},
  doi          = {10.1016/j.engappai.2023.105842},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105842},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rotation adaptive grasping estimation network oriented to unknown objects based on novel RGB-D fusion strategy},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and optimal epsilon-insensitive kernel-based
regression for general noise models. <em>EAAI</em>, <em>120</em>,
105841. (<a
href="https://doi.org/10.1016/j.engappai.2023.105841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse representation of kernel based regression (KBR) has received considerable attention in recent years. Studies on sparse KBR can be divided into two distinct groups, namely (i) pruning-based methods that remove the training samples with the least training errors and retrain the remaining training samples, and (ii) direct methods that begin with a full-dense solution and delete training data according to objective criteria. Pruning-based methods give rise to a high computation time, while direct methods may lead to non-optimal solutions and thus a poor approximation. In addition, most current KBR models assume that the error distribution is Gaussian. However, observations in many practical applications indicate that the noise models do not satisfy the Gaussian error distribution. In such cases, current KBR models are not optimal. To address the above-mentioned problems, this study proposes a new sparse KBR framework for general noise distributions, including the epsilon-insensitive noise family. Compared with other sparse algorithms, sparsity is directly imposed by epsilon-insensitive convex loss functions derived from the theoretical framework of the Bayesian approach within the scope of regularization networks, and then handles the optimization problem in Lagrangian form. Experiments on artificial and real-life benchmark datasets demonstrate that the proposed epsilon-insensitive KBR models are more effective and efficient than pruning-based approaches.},
  archive      = {J_EAAI},
  author       = {Omer Karal},
  doi          = {10.1016/j.engappai.2023.105841},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105841},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust and optimal epsilon-insensitive kernel-based regression for general noise models},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aircraft flight regime recognition with deep temporal
segmentation neural network. <em>EAAI</em>, <em>120</em>, 105840. (<a
href="https://doi.org/10.1016/j.engappai.2023.105840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and effective flight regime recognition is one of the key tasks for structural usage monitoring, it can provide early warning to the dangerous regime. However, existing methods for flight regime recognition either rely on expert knowledge or ignore the continuity and decision boundary of the regimes, which limits their performance for complex regimes and hinders their deployment in practice. In this paper, we provided a brand-new solution for this problem and designed a deep temporal segmentation neural network to realize intelligent regime segmentation. Meanwhile, we revealed the long-tailed distribution of flight regimes and proposed class-wise dynamic group rebalance loss to keep inter-class accuracy balanced. To evaluate the effectiveness of the proposed model, we collected and elaborately annotated plentiful actual flight sorties data, including 11 flight regimes. Test results demonstrated that the model can automatically separate different regimes in a continuous flight sortie without any pre-processing and post-processing while extracting the accurate regime boundary and achieving 95.98% recognition accuracy.},
  archive      = {J_EAAI},
  author       = {Jingyao Wu and Chenye Hu and Chuang Sun and Xuefeng Chen and Ruqiang Yan},
  doi          = {10.1016/j.engappai.2023.105840},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105840},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Aircraft flight regime recognition with deep temporal segmentation neural network},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Daily solar radiation estimation in belleville station,
illinois, using ensemble artificial intelligence approaches.
<em>EAAI</em>, <em>120</em>, 105839. (<a
href="https://doi.org/10.1016/j.engappai.2023.105839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimating the solar radiation (SR) in a region is an essential issue in hydrological studies, energy engineering, architecture, and agricultural planning. In the current study, the conventional multiple linear regression (MLR), multilayer perceptron neural network (MLPNN), and adaptive neuro-fuzzy inference system (ANFIS) improved using evolutionary algorithms, the particle swarm optimization algorithm (PSO), differential evolution (DE), ant colony optimization for continuous domains (ACOR), and genetic algorithm (GA), as well as three different ensemble techniques, including simple average ensemble (SAE), weighted average ensemble (WAE), and neural network ensemble (NNE) were applied to model daily solar radiation (DSR) in Belleville station in Illinois, USA. For this purpose, the DSR data for eleven stations collected from 2015 to 2019 were obtained from ISWS (the Institute of Illinois State Water Survey). Seven models were then run using three distinct input datasets to estimate the DSR in the study area. The findings indicated that the evolutionary algorithms are significantly effective in boosting the performance of the ANFIS model when the number of inputs increases. It was also found that ensemble methods can improve the performance of the single models in estimating daily solar radiation. Overall, the results indicated that the ANFIS-GA had the best performance for the selected inputs ( R 2 = 0 . 947 , RMSE = 2.010 (MJ m −2 day −1 ), MAPE = 15.61, NSE = 0.947). The results of the complexity analysis showed that although the ANFIS-GA algorithm had the highest accuracy in estimating daily solar radiation in the study area, it has more complexity than ANFIS-PSO and ANFIS-DE algorithms.},
  archive      = {J_EAAI},
  author       = {Fatemeh Sohrabi Geshnigani and Mohammad Reza Golabi and Rasoul Mirabbasi and Mohammad Nazeri Tahroudi},
  doi          = {10.1016/j.engappai.2023.105839},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105839},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Daily solar radiation estimation in belleville station, illinois, using ensemble artificial intelligence approaches},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive blind denoising autoencoder for real time
denoising of industrial IoT sensor data. <em>EAAI</em>, <em>120</em>,
105838. (<a
href="https://doi.org/10.1016/j.engappai.2023.105838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an industrial IoT setting, ensuring the quality of sensor data is a must when data-driven algorithms operate on the upper layers of the control system. Unfortunately, the common place in industrial facilities is to find sensor time series heavily corrupted by noise and outliers. This work proposes a purely data-driven self-supervised learning-based approach, based on a blind denoising autoencoder, for real time denoising of industrial sensor data. The term blind stresses that no prior knowledge about the noise is required for denoising, in contrast to typical denoising autoencoders. Blind denoising is achieved by using a noise contrastive estimation (NCE) regularization on the latent space of the autoencoder, which not only helps to denoise but also induces a meaningful and smooth latent space that can be exploited in other downstream tasks. Experimental evaluation in both a simulated system and a real industrial process shows that the proposed technique outperforms classical denoising methods.},
  archive      = {J_EAAI},
  author       = {Saúl Langarica and Felipe Núñez},
  doi          = {10.1016/j.engappai.2023.105838},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105838},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Contrastive blind denoising autoencoder for real time denoising of industrial IoT sensor data},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised learning for data scarcity in a fatigue
damage prognostic problem. <em>EAAI</em>, <em>120</em>, 105837. (<a
href="https://doi.org/10.1016/j.engappai.2023.105837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing availability of data for Prognostics and Health Management (PHM), Deep Learning (DL) techniques are now the subject of considerable attention for this application, often achieving more accurate Remaining Useful Life (RUL) predictions. However, one of the major challenges for DL techniques resides in the difficulty of obtaining large amounts of labelled data on industrial systems. To overcome this lack of labelled data, an emerging learning technique is considered in our work: Self-Supervised Learning, a sub-category of unsupervised learning approaches. This paper aims to investigate whether pre-training DL models in a self-supervised way on unlabelled sensors data can be useful for RUL estimation with only Few-Shots Learning, i.e. with scarce labelled data. In this research, a fatigue damage prognostics problem is addressed, through the estimation of the RUL of aluminium alloy panels (typical of aerospace structures) subject to fatigue cracks from strain gauge data. Synthetic datasets composed of strain data are used allowing to extensively investigate the influence of the dataset size on the predictive performance. Results show that the self-supervised pre-trained models are able to significantly outperform the non-pre-trained models in downstream RUL prediction task, and with less computational expense, showing promising results in prognostic tasks when only limited labelled data is available.},
  archive      = {J_EAAI},
  author       = {Anass Akrim and Christian Gogu and Rob Vingerhoeds and Michel Salaün},
  doi          = {10.1016/j.engappai.2023.105837},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105837},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised learning for data scarcity in a fatigue damage prognostic problem},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI based rice leaf disease identification enhanced by
dynamic mode decomposition. <em>EAAI</em>, <em>120</em>, 105836. (<a
href="https://doi.org/10.1016/j.engappai.2023.105836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the task of rice leaf disease identification using transfer-learned deep learning models. The similarity between various symptoms and the inability to distinguish diseases at glance have become a major challenge in the area. Modern deep CNN-based models have acquired state-of-the-art performance and they frequently incorporate global image as an input to learn the model. The major drawback of such a system for rice leaf disease identification is that the diseases often affect small area; CNN models trained on global images may suffer from irrelevant noisy regions. This paper proposes a Dynamic Mode Decomposition based on attention-driven preprocessing for rice leaf disease identification. The four different categories of rice leaf diseases such as bacterial blight, blast, brown spot and tungro (3416 images in total) are considered for the study. Four types of experiments are conducted in this work, Initially the effectiveness of 10 transfer-learned Deep CNN (DCNN) models for rice leaf disease identification is analyzed with an accuracy of 93.87%, DenseNet121 outperformed other transfer-learned models. Secondly, 3 machine learning models are trained on the deep features extracted from the final fully connected layers of DCNN models. The simulation results indicate that the DenseNet121 deep feature with Random Forest classifier performs better compared to other deep feature and machine learning algorithms. Furthermore, Dynamic mode decomposition (DMD) based attention-driven pre-processing mechanism to localize the infected region is investigated. The sparse component obtained from the DMD algorithm is processed to produce a hard attention map which is further multiplied with the original images to generate hard segmentation map. The influence of hard segmentation maps which localizes the infected regions for rice leaf disease identification is investigated. The performance of 10 DCNN models was evaluated using transfer learning strategy and machine learning models learned on deep features both on original images and DMD preprocessed images. The XceptionNet deep feature with SVM classifier on DMD preprocessed images outperforms other models with a test accuracy of 100%. Finally, the performance of the proposed DMD-based attention-driven pre-processing was investigated on on-field rice leaf images. XceptionNet model achieved a better classification accuracy of 94.33, compared to other transfer-learned models. The Analysis in terms of Accuracy, Precision, Recall and F1-Score revealed that the models trained on DMD pre-processed images exhibit significantly better performance.},
  archive      = {J_EAAI},
  author       = {Sudhesh K.M. and Sowmya V. and Sainamole Kurian P. and Sikha O.K.},
  doi          = {10.1016/j.engappai.2023.105836},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105836},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AI based rice leaf disease identification enhanced by dynamic mode decomposition},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven failure prediction of fiber-reinforced polymer
composite materials. <em>EAAI</em>, <em>120</em>, 105834. (<a
href="https://doi.org/10.1016/j.engappai.2023.105834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study illustrates the effectiveness of Deep Neural Networks (DNN) as a tool for creating a data-driven failure model for Fiber-reinforced Polymer (FRP) composite materials. Experimental failure data presented in the literature for laminates tested under biaxial and triaxial stresses were used to develop the data-driven model. A fully connected DNN with 20 input units and 1 output unit trained with a constant learning rate. The network’s inputs describe the laminate layup sequence, lamina properties, and the loading conditions applied to the test specimen, whereas the output is the length of the failure vector. The failure boundaries generated by the DNN were compared to conventional theories such as the Tsai–Wu, Cuntze, and Pinho theory. The data-driven model’s predictions are found to fit the experimental data better than the conventional theories. The DNN’s ability to fit higher-order polynomials to data makes it an effective tool for predicting the final failure of FRP composite laminates.},
  archive      = {J_EAAI},
  author       = {Allyson Fontes and Farjad Shadmehri},
  doi          = {10.1016/j.engappai.2023.105834},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105834},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven failure prediction of fiber-reinforced polymer composite materials},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Voltage control of DC–DC converters through direct control
of power switches using reinforcement learning. <em>EAAI</em>,
<em>120</em>, 105833. (<a
href="https://doi.org/10.1016/j.engappai.2023.105833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that unmodeled dynamics and uncertainties can deteriorate the performance of classical controllers. To resolve this problem, there is growing popularity in using the capabilities of Artificial Intelligence (AI) algorithms, especially Reinforcement Learning (RL) in power systems, because it is a promising adaptive model-free control strategy that can take optimal decisions in unknown environments (dynamics). For this reason, in this paper, two state-of-the-art RL agents, namely Deep Q-Network (DQN) and Deep Deterministic Policy Gradient (DDPG), are used for voltage control of a DC–DC buck converter, and their performance is reported compared with other classical controllers such as Model Predictive Control (MPC) and Sliding Mode Control (SMC). The DQN agent directly controls the power switches of converters. In other words, based on the current condition of the converter, the agent decides whether or not to close the power switches. On the other hand, the DDPG agent and the other mentioned traditional controllers manipulate the duty cycle of a Pulse Width Modulation (PWM) signal to adjust the output voltage of the converter at desired setpoints. According to experimental results, both RL agents outperform the classical controllers in terms of transient response error and robustness against uncertainties. Also, with regard to computational costs and learning rate among RL-based controllers, the DQN agent can learn more from a single interaction with fewer computations because of its simpler structure and direct control of the switches of the converter. Additionally, one of the most important advantages of the RL-based controllers is that they can be applied to various configurations of DC–DC​ converters like buck, boost, and buck-boost converters, provided that it is retrained for the new environments. Finally, the number of transitions in the semiconductor switches of the converter reduces appreciably by using the DQN agent, which certainly prolongs their longevity.},
  archive      = {J_EAAI},
  author       = {Omid Zandi and Javad Poshtan},
  doi          = {10.1016/j.engappai.2023.105833},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105833},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Voltage control of DC–DC converters through direct control of power switches using reinforcement learning},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble deep random vector functional link for
self-supervised direction-of-arrival estimation. <em>EAAI</em>,
<em>120</em>, 105831. (<a
href="https://doi.org/10.1016/j.engappai.2023.105831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direction-of-arrival (DOA) estimation is a key step in the passive target location. The primary issues with traditional DOA estimation methods are the huge computation and weak noise immunity in extreme noise environments. Random vector functional link (RVFL) and its variants (RVFL without direct links, RVFL v ) have demonstrated high learning efficiency and strong generalization ability in previous studies. However, due to the shallow network structure, they may not be effective for underwater acoustic array signals with complex features. Therefore, we propose a model-embedded self-supervised ensemble deep RVFL (ME-SedRVFL) network to estimate the DOA of underwater acoustic array signals. To prove the efficiency and generalization ability, ME-SedRVFL is compared with its variants (ME-SRVFL v ), as well as other well-known randomization-based networks. The results testify the noise immunity of ME-SedRVFL and ME-SRVFL v is 9.62% and 9.34% better than traditional signal model-based methods, 1.68% and 1.40% better than randomization-based parameter estimation methods (Signal-to-noise ratio is −20 dB, frequency is 200 Hz). The statistical box diagrams and statistical comparisons are performed to evaluate different methods, which indicate that the ME-SedRVFL obtains superior DOA estimation performance to ME-SRVFL v in most cases, due to direct input–output connections helping regularize the randomization. Hence, ME-SedRVFL is identified as the best-performing DOA estimation method through a comprehensive evaluation of real-world and simulated datasets.},
  archive      = {J_EAAI},
  author       = {Jiawen He and Xiaolei Li and Peishun Liu and Liang Wang and Hao Zhou and Jinyu Wang and Ruichun Tang},
  doi          = {10.1016/j.engappai.2023.105831},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105831},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble deep random vector functional link for self-supervised direction-of-arrival estimation},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constitutive model characterization and discovery using
physics-informed deep learning. <em>EAAI</em>, <em>120</em>, 105828. (<a
href="https://doi.org/10.1016/j.engappai.2023.105828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constitutive models are fundamental blocks of modeling physical processes, where they connect conservation laws with the kinematics of the system. They are often expressed in the form of linear or nonlinear systems of ordinary differential equations (ODEs). Within nonlinear regimes, however, it is often challenging to characterize these constitutive models. For solids and geomaterials, the constitutive relations that relate the macroscopic stress and strain quantities are described using highly nonlinear, constrained ODEs to characterize their mechanical response at different stages of both reversible and irreversible deformation process. A recent trend in constitutive modeling leverages complex neural network architectures to construct model-free material models, however, such complex networks are inefficient and demand significant training data. Therefore, we believe theory-based parametric models of elastoplasticity are still the most efficient and predictive. To alleviate the challenging task of characterization and discovery of such models, here, we present a physics-informed neural network (PINN) formulation for stress–strain constitutive modeling. The main obstacle that we address is to have complex inequality constraints of elastoplasticity theory embedded in the PINN loss functions. These constraints are crucial to find the correct form of the yield surface and plastic flow. We also show that calibration of new datasets can be performed very efficiently and that enhanced performance can be achieved even for the case of discovery. This framework requires a single dataset for characterization. Although we only focus on mechanical constitutive models, similar analogies can be used to characterize constitutive models for any physical process.},
  archive      = {J_EAAI},
  author       = {Ehsan Haghighat and Sahar Abouali and Reza Vaziri},
  doi          = {10.1016/j.engappai.2023.105828},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105828},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constitutive model characterization and discovery using physics-informed deep learning},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of an optimally designed real-time automatic
citrus fruit grading–sorting​ machine leveraging computer vision-based
adaptive deep learning model. <em>EAAI</em>, <em>120</em>, 105826. (<a
href="https://doi.org/10.1016/j.engappai.2023.105826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional automation approaches for postharvest operations are plagued by time and data inefficiency seldom leading to suboptimal solutions. Automatic machines often require highly skilled software professionals for calibration and reconfiguration thus making the technology prone to high costs. Contemporary sensors and smart devices capable of handling deep learning image analytics have been employed in the present study for the development of an automatic machine that performs postharvest operations, like—washing, vision-based sorting and weight-based grading of citrus fruits with much reduced human effort while achieving excellent performance for the designated tasks. Accuracy of performance was ensured by the optimal design of mechanical components carried out by kinematic synthesis and dimensional analysis. The machine was equipped with an effective custom lightweight CNN model “SortNet” that was designed and tuned to carry out vision-based classification of citrus fruits into “accept” and “reject” based on surface characteristics. SortNet was less complex and took less computational time while exhibiting comparable accuracy with respect to existing state-of-the-art pre-trained deep learning models. An embedded system operated by a single-board computer was used in the weight grading section for segregating fruits based on three weight categories. Evaluation, realization and transferability of the above said strategy was demonstrated by the real hardware with physical actuators working in real-time to serve as proof-of-concept for a sustainable solution to postharvest automation of citrus fruits.},
  archive      = {J_EAAI},
  author       = {Subir Kumar Chakraborty and Subeesh A. and Kumkum Dubey and Dilip Jat and Narendra Singh Chandel and Rahul Potdar and N.R.N.V. Gowripathi Rao and Deepak Kumar},
  doi          = {10.1016/j.engappai.2023.105826},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105826},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of an optimally designed real-time automatic citrus fruit grading–sorting​ machine leveraging computer vision-based adaptive deep learning model},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Selective feature bagging of one-class classifiers for
novelty detection in high-dimensional data. <em>EAAI</em>, <em>120</em>,
105825. (<a
href="https://doi.org/10.1016/j.engappai.2023.105825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novelty detection in high-dimensional data is a challenging task due to the masking effect of irrelevant attributes. A common solution is to discover feature subspace, of which attributes are relevant to novelties. Due to the high uncertainty of novelties in practical applications, ensemble models that combine results from multiple subspaces are proved to be more effective than single models. According to the theory of bias–variance tradeoff , existing ensembles are often developed based on variance reduction. However, it is argued that the combination of poor detectors will deteriorate the performance of ensembles. To this end, this paper proposes an ensemble detector that takes into account variance and bias reduction simultaneously. Our ensemble is referred to as Selective Feature Bagging (SFB) since it is developed on the basis of Feature Bagging (FB). In order to improve the accuracy without deterioration of diversity of base detectors in FB, we resort to the notion of dynamic classifier selection which is proved be effective in classification. During the ensemble generation phase, base detectors are produced and categorized into different groups that are distinguished by the dimensionality of subspace used for training. The purpose of such a design is to maintain the diversity. During the generation phase, the most competent base detector from each of groups is dynamically selected and used to make decision on the test pattern. The purpose of such a design is to enhance the accuracy. We verify the effectiveness of SFB on 15 data sets from KEEL repository. Experimental results have shown that SFB can statistically outperform FB. In addition, several state-of-the-art have also been outperformed by SFB.},
  archive      = {J_EAAI},
  author       = {Biao Wang and Wenjing Wang and Guanglei Meng and Tiankuo Meng and Bin Song and Yingnan Wang and Yuming Guo and Zhihua Qiao and Zhizhong Mao},
  doi          = {10.1016/j.engappai.2023.105825},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105825},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Selective feature bagging of one-class classifiers for novelty detection in high-dimensional data},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature construction using explanations of individual
predictions. <em>EAAI</em>, <em>120</em>, 105823. (<a
href="https://doi.org/10.1016/j.engappai.2023.105823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature construction can contribute to comprehensibility and performance of machine learning models. Unfortunately, it usually requires exhaustive search in the attribute space or time-consuming human involvement to generate meaningful features. We propose a novel heuristic approach for reducing the search space based on aggregation of instance-based explanations of predictive models. The proposed Explainable Feature Construction (EFC) methodology identifies groups of co-occurring attributes exposed by popular explanation methods, such as IME and SHAP. We empirically show that reducing the search to these groups significantly reduces the time of feature construction using logical, relational, Cartesian, numerical, and threshold ( num-of-N and X-of-N ) constructive operators. An analysis on 10 transparent synthetic datasets shows that EFC effectively identifies informative groups of attributes and constructs relevant features. Using 30 real-world classification datasets, we show significant improvements in classification accuracy for several classifiers and demonstrate the feasibility of the proposed feature construction even for large datasets. Finally, EFC generated interpretable features on a real-world problem from the financial industry, which were confirmed by a domain expert.},
  archive      = {J_EAAI},
  author       = {Boštjan Vouk and Matej Guid and Marko Robnik-Šikonja},
  doi          = {10.1016/j.engappai.2023.105823},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105823},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature construction using explanations of individual predictions},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed deep reinforcement learning-based gas supply
system coordination management method for solid oxide fuel cell.
<em>EAAI</em>, <em>120</em>, 105818. (<a
href="https://doi.org/10.1016/j.engappai.2023.105818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to sustain solid oxide fuel cell (SOFC) net output power and prevent violation of oxygen excess ratio (OER) constraint and fuel utilization (FU) constraint, a data-driven gas supply system coordination management method is proposed. Accordingly, a population evolution-based multi-agent double delay deep deterministic policy gradient (PE-MA4DPG) algorithm is introduced. The artificial intelligence design of the algorithm is guided by the concepts of imitation learning and curriculum learning, whereby different agents of different combinations are trained in different environments, thus improving the robustness of the coordination strategy. In this algorithm, the hydrogen controller and the air controller are treated as two agents. The centralized training enables agents with different objectives to coordinate with each other. The effectiveness of the proposed algorithm is demonstrated in three experiments, wherein the proposed algorithm is compared with a group of existing algorithms.},
  archive      = {J_EAAI},
  author       = {Jiawen Li and Haoyang Cui and Wei Jiang},
  doi          = {10.1016/j.engappai.2023.105818},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105818},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributed deep reinforcement learning-based gas supply system coordination management method for solid oxide fuel cell},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamic graph aggregation framework for 3D point cloud
registration. <em>EAAI</em>, <em>120</em>, 105817. (<a
href="https://doi.org/10.1016/j.engappai.2023.105817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, most of the existing point cloud registration methods use stacked edge convolution as feature extractor, ignoring the importance of deep semantic information, meanwhile, the use of attention mechanism tends to increase the computational cost of the model and limits the matching effect. This paper proposes a dynamic graph aggregation framework for point cloud registration by building a dynamic deep network, which can capture richer semantic information and shape properties of point clouds. First, a hybrid feature extractor, which fully fuses local graph information and global graph information, is designed to obtain more discriminative feature descriptors. Second, a local graph neighborhood scoring module to update local graph features and achieve feature enhancement is built by learning the difference of similar point neighborhood features. Finally, a dual-constrained matching module is designed, which is used to measure the similarity of point pairs from the two aspects of Euclidean distance and affinity between features. The proposed framework achieves excellent registration performance, as demonstrated by experimental results on challenging 3D point cloud benchmarks. Especially in partial point cloud registration, MAE( R ) achieved excellent results of 0.2614 and 0.2619 under unseen shapes and unseen categories.},
  archive      = {J_EAAI},
  author       = {Feilong Cao and Jiatong Shi and Chenglin Wen},
  doi          = {10.1016/j.engappai.2023.105817},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105817},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic graph aggregation framework for 3D point cloud registration},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast brain tumor detection using adaptive stochastic
gradient descent on shared-memory parallel environment. <em>EAAI</em>,
<em>120</em>, 105816. (<a
href="https://doi.org/10.1016/j.engappai.2022.105816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor detection is a very important and challenging task. An efficient detection algorithm is of great importance to the practice of brain tumor medicine. In this paper, we propose a novel parallel optimization algorithm based on a shared-memory environment to solve the SVM classifier for brain tumor detection. Firstly, the HOG algorithm is used to extract brain tumor MR image features and compare them with the wavelet transform method. Secondly, SVM with ℓ 1 -norm loss function is utilized as a classifier. Due to its sparsity, the detection speed is significantly faster. Finally, SMP-SGD, SMP-Momentum, SMP-Adagrad, and SMP-Adam algorithms are proposed and applied to the classifier solution. The experimental results show that the HOG algorithm extracts brain tumor MRI features more effectively than the discrete wavelet transform method. The proposed SMP-SGD algorithm and its variants achieved state-of-the-art accuracy and efficiency for brain tumor detection.},
  archive      = {J_EAAI},
  author       = {Chuandong Qin and Baosheng Li and Baole Han},
  doi          = {10.1016/j.engappai.2022.105816},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105816},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast brain tumor detection using adaptive stochastic gradient descent on shared-memory parallel environment},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LiDAR-camera fusion: Dual transformer enhancement for 3D
object detection. <em>EAAI</em>, <em>120</em>, 105815. (<a
href="https://doi.org/10.1016/j.engappai.2022.105815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the progress in autonomous driving tries to leverage the strong complementarity of LiDAR point clouds and RGB images to realize a high-efficient 3D object detection task. However, some works just simply decorate the raw point clouds or point-cloud features with camera clues in a hard way, which cannot fully exploit the relevance between the two-modal data. In this paper, we propose a dual-feature interaction module that adopts a soft-fusion strategy to give guidance for the LiDAR-camera feature fusion by interacting the LiDAR and camera features with Transformer. Compared with the hard-fusion method, this soft-fusion method can decorate the LiDAR feature with a reliable image feature. Additionally, we design an uncertainty-based 3D Intersection over Union (IoU) metric in the training process. This strategy aims at modeling the unreliability of 3D IoU scores to alleviate the bad effects caused by the coupling problem of 3D properties. Experiments conducted on the KITTI dataset achieve significant improvements in the 3D object detection and bird’s eye view tasks when compared with the previous arts. Especially for the task of 3D object detection, our approach obtains 0.68 and 0.45 gains for the metric of A P 3 D on the moderate level and hard level, respectively.},
  archive      = {J_EAAI},
  author       = {Mu Chen and Pengfei Liu and Huaici Zhao},
  doi          = {10.1016/j.engappai.2022.105815},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105815},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LiDAR-camera fusion: Dual transformer enhancement for 3D object detection},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature based analysis of thermal images for emotion
recognition. <em>EAAI</em>, <em>120</em>, 105809. (<a
href="https://doi.org/10.1016/j.engappai.2022.105809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal imaging has recently been investigated in automatic emotion identification to get an insight into reliable information about human emotion. However, the methods employed to classify thermal emotion in literature are discrete and randomly selected. These methods are deficit in explanation and also lack adequate justification for the obtained result. The assertions above are supported by the fact that, despite previous research, the existing methods are not successful in real-time and are resistant to obstacles such as spectacles, facial hair, and body movements. So there is enough room for more methods and thorough research into the effects of various features on thermal images and the characteristics of thermal emotion that are conveyed by those features. To address the issue, this research provides an in-depth performance analysis of hand-crafted features on thermal images while distinguishing emotion. In this study, we examine the inherent spatial and spectral aspects of several histogram-based feature descriptors along with a set of classifiers to classify thermal emotion. The study is carried out on two datasets, each with a distinct pseudo-color palette and sample size. Moreover, to the best of our knowledge, no work has been done to evaluate their feature extraction methods for the subject-independent case of thermal emotion recognition. Constructing a subject-independent model is the first step in classifying thermal emotive faces in real-time. This paper offers an early draft of the same, employing hand-crafted features. The author attempts to highlight the enormous scope of this research area because the subject-independent result obtained is weak. The existence of mixed emotions and inter-person variability are just two of the most likely causes of low accuracy and precision.},
  archive      = {J_EAAI},
  author       = {Suparna Rooj and Aurobinda Routray and Manas K. Mandal},
  doi          = {10.1016/j.engappai.2022.105809},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105809},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature based analysis of thermal images for emotion recognition},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification and health-aware economic control of
production systems: A fuzzy logic max plus algebraic approach.
<em>EAAI</em>, <em>120</em>, 105802. (<a
href="https://doi.org/10.1016/j.engappai.2022.105802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first objective of this paper is to settle the practical problem pertaining to the modelling and identification of the production system performance, which is defined a discrete event one. For that purpose the Internet of Things tools are employed, which are located at each manufacturing machine. As a result, a set of time-driven data is obtained, which measure the metal processing time of the shot blasting machines. These result constitute the base for the development of the state-space model designed with fuzzy logic and max-plus algebraic paradigms. The appealing property of the processing time model is that it is designed with the experimental design strategy, and hence, a minimum number of metal plates is required for its design. It should be noted that the system considered contains concurrent machines, which are redundant, and hence, cause the need for appropriate scheduling and control. Apart from that the system has an associated economic and health-aware indicators, which express the cost of possible degradation of using them over a specified time horizon. Thus, the proposed strategy allows finding a trade-off between general performance of the entire system and these indicators. The proposed strategy is illustrated with a practical proof-of-concept production system, which clearly exhibits the benefits concerning the application of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Marcin Mrugalski},
  doi          = {10.1016/j.engappai.2022.105802},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105802},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification and health-aware economic control of production systems: A fuzzy logic max plus algebraic approach},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimization of reward shaping function based on genetic
algorithm applied to a cross validated deep deterministic policy
gradient in a powered landing guidance problem. <em>EAAI</em>,
<em>120</em>, 105798. (<a
href="https://doi.org/10.1016/j.engappai.2022.105798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One major capability of a Deep Reinforcement Learning (DRL) agent to control a specific vehicle in an environment without any prior knowledge is decision-making based on a well-designed reward shaping function. An important but little-studied major factor that can alter significantly the training reward score and performance outcomes is the reward shaping function. To maximize the control efficacy of a DRL algorithm, an optimized reward shaping function and a solid hyperparameter combination are essential. In order to achieve optimal control during the powered descent guidance (PDG) landing phase of a reusable launch vehicle, the Deep Deterministic Policy Gradient (DDPG) algorithm is used in this paper to discover the best shape of the reward shaping function (RSF). Although DDPG is quite capable of managing complex environments and producing actions intended for continuous spaces, its state and action performance could still be improved. A reference DDPG agent with the original reward shaping function and a PID controller were placed side by side with the GA-DDPG agent using GA-optimized RSF. The best GA-DDPG individual can maximize overall rewards and minimize state errors with the help of the potential-based GA(PbGA) searched RSF, maintaining the highest fitness score among all individuals after has been cross-validated and retested extensively Monte-Carlo experimental results.},
  archive      = {J_EAAI},
  author       = {Larasmoyo Nugroho and Rika Andiarti and Rini Akmeliawati and Ali Türker Kutay and Diva Kartika Larasati and Sastra Kusuma Wijaya},
  doi          = {10.1016/j.engappai.2022.105798},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105798},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization of reward shaping function based on genetic algorithm applied to a cross validated deep deterministic policy gradient in a powered landing guidance problem},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple local domains transfer network for equipment fault
intelligent identification. <em>EAAI</em>, <em>120</em>, 105791. (<a
href="https://doi.org/10.1016/j.engappai.2022.105791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely used in the field of mechanical fault diagnosis and equipment health monitoring. A crucial practical issue is the cross-domain machinery fault diagnosis, where we typically train the models with artificial fault samples designed from experimental simulation as the real fault samples are very limited in practice. The characteristic distribution of artificial fault samples in the laboratory is quite different from that of real fault samples in the industrial environment. Whereas, the conventional method mainly focuses on the adversarial domain transfer learning in global domain, ignoring the local similarity of the same fault types between source domain and target domain. This causes an incomplete transfer for the fault types distributed in two domains. To address this issue, this study proposes a multiple local domains transfer network, which consists of two feature extractors, a state classifier and multiple local domain discriminators. The multi-local domain adversarial learning can effectively reduce the negative transfer in network training. By comparing with other five cutting-edge deep learning models, the proposed method shows outstanding robustness and accuracy in fault intelligent identification. Especially, it can be also found that the average accuracy of the proposed method is respectively higher than that of other adversarial domain transfer methods with a promotion for 5% on bearing and gear datasets.},
  archive      = {J_EAAI},
  author       = {Yinjun Wang and Liang Ge and Chunrong Xue and Xiaobo Li and Xianghui Meng and Xiaoxi Ding},
  doi          = {10.1016/j.engappai.2022.105791},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {105791},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple local domains transfer network for equipment fault intelligent identification},
  volume       = {120},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MemSeg: A semi-supervised method for image surface defect
detection using differences and commonalities. <em>EAAI</em>,
<em>119</em>, 105835. (<a
href="https://doi.org/10.1016/j.engappai.2023.105835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-accuracy and real-time semi-supervised image surface defect detection is extensively needed in industrial scenarios. However, existing methods do not provide a good balance between accuracy and speed of defect detection, so this paper proposes an end-to-end memory-based segmentation network (MemSeg) to better accomplish this task. Considering the small intra-class variance of products in the same production line, from the perspective of differences and commonalities, MemSeg introduces artificially simulated abnormal samples and memory samples to assist the model learning. In the training phase, MemSeg explicitly learns the potential differences between normal and simulated abnormal images to obtain a robust classification hyperplane. At the same time, inspired by the mechanism of human memory, MemSeg uses a memory pool to store the general patterns of normal samples. By comparing the similarities and differences between input samples and memory samples in the memory pool to give effective guesses about abnormal regions; In the inference phase, MemSeg directly determines the abnormal regions of the input image in an end-to-end approach. Simple but high-performance, MemSeg achieves state-of-the-art (SOTA) performance on MVTec AD datasets with AUC scores of 99.56% and 98.84% at the image level and pixel level, respectively, while also meeting the real-time requirements in industrial scenarios.},
  archive      = {J_EAAI},
  author       = {Minghui Yang and Peng Wu and Hui Feng},
  doi          = {10.1016/j.engappai.2023.105835},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105835},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MemSeg: A semi-supervised method for image surface defect detection using differences and commonalities},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic part segmentation of facial anatomies using
geometric deep learning toward a computer-aided facial rehabilitation.
<em>EAAI</em>, <em>119</em>, 105832. (<a
href="https://doi.org/10.1016/j.engappai.2023.105832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection, identification, and segmentation of facial landmarks and anatomies play an essential role in the automatic reconstruction of patient specific model of the human head for facial diagnosis, monitoring, and rehabilitation. The objective of the present study was to apply geometric deep learning to perform part segmentation on the human face to automatically segment facial anatomies from a 3D point set. A database of Computed Tomography images of 333 subjects was reconstructed. Labels of facial anatomies (eyes, nose, and mouth) were manually performed. Two state-of-the-art geometric deep learning models (PointNet++ and PointCNN) were implemented and evaluated. Then, the best model was applied to perform part segmentation on new Kinect-driven face data of healthy subjects and facial palsy patients. Accuracy and Intersection over Union (IoU) were used as evaluation metrics. An accuracy level of 99.19% and an IoU of 89.09% are obtained for the CT database using the PointNet++ model. Regarding the use of the PointCNN model, an accuracy level of 98.43 and an IoU of 78.33 were obtained. An accuracy range of [81.45%–92.09%] and [81.05%–84.08%] was obtained by using PointNet++ model on Kinect data for healthy subjects and facial palsy patients respectively. This study suggested that geometric deep learning can be used for automatic segmentation of facial anatomies from a 3D data set. The obtained outcomes confirmed the accuracy of PointNet++ and PointCNN architectures. As perspectives, the proposed method will be implemented into an available computer vision system for facial monitoring and rehabilitation.},
  archive      = {J_EAAI},
  author       = {Duc-Phong Nguyen and Paul Berg and Bilel Debbabi and Tan-Nhu Nguyen and Vi-Do Tran and Ho-Quang Nguyen and Stéphanie Dakpé and Tien-Tuan Dao},
  doi          = {10.1016/j.engappai.2023.105832},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105832},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic part segmentation of facial anatomies using geometric deep learning toward a computer-aided facial rehabilitation},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Radio resource allocation in a 6G d-OMA network with
imperfect SIC: A framework aided by a bi-objective hyper-heuristic.
<em>EAAI</em>, <em>119</em>, 105830. (<a
href="https://doi.org/10.1016/j.engappai.2023.105830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the sixth generation (6G) of mobile communication networks, radio resource allocation management (RRAM) systems must offer high levels of customization and sustainability in their operations. For this reason, this article proposes a framework that maximizes the quality of experience (QoE) of users of a 6G network that implements the delta-orthogonal multiple access (D-OMA) scheme as well as the system’s energy efficiency (EE), considering imperfections in successive interference cancellation (SIC) activities. The framework has two phases: in phase (a), a low-complexity heuristic was implemented in order to carry out the selection of base stations (BSs) and distribution of the electromagnetic spectrum slices to each communication device (CD); and in phase (b), a new bi-objective selection hyper-heuristic (SHH) performs the transmission power levels allocation. To evaluate the framework’s performance, we performed two tests: First, we evaluated the generalization capacity of our SHH with the isolated application of its constituent metaheuristics. Second, our hyper-heuristic was compared to other state-of-the-art transmit power allocation methods (TPLAMs) developed for non-orthogonal multiple access (NOMA) environments. For a fair comparison, all TPLAMs used the same heuristic for phase (a). As a result, the framework, in addition to providing high levels of QoE to network users, also presented low levels of failure probability as well as improved the average EE of the system.},
  archive      = {J_EAAI},
  author       = {Fábio de O. Torres and Valdivino A. Santiago Júnior and D.B. da Costa and Diego L. Cardoso and Roberto C.L. Oliveira},
  doi          = {10.1016/j.engappai.2023.105830},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105830},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Radio resource allocation in a 6G D-OMA network with imperfect SIC: A framework aided by a bi-objective hyper-heuristic},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A bi-objective home care routing and scheduling problem
considering patient preference and soft temporal dependency constraints.
<em>EAAI</em>, <em>119</em>, 105829. (<a
href="https://doi.org/10.1016/j.engappai.2023.105829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Home Health Care Routing and Scheduling Problem (HHCRSP) is one of the most practical branches in Home Health Care (HHC) optimization. The main focus of this study is to investigate an HHCRSP with both soft and Hard Time Windows (HTWs) associated with caregivers and patients, respectively. Furthermore, five different types of soft temporal dependency constraints are considered, which specify different relations amongst the starting time of dependent visits. Accordingly, a bi-objective Mixed-Integer Programming (MIP) model is devised to incorporate staff rostering, vehicle routing, and scheduling simultaneously. This model aims at minimizing the system’s total cost while maximizing the total satisfaction of patient preference. Since the problem is NP-hard, Iterated Local Search (ILS) is applied to solve large-sized problems in high frequencies and within reasonable computational time. Computational results on some real-world-inspired benchmark instances highlight the overall efficiency of the employed algorithm compared to the Non-dominated Sorting Genetic Algorithm (NSGA-II).},
  archive      = {J_EAAI},
  author       = {Nastaran Oladzad-Abbasabady and Reza Tavakkoli-Moghaddam and Mehrdad Mohammadi and Behdin Vahedi-Nouri},
  doi          = {10.1016/j.engappai.2023.105829},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105829},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A bi-objective home care routing and scheduling problem considering patient preference and soft temporal dependency constraints},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A two-stage multi-criteria decision-making method with
interval-valued q-rung orthopair fuzzy technology for selecting
bike-sharing recycling supplier. <em>EAAI</em>, <em>119</em>, 105827.
(<a href="https://doi.org/10.1016/j.engappai.2023.105827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-Sharing has rapidly attracted worldwide attention for its benefits, such as easing traffic congestion and reducing greenhouse gases. However, the waste of resources and environmental pollution caused by discarded bike-sharing should not be underestimated. To tackle this severe problem by selecting the bike-sharing recycling supplier, this paper proposes a two-stage multi-criteria decision-making (MCDM) method using interval-valued q-Rung Orthopair fuzzy (IVq-ROF) technique. In the first stage, based on the Einstein operations, IVq-ROF Einstein operators are defined to aggregate the evaluation information of bike-sharing recycling suppliers. Specifically, IVq-ROF Einstein weighted averaging (IVq-ROFEWA) operator, IVq-ROF Einstein order weighted averaging (IVq-ROFEOWA) operator, IVq-ROF Einstein weighted geometric (IVq-ROFEWG) operator, and IVq-ROF Einstein order weighted geometric (IVq-ROFEOWG) operator are constructed and proved, respectively. In addition, the properties of the proposed operators, including consistency, boundedness and monotonicity, are given and proved. In the second stage, based on the IVq-ROFEWA operator, a MCDM method utilizing Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) in the IVq-ROF environment is presented to select the best bike-sharing recycling supplier. Subsequently, a case study is conducted on the selection of the optimal bike-sharing recycling supplier by exploiting the proposed two-stage MCDM method, which reflects the practicality and availability of the proposed method. Finally, the validity and superiority of the proposed method are verified by comparison and sensitivity analysis.},
  archive      = {J_EAAI},
  author       = {Yuan Xu},
  doi          = {10.1016/j.engappai.2023.105827},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105827},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage multi-criteria decision-making method with interval-valued q-rung orthopair fuzzy technology for selecting bike-sharing recycling supplier},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluation of climate change-resilient transportation
alternatives using fuzzy hamacher aggregation operators based group
decision-making model. <em>EAAI</em>, <em>119</em>, 105824. (<a
href="https://doi.org/10.1016/j.engappai.2023.105824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change has become one of the most significant threats that all countries face. The extent of the effects of climate change will increase if the pace is not altered. Transportation systems are very important considering the order and organization of cities. Therefore, transportation networks must be resilient to the effects of climate change. In this study, three different alternatives to climate change resilient transportation networks, which are climate change resistant design of transportation facilities, alternative routes and strategies for the transportation systems, and climate preparedness are defined. In this study, these alternatives are assessed and prioritized under twelve sub-criteria using the decision-making model. By combining the interval-valued Fermatean fuzzy Hamacher aggregation operators with three decision-making methods including the MEREC (Method using the removal effects of criteria), RS (Rank sum), and the MULTIMOORA (Multi-attribute multi-objective optimization based on the ratio analysis), we develop a novel hybrid model for handling decision-making problems. The practicability and effectiveness of the presented model are tested with a case study. The results of the study show that operationally preparing for the effects of climate change is the best choice out of the ones that were given.},
  archive      = {J_EAAI},
  author       = {Muhammet Deveci and Ilgin Gokasar and Arunodaya Raj Mishra and Pratibha Rani and Zhen Ye},
  doi          = {10.1016/j.engappai.2023.105824},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105824},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluation of climate change-resilient transportation alternatives using fuzzy hamacher aggregation operators based group decision-making model},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RTLSeg: A novel multi-component inspection network for
railway track line based on instance segmentation. <em>EAAI</em>,
<em>119</em>, 105822. (<a
href="https://doi.org/10.1016/j.engappai.2023.105822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The condition monitoring of railway track line is one of the fundamental tasks to ensure the safety of the railway transportation system. Railway track line is mainly made up of tracks, fasteners, bolts, backing plates, and so on. Given the requirements for rapid and accurate inspection, an innovative and intelligent method for multi-component identification and common defect detection of railway track line is investigated based on instance segmentation. More specifically, a railway track line image (RTL-I) dataset is constructed and annotated manually in this paper. After that, based on the work of YOLACT and YOLACT++, combined with prior knowledge, a railway track line image segmentation model (RTLSeg for short) is proposed. Firstly, taking the characteristics of the objects in the RTL-I dataset, preset anchors are redesigned and a feature enhanced module is introduced in the prediction head to improve the detection and segmentation accuracy of the model. Secondly, to strengthen the internal information propagation within the model, PaFPN (path aggregation feature pyramid network) is applied instead of FPN in RTLSeg. Thirdly, with the help of CoordConv, Coord-Protonet is presented to add position awareness explicitly to the model for more robust and higher quality prototype masks. Finally, to further improve the model performance, the attention mechanism is explored and a novel spatial attention-guided bounding box branch is employed in the enhanced prediction head. Both quantitative and qualitative experimental results show that the proposed method is feasible in detecting and segmenting multi-component and common defects of railway track line, and outperforms the compared baseline models. In particular, RTLSeg is able to achieve 91.35 bbox mAP and 91.60 mask mAP with the customized dataset. Meanwhile, the average inference speed reaches 13.07 fps. The average detection accuracy and recall are 100% and 99.83%, respectively. Furthermore, the effectiveness of each optimized part of the proposed RTLSeg model is demonstrated by additional ablation study.},
  archive      = {J_EAAI},
  author       = {Dehua Wei and Xiukun Wei and Qingfeng Tang and Limin Jia and Xinqiang Yin and Yang Ji},
  doi          = {10.1016/j.engappai.2023.105822},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105822},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RTLSeg: A novel multi-component inspection network for railway track line based on instance segmentation},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An accurate automated speaker counting architecture based on
james webb pattern. <em>EAAI</em>, <em>119</em>, 105821. (<a
href="https://doi.org/10.1016/j.engappai.2023.105821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker counting is an important research area in sound forensics. There are limited speaker counting papers in the literature, as it is challenging to collect datasets. This work aims to collect a new overlapping speech signal dataset for speaker counting and propose a novel feature engineering model. In this work, textural feature extraction is based on the iconic James Webb space telescope; hence, this pattern is named James Webb Pattern (JWPat). A new speaker counting speech dataset comprising 3,121 speeches divided into 32 classes (the class number corresponded to the number of speakers) was collected. A new framework that mimics the deep learning model has been proposed to classify the collected speech classes. The proposed feature engineering model is self-organized and uses various mother wavelet functions to generate features at both low and high levels. We have obtained the best classification accuracy of 86.74% using the symlet4 mother wavelet function. Using our proposed framework, eight classification results have been calculated with accuracy ranging from 75.94% to 86.74% . This range is over 10% accuracy, and it demonstrates the effect of the mother wavelet function on the classification performance. Moreover, the feature extraction capability of the mirror of the James Webb telescope has been demonstrated. Our proposed method yielded 86.74% accuracy on a large dataset and indicated the success of our proposed model.},
  archive      = {J_EAAI},
  author       = {Prabal Datta Barua and Arif Metehan Yildiz and Nida Canpolat and Tugce Keles and Sengul Dogan and Mehmet Baygin and Ilknur Tuncer and Turker Tuncer and Ru-San Tan and Hamido Fujita and U. Rajendra Acharya},
  doi          = {10.1016/j.engappai.2023.105821},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105821},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An accurate automated speaker counting architecture based on james webb pattern},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prognosticating various acute covid lung disorders from
COVID-19 patient using chest CT images. <em>EAAI</em>, <em>119</em>,
105820. (<a
href="https://doi.org/10.1016/j.engappai.2023.105820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global spread of coronavirus illness has surged dramatically, resulting in a catastrophic pandemic situation. Despite this, accurate screening remains a significant challenge due to difficulties in categorizing infection regions and the minuscule difference between typical pneumonia and COVID (Coronavirus Disease) pneumonia. Diagnosing COVID-19 using the Mask Regional-Convolutional Neural Network (Mask R-CNN) is proposed to classify the chest computerized tomographic (CT) images into COVID-positive and COVID-negative. Covid-19 has a direct effect on the lungs, causing damage to the alveoli, which leads to various lung complications. By fusing multi-class data, the severity level of the patients can be classified using the meta-learning few-shot learning technique with the residual network with 50 layers deep (ResNet-50) as the base classifier. It has been tested with the outcome of COVID positive chest CT image data. From these various classes, it is possible to predict the onset possibilities of acute COVID lung disorders such as sepsis, acute respiratory distress syndrome (ARDS), COVID pneumonia, COVID bronchitis, etc. The first method of classification is proposed to diagnose whether the patient is affected by COVID-19 or not; it achieves a mean Average Precision (mAP) of 91.52% and G-mean of 97.69% with 98.60% of classification accuracy. The second method of classification is proposed for the detection of various acute lung disorders based on severity provide better performance in all the four stages, the average accuracy is of 95.4%, the G-mean for multiclass achieves 94.02%, and the AUC is 93.27% compared with the cutting-edge techniques. It enables healthcare professionals to correctly detect severity for potential treatments.},
  archive      = {J_EAAI},
  author       = {Suganya D. and Kalpana R.},
  doi          = {10.1016/j.engappai.2023.105820},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105820},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prognosticating various acute covid lung disorders from COVID-19 patient using chest CT images},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning fair representations for accuracy parity.
<em>EAAI</em>, <em>119</em>, 105819. (<a
href="https://doi.org/10.1016/j.engappai.2023.105819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of artificial intelligence in various fields of society, algorithm fairness has become a concern in social decision-making. Researchers have proposed various fair algorithms to achieve statistical parity and equal opportunity of outputs. However, the accuracy parity of algorithms has not been fully discussed. Existing fair algorithms either ignore the accuracy parity or sacrifice the joint accuracy of the model while achieving accuracy parity. A novel fairness algorithm referred to as balanced fair representation for accuracy parity (BFA) is proposed to reduce the bias on the accuracy among sensitive attribute groups while maintaining their joint accuracy. BFA uses representation learning methods to learn similar representations from different sensitive attribute groups. The learned representations are used as training data to learn a fair classification model. The classification error of the model is constrained to be independent of the sensitive attributes. To obtain similar representations, BFA calculates the characteristic scores of different sensitive attribute groups, respectively. BFA takes the difference between scores of different sensitive attribute groups from the same label as the constraint objective of learning the representation. To achieve accuracy parity, BFA calculates the cross entropy loss of neural networks from the learned similar representations and reduces the correlation between the loss and sensitive information. Empirical results show that the proposed representations provide a better trade-off between accuracy parity and joint accuracy than state-of-the-art works.},
  archive      = {J_EAAI},
  author       = {Tangkun Quan and Fei Zhu and Quan Liu and Fanzhang Li},
  doi          = {10.1016/j.engappai.2023.105819},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105819},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning fair representations for accuracy parity},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RFA-net: Residual feature attention network for fine-grained
image inpainting. <em>EAAI</em>, <em>119</em>, 105814. (<a
href="https://doi.org/10.1016/j.engappai.2022.105814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although most existing methods using Generative Adversarial Networks (GAN) generally produce plausible results, there is a significant amount of artifacts and less-than-ideal restoration of textures when large regions are missing or the background of missing regions is complex. To address this issue, in this paper, we propose a novel texture-aware backbone net named RFA-Net for finer texture image inpainting. Compared to conventional encoder–decoder methods, our main contribution is proposing a novel RFA-Net adopt a non-pooling residual CNN structure with three novel modules, which retains texture features from shallow layers and adaptively learn the importance of certain channels and locations of features that may potentially benefit image inpainting. In addition, we propose a hybrid loss optimization (HLO) module to enable the generator to focus on the semantic and texture details of the inpainted contents. Experimental results demonstrate that our RFA-Net is able to recover texture details and ground-truth consistent images, and outperforms the state-of-the-art methods both in terms of image quality and quantitative metrics. Our source code and data are available online at https://github.com/Jamie-61/RFA-Net-Inpainting .},
  archive      = {J_EAAI},
  author       = {Min Chen and Shengrui Zang and Zhenhua Ai and Jieru Chi and Guowei Yang and Chenglizhao Chen and Teng Yu},
  doi          = {10.1016/j.engappai.2022.105814},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105814},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RFA-net: Residual feature attention network for fine-grained image inpainting},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Deep learning-based real-time 3D human pose estimation.
<em>EAAI</em>, <em>119</em>, 105813. (<a
href="https://doi.org/10.1016/j.engappai.2022.105813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human body pose estimation represented by joint rotations is essential for driving the virtual characters. The present paper developed a novel end-to-end point-to-pose mesh fitting network (P2P-MeshNet) to directly estimate the body joint rotations. P2P-MeshNet provided a strong collaboration between the deep learning network, an inverse kinematics network for body pose estimation (IKNet-body), and the self-correcting network, an iterative error feedback network (IEF). The introduced P2P-MeshNet was then applied to the free mocap (FreeMocap) dataset covering OpenPose 3D joint locations reconstructed from multi-view OpenPose 2D joint locations. The generated joint rotations were tested using the mean per joint position error (MPJPE), as well as the percentage of correct keypoints (PCK) along with the area under the PCK curve (AUC) with a threshold range of 0–60 mm after Procrustes aligned. Based on the compared metrics, P2P-MeshNet with 11.31 mm and 99.7% in estimate error and success rate as well as an AUC of 80.9 demonstrated a more consistent tool for future human body pose estimation. The runtime performance of 100 frames per second implied its potential application prospects.},
  archive      = {J_EAAI},
  author       = {Xiaoyan Zhang and Zhengchun Zhou and Ying Han and Hua Meng and Meng Yang and Sutharshan Rajasegarar},
  doi          = {10.1016/j.engappai.2022.105813},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105813},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based real-time 3D human pose estimation},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vaccine selection for COVID-19 by AHP and novel VIKOR hybrid
approach with interval type-2 fuzzy sets. <em>EAAI</em>, <em>119</em>,
105812. (<a
href="https://doi.org/10.1016/j.engappai.2022.105812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decisions in the health industry have a significant impact on human lives. With the COVID-19 pandemic, a global war is being waged. Vaccination is a critical component in this fight. The governments are attempting to offer their citizens the best vaccine for the public based on limitations. However, due to the unique characterizations of countries and the people who live in the country, the definition of “the ideal vaccination” is indefinite. Fuzzy set theory has been an ideal tool to cope with problems involving imprecise information such as the meaning of “ideal” in this case. In this study Interval Type-2 Fuzzy Sets (IT2FSs) will be used to describe uncertainty. This IT2FS structure will be the framework of the AHP (Analytic Hierarchy Process), to determine the criteria weights, and the VIKOR (VIseKriterijumska Optimizacija I Kompromisno Resenje), to generate a set of optimal choices. The main objective of this study is to sustain the necessary effect of uncertainty of fuzzy sets via the Interval Type-2 Fuzzy (IT2F) metric to the VIKOR method and thus propose an extended VIKOR. The presented new approach will be applied to the problem of vaccine selection for COVID-19. Hence, for the first time in the literature, an application with a multilevel hierarchy will be used in IT2FAHP-VIKOR. Also, obtained optimal solution set with this hybrid framework will be compared with fuzzy AHP-VIKOR and the rankings evaluated with the IT2FTOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) and sensitivity analysis will be performed.},
  archive      = {J_EAAI},
  author       = {Büşra Meni̇z and E. Mehmet Özkan},
  doi          = {10.1016/j.engappai.2022.105812},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105812},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vaccine selection for COVID-19 by AHP and novel VIKOR hybrid approach with interval type-2 fuzzy sets},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved estimation of rail–wheel contact forces from
instrumented wheel-set data through higher harmonic cancellation and a
back-propagation neural network scheme. <em>EAAI</em>, <em>119</em>,
105811. (<a
href="https://doi.org/10.1016/j.engappai.2022.105811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instrumented wheelsets, equipped with numbers of strain gauges, are widely used to estimate the rail–wheel contact parameters. The accuracy in estimation of rail–wheel contact parameters from the measured strain signals depends on the layout of the strain gauges and correlation techniques adopted for processing measured signals. Harmonic components estimation is the most widely used conventional correlation technique. However, its accuracy in estimation of rail–wheel contact parameters is limited to the order of 80%–90%. This study proposes a signal modification algorithm, initially utilizing cancellation of next significant higher harmonics than those considered in the existing algorithms and then further, a novel Artificial Neural Network architecture for the same purpose. The signal modification approach is based on the realization that the seventh harmonic has significant contribution on the strain signals. The proposed algorithm is aimed at estimating and cancelling the effects of the seventh harmonic in strain signals. The accuracy thus improves to 91% in vertical contact force estimates, while the accuracy in estimation of lateral contact force and lateral contact position are improved to 97% and 95%, respectively. Due to the highly non-linear nature of the rail–wheel contact parameters, an optimized nonlinear mapping is required for further improvement in the accuracy. The viability of using artificial neural networks in estimation of rail–wheel contact parameters have been explored earlier. The proposed architectures are complicated and require extensive manual optimization of tuning parameters. A simple back-propagation artificial neural network architecture, using Bayesian regularization training function with Levenberg–Marquardt optimization technique is proposed in this study. The proposed neural network consists of 18 measured strain signals as input, three hidden layers with 20, 6 and 3 neurons, respectively, and vertical force, lateral force and lateral contact position as three outputs. Accuracies of the order of 99%, 99% and 96% are achieved in the estimation of vertical contact force, lateral contact force and lateral contact position respectively. The input and training data is generated from the multi-body dynamics and finite element simulations.},
  archive      = {J_EAAI},
  author       = {Onkar S. Ropalkar and Om Prakash Yadav and Chetan Zambare and Nalinaksh S. Vyas},
  doi          = {10.1016/j.engappai.2022.105811},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105811},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved estimation of rail–wheel contact forces from instrumented wheel-set data through higher harmonic cancellation and a back-propagation neural network scheme},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strawberry localization in a ridge planting with an
autonomous rover. <em>EAAI</em>, <em>119</em>, 105810. (<a
href="https://doi.org/10.1016/j.engappai.2022.105810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Having complete knowledge of a strawberry crop field is helpful in making crucial decisions and optimizing strawberry production. For that aim, autonomous robots have played a crucial role in getting such information through various sensors in the last few years. In this context, we present an autonomous rover system that detects strawberries and estimates their ripeness in a natural crop field through visual information using a stereo camera. With that aim, we propose an algorithm that uses image processing techniques with deep learning approaches. Furthermore, we construct a strawberry map to provide the farmer with information regarding the growing state of the fruit, health, and even a production estimation. Moreover, the rover and the vision algorithm are designed to work on ridge planting , a kind of strawberry crop field where uneven terrains, narrow spaces, and rugged backgrounds are presented. Experiments were conducted in a natural crop field, showing satisfactory results; from comparison results with the most recent work in the state-of-the-art, we observe that our system detects 14% more strawberries. Furthermore, a video showing the obtained results is presented. Finally, intending to contribute to the community, we release the code corresponding to our proposed method on our GitHub website.},
  archive      = {J_EAAI},
  author       = {Gesem Mejia and Andrés Montes de Oca and Gerardo Flores},
  doi          = {10.1016/j.engappai.2022.105810},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105810},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Strawberry localization in a ridge planting with an autonomous rover},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A deeper generative adversarial network for grooved cement
concrete pavement crack detection. <em>EAAI</em>, <em>119</em>, 105808.
(<a href="https://doi.org/10.1016/j.engappai.2022.105808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periodic grooved cement concrete pavement crack detection is of great importance for pavement condition monitoring and maintenance. The current state-of-the-art (SOTA) detection solutions highly depend on datasets. However, due to the limited access to crack images, more efficient methods are urgently needed to advance the detection of cracking on grooved cement concrete pavement. This study proposes an improved deeper Wasserstein generative adversarial network with gradient penalty (WGAN-GP) to generate datasets of pavement images with a size of 512 × 512 pixels 2 . Poisson bleeding is adopted to create the synthesized grooved cement concrete pavement crack images based on the generated crack images and groove images. The robustness of the proposed improved deeper WGAN-GP model is validated by Faster R-CNN, YOLOv3, and YOLOv4 models trained on original crack images and generated crack images for region-level detection. U-Net and W-segnet are used to achieve pixel-level crack detection to evaluate the effectiveness of proposed model. Results show that the improved deeper WGAN-GP could generate more realistic transverse, longitudinal and oblique crack images. In addition, the Poisson bleeding algorithm contributes to synthesizing grooved cement concrete pavement crack images. Moreover, it is observed that YOLOv3 trained by the augmented dataset could achieve a mean average precision (MAP) of 81.98%, 6% MAP higher than the non-augmented dataset. U-Net and W-segnet benefit from augmented dataset with a better pixel-level segmentation result. Based on the results, it can be concluded that the improved deeper WAGN-GP image generation method can provide a straightforward way to fill the data shortage gap of grooved cement concrete pavement cracks, thus increasing the problem-solving capability of the SOTA crack detection models.},
  archive      = {J_EAAI},
  author       = {Jingtao Zhong and Ju Huyan and Weiguang Zhang and Hanglin Cheng and Jing Zhang and Zheng Tong and Xi Jiang and Baoshan Huang},
  doi          = {10.1016/j.engappai.2022.105808},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105808},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deeper generative adversarial network for grooved cement concrete pavement crack detection},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural TV program recommendation with multi-source
heterogeneous data. <em>EAAI</em>, <em>119</em>, 105807. (<a
href="https://doi.org/10.1016/j.engappai.2022.105807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {TV program recommendation is important for users in the face of a huge amount of information data. The existing TV program recommendation mainly relies on a collaborative filtering method to recommend through interactive data between users and programs. Although some methods utilize auxiliary information to enrich semantic features, most of them only use a single data type, which cannot capture a more diverse feature representation of the user and program. In this paper, we propose a neural TV program recommendation model with multi-source heterogeneous data, which makes full use of the multi-source heterogeneous auxiliary information. Specifically, we combine heterogeneous features derived from auxiliary information to learn a deep program representation in the program encoder module. To more accurately capture user preferences, we further utilize the personalized attention mechanism to determine the importance of different programs to the user representation based on the interaction between users and programs in the user encoder module. Extensive experiments on a real dataset of the Chinese capital show that our model can effectively improve the performance of TV program recommendations compared to the existing models.},
  archive      = {J_EAAI},
  author       = {Fulian Yin and Tongtong Xing and Zhaoliang Wu and Xiaoli Feng and Meiqi Ji},
  doi          = {10.1016/j.engappai.2022.105807},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105807},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural TV program recommendation with multi-source heterogeneous data},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive enhanced interval type-2 possibilistic fuzzy local
information clustering with dual-distance for land cover classification.
<em>EAAI</em>, <em>119</em>, 105806. (<a
href="https://doi.org/10.1016/j.engappai.2022.105806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land cover classification of remote sensing image is faced with uncertainties such as “significant difference in category density”, “the same object with different spectra”, and “different objects with the same spectrum”. Existing possibilistic fuzzy clustering-related method still cannot fully meet the interpretation requirements of remote sensing data. To accurately classify remote sensing image with complex geographical distribution, this paper proposes a robust interval type-2 dual-distance driven possibilistic fuzzy clustering motivated by interval-valued number for land cover classification. Firstly, interval-valued data model is established by using the local mean and variance of single-valued data. Secondly, Hausdorff distance and MW distance for interval-valued numbers are introduced to realize the maximum separability of overlapping categories in interval-valued data and generate interval uncertainty sets. To further enhance its robustness, weighted local information factors are constructed by making full use of the generated fuzzy membership and possibilistic typicality, and a novel robust interval type-2 possibilistic fuzzy C-means clustering is proposed. Finally, the adaptive type reduction method is introduced, meanwhile the adaptive expansion of interval-valued data model is realized by using the adaptive contraction expansion control factor. After the iterative algorithm convergences, the accurate classification of covered objects in remote sensing images is realized. Experimental results indicate that the classification performance of the proposed algorithm is better than that of existing interval type-2 fuzzy clustering algorithm and its variants, and it is more suitable for the interpretation of remote sensing images in the actual environments.},
  archive      = {J_EAAI},
  author       = {Chengmao Wu and Xiaokang Guo},
  doi          = {10.1016/j.engappai.2022.105806},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105806},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive enhanced interval type-2 possibilistic fuzzy local information clustering with dual-distance for land cover classification},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAN-AE: An unsupervised intrusion detection system for MQTT
networks. <em>EAAI</em>, <em>119</em>, 105805. (<a
href="https://doi.org/10.1016/j.engappai.2022.105805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Households and businesses are becoming increasingly reliant on IoT systems since they can reliably automate many tasks that otherwise require extensive human involvement. As a result, the number of IoT devices that are being added to the Internet is increasing steeply. To cater to the increasing demand and attract customers, manufacturers are focusing on producing cheaper and easy-to-use IoT devices without giving enough importance to the security aspect. With the recent developments in machine learning algorithms, IoT device manufacturers have started using supervised intrusion detection models to protect IoT systems from security breaches. However, these systems are being targeted by novel attacks that cannot be detected by the already deployed supervised models. Thus, it is important to develop solutions to protect the IoT networks/systems from these previously unknown intrusions. MQTT is a widely used network protocol in IoT systems due to its lightweight and flexible nature. In this paper, we propose a novel unsupervised GAN and autoencoder-based model, called GAN-AE, for detecting unknown intrusions in MQTT IoT applications. The performance of the proposed GAN-AE model is compared with other popular unsupervised models namely autoencoder, One-Class SVM (OCSVM), and Isolation Forest (IF). The GAN-AE model performed superior to other models with accuracy, F1-Score of 0.97 on our custom-built and public MQTT dataset.},
  archive      = {J_EAAI},
  author       = {Tej Kiran Boppana and Priyanka Bagade},
  doi          = {10.1016/j.engappai.2022.105805},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105805},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GAN-AE: An unsupervised intrusion detection system for MQTT networks},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble of effect size methods based on meta fuzzy
functions. <em>EAAI</em>, <em>119</em>, 105804. (<a
href="https://doi.org/10.1016/j.engappai.2022.105804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many methods are used in the literature to determine the effect size (ES) for two independent groups. Many of these methods yield consistent results under the assumptions of normality of data and homogeneity of variances. However, not every dataset can provide these assumptions. In order to overcome the limitations mentioned, this study proposes the use of meta fuzzy effect size functions (MFESF). The MFESF weights six ES methods (Cohen’s d , Hedge’s g , and Glass’ delta, Cliff’s delta, Vargha and Delaney A and Glass’ rank-biserial correlation) used for two independent groups according to their performances and provides better outcomes, regardless of assumptions. The MFESF method uses the fuzzy c-means (FCM) clustering algorithm to combine the selected ES methods. In this study, MFESF is evaluated by using generated datasets based on normal and non-normal distribution for six reference values. In addition, the performance of MFESF is evaluated by using real datasets with normal and non-normal distributions. As a result, the MFESF performed the best with the lowest mean absolute percentage error (MAPE) compared to the individual ES methods for all datasets.},
  archive      = {J_EAAI},
  author       = {Ayşegül Yabacı Tak and Ilker Ercan},
  doi          = {10.1016/j.engappai.2022.105804},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105804},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble of effect size methods based on meta fuzzy functions},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Designing of optimal digital IIR filter in the
multi-objective framework using an evolutionary algorithm.
<em>EAAI</em>, <em>119</em>, 105803. (<a
href="https://doi.org/10.1016/j.engappai.2022.105803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an optimization technique i.e. diversity-driven multi-parent evolutionary algorithm with adaptive non-uniform mutation (DDMPEA-ANUM) has been used to design a digital IIR filter considering the magnitude response error of pass-band and stop-band and linear phase response error as fitness functions. The proposed algorithm utilizes population space aggregation and fitness variance concepts to guide the solution so that it will not stuck in local optima. The efficacy of the developed method is tested on twenty-three benchmark functions and compared with other state of art algorithms in terms of best, worst, average and standard deviation. The statistical analysis of the developed algorithm has also been carried out through Wilcoxon’s rank-sum to confirm its effectiveness. The developed algorithm while designing the IIR filter design problem obtained the least values for magnitude response error of pass-band and stop-band and linear phase response when compared to other state of art algorithms. For instance, the developed algorithm obtained magnitude response error for pass band and stop band and linear phase response error of 0.0101, 0.727 and 3.3903 × 1 0 − 06 for LP, 0.0073, 0.003 and 2.3933 × 1 0 − 06 for HP, 0.0018, 0.0260 and 4.4429 × 1 0 − 06 for bandpass filter and 0.0445, 0.0209 and 1.3081 × 1 0 − 06 for band stop filter.},
  archive      = {J_EAAI},
  author       = {Sumika Chauhan and Manmohan Singh and Ashwani Kumar Aggarwal},
  doi          = {10.1016/j.engappai.2022.105803},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105803},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Designing of optimal digital IIR filter in the multi-objective framework using an evolutionary algorithm},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review of stance detection for rumor verification in social
media. <em>EAAI</em>, <em>119</em>, 105801. (<a
href="https://doi.org/10.1016/j.engappai.2022.105801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media is a perfect breeding ground for false rumors due to the simplicity of sharing information, which may have negative implications in a variety of domains, including economics, healthcare, and politics. Previous research indicates that public reactions to false rumors are a critical indicator for determining the truthfulness of news. In social media, substantial effort has been invested in detecting and debunking rumors based on crowd stance, given that stance is a vital part of automatic news verification. This paper presents a review of recent approaches in the area of rumor verification using stance detection, which attempts to determine a given document’s stance with respect to a given piece of news. The review offers a detailed list of datasets, as well as a summary of relevant experiments and methods employed, as well as analysis of helpful features for addressing this issue. Finally, we highlight the main challenges and future directions in this field by utilizing stance detection.},
  archive      = {J_EAAI},
  author       = {Hissa F. Alsaif and Hmood D. Aldossari},
  doi          = {10.1016/j.engappai.2022.105801},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105801},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review of stance detection for rumor verification in social media},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Thermal failure of diamond tools indicated by diamond
degradation: Damage evaluation and property prediction on small image
datasets. <em>EAAI</em>, <em>119</em>, 105800. (<a
href="https://doi.org/10.1016/j.engappai.2022.105800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High temperature induced diamond degradation often leads to the failure of diamond tools. In this work, diamond samples holding different degrees of thermal damage were prepared by heating and sintering. The influence of diamond particle size and processing temperature was investigated through mechanical testing and micromorphology observation, meanwhile, a dataset containing 2870 SEM images showing diamonds with different degrees of degradation was constructed. By modification of VGG16 network, classification models and regression models were developed for thermal damage evaluation and sample property prediction. Training strategies including transfer learning and data augmentation were implemented and verified essential on the small dataset, where drop-out showed no positive effects. Two classification models (3-class and 65-class) were constructed and trained for damage evaluation. Visualized damage feature maps exported from Grad-CAM revealed the influential mechanism of thermal damage on diamonds, which proved the effectiveness of the classification models as well. Under the optimized training strategies, regression models were built for sample property prediction. The models towards toughness index, bending strength loss, relative density and Rockwell hardness were examined. Comparing the output results with real property values in test sets, the first two models matched well, and the latter two showed the opposite. It verified the validity of the regression models for property prediction as they were all established based on diamond damage image datasets. The loss in bending strength loss prediction model was smaller than that of toughness index, indicating bending strength easier to be shorten than impact toughness for diamond/metal composites suffering thermal impacts.},
  archive      = {J_EAAI},
  author       = {Wucheng Sun and Hui Gao and Yuxiang Chen and Zhiming Wang and Longchen Duan and Songcheng Tan and Xiaohong Fang},
  doi          = {10.1016/j.engappai.2022.105800},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105800},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal failure of diamond tools indicated by diamond degradation: Damage evaluation and property prediction on small image datasets},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inception 1D-convolutional neural network for accurate
prediction of electrical insulator leakage current from environmental
data during its normal operation using long-term recording.
<em>EAAI</em>, <em>119</em>, 105799. (<a
href="https://doi.org/10.1016/j.engappai.2022.105799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contamination flashover remains one of the biggest challenges for power grid designers and maintenance engineers. Insulator leakage current contains relevant information about their state so that continuous monitoring is considered the most effective way to prevent contamination flashover. In this work, we attempted to accurately predict insulator leakage current in real time during normal operations based on environmental data using long-term recordings. We first confirmed that the history of environmental data also contained relevant information to predict leakage current by conditional Granger analysis and determined that 20 was the optimal number of previous samples for this purpose. We then compared the performance of typical regression models and convolutional neural network (CNN), when using both current and the last 21 samples as input features. We confirmed that the model with the last 21 samples might perform significantly better. Input features pre-processing by cascaded inception architecture was fundamental to capture the complex dynamic interaction between environmental data and leakage current and significantly improved the model performance. CNN based on inception architecture performed much better, achieving an average R 2 of 0.94 ± 0.03. The proposed model could be used to predict leakage current in both porcelain insulators with or without coatings and silicone composite insulators. Our results pave the way for creating an on-line pre-warning system adapted to individual installations, can anticipate the negative consequences of weather and/or pollution deposits and is useful for designing a strategic high-voltage electrical insulator preventive maintenance plan for preventing contamination flashover and thus increase power grid reliability and resilience.},
  archive      = {J_EAAI},
  author       = {Jose-M. Bueno-Barrachina and Yiyao Ye-Lin and Felix Nieto-del-Amor and Vicente Fuster-Roig},
  doi          = {10.1016/j.engappai.2022.105799},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105799},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inception 1D-convolutional neural network for accurate prediction of electrical insulator leakage current from environmental data during its normal operation using long-term recording},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PlaceNet: A multi-scale semantic-aware model for visual loop
closure detection. <em>EAAI</em>, <em>119</em>, 105797. (<a
href="https://doi.org/10.1016/j.engappai.2022.105797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loop closure detection helps simultaneous localization and mapping systems reduce map and state uncertainty via recognizing previously visited places along the path of a mobile robot. However, visual loop closure detection is susceptible to scenes with dynamic objects and changes in illumination, background, and weather conditions. This paper introduces PlaceNet, a novel plug-and-play model for visual loop closure detection. PlaceNet is a multi-scale deep autoencoder network augmented with a semantic fusion layer for scene understanding. The main idea of PlaceNet is to learn where not to look in a dynamic scene full of moving objects, i.e., avoid being distracted by dynamic objects to focus on the scene landmarks instead. We train PlaceNet to identify dynamic objects in scenes via learning a grayscale semantic map indicating the position of static and moving objects in the image. PlaceNet generates semantic-aware deep features that are robust to dynamic environments and scale invariant. We evaluated our method on different challenging indoor and outdoor benchmarks. To conclude, PlaceNet demonstrated competitive results compared to the state-of-the-art methods over various datasets used in our experiments.},
  archive      = {J_EAAI},
  author       = {Hussein Osman and Nevin Darwish and AbdElMoniem Bayoumi},
  doi          = {10.1016/j.engappai.2022.105797},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105797},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PlaceNet: A multi-scale semantic-aware model for visual loop closure detection},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy scheduler for MAS applied to object tracking.
<em>EAAI</em>, <em>119</em>, 105796. (<a
href="https://doi.org/10.1016/j.engappai.2022.105796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent industry and Internet of Things (IoT) rely on sensors to monitor the surroundings and allow information exchange. More sensors deployed in an environment offer additional benefits, such as increased availability and more accurate observations, as they generate information from different perspectives. Nonetheless, dealing with large amounts of data and multiple input sources to deduct unified information often requires considerable processing, communication, and energy resources. To address such a problem, this work examines intelligent agents that cooperate to generate a unified output in a Multi-Agent System (MAS) environment. The proposed approach presents a fuzzy scheduler that evaluates the processing and accuracy level to determine the relevance of each agent by comparing its information with the unified output. The proposal orchestrates when an agent can have its processing suspended. Our evaluations demonstrate that this proposal improves service level metrics, such as the rate of video frames processed per second for an increasing number of agents. We consider three experimental setups using tracking agents. First, we evaluate the threshold and how long an agent should remain idle when its observations are irrelevant. The second experiment considers an increasing number of agents. Agent scheduling achieves a frame processing rate 12.5 times faster while suffering a 6% accuracy loss for 20 agents. The third experiment focuses on using different tracking algorithms simultaneously. In this case, compared to when no agent scheduling is applied, there is a 23.9 fold increase in the frame processing rate while losing some accuracy, limited to around 6%.},
  archive      = {J_EAAI},
  author       = {Gibson Barbosa and Marrone Dantas and Assis Tiago de Oliveira Filho and Iago Richard Rodrigues and Daniel Bezerra and Djamel Sadok and Judith Kelner and Ricardo Souza},
  doi          = {10.1016/j.engappai.2022.105796},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105796},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fuzzy scheduler for MAS applied to object tracking},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient entropy based dissimilarity measure to cluster
categorical data. <em>EAAI</em>, <em>119</em>, 105795. (<a
href="https://doi.org/10.1016/j.engappai.2022.105795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an unsupervised learning technique that discovers intrinsic groups based on proximity between data points. Therefore, the performance of clustering techniques mainly relies on the proximity measures used to compute the (dis)similarity between the data objects. In general, it is relatively easier to compute the distance between numerical data points as numerical operations can directly be applied to values along features. However, for categorical datasets, computing the (dis)similarity between the data objects becomes a non-trivial problem. Therefore, in this paper, we propose a new distance metric based on the information theoretic approach to compute the dissimilarity between categorical data points. We compute entropy along each feature to capture the intra-attribute statistical information, based on which significance of attributes are decided during clustering. The proposed measure is free from any domain-dependent parameters and also does not rely on the distribution of data points. Experiment is conducted over diversified benchmark data sets, considering six competing proximity measures with three popular clustering algorithms and the clustering results are compared in terms of RI (Rand Index), ARI (Adjusted Rand Index), CA (Clustering Accuracy) and Cluster Discrimination Matrix (CDM). Over 85 percent of the data sets, the clustering accuracy of the proposed metric embedded with K-Mode and Weighted K-Mode outperforms its counterparts. Approximately, 0.2951 s is needed by the proposed metric to cluster a data set having 10,000 data points with 8 attributes and 2 clusters on a standard desktop machine. Overall, experimental results demonstrate the efficacy of the proposed metric to handle complex real datasets of different characteristics.},
  archive      = {J_EAAI},
  author       = {Amit Kumar Kar and Amaresh Chandra Mishra and Sraban Kumar Mohanty},
  doi          = {10.1016/j.engappai.2022.105795},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105795},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient entropy based dissimilarity measure to cluster categorical data},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GTFE-net: A gramian time frequency enhancement CNN for
bearing fault diagnosis. <em>EAAI</em>, <em>119</em>, 105794. (<a
href="https://doi.org/10.1016/j.engappai.2022.105794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis of the bearing is vital for the safe and reliable operation of rotating machines in the manufacturing industry. Convolutional neural networks (CNNs) have been popular in bearing fault diagnosis by right of robust and reliable feature extraction ability. However, the collected vibrational signals from machines are usually corrupted by unrelated noises due to complicated transfer path modulations and component coupling. As traditional CNN lacks the denoising structure, its capability of extracting features from vibrational features is restrained by noise disturbances. In response to the above issue, this paper first proposes a simple but efficient Gramian-based noise reduction strategy called Gramian Noise Reduction (GNR) based on the periodic self-similarity of vibrational signals. Second, for the problem of lacking denoising structure in traditional CNNs, a novel end-to-end GNR-based CNN model, termed as Gramian Time Frequency Enhancement Network (GTFE-Net), is presented for bearing fault diagnosis. The GTFE-Net has three branches to parallelly process the raw original signal, the GNR denoised signal, and the frequency spectrums, respectively. GNR is integrated into the GTFE-Net, prompting the network to pay more attention to feature extraction rather than noise suppression. Three case studies using test rig and real engineering datasets are performed to verify the effectiveness of the proposed method for bearing fault diagnosis. The experimental results show that the GTFE-Net can reduce the useless noises in vibrational signals and deliver a remarkable improvement in classification performance compared with the six state-of-the-art methods. The source code is available at},
  archive      = {J_EAAI},
  author       = {Linshan Jia and Tommy W.S. Chow and Yixuan Yuan},
  doi          = {10.1016/j.engappai.2022.105794},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105794},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GTFE-net: A gramian time frequency enhancement CNN for bearing fault diagnosis},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy management in residential microgrid using model
predictive control-based reinforcement learning and shapley value.
<em>EAAI</em>, <em>119</em>, 105793. (<a
href="https://doi.org/10.1016/j.engappai.2022.105793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an Energy Management (EM) strategy for residential microgrid systems using Model Predictive Control (MPC)-based Reinforcement Learning (RL) and Shapley value. We construct a typical residential microgrid system that considers fluctuating spot-market prices, highly uncertain user demand and renewable generation, and collective peak power penalties. To optimize the benefits for all residential prosumers, the EM problem is formulated as a Cooperative Coalition Game (CCG). The objective is to first find an energy trading policy that reduces the collective economic cost (including spot-market cost and peak-power cost) of the residential coalition, and then to distribute the profits obtained through cooperation to all residents. An MPC-based RL approach, which compensates for the shortcomings of MPC and RL and benefits from the advantages of both, is proposed to reduce the monthly collective cost despite the system uncertainties. To determine the amount of monthly electricity bill each resident should pay, we transfer the cost distribution problem into a profit distribution problem. Then, the Shapley value approach is applied to equitably distribute the profits (i.e., cost savings) gained through cooperation to all residents based on the weighted average of their respective marginal contributions. Finally, simulations are performed on a three-household microgrid system located in Oslo, Norway, to validate the proposed strategy, where a real-world dataset of April 2020 is used. Simulation results show that the proposed MPC-based RL approach could effectively reduce the long-term economic cost by about 17.5%, and the Shapley value method provides a solution for allocating the collective bills fairly.},
  archive      = {J_EAAI},
  author       = {Wenqi Cai and Arash Bahari Kordabad and Sébastien Gros},
  doi          = {10.1016/j.engappai.2022.105793},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105793},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy management in residential microgrid using model predictive control-based reinforcement learning and shapley value},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous dispatch trajectory planning on flight deck: A
search-resampling-optimization framework. <em>EAAI</em>, <em>119</em>,
105792. (<a
href="https://doi.org/10.1016/j.engappai.2022.105792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing expectation to realize the autonomous dispatch on flight deck, where dispatch trajectory planning is seen as the key technique. Optimal-control based method has shown great advantages in high degree of constraint satisfaction over its counterparts in the last decade. However, it suffers from low computational efficiency even numerical divergence under scenarios with complicated obstacles. To deal with such an issue, a search-resampling-optimization (SRO) framework is proposed in this paper. A hybrid A* algorithm is employed to generate a coarse path according to the boundary conditions in the search stage. Then a resampling process is implemented to pave a series of safe dispatch corridors (SDCs) along the coarse path. Finally, by replacing the common one-to-one collision-avoidance with the constructed within-SDC constraints, an optimal control problem whose scale is totally independent of the number of obstacles can be formulated. The resampled result is further fed into the optimization stage to facilitate the numerical solution. Dispatch trajectory planning for taxiing aircraft and tractor can be treated uniformly under this framework. And numerical simulations demonstrate that the SRO framework is efficient and robust even with narrow accessible tunnels. The SRO is inherently flexible and can be easily extended to the trajectory planning problem in other fields. A video of the main idea and numerical simulations in this paper is available at www.bilibili.com/video/BV1tP4y1d7xy/ .},
  archive      = {J_EAAI},
  author       = {Xinwei Wang and Bai Li and Xichao Su and Haijun Peng and Lei Wang and Chen Lu and Chao Wang},
  doi          = {10.1016/j.engappai.2022.105792},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105792},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Autonomous dispatch trajectory planning on flight deck: A search-resampling-optimization framework},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-guided bayesian neural networks by ABC-SS:
Application to reinforced concrete columns. <em>EAAI</em>, <em>119</em>,
105790. (<a
href="https://doi.org/10.1016/j.engappai.2022.105790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript proposes a physics-guided Bayesian neural network, which combines Approximate-Bayesian-Computation training with physics-based models. This hybrid algorithm uses the laws of physics to mitigate the lack of data, and the flexibility of neural networks to model the complexities inherent in nature. The state-of-the-art approaches often introduce the physics in the loss function, or through some known boundary conditions, and then use backpropagation to adjust the weights. However, this training method involves some rigidity and drawbacks, mostly related to the adoption of a predefined loss/likelihood function and the evaluation of its gradient during training. The use of approximate Bayesian computation as the learning engine results in a greater prediction accuracy and flexibility to quantify the uncertainty, due to the gradient-free nature of the algorithm, the absence of loss/likelihood function and the non-parametric formulation of the weights. Furthermore, the physics-based model is introduced in the forward pass of the neural network, which significantly increases the extrapolation capabilities of the proposed hybrid model. The proposed algorithm has been applied to lateral-load tests in reinforced concrete columns, providing promising results when making predictions about future loading cycles, surpassing the purely data-driven and physics-based methods as well as the state-of-the-art physics-guided neural networks. In light of the performance shown during the experiments, the proposed algorithm has the potential to become a useful tool for fast evaluation of critical buildings after seismic events.},
  archive      = {J_EAAI},
  author       = {Juan Fernández and Juan Chiachío and Manuel Chiachío and José Barros and Matteo Corbetta},
  doi          = {10.1016/j.engappai.2022.105790},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105790},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-guided bayesian neural networks by ABC-SS: Application to reinforced concrete columns},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Inference and analysis of a new evidential reasoning
rule-based performance evaluation model. <em>EAAI</em>, <em>119</em>,
105789. (<a
href="https://doi.org/10.1016/j.engappai.2022.105789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current studies on the evidential reasoning (ER) rule, a performance evaluation model that utilizes the ER rule to combine evidence constituted by a single observation indicator (Single indicator-based ER rule, SER) has been developed with excellent scalability. However, the belief distribution (BD) of SER-based evaluation model is composed of a set of single grades that describe the system performance and the corresponding belief degrees. This makes some common uncertain judgments with local ignorance unable to be considered in the inference process, resulting in a decrease in the accuracy and validity of the evaluation results. In this paper, a new SER-based performance evaluation model with extended BD is proposed. Firstly, on the basis of the existing BD in SER, some new elements capable of describing local ignorance are introduced. Secondly, by calculating and optimizing the relevant parameters, the new evaluation model is formed. Thirdly, according to the Stone–Weierstrass theorem and information entropy theory, the approximation ability and uncertainty of the evaluation model are discussed respectively. Finally, a practical example is given to illustrate the potential applications of the proposed model in engineering practice.},
  archive      = {J_EAAI},
  author       = {Jie Wang and Zhi-Jie Zhou and Peng-Yun Ning and Shuai-Tong Liu and Xiang-Yi Zhou and Yu Zhao},
  doi          = {10.1016/j.engappai.2022.105789},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105789},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inference and analysis of a new evidential reasoning rule-based performance evaluation model},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilizing optical neural network to establish
high-performance OR and XOR logic gates. <em>EAAI</em>, <em>119</em>,
105788. (<a
href="https://doi.org/10.1016/j.engappai.2022.105788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optical–neural-network logic gates using unsupervised learning method and supervised learning method are investigated. The structures of the optical neurons using self-connection configuration and interconnection configuration are proposed. The performance of the AND, OR, NAND, NOR and XOR logic gates are analyzed. According to our simulation results, the bit error ratio (BER) of the optical neurons using the interconnection configuration is lower than that using self-connection configuration. For OR logic gate, the best performance is BER = 6.54%. For XOR logic gate, the best performance is BER &lt; 4.89 × 10 −5 . The results show that the proposed optical structure can work for different logic gates by tuning the parameters of the couplers and the phase shifters.},
  archive      = {J_EAAI},
  author       = {Chu-En Lin and Ching-Pao Sun and Chii-Chang Chen},
  doi          = {10.1016/j.engappai.2022.105788},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105788},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Utilizing optical neural network to establish high-performance OR and XOR logic gates},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent quantum-inspired deep reinforcement learning for
real-time distributed generation control of 100. <em>EAAI</em>,
<em>119</em>, 105787. (<a
href="https://doi.org/10.1016/j.engappai.2022.105787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With promoting peaking carbon emissions and achieving carbon neutrality, the real-time distributed control of the prosumers of 100% renewable energy systems (RESs) is challenging. This paper proposes multi-agent quantum-inspired deep reinforcement learning (QDRL) approaches for real-time distributed generation control of 100% RESs. Quantum-inspired operation is introduced into deep reinforcement learning (DRL) as quantum-inspired Q-learning, quantum-inspired state–action–reward-state–action, quantum-inspired deep Q-network, quantum-inspired policy gradient, quantum-inspired deep deterministic policy gradient, quantum-inspired twin-delayed deep deterministic policy gradient, quantum-inspired actor–critic,​ quantum-inspired proximal policy optimization, and quantum-inspired soft actor–critic.​ These proposed nine QDRL approaches are compared with DRL approaches under two 100% RESs. The numeric results show that the QDRL obtains more minor carbon emissions and frequency deviations under complex 100% RESs. Moreover, the quantum states of QDRL match the uncertain states of the prosumers of 100% RESs. Besides, the exploration and exploitation of the QDRL for the real-time control problems of multi-agent systems are verified and analyzed.},
  archive      = {J_EAAI},
  author       = {Dan Liu and Yingzi Wu and Yiqun Kang and Linfei Yin and Xiaotong Ji and Xinghui Cao and Chuangzhi Li},
  doi          = {10.1016/j.engappai.2022.105787},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105787},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-agent quantum-inspired deep reinforcement learning for real-time distributed generation control of 100% renewable energy systems},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From time-series to 2D images for building occupancy
prediction using deep transfer learning. <em>EAAI</em>, <em>119</em>,
105786. (<a
href="https://doi.org/10.1016/j.engappai.2022.105786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building occupancy information could aid energy preservation while simultaneously maintaining the end-user comfort level. Energy conservation becomes essential since energy resources are scarce and human dependency on appliances is only exponentially increasing. While intrusive sensors (i.e., cameras and microphones) can raise privacy concerns, this paper presents an innovative non-intrusive occupancy detection approach using environmental sensor data (e.g., temperature, humidity, carbon dioxide (CO 2 ), and light sensors). The proposed scheme transforms multivariate time-series data into images for better encoding and extracting relevant features. The utilized image transformation method is based on data normalization and matrix conversion. Precisely, by representing time-series in 2D space, an encoding kernel can move in two directions while it can move only in one direction when applied to a 1D signal. Moreover, machine learning (ML) and deep learning (DL) techniques are utilized to classify occupancy patterns. Several simulations are used to evaluate the approach; mainly, we investigated pre-trained and custom convolutional neural network (CNN) models. The latter attained an accuracy of 99.00%. Additionally, pixel data are extracted from the generated images and subjected to traditional ML methods. Throughout the numerous comparison settings, it was observed that the latter strategy provided the optimal balance of 99.42% accuracy performance and minimal training time across the occupancy datasets.},
  archive      = {J_EAAI},
  author       = {Aya Nabil Sayed and Yassine Himeur and Faycal Bensaali},
  doi          = {10.1016/j.engappai.2022.105786},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105786},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From time-series to 2D images for building occupancy prediction using deep transfer learning},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A machine learning driven multiple criteria decision
analysis using LS-SVM feature elimination: Sustainability performance
assessment with incomplete data. <em>EAAI</em>, <em>119</em>, 105785.
(<a href="https://doi.org/10.1016/j.engappai.2022.105785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The move towards an era of big data structured problems has led to the development of state-of-the-art solutions, mainly in decision sciences. Large Scale Decision-Making (LSDM) and Data-Driven Decision-Making (DDDM) approaches have emerged from a rapidly evolving research field. A common challenge in LSDM problems formed from various heterogeneous databases is incomplete data. Multiple criteria decision analysis approaches have been utilized as the primary element of LSDM techniques to solve similar complex problems, and these methods cannot function under incomplete data. Large number of dimensions in LSDM problems are usually problematic, which has previously been addressed by machine learning driven methods. Moreover, while in traditional multiple criteria decision analysis methods, the criteria are based on beneficial and non-beneficial attributes, in LSDM problems, decision-makers define specific objectives for attributes adjusting the problem with their specific preferences. This study proposed a machine learning-driven DDDM method for solving LSDM problems with incomplete data and a substantial number of decision attributes. Incomplete data imputation was conducted using the Expectation–Maximization (EM) algorithm, and Recursive Feature Elimination (RFE) with Least Square Support Vector (LS-SVM) was used to extract the core criteria. Target-based COmbined COmpromise Solution (T-CoCoSo) and Target-based Multi-Attributive Border Approximation Area Comparison (T-MABAC) methods combined with Shannon’s Entropy weighting method were used for the performance assessment stage. Ultimately, to validate the reliability of the proposed method, sustainability performance of all countries worldwide under Sustainable Development Goals (SDGs) with incomplete data was evaluated. The outcomes show that the proposed machine learning-driven data-driven decision-making method is a reliable tool for such LSDM problems.},
  archive      = {J_EAAI},
  author       = {Abtin Ijadi Maghsoodi and Ali Ebadi Torkayesh and Lincoln C. Wood and Enrique Herrera-Viedma and Kannan Govindan},
  doi          = {10.1016/j.engappai.2022.105785},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105785},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A machine learning driven multiple criteria decision analysis using LS-SVM feature elimination: Sustainability performance assessment with incomplete data},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI in apiculture: A novel framework for recognition of
invasive insects under unconstrained flying conditions for smart
beehives. <em>EAAI</em>, <em>119</em>, 105784. (<a
href="https://doi.org/10.1016/j.engappai.2022.105784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncompromised population growth of invasive insects endangers biodiversity, agribusinesses, and ecosystems. One such example is the invasion of Vespa hornets in honey harvesting areas which leads to a devastating impact on honeybee ecology and subsequently on the economic activities linked with it. To mitigate the imposed threat, a vision-based system capable to recognize Vespa hornets near beehives can serve the purpose. But the arbitrary position and pose of these small-scale fast-moving insects with respect to the camera viewpoint in natural daylight make it challenging to realize the task. Keeping in view the situational intricacies, a novel AI-based framework is proposed to recognize Vespa hornets near beehives under unconstrained flying conditions using a multi-modal data and multi-evidence approach. Multiple modalities include 3-D trajectories and IR imagery while multiplicity in evidence evolves through the retrieval of IR images from multiple spatial locations furnished by the insects’ trajectories. The proposed framework exploits the information provided by a limited piece of evidence selected at random from multi-modal and multi-evidence observation sets through pre-evaluated deep learning/machine learning models. Individual inferences from selected recognition models are then fused using a weighted summation scheme to make the final decision. The recognition framework demonstrated a classification accuracy of 97.1% for two hornet types of the genus Vespa along with the honeybee Apis mellifera . The proposed strategy indicating promising results is a pioneering work of applying AI in the domain of entomology and apiculture to have the detection capability for invasive insects in the vicinity of beehives to make them safer and smarter.},
  archive      = {J_EAAI},
  author       = {Abdul Nasir and Muhammad Obaid Ullah and Muhammad Haroon Yousaf},
  doi          = {10.1016/j.engappai.2022.105784},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105784},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AI in apiculture: A novel framework for recognition of invasive insects under unconstrained flying conditions for smart beehives},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). A novel dynamic opposite learning enhanced jaya
optimization method for high efficiency plate–fin heat exchanger design
optimization. <em>EAAI</em>, <em>119</em>, 105778. (<a
href="https://doi.org/10.1016/j.engappai.2022.105778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Plate–fin heat exchanger (PFHE) is a compact and efficient thermal device, whose performance strongly depends on its structural design. However, the design optimization of a PFHE is a mixed-integer optimization problem with a strong nonlinear characteristic, which presents significant challenges for existing optimization algorithms. Meta-heuristic algorithms (MAs) are competitive for solving complex non-linear optimization problems. In this paper, an improved dynamic-opposite learning Jaya (DOLJaya) method, the goal is to make the algorithm adaptable to each problem. The results of eighteen unimodal and multi-modal benchmarks and nine hybrid benchmarks demonstrate that the proposed DOLJaya has competitive robustness, efficiency and effectiveness for solving complex nonlinear problems compared to its popular counterparts. At the same time, we selected the optimization of the plate–fin heat exchanger as the industrial test benchmark for optimization, and the results of DOLJaya algorithm have been improved by a maximum average of 108.29% and 7.60% compared with the original Jaya, which are also satisfactory.},
  archive      = {J_EAAI},
  author       = {Lidong Zhang and Tianyu Hu and Linxin Zhang and Zhile Yang and Seán McLoone and Muhammad Ilyas Menhas and Yuanjun Guo},
  doi          = {10.1016/j.engappai.2022.105778},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105778},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel dynamic opposite learning enhanced jaya optimization method for high efficiency plate–fin heat exchanger design optimization},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linguistic pythagorean fuzzy CRITIC-EDAS method for
multiple-attribute group decision analysis. <em>EAAI</em>, <em>119</em>,
105777. (<a
href="https://doi.org/10.1016/j.engappai.2022.105777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrialization plays a significant role in the development and growth of a country. Pakistan is one of the developing countries which entirely depends upon their industrial steel sector to meet their economic growth. Pakistan Steel Mills Corporation (PSMC) is a Pakistan’s largest steel industry producing tonnes of steel every year but this production of steel has resulted in a rapid increase in industrial solid waste. Several techniques are available for industrial waste management, ranging from traditional methods to advanced technologies. But the selection of most suitable alternative is a complex task owing to numerous strategies available and multiple attributes involved in selection. To resolve this issue, we introduced a dynamic model for selecting best industrial waste management technique utilizing the linguistic Pythagorean fuzzy sets (LPFSs). The concept of LPFSs has proven to be a productive and advantageous approach in the development of decision problems to manage inconsistency in the escalating sophistication of expert systems. The main goal of this study is to introduce a general MAGDM model by integrating CRiteria Importance Through Intercriteria Correlation (CRITIC) method and Evaluation based on Distance from Average Solution (EDAS) method. Firstly, some Hamacher relations and operations are adapted to linguistic Pythagorean fuzzy environment which initiated a variety of Hamacher operators in the context of LPFSs. Meanwhile some fundamental properties of proposed operators are investigated. Secondly, a novel LPFH-CRITIC-EDAS technique is introduced. In the developed framework, the LPF-CRITIC method is used to calculate the criteria weights and the LPF-EDAS technique is utilized to evaluate the rank of alternatives. Furthermore, the flowchart of the proposed model is presented in a systematic way. Moreover, an example of the industrial waste management technique selection for PSMC is addressed to illustrate the feasibility of the proposed technique. Finally, the new framework is compared with existing techniques to demonstrate its strength. The comparative study reveals that the results of the proposed method are more feasible and practical than the existing techniques.},
  archive      = {J_EAAI},
  author       = {Muhammad Akram and Naila Ramzan and Muhammet Deveci},
  doi          = {10.1016/j.engappai.2022.105777},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105777},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Linguistic pythagorean fuzzy CRITIC-EDAS method for multiple-attribute group decision analysis},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combined framework based on data preprocessing and
multi-objective optimizer for electricity load forecasting.
<em>EAAI</em>, <em>119</em>, 105776. (<a
href="https://doi.org/10.1016/j.engappai.2022.105776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, accurate electricity load forecasting has become increasingly essential for improving the management efficiency of power-generation systems. However, previously proposed hybrid models directly apply signal-processing technology in data preprocessing, resulting in poor efficiency in matching the electricity sequence characteristics. Moreover, most studies exhibit non-optimal performance in practical applications because they focus on forecasting accuracy and ignore forecasting stability. In this study, a combined framework that includes amodified noise processing strategy, multi-objective optimization algorithm, and deep neural network is proposed to solve the low prediction-accuracy problem in electricity load forecasting. The 30-minute real time data of electricity load from Queensland, Australia, are employed to verify the reliability of the proposed framework. The mean absolute percentage error values of the proposed framework in a multi-step prediction approached the values of MAPE 1−step = 0 . 79 % , MAPE 2−step = 1 . 13 % , and MAPE 3−step = 1 . 50 % in Series 1, which significantly outperformed the existing contrast models.},
  archive      = {J_EAAI},
  author       = {Yurui Xia and Jianzhou Wang and Danxiang Wei and Ziyuan Zhang},
  doi          = {10.1016/j.engappai.2022.105776},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105776},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combined framework based on data preprocessing and multi-objective optimizer for electricity load forecasting},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An innovative deep anomaly detection of building energy
consumption using energy time-series images. <em>EAAI</em>,
<em>119</em>, 105775. (<a
href="https://doi.org/10.1016/j.engappai.2022.105775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep anomaly detection (DAD) is essential in optimizing building energy management. Nonetheless, most existing works concerning this field consider unsupervised learning and involve the analysis of sensor readings through a one-dimensional (1D) energy time series, which limits the options for detecting anomalies within the building’s energy consumption. To the best of the authors’ knowledge, this paper presents the first study that explores using two-dimensional (2D) image representations as features of a supervised deep transfer learning (DTL) approach. Specifically, using 2D image representations allows taking advantage of any underlying data within the feature set, providing more possibilities to encode data and detect pertinent features which may not be considered in standard 1D time-series. Furthermore, the effects of using CNN activations as machine learning (ML) model features are also investigated to combine the advantages of both techniques. Additionally, the concept of layer and hyperparameter variation for the CNN model is also studied, with the objective of reducing the overall time computation and resource requirements of the proposed system. Hence, this makes our approach a candidate for edge-based applications. As per the conducted experiments, the top methodology rests at the F1-scores of 93.63% and 99.89% under simulated and real-world energy datasets, respectively. This involves using grayscale 2D image representations that combine CNN activations extracted from AlexNet and GoogleNet pre-trained models as features to a linear support vector machine (SVM) classifier. Finally, the comparison analysis with the state-of-the-art has shown the superiority of the proposed method in various assessment criteria.},
  archive      = {J_EAAI},
  author       = {Abigail Copiaco and Yassine Himeur and Abbes Amira and Wathiq Mansoor and Fodil Fadli and Shadi Atalla and Shahab Saquib Sohail},
  doi          = {10.1016/j.engappai.2022.105775},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105775},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An innovative deep anomaly detection of building energy consumption using energy time-series images},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive cross-domain knowledge distillation for
efficient unsupervised domain adaptive object detection. <em>EAAI</em>,
<em>119</em>, 105774. (<a
href="https://doi.org/10.1016/j.engappai.2022.105774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) is a technique for relieving domain shifts via transferring relevant domain knowledge from the full-labeled source domain to an unlabeled target domain. While tremendous advances have been witnessed recently, the adoption of deep CNN-based UDA methods in real-world scenarios is still constrained by low-resource computers. Most prior strategies either handle domain shift problems via UDA or compress CNNs using knowledge distillation (KD), we seek to implement the model on constrained-resource devices to learn domain adaptive knowledge without sacrificing accuracy. In this paper, we proposed a three-step Progressive Cross-domain Knowledge Distillation (PCdKD) paradigm for efficient unsupervised adaptive object detection, since directly alleviating the significant discrepancy across domains could result in unstable training procedures and suboptimal performance. First, we apply pixel-level alignment via image-to-image translation to reduce the appearance discrepancy between different domains. Then, a focal multi-domain discriminator is utilized to train the teacher–student peer networks for gradually distilling domain adaptive knowledge in a cooperative manner. Finally, reliable pseudo labels obtained by the adapted teacher detector are further utilized to retrain the teacher–student models. Our proposed method can boost the transferability of the teacher model as well as enhance the student model to meet the demand of real-time applications. Comprehensive experiments on four different cross-domain datasets show that our PCdKD outperforms most existing state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Wei Li and Lingqiao Li and Huihua Yang},
  doi          = {10.1016/j.engappai.2022.105774},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105774},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive cross-domain knowledge distillation for efficient unsupervised domain adaptive object detection},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Urban natural gas consumption forecasting by novel
wavelet-kernelized grey system model. <em>EAAI</em>, <em>119</em>,
105773. (<a
href="https://doi.org/10.1016/j.engappai.2022.105773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gas is playing a key role in the Carbon Neutral path, which is clean and abundant. However it is difficult to collect sufficient data of urban natural gas consumption in China, and such data sets often present high nonlinearity and complex features, making it difficult to make accurate forecasts for the mid-small cities based on small samples. In this work, a novel wavelet kernel-based grey system model is proposed by using the wavelet kernel-based machine learning and the grey system modelling, taking advantage of the features of nonlinearity and periodicity of the wavelet kernel. A complete computational algorithm is presented by utilizing a hold-out cross validation-based grid-search scheme for selecting the optimal hyperparameters. Three case studies are carried out based on the real-world data sets of urban natural gas consumption in Kunming China, in which the proposed model outperforms other 15 time series forecasting models (including kernel-based models, grey system models and deep learning models), illustrating its priority in such forecasting tasks and high potential in similar applications.},
  archive      = {J_EAAI},
  author       = {Xin Ma and Hongfang Lu and Minda Ma and Lifeng Wu and Yubin Cai},
  doi          = {10.1016/j.engappai.2022.105773},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105773},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Urban natural gas consumption forecasting by novel wavelet-kernelized grey system model},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). StrokeViT with AutoML for brain stroke classification.
<em>EAAI</em>, <em>119</em>, 105772. (<a
href="https://doi.org/10.1016/j.engappai.2022.105772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke, categorized under cardiovascular and circulatory diseases, is considered the second foremost cause of death worldwide, causing approximately 11% of deaths annually. Stroke diagnosis using a Computed Tomography (CT) scan is considered ideal for identifying whether the stroke is hemorrhagic or ischemic. However, most methods for stroke classification are based on a single slice-level prediction mechanism, meaning that the most imperative CT slice has to be manually selected by the radiologist from the original CT volume. This paper proposes an integration of Convolutional Neural Network (CNN), Vision Transformers (ViT), and AutoML to obtain slice-level predictions as well as patient-wise prediction results. While the CNN with inductive bias captures local features, the transformer captures long-range dependencies between sequences. This collaborative local-global feature extractor improves upon the slice-wise predictions of the CT volume. We propose stroke-specific feature extraction from each slice-wise prediction to obtain the patient-wise prediction using AutoML. While the slice-wise predictions helps the radiologist to verify close and corner cases, the patient-wise predictions makes the outcome clinically relevant and closer to real-world scenario. The proposed architecture has achieved an accuracy of 87% for single slice-level prediction and an accuracy of 92% for patient-wise prediction. For comparative analysis of slice-level predictions, standalone architectures of VGG-16, VGG-19, ResNet50, and ViT were considered. The proposed architecture has outperformed the standalone architectures by 9% in terms of accuracy. For patient-wise predictions, AutoML considers 13 different ML algorithms, of which 3 achieve an accuracy of more than 90%. The proposed architecture helps in reducing the manual effort by the radiologist to manually select the most imperative CT from the original CT volume and shows improvement over other standalone architectures for classification tasks. The proposed architecture can be generalized for volumetric scans aiding in the patient diagnosis of head and neck, lungs, diseases of hepatobiliary tract, genitourinary diseases, women’s imaging including breast cancer and various musculoskeletal diseases. Code for proposed stroke-specific feature extraction with the pre-trained weights of the trained model is available at: https://github.com/rishiraj-cs/StrokeViT_With_AutoML .},
  archive      = {J_EAAI},
  author       = {Rishi Raj and Jimson Mathew and Santhosh Kumar Kannath and Jeny Rajan},
  doi          = {10.1016/j.engappai.2022.105772},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105772},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {StrokeViT with AutoML for brain stroke classification},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Corrigendum to “self-supervised monocular depth estimation
based on combining convolution and multilayer perceptron” [eng. Appl.
Artif. Intell. 117 (2023) 105587]. <em>EAAI</em>, <em>119</em>, 105771.
(<a href="https://doi.org/10.1016/j.engappai.2022.105771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Qiumei Zheng and Tao Yu and Fenghua Wang},
  doi          = {10.1016/j.engappai.2022.105771},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105771},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Self-supervised monocular depth estimation based on combining convolution and multilayer perceptron” [Eng. appl. artif. intell. 117 (2023) 105587]},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Swin-JDE: Joint detection and embedding multi-object
tracking in crowded scenes based on swin-transformer. <em>EAAI</em>,
<em>119</em>, 105770. (<a
href="https://doi.org/10.1016/j.engappai.2022.105770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) is a highly valued and challenging research topic in computer vision. To achieve more robust tracking performance, recently published MOT methods tend to use anchor-free object detectors, which have the advantage of dealing with the identity ambiguity problem encountered by anchor-based methods in learning appearance features. However, in practical applications, it is found that the detection accuracy of the anchor-free object detector based on classical convolutional neural networks in crowded scenes will be significantly reduced. In order to have better detection and tracking performance in crowded scenes, this paper proposes an anchor-free joint detection and embedding (JDE) MOT method based on Transformer architecture, called Swin-JDE. The proposed method includes a novel Patch-Expanding module, which can improve the spatial information of feature maps by up-sampling processing through neural network learning and Einops Notation-based rearrangement to enhance the detection and tracking performance of the MOT model. In terms of training method, we propose a two-step training method that trains the detection branch separately from the appearance branch to enhance the detection robustness of anchor-free predictors. Furthermore, during the training process, we also propose an examination method to remove occluded targets from the training dataset to improve the accuracy of the appearance embedding layer. In terms of data association, we propose a new post-processing method, which simultaneously considers the three factors of detection confidence, appearance embedding distance, intersection-over-union (IoU) distance to match each tracklet and the detection information to improve the tracking robustness of the MOT model. Experimental results show that the proposed method achieves 70.38% multiple object tracking accuracy (MOTA) and 69.53% identification F1-score (IDF1) results in the MOT20 benchmark dataset, and the identification switch (ID Switch) is reduced to 2026. Compared with FairMOT, the proposed method improves MOTA and IDF1 by 8.58% and 2.23%, respectively.},
  archive      = {J_EAAI},
  author       = {Chi-Yi Tsai and Guan-Yu Shen and Humaira Nisar},
  doi          = {10.1016/j.engappai.2022.105770},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105770},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Swin-JDE: Joint detection and embedding multi-object tracking in crowded scenes based on swin-transformer},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic congestion-aware graph-based vehicle rerouting
framework from aerial imagery. <em>EAAI</em>, <em>119</em>, 105769. (<a
href="https://doi.org/10.1016/j.engappai.2022.105769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In digital era, being stranded from very basic telecommunication protocols and internet makes vehicle rerouting-like crucial tools more difficult or even impossible, especially in times of disaster and emergency. In this study, we propose a modular rerouting framework for only one single vehicle composed of visual perception, property estimation and trajectory optimization, which enables to generate optimum paths exploiting aerial imagery. Once the deep network, which is fine-tuned on newly introduced dataset herein named MaVefAI, processes the input, the following module estimates pose, motion direction and speed of detected vehicles. Afterwards, we link the appropriate vehicles via graphs to obtain group properties that pave the way for estimating the traffic congestion level. In the end, we get the output as the optimum path from the independent trajectory optimization module to which required inputs are already sent by preceding modules. We solve the multi-objective cost function subject to velocity and congestion intervals, which comprises distance, traffic congestion level, and angle inconsistency. We employ Dijkstra, A*, RRT, and RRT* to optimize the cost while vast majority of existing works focus to optimize via single method. The fine-tuned segmentation model accuracy becomes more than 98% for vehicle groups thanks to MaVefAI. The extensive experiments reveal that all algorithms follow the same path. However, RRT* achieves the fastest result by examining most of the possible options in less time, which also appears to be the most robust method comparing with the alternatives for route optimization. Our dataset MaVefAI is publicly available here: https://precisioncomputing.sakarya.edu.tr .},
  archive      = {J_EAAI},
  author       = {Ertugrul Bayraktar and Burla Nur Korkmaz and Aras Umut Erarslan and Numan Celebi},
  doi          = {10.1016/j.engappai.2022.105769},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105769},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Traffic congestion-aware graph-based vehicle rerouting framework from aerial imagery},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy constraint prioritization to solve heavily constrained
problems with the genetic algorithm. <em>EAAI</em>, <em>119</em>,
105768. (<a
href="https://doi.org/10.1016/j.engappai.2022.105768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic algorithms (GAs) are approximate solving methods that have been originally proposed to achieve unconstrained optimization. To handle constrained problems, which is the case for the majority of real-life circumstances, GAs must be equipped with a constraint-handling mechanism. Transformation functions (TFs) are among the constraint-handling approaches that intervene in the phenotypic space. In this paper, we study the impact of considering constraint priorities on the GA performance when it deals with heavily constrained problems. Priorities are set by integrating a constraint order into the TF definition. We consider different TF forms enhanced with a fuzzy inference engine to find the best constraint ordering. Finally, we conduct an experimental study to assess the performance of the proposed approach on the semi-supervised graph partitioning problem. The obtained results show with statistical evidence that the proposed fuzzy method is promising.},
  archive      = {J_EAAI},
  author       = {Basma Alouane and Menouar Boulif},
  doi          = {10.1016/j.engappai.2022.105768},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105768},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy constraint prioritization to solve heavily constrained problems with the genetic algorithm},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An intelligent intrusion detection and performance
reliability evaluation mechanism in mobile ad-hoc networks.
<em>EAAI</em>, <em>119</em>, 105760. (<a
href="https://doi.org/10.1016/j.engappai.2022.105760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Mobile Ad-Hoc Network (MANET) is a widely used temporary network. It is simple to install and handle. However, its dynamic nature is more vulnerable to routing attacks than fixed networks. Many intrusion detection methods are available to tackle its vulnerability and attacks. These works used different statistical parameters and measured various performances to validate their methods. Existing works have different claims or validations. However, these works show ambiguities in performance comparison. There are many reasons for performance ambiguities, such as imbalanced distribution of samples, number of training samples, number of labels, etc., whereas these are executed on the same dataset. This paper presents deployment of the network, data generation, sample labeling, feature extraction, an intrusion detection method, and a performance reliability evaluation model. The evaluation model analyzes the performance and hardware dependability of intrusion detection methods, and it computes the performance reliability of related methods using a fuzzy logic system. The outcome shows that when one statistical performance increases, another performance decreases due to an imbalanced sample ratio. Therefore, the proposed evaluation model has analyzed the two best performances. It evaluates intrusion detection mechanisms and provides a comparative analysis with an approximate performance as scheme reliability. The experimental results show that the performance of the proposed detection method is better than existing methods in terms of maintaining high scheme reliability.},
  archive      = {J_EAAI},
  author       = {Mahendra Prasad and Sachin Tripathi and Keshav Dahal},
  doi          = {10.1016/j.engappai.2022.105760},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105760},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An intelligent intrusion detection and performance reliability evaluation mechanism in mobile ad-hoc networks},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dumodds: Dual modeling approach for drowsiness detection
based on spatial and spatio-temporal features. <em>EAAI</em>,
<em>119</em>, 105759. (<a
href="https://doi.org/10.1016/j.engappai.2022.105759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road accidents have been a significant problem in recent years. As per statistics, this is primarily due to the driver’s drowsy behavior. As an impact, many valuable lives have been lost in road accidents. So, a reliable system is required to overcome this issue. As part of this meticulous analysis, we have chosen a sizable realistic drowsiness video dataset created by the University of Texas. After that, we picked just the extreme classes of videos, such as alert and drowsy, from this dataset. Then, we created two distinct models, namely Model-A for temporal features and Model-B for spatiotemporal characteristics. In the first model, computer vision techniques, i.e., YOLOv3, are used to retrieve temporal characteristics, then processed using long short-term memory (LSTM). Here, we suited the occlusion issue by imposing a condition on each frame. The overfitting problem arises when occluded frames are discarded during this procedure. This issue is handled with the help of TransGAN’s augmentation approach. The second model, on the other hand, extracts spatial information using a convolution neural network (CNN) called InceptionV3, which is subsequently processed using LSTM. Even though Model-A is more complicated and has lower accuracy, i.e., 86%, than Model-B, with an accuracy of 97.5%, the investigation reveals that Model-A seems much superior to Model-B regarding the training period. These differences are emphasized through the AUC-ROC score and confusion metrics.},
  archive      = {J_EAAI},
  author       = {Nageshwar Nath Pandey and Naresh Babu Muppalaneni},
  doi          = {10.1016/j.engappai.2022.105759},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105759},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dumodds: Dual modeling approach for drowsiness detection based on spatial and spatio-temporal features},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter uncertainty modeling for multiobjective robust
control design. Application to a temperature control system in a proton
exchange membrane fuel cell. <em>EAAI</em>, <em>119</em>, 105758. (<a
href="https://doi.org/10.1016/j.engappai.2022.105758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced control systems are tuned using dynamic models and optimization techniques. This approach frequently involves satisfying multiple conflicting objectives. Tuning robust controllers requires considering a framework that represents the system uncertainties, and its definition is not a trivial task. When dealing with a nonlinear model with many parameters, a high-quality representation requires a massive sampling of variations. In many cases, this represents an inaccessible computational cost for the optimization process. This work presents a new methodology for parameter uncertainty modeling that is oriented to tuning robust controllers based on multiobjective optimization techniques. The uncertainty modeling formulated represents a feasible computational cost and leads to robust solutions without attributing excessive conservatism. The novelty of this process consists in using the multiobjective space to define a set of scenarios with highly representative properties of the global uncertainty framework that formulate the control problem under a predefined minimization strategy. To demonstrate the effectiveness of this methodology, we present a temperature control design in a micro-CHP system under worst-case minimization. Based on the results, particular interest is given to verifying the appropriate formulation of the uncertainty modeling, which represents a 92.8% reduction of the computational cost involved in solving the robust optimization problem under a global uncertainty framework.},
  archive      = {J_EAAI},
  author       = {U. Veyna and X. Blasco and J.M. Herrero and A. Pajares},
  doi          = {10.1016/j.engappai.2022.105758},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105758},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parameter uncertainty modeling for multiobjective robust control design. application to a temperature control system in a proton exchange membrane fuel cell},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new multi-objective evolutionary algorithm for
citation-based summarization: Comprehensive analysis of the generated
summaries. <em>EAAI</em>, <em>119</em>, 105757. (<a
href="https://doi.org/10.1016/j.engappai.2022.105757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of scientific publications in different knowledge fields has considerably grown in recent times. This makes difficult for researchers to synthesize all the scientific-technical advances, so automatic summarization methods of scientific papers would be helpful. These methods generate a summary from a reference paper with its most relevant contributions. More specifically, citation-based summarization considers the citation contexts to the reference paper in subsequent publications. For the first time, this problem has been formulated as a multi-objective optimization problem, optimizing the content coverage and the redundancy reduction in a simultaneous way. A Decomposition-based Multi-Objective optimization algorithm for Citation-based Summarization (DMOCS) has been designed, developed, and applied for solving this problem. The results obtained by the proposed approach have improved the existing ones in the scientific literature between 17.47% and 133.50%, increasing the ROUGE percentage improvements when the N -gram is larger. Besides, an exhaustive analysis of the different parts of a scientific paper has been performed, showing that the citations from the citing papers with their corresponding spans in the reference paper impact in the quality of a citation-based summary.},
  archive      = {J_EAAI},
  author       = {Jesus M. Sanchez-Gomez and Miguel A. Vega-Rodríguez and Carlos J. Pérez},
  doi          = {10.1016/j.engappai.2022.105757},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105757},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new multi-objective evolutionary algorithm for citation-based summarization: Comprehensive analysis of the generated summaries},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective train speed profile determination for
automatic train operation with conscious search: A new optimization
algorithm, a comprehensive study. <em>EAAI</em>, <em>119</em>, 105756.
(<a href="https://doi.org/10.1016/j.engappai.2022.105756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Train speed profile is one of the most fundamental optimization issues in rail transportation. The speed profile has several indices, such as travel time and energy consumption. These indices mostly have opposite natures, which leads to a non-linear, complex multi-objective optimization problem. This paper introduces a new heuristic algorithm called Conscious Search (CS) to determine the optimal speed profile. For this purpose, after modeling the train dynamics, we initially analyze the validated heuristic optimization algorithms, including Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), Bees Algorithm (BA), and Teaching–learning Based Optimization (TLBO) statistically using sensitivity analysis. Then, using new criteria called the Impact Factor, we show that a trade-off prevails in the global and local search for algorithms. In general, the stronger the algorithm in one domain, the weaker in the other. Subsequently, no algorithm is superior to another. In this regard, CS is proposed as a hybrid algorithm that performs the optimization in two separate global and local phases to address this problem and achieve the ideal optimization. CS steps are designed to dominate other algorithms in both local and global phases. In the evaluation, we obtained the train speed profile using the proposed method and the proven latest versions of the mentioned algorithms. Based on the simulation results, CS outperforms the considered algorithms by a palpable margin, and its solutions dominate others. These results indicate on effectiveness and excellence of the proposed method.},
  archive      = {J_EAAI},
  author       = {Pedram Havaei and Mohammad Ali Sandidzadeh},
  doi          = {10.1016/j.engappai.2022.105756},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105756},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective train speed profile determination for automatic train operation with conscious search: A new optimization algorithm, a comprehensive study},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AdaDerivative optimizer: Adapting step-sizes by the
derivative term in past gradient information. <em>EAAI</em>,
<em>119</em>, 105755. (<a
href="https://doi.org/10.1016/j.engappai.2022.105755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AdaBelief fully utilizes “belief” to iteratively update the parameters of deep neural networks. However, the reliability of the “belief” is determined by the gradient’s prediction accuracy, and the key to this prediction accuracy is the selection of the smoothing parameter β 1 . AdaBelief also suffers from the overshoot problem, which occurs when the value of parameters exceeds the value of the target and cannot be changed along the gradient direction. In this paper, we propose AdaDerivative to eliminate the overshoot problem of AdaBelief. The key to AdaDerivative is that the “belief” of AdaBelief is replaced by the derivative term’s exponential moving average (EMA), which can be constructed as ( 1 − β 2 ) ∑ i = 1 t β 2 t − i ( g i − g i − 1 ) 2 based on the past and current gradients. We validate the performance of AdaDerivative on a variety of tasks, including image classification, language modeling, node classification, image generation, and object detection tasks. Extensive experimental results demonstrate that AdaDerivative can achieve state-of-the-art performance.},
  archive      = {J_EAAI},
  author       = {Weidong Zou and Yuanqing Xia and Weipeng Cao},
  doi          = {10.1016/j.engappai.2022.105755},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105755},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AdaDerivative optimizer: Adapting step-sizes by the derivative term in past gradient information},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AgriDet: Plant leaf disease severity classification using
agriculture detection framework. <em>EAAI</em>, <em>119</em>, 105754.
(<a href="https://doi.org/10.1016/j.engappai.2022.105754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of modern agriculture, plant disease detection plays a vital role in improving crop productivity. To increase the yield on a large scale, it is necessary to predict the onset of the disease and give advice to farmers. Previous methods for detecting plant diseases rely on manual feature extraction, which is more expensive. Therefore, image-based techniques are gaining interest in the research area of plant disease detection. However, existing methods have several problems due to the improper nature of the captured image, including improper background conditions that lead to occlusion, illumination, orientation, and size. Also, cost complexity, misclassifications, and overfitting problems occur in several real-time applications. To solve these issues, we proposed an Agriculture Detection (AgriDet) framework that incorporates conventional Inception-Visual Geometry Group Network (INC-VGGN) and Kohonen-based deep learning networks to detect plant diseases and classify the severity level of diseased plants. In this framework, image pre-processing is done to remove all the constraints in the captured image. Then, the occlusion problem is tackled by the proposed multi-variate grabcut algorithm for effective segmentation. Furthermore, the framework performs accurate disease detection and classification by utilizing an improved base network, namely a pre-trained conventionally based INC-VGGN model. Here, the pre-trained INC-VGGN model is a deep convolutional neural network for prediction of plant diseases that was previously trained for the distinctive dataset. The pre-trained weights and the features learned in this base network are transferred into the newly developed neural network to perform the specific task of plant disease detection for our dataset. In order to overcome the overfitting problem, a dropout layer is introduced, and the deep learning of features is performed using the Kohonen learning layer. After percentage computation, the improved base network classifies the severity classes in the training sets. Finally, the performance of the framework is computed for different performance metrics and achieves better accuracy than previous models. Also, the performance of the statistical analysis is validated to prove the results in terms of accuracy, specificity, and sensitivity.},
  archive      = {J_EAAI},
  author       = {Arunangshu Pal and Vinay Kumar},
  doi          = {10.1016/j.engappai.2022.105754},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105754},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AgriDet: Plant leaf disease severity classification using agriculture detection framework},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning from expert demonstrations with
application to redundant robot control. <em>EAAI</em>, <em>119</em>,
105753. (<a
href="https://doi.org/10.1016/j.engappai.2022.105753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current methods of reinforcement learning from expert demonstrations require humans to give all possible demonstrations in the learning phase, which is very difficult for continuous or high-dimensional spaces. In this paper, we proposed biased exploration reinforcement learning to avoid the exploration of unnecessary states and actions of the expert demonstrations. We present a convergence analysis of the novel method. This method is applied to learn the control of a redundant robot manipulator with 7-degree-of-freedom. The experimental results demonstrate that the proposed method accelerates the learning phase. The obtained policy can successfully achieve the pretended task.},
  archive      = {J_EAAI},
  author       = {Jorge Ramirez and Wen Yu},
  doi          = {10.1016/j.engappai.2022.105753},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105753},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning from expert demonstrations with application to redundant robot control},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel fermatean fuzzy bonferroni mean aggregation operators
for selecting optimal health care waste treatment technology.
<em>EAAI</em>, <em>119</em>, 105752. (<a
href="https://doi.org/10.1016/j.engappai.2022.105752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fermatean fuzzy set (FFS) is an expedient tool in today’s world for coping with uncertainty, ambiguity, and incompleteness that emerge in many decision-making processes. In light of the relevance of FFS, this work offers a Multi-Criteria Group Decision Making (MCGDM) method together with Bonferroni mean and weighted Bonferroni mean operators in FF environment. These operators consider the interdependencies between the parameters into account during aggregation process in group decision making. On the other hand, health care waste (HCW) is an unavoidable byproduct of healthcare institutions, and so HCW management is vital owing to its negative influence on public health and environment. In this study, the proposed FFMCGDM has been applied to determine the optimal HCW treatment technologies (TT) for assuring sustainable environmental development, considering six TTs as alternatives assessing against nine criteria. Moreover, the proposed approach has been illustrated through an empirical case study of many district hospitals in Tripura, India. The obtained results are compared to other two well-known MCDM techniques as well as existing Fermatean Fuzzy Aggregation Operators (FFAOs). A sensitivity analysis has also been carried out to examine the stability of the model. From the analysis, it has been found that the proposed technique is competitive to obtain the optimal HCW TT. For further validation of the proposed method, a well-known MCDM problem, namely Green Supplier Selection (GSS) has been modeled and solved.},
  archive      = {J_EAAI},
  author       = {Sayanta Chakraborty and Apu Kumar Saha},
  doi          = {10.1016/j.engappai.2022.105752},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105752},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel fermatean fuzzy bonferroni mean aggregation operators for selecting optimal health care waste treatment technology},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hessian scatter regularized twin support vector machine for
semi-supervised classification. <em>EAAI</em>, <em>119</em>, 105751. (<a
href="https://doi.org/10.1016/j.engappai.2022.105751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, semi-supervised twin support vector machine based on Laplacian regularization (LapTSVM) have received extensive attention and research in many fields of machine learning. Unfortunately, Laplacian regularization has a constant null space, so the solution is often a constant function and cannot well maintain the local topology of the samples. Aiming the above urgent problems, this paper, we first construct a Hessian scatter regularization (HSR) term. HSR has two major advantages: (1) HSR prefers linear variation in function values along of the geodesic distance and maintains the local manifold structure of the samples well. (2) HSR tries to find the projection from the original space to the feature space to maximize the inter-class scatter and minimize the intra-class scatter of the samples; the scatter is regarded as the discriminative information (structural information) of samples. Secondly, by introducing HSR, we propose a Hessian scatter regularized twin support vector machine (HSR-TSVM). Compared with LapTSVM, HSR-TSVM uses the global and local structure information of the sample to overcome the shortcomings of insufficient extrapolation caused by Laplacian regularization, while retaining almost all the advantages of the classic LapTSVM. Furthermore, to improve the computational efficiency of HSR-TSVM, the least-squares version of HSR-TSVM, namely HSR-LSTSVM, is proposed, and the conjugate gradient method is used to solve it. Experimental results on four synthetic datasets, ten UCI datasets, and four image datasets show that the proposed methods are competitive with semi-supervised learning methods based on Laplacian regularization.},
  archive      = {J_EAAI},
  author       = {Guolin Yu and Jun Ma and Chenzhen Xie},
  doi          = {10.1016/j.engappai.2022.105751},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105751},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hessian scatter regularized twin support vector machine for semi-supervised classification},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning based algorithms for modeling natural
convection fluid flow and heat and mass transfer in rectangular cavities
filled with non-newtonian fluids. <em>EAAI</em>, <em>119</em>, 105750.
(<a href="https://doi.org/10.1016/j.engappai.2022.105750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of studying double-diffusive fluid flows along with the significance of non-Newtonian fluids have been well recognized in the fluid dynamics field for scientific and practical purposes. However, and given the ever-rising complexity of such non-linear flows, the conventional simulation methods are confronted with problems related to accuracy and required computation time and resources. As a result, the Machine Learning approach qualifies as a promising solution to said limitations. The present study investigates the application of Machine Learning models to study double-diffusive natural convection in rectangular cavities filled with non-Newtonian fluids. The flow is governed by four dimensionless parameters, namely: thermal Rayleigh number R a T , Lewis number L e , buoyancy ratio N , and power-law behavior index n , employed as input features. To precisely model fluid flow, three characteristics are predicted: flow intensity | ψ c | , average Nusselt number N u ¯ , and average Sherwood number S h ¯ using four machine learning models: Artificial Neural Networks (ANN), Random Forests (RF), Gradient Boosted Decision Trees (GBDT), and Extreme Gradient Boosting (XGBoost). The analysis of investigated models’ fine-tuned architectures using various tools confirms the non-linear complexity of the problem and allows to explore and discuss in details the inner-workings of each model. The ANN predicts the test data with R 2 = 0 . 9999 , R 2 = 0 . 9996 , and R 2 = 0 . 9999 followed by XGBoost with R 2 = 0 . 9979 , R 2 = 0 . 9802 , and R 2 = 0 . 9979 , and that for | ψ c | , N u ¯ , and S h ¯ , respectively. The study shows the strong and correlated effects of R a T and n on the flow characteristics. The models’ generalization is further examined using fluids with power-law behavior indexes outside the learning range. The present paper validates the choice of Machine Learning approach as a promising solution to model non-Newtonian double-diffusive fluid flows and encourages future works in this direction.},
  archive      = {J_EAAI},
  author       = {Youssef Tizakast and Mourad Kaddiri and Mohamed Lamsaadi and Taoufik Makayssi},
  doi          = {10.1016/j.engappai.2022.105750},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105750},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning based algorithms for modeling natural convection fluid flow and heat and mass transfer in rectangular cavities filled with non-newtonian fluids},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven failure prediction and RUL estimation of
mechanical components using accumulative artificial neural networks.
<em>EAAI</em>, <em>119</em>, 105749. (<a
href="https://doi.org/10.1016/j.engappai.2022.105749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is necessary to develop advanced fault prognostics techniques for improving maintenance planning and scheduling to avoid unexpected shutdowns, additional expenses and decreased productivity. Such techniques include advanced failure prediction and remaining useful life (RUL) estimation of mechanical components comprising manufacturing systems with complicated structures. This study proposes a novel data-driven prognostic analysis approach for predicting the failure of a mechanical component based on its degradation path and estimating the RUL. A simulated labelled degradation dataset of a mechanical component with a predefined failure threshold was exploited. In order to increase the ability to maintain the increasing trend and the monotony of the degradation path, supervised machine learning models, including combined artificial neural network architectures and an improved version of the neuron-by-neuron training algorithm using accumulative neural networks design were applied for the prediction process. The expected degradation path was extrapolated as a testing dataset of the trained prediction model using an accumulative function. The predicted values are updated with each new data point during the training process until a failure occurs. The results show that the used approach is efficient in predicting the failure and estimating the RUL of mechanical components with high accuracy and a high prediction success rate, and it can maintain the monotonous trend of the degradation path. On the other hand, the used network architectures enable the prediction of the failures of mechanical components within a manufacturing system having a complex structure and providing a vast amount of data.},
  archive      = {J_EAAI},
  author       = {Basheer Shaheen and Ádám Kocsis and István Németh},
  doi          = {10.1016/j.engappai.2022.105749},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105749},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven failure prediction and RUL estimation of mechanical components using accumulative artificial neural networks},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aggregation operators of quadripartitioned single-valued
neutrosophic z-numbers with applications to diverse COVID-19 scenarios.
<em>EAAI</em>, <em>119</em>, 105748. (<a
href="https://doi.org/10.1016/j.engappai.2022.105748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Z-number, proposed by Zadeh is an ordered pair of fuzzy numbers which have the capability to depict both the reliability and certainty of any available information. Likewise, based upon Belnap’s four-valued logic, Quadripartitioned Single-Valued Neutrosophic Sets (QSVNSs) are characterized by four independent components of truth, contradiction, ignorance, and falsity degrees to represent uncertain information or data at hand. In fact, QSVNSs are extensions of Single-Valued Neutrosophic Sets (SVNSs) where the indeterminacy component is further partitioned into two parts — contradiction and ignorance. However, QSVNSs alone cannot reflect the reliability measure of decision maker’s preferences or allocations. Thus, for better modeling of uncertainty and to combine the information of truth, contradiction, ignorance, and falsity degrees with their respective reliability attributes, we put forward a hybrid framework for the first time in this study. Hence, we propose a notion of Quadripartitioned Single-Valued Neutrosophic Z-number (QSVNZN), which is constructed as a generalization of the Z-number and the QSVNSs. Some basic operations and a score function are also defined for ranking QSVNZNs. Moreover, we also aggregate QSVN information with the help of three weighted aggregation operators viz ., QSVNZN weighted arithmetic averaging (QSVNZNWAA) operator, QSVNZN weighted geometric averaging (QSVNZNWGA) operator, and QSVNZN weighted hybrid averaging (QSVNZNWHA) operator. Several suitable properties and relations between these operators are also presented. The applicability of our newly proposed operators and the score function is demonstrated in three multi-criteria decision making (MCDM) occasions specifically in the COVID-19 context. Meticulous comparative analysis, the validity of our proposed approaches, sensitivity analysis, and runtime analysis is also carried out to depict the legitimacy, veracity, and feasibility of our theoretical construct. The obtained results shall greatly benefit the decision-makers to deal with indeterminate and inconsistent information efficiently. Or in other words, the new framework shall exhibit sufficient descriptive ability from the human-cognition-based perspective.},
  archive      = {J_EAAI},
  author       = {Gourangajit Borah and Palash Dutta},
  doi          = {10.1016/j.engappai.2022.105748},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105748},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Aggregation operators of quadripartitioned single-valued neutrosophic Z-numbers with applications to diverse COVID-19 scenarios},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A distance measure for optimistic viewpoint of the
information in interval-valued intuitionistic fuzzy sets and its
applications. <em>EAAI</em>, <em>119</em>, 105747. (<a
href="https://doi.org/10.1016/j.engappai.2022.105747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance measures in interval-valued intuitionistic fuzzy sets are useful tools for a wide range of decision-making, pattern recognition, and clustering problems. However, so far, only a few distance measures have been developed. Furthermore, the developed distance measure takes a moderate view of the information held in the interval-valued intuitionistic fuzzy sets. It is frequently necessary to be optimistic about the information contained in interval-valued intuitionistic fuzzy sets. Furthermore, in decision-making problems, cross-time information is an important parameter. As a result, a new distance measure has been developed to fill this gap in the literature. The developed distance measure takes into account the optimistic viewpoint of the information held in the interval-valued intuitionistic fuzzy sets as well as the cross-time information via the difference between the maximum and minimum cross-information factors. Numerical and comparative studies are being conducted to demonstrate the superiority of the proposed distance measure. Furthermore, to establish the validity and applicability of the proposed distance measure, it is being used to solve multi-attribute decision making problems, pattern recognition problems, and clustering problems in an interval-valued intuitionistic fuzzy environment. The results of the multi-attribute decision making problem of recruiting a marketing expert have been found to be equivalent to the majority of existing methods. Furthermore, the pattern recognition and clustering problems of building material classification are based on the same data set, with the pattern recognition problem determining that polyvinyl chloride flooring belongs to carpet, and the clustering problem determining that polyvinyl chloride flooring and carpet belong to the same class with a very high confidence interval. These demonstrate the proposed distance measure’s validity and applicability. In general, this work highlights on decision making, pattern recognition, and clustering of engineering problems under interval-valued intuitionistic fuzzy environment from an optimistic point of view.},
  archive      = {J_EAAI},
  author       = {Brindaban Gohain and Rituparna Chutia and Palash Dutta},
  doi          = {10.1016/j.engappai.2022.105747},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105747},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A distance measure for optimistic viewpoint of the information in interval-valued intuitionistic fuzzy sets and its applications},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A collaborative perception method of human-urban environment
based on machine learning and its application to the case area.
<em>EAAI</em>, <em>119</em>, 105746. (<a
href="https://doi.org/10.1016/j.engappai.2022.105746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human perception refers to people’s psychological feelings about a place. Understanding residents’ perception and their activities is important for promoting people-oriented urban construction. Recently, with the development of machine learning, researchers used this technology to study human perception from the open-source street view images. However, the perception measurement is limited, caused by the inadequate feature extraction. Besides, human perceptions and their activities are separately studied, which hinders the process of revealing the relationship between human and environment. Hence, a human perception model was firstly proposed, where a Transformer network was introduced to extract more discriminative semantic features and visual elements were integrated to enhance the feature representations. Experiments showed that the average deviation of perceptual scores was controlled within 1.6 points, and its performance was improved by around 1%–18% in mean square error (MSE), root mean square error (RMSE) and mean absolute error (MAE) compared with the existing best results. Secondly, the collaborative study of environmental perception and residents’ activities was carried out in the case area. Specifically, the perceptual measures of environment were implemented based on the street view video data. Meanwhile, the activities of residents were recognized by SlowFast network and quantified by a new informatics-based diversity indicator (Active Index). This study finally obtained their spatial distribution map, and showed that the perceptual dimensions lively , boring , safe , and depressing are correlated with information quantity of activities. The paper provides a novel method to understand better the urban environment and the distribution of residents’ activities to facilitate urban planning.},
  archive      = {J_EAAI},
  author       = {Jianlin Huang and Linbo Qing and Longmei Han and Jiajia Liao and Li Guo and Yonghong Peng},
  doi          = {10.1016/j.engappai.2022.105746},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105746},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A collaborative perception method of human-urban environment based on machine learning and its application to the case area},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CCNSim: An artificial intelligence enabled classification,
clustering and navigation simulator for social internet of things.
<em>EAAI</em>, <em>119</em>, 105745. (<a
href="https://doi.org/10.1016/j.engappai.2022.105745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the IoT technology stack and the need for information and process ubiquity, social IoT (SIoT) is becoming popular to cater to intelligent and connected living needs. Furthermore, increasing AI-based big traffic data analytics for device and service discovery, service and application recommendations, and personalizations have garnered interest from the research community. To satisfy the needs of lifestyle research problems like smart-city applications, we propound a SIoT simulator called CCNSim, which offers basic network simulator functionalities and sophisticated AI-based traffic analytics and visualization. The proposed functionalities form a middleware that enables communication between the hardware and software interfaces. In addition, the proposed middleware offers a configuration environment for object selection and navigation, service provisioning, object profiling, service and application recommendations, and user behavior predictions. The simulation experimentations and results emphasize the scope and ease of use of the proposed simulation framework.},
  archive      = {J_EAAI},
  author       = {Mohana S.D. and S.P. Shiva Prakash and Kirill Krinkin},
  doi          = {10.1016/j.engappai.2022.105745},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105745},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CCNSim: An artificial intelligence enabled classification, clustering and navigation simulator for social internet of things},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MSE-fusion: Weakly supervised medical image fusion with
modal synthesis and enhancement. <em>EAAI</em>, <em>119</em>, 105744.
(<a href="https://doi.org/10.1016/j.engappai.2022.105744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing multi-modal image fusion methods utilize multi-modal images as input that require multiple imaging of patients causing harm to patients’ bodies and large costs, moreover, image fusion needs a large number of registered images which is time-consuming and difficult to get, and has unclear texture and structure of the fused images. Therefore, a weakly supervised medical image fusion method with modal synthesis and enhancement is proposed. In modal synthesis, a weakly supervised approach is used to train the model to decrease the requirements of registered images, and MR images are used as input to synthesize CT images through a deep-structure and shallow-detail generator by training to reduce the required input modal and make the texture and structure clearer. In image enhancement, MR images are passed through a trained generator to generate enhanced MR images which enhance the texture and structure of the MR images. And then using the synthesized CT and enhanced MR images together with the original PET images as input to achieve tri-modal image fusion. Compared with 13 state-of-the-art modal synthesis and image fusion methods on the same datasets, the performance of the proposed method on 7 objective evaluation metrics is significantly improved. The subjective visual effect and objective evaluation metrics of our method are better than those of the compared image fusion methods.},
  archive      = {J_EAAI},
  author       = {Lifang Wang and Yang Liu and Jia Mi and Jiong Zhang},
  doi          = {10.1016/j.engappai.2022.105744},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105744},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MSE-fusion: Weakly supervised medical image fusion with modal synthesis and enhancement},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification and classification of exfoliated graphene
flakes from microscopy images using a hierarchical deep convolutional
neural network. <em>EAAI</em>, <em>119</em>, 105743. (<a
href="https://doi.org/10.1016/j.engappai.2022.105743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification of exfoliated graphene flakes and classification of the thickness are important in the nanomanufacturing of advanced materials and devices. This paper presents a deep learning method to automatically identify and classify exfoliated graphene flakes on Si/SiO 2 substrates from optical microscope images. The presented framework uses a hierarchical deep convolutional neural network that is capable of learning new images while preserving the knowledge from previous images. The deep learning model was trained and used to classify exfoliated graphene flakes into monolayer, bi-layer, tri-layer, four-to-six-layer, seven-to-ten-layer, and bulk categories. Compared with existing machine learning methods, the presented method showed high accuracy and efficiency as well as robustness to the background and resolution of images. The results indicated that the pixel-wise accuracy of the trained deep learning model was 99% in identifying and classifying exfoliated graphene flakes. This research will facilitate scaled-up manufacturing and characterization of graphene for advanced materials and devices.},
  archive      = {J_EAAI},
  author       = {Soroush Mahjoubi and Fan Ye and Yi Bao and Weina Meng and Xian Zhang},
  doi          = {10.1016/j.engappai.2022.105743},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105743},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identification and classification of exfoliated graphene flakes from microscopy images using a hierarchical deep convolutional neural network},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent mining of safety hazard information from
construction documents using semantic similarity and information
entropy. <em>EAAI</em>, <em>119</em>, 105742. (<a
href="https://doi.org/10.1016/j.engappai.2022.105742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Project construction on-site is known to be very dangerous workplace environments due to large numbers of safety hazards. Analysis of construction safety hazards is essential to formulate rational safety management plans and prevent accidents. Construction documents contain large volumes of safety hazard information available for analysis. However, such analyses are challenging because the safety hazard information in the construction documents is presented in an unstructured or semi-structured format. This study proposes a method for intelligent mining of safety hazard information, which comprises safety hazard technical term recognition and safety hazard information analysis. The safety hazard technical term recognition model is developed based on semantic similarity and information correlation to build a safety hazard technical term library. The safety hazard information based on the technical term library is mined and analyzed using the term frequency-inverse document frequency method (TF-IDF). Finally, the proposed method is applied to build the safety hazard technical term library, which contains 2697 technical terms, and develop a hydraulic project construction safety hazard analysis system, which can realize the intelligent recognition and application of technical terms. Meanwhile, this system can automatically extract safety hazard information and provide a visualization interface to intuitively show the safety hazard analysis results, which improves the extraction efficiency of safety hazard information. The study provides a new approach for recognizing technical terms and mining safety hazard information, which can lead to enhancing management efficiency and practical knowledge discovery for safety management.},
  archive      = {J_EAAI},
  author       = {Dan Tian and Mingchao Li and Yang Shen and Shuai Han},
  doi          = {10.1016/j.engappai.2022.105742},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105742},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent mining of safety hazard information from construction documents using semantic similarity and information entropy},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive machine learning algorithm for the
resource-constrained classification problem. <em>EAAI</em>,
<em>119</em>, 105741. (<a
href="https://doi.org/10.1016/j.engappai.2022.105741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource-constrained classification tasks are common in real-world applications such as allocating tests for disease diagnosis, hiring decisions when filling a limited number of positions, and defect detection in manufacturing settings under a limited inspection budget. Typical classification algorithms treat the learning process and the resource constraints as two separate and sequential tasks. We develop an adaptive learning approach that considers resource constraints and learning jointly by iteratively fine-tuning misclassification costs. Via a structured experimental study using a publicly available data set, we evaluate a decision tree classifier that utilizes the proposed approach. The adaptive learning approach performs significantly better than alternative approaches, especially for difficult classification problems in which the performance of common approaches may be unsatisfactory. The suggested approach reaches similar classification decisions for different costs, thus it may be useful when misclassification costs are not known precisely or are costly to achieve. We envision the suggested learning approach as an important addition to the repertoire of techniques for handling resource-constrained classification problems.},
  archive      = {J_EAAI},
  author       = {Danit Abukasis Shifman and Izack Cohen and Kejun Huang and Xiaochen Xian and Gonen Singer},
  doi          = {10.1016/j.engappai.2022.105741},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105741},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive machine learning algorithm for the resource-constrained classification problem},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Robustness of visual perception system in progressive
challenging weather scenarios. <em>EAAI</em>, <em>119</em>, 105740. (<a
href="https://doi.org/10.1016/j.engappai.2022.105740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional field test and laboratory test can only evaluate hardware performance, and cannot test the robustness of artificial intelligence (AI) device for object detection, instance segmentation, etc. under task scenarios. For AI-based visual perception system, this need for evaluation and testing is very urgent. In this paper, we consider the adverse effects of challenging weather on the visual perception system, investigate the robustness of visual perception system affected by adverse weather through imaging, and propose a method to evaluate the robustness of object detection model under different weather variations. To begin, we analyze the components that influence the visual perception system’s robustness and develop a weather generation model under rainy and foggy scenes. After that, quantifiable weather meta-datasets with visibility in fog and rain intensity as variable parameters are built. Finally, regression analysis and statistical test are used to verify the nonlinear relationship between model performance and weather variations, the robustness of state-of-the-art object detection algorithms under progressive challenging weather images is evaluated.},
  archive      = {J_EAAI},
  author       = {Xingge Li and Shufeng Zhang and Xun Chen and Yashun Wang and Zhengwei Fan and Xiaofei Pang and Jingwen Hu},
  doi          = {10.1016/j.engappai.2022.105740},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105740},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robustness of visual perception system in progressive challenging weather scenarios},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A hybrid adaptive differential evolution based on gaussian
tail mutation. <em>EAAI</em>, <em>119</em>, 105739. (<a
href="https://doi.org/10.1016/j.engappai.2022.105739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an improved version of JADE by h ybridizing the JADE algorithm with a G aussian t ail, a modified hunger games search (HGS) algorithm, and a distance-based multi-population (DbMP) approach named as HJADE-GT. In the proposed algorithm, two sets of operators (modified HGS operator and JADE operator with Gaussian tail) are utilized to generate offspring to further enhance the exploration and exploitation abilities. DbMP approach is proposed to make full use of feedback information from the whole population. In HJADE-GT, the main population is divided into three fixed-size subpopulations: exploration subpopulation, balanced subpopulation, and exploitation subpopulation. Secondly, a modified HGS operator is incorporated into the exploration subpopulation to improve global searchability. Thirdly, the JADE operator with a Gaussian tail is utilized to enhance the ability of exploitation subpopulation. Finally, the DbMP approach is utilized for the balanced subpopulation to choose an appropriate operator for current individuals to make full use of feedback information from the exploration subpopulation and exploitation subpopulation. In the experimental studies, it is demonstrated that the proposed algorithm presents competitive performance with 13 well-known algorithms, including jDE, SaDE, JADE, MPEDE, SHADE, CoDE, SaJADE, iLSHADE, jSO, CMAES, MGFPA, ESSA, and PPSO on CEC2017 benchmark functions. Four engineering problems and three dynamic economic emission dispatch (DEED) problems were utilized to verify the performance of HJADE-GT, and the experiments on DEED problems confirm that HJADE-GT is an efficient algorithm to solve engineering and large-scale constrained DEED problems.},
  archive      = {J_EAAI},
  author       = {Hui Chen and Shaolang Li and Xiaobo Li and Yuxin Zhao and Junwei Dong},
  doi          = {10.1016/j.engappai.2022.105739},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105739},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid adaptive differential evolution based on gaussian tail mutation},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of GA-BPNN on estimating the flow rate of a
centrifugal pump. <em>EAAI</em>, <em>119</em>, 105738. (<a
href="https://doi.org/10.1016/j.engappai.2022.105738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pumps consume nearly 8% of global electricity as the essential equipment for liquid transportation. A practical method for improving centrifugal pump energy efficiency is accurately predicting and controlling the pump operation status. However, current estimation methods for sensorless flow rate prediction have a significant error at low flow rate conditions. This study adds valve opening as the estimation model input variable, including motor shaft power and speed, to form a back-propagation neural network (BPNN) on an asynchronous motor-driven multistage centrifugal pump. By optimizing the initial weights and thresholds of BPNN, a GA-BPNN model was proposed to improve the prediction accuracy by using a genetic algorithm (GA). The results indicate that, with the addition of the valve opening as an input variable, the accuracy of BPNN-VO and GA-BPNN prediction improves significantly more than BPNN-NVO. Furthermore, the GA-BPNN model produces a significantly lower mean square error (MSE) and root mean square error (RMSE) than the original BPNN model. According to the experimental comparison and analysis, the absolute error of GA-BPNN between predicted flow rate and measured flow rate is less than 0.3 m 3 /h, the average relative error is less than 2%, and the relative error of low flow rate is less than 5%. This GA-BPNN estimation model significantly improves the accuracy of flow rate prediction, especially at small flow rates, and extends the scope of centrifugal pumps’ monitoring and control technology without flow sensors.},
  archive      = {J_EAAI},
  author       = {Yuezhong Wu and Denghao Wu and Minghao Fei and Henrik Sørensen and Yun Ren and Jiegang Mou},
  doi          = {10.1016/j.engappai.2022.105738},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105738},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of GA-BPNN on estimating the flow rate of a centrifugal pump},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attribute-relevant distributed variational autoencoder
integrated with LSTM for dynamic industrial soft sensing. <em>EAAI</em>,
<em>119</em>, 105737. (<a
href="https://doi.org/10.1016/j.engappai.2022.105737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complicated features of process data in terms of high dimension, nonlinearity and coupling, it tends to be a grand challenge to extract important features from complicated process for predicting quality variables using a reliable soft sensor model. Variational Autoencoder (VAE), one of the unsupervised deep learning methods, has been widely used for Gaussian-restricted feature extraction. Considering that the high-dimensional process variables may have different impacts on the predicted quality variable and process variables effect the prediction accuracy, a novel attribute-relevant distributed variational autoencoder (AR-DVAE) is first proposed to effectively extract features from input variables with different correlations. In AR-DVAE, by performing correlation analysis between the input variables and the quality variable, a distributed structure with two encoder subnets is constructed. In each encoder subnet, the input attributes have the same correlation with the output quality variable. As a consequence, the proposed AR-DVAE can extract features with dual channels. Next, a supervised regressor based on the long short-term memory machine shortened to LSTM is utilized for developing soft sensing between the extracted features and the quality variable. Case studies on two actual industrial processes are carried out to confirm the high accuracy of the presented AR-DVAE integrated with the LSTM soft sensing model.},
  archive      = {J_EAAI},
  author       = {Yan-Lin He and Xing-Yuan Li and Jia-Hui Ma and Qun-Xiong Zhu and Shan Lu},
  doi          = {10.1016/j.engappai.2022.105737},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105737},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attribute-relevant distributed variational autoencoder integrated with LSTM for dynamic industrial soft sensing},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Traffic classification using distributions of latent space
in software-defined networks: An experimental evaluation. <em>EAAI</em>,
<em>119</em>, 105736. (<a
href="https://doi.org/10.1016/j.engappai.2022.105736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of new Internet services and the drastic increase in Internet traffic, traffic classification has become increasingly important to effectively satisfy the quality of service to users. The traffic classification system should be resilient and operate smoothly regardless of network conditions or performance and should be capable of handling various classes of Internet services. This paper proposes a traffic classification method in a software-defined network environment that employs a variational autoencoder (VAE) to accomplish this. The proposed method trains the VAE using six statistical features and extracts the distributions of latent features for the flows in each service class. Furthermore, it classifies the query traffic by comparing the distributions of latent features for the query traffic with the learned distributions of the service classes. For the experiment, the statistical features of network flows were collected from real-world domestic and overseas Internet services for training and testing. According to the experimental results, the proposed method has an average accuracy of 89%. This accuracy was 52%, 47%, 39%, 59%, and 26% higher than conventional statistics-based classification methods, MLP, AE+MLP, VAE+MLP, and SVM, respectively. This result clearly suggests that probability distributions of latent features, rather than specific values for latent features, can be used as more stable features.},
  archive      = {J_EAAI},
  author       = {Yehoon Jang and Namgi Kim and Byoung-Dai Lee},
  doi          = {10.1016/j.engappai.2022.105736},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105736},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Traffic classification using distributions of latent space in software-defined networks: An experimental evaluation},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A nearly end-to-end deep learning approach to fault
diagnosis of wind turbine gearboxes under nonstationary conditions.
<em>EAAI</em>, <em>119</em>, 105735. (<a
href="https://doi.org/10.1016/j.engappai.2022.105735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis of wind turbine gearboxes is crucial in ensuring wind farms’ reliability and safety. However, nonstationary working conditions, such as load change or speed regulation, may result in an accuracy deterioration of many existing fault diagnosis approaches. To overcome the issue, this research proposes a nearly end-to-end deep learning approach to fault diagnosis of wind turbine gearboxes using vibration signals. Concretely, we adopt Empirical Mode Decomposition (EMD) to decompose vibration signals into a series of Intrinsic Mode Functions (IMFs). Then, the multi-channel IMFs are fed into a 1D Convolutional Neural Network (CNN) for automatic feature learning and fault classification. Since EMD is a signal processing technique requiring no prior knowledge, the model architecture can be viewed as nearly end-to-end. The proposed approach was validated in a real-world dataset; it proved deep learning models have an overwhelming advantage in representation capacity over traditional shallow models. It also demonstrated that the introduction of EMD as a preprocessing step improves both the training efficiency and the generalization ability of a deep model, thus leading to a better fault diagnosis efficacy under variable working conditions.},
  archive      = {J_EAAI},
  author       = {Liangwei Zhang and Qi Fan and Jing Lin and Zhicong Zhang and Xiaohui Yan and Chuan Li},
  doi          = {10.1016/j.engappai.2022.105735},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105735},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A nearly end-to-end deep learning approach to fault diagnosis of wind turbine gearboxes under nonstationary conditions},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Madhubani art classification using transfer learning with
deep feature fusion and decision fusion based techniques. <em>EAAI</em>,
<em>119</em>, 105734. (<a
href="https://doi.org/10.1016/j.engappai.2022.105734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some traditional Indian art forms enjoy widespread popularity across the world. One of the most prominent among these is the Madhubani style. This art form’s rich heritage and beauty enthrall the connoisseurs and continue to inspire new designs catering to the changing tastes of prevalent fashion. Preservation of these traditional art forms is the need of the hour. Modern technological advances can be utilized with great advantage for this purpose. Since a database of Madhubani art forms was hitherto unavailable, an attempt is made in this work to create one from scratch. Five different classes of Madhubani art, i.e., Bharni, Godna, Kachni, Kohbar, and Tantrik, are identified, and the collected images are annotated with these classes. Classification of the art images is attempted using the handcrafted Local Binary Pattern (LBP) texture descriptors and state-of-the-art Convolutional Neural Networks (CNNs). The Transfer Learning approach with CNNs is employed to classify the designs. An attempt is made to obtain a better classification accuracy than the one provided by standard CNNs. Towards this end, the current work proposes a fusion of features extracted from several deep CNNs, decision fusion-based classification based on averaging prediction score (FAVG), and maximum vote score (FMAX). The proposed method’s performance is tested on our Madhubani art dataset and compared against several standard pre-trained CNNs available in the literature. The proposed approaches provide significantly higher classification accuracy for Madhubani art patterns, with decision fusion based on averaging prediction score (FAVG) approach being the best. The maximum accuracy, specificity, and error rate scores are 98.82%, 99.72%, and 1.18%, respectively. This is the first such attempt, and the excellent results motivate further work to develop content-based image retrieval tools and evolutionary design-based tools for automating the development of new designs. These endeavors are expected to go a long way in preserving precious art heritage and fostering its rapid growth in the world market. The dataset will be made publically available for further experimentation.},
  archive      = {J_EAAI},
  author       = {Seema Varshney and C. Vasantha Lakshmi and C. Patvardhan},
  doi          = {10.1016/j.engappai.2022.105734},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105734},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Madhubani art classification using transfer learning with deep feature fusion and decision fusion based techniques},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Part-aware attention correctness for video salient object
detection. <em>EAAI</em>, <em>119</em>, 105733. (<a
href="https://doi.org/10.1016/j.engappai.2022.105733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video salient object detection (VSOD), aiming to detect the most conspicuous objects or regions in a video, has become an important research topic over the past few years. Preliminary studies mainly focus on spatial–temporal architecture that heavily relies on implicit attention model to aggregate complementary information from adjacent video frames. Despite the remarkable improvements, existing approaches pay little attention to cross-video affinities, which is important to build explicit attention schema for VSOD. To this end, we propose a novel attention correctness strategy to supervise the aggregation process. Specifically, different from previous works, we employ pairwise training schema, leveraging both positive and negative aggregation supervision to explore inter-video affinities for VSOD. The proposed mechanism successfully suppresses negative correspondence for video frames and reinforces discriminative feature mining for conspicuous objects. To enhance intra-video correspondence, we propose part-aware similarity aggregation module that helps intra-video affinities to segment the salient objects with video-level context. Extensive experiments are conducted on six popular benchmarks, including FBMS, DAVIS, DAVSOD, SegTrack-V2, VOS and ViS. Experimental results on challenging scenes (i.e., for DAVSOD-T, we achieve an improvement of 0.4% for MAE, 1.1% for maximum F-measure and 0.5% for S-measure compared with other competitive models) demonstrate the effectiveness of our proposed method.},
  archive      = {J_EAAI},
  author       = {Ze-yu Liu and Jian-wei Liu},
  doi          = {10.1016/j.engappai.2022.105733},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105733},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Part-aware attention correctness for video salient object detection},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Greedy-AutoML: A novel greedy-based stacking ensemble
learning framework for assessing soil liquefaction potential.
<em>EAAI</em>, <em>119</em>, 105732. (<a
href="https://doi.org/10.1016/j.engappai.2022.105732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated machine learning (AutoML) is a generic term for a specific approach to machine learning (ML) area that tries to automate the end-to-end process of employing repetitive ML tasks for real-world problems. In recent years, the AutoML framework, which is the subject of an increasing number of research articles, has become a potential approach for developing complicated ML models without human experience and support. Although existing techniques on AutoML have yielded promising results, research in this field is immature, and new approaches should be developed gradually. This study describes a novel AutoML framework to predict soil liquefaction potential problem based on stacking ensemble learning (SEL) combined with a greedy search algorithm. A special AutoML framework, called Greedy-AutoML, is presented that automatically produces an optimized ML model for predicting on a supervised classification task. The general concept of the proposed AutoML framework consists of three main steps: data preparation, greedy feature selection, and greedy stacking ensemble. Furthermore, the Greedy-AutoML framework has been published on a user-friendly web-based platform for testing or trial purposes. To highlight the capability of this AutoML application, Greedy-AutoML is applied to predict the liquefaction potential of soils using three well-known datasets (i.e., CPT — cone penetration test, SPT — standard penetration test, and V s — shear wave velocity test) collected from previously published research. The results are assessed based on different performance matrices, namely Accuracy ( Acc ), Kappa, Precision, Recall, and F1-Score. Experiments with datasets from existing case histories with varying distribution and features showed that the proposed greedy based SEL method achieved an Acc of 98% for the CPT and SPT datasets, while the achieved Acc for the Vs dataset was about 99%.},
  archive      = {J_EAAI},
  author       = {Emrehan Kutlug Sahin and Selcuk Demir},
  doi          = {10.1016/j.engappai.2022.105732},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105732},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Greedy-AutoML: A novel greedy-based stacking ensemble learning framework for assessing soil liquefaction potential},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hindi fake news detection using transformer ensembles.
<em>EAAI</em>, <em>119</em>, 105731. (<a
href="https://doi.org/10.1016/j.engappai.2022.105731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few decades, due to the growth of social networking sites such as Whatsapp and Facebook, information distribution has been at a level never seen before. Knowing the integrity of information has been a long-standing problem, even more so for the regional languages. Regional languages, such as Hindi, raise challenging problems for fake news detection as they tend to be resource constrained. This limits the amount of data available to efficiently train models for these languages. Most of the existing techniques to detect fake news is targeted towards the English language or involves the manual translation of the language to the English language and then proceeding with Deep Learning methods. Pre-trained transformer based models such as BERT are fine-tuned for the task of fake news detection and are commonly employed for detecting fake news. Other pre-trained transformer models, such as ELECTRA and RoBERTa have also been shown to be able to detect fake news in multiple languages after suitable fine-tuning. In this work, we propose a method for detecting fake news in resource constrained languages such as Hindi more efficiently by using an ensemble of pre-trained transformer models, all of which are individually fine-tuned for the task of fake news detection. We demonstrate that the use of such a transformer ensemble consisting of XLM-RoBERTa, mBERT and ELECTRA is able to improve the efficiency of fake news detection in Hindi by overcoming the drawbacks of individual transformer models.},
  archive      = {J_EAAI},
  author       = {Amit Praseed and Jelwin Rodrigues and P. Santhi Thilagam},
  doi          = {10.1016/j.engappai.2022.105731},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105731},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hindi fake news detection using transformer ensembles},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable anomaly detection with DIFFI: Depth-based
feature importance of isolation forest. <em>EAAI</em>, <em>119</em>,
105730. (<a
href="https://doi.org/10.1016/j.engappai.2022.105730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly Detection is an unsupervised learning task aimed at detecting anomalous behaviors with respect to historical data. In particular, multivariate Anomaly Detection has an important role in many applications thanks to the capability of summarizing the status of a complex system or observed phenomenon with a single indicator (typically called ‘anomaly score’) and thanks to the unsupervised nature of the task that does not require human tagging. The Isolation Forest is one of the most commonly adopted algorithms in the field of Anomaly Detection due to its proven effectiveness and low computational complexity. A major problem affecting Isolation Forest is represented by the lack of interpretability, an effect of the inherent randomness governing the splits performed by the Isolation Trees, the building blocks of the Isolation Forest. In this paper, we propose effective yet computationally inexpensive methods to define feature importance scores at both global and local levels for the Isolation Forest. Moreover, we define a procedure to perform unsupervised feature selection for Anomaly Detection problems based on our interpretability method. Such a procedure also serves the purpose of tackling the challenging task of feature importance evaluation in unsupervised anomaly detection. We assess the performance on several synthetic and real-world datasets, including comparisons against state-of-the-art interpretability techniques, and make the code publicly available to enhance reproducibility and foster research in the field.},
  archive      = {J_EAAI},
  author       = {Mattia Carletti and Matteo Terzi and Gian Antonio Susto},
  doi          = {10.1016/j.engappai.2022.105730},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105730},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable anomaly detection with DIFFI: Depth-based feature importance of isolation forest},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new risk quantification method in project-driven supply
chain by MABACODAS method under interval type-2 fuzzy environment with a
case study. <em>EAAI</em>, <em>119</em>, 105729. (<a
href="https://doi.org/10.1016/j.engappai.2022.105729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous decision-making in the supply chain and project management has attracted much attention. The integration of these two areas is called the project-driven supply chain. Timely supply of materials and services from the supply chain is significant for project activities. For this purpose, this paper presents a new method for the first time in the literature to quantify the supply risks in project activities and objectives. At first, the project’s critical path is specified according to the time, cost, risk, and quality criteria through a new decision model, namely MABACODAS, under parametric fuzzy values. The MABACODAS consists of two parts; One is about the degree of criticality of the paths, and the other is about determining the weight of experts in group decision-making. Then, a dynamic view is investigated under type-2 fuzzy numbers in the project, and it is observed that the critical path changes for different alpha values. The project suppliers’ resilience and each activity’s resilience are determined through the proposed MABACODAS model to obtain the appropriate alpha value. In other words, by using the resilience of each activity, the alpha value is selected, and the critical path is specified by considering the risk of the supply chain. Notably, the MABACODAS model is extended under interval type-2 fuzzy sets for uncertainty considerations. The main contribution of this study is introducing a risk quantification method. This method uses the MABACODAS method for specifying the criticality index of paths and resilience scores of suppliers. Also, this method is expanded under the IT2FSs. Finally, a real case study of the construction project is presented to show the applicability of the introduced model.},
  archive      = {J_EAAI},
  author       = {Yahya Dorfeshan and Fariborz Jolai and Seyed Meysam Mousavi},
  doi          = {10.1016/j.engappai.2022.105729},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105729},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new risk quantification method in project-driven supply chain by MABACODAS method under interval type-2 fuzzy environment with a case study},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-dimensional representation of monthly electricity demand
profiles. <em>EAAI</em>, <em>119</em>, 105728. (<a
href="https://doi.org/10.1016/j.engappai.2022.105728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of reducing the number of values required to characterize an electricity demand profile, which is usually known as its dimensionality. This reduction may have a significant impact on the computational efforts and storage capacities required to analyze and process high volumes of electricity load curves. Also, the reduction to 2 or even 1 component enables its graphic representation. Specifically, this work is mainly focused on profiles defined by their monthly demand values, and where the clients are aggregated by locations and/or economic activities. This approach is of great interest for marketing analysis and decision-making of electricity retailers. In this sense, the use of dimensionality reduction techniques based on knowledge (calendar and temperature) along with the application of data-driven procedures (Principal Component Analysis and autoencoders), are explored in the paper. The results of this research show that autoencoders clearly outperform the other techniques, yielding errors in the reduction process between 15% to 40% lower and preserving distances between profiles in the low-dimensional spaces, with a correlation of 0.93 with the distances in high dimensional space. Additionally, the bidimensional graphical representation of a profile can easily be interpreted in a polar way, where the angle denotes the shape of the profile, and the radius reveals its scale. To reach these results, a very large dataset has been employed, with about half a million aggregated profiles corresponding to the electricity consumption during 3 years of more than 27 million clients in Spain.},
  archive      = {J_EAAI},
  author       = {Joaquin Luque and Enrique Personal and Francisco Perez and MCarmen Romero-Ternero and Carlos Leon},
  doi          = {10.1016/j.engappai.2022.105728},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105728},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Low-dimensional representation of monthly electricity demand profiles},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SubGE: Enhancing the subgraph representation of molecular
compounds structure–activity relationship discovery. <em>EAAI</em>,
<em>119</em>, 105727. (<a
href="https://doi.org/10.1016/j.engappai.2022.105727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of the molecular compound structure–activity relationship is one of the most critical tasks in computer-assisted drug design. To accurately predict the properties of molecular compounds and explain their structure–activity relationships, we proposed a subgraph embedding model, subGE, based on reinforcement learning and mutual information mechanisms. First, molecular compounds were abstracted into graphs, and the original graphs were sampled using a breadth-first search. These subgraphs were then encoded using graph neural networks and converted into graph embeddings. Reinforcement learning was introduced to reduce the dimensionality of the subgraph embeddings and filter out significant subgraphs. A mutual information mechanism was introduced to further enhance the ability of the filtered subgraphs to characterize a full graph. SubGE was evaluated based on three open-source datasets, BBBP, Bace, and Clintox from the DeepChem package developed by MoleculeNet. The experimental results showed that subGE achieved accuracies of 86.61%, 80.49%, 95.81%, and 96.34% for four classification tasks with three datasets. These values represent improvements of 16.87%, 19.29%, 3.91%, and 3.73%, respectively, compared to that of existing graph convolutional networks, and of 8.34%, 6.64%, 5.53%, and 5.50%, respectively, compared to that of the direct encoding of subgraphs without introducing reinforcement learning and mutual information mechanisms. The subgraphs extracted by subGE could fully explain the conformational relationships of compounds through visualization.},
  archive      = {J_EAAI},
  author       = {Xiaoyu Chen and Quan Qian},
  doi          = {10.1016/j.engappai.2022.105727},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105727},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SubGE: Enhancing the subgraph representation of molecular compounds structure–activity relationship discovery},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On spherical fuzzy distance measure and TAOV method for
decision-making problems with incomplete weight information.
<em>EAAI</em>, <em>119</em>, 105726. (<a
href="https://doi.org/10.1016/j.engappai.2022.105726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A spherical fuzzy set is one of the reliable tools to handle the uncertainties in the data with the help of the three membership degrees: Positive, neutral, and negative. Under this environment, the paper aims to present a novel decision-making algorithm named as MCDM-TAOV with some novel distance measures using matrix norms. In the literature, several kinds of distance measures occur, but they fail to meet certain axioms of the measure. To overwhelm this, the proposed measure satisfies all axiomatic requirements and overcomes the hindrances in the existing distance measures. Several counter-intuitive examples are provided to justify the superiority of the proposed measures. Furthermore, we addressed the total area based on orthogonal vector (TAOV) methodology to solve the MCDM (“multi-criteria decision-making”) problems. A distance-based criteria weight determination method is presented to compute the unknown criteria weight. The approach has been demonstrated by assessing the third-party reverse logistics provider (3PRLP) problem. The practical applicability, comparative analysis and advantages of the study with other decision-making methods are furnished to depict the efficiency of the moulded process.},
  archive      = {J_EAAI},
  author       = {Jawad Ali and Harish Garg},
  doi          = {10.1016/j.engappai.2022.105726},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105726},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On spherical fuzzy distance measure and TAOV method for decision-making problems with incomplete weight information},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preventive maintenance scheduling of a multi-skilled human
resource-constrained project’s portfolio. <em>EAAI</em>, <em>119</em>,
105725. (<a
href="https://doi.org/10.1016/j.engappai.2022.105725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Companies often struggle with the problem of appropriately assigning multi-skilled employees and maintaining the required skill levels while performing a changing project’s portfolio. The paper focuses on maintaining employee skills at a constant level without degradation. Maintaining the required team efficiency and competency levels through staff rotation while avoiding additional periodic training because of competency loss has been considered. The aim is to develop an analytical tool that considers individual learning and workers who irregularly perform repetitive tasks and forget their skills. Incorporating competency’s learning and forgetting curves into modelling workers’ assignments and schedules allows for more accurate estimates of actual and future workforce performance. The paper contributes to the theory by proposing a novel declarative programming approach which allows for rotating a multi-skilled team of employees to maintain their competences at a required level. The stationary declarative model that implements this approach can easily be extended to non-stationary and fuzzy variants. The decision-making problem is looking for the rotation schedule of a multi-skilled team of employees to maintain their competences at a required level when satisfying the timely fulfilment of a given project’s portfolio. The presented case study from remanufacturing industry illustrates that the proposed approach can be used for the scale of problems which occur in real-life companies.},
  archive      = {J_EAAI},
  author       = {G. Bocewicz and P. Golińska-Dawson and E. Szwarc and Z. Banaszak},
  doi          = {10.1016/j.engappai.2022.105725},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105725},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Preventive maintenance scheduling of a multi-skilled human resource-constrained project’s portfolio},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconstruction of hydrofoil cavitation flow based on the
chain-style physics-informed neural network. <em>EAAI</em>,
<em>119</em>, 105724. (<a
href="https://doi.org/10.1016/j.engappai.2022.105724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cavitation flow is a typical complex flow phenomenon, which involves many flow mechanisms. At present, the main approach to reconstruct the cavitation flow field based on the experimental results is numerical simulation, which has the defects of low computational efficiency and is difficult to effectively use the experimental data. In this paper, a chain-style physics-informed neural network (chain-style PINN) is developed to solve the reconstruction problem of cavitation flow field. On the basis of decoupling the governing equations, our method solves the physical quantities of interest serially by introducing multiple serial PINNs. A physics-informed loss function is defined to realize the assimilation of experimental data and physical mechanism. The prediction for a 3D NACA66 hydrofoil case is validated by comparing with Direct Numerical Simulation (DNS), which demonstrates that the calculation time is reduced by about 70% while the relative L 2 errors of pressure and liquid volume fraction fields are only 0.0030 and 0.0035. While comparing with the existing method Hidden Fluid Mechanics (i.e., baseline PINN), the results show the validity of our method. To the best of our knowledge, this is the first theoretical work that applies PINN to cavitation flow.},
  archive      = {J_EAAI},
  author       = {Hanqing Ouyang and Zhicheng Zhu and Kuangqi Chen and Beichen Tian and Biao Huang and Jia Hao},
  doi          = {10.1016/j.engappai.2022.105724},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105724},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reconstruction of hydrofoil cavitation flow based on the chain-style physics-informed neural network},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive neuro-fuzzy inference system based data
interpolation for particle image velocimetry in fluid flow applications.
<em>EAAI</em>, <em>119</em>, 105723. (<a
href="https://doi.org/10.1016/j.engappai.2022.105723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an adaptive neuro-fuzzy inference system (ANFIS) approach for recovering the missing velocity vectors that commonly occur during fluid flow measurements in fluid mechanics. The capability of ANFIS in refilling the missing data is demonstrated with two case studies. First, the ANFIS is applied to estimate the velocity field data within the masked region of an available particle image velocimetry (PIV) experiment. Then, the ANFIS is trained using the data from outside the masked region and learns the relationship between the velocity vectors. Thus, it predicts the fluid patterns within the gappy area based on its understanding. ANFIS is also applied in another study to capture the small feature in the fluid flow. The vortices within a small area behind an obstacle are removed, and the rest of the data is introduced into the ANFIS model. The efficacy of the proposed ANFIS algorithm in predicting the missing velocity vectors is compared to both artificial neural network (ANN) and 2D cubic interpolation algorithms. It is found that intelligent algorithms (ANFIS and ANN) can predict the presence of vortices in the fluid flow even when there is no information about a circulating flow in the training dataset. The performance of ANFIS (R 2 = 0.91) in accurately predicting the velocity vectors is superior to the conventional ANN (R 2 = 0.86).},
  archive      = {J_EAAI},
  author       = {Mohammad Amin Kazemi and Mary Pa and Mohammad Nasir Uddin and Mashallah Rezakazemi},
  doi          = {10.1016/j.engappai.2022.105723},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105723},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive neuro-fuzzy inference system based data interpolation for particle image velocimetry in fluid flow applications},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new one-dimensional testosterone pattern-based EEG
sentence classification method. <em>EAAI</em>, <em>119</em>, 105722. (<a
href="https://doi.org/10.1016/j.engappai.2022.105722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) signals are crucial data to understand brain activities. Thus, many papers have been proposed about EEG signals. In particular, machine learning techniques have been used/presented to extract information from EEG signals. However, there are limited works on sentence classification using this data. To fill this gap, we propose an automated EEG signal classification model. In this model, we have presented a new molecular-based feature extractor, which utilizes a graph of the testosterone molecular structure. The proposed testosterone graph-based pattern is a nature-inspired pattern. The motivation is to show the feature extraction capability of the chemical-based graphs. Hence, we presented a hand-modeled EEG classification architecture. Our architecture uses wavelet packet decomposition (WPD) to generate wavelet bands to extract low and high-level features. The statistical feature extraction function has been used to generate statistical features, and our proposed testosterone pattern (TesPat) generates textural features. A feature selector has been used to choose the most informative features (neighborhood component analysis). Channel-wise results have been calculated by deploying a shallow classifier (k nearest neighbors). Majority voting has been conducted to create general results, and our proposed model selects the best-resulted predicted labels vector. Our proposed model attained a classification accuracy of &gt;97% with 10-fold cross-validation (CV) and &gt;91% with leave-one subject out (LOSO) CV. Our high classification results demonstrate that our presented system is an accurate and robust sentence classification model. The novelty of this work is the development of an accurate testosterone-based learning model using three EEG sentence datasets.},
  archive      = {J_EAAI},
  author       = {Tugce Keles and Arif Metehan Yildiz and Prabal Datta Barua and Sengul Dogan and Mehmet Baygin and Turker Tuncer and Caner Feyzi Demir and Edward J. Ciaccio and U. Rajendra Acharya},
  doi          = {10.1016/j.engappai.2022.105722},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105722},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new one-dimensional testosterone pattern-based EEG sentence classification method},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review on optimization techniques and role of artificial
intelligence in home energy management systems. <em>EAAI</em>,
<em>119</em>, 105721. (<a
href="https://doi.org/10.1016/j.engappai.2022.105721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Present advancements in the power systems paved way for introducing the smart grid (SG). A smart grid is beneficial to consumers which enables the bi-directional flow of information between the utility and customer. Demand-side management (DSM) techniques are crucial as load-side management techniques to attain the better stability of the grid. Home energy management systems (HEMS) play a indispensable part in the DSM. Countless traditional optimization techniques are utilized to implement HEMS, but the limitations of traditional Math heuristic methods gave rise to a concept-based optimization techniques called the Meta heuristic methods. Recent advancements introduced smart optimization techniques powered by Artificial Intelligence (AI). This article elucidates the applications of AI-based optimization techniques and their advantages over other methods. Various Machine learning (ML) and Deep Learning (DL) algorithms and their utilization for HEMS are discussed in brief.},
  archive      = {J_EAAI},
  author       = {Mounica Nutakki and Srihari Mandava},
  doi          = {10.1016/j.engappai.2022.105721},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105721},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review on optimization techniques and role of artificial intelligence in home energy management systems},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved marine predator algorithm based on epsilon
dominance and pareto archive for multi-objective optimization.
<em>EAAI</em>, <em>119</em>, 105718. (<a
href="https://doi.org/10.1016/j.engappai.2022.105718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving multi-objective optimization problems plays an important role in several applications. Recently, the Marine Predator Algorithm (MPA) was introduced for solving single objective optimization problems inspired by the behaviour of marine predator in their search for a prey. This paper proposes a modified MPA based framework called Guided Multi-objective Marine Predator Algorithm (GMOMPA) to solve multi-objective optimization problems. The proposed GMOMPA incorporates an external archive to help store the optimal Pareto set solution and guide the particles during the exploitation of the search space. For obtaining non-dominated solutions, the Pareto dominance concept is utilized while the epsilon dominance is considered to update the archive’s sorted solutions. In this context, the epsilon dominance concept extends the diversity and exploration of the solutions. Further, a fast non-dominated solution and crowding distance are introduced to update the particle’s position, while maintaining the diversity and ensuring a fast convergence towards the Pareto optimal. The proposed GMOMPA is evaluated on several different benchmark test functions including multi-objective ZDT, DTLZ, UF, and WFG test functions as well as the recent multi-objective multimodal CEC 2020 test functions. Moreover, the performance of the proposed GMOMPA is compared with well-known multi-objective optimization algorithms. The obtained results show that the proposed GMOMPA is a good tool for multi-objective optimization and has significant advantages over several state-of-the-art algorithms in almost all of the test functions.},
  archive      = {J_EAAI},
  author       = {Nour Elhouda Chalabi and Abdelouahab Attia and Abderraouf Bouziane and M. Hassaballah},
  doi          = {10.1016/j.engappai.2022.105718},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105718},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved marine predator algorithm based on epsilon dominance and pareto archive for multi-objective optimization},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parking demand forecasting based on improved complete
ensemble empirical mode decomposition and GRU model. <em>EAAI</em>,
<em>119</em>, 105717. (<a
href="https://doi.org/10.1016/j.engappai.2022.105717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parking demand forecasting plays an important role in relieving traffic congestion and reducing greenhouse gas emissions. However, most previous studies model based on historical data on parking itself or numerous factors that influences parking demand, which increase the complexity of the data and the time taken to run the model, resulting in a poor fit of the model to the extreme value points and not meeting the needs of practical applications. To address this issue, a hybrid prediction model based on improved complete ensemble empirical mode decomposition (ICEEMDAN) and gate recurrent unit (GRU) model for predicting parking demand, as well as a method called homogeneous linear mean interpolation to fill in the missing data were proposed in this paper. The ICEEMDAN algorithm was used to decompose the parking time series and reduce its complexity and nonlinearity. Based on the decomposed sequences, GRU neural networks were constructed for simultaneous training and prediction. Finally, the subsequences of the predicted output were aggregated. The effectiveness of the proposed model was validated using parking data collected from a large transportation hub parking lot. The experimental results show that compared with the single GRU model, the RMSE of the ICEEMDAN-GRU model is reduced by 59.29%, the MAE is reduced by 64.08%, and the R-square is improved by 4.93%. The ICEEMDAN-GRU model is the closest to the real parking time series. Therefore, this method is more effective than other models in parking demand forecasting.},
  archive      = {J_EAAI},
  author       = {Guangxin Li and Xiang Zhong},
  doi          = {10.1016/j.engappai.2022.105717},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105717},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parking demand forecasting based on improved complete ensemble empirical mode decomposition and GRU model},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intuitionistic fuzzy power aczel-alsina model for
prioritization of sustainable transportation sharing practices.
<em>EAAI</em>, <em>119</em>, 105716. (<a
href="https://doi.org/10.1016/j.engappai.2022.105716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion and environmental pollution generated by transportation activities significantly endanger the sustainable development of cities. This study presents a new strategy for implementing the concept of shared mobility, where postal operators use their widespread networks of units and serve as service providers. To enhance its real-world implementation, four sustainable transportation sharing practices are elaborated. The key question is how to identify the most sustainable alternative that should be offered by service providers. To resolve this challenge, this paper develops an advanced decision support model based on Aczel-Alsina aggregation operators and power operators within the intuitionistic fuzzy (IF) environment. The criteria weights are determined through the Shannon entropy-based power weighted method. Aczel-Alsina operations for IF numbers are proposed to aggregate the decision information. In light of these operational laws, two IF Aczel-Alsina aggregation operators and their enviable characteristics are provided. These advanced aggregation operators are used to formulate the IF power Aczel-Alsina model. The case study of the city of Novi Sad illustrates its applicability. According to the research findings, it is recommended that the public postal operator invests in a sharing e-bicycle fleet. The comparative investigation demonstrates the superiority of the developed decision support model. Its major strengths are simple calculation and fast information processing.},
  archive      = {J_EAAI},
  author       = {Tapan Senapati and Vladimir Simic and Abhijit Saha and Momcilo Dobrodolac and Yuan Rong and Erfan Babaee Tirkolaee},
  doi          = {10.1016/j.engappai.2022.105716},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105716},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intuitionistic fuzzy power aczel-alsina model for prioritization of sustainable transportation sharing practices},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative design of physical objects using modular
framework. <em>EAAI</em>, <em>119</em>, 105715. (<a
href="https://doi.org/10.1016/j.engappai.2022.105715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years generative design techniques have become firmly established in numerous applied fields, especially in engineering. These methods are crucial for automating the initial stages of the engineering design of various structures, which reduces the amount of routine work. However, existing approaches are limited by the specificity of the problem under consideration. In addition, they do not provide the desired flexibility in choosing a method for a particular problem. To avoid these issues, we proposed a general approach to an arbitrary generative design problem and implemented a novel open-source framework called GEFEST (Generative Evolution For Encoded STructure) on its basis. This approach is based on three general principles: sampling, estimation, and optimization. This ensures the freedom of method adjustment for the solution of the particular generative design problem and therefore enables the construction of the most suitable one. A series of experimental studies was conducted to confirm the effectiveness of the GEFEST framework. It involved synthetic and real-world cases (coastal engineering, microfluidics, thermodynamics, and oil field planning). The flexible structure of GEFEST makes it possible to obtain results that surpass baseline and state-of-the-art solutions: 12% improvement in the coastal engineering problem; 9% in microfluidics; 8% in thermodynamics and 7% in oil field planning.},
  archive      = {J_EAAI},
  author       = {Nikita O. Starodubcev and Nikolay O. Nikitin and Elizaveta A. Andronova and Konstantin G. Gavaza and Denis O. Sidorenko and Anna V. Kalyuzhnaya},
  doi          = {10.1016/j.engappai.2022.105715},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105715},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generative design of physical objects using modular framework},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-model data-fusion based deep transfer learning for
improved remaining useful life estimation for IIOT based systems.
<em>EAAI</em>, <em>119</em>, 105712. (<a
href="https://doi.org/10.1016/j.engappai.2022.105712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) estimation, a key component in predictive maintenance (PdM), aims to reduce maintenance cycles in the prognostic health of mechanical equipment(s). Research directions using deep-learning-based RUL estimation often suffer from limited availability of degradation signals resulting inaccurate predictions. Until now, state-of-the-art models trained on large sets of natural images to classify objects have not been re-used to improve regression-based RUL estimation accuracies of mechanical equipment. Actually, this is a rarely researched topic in PdM. Inspired by transfer learning, we showcase that the knowledge learned by popular pre-trained models can be transferred to improve industrial machinery-based-maintenance decision-making. Accordingly, this paper proposes a novel multi-model data-fusion-based deep transfer learning (MMF-DTL) framework for improved RUL estimation of rolling bearings through degradation images (DI) and pre-trained deep convolutional neural networks (CNNs). After procuring the degradation signals, we obtain DIs incorporating sufficient deterioration information using Markov Transition Fields. Next, these DIs are input into a DTL network comprising three pre-trained CNNs, i.e., DenseNet201, VGG16, and ResNet50, designed in a parallel fashion, where each constituent fine-tunes a different count of layers. Subsequently, features extracted from each component model are fused in a weighted manner and passed onto several fully connected layers. The effectiveness of the proposed framework is validated using the PHM Challenge 2012 bearing degradation dataset. Compared to several state-of-the-art works, our approach improves ∼ 12 . 57 % on error rate and ∼ 26 . 04 % on MAE, suggesting it is practically feasible to grasp transferable attributes from a general-purpose related dataset to another with minimal dataset size.},
  archive      = {J_EAAI},
  author       = {Sourajit Behera and Rajiv Misra},
  doi          = {10.1016/j.engappai.2022.105712},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105712},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-model data-fusion based deep transfer learning for improved remaining useful life estimation for IIOT based systems},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diverse features discovery transformer for pedestrian
attribute recognition. <em>EAAI</em>, <em>119</em>, 105708. (<a
href="https://doi.org/10.1016/j.engappai.2022.105708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Swin Transformer has been widely explored as a general backbone for computer vision, which helps to improve the performance of vision tasks due to the ability to establish associations for long-range dependencies of different spatial locations. By implementing the pedestrian attribute recognition with Swin Transformer, we observe that Swin Transformer tends to focus on a relatively small number of local regions within which attributes may be correlated with other attributes, which leads Swin Transformer to predict attributes in those neglected regions based on such correlation. In fact, discriminative information may exist within these neglected regions, which is crucial for attribute identification. To address this problem, we propose a novel diverse features discovery transformer (DFDT) which can find more attribute relationship regions for robust pedestrian attribute recognition. First, Swin Transformer is used as a feature extraction network to acquire attribute features with the long-distance association, which predicts the corresponding attribute information. Second, we propose a diverse features suppression module (DFSM) to obtain semantic features directly associated with attributes by suppressing the peak locations of the most discriminative features and randomly selected feature regions to spread the feature regions that Swin Transformer is interested in. Third, we plug the diverse features suppression module into different stages of Swin Transformer to learn detailed texture features to help recognition. In addition, we have divided the attribute features into multiple vertical feature regions to improve the focus on local attribute features. Experiments on three benchmark datasets validate the effectiveness of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Aihua Zheng and Huimin Wang and Jiaxiang Wang and Huaibo Huang and Ran He and Amir Hussain},
  doi          = {10.1016/j.engappai.2022.105708},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105708},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diverse features discovery transformer for pedestrian attribute recognition},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal salient object detection via adversarial learning
with collaborative generator. <em>EAAI</em>, <em>119</em>, 105707. (<a
href="https://doi.org/10.1016/j.engappai.2022.105707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal salient object detection(MSOD), which utilizes multimodal information (e.g., RGB image and thermal infrared or depth image) to detect common salient objects, has received much attention recently. Different modalities reflect different appearance properties of salient objects, some of which could contribute to improving the precision and/or recall of MSOD. To greatly improve both Precision and Recall by fully exploring multimodal data, in this work, we propose an effective adversarial learning framework based on a novel collaborative generator for accurate multimodal salient object detection. In particular, the collaborative generator consists of three generators (generator1, generator2 and generator3), which aim at decreasing the false positive and false negative of the generated saliency maps and improving F-measure of the final saliency maps respectively. Generator1 and generator2 contain two encoder–decoder networks for multimodal inputs, and we propose a new co-attention model to perform adaptive interactions between different modalities. Furthermore, we apply generator3 to integrate feature maps from generator1 and generator2 in a complementary way. Through adversarially learning the collaborative generator and discriminator, both Precision and Recall of the predicted maps are boosted with the complementary benefits of multimodal data. Extensive experiments on three RGBT datasets and six RGBD datasets show that our method performs quite well against state-of-the-art MSOD methods.},
  archive      = {J_EAAI},
  author       = {Zhengzheng Tu and Wenfang Yang and Kunpeng Wang and Amir Hussain and Bin Luo and Chenglong Li},
  doi          = {10.1016/j.engappai.2022.105707},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105707},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal salient object detection via adversarial learning with collaborative generator},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly supervised semantic segmentation via graph
RecalibratiOn with scaling weight uNit. <em>EAAI</em>, <em>119</em>,
105706. (<a
href="https://doi.org/10.1016/j.engappai.2022.105706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation (WSSS) has garnered considerable attention for its efficacy in generating pixel-level labels using weak labels. Class activation maps (CAMs) are utilized by WSSS to generate pseudo-masks from image-level labels. However, these CAMs primarily focus on the most discriminative features of an object, while less discriminative features may be ignored or unidentified. Due to co-occurring pixels, it may also be impossible to distinguish between the foreground and background. In this paper, we propose a method referred to as Graph RecalibratiOn with Scaling Weight uNit (GROWN) to address these challenges. It illustrates the relation between local and global features by utilizing graph structure. Adaptively representing the image’s semantic features is possible by scaling weights that aggregate contextual features. The proposed method successfully captures long-range dependencies and extracts contextual features to improve the pseudo-mask quality. As a result, the proposed method can predict pixel-level labels effectively. The datasets PASCAL VOC 2012 and MS COCO were utilized in the experiments. GROWN outperforms state-of-the-art WSSS methods that employ image-level labels, as demonstrated by the results.},
  archive      = {J_EAAI},
  author       = {Soojin Jang and JuneHyoung Kwon and KyoHoon Jin and YoungBin Kim},
  doi          = {10.1016/j.engappai.2022.105706},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105706},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Weakly supervised semantic segmentation via graph RecalibratiOn with scaling weight uNit},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Permutation jensen–shannon divergence for random permutation
set. <em>EAAI</em>, <em>119</em>, 105701. (<a
href="https://doi.org/10.1016/j.engappai.2022.105701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random Permutation Set (RPS) considers the permutation of elements for a certain set, which is an efficient tool for dealing with uncertainty with ordered information. An important feature of RPS theory is that in the fusion rule of RPS sources, the fusion order has a great impact on fusion results. However, how to determine the fusion order has not yet been discussed. To address this problem, this paper first proposes Permutation Jensen–Shannon (PJS) divergence for measuring the distance between two RPSs. Based on PJS divergence, a new Reliability Assessment algorithm, named RAPJS, is then presented for determining the fusion order of RPSs. The proposed PJS divergence satisfies the properties of non–degeneracy, boundary, and symmetry, and has desirable compatibility with Belief Jensen–Shannon divergence and Jensen–Shannon divergence under certain conditions. The presented RAPJS makes use of the divergence information to calculate the reliability degree of RPS sources, the RPS with a higher reliability is fused first. Experiment results in threat assessment reveal that the presented RAPJS algorithm can determine the fusion order reasonably and effectively. The assessment results using the proposed RAPJS algorithm has the highest target recognition rate compared to other results under different fusion orders.},
  archive      = {J_EAAI},
  author       = {Luyuan Chen and Yong Deng and Kang Hao Cheong},
  doi          = {10.1016/j.engappai.2022.105701},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105701},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Permutation Jensen–Shannon divergence for random permutation set},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video surveillance using deep transfer learning and deep
domain adaptation: Towards better generalization. <em>EAAI</em>,
<em>119</em>, 105698. (<a
href="https://doi.org/10.1016/j.engappai.2022.105698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, developing automated video surveillance systems (VSSs) has become crucial to ensure the security and safety of the population, especially during events involving large crowds, such as sporting events. While artificial intelligence (AI) smooths the path of computers to think like humans, machine learning (ML) and deep learning (DL) pave the way more, even by adding training and learning components. DL algorithms require data labeling and high-performance computers to effectively analyze and understand surveillance data recorded from fixed or mobile cameras installed in indoor or outdoor environments. However, they might not perform as expected, take much time in training, or not have enough input data to generalize well. To that end, deep transfer learning (DTL) and deep domain adaptation (DDA) have recently been proposed as promising solutions to alleviate these issues. Typically, they can (i) ease the training process, (ii) improve the generalizability of ML and DL models, and (iii) overcome data scarcity problems by transferring knowledge from one domain to another or from one task to another. Although the increasing number of articles proposed to develop DTL- and DDA-based VSSs, a thorough review that summarizes and criticizes the state-of-the-art is still missing. To that end, this paper introduces, to the best of the authors’ knowledge, the first overview of existing DTL- and DDA-based video surveillance to (i) shed light on their benefits, (ii) discuss their challenges, and (iii) highlight their future perspectives.},
  archive      = {J_EAAI},
  author       = {Yassine Himeur and Somaya Al-Maadeed and Hamza Kheddar and Noor Al-Maadeed and Khalid Abualsaud and Amr Mohamed and Tamer Khattab},
  doi          = {10.1016/j.engappai.2022.105698},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105698},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Video surveillance using deep transfer learning and deep domain adaptation: Towards better generalization},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning based multi-labelled soil classification and
empirical estimation toward sustainable agriculture. <em>EAAI</em>,
<em>119</em>, 105690. (<a
href="https://doi.org/10.1016/j.engappai.2022.105690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is the underlying occupation of the vast people in India and it is a major economic contribution. Soil is prime for the vital nutrient supply to the crops and its yield. Determination of the type of soil which comprises of the clay, sand and silt particles in the respective proportion is indeed significant for the suitable crop selection and to identify the weeds growth. The most commonly utilized soil determination methods were International Pipette method and Pressure-plate apparatus method. In this research work, multiclass soil classification using machine learning and deep learning models for the appropriate determination of the soil type as Multi-Stacking ensemble model and a novel feature selection algorithm Q-HOG is proposed; since the Artificial Intelligence has led to furtherance in the smart agriculture. Besides, the images are collected from the exploration site vriddhachalam along with the soil datasets will increase the classification accuracy. The deep learning models Recurrent Neural Network(RNN), Long Short Term Memory(LSTM), Gated Recurrent Unit(GRU) and VGG16 are considered and the comprehensive evaluation of these different deep learning architectures and also the machine learning algorithms such as Naïve-bayes, KNN, SVM are carried out and the obtained results are tabulated. Multi-stacking ensemble model for multi-classification is proposed with the Machine learning and deep learning algorithms and evaluated the performance with increased computation time. Among these models the proposed model outperformed in soil classification in-terms of accuracy as 98.96 percent, achieved precision as 96.14 percent, recall as 99.65 percent and the achieved F1-Score is 97.87 percent.},
  archive      = {J_EAAI},
  author       = {Padmapriya J. and Sasilatha T.},
  doi          = {10.1016/j.engappai.2022.105690},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105690},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning based multi-labelled soil classification and empirical estimation toward sustainable agriculture},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controlling highway toll stations using deep learning,
queuing theory, and differential evolution. <em>EAAI</em>, <em>119</em>,
105683. (<a
href="https://doi.org/10.1016/j.engappai.2022.105683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion is, nowadays, one of the most important highway problems. Highway tolls with booth operators are one of the causes of traffic congestion on highways, especially in rush hour periods, or during seasonal holiday travels. The value of driver waiting time (needed to stop and pay the toll) and the cost of the toll booth operators can reach up to about one-third of the revenue. In this paper we propose a novel methodology for continuous-time optimal control of highway tolls by predicting the optimal number of active modules (booths) in toll stations. The proposed methodology is based on a combination of recurrent neural networks, queuing theory, and metaheuristics. We utilized several recurrent neural network architectures for predicting the average intensity of vehicle arrivals. Moreover, the prediction error of the first recurrent neural network was modelled by another one in order to provide confidence estimates, additional regularization, and robustness. The predicted intensity of vehicle arrival rates was used as an input of the queuing model, whereas differential evolution was applied to minimize the total cost (waiting and service costs) by determining the optimal number of active modules on a highway toll in continuous time. The developed methodology was experimentally tested on real data from highway E70 in the Republic of Serbia. The obtained results showed significantly better performance compared to the currently used toll station opening pattern. The solutions obtained by solving a system of differential equations of the queuing model were also validated by a simulation procedure.},
  archive      = {J_EAAI},
  author       = {Andrija Petrović and Mladen Nikolić and Uglješa Bugarić and Boris Delibašić and Pietro Lio},
  doi          = {10.1016/j.engappai.2022.105683},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {105683},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Controlling highway toll stations using deep learning, queuing theory, and differential evolution},
  volume       = {119},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated clustering for recognizing driving styles from
private trajectories. <em>EAAI</em>, <em>118</em>, 105714. (<a
href="https://doi.org/10.1016/j.engappai.2022.105714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving style recognition of real-world drivers is beneficial for various reasons, such as safe and economic driving, auto-insurance and designing autonomous systems. A common way to achieve this goal is to group drivers using clustering methods according to their trajectory data. However, the conventional model training process is centralized, where all drivers’ private trajectories are collected and shared, which has resulted in privacy concerns. Considering that the driving data are sourced from various vehicles and have a decentralized distribution, we introduce a federated clustering approach for privacy-preserving driving style recognition. The method preserves the trajectory data in edge devices, such as connected vehicles or roadside units, and allows only the exchange of model parameters and not raw, sensitive data under the coordination of a central server to meet the privacy protection requirements. To address the clustering heterogeneous challenge posed by the imbalanced distribution of trajectory data in this setting, we combine local Bayesian Gaussian mixture and global weighted K-means to output high-quality global initialization centers. Then, novel local training and global aggregation strategies are proposed to ensure the convergence of training and improve the performance of the final global model. Through comparison experiments on benchmark and real-world datasets, we conclude that this method outperforms existing methods.},
  archive      = {J_EAAI},
  author       = {Lin Lu and Yao Lin and Yuan Wen and Jinxiong Zhu and Shengwu Xiong},
  doi          = {10.1016/j.engappai.2022.105714},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105714},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Federated clustering for recognizing driving styles from private trajectories},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-agent deep reinforcement learning for task offloading
in group distributed manufacturing systems. <em>EAAI</em>, <em>118</em>,
105710. (<a
href="https://doi.org/10.1016/j.engappai.2022.105710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of cloud computing and the Internet of Things (IoT) have facilitated near real-time optimization of the group distributed manufacturing systems. Currently, the most common technique to accomplish near-real-time optimization is cloud–edge cooperation for offloading optimization tasks. The tasks are partially offloaded to the cloud to be completed, and the remaining are kept at the edge. Due to the complexity of task offloading, such as capacity restrictions of cloud and edge computing resources, or task deadlines, unbalanced or insufficient tasks are offloaded to cloud and edge, causing time delay. To address the imbalance and insufficiency in the task offloading process, a mixed-integer programming model was developed to reduce the latency of task calculation. The task offloading problem is decomposed into two sub-problems: 1) Defining priorities for the tasks in near real-time. 2) Determining if the task is offloaded to the cloud. A multi-agent deep reinforcement learning with attention mechanism (MaDRLAM) framework is proposed to solve the two-step decision problem. The MaDRLAM framework consists of two agents, and each agent corresponds to a sub-problem. Each agent comprises an encoder and a decoder, and the two agents cooperate in devising an offloading strategy for the tasks. The Encoder and Decoder built for each agent are based on the Transformer structure. Unlike the traditional Transformer, we added the Pointer networks to the Transformer to solve the proposed decision problem. Besides, an improved multi-actor and single-critic strategy based on the REINFORCE algorithm is designed to train the proposed MaDRLAM. Finally, Extensive computational experiments are conducted on instances with a varying number of tasks, different task data sizes, and different cloud computing capacities. Computational results show that the proposed framework can find a solution with a GAP value of less than 1% within 1 s for each instance. The proposed framework is competitive in both solution accuracy and solution time compared with other offloading strategies.},
  archive      = {J_EAAI},
  author       = {Jianyu Xiong and Peng Guo and Yi Wang and Xiangyin Meng and Jian Zhang and Linmao Qian and Zhenglin Yu},
  doi          = {10.1016/j.engappai.2022.105710},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105710},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-agent deep reinforcement learning for task offloading in group distributed manufacturing systems},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of local and global wastewater biochemical
oxygen demand real-time prediction models using supervised machine
learning algorithms. <em>EAAI</em>, <em>118</em>, 105709. (<a
href="https://doi.org/10.1016/j.engappai.2022.105709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to shed light on a new understanding of global machine-learning (ML) prediction models for wastewater treatment plants (WWTPs). The paper evaluates the development of local and global prediction models to predict the wastewater influent biochemical oxygen demand (BOD5) in four WWTPs. The paper proposes an integrated framework of remote sensing and ML techniques, specifically decision tree, random forest, adaptive boosting, and gradient boost algorithms. The modeling considered two cases for local and global models. The local model’s best score achieved 0.92 coefficient of determination (R 2 ), 6.56 mean absolute error (MAE), and 1.00 R 2 , 0.08 MAE, respectively. In the second case, the global model’s best score achieved 0.58 R 2 , 20.73 MAE, and 0.95 R 2 , 3.93 MAE, respectively. The results showed that the developed local model reduced the BOD5 test results duration from five days to only three hours. However, in the first case, the developed global model failed to achieve good predictions against other WWTPs. This is due to the biological factors that change wastewater characteristics from one place to another. The study concluded that a local model is recommended to be developed for each WWTP separately. The novelty of this paper is that it investigates the various cases of testing the performance of the ML prediction models against different WWTPs than the one used to train and test. Also, it technically discusses the biological factors of wastewater that result in complications in ML modeling and prediction, which was never discussed or taken into consideration in ML literature.},
  archive      = {J_EAAI},
  author       = {Abdulaziz Sami Qambar and Mohammed Majid M. Al Khalidy},
  doi          = {10.1016/j.engappai.2022.105709},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105709},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of local and global wastewater biochemical oxygen demand real-time prediction models using supervised machine learning algorithms},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PVDet: Towards pedestrian and vehicle detection on
gigapixel-level images. <em>EAAI</em>, <em>118</em>, 105705. (<a
href="https://doi.org/10.1016/j.engappai.2022.105705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, gigapixel photography has been developed considerably and gradually put into remote sensing, video surveillance, etc. Gigapixel images have a visible field of view area at the square-kilometer level (containing thousands of targets) and up to 100 times the scale variation. Among them, the differences in target pose, scale, and occlusion are huge, and most existing target detection algorithms cannot directly process them. To solve these problems, we propose a new multi-target pedestrian and vehicle detector PVDet (Towards Pedestrian and Vehicle Detection on Gigapixel-level images) for gigapixel-level images. First, the DPRNet (Deformable deeP Residual Network) is designed as the backbone network to enhance the effective perceptual field and improve the feature representation of pose varying and occluded targets. Then, the PAFPN (Path Aggregation Feature Pyramid Network) is adopted to process the multi-scale features extracted by the backbone, boosting the multi-scale target modeling capability and the localization of small targets. Finally, the DyHead module is introduced to enhance the detection head’s scale, spatial and task awareness, further optimizing pedestrian and vehicle classification and localization. Compared with other State-of-the-Art methods on the PANDA dataset, the experimental results show that the proposed method dramatically improves AP of pedestrian and vehicle detection in gigapixel-level images by 10.4 AP over baseline, which is better than the existing target detection algorithms. We also conducted experiments on the PASCAL VOC 2012 dataset to further demonstrate the generalization capability and effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Wanghao Mo and Wendong Zhang and Hongyang Wei and Ruyi Cao and Yan Ke and Yiwen Luo},
  doi          = {10.1016/j.engappai.2022.105705},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105705},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PVDet: Towards pedestrian and vehicle detection on gigapixel-level images},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Saliency and ballness driven deep learning framework for
cell segmentation in bright field microscopic images. <em>EAAI</em>,
<em>118</em>, 105704. (<a
href="https://doi.org/10.1016/j.engappai.2022.105704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell segmentation is the most significant task in microscopic image analysis as it facilitates differential cell counting and analysis of sub-cellular structures for diagnosing cytopathological diseases. Bright-field microscopy is considered the gold standard among different types of optical microscopes used for cell analysis due to its simplicity and cost-effectiveness. However, automatic cell segmentation in bright field microscopy is challenging due to imaging artifacts, poor contrast, overlapping cells, and wide variability of cells. Also, the availability of labeled bright-field images is limited, further constraining the research in developing supervised models for automated cell segmentation. In this research, we propose a novel cell segmentation framework termed Saliency and Ballness driven U-shaped Network (SBU-net) to overcome these challenges. The proposed architecture comprises a novel data-driven feature fusion module that enhances the perceivable structure of cells using its saliency and ballness features. This, together with an encoder–decoder model having dilated convolutions and a novel combination loss function, captured the global context of cell structures and produced accurate cell segmentation results. SBU-net is evaluated using two publicly available bright-field datasets of T cells and pancreatic cancer cells. The model is subjected to 5-fold cross-validation and outperformed state-of-the-art models by producing mean Intersection over Union (IoU) scores of 0.804, 0.829, and mean Dice of 0.891, 0.906, respectively. The architecture was also tested on a fluorescent dataset to see how well it could generalize, and it came out with a mean IoU of 0.892 and a mean Dice of 0.948, outperforming other models reported in the literature.},
  archive      = {J_EAAI},
  author       = {S.B. Asha and G. Gopakumar and Gorthi R.K. Sai Subrahmanyam},
  doi          = {10.1016/j.engappai.2022.105704},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105704},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Saliency and ballness driven deep learning framework for cell segmentation in bright field microscopic images},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). RFIA-net: Rich CNN-transformer network based on asymmetric
fusion feature aggregation to classify stage i multimodality oesophageal
cancer images. <em>EAAI</em>, <em>118</em>, 105703. (<a
href="https://doi.org/10.1016/j.engappai.2022.105703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Endoscopic images of oesophageal cancer have the characteristics of rich colours; furthermore, the small lesions are similar to the oesophageal wall tissue, and the pathological images have the characteristics of various staining methods, different shapes, and rich texture details. Aiming at the above characteristics and combining the unique advantages of convolutional architectures and the development of vision transformers in computer vision tasks, in this paper, for the stage I multimodality oesophageal cancer image classification task, we design an efficient hybrid architecture that leverages the local modelling capabilities and powerful semantic feature extraction capabilities of convolutional neural networks and the ability of transformers to extract global information. And combined with the structural reparameterization strategy to further improve the model expression. Specifically, our architecture consists of a feature extraction module and a feature enhancement module. In the feature enhancement module, we supplement the semantic information of each branch by continuously exchanging information between the two branches, which further improves the performance of the network. Furthermore, we propose an asymmetric fusion module that allows features to further enhance the feature relationships between different branches through spatial translation and channel swapping. Compared with networks such as ResNet-18, our proposed method achieves the best results for oesophageal cancer image classification on both tasks on the XJMU-XJU stage I multimodal oesophageal cancer dataset. The proposed method achieved an AUC of 0.9973 and an ACC of 0.9902 on the staging task and achieved a recall of 0.9742 and an ACC of 0.9750 on the differentiation task.},
  archive      = {J_EAAI},
  author       = {Zhicheng Zhou and Gang Sun and Long Yu and Shengwei Tian and Guangli Xiao and Junwen Wang and Shaofeng Zhou},
  doi          = {10.1016/j.engappai.2022.105703},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105703},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RFIA-net: Rich CNN-transformer network based on asymmetric fusion feature aggregation to classify stage i multimodality oesophageal cancer images},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fuzzy convolutional attention-based GRU network for human
activity recognition. <em>EAAI</em>, <em>118</em>, 105702. (<a
href="https://doi.org/10.1016/j.engappai.2022.105702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition has become a pillar of today intelligent Human–Computer Interfaces as it typically provides more comfortable and ubiquitous interaction. This paper proposes a novel fuzzy-based deep learning-based algorithm to predict future sequences of activities from a given sequence of daily living activities of a subject wearing a lower limb exoskeleton. The engineering application concerns the challenging task of recognizing locomotion activities of the wearer in real-time, which is needed to ensure appropriate control of the robot during daily living activities. Indeed, real-time locomotion activity recognition is very challenging for controlling lower-limb exoskeletons. The model proposes a new adaptive kernel, based on the data features derived from the fuzzy rules on the input sequences to enrich the features of the activity sequences. Then, a CNN is applied to extract local subsequences from the whole sequences to identify local patterns in the convolution window. Finally, an attention-based GRU is incorporated into the model to extract meaningful parts of the time-series sequences. The results show high accuracy in the estimation of the transition between gait modes which is critical to ensure smooth control of the exoskeleton. The performance of the model is evaluated using the dynamic activity data gathered from different subjects. The proposed model outperforms the traditional models used in the literature.},
  archive      = {J_EAAI},
  author       = {Ghazaleh Khodabandelou and Huiseok Moon and Yacine Amirat and Samer Mohammed},
  doi          = {10.1016/j.engappai.2022.105702},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105702},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fuzzy convolutional attention-based GRU network for human activity recognition},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Research on significant factors affecting adoption of
blockchain technology for enterprise distributed applications based on
integrated MCDM FCEM-MULTIMOORA-FG method. <em>EAAI</em>, <em>118</em>,
105699. (<a
href="https://doi.org/10.1016/j.engappai.2022.105699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology-powered applications infuse trust in the system without intermediary entities. Researchers’ interest in blockchain technology has increased dramatically in recent years as a result of this distinguishing feature. However, the adoption of this novel paradigm in enterprise distributed applications is not very encouraging. To adopt a new technology in an industry, managers and technocrats have to do multiple-criteria decision-making (MCDM) in a fuzzy environment. The aim of this study is to propose a system model for the identification and monitoring of significant factors responsible for the slow adoption rate of blockchain technology. In this research, the MULTIMOORA method for group decision-making, a popular MCDM approach, has been further extended by integrating the information entropy weight–fuzzy comprehensive evaluation model (IEW-FCEM) for an uncertain environment. The proposed method of FCEM-MULTIMOORA-FG combines the benefits of four best-in-class ranking methods, namely, the fuzzy ratio system, the fuzzy reference point method, the fuzzy full multiplicative form, and the IEW-FCEM. The idea behind integrating the IEW-FCEM with MULTIMOORA-FG is that information entropy will derive the objective weights of the criteria, thus removing the dependency upon subject matter expert experience only. An empirical study demonstrates the efficacy and practicability of the FCEM-MULTIMOORA-FG method. The simulation results demonstrate that the proposed method is computationally straightforward with better position accuracy than previous algorithms and that its basic idea is logical and understandable, making it easier to apply in a computer system. Additionally, a comparative analysis with five more MCDM methods was executed to validate the results.},
  archive      = {J_EAAI},
  author       = {Zeeshan Ali Siddiqui and Mohd. Haroon},
  doi          = {10.1016/j.engappai.2022.105699},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105699},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on significant factors affecting adoption of blockchain technology for enterprise distributed applications based on integrated MCDM FCEM-MULTIMOORA-FG method},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Review of artificial intelligence applications in
engineering design perspective. <em>EAAI</em>, <em>118</em>, 105697. (<a
href="https://doi.org/10.1016/j.engappai.2022.105697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Having passed the primitive phases and starting to revolutionize many different fields in some way, artificial intelligence is on its way to becoming a disruptive technology. It is also foreseen to totally change human-centred traditional engineering design approaches. Although still in the early phases, AI-powered engineering applications enable them to work with ambiguous design parameters and solve complex engineering problems, not otherwise possible with traditional design methods. This work attempts to shine a light on current progress and future research trends in AI applications in design/engineering design concepts, covering the last 15 years which is the ramp-up period for AI. Methods such as machine learning, genetic algorithm, and fuzzy logic have been carefully examined from an engineering design perspective. AI-powered design studies have been categorized and critically reviewed for various design stages such as inspiration, idea and concept generation, evaluation, optimization, decision-making, and modelling. As an overview result of this review, we can confidently say that the interest in data-based design methods and Explainable Artificial Intelligence (XAI) has increased in recent years. Furthermore, the use of AI methods in engineering design applications helps to obtain efficient, fast, accurate, and comprehensive results. Especially with deep learning methods and combinations, situations where human capacity is insufficient can be addressed efficiently. However, choosing the right AI method for a design problem under consideration is significantly important for such successful results. Hence, we have given an outline perspective on choosing the right AI method based on the literature outcomes for design problems.},
  archive      = {J_EAAI},
  author       = {Nurullah Yüksel and Hüseyin Rıza Börklü and Hüseyin Kürşad Sezer and Olcay Ersel Canyurt},
  doi          = {10.1016/j.engappai.2022.105697},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105697},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review of artificial intelligence applications in engineering design perspective},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive sparse general regression neural network-based
force observer for teleoperation system. <em>EAAI</em>, <em>118</em>,
105689. (<a
href="https://doi.org/10.1016/j.engappai.2022.105689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restricted by factors such as small robot size and harsh operating environment, the inability to obtain the interaction force between the robot arm and the environment through force sensors has become problematic in promoting the application of teleoperation systems in minimally invasive surgery, nuclear waste cleanup, and other fields. To accurately obtain the interaction force without the force sensors, a force observer based on an adaptive sparse general regression neural network (ASGRNN) is proposed in this paper. The proposed force observer uses a machine learning-based approach to obtain estimated force, thus eliminating the need for the dynamic parameters of the robot arm. Also, an innovative feature selection method incorporating the wrapper method and sparse regularization is proposed to select the input features of the force observer. Secondly, two new criteria are defined to eliminate the useless support vectors in the model. In addition, an improved antlion optimization algorithm (IALO) is proposed to optimize the bandwidth parameters of the model. To verify the performance of the proposed force observer, a 6-degree-of-freedom teleoperation robot experimental platform is built and compared with three existing force estimation models. The results show that the proposed force observer outperforms the existing model in terms of estimation accuracy, and the mean square error (MSE) is at least 35.79% lower than the existing model. In conclusion, this paper provides a feasible and effective force observer for a teleoperation system where force sensors are not applicable and dynamic parameters are non-knowable.},
  archive      = {J_EAAI},
  author       = {Mingzhang Pan and Jing Li and Qiye Yang and Yupeng Wang and Yu Tang and Lei Pan and Xianbao Jiang and Yizhong Lin and Ke Liang},
  doi          = {10.1016/j.engappai.2022.105689},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105689},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive sparse general regression neural network-based force observer for teleoperation system},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforcement learning based computational intelligence
approach for binary optimization problems: The case of the set-union
knapsack problem. <em>EAAI</em>, <em>118</em>, 105688. (<a
href="https://doi.org/10.1016/j.engappai.2022.105688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As today’s one of the hottest topics, machine learning brings about opportunities in various research areas. Moreover, computational intelligence and metaheuristics open up new strategies, which are shown to be efficient in solving optimization problems. However, studies bringing such remarkable approaches together are still lacking. In this context, the present paper introduces a Q-learning reinforcement learning strategy for binary optimization problems. The developed algorithm works as a reinforcement and recommendation system that evaluates the used algorithms, assigns rewards, promotes or demotes them. Thus, it invokes more promising optimizers more frequently. The proposed Q-learning algorithm uses Particle Swarm Optimization (PSO), Genetic Algorithm and a hybrid of these algorithms, namely, genetic-based PSO (gbPSO) as optimizers. Therefore, it is aimed to avoid local optima by using various optimizers and gathering additional statistical data. Secondarily, all optimizers are further enhanced by adopting an initial solution generation technique and triggered random immigrants mechanism to preserve swarm diversity. In addition to these procedures, a mutation procedure that decreases the diversity is adopted. Thus, more intensified search is encouraged towards the end of search. Moreover, while PSO requires for transfer functions in order to perform in binary spaces, the adopted and further improved gbPSO does not necessarily need such auxiliary procedures. Finally, the performances of all used algorithms are analysed on a recently caught on binary problem, namely, the set-union knapsack problem, which has a wide range of real-life applications. As demonstrated by the comprehensive experimental study and appropriate statistical tests, promising improvements are achieved.},
  archive      = {J_EAAI},
  author       = {Fehmi Burcin Ozsoydan and İlker Gölcük},
  doi          = {10.1016/j.engappai.2022.105688},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105688},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reinforcement learning based computational intelligence approach for binary optimization problems: The case of the set-union knapsack problem},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable knowledge-guided framework for modeling
minimum miscible pressure of CO2-oil system in CO2-EOR projects.
<em>EAAI</em>, <em>118</em>, 105687. (<a
href="https://doi.org/10.1016/j.engappai.2022.105687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon dioxide enhanced oil recovery (CO 2 -EOR) is a promising application for carbon capture, utilization and storage (CCUS). Accurate modeling of CO 2 -oil minimum miscible pressure (MMP) is crucial for CO 2 -EOR projects. In this study, a knowledge-guided framework for an extreme gradient boosting machine (XGBoost) and interpretable tabular learning architecture (TabNet), called KXGB and KTabNet, respectively, are developed to model the MMP. The proposed models are strengthened using a large MMP database of 421 samples collected from literature. Domain knowledge is integrated into intelligent models to prevent data-driven models from producing predictions that violated the domain knowledge. The Shapley Additive Explanations (SHAP) method is used to explain the proposed model to ensure the credibility of petroleum engineers. To further verify the model’s effectiveness, the same experimental strategy is employed to compare the proposed models with existing machine-learning (ML) methods. The results show that KXGB is the most recommended superior solution for modeling MMP owing to its outstanding performance and simplicity of optimization. The correlation coefficient, root mean square error, and mean absolute error are 0.9833, 0.7637 and 0.55, respectively. However, KTabNet has great potential. Although its accuracy is slightly lower than that of the former, its strong representation ability and decision transparency may be favorable for future research. This study also demonstrate that the proposed framework conforms to certain theoretical rules and has a reasonable domain of applicability. To the best of our knowledge, this is the first study on integration of domain knowledge into MMP modeling methods. The experience and insights obtained from this study can guide CO 2 -EOR projects and other tabular data modeling in the oil and gas industry.},
  archive      = {J_EAAI},
  author       = {Bin Shen and Shenglai Yang and Xinyuan Gao and Shuai Li and Kun Yang and Jiangtao Hu and Hao Chen},
  doi          = {10.1016/j.engappai.2022.105687},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105687},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable knowledge-guided framework for modeling minimum miscible pressure of CO2-oil system in CO2-EOR projects},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint deep reversible regression model and physics-informed
unsupervised learning for temperature field reconstruction.
<em>EAAI</em>, <em>118</em>, 105686. (<a
href="https://doi.org/10.1016/j.engappai.2022.105686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temperature monitoring over heat source components in engineering systems, such as the energy system, electronic equipments, becomes essential to guarantee the working performance of these components. However, prior methods, which mainly use the interpolate estimation to reconstruct the overall temperature field from limited monitoring points, require large amounts of temperature tensors for an accurate estimation. This may affect the availability and reliability of the system. To solve the problem, this work develops a novel reconstruction method which joints the deep reversible regression model and physics-informed unsupervised learning for temperature field reconstruction of heat-source systems (TFR-HSS). Firstly, we define the TFR-HSS mathematically, numerically model the system with discrete grids, and hence transform the task as an image-to-image regression problem. Then, this work develops the deep reversible regression model which can better learn physical information, especially over the area near the boundaries of the system. Finally, this work proposes the physics-informed reconstruction loss with the physical characteristics of the system and learns the deep model without labelled samples. Experimental studies have conducted over typical two-dimensional heat-source systems to validate the effectiveness of the proposed method. Under the proposed method, the mean average error of the constructed temperature field can achieve about 0.1K, 50% lower than other methods. Besides, the proposed method takes 5.2 ms per sample for inference which can provide real-time predictions.},
  archive      = {J_EAAI},
  author       = {Zhiqiang Gong and Weien Zhou and Jun Zhang and Wei Peng and Wen Yao},
  doi          = {10.1016/j.engappai.2022.105686},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105686},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Joint deep reversible regression model and physics-informed unsupervised learning for temperature field reconstruction},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VB-DeepONet: A bayesian operator learning framework for
uncertainty quantification. <em>EAAI</em>, <em>118</em>, 105685. (<a
href="https://doi.org/10.1016/j.engappai.2022.105685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network based data-driven operator learning schemes have shown tremendous potential in computational mechanics. DeepONet is one such neural network architecture which has gained widespread appreciation owing to its excellent prediction capabilities. Having said that, being set in a deterministic framework exposes DeepONet architecture to the risk of overfitting, poor generalization and in its unaltered form, it is incapable of quantifying the uncertainties associated with its predictions. To address these challenges, we propose a novel Bayesian operator learning framework referred to as the Variational Bayes DeepONet (VB-DeepONet). VB-DeepONet is rooted in Bayesian statistics and hence, (a) is less prone to overfitting as compared to its deterministic counterpart, (b) has better generalization, and (c) yields predictive uncertainty which is instrumental when decision making is concerned. VB-DeepONet exploits variational inference and hence has the capacity to take into account high dimensional posterior distributions while keeping the associated computational cost reasonable. Different examples covering mechanics problems like diffusion reaction, gravity pendulum, advection diffusion have been considered to illustrate the performance of the proposed VB-DeepONet and comparisons have been drawn against DeepONet set in deterministic framework, Proper Orthogonal Decomposition based Gaussian Process and DenseED. The results obtained illustrate the efficacy of the proposed approach in solving uncertainty quantification problems.},
  archive      = {J_EAAI},
  author       = {Shailesh Garg and Souvik Chakraborty},
  doi          = {10.1016/j.engappai.2022.105685},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105685},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {VB-DeepONet: A bayesian operator learning framework for uncertainty quantification},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed time synchronization of octonion valued neural
networks with time varying delays. <em>EAAI</em>, <em>118</em>, 105684.
(<a href="https://doi.org/10.1016/j.engappai.2022.105684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Octonion valued neural networks (OVNNs) does not fall into the category of Clifford valued neural networks because of the non-associativity of OVNNs. The present article contains the study of fixed time synchronization of OVNNs with time varying delays. Fixed time synchronization is an extension of the finite time synchronization. In fixed time synchronization, the trajectories of the error system reaches the origin in finite time independent of the initial conditions. In this article, OVNNs are decomposed into eight real valued systems of equations. Using some lemmas and Lyapunov function, several sufficient criteria have been derived for the fixed time synchronization. Moreover, a suitable novel non-linear controller is created to keep the drive–response system in synchronization state. Finally, a numerical example is performed to demonstrate and validate the theoretical findings.},
  archive      = {J_EAAI},
  author       = {Shiv Shankar Chouhan and Umesh kumar and Subir Das and Jinde Cao},
  doi          = {10.1016/j.engappai.2022.105684},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105684},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fixed time synchronization of octonion valued neural networks with time varying delays},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrated lot-sizing and scheduling: Mitigation of
uncertainty in demand and processing time by machine learning.
<em>EAAI</em>, <em>118</em>, 105676. (<a
href="https://doi.org/10.1016/j.engappai.2022.105676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production rescheduling is one of the most challenging problems in production management, in which some parameters, such as customer demand and job processing time, are subject to uncertainty during the planning horizon. This paper develops a scheduling and rescheduling method for the simultaneous lot-sizing and job shop scheduling problem, considering sequence-dependent setup times and capacity constraints. The objective is to find a trade-off between safety levels and production costs focusing on schedulability and optimality as the two most important performance indicators in the face of uncertainty. Therefore, a new adjustable formulation based on satisfiability modulo theories has been developed to tackle the demand and processing time uncertainty. Then, a combination of neural networks and a K-means based heuristic was applied to calibrate the model by determining the profitable value of the safety levels as a strategy to increase the robustness of the schedule. We also developed a Monte Carlo simulation to assess the performance of the proposed algorithm and compare it with other approaches addressed in the literature. The computational results show that the proposed algorithm is efficient and promising in protecting the schedulability of the model, taking the optimality criterion into account.},
  archive      = {J_EAAI},
  author       = {Mohammad Rohaninejad and Mikoláš Janota and Zdeněk Hanzálek},
  doi          = {10.1016/j.engappai.2022.105676},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105676},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrated lot-sizing and scheduling: Mitigation of uncertainty in demand and processing time by machine learning},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessment of the spatiotemporal prediction capabilities of
machine learning algorithms on sea surface temperature data: A
comprehensive study. <em>EAAI</em>, <em>118</em>, 105675. (<a
href="https://doi.org/10.1016/j.engappai.2022.105675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal time series prediction plays a crucial role in a wide range of applications. However, in most of the studies, spatial information was ignored and predictions were carried out either on a few points or on average values. In this study, 37 different configurations of 4 traditional ML models and 3 Neural Network (NN) based models were utilized to provide a comprehensive comparison and evaluate the spatiotemporal data prediction capabilities of the ML models. Additionally, to reveal the importance of spatial data for the time series prediction process, the best configuration of each ML model was evaluated with and without using spatial information. The utilized models were: (i) Linear Regression (LR), (ii) K-Nearest Neighbors (KNN), (iii) Decision-Trees (DT), (iv) Support Vector Machine (SVM), (v) Multi-Layer Perceptron (MLP), (vi) Long Short-Term Memory (LSTM), and (vii) Gated Recurrent Unit (GRU). The study was performed on the Sea Surface Temperature (SST) data collected by satellite radiometers via infrared measurements. The models were evaluated according to their one-month ahead spatiotemporal SST prediction performance over the southern coasts of Turkey, and the effects of spatial information on model performance were presented. Results reveal that the spatial information increased the prediction performance by approximately 25%, in terms of RMSE. Additionally, acquired results show that the LSTM model outperforms all other ML models and gives the smallest prediction errors in all metrics.},
  archive      = {J_EAAI},
  author       = {Serkan Kartal},
  doi          = {10.1016/j.engappai.2022.105675},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105675},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessment of the spatiotemporal prediction capabilities of machine learning algorithms on sea surface temperature data: A comprehensive study},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical concept bottleneck models for vision and their
application to explainable fine classification and tracking.
<em>EAAI</em>, <em>118</em>, 105674. (<a
href="https://doi.org/10.1016/j.engappai.2022.105674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the explainability of Computer Vision models based on Deep Learning has recently become a compelling problem, ensuring reliable predictions to the end-user and enabling more fine-grained classifications. Recently, Concept Bottleneck models have been proposed for images classification, partitioning the problem in two stages and thereby defining a hierarchy of concepts. So far, however, little work has been done to investigate the applicability of this approach to other datasets with higher intra-class variability and ambiguity, and to discuss its flexibility to tasks different from whole-images classification. In this work we develop and discuss a Concept Bottleneck model for images segmentation, objects fine classification and tracking, and compare it to more classical methods based on Mask R-CNN and images similarity algorithms. All our models are trained and tested on a dataset comprised of pictures of fridges filled with various objects, however the method can be applied to any fine classification task. The proposed model makes full use of the hierarchy in concepts, exploiting the relationships between different categories at the same hierarchical level and relying on a novel method for handling multi-labels classifications. We show that the performance on fine classification is on par with a regular Mask R-CNN, but with a significant increase in explainability and in handling classes confusion. New explainable metrics are proposed to quantitatively evaluate the increase in explainability. We also demonstrate the effectiveness of the derived Concept Bottleneck features on related tasks, i.e., the tracking of objects between consecutive pictures in a sequence. The code is released as open source and available at https://opensource.silicon-austria.com/pittinof/hierarchical-concept-bottleneck .},
  archive      = {J_EAAI},
  author       = {Federico Pittino and Vesna Dimitrievska and Rudolf Heer},
  doi          = {10.1016/j.engappai.2022.105674},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105674},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical concept bottleneck models for vision and their application to explainable fine classification and tracking},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TFG-net: Tropical cyclone intensity estimation from a
fine-grained perspective with the graph convolution neural network.
<em>EAAI</em>, <em>118</em>, 105673. (<a
href="https://doi.org/10.1016/j.engappai.2022.105673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tropical Cyclone Intensity Estimation (TIE) is a fundamental study subject for tropical cyclone development, flood or landslide avoidance, etc. Despite considerable efforts, two main challenges remain unresolved in this critical endeavor. The first challenge is that the TIE task is frequently conducted as a coarse-grained recognition problem rather than a fine-grained one. The second challenge is that the prediction fails to consider general wind speed information. To conquer these two challenges, we offer a novel model, namely Tropical cyclone intensity estimation from a Fine-grained perspective with the Graph convolution neural Network (TFG-Net). It is composed of three key components, viz., the Backbone, the Fine-grained Tropical cyclone Features Extractor (FTFE), and the Wind Scale Transition Rule Generator (WTRG), which aim at extracting general spatial features, subtle spatial features, and general wind speed information, respectively. To validate the proposed method, extensive experiments on a well-known real-world tropical dataset named GridSat were carried out. Following the standard benchmark task setting that the model estimates the wind speed from a given satellite image, the proposed TFG-Net reaches 11.12 knots in the RMSE metric, which outperforms 33.33%, 2.54% to the traditional method and the state-of-the-art deep learning method, respectively. The code is available on GitHub: https://github.com/xuguangning1218/TI_Estimation and its reproductive result is available on Code Ocean: https://doi.org/10.24433/CO.6606867.v1 .},
  archive      = {J_EAAI},
  author       = {Guangning Xu and Yan Li and Chi Ma and Xutao Li and Yunming Ye and Qingquan Lin and Zhichao Huang and Shidong Chen},
  doi          = {10.1016/j.engappai.2022.105673},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105673},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TFG-net: Tropical cyclone intensity estimation from a fine-grained perspective with the graph convolution neural network},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-attribute strategic weight manipulation with minimum
adjustment trust relationship in social network group decision making.
<em>EAAI</em>, <em>118</em>, 105672. (<a
href="https://doi.org/10.1016/j.engappai.2022.105672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social network group decision making (SNGDM), multi-attribute strategic weight manipulation refers to adjusting expert trust relationships to determine a strategic attribute weight for getting a coordinator’s desired ranking results. We suggest a model of strategic weight manipulation with a minimum adjustment trust relationship to achieve the strategic attribute weight, motivated by the desire to reduce the adjustments. Then, in order to find the best solution for the suggested model, a method based on the mixed 0–1 linear programming models (MLPMs) was employed. Additionally, one desired property is provided in order to achieve a strategic attribute weight depending on the ranking range in social network situations. Finally, the efficiency of our suggested models is confirmed using a numerical example, and two simulation experiments are created to provide to compare weighted averaging (WA) and ordered weighted averaging (OWA). Because the OWA has a larger value of minimum adjustment when manipulating a strategic attribute weight, we argue that: (1) the OWA has a better performance in defending against strategic weight manipulation than the WA; (2) as the number of trust relationships and experts increases, the performance gap between the two approaches gets smaller.},
  archive      = {J_EAAI},
  author       = {Yating Liu and Haiming Liang and Yucheng Dong and Yongfeng Cao},
  doi          = {10.1016/j.engappai.2022.105672},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105672},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-attribute strategic weight manipulation with minimum adjustment trust relationship in social network group decision making},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 2-tuple linguistic decision-making with consistency
adjustment strategy and data envelopment analysis. <em>EAAI</em>,
<em>118</em>, 105671. (<a
href="https://doi.org/10.1016/j.engappai.2022.105671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {2-tuple linguistic preference relations (2-TLPRs) are useful tools for addressing decision-making issues where the decision makers (DMs) are inclined to apply linguistic variables to express evaluation information. To retain the DM’s initial preference information as much as possible, this paper provides a 2-tuple linguistic decision-making method that incorporates a consistency adjustment algorithm and a 2-tuple linguistic data envelopment analysis (DEA) model. As two important aspects of decision-making, it is worthy to further study the improvements in consistency and weight generation for alternatives with 2-TLPRs. In this paper, in order to adjust the consistency of an original 2-TLPR to a predetermined level, a convergent consistency-improving algorithm is first presented, and we employ a minimum adjustment strategy to preserve the DM’s initial evaluation information. A 2-tuple linguistic DEA model is then developed to generate a vector of weights for the alternatives and we can derive reliable decision-making results. Finally, we provide a numerical example that can identify the most influential factor in Fog–haze weather to indicate the applicability of the 2-tuple linguistic decision-making method. The comparative analysis highlights the advantages and effectiveness of the 2-tuple linguistic decision-making method.},
  archive      = {J_EAAI},
  author       = {Feifei Jin and Shuyan Guo and Yuhang Cai and Jinpei Liu and Ligang Zhou},
  doi          = {10.1016/j.engappai.2022.105671},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105671},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {2-tuple linguistic decision-making with consistency adjustment strategy and data envelopment analysis},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RepuTE: A soft voting ensemble learning framework for
reputation-based attack detection in fog-IoT milieu. <em>EAAI</em>,
<em>118</em>, 105670. (<a
href="https://doi.org/10.1016/j.engappai.2022.105670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impetuous expansion of the Internet of Things (IoT) network has resulted in a noticeable increase in the production of sensitive user data. With this, to meet the demand for real-time response, a processing layer is introduced near the user end which is known as the fog computing layer. The fog layer lies in the user’s vicinity and thus highly attracts malicious and/or curious intruders. As a result, the trust of the network gets negatively impacted. Motivated by the aforementioned issue, the authors consider Reputation-based trust and propose a RepuTE Framework in the Fog-IoT domain. The given framework consists of a soft voting ensemble learning model that classifies and predicts two popular reputation-based attacks namely, DoS/ DDoS and Sybil attacks. Furthermore, a novel feature selection technique is also presented that selects the most relevant features well in advance. The performance evaluation is done on NSL-KDD, CICDDOS2019, IoTID20, NBaIoT2018, TON_IoT, and UNSW_NB15 benchmarked IoT and network traffic datasets. The comprehensive performance analysis depicts that the proposed model attains 99.99% accuracy and outperforms other recent state-of-the-art works. This indicates the potential of the proposed approach for reputation-based attack filtration in the IoT domain.},
  archive      = {J_EAAI},
  author       = {Richa Verma and Shalini Chandra},
  doi          = {10.1016/j.engappai.2022.105670},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105670},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RepuTE: A soft voting ensemble learning framework for reputation-based attack detection in fog-IoT milieu},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Imbalanced tabular data modelization using CTGAN and machine
learning to improve IoT botnet attacks detection. <em>EAAI</em>,
<em>118</em>, 105669. (<a
href="https://doi.org/10.1016/j.engappai.2022.105669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has been trending in the past few years, posing so many security problems. IoT Botnets are one of the most serious attacks that threaten the reliability of IoT systems because of IoT devices resources constraints. Most of the classical and even the intelligent solutions such as ML and DL for botnet detection are trained on unlabeled dataset, in other cases, dataset trustability is not approved but it is used, which may cause degradation of performance in case those models were implemented in security tools in order to deal with zero-day threats. Another two critical problems are the limits of classical oversampling methods while generating samples and the limits of understanding complex datasets and modeling real tabular data by the existing GAN models. The aim of this paper is to implement the CTGAN model, the state-of-the-art of Generative Adversarial Networks models in tabular data modeling and generation in order to overcome all previous mentioned limits. The results are promising. After data augmentation using CTGAN, MLP achieves an accuracy of 98.93%, F1-Score equal to 0.9907, Geometric-Score equal to 0.9874, sensitivity and specificity achieve resp. values of 0.9893 and 0.9856.},
  archive      = {J_EAAI},
  author       = {Omar Habibi and Mohammed Chemmakha and Mohamed Lazaar},
  doi          = {10.1016/j.engappai.2022.105669},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105669},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Imbalanced tabular data modelization using CTGAN and machine learning to improve IoT botnet attacks detection},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Inverse dynamics modelling and tracking control of conical
dielectric elastomer actuator based on GRU neural network.
<em>EAAI</em>, <em>118</em>, 105668. (<a
href="https://doi.org/10.1016/j.engappai.2022.105668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents intelligent modelling and tracking control methods for a conical dielectric elastomer actuator (CDEA) utilized in soft robots. Firstly, an inverse dynamics model (IDM) of the CDEA is established based on a gated recurrent unit neural network. Then, the IDM is directly taken as a feed-forward compensation controller to compensate the complex “memory” characteristic (mainly including the hysteresis nonlinearity and the creep nonlinearity) of the CDEA in its tracking control. Next, a proportional integral feedback controller is devised to cooperate with the compensating controller to enhance the tracking control performance. Lastly, some tracking control experiments with various target trajectories are implemented to demonstrate the validity of the presented methods. Different from traditional methods, using the proposed method can directly construct the compensating controller, thereby avoiding the complicated calculation of the analytical inverse of the dynamics model. Moreover, the fitness values of the results of tracking control experiments are higher than 93.6%, and the root-mean-square errors are lower than 1.3%. Therefore, the proposed intelligent modelling and tracking control methods are superior.},
  archive      = {J_EAAI},
  author       = {Yue Zhang and Jundong Wu and Peng Huang and Chun-Yi Su and Yawu Wang},
  doi          = {10.1016/j.engappai.2022.105668},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105668},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse dynamics modelling and tracking control of conical dielectric elastomer actuator based on GRU neural network},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A review on video summarization techniques. <em>EAAI</em>,
<em>118</em>, 105667. (<a
href="https://doi.org/10.1016/j.engappai.2022.105667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of technology has resulted in a profusion of advanced imaging devices and eases internet accessibility, leading to an increase in the creation and use of multimedia content. Analyzing representative or meaningful information from such massive data is a time-consuming task that impacts the efficiency of various video processing applications, including video searching, retrieval, indexing, sharing, and many more. In literature, numerous video summarization techniques which extract key-frames or key-shots from the original video to generate a concise yet informative summary have been proposed to address these issues. This paper presents a discussion of the state-of-the-art video summarization techniques along with limitations and challenges. The paper examines summarization techniques in a holistic manner based upon the distinct attributes of evolving video data types on the basis of parameters such as the number of views, dimensions, modality, and content. Such a categorization framework enables us to critically analyze the recent progress, future directions, limitations, datasets, application domains etc., in a better comprehensible manner.},
  archive      = {J_EAAI},
  author       = {Preeti Meena and Himanshu Kumar and Sandeep Kumar Yadav},
  doi          = {10.1016/j.engappai.2022.105667},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105667},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review on video summarization techniques},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fast implementation of coalitional model predictive
controllers based on machine learning: Application to solar power
plants. <em>EAAI</em>, <em>118</em>, 105666. (<a
href="https://doi.org/10.1016/j.engappai.2022.105666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a real-time implementation of distributed model predictive controllers to maximize the thermal energy generated by parabolic trough collector fields. For this control strategy, we consider that each loop of the solar collector field is individually managed by a controller, which can form coalition with other controllers to attain its local goals while contributing to the overall objective. The formation of coalitions is based on a market-based mechanism in which the heat transfer fluid is traded. To relieve the computational burden online, we propose a learning-based approach that approximates optimization problems so that the controller can be applied in real time. Finally, simulations in a 100 -loop solar collector field are used to assess the coalitional strategy based on neural networks in comparison with the coalitional model predictive control. The results show that the coalitional strategy based on neural networks provides a reduction in computing time of up to 99 . 74 % and a minimal reduction in performance compared to the coalitional model predictive controller used as the baseline.},
  archive      = {J_EAAI},
  author       = {Eva Masero and Sara Ruiz-Moreno and José Ramón D. Frejo and José M. Maestre and Eduardo F. Camacho},
  doi          = {10.1016/j.engappai.2022.105666},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105666},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast implementation of coalitional model predictive controllers based on machine learning: Application to solar power plants},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nuts&amp;bolts: YOLO-v5 and image processing based component
identification system. <em>EAAI</em>, <em>118</em>, 105665. (<a
href="https://doi.org/10.1016/j.engappai.2022.105665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assembly is an important process of aerospace industry which involves significant number of fastening elements such as bolts, washers and nuts, etc. Presently, the identification of these elements is done manually by humans. Since human operators are prone to errors, any fault in the assembly line can have a major impact on the overall efficiency and safety of an aerospace vehicle. In this paper, we present a deep learning and image processing-based approach for identification of mechanical fixation/fastening elements used in the aerospace assembly line. We propose YOLO-v5 algorithm to classify the components based on their head and lateral shape. We also propose an image processing method to estimate the spatial dimensions of the assembly line components including thread pitch. Moreover, this study also features the development of an image acquisition platform with two cameras mounted and proper lighting mechanism to capture quality images. Despite the challenges associated with such systems, the proposed deep learning ( YOLO-v5) algorithm has shown promising results with a mAP@ 0.5 of 0.996 for component classification. Whereas, the proposed image processing mechanism achieved an accuracy of 100% for standard size assignments with a maximum error of 0.05 mm for pitch calculation.},
  archive      = {J_EAAI},
  author       = {Faisel Mushtaq and Kaki Ramesh and Sandip Deshmukh and Tathagata Ray and Chandu Parimi and Praveen Tandon and Pramod Kumar Jha},
  doi          = {10.1016/j.engappai.2022.105665},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105665},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nuts&amp;bolts: YOLO-v5 and image processing based component identification system},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning based electricity demand forecasting to
minimize the cost of energy imbalance: A real case application with some
fortune 500 companies in türkiye. <em>EAAI</em>, <em>118</em>, 105664.
(<a href="https://doi.org/10.1016/j.engappai.2022.105664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the electricity demands of some Fortune 500 companies in Türkiye have been forecasted by using deep learning techniques. This is a quite harder problem than the forecasting of the aggregated electricity demand in which the negative and positive fluctuations are absorbed on paper. Forecasting of firm-level electricity demand is an important problem since it can help automating firms’ routine forecasting operations, reducing the electricity supply costs of the firms by improving the quality of the forecasts, and improving the quality of the electricity on the transmission network. Long Short-Term Memory (LSTM) and Multilayer Perceptron (MLP) techniques have been preferred concerning the successful results in the literature. As the originality of this paper, the Multiple Seasonal-Trend Decomposition using Loess (MSTL) technique is used for the electricity demand forecasting problem for the first time. The obtained results showed that although it is simple to implement, MSTL outperforms MLP and LSTM for most of the firms operating in mass production form. It is seen that the complexity of the model does not always guarantee good results and simple methods sometimes can work well. Load balancing studies are also very important for the economic sustainability of the industry since the electricity price and imbalance penalty have extremely increased (i.e., 8 times in Türkiye) during the post-pandemic period. Therefore, the energy cost reduction potential of the companies has also been assessed. This study resulted in cost savings of approximately 378 minimum wages for the pilot company.},
  archive      = {J_EAAI},
  author       = {Gürkan Işık and Hulisi Öğüt and Mustafa Mutlu},
  doi          = {10.1016/j.engappai.2022.105664},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105664},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning based electricity demand forecasting to minimize the cost of energy imbalance: A real case application with some fortune 500 companies in türkiye},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A feature-enhanced long short-term memory network combined
with residual-driven ν support vector regression for financial market
prediction. <em>EAAI</em>, <em>118</em>, 105663. (<a
href="https://doi.org/10.1016/j.engappai.2022.105663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the long short-term memory (LSTM) network has gained special attention in the investigation of financial market forecasting since it has a good ability to mine crucial information from time series data via network learning. However, most existing LSTM networks cannot perform well on the small number of samples and usually have a weak feature extraction and inadequate use of information. To address the above issues, a novel LSTM network, namely feature-enhanced LSTM network combined with residual-driven ν support vector regression, is put forward. Such a proposed LSTM network has the following two whelming merits: (1) the convolution layers are utilized to extract crucial profitable latent features and then the LSTM is applied to gain the rough prediction by using both long-term and short-term information; (2) a residual-driven ν support vector regression ( ν SVR) model is developed to make an promotion over the rough prediction by taking full consideration of historical information. Finally, extensive experiments in real-world datasets demonstrate the desirable results of the proposed method as opposed to other baseline models.},
  archive      = {J_EAAI},
  author       = {Yameng Zhang and Yan Song and Guoliang Wei},
  doi          = {10.1016/j.engappai.2022.105663},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105663},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A feature-enhanced long short-term memory network combined with residual-driven ν support vector regression for financial market prediction},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight bidirectional long short-term memory based on
automated model pruning with application to bearing remaining useful
life prediction. <em>EAAI</em>, <em>118</em>, 105662. (<a
href="https://doi.org/10.1016/j.engappai.2022.105662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearings are key components in industrial machinery, and their remaining useful life (RUL) prediction plays a prominent part in machine safety and maintenance. Bidirectional long short-term memory (Bi-LSTM) shows great performance in this field, but in most cases, the methods do not consider the model redundancy that may cause negative effects. To address this issue, this paper proposes a novel lightweight Bi-LSTM based on automated model pruning for bearing RUL prediction. The method carries out automatic model pruning by directly using the original Bi-LSTM model as input and intelligently identifying the redundant elements in the model based on norm information and reinforcement learning. It avoids the complex manual process of searching and selecting the optimal pruning architecture. The method can achieve an efficient adaptive allocation of computational resources and obtain a lightweight Bi-LSTM model with better performance. The application on the bearing RUL prediction shows that the lightweight Bi-LSTM can effectively predict the bearing degradation curve with the root mean square as health index. In comparison with several popular methods, the lightweight Bi-LSTM shows excellent learning ability in predicting long and complex time series. The lightweight Bi-LSTM achieves a 36% model pruning rate while improving the prediction accuracy by 3% when compared with the original Bi-LSTM. This study is of significance to the bearing fault state prediction and sub-health stage detection.},
  archive      = {J_EAAI},
  author       = {Jiankai Sun and Xin Zhang and Jiaxu Wang},
  doi          = {10.1016/j.engappai.2022.105662},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105662},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight bidirectional long short-term memory based on automated model pruning with application to bearing remaining useful life prediction},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A damping grey multivariable model and its application in
online public opinion prediction. <em>EAAI</em>, <em>118</em>, 105661.
(<a href="https://doi.org/10.1016/j.engappai.2022.105661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online public opinion plays pivotal role in social stability, and predicting hotness of online opinion accurately can provide theoretical and practical guidance for government and enterprises. A damping accumulated multivariable grey model is proposed to forecast the online public opinion trends in this paper. Firstly, the dynamic damping trend factor is introduced into the accumulation process, so that the model can adjust the accumulating order of different sequences more flexibly. Secondly, considering that the accumulated sequences have grey exponential rate property, the damping grey multivariable model is established by optimizing the structure of the background values. Finally, due to the assumption that the relevant factor variables are grey constants, the systematic error occurs in the traditional grey multivariate model, the time response equation is given to reduce error by using the composite quadrature method. Two real cases are used for empirical analysis to verify the effectiveness of the new model. And the forecasting accuracy and robustness of the new model is better than those of other prediction models. Therefore, the model is an effective method dealing with nonlinear problems, which further improves the grey modeling theory and can be applied to the prediction of online opinion.},
  archive      = {J_EAAI},
  author       = {Shuli Yan and Qi Su and Lifeng Wu and Pingping Xiong},
  doi          = {10.1016/j.engappai.2022.105661},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105661},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A damping grey multivariable model and its application in online public opinion prediction},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physically plausible propeller noise prediction via
recursive corrections leveraging prior knowledge and experimental data.
<em>EAAI</em>, <em>118</em>, 105660. (<a
href="https://doi.org/10.1016/j.engappai.2022.105660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For propeller-driven vessels, cavitation is the most dominant noise source producing both structure-borne and radiated noise impacting wildlife, passenger comfort, and underwater warfare. Physically plausible and accurate predictions of the underwater radiated noise at design stage, i.e., for previously untested geometries and operating conditions, are fundamental for designing silent and efficient propellers. State-of-the-art predictive models are based on physical, data-driven, and hybrid approaches. Physical models (PMs) meet the need for physically plausible predictions but are either too computationally demanding or not accurate enough at design stage. Data-driven models (DDMs) are computationally inexpensive ad accurate on average but sometimes produce physically implausible results. Hybrid models (HMs) combine PMs and DDMs trying to take advantage of their strengths while limiting their weaknesses but state-of-the-art hybridisation strategies do not actually blend them, failing to achieve the HMs full potential. In this work, for the first time, we propose a novel HM that recursively correct a state-of-the-art PM by means of a DDM which simultaneously exploits the prior physical knowledge in the definition of its feature set and the data coming from a vast experimental campaign at the Emerson Cavitation Tunnel on the Meridian standard propeller series behind different severities of the axial wake. Results in different extrapolating conditions, i.e., extrapolation with respect to propeller rotational speed, wakefield, and geometry, will support our proposal both in terms of accuracy and physical plausibility.},
  archive      = {J_EAAI},
  author       = {Miltiadis Kalikatzarakis and Andrea Coraddu and Mehmet Atlar and Stefano Gaggero and Giorgio Tani and Luca Oneto},
  doi          = {10.1016/j.engappai.2022.105660},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105660},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physically plausible propeller noise prediction via recursive corrections leveraging prior knowledge and experimental data},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intuitionistic fuzzy three-way transfer learning based on
rough almost stochastic dominance. <em>EAAI</em>, <em>118</em>, 105659.
(<a href="https://doi.org/10.1016/j.engappai.2022.105659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a significant extension of rough set theory, three-way decision (3WD) theory plays a crucial role in the data mining of uncertain information and decision-making analysis. Transfer learning (TL) is also a powerful knowledge discovery and deep learning strategy that has attracted the attention of many scholars. At present, many achievements have been made in related studies based on the concepts of sample transfer, feature transfer, and parameter transfer. However, there are few studies on multi-granularity fusion and TL for multisource data from the perspective of the stochastic dominance (SD) relation. In this paper, an intuitionistic fuzzy three-way transfer learning (IF3WTL) model based on rough almost stochastic dominance (RASD) is proposed. In this scenario, we first introduce the concept of a rough marginal information measure and the corresponding calculation method. Then, an RASD method is proposed to generate the multi-granularity distribution of same-category information in the source domain. In addition, 3WD theory is introduced to classify the target domain objects into positive, negative, and boundary regions based on the relation between marginal minimum risk information and the corresponding multi-granularity distribution. Furthermore, a secondary decision strategy with an SVM algorithm is implemented to iteratively process boundary region objects. The proposed method can reduce the differences in the data distribution among domains through RASD, improve noise tolerance, and obtain the degree of roughness of common information at different scales. Moreover, the proposed method adopts an iterative learning strategy, which can reduce the decision-making cost in cases with insufficient information and improve the accuracy of classification for objects in the boundary region. The rationality and effectiveness of the proposed model are verified through experiments with the ABIDE dataset and comparative analyses with the existing state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Xian-wei Xin and Chun-lei Shi and Tian-bao Song and Hai-tao Liu and Zhan-ao Xue and Ji-hua Song},
  doi          = {10.1016/j.engappai.2022.105659},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105659},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intuitionistic fuzzy three-way transfer learning based on rough almost stochastic dominance},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal variable selection for industrial process quality
prediction via attention-based GRU network. <em>EAAI</em>, <em>118</em>,
105658. (<a
href="https://doi.org/10.1016/j.engappai.2022.105658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While constructing predictive model for industrial process quality prediction, the selection of an appropriate input variable set is crucial to the online prediction performance. In this paper, the issue is solved through a deep causality analysis method, where the deep learning feature extracting unit, i.e., the Gated Recurrent Unit (GRU), is combined with the Granger Causality (GC) to extract the causal relationships between process variables. In this way, the nonlinear and dynamic features contained in the process data can be effectively learned in the GC analyzing framework, resulting in a more reliable causal relationship structure. Furthermore, through applying the attention mechanism to the input layer of the GRU cells, the causal relationship between process variables and the quality variable can be extracted, even the long time-lags exist. Based on the direct and indirect causal structure, the quality-related causal input variables are selected, and the predictive model is established through a deep dynamic regression network with GRU cells. A numerical example and a real chemical process case are provided to verify the effectiveness of the proposed causal variable selection method, where the prediction performance is significantly improved comparing with the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Le Yao and Zhiqiang Ge},
  doi          = {10.1016/j.engappai.2022.105658},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105658},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal variable selection for industrial process quality prediction via attention-based GRU network},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Community detection in networks through a deep robust
auto-encoder nonnegative matrix factorization. <em>EAAI</em>,
<em>118</em>, 105657. (<a
href="https://doi.org/10.1016/j.engappai.2022.105657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a field of research with increasing influence due to its importance in dimensionality reduction and revealing the organizational patterns in networks. A community or cluster in a network reflects the interactions among the objects that are strongly connected and distinguish them from the ones in other clusters. Over the past decades, various algorithms have been developed to detect the community structure in networks. However, the performance of these algorithm is affected by the existence of noise or nonlinear information in the network. Consequently, deep learning algorithms arise to tackle this issue. In this paper, we propose a novel deep robust auto-encoder nonnegative matrix factorization (DRANMF) approach to detect the community structure in networks. In particular, DRANMF consists of a deep structured decoder and encoder components to transform the high-order proximity matrix of the network to and from the cluster membership space, respectively. Moreover, we enhance the robustness of the proposed approach against noise and outliers by adopting the l 2 , 1 -norm to formulate the objective function. The experiments on multiple synthetic and real-world networks demonstrate that the proposed DRANMF has a better performance and robustness than other existing methods.},
  archive      = {J_EAAI},
  author       = {Esraa Al-sharoa and Baraa Rahahleh},
  doi          = {10.1016/j.engappai.2022.105657},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105657},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Community detection in networks through a deep robust auto-encoder nonnegative matrix factorization},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised fault diagnosis of wind turbine bearing via a
deep residual deformable convolution network based on subdomain
adaptation under time-varying speeds. <em>EAAI</em>, <em>118</em>,
105656. (<a
href="https://doi.org/10.1016/j.engappai.2022.105656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen the rapid development and marvelous achievement of deep learning-based fault diagnosis (FD) methods which assume that training data and testing data have the same distribution. However, in real FD of wind turbine bearing (WTB), the particularity of time-varying speeds makes a huge difference in the distribution of training data and testing data, greatly increasing the difficulty of FD. Accordingly, in this paper, a novel deep residual deformable subdomain adaptation framework is proposed for cross-domain failure diagnosis of WTB under time-varying speeds. In the proposed approach, the traditional residual network is improved by using a deformable convolution module to replace plain counterparts, which can make the feature representation of an object adapt its configuration and enhance the ability of the model to extract transferable features. Moreover, the popular FD model based on domain adversarial neural nets and global maximum mean discrepancy is improved by removing the adversarial training mechanism and employing a local maximum mean discrepancy to align the distributions of the identical fault type in different domains, making the diagnostic model simpler and more efficient. Two experimental cases under time-varying speeds are conducted to analyze the performance of the proposed approach and the results indicate that this method can utilize the knowledge in the source domain to diagnose the fault in the target domain. Compared with the existing methods, the diagnosis accuracy and efficiency are significantly improved, demonstrating its effectiveness and potential applications in fault transfer diagnosis of wind turbine bearing.},
  archive      = {J_EAAI},
  author       = {Pengfei Liang and Bin Wang and Guoqian Jiang and Na Li and Lijie Zhang},
  doi          = {10.1016/j.engappai.2022.105656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised fault diagnosis of wind turbine bearing via a deep residual deformable convolution network based on subdomain adaptation under time-varying speeds},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Digital twin of an industrial workstation: A novel method of
an auto-labeled data generator using virtual reality for human action
recognition in the context of human–robot collaboration. <em>EAAI</em>,
<em>118</em>, 105655. (<a
href="https://doi.org/10.1016/j.engappai.2022.105655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of human actions based on artificial intelligence methods to enable Human–Robot Collaboration (HRC) inside working environments remains a challenge, especially because of the necessary huge training datasets needed. Meanwhile, Digital Twins (DTs) of human centered productions are increasingly developed and used in the design and operation phases. As instance, DTs are already helping industries to design, visualize, monitor, manage, and maintain their assets more effectively. However, few works are dealing with using DTs as a dataset generator tool. Therefore, this paper explores the use of a DT of a real industrial workstation involving assembly tasks with a robotic arm interfaced with Virtual Reality (VR) to extract a digital human model. The DT simulates assembly operations performed by humans aiming to generate self-labeled data. Thereby, a Human Action Recognition dataset named InHARD-DT was created to validate a real use case in which we use the acquired auto-labeled DT data of the virtual representation of the InHARD dataset to train a Spatial–Temporal Graph Convolutional Neural Network with skeletal data on one hand. On the other hand, the Physical Twin (PT) data of the InHARD dataset was used for testing. Obtained results show the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Mejdi Dallel and Vincent Havard and Yohan Dupuis and David Baudry},
  doi          = {10.1016/j.engappai.2022.105655},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105655},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Digital twin of an industrial workstation: A novel method of an auto-labeled data generator using virtual reality for human action recognition in the context of human–robot collaboration},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristic position allocation methods for forming multiple
UAV formations. <em>EAAI</em>, <em>118</em>, 105654. (<a
href="https://doi.org/10.1016/j.engappai.2022.105654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a common action that the unmanned aerial vehicles (UAVs) change the formation during the flight to realize different goals and address an emergency. In this process, the UAVs should determine their positions in the new formation to avoid the collision and reduce the flight time. In this paper, the position allocation problem for multiple UAV formations is studied, and the problem is solved considering the different requirements on offline and online cases. In the offline case, the trajectories of UAVs when forming new formations are calculated by the consensus-based trajectory planning (CBTP) method, in which the transient process is introduced to avoid the collision among UAVs. Then a hybrid genetic and simulated annealing (HGSA) algorithm, which utilizes the framework of genetic algorithm (GA) and the operators in simulated annealing (SA) algorithm, is proposed to obtain the optimal position allocation scheme. The CBTP method is treated as a part of the HGSA algorithm to calculate the optimization index for a specific position allocation scheme. In the online case, a two-step minimal cost increase strategy (MCIS)-based method is developed and the UAVs in each new formation and the allocated position of UAV in the new formation are determined successively. Simulation results demonstrate that the CBTP method can generate the safe trajectories for the UAVs when forming new formations, and the optimal position allocation scheme can be obtained by the HGSA algorithm. The HGSA algorithm performs better than other similar algorithms especially in the complicated situation. The MCIS-based method can output the partially optimized position allocation scheme at short notice, but the real trajectories of UAVs are not considered in the online case to reduce the computation time.},
  archive      = {J_EAAI},
  author       = {Yu Wu and Shuting Xu and Wei Dai and Liyang Lin},
  doi          = {10.1016/j.engappai.2022.105654},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105654},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Heuristic position allocation methods for forming multiple UAV formations},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A two-stage gap safe screening rule for multi-label optimal
margin distribution machine. <em>EAAI</em>, <em>118</em>, 105653. (<a
href="https://doi.org/10.1016/j.engappai.2022.105653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label optimal margin distribution machine (mlODM) is an efficient algorithm for multi-label classification. Although it can achieve great generalization performance, it is inefficient for large-scale datasets due to the huge number of label pairs. Motivated by its sparse solution, in this paper, we propose a two-stage gap safe screening rule for accelerating mlODM, termed as TSSR. First, a sequential safe screening rule (SSSR) based on gap is designed to screen out part of redundant label pairs prior to training, which reduces the scale of mlODM. Compared with the previous DVI rule, our method ensures absolute safety without destroying efficiency. In the second stage, to further speed up the solving process, a dynamic safe screening rule (DSSR) is embedded into the solving algorithm DCDM when training the simplified mlODM. More importantly, the feasible solution generated in the first stage can promote the efficiency of DSSR. To the best of our knowledge, this is the first attempt to create a hybrid screening rule for multi-label model. Our TSSR can greatly reduce the cost and achieve exactly the same accuracy. Experimental results on seven multi-label benchmark datasets and two real-world learning problems including movie genres classification and hypoglycemic drugs prediction verify the superiority of the proposed methods.},
  archive      = {J_EAAI},
  author       = {Mengdan Ma and Yitian Xu},
  doi          = {10.1016/j.engappai.2022.105653},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105653},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage gap safe screening rule for multi-label optimal margin distribution machine},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design of concrete incorporating microencapsulated phase
change materials for clean energy: A ternary machine learning approach
based on generative adversarial networks. <em>EAAI</em>, <em>118</em>,
105652. (<a
href="https://doi.org/10.1016/j.engappai.2022.105652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inclusion of microencapsulated phase change materials (MPCM) in construction materials is a promising solution for increasing the energy efficiency of buildings and reducing their carbon emissions. Although MPCMs provide thermal energy storage capability in concrete, they typically decrease its compressive strength. A unified framework for the mixture design of concrete incorporating MPCM is yet to be developed to facilitate practical applications. This study proposes a mix design procedure using a novel ternary machine learning (ML) paradigm. For this purpose, the tabular generative adversarial network (TGAN) was utilized to generate large synthetic mixture design data based on the limited available experimental observations. The synthetic data is then employed to construct robust predictive ML models. The gradient boosting regressor (GBR) model trained with synthetic data outperformed the model trained with real data, achieving a testing coefficient of determination (R 2 ) of 0.963 and mean absolute error (MAE) of 2.085 MPa. The TGAN-GBR model was ultimately integrated with the particle swarm optimization (PSO) algorithm to construct a powerful recommendation system for optimizing the mixture design of concrete and mortar incorporating different types of MPCMs. Extensive parametric analyses along with the employed optimization procedure accomplished the mixture design of latent heat thermal energy storage concrete with maximum MPCM inclusion and minimum cement content for various compressive strength classes. The proposed framework enables energy conservation technology in the design of eco-friendly building materials with acceptable mechanical performance.},
  archive      = {J_EAAI},
  author       = {Afshin Marani and Lei Zhang and Moncef L. Nehdi},
  doi          = {10.1016/j.engappai.2022.105652},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105652},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design of concrete incorporating microencapsulated phase change materials for clean energy: A ternary machine learning approach based on generative adversarial networks},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-task learning on the edge for effective gender, age,
ethnicity and emotion recognition. <em>EAAI</em>, <em>118</em>, 105651.
(<a href="https://doi.org/10.1016/j.engappai.2022.105651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More and more real-world applications, especially in cognitive robotics, require the running of different computer vision algorithms in parallel on board of embedded devices with limited GPU and memory resources. Multi-task learning, namely the usage of the same model to perform multiple classification and/or regression tasks by learning a shared low level representation, revealed to be a valid solution to reduce computation and required memory space while preserving the accuracy. In this paper, we propose a solution for real-time user profiling based on a multi-task convolutional neural network (CNN) for gender, age, ethnicity and emotion recognition from face images. To find the best trade-off between accuracy and processing time, we evaluate three different architectures, specifically designed for the purpose, and backbones, based on MobileNet, ResNet and SENet, which include convolutional layers, residual blocks and attention modules that already demonstrated great potential in face analysis. We trained the multi-task neural network with a custom learning procedure, which solves the problems of missing labels, dataset imbalance and loss function imbalance through label masking, batch balancing and a custom weighted loss function; there are no other multi-task neural networks for face analysis that address all these challenges simultaneously.. The proposed solution demonstrated its effectiveness in the comparison with the corresponding single-task CNNs in terms of accuracy, processing time and memory space; in fact, the multi-task CNNs achieved a processing speed-up between 2.5 and 4 times and a reduction of the memory space between 2 and 4 times, while preserving the accuracy. Moreover, the useful insights that arise from the experiments allow to choose a solution for face analysis easily integrable into real applications on smart cameras and embedded systems and most suited for the specific application constraints in terms of computational resources.},
  archive      = {J_EAAI},
  author       = {Pasquale Foggia and Antonio Greco and Alessia Saggese and Mario Vento},
  doi          = {10.1016/j.engappai.2022.105651},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105651},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-task learning on the edge for effective gender, age, ethnicity and emotion recognition},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A synergy of an evolutionary algorithm with slime mould
algorithm through series and parallel construction for improving global
optimization and conventional design problem. <em>EAAI</em>,
<em>118</em>, 105650. (<a
href="https://doi.org/10.1016/j.engappai.2022.105650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imitating behaviour of the slime mould algorithm (SMA) supports the collective efficiency, whereas the evolutionary algorithm (EA) smoothens the global effectiveness through a crossover. This observation leads to the integration of the EA with SMA. Thus, in this paper, an attempt has been made to hybridize the said algorithms in a parallel and series manner. In parallel structure, EA and SMA are executed parallelly and solutions obtained from both are combined to obtain the best solution which is further saved and updated as to a global best solution. Whereas, in a series structure, the population is fed to the EA initially to obtain the best solution which is again fed to SMA to obtain the global best solution. Under such guidance, the global search ability and search efficiency of EA and SMA are enhanced. The proposed PSEASMA and SSEASMA are tested on 23 classical benchmark functions and ten CEC2019 functions. The Wilcoxon rank-sum test is also carried out to validate the efficacy of the proposed work. The proposed work has been compared with other renowned metaheuristic algorithms in terms of average and standard deviation. Based on average and standard deviation, the ranks of each algorithm have been assigned through the Friedman test. The results suggested that the proposed method outperformed the other state of arts. The PSEASMA and SSEASMA have also been applied to classical engineering design problems. The performance of the proposed work is significantly superior compared to basic SMA, EA and other meta-heuristic algorithms.},
  archive      = {J_EAAI},
  author       = {Sumika Chauhan and Govind Vashishtha},
  doi          = {10.1016/j.engappai.2022.105650},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105650},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A synergy of an evolutionary algorithm with slime mould algorithm through series and parallel construction for improving global optimization and conventional design problem},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of machine learning models in the behavioral
study of forest fires in the brazilian federal district region.
<em>EAAI</em>, <em>118</em>, 105649. (<a
href="https://doi.org/10.1016/j.engappai.2022.105649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ecosystems, settlements, and human lives are put at risk by forest fires every year. Several models proposed for the prediction of their occurrence and behavior have aimed at identifying their conditioning factors, risks, and post-effects. However, their application in other regions is impracticable or very difficult, due to the distinct geographic characteristics of the areas and the unavailability of data. This research is devoted to the prediction of both spread and behavior of wildfires at a specific time and/or in specific regions for helping fire management agencies minimize the damages caused. The Brazilian Federal District, inserted in the Cerrado biome, is the focus of the analyses, due to its large number of fire occurrences and reduced number of studies conducted on the region. A dataset was compiled from Brazilian governmental open data for the prediction of the wildfire behavior and used for the training of several Machine Learning models that consider the fire point of ignition to predict the areas that will be impacted. It includes observations on climate features from 5 monitoring stations and satellite data on fires that occurred over the past two decades and was enriched with other topographic, hydrographic, and anthropogenic features, such as urbanization index, distance to rivers/roads, and Normalized Difference Vegetation Index (NDVI). According to the results, AdaBoost model predicted the area affected by the wildfire with 91% accuracy, showing better performance than Random Forest (RF) 88%, Artificial Neural Network (ANN) 86%, and Support Vector Machine (SVM) 81%.},
  archive      = {J_EAAI},
  author       = {Jesús N.S. Rubí and Paulo H.P. de Carvalho and Paulo R.L. Gondim},
  doi          = {10.1016/j.engappai.2022.105649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of machine learning models in the behavioral study of forest fires in the brazilian federal district region},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machine learning-based automatic focusing for high
magnification systems. <em>EAAI</em>, <em>118</em>, 105648. (<a
href="https://doi.org/10.1016/j.engappai.2022.105648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise focus plays a critical role in the quality of astronomical observations, significantly affecting scientific research. Accordingly, the automatic focusing of a high magnification telescope system is desirable. The auto-focusing level is measured using a focus measure operator. The principal challenge is to find a robust operator that can accurately estimate the focus level for high magnification astronomical images that suffer from high blur. In addition, images can suffer from aberrations as the distance from the image center increases, along with dramatic effects associated with dynamic observation conditions such as temperature, clouds, humidity, and seeing. In this study, we first propose a focus measure relying on fuzzy logic that can handle imprecise data. Second, we optimize the parameters of the fuzzy membership functions using multivariate particle swarm optimization (PSO). We apply the proposed method to five sequences of different star clusters acquired using the 74-inch telescope at the Kottamia astronomical observatory (KAO) during good seeing conditions. We then compare our proposed method with other traditional focus operators and rank them according to evaluation criteria. The results show that the proposed operator generally outperforms the others, and that the optimized operator provides further improvement.},
  archive      = {J_EAAI},
  author       = {Islam Helmy and Wooyeol Choi},
  doi          = {10.1016/j.engappai.2022.105648},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105648},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning-based automatic focusing for high magnification systems},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A theory-guided deep-learning method for predicting power
generation of multi-region photovoltaic plants. <em>EAAI</em>,
<em>118</em>, 105647. (<a
href="https://doi.org/10.1016/j.engappai.2022.105647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, clean solar energy has aroused wide attention due to its excellent potential for electricity production. A highly accurate prediction of photovoltaic power generation (PVPG) is the basis of the production and transmission of electricity. However, the current works neglect the regional correlation characteristics of PVPG and few studies propose an effective framework by incorporating prior knowledge for more physically reasonable results. In this work, a hybrid deep learning framework is proposed for simultaneously capturing the spatial correlations among different regions and temporal dependency patterns with various importance. The scientific theory and domain knowledge are incorporated into the deep learning model to make the predicted results possess physical reasonability. Subsequently, the theory-guided and attention-based CNN-LSTM (TG-A-CNN-LSTM) is constructed for PVPG prediction. In the training process, data mismatch and boundary constraint are incorporated into the loss function, and the positive constraint is utilized to restrict the output of the model. After receiving the parameters of the neural network, a TG-A-CNN-LSTM model, whose predicted results obey the physical law, is constructed. A real energy system in five regions is used to verify the accuracy of the proposed model. The predicted results indicate that TG-A-CNN-LSTM can achieve higher precision of PVPG prediction than other prediction models, with RMSE being 11.07, MAE being 4.98, and R 2 being 0.94, respectively. Moreover, the performance of prediction models with sparse data is tested to illustrate the stability and robustness of TG-A-CNN-LSTM.},
  archive      = {J_EAAI},
  author       = {Jian Du and Jianqin Zheng and Yongtu Liang and Qi Liao and Bohong Wang and Xu Sun and Haoran Zhang and Maher Azaza and Jinyue Yan},
  doi          = {10.1016/j.engappai.2022.105647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A theory-guided deep-learning method for predicting power generation of multi-region photovoltaic plants},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence-aided nanoplasmonic biosensor
modeling. <em>EAAI</em>, <em>118</em>, 105646. (<a
href="https://doi.org/10.1016/j.engappai.2022.105646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of monolithic biosensors is increasingly popular in fundamental biological studies. Rapid advances in nanophotonic biosensors are leading to lab-on-a-chip platforms. In this paper we propose a method to use artificial neural networks (ANNs) to predict the output electrical signal of biosensor. Multilayer perceptron model is developed by assuming electrical current as outputs, and the refractive index of biosamples, central wavelength ( λ ) and full width half maximum (FWHM) of input light source as inputs. A comparative approach was applied between finite-difference time-domain (FDTD) method and ANN results to evaluate the biosensor’s ANN model. Results showed that the ANN design with topology of (3 5 4 4 6 21) can predict the output accurately based on the value of mean square error (MSE) about 2.9 × 10 −8 as evaluation parameter. It was shown that the developed ANN model can approximate the outcome to high precision with only a small sampling of the data. Using the developed model, pre-optimization was run to find the optimum condition for electrical sensitivity and responsivity of the device. We found that the light source with central wavelength of 735 nm and FWHM of 70 nm can simultaneously satisfy the optimum conditions for sensitivity and responsivity.},
  archive      = {J_EAAI},
  author       = {Samaneh Hamedi and Hamed Dehdashti Jahromi and Ahmad Lotfiani},
  doi          = {10.1016/j.engappai.2022.105646},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105646},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence-aided nanoplasmonic biosensor modeling},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi objective optimization of detailed building models
with typical short sequences considering sequential and adaptive
methods. <em>EAAI</em>, <em>118</em>, 105645. (<a
href="https://doi.org/10.1016/j.engappai.2022.105645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization of detailed building models may lead to high computational time expenses. The work presented in this paper presents an alternative of classical approaches based on the usage of reduced sequences in a sequential and an adaptive approach. The sequential approach runs directly the reduced sequence obtained from a typical day selection algorithm which employs a k- medoids clustering algorithm in a multi-objective optimization study. It was applied on a solar combisystem connected to a building model and showed its capability of reproducing the Pareto front 25 times faster with relative errors not exceeding 5% when considering several parametric configurations of the model and focusing on a limited number of selection criteria during the day selection process. On the other hand, the adaptive approach for optimization named OptiTypSS achieves day selection during the optimization process by combining an iterative day selection algorithm (TypSS) with a genetic algorithm of optimization (NSGA-II). The method succeeded in obtaining results with errors inferior to 3% being therefore as efficient as a classical metamodel adaptive approach yet with relatively higher computational time. Further improvements including parallel simulation during the day selection process can be done to enhance the performance.},
  archive      = {J_EAAI},
  author       = {Hasan Sayegh and Antoine Leconte and Gilles Fraisse and Etienne Wurtz and Simon Rouchier},
  doi          = {10.1016/j.engappai.2022.105645},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105645},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi objective optimization of detailed building models with typical short sequences considering sequential and adaptive methods},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic antibiotic resistance prediction in klebsiella
pneumoniae based on MALDI-TOF mass spectra. <em>EAAI</em>, <em>118</em>,
105644. (<a
href="https://doi.org/10.1016/j.engappai.2022.105644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix-Assisted Laser Desorption Ionization Time-Of-Flight (MALDI-TOF) Mass Spectrometry (MS) is a reference method for microbial identification and it can be used to predict Antibiotic Resistance (AR) when combined with artificial intelligence methods. However, current solutions need time-costly preprocessing steps, are difficult to reproduce due to hyperparameter tuning, are hardly interpretable, and do not pay attention to epidemiological differences inherent to data coming from different centres, which can be critical. We propose using a multi-view heterogeneous Bayesian model (KSSHIBA) for the prediction of AR using MALDI-TOF MS data together with their epidemiological differences. KSSHIBA is the first model that removes the ad-hoc preprocessing steps that work with raw MALDI-TOF data. In addition, due to its Bayesian probabilistic nature, it does not require hyperparameter tuning, provides interpretable results, and allows exploiting local epidemiological differences between data sources. To test the proposal, we used data from 402 Klebsiella pneumoniae isolates coming from two different domains and 20 different hospitals located in Spain and Portugal. KSSHIBA outperforms current state-of-the-art approaches in antibiotic susceptibility prediction, obtaining a 0.78 AUC score in Wild Type classification and a 0.90 AUC score in Extended-Spectrum Beta-Lactamases (ESBL)+Carbapenemases (CP)-producers. The proposal consistently removes the need for ad-hoc preprocessing by working with raw MALDI-TOF data, which, in turn, reduces the time needed to obtain the results of the resistance mechanism in microbiological laboratories. The proposed model implementation as well as both data domains are publicly available.},
  archive      = {J_EAAI},
  author       = {Alejandro Guerrero-López and Carlos Sevilla-Salcedo and Ana Candela and Marta Hernández-García and Emilia Cercenado and Pablo M. Olmos and Rafael Cantón and Patricia Muñoz and Vanessa Gómez-Verdejo and Rosa del Campo and Belén Rodríguez-Sánchez},
  doi          = {10.1016/j.engappai.2022.105644},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105644},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic antibiotic resistance prediction in klebsiella pneumoniae based on MALDI-TOF mass spectra},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural network modelling and prediction of an anaerobic
filter membrane bioreactor. <em>EAAI</em>, <em>118</em>, 105643. (<a
href="https://doi.org/10.1016/j.engappai.2022.105643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anaerobic membrane bioreactors have become an environmentally friendly solution for wastewater treatment. The lack of sufficiently accurate mathematical procedures to model their behaviour and the fouling process of the membranes, poses a challenge when trying to optimise their energy consumption and maintenance costs. An accurate model of the fouling process of the membranes is critical to make the most of this technology. This is a perfect scenario in which to introduce neural networks (NN) as an alternative to mathematical modelling. However, the duration of the experiments and the difficulties in measuring some relevant variables, make it hard to collect high quality datasets to train the NN. Our goal is to obtain a good prediction of the fouling status of the membranes to enable an adjustment of operation conditions and maintenance procedures ahead in time. To do so we must obtain high quality datasets to train our neural networks. The combination of static and dynamic networks enables us to leverage the best prediction capabilities of each one. This combination requires a preprocessing of the datasets that separates trends from oscillations. The outputs obtained need to be put together to build up the predicted evolution of fouling. Accurate predictions are then extended from 25 to up to 75 filtration cycles. To maintain and even extend accuracy after sudden changes in operating conditions, retraining the NN every 25 cycles is proposed. AI based real time predictions open a new scope for decision making, and optimisation in the field of anaerobic membrane reactors.},
  archive      = {J_EAAI},
  author       = {José M. Cámara and Victorino Diez and Cipriano Ramos},
  doi          = {10.1016/j.engappai.2022.105643},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105643},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural network modelling and prediction of an anaerobic filter membrane bioreactor},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A cooperative EV charging scheduling strategy based on
double deep q-network and prioritized experience replay. <em>EAAI</em>,
<em>118</em>, 105642. (<a
href="https://doi.org/10.1016/j.engappai.2022.105642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the number of electric vehicles (EVs) has significantly increased the demand for electricity of residents, which may lead to transformer overload of distribution networks if there is no reasonable power consumption planning. In view of the coordinated charging of EVs under the photovoltaic (PV) energy connected to the power grid, a collaborative charging control strategy is proposed based on a double deep q-network with Prioritized experience replay (DDQN-PER). Specifically, Long–Short-Term Memory (LSTM) neural network is utilized to capture the uncertainties caused by power requirement, PV power, and real-time electricity price. Then, a modified DDQN approach and the corresponding reward function are applied to solve the cooperative charging problem. In addition, the introduction of a PER mechanism based on TD bias sampling in reinforcement learning alleviates the problem of reward sparsity in learning scenarios and improves the training stability and efficiency. The proposed approach can achieve collaborative scheduling of EVs, which helps reduce the charging cost, promote the consumption of PV energy and avoid transformer overload. Simulation case studies based on real data demonstrate that the proposed algorithm can reduce the charging cost by 30% and increase the PV power utilization by 10% compared to the DDQN algorithm.},
  archive      = {J_EAAI},
  author       = {Yanyu Zhang and Xinpeng Rao and Chunyang Liu and Xibeng Zhang and Yi Zhou},
  doi          = {10.1016/j.engappai.2022.105642},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105642},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A cooperative EV charging scheduling strategy based on double deep Q-network and prioritized experience replay},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An anatomization of research paper recommender system:
Overview, approaches and challenges. <em>EAAI</em>, <em>118</em>,
105641. (<a
href="https://doi.org/10.1016/j.engappai.2022.105641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this study is to present an exhaustive analysis on research paper recommender systems which have become very popular and gained a lot of research attention. Though the major focus is on developing new recommendation algorithms, other research dimensions are left untouched. Renown recommendation classes include content-based approaches, collaborative filtering, link-based algorithms, co-occurrence based approaches, global relevance and hybrid methods. These approaches mainly differ in background knowledge and modes of user behavior analysis. For instance, content-based filtering uses paper descriptions which are mostly word-based features. Collaborative filtering makes predictions based on peers’ interests. Link-based algorithms utilize academic associations that exist between different entities in academia. Co-occurrence based techniques incorporate event occurrences to locate related papers. Global relevance adopts a ‘one-for-all’ policy for recommending popular articles. Hybrid methods combine the above approaches to design efficient algorithms. We have reviewed articles implementing several versions of these classes, however minor customizations make it difficult to categorize the new methods to one of the base classes. We have defined the concept of ‘background knowledge and operating principle’ for proper classification and to make a clear distinction among the recommendation approaches. We have used a combination of systematic literature review, critical review, and conceptual review to conduct this survey which presents current advancements in the field and discusses popular recommendation approaches. This paper reveals the factors affecting users’ behavior and introduces a taxonomy of knowledge acquisition sources. Moreover, various evaluation methods and important performance criteria are explored. Finally, this paper examines the research trends and reports major loopholes in current research to foster the development of efficacious recommender systems.},
  archive      = {J_EAAI},
  author       = {Ritu Sharma and Dinesh Gopalani and Yogesh Meena},
  doi          = {10.1016/j.engappai.2022.105641},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105641},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An anatomization of research paper recommender system: Overview, approaches and challenges},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Thermal images-aware guided early fusion network for
cross-illumination RGB-t salient object detection. <em>EAAI</em>,
<em>118</em>, 105640. (<a
href="https://doi.org/10.1016/j.engappai.2022.105640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-T salient object detection (SOD) has been developed rapidly and achieved excellent results in recent years. However, some problems have not yet been solved. The current RGB-T datasets contain only a tiny amount of low-illumination data. The RGB-T SOD method trained based on these RGB-T datasets does not detect the salient objects in extremely low-illumination scenes very well. To improve the detection performance of low-illumination data, we can spend a lot of labor to label low-illumination data, but we tried a new idea to solve the problem by making full use of the properties of Thermal (T) images. Therefore, we propose a T-aware guided early fusion network for cross-illumination salient object detection. Specifically, in the training and testing stage, we use normal illumination data to train our network and then use low and extremely low-illumination data to verify the effectiveness of our method. In the early fusion stage, we propose a T-aware guided module (T-aware) for enhancing salient regions of RGB images at different illumination levels. Secondly, in the decoding stage, we use T images to guide the cross-modal fusion of RGB and T images. In addition, we propose a cross-modal fusion localization-remote correction module (CFL-RCM), which is used to deeply screen and correct redundant information generated by illumination variations. Comparative experiments on the VDT-2048 dataset validate the superior performance of our method on the cross-illumination RGB-T saliency detection. We also obtained favorable results on generalizability experiments with VT5000, VT1000, and VT821 datasets.},
  archive      = {J_EAAI},
  author       = {Han Wang and Kechen Song and Liming Huang and Hongwei Wen and Yunhui Yan},
  doi          = {10.1016/j.engappai.2022.105640},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105640},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal images-aware guided early fusion network for cross-illumination RGB-T salient object detection},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 2C2S: A two-channel and two-stream transformer based
framework for offline signature verification. <em>EAAI</em>,
<em>118</em>, 105639. (<a
href="https://doi.org/10.1016/j.engappai.2022.105639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, with the outstanding performance of the transformer in NLP, approaches that employ the transformer to address vision problem is becoming a research focus. However, transformer-based research rarely focuses on signature verification. To fill this gap, this paper proposes a two-channel and two-stream transformer approach (2C2S) to cope with the signature verification problem. 2C2S is composed of original and central streams. The original stream receives the original signature pair as input, and the central stream receives the signature pair generated by cropping the central at the original pair as input. In order to establish the associations among feature channels, a squeeze-and-excitation operation is applied between two standard Swin Transformer blocks. Moreover, an up-sampling enhancement module directly steers the model to focus on useful information. The verification accuracy of 2C2S on SUES-SiG and several publically available datasets: CEDAR, BHSig-B, and BHSig-H, reaches 93.25%, 90.68%, 100%, and 72.22%, respectively. Extensive experiments illustrate that the proposed framework is competitive with the existing techniques for offline handwritten signature verification.},
  archive      = {J_EAAI},
  author       = {Jian-Xin Ren and Yu-Jie Xiong and Hongjian Zhan and Bo Huang},
  doi          = {10.1016/j.engappai.2022.105639},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105639},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {2C2S: A two-channel and two-stream transformer based framework for offline signature verification},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A stochastic dynamic programming approach for the machine
replacement problem. <em>EAAI</em>, <em>118</em>, 105638. (<a
href="https://doi.org/10.1016/j.engappai.2022.105638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses both the modeling and the resolution of the replacement problem for a population of machines. The main objective is the computation of a minimum cost replacement policy, which, based on the status of each machine, determines whether one or more machines have to be replaced over a given finite time horizon. The replacement problem of a set of machines can be regarded as a sequential decision-making problem under uncertainty. Thanks to this, we propose a novel formulation for such problems consisting of a composition of discrete-time multi-state Markov Decision Processes (MDPs), one for each specific machine. The underlying optimization problem is formulated as a stochastic Dynamic Programming (DP), and then solved by using the principles of the backward DP algorithm. Moreover, to deal with the curse of dimensionality due to the high-cardinality state–space of real-world/industrial applications, a new generalized multi-trajectory Least-Squares Temporal Difference (LSTD) based method is introduced. The resulting algorithm computes an approximate optimal cost function by: (i) running Monte Carlo simulations over different trajectories of a given length; (ii) embedding the policy improvement step within the recursive LSTD iterations; (iii) enforcing an off-policy mechanism to improve the LSTD exploration capabilities. A study on the convergence properties of the proposed approach is also provided. Several numerical examples are given to illustrate its effectiveness in terms of parametric sensitivity, computational burden, and performance of the computed policies compared with some heuristics defined in the literature.},
  archive      = {J_EAAI},
  author       = {Ali Forootani and Majid Ghaniee Zarch and Massimo Tipaldi and Raffaele Iervolino},
  doi          = {10.1016/j.engappai.2022.105638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A stochastic dynamic programming approach for the machine replacement problem},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning-based detection of aluminum casting defects
and their types. <em>EAAI</em>, <em>118</em>, 105636. (<a
href="https://doi.org/10.1016/j.engappai.2022.105636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its unique properties, high-pressure aluminum die-casting parts are used quite often, especially in the automotive industry. However, die-casting is a process which requires non-destructive testing of the critical components using technologies such as X-ray to examine the internal defects that are not otherwise visible. Such a timeconsuming visual inspection requires well-trained human specialists with the utmost attention. In this study, state-of-the-art deep learning-based object detection methods were trained using an X-ray image dataset of aluminum parts to detect internal defects and predict their types without human attention. The Al-Cast image dataset used in this study contains 3466 images of parts produced in high-pressure die casting machines. It is shared as an open-access original database for the nondestructive testing (NDT) community. ASTM standard definitions for aluminum casting defects are used in determining their types, and to the best of our knowledge, this novel approach is the first in the deep learning literature. Among the 12 deep learning-based object detection methods used for comparison, YOLOv5 versions yielded the highest detection accuracy (0.956 mAP) with the shortest training time (0.75 h). In addition, tests were performed for both original and contrast enhanced images on 348 test images. YOLOv5m performed an accurate detection performance of 95.9%. Additionally, YOLOv5n can process 132 images per second. This study can be considered the first step of an artificial intelligence product that can detect internal defects of aluminum casting parts with industrial standards and explain the relationship between highpressure injection die casting parameters and these defects.},
  archive      = {J_EAAI},
  author       = {İsmail Enes Parlak and Erdal Emel},
  doi          = {10.1016/j.engappai.2022.105636},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105636},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based detection of aluminum casting defects and their types},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diagnosis of hepatocellular carcinoma using deep network
with multi-view enhanced patterns mined in contrast-enhanced ultrasound
data. <em>EAAI</em>, <em>118</em>, 105635. (<a
href="https://doi.org/10.1016/j.engappai.2022.105635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hepatocellular carcinoma, representing the most frequent primary liver cancer, is a common cancer disease that is the fourth leading cause of cancer-related mortality worldwide. In comparison, non-hepatocellular carcinoma liver cancers often present different prognoses and require distinct management which makes the accurate discrimination between hepatocellular carcinoma and non-hepatocellular carcinoma malignant lesions in contrast-enhanced ultrasound data critical for precise intervention. However, different types of liver cancers have similar enhanced patterns against the perfusion stages that raise the difficulty in the classification of hepatocellular carcinoma with the other liver cancers, especially when the contrast-enhanced ultrasound data is collected from different imaging machines. To this end, this paper innovatively proposes to extract perfusion features from a multi-view learning procedure for obtaining the inherent distinguishing features among liver cancers, leading to a more precise deep model in differentiating the hepatocellular carcinoma from other malignant cases. In particular, the proposed network consists of two novel structures for learning the correlation information among the different views to enhance the robustness of the features and fuse them by reducing redundant information. The proposed method is verified on a multi-source dataset collected from 1241 participants and achieves an AUC value of 89% for classification performance. The experimental results demonstrate the effectiveness of the proposed method for the diagnosis of hepatocellular carcinoma with a multi-source contrast-enhanced ultrasound dataset and might provide an effective assistant for clinical radiologists in liver cancer differentiation.},
  archive      = {J_EAAI},
  author       = {Xiangfei Feng and Wenjia Cai and Rongqin Zheng and Lina Tang and Jianhua Zhou and Hui Wang and Jintang Liao and Baoming Luo and Wen Cheng and An Wei and Weian Zhao and Xiang Jing and Ping Liang and Jie Yu and Qinghua Huang},
  doi          = {10.1016/j.engappai.2022.105635},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105635},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diagnosis of hepatocellular carcinoma using deep network with multi-view enhanced patterns mined in contrast-enhanced ultrasound data},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting stock market for an efficient portfolio by
combining XGBoost and hilbert–huang​ transform. <em>EAAI</em>,
<em>118</em>, 105626. (<a
href="https://doi.org/10.1016/j.engappai.2022.105626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio formation in financial markets is the task of not taking non-necessary risks. Quantitative investment powered by machine learning has opened many new opportunities for more insight generation from financial data resulting in the explosion of ideas to enhance the performance of investments in the stock markets. In this research, we propose a first-introduced model called HHT-XGB to predict the changing trends in the next close price of stocks under the study. The proposed model combines Hilbert–Huang Transform (HHT) as the feature engineering part and the extreme gradient boost (XGBoost) as the Close price trend classifier. The classification output is a sequence of ups and downs used to optimize the stocks’ portfolio weights with the best trading performance The performance of the portfolios optimized under this study proves that our novel combination of HHT with classification performs 99.8% better than forming the portfolio using raw financial data. The back-testing process suggests that the HHT-XGB strategy outperforms the benchmark strategies even with the poor-performing markets.},
  archive      = {J_EAAI},
  author       = {Arsalan Dezhkam and Mohammad Taghi Manzuri},
  doi          = {10.1016/j.engappai.2022.105626},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105626},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting stock market for an efficient portfolio by combining XGBoost and Hilbert–Huang​ transform},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The RNVP-based process monitoring with transforming
non-normal data to multivariate normal data. <em>EAAI</em>,
<em>118</em>, 105623. (<a
href="https://doi.org/10.1016/j.engappai.2022.105623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern industry, process monitoring with control charts is essential to improve processes by decreasing defects. Control charts, which are based on grounded statistical theory, have been used as an online process monitoring method to detect out-of-control. However, because control charts assume that the process data are normally distributed (a.k.a. the assumption of normality), they do not perform as well as failing to detect out-of-control when assumptions are not held. In practice, most process data violate the assumption of normality, the application of control charts in real manufacturing sites is limited. Therefore, to address this limitation, this study proposes a real-valued non-volume preserving (RNVP)-based control chart. The proposed method first transforms the process data to follow a multivariate normal distribution, and then monitors the transformed data using a control chart. As a result of conducting numerical experiments to evaluate the effectiveness of the proposed method, it was found that the performance of the proposed method was superior to that of the existing control charts in terms of Type II error rate and average run length.},
  archive      = {J_EAAI},
  author       = {Chang Ki Lee},
  doi          = {10.1016/j.engappai.2022.105623},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105623},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The RNVP-based process monitoring with transforming non-normal data to multivariate normal data},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing the performance of piezoelectric energy harvester
under electrostatic actuation using a robust metaheuristic algorithm.
<em>EAAI</em>, <em>118</em>, 105619. (<a
href="https://doi.org/10.1016/j.engappai.2022.105619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel shape optimization methodology based on evolutionary algorithms to maximize the harvesting energy from piezoelectric energy harvester stimulated by the β -emitted radioisotope. The parametric width function is used to model the piezoelectric layer non-prismatically. All the geometrical dimensions as well as parameters related to the parametric width function are optimized using the metaheuristic algorithms The piezoelectric layer partially covers the beam to obtain the optimal location of the piezoelectric layer. The pull-in instability causes the discharge in the system, and the piezoelectric layer converts the vibration of the released microcantilever into electricity. The nonlinear effects of electrostatic force and geometry are taken into account, and the differential equations governing the system are discretized utilizing the exact mode shapes of the system considering the geometrical effects of non-uniform microcantilever and the piezoelectric layer. The robust chaotic Harris Hawk optimization (RCHHO) algorithm is proposed for finding the optimal shape of the system. The performance of the proposed algorithm is compared with various metaheuristic algorithms in the literature. After optimizing the shape of the piezoelectric layer, the maximum voltage produced with the optimal model using the presented method was 8.105 times that of the classic model with rectangular piezoelectric layer used in previous works. Moreover, the maximum energy and average energy harvested in the optimal model were 61 and 7.22 times, respectively, of the non-optimal model.},
  archive      = {J_EAAI},
  author       = {Behnam Firouzi and Ahmad Abbasi and Polat Sendur and Mehdi Zamanian and Huiling Chen},
  doi          = {10.1016/j.engappai.2022.105619},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105619},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing the performance of piezoelectric energy harvester under electrostatic actuation using a robust metaheuristic algorithm},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural networks-based formulation for predicting ultimate
strength of bolted shear connectors in composite cold-formed steel
beams. <em>EAAI</em>, <em>118</em>, 105614. (<a
href="https://doi.org/10.1016/j.engappai.2022.105614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the use of artificial intelligence-based methods in engineering problems has been expanded. In the current study, the method of artificial neural networks (ANN) has been employed to predict the ultimate strength of bolted shear connectors in cold-formed steel (CFS) composite beams. For this purpose, multilayer perceptron (MLP) networks with a hidden layer were used. Three parameters affecting the performance of these networks, including the training algorithm, the activation function in the hidden layer, and the number of neurons in the hidden layer, were examined and the most accurate network was selected. The input and target data for training the network were provided by conducting an extensive numerical study on the behavior of bolted shear connectors in CFS composite beams. Consequently, using ABAQUS software, finite element (FE) models validated with experimental results were first developed. Then, 216 models with different characteristics were analyzed and a reliable database was provided for the development of neural networks. Moreover, in order to prove the high accuracy of the ANN method, the stepwise regression (SR) method was also developed as one of the powerful regression-based methods, and the performances of these two methods were compared. Finally, the most important purpose of this study is to propose an accurate ANN-based formulation in order to predict the ultimate strength of bolted shear connectors in CFS composite beams. Due to the fact that so far no relationship has been proposed to predict the resistance of shear connectors in CFS composite beams, the formula presented in this paper can be helpful in the design process of this type of beams.},
  archive      = {J_EAAI},
  author       = {Mahmoud Hosseinpour and Maryam Daei and Mehran Zeynalian and Abdolreza Ataei},
  doi          = {10.1016/j.engappai.2022.105614},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105614},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural networks-based formulation for predicting ultimate strength of bolted shear connectors in composite cold-formed steel beams},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph-based pivotal semantic mining framework for rumor
detection. <em>EAAI</em>, <em>118</em>, 105613. (<a
href="https://doi.org/10.1016/j.engappai.2022.105613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the gathering place for modern content sharing, social platforms not only provide places for people to obtain information and express opinions, but also provide hidden channels for the generation and dissemination of rumors. Rumor detection is an important and challenging task for mining fake information in social networks. Previous methods utilized sequential models to embed semantic features, which are not comprehensive for mining pivotal semantic information and easy to ignore discontinuous dependencies. However, excessive mining of information content will lead to the acquisition of some redundant information, whose existence will affect the extraction of useful features and the detection ability of the model. To address these issues, this paper offers a graph-based pivotal semantic mining framework. Specifically, we model the content information as a graph structure, learn the semantic dependencies across segments through a gated graph neural network, and co-learn by combining the propagation features of rumors. Furthermore, in order to highlight the precious essential semantic information, a shared unit cell is offered to reduce the influence of redundant information. Experimental results on realworld datasets show that the proposed method exceeds existing methods in terms of benchmark testing.},
  archive      = {J_EAAI},
  author       = {Yeqing Yan and Yongjun Wang and Peng Zheng},
  doi          = {10.1016/j.engappai.2022.105613},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105613},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A graph-based pivotal semantic mining framework for rumor detection},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary aquila optimizer for 0–1 knapsack problems.
<em>EAAI</em>, <em>118</em>, 105592. (<a
href="https://doi.org/10.1016/j.engappai.2022.105592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization process entails determining the best values for various system characteristics in order to finish the system design at the lowest possible cost. In general, real-world applications and issues in artificial intelligence and machine learning are discrete, unconstrained, or discrete. Optimization approaches have a high success rate in tackling such situations. As a result, several sophisticated heuristic algorithms based on swarm intelligence have been presented in recent years. Various academics in the literature have worked on such algorithms and have effectively addressed many difficulties. Aquila Optimizer (AO) is one such algorithm. Aquila Optimizer (AO) is a recently suggested heuristic algorithm. It is a novel population-based optimization strategy. It was made by mimicking the natural behavior of the Aquila. It was created by imitating the behavior of the Aquila in nature in the process of catching its prey. The AO algorithm is an algorithm developed to solve continuous optimization problems in their original form. In this study, the AO structure has been updated again to solve binary optimization problems. Problems encountered in the real world do not always have continuous values. It exists in problems with discrete values. Therefore, algorithms that solve continuous problems need to be restructured to solve discrete optimization problems as well. Binary optimization problems constitute a subgroup of discrete optimization problems. In this study, a new algorithm is proposed for binary optimization problems (BAO). The most successful BAO-T algorithm was created by testing the success of BAO in eight different transfer functions. Transfer functions play an active role in converting the continuous search space to the binary search space. BAO has also been developed by adding candidate solution step crossover and mutation methods (BAO-CM). The success of the proposed BAO-T and BAO-CM algorithms has been tested on the knapsack problem, which is widely selected in binary optimization problems in the literature. Knapsack problem examples are divided into three different benchmark groups in this study. A total of sixty-three low, medium, and large scale knapsack problems were determined as test datasets. The performances of BAO-T and BAO-CM algorithms were examined in detail and the results were clearly shown with graphics. In addition, the results of BAO-T and BAO-CM algorithms have been compared with the new heuristic algorithms proposed in the literature in recent years, and their success has been proven. According to the results, BAO-CM performed better than BAO-T and can be suggested as an alternative algorithm for solving binary optimization problems.},
  archive      = {J_EAAI},
  author       = {Emine Baş},
  doi          = {10.1016/j.engappai.2022.105592},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105592},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Binary aquila optimizer for 0–1 knapsack problems},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bi-level optimization of charging scheduling of a battery
swap station based on deep reinforcement learning. <em>EAAI</em>,
<em>118</em>, 105557. (<a
href="https://doi.org/10.1016/j.engappai.2022.105557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid increase of in the number of electric vehicle (EV), battery swapping is becoming a promising idea because of its short service waiting time. However, in the face of the uncertainty of the power grid and EV behavior, it is difficult to achieve a forward-looking and fast-response scheduling in a large scale battery swap station (BSS). A new bi-level scheduling model is proposed to solve this problem, in which the upper level is built on a deep reinforcement learning (DRL) framework to optimally allocate power among the chargers, and the lower level is modeled as a series of MILP subproblems for dispatching power among the batteries in a charger. A prediction module is included in the DRL framework improve the foresight of the algorithm, and a safety module is designed to avoid unsafe actions. Experimental results indicate that the proposed approach has excellent performance in large scale problem solving. It reduces the operating costs of the BSS significantly while satisfying the maximum power demand constraint. This is able to provide more economic benefits for the BSS and help peak shaving and valley filling for the power grid.},
  archive      = {J_EAAI},
  author       = {Mao Tan and Zhuocen Dai and Yongxin Su and Caixue Chen and Ling Wang and Jie Chen},
  doi          = {10.1016/j.engappai.2022.105557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bi-level optimization of charging scheduling of a battery swap station based on deep reinforcement learning},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An online path planning algorithm for autonomous marine
geomorphological surveys based on AUV. <em>EAAI</em>, <em>118</em>,
105548. (<a
href="https://doi.org/10.1016/j.engappai.2022.105548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a data-driven bi-pattern (DDBP) path planning algorithm for ocean geomorphological surveys based on Autonomous Underwater Vehicles (AUVs). When an AUV conducts surveys in unknown areas, it uses the observation data of real-time side-scan sonar to conduct environment modeling to drive independent online path re-planning (PRP) according to the feature density of the interesting targets. Based on the DDBP algorithm, the AUV can autonomously focus on regions with rich target distribution and deviate from regions with sparse target distribution without prior knowledge of the task region. The quality and efficiency of the AUV-based surveys can be improved by focusing on the underwater detection area with high feature density. The DDBP algorithm includes two patterns: rough and fine scan, and the corresponding planning pattern is selected according to the distribution of the detected targets. AUV performs online PRP in the corresponding pattern according to the pre-identified strategy set. We conducted simulation experiments and selected sand waves and fish reefs as natural and artificial structures to conduct typical marine survey tests. Compared with the traditional marine survey method, the survey efficiency was increased by 33.6% and 29.6%, respectively, in the two DDBP survey experiments for sand waves; the efficiency increased by 32.9% and 36.7%, respectively, in the two groups of DDBP survey experiments on artificial reefs. The proposed general technical framework for online path planning driven by real-time observation data has good application prospects in underwater archaeology, rapid understanding of specific targets on the seafloor, and search of specific targets.},
  archive      = {J_EAAI},
  author       = {Yixiao Zhang and Qi Wang and Yue Shen and Bo He},
  doi          = {10.1016/j.engappai.2022.105548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An online path planning algorithm for autonomous marine geomorphological surveys based on AUV},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A qualitative systematic review of metaheuristics applied to
tension/compression spring design problem: Current situation,
recommendations, and research direction. <em>EAAI</em>, <em>118</em>,
105521. (<a
href="https://doi.org/10.1016/j.engappai.2022.105521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New metaheuristic algorithms have soared over the past ten years. A common practice in proposing a new algorithm is validating it on several benchmark functions and engineering problems. Although CEC benchmark problems are specifically designed to validate the performance of new meta-heuristics, engineering design problems from pressure vessels to springs have been used in hundreds of papers to prove algorithm efficiency. To date, no benchmark practices have been established yet, i.e., researchers design their own benchmark to validate their algorithm. Thus, the high number of new algorithms combined with the high number of different benchmarking setups complicates the comparing and validating processes. In this paper, we study benchmark practices related to engineering applications. In particular, our exhaustive qualitative systematic review focuses on metaheuristics applied to the tension/compression spring design problem (TCSDP). The aim of this study is threefold: (i) evaluate where the field stands in regards of algorithm performance on the TCSDP, (ii) evaluate benchmarking practices, and (iii) facilitate future algorithm comparison. For these purposes, we first review all the existing metaheuristics applied to the TCSDP in their first publication. For each paper, we gather the data regarding the problem definition, the simulation setup, and the optimized design. We evaluated the data through several metrics to find the best-optimized design so far. Our findings and analysis concluded that the field of metaheuristics and its benchmarking practice have not reached maturity yet. Thus, we recommend some actions to address the issues and provide future research directions.},
  archive      = {J_EAAI},
  author       = {Alexandros Tzanetos and Maude Blondin},
  doi          = {10.1016/j.engappai.2022.105521},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {105521},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A qualitative systematic review of metaheuristics applied to tension/compression spring design problem: Current situation, recommendations, and research direction},
  volume       = {118},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Withdrawal notice to: A novel hybrid based on
nature-inspired and stochastic fractal search algorithms for optimizing
of artificial neural network model in landslide susceptibility’ [eng.
Appl. Artif. Intell. 117PA (2022) 105457]. <em>EAAI</em>, <em>117</em>,
105700. (<a
href="https://doi.org/10.1016/j.engappai.2022.105700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Hossein Moayedi and Atefeh Ahmadi Dehrashid and Mohammad Hossein Gholizadeh},
  doi          = {10.1016/j.engappai.2022.105700},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105700},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Withdrawal notice to: A novel hybrid based on nature-inspired and stochastic fractal search algorithms for optimizing of artificial neural network model in landslide susceptibility’ [Eng. appl. artif. intell. 117PA (2022) 105457]},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Ada-CCFNet: Classification of multimodal direct
immunofluorescence images for membranous nephropathy via adaptive
weighted confidence calibration fusion network. <em>EAAI</em>,
<em>117</em>, 105637. (<a
href="https://doi.org/10.1016/j.engappai.2022.105637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the pathological diagnosis of early, late and non-membranous nephropathy, direct immunofluorescence is highly likely to present potentially specific lesions, while it is often overlooked due to the difficulty of screening with naked eyes. With the advanced progress of deep learning, they have shown powerful abilities in detecting potential lesions. In this paper, we propose an adaptive weighted confidence calibration fusion framework (Ada-CCFNet) consisting of a preprocessing module, an adaptive weighted confidence calibration fusion (Ada-CCF) module and a classification module for diagnosis of membranous nephropathy by classifying the multimodal direct immunofluorescence images. In the preprocessing module, we use the well-known U-Net to segment individual glomeruli and standardize their luminance appearance by the average luminance difference method, allowing the subsequent modules to focus more on the diseased glomerular region. Subsequently, in the Ada-CCF module, six confidence calibration methods are utilized for two main direct immunofluorescence images, IgG and C3, and the comprehensive calibration scores are obtained based on the adaptive weighted fusion of six confidence calibration methods to obtain more reliable confidence level, in which the adaptive weights are related with expected calibration error reductions. For the classification module, the weighted probability scores of IgG and C3 are jointly fed into the module to achieve the classification by random forest. Experimental results showed that Ada-CCFNet achieves the classification accuracy of 73.52%, surpassing the methods of using single IgG or C3 images and positive grade indicator with 8.24%, 8.94% and 22.76%, and outperforming the compared methods in the classification of membranous nephropathy.},
  archive      = {J_EAAI},
  author       = {Ruili Wang and Xueyu Liu and Fang Hao and Xing Chen and Xinyu Li and Chen Wang and Dan Niu and Ming Li and Yongfei Wu},
  doi          = {10.1016/j.engappai.2022.105637},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105637},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ada-CCFNet: Classification of multimodal direct immunofluorescence images for membranous nephropathy via adaptive weighted confidence calibration fusion network},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A decision tree model for the prediction of the stay time of
ships in brazilian ports. <em>EAAI</em>, <em>117</em>, 105634. (<a
href="https://doi.org/10.1016/j.engappai.2022.105634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maritime transport is an alternative modal logistic in transporting cargo for long distances and in large quantities. However, the logistical planning for this modal becomes costly due to the uncertainties, such as climatic conditions, cargo types, and port characteristics. Therefore, estimating the stay times of ships becomes an essential objective for the planning and scheduling of the waterway modal. Determining the time frame the port has to operate the ship, based on the expected time that ships stay moored, is a challenge for the port management. In the present study, we collected data on the main cargo movements in Brazilian ports in 2018 to develop a model for predicting the stay time of ships, using algorithms based on decision tree models. There are no studies in the literature on models for predicting the stay time of ships, which is the gap to be filled in this research. In addition, an exploratory data analysis was performed to discover the variables that most influence the stay time. This research used several classification machine learning algorithms (support vector machines, gradient boosting, decision tree, random forest, among others) to build stay time prediction. As a result, the best model generated was that of random forests that obtained acceptable performance, with accuracy and f1-score above 73%, and train and test times around 14 s and the most important features to the model involve geographical and cargo characteristics. Therefore, it is possible to use them in real environments to develop logistic planning of the waterway modal.},
  archive      = {J_EAAI},
  author       = {Levi R. Abreu and Ingrid S.F. Maciel and Joab S. Alves and Lucas C. Braga and Heráclito L.J. Pontes},
  doi          = {10.1016/j.engappai.2022.105634},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105634},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A decision tree model for the prediction of the stay time of ships in brazilian ports},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Incipient fault diagnosis of analog circuit with ensemble
HKELM based on fused multi-channel and multi-scale features.
<em>EAAI</em>, <em>117</em>, 105633. (<a
href="https://doi.org/10.1016/j.engappai.2022.105633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an essential part in electronics-rich system, the failure of analog circuits will severely affect the system reliability and security. Incipient fault of analog circuit refers to the early stage of degradation fault where the fault characteristics are generally weak and almost indistinguishable. In order to enhance the reliability of electronic systems, it is necessary to diagnose incipient faults of analog circuits promptly and effectively. Existing approaches generally capture fault characteristics only from single signal, ignoring the valuable information inherent in different domains and scales. To address this problem, a novel diagnostic strategy based on multi-scale feature extraction and multi-channel feature fusion is designed to guarantee the completeness and richness of fault information. In this study, a deep extreme learning machine denoising auto-encoder (DELM-DAE) based method is proposed to conduct unsupervised multi-scale and multi-channel feature fusion to extract distinguishable features for incipient faults. The proposed method has higher learning efficiency and overcomes the common problem of low efficiency in deep learning model training. Meanwhile, in order to improve the ability to distinguish high-resolution features, an ensemble hybrid kernel extreme learning machine with novel roulette selection and weighted voting scheme is proposed to enhance the recognition performance and stability. In the verification experiment, the diagnosis accuracy on four typical circuits all reaches above 98%, which demonstrates that the proposed incipient fault diagnosis method for analog circuits has more conspicuous performance than other state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Shengdong Wang and Zhenbao Liu and Zhen Jia and Zihao Li},
  doi          = {10.1016/j.engappai.2022.105633},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105633},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Incipient fault diagnosis of analog circuit with ensemble HKELM based on fused multi-channel and multi-scale features},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LACN: A lightweight attention-guided ConvNeXt network for
low-light image enhancement. <em>EAAI</em>, <em>117</em>, 105632. (<a
href="https://doi.org/10.1016/j.engappai.2022.105632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-light conditions usually have poor visual quality, and hence greatly reduce the accuracy of subsequent tasks such as image segmentation and detection. In the low-light image enhancement task, noises in the dark areas are generally amplified while the images’ brightness is enhanced. It should be pointed out that many deep learning methods cannot effectively suppress the noise at this stage and capture important feature information. To address the above problem, this paper proposes a Lightweight Attention-guided ConvNeXt Network (LACN) for low-light image enhancement. A novel Attention ConvNeXt Module (ACM) is first proposed by introducing a parameter-free attention module (i.e. SimAM) into the ConvNeXt backbone network. Then, a nontrivial lightweight network LACN based on a multi-attention mechanism is established through stacking two ACMs and fusing their features. In what follows, an improved hybrid attention mechanism, Selective Kernel Attention Module (SKAM), is adopted to effectively extract both global and local information. Such a module realizes the evaluation of lighting conditions for the whole image and the adaptive adjustment of the receptive field. Finally, through the feature fusion module, the features of different stages are aggregated to improve the ability of network to retain color information. Numerous experiments on low-light image enhancement are implemented via comparison with other state-of-the-art methods. Experiments show that the proposed method significantly improves the brightness and contrast of low-illumination images, preserves color information, and suppresses the generation of noises after image brightening.},
  archive      = {J_EAAI},
  author       = {Saijie Fan and Wei Liang and Derui Ding and Hui Yu},
  doi          = {10.1016/j.engappai.2022.105632},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105632},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LACN: A lightweight attention-guided ConvNeXt network for low-light image enhancement},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active learning based on computer vision and human–robot
interaction for the user profiling and behavior personalization of an
autonomous social robot. <em>EAAI</em>, <em>117</em>, 105631. (<a
href="https://doi.org/10.1016/j.engappai.2022.105631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots coexist with humans in situations where they have to exhibit proper communication skills. Since users may have different features and communicative procedures, personalizing human–robot interactions is essential for the success of these interactions. This manuscript presents Active Learning based on computer vision and human–robot interaction for user recognition and profiling to personalize robot behavior. The system identifies people using Intel-face-detection-retail-004 and FaceNet for face recognition and obtains users’ information through interaction. The system aims to improve human–robot interaction by (i) using online learning to allow the robot to identify the users and (ii) retrieving users’ information to fill out their profiles and adapt the robot’s behavior. Since user information is necessary for adapting the robot for each interaction, we hypothesized that users would consider creating their profile by interacting with the robot more entertaining and easier than taking a survey. We validated our hypothesis with three scenarios: the participants completed their profiles using an online survey, by interacting with a dull robot, or with a cheerful robot. The results show that participants gave the cheerful robot a higher usability score ( 82 . 14 / 100 points), and they were more entertained while creating their profiles with the cheerful robot than in the other scenarios. Statistically significant differences in the usability were found between the scenarios using the robot and the scenario that involved the online survey. Finally, we show two scenarios in which the robot interacts with a known user and an unknown user to demonstrate how it adapts to the situation.},
  archive      = {J_EAAI},
  author       = {Marcos Maroto-Gómez and Sara Marqués-Villaroya and José Carlos Castillo and Álvaro Castro-González and María Malfaz},
  doi          = {10.1016/j.engappai.2022.105631},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105631},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Active learning based on computer vision and human–robot interaction for the user profiling and behavior personalization of an autonomous social robot},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multisource traffic incident reporting and evidence
management in internet of vehicles using machine learning and
blockchain. <em>EAAI</em>, <em>117</em>, 105630. (<a
href="https://doi.org/10.1016/j.engappai.2022.105630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent transportation systems require efficient ways to manage traffic incidents like accidents and traffic rule violations. Secure logging of incident related data is important in case of accidents for forensic analysis, insurance, and legal settlements. Internet of vehicles can be enhanced using machine learning techniques to detect events automatically at the vehicle and road infrastructure level and blockchain can be used as a source for immutable evidence storage and management. The work proposes a framework addressing multiple challenges in traffic incident detection and evidence management like gathering of traffic event related evidence from multiple sources, addressing fault management in embedded vehicle on board units, resiliency from malicious event reporting and handling conflicting traffic incident event reports. The framework relies on a combination of cooperative event correlation and trust model to detect malicious and erroneous reporting of traffic incidents followed by Long Short term Memory (LSTM) and Bayesian model to resolve conflicting event reports. The events are correlated and verified before being transmitting onto the blockchain for evidence management and access control by various stakeholders. Analysis is presented highlighting the improvement in efficiency achieved by convergence of the multiple approaches proposed.},
  archive      = {J_EAAI},
  author       = {Abin Oommen Philip and RA.K. Saravanaguru},
  doi          = {10.1016/j.engappai.2022.105630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multisource traffic incident reporting and evidence management in internet of vehicles using machine learning and blockchain},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A method for creating a depth map based on a three-level
fuzzy model. <em>EAAI</em>, <em>117</em>, 105629. (<a
href="https://doi.org/10.1016/j.engappai.2022.105629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new fuzzy method for creating a depth map is presented in the article. It is based on a combination of Canny detector with a three-level fuzzy system and is designed to improve the accuracy of depth mapping. The first fuzzy model was developed to eliminate the errors inherent in Canny detector. The article presents examples to illustrate that Canny filter is not very sensitive to changes in the shape of the gradient. The second fuzzy model makes it possible to eliminate white color artifacts that appear due to the presence of identical large areas on a stereopair, for instance, the background. The third level of the fuzzy model refines the values of disparity obtained using the second level of the fuzzy model and the distances to the near left and right edges of the images obtained during four passes over the stereopair. It was found during the study that the following factors affect the accuracy of the resulting depth map: labels of membership functions of input variables of a three-level fuzzy system; the combination of t and s-norms in the compositional rules of fuzzy inference. The calculation of the root mean square error values made it possible to evaluate the proposed fuzzy model in relation to similar models. It has been established that value of Root Mean Square Error is minimal with the combination of MEAN-MEAN in the structure of fuzzy inference. And three-level fuzzy system for creating a depth map proposed in the article has a significant advantage over existing analogs.},
  archive      = {J_EAAI},
  author       = {Maxim Bobyr and Alexander Arkhipov and Sergey Emelyanov and Natalya Milostnaya},
  doi          = {10.1016/j.engappai.2022.105629},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105629},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A method for creating a depth map based on a three-level fuzzy model},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a cross-scale weighted feature fusion network
for hot-rolled steel surface defect detection. <em>EAAI</em>,
<em>117</em>, 105628. (<a
href="https://doi.org/10.1016/j.engappai.2022.105628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defects of hot-rolled steel would affect the performance and appearance of the final products. In order to detect steel surface defects efficiently, a cross-scale weighted feature fusion network for identifying defect categories and locating defects is proposed in this work. Combined with Laplace sharpening, the backbone in the YOLOv5s model is used to extract multi-scale defect features from input images. And then, an improved weighted bi-directional feature pyramid network embedded with residual modules is proposed to aggregate multi-scale feature maps for enhancing the robustness of multi-size defect representation. Finally, four prediction branches accompanied with prior bounding boxes by a k -means clustering algorithm are responsible for predicting defects with different sizes. The proposed detection network is verified on the NEU-DET dataset, and experimental results show that the proposed network can achieve 86.8% mAP with the IoU threshold of 0.5, and can efficiently process images at 51 fps with the RGB image size 640 × 640. The Laplace sharpening module, the k _means clustering module and the improved C3-BiFPN module all contribute to the improvement of performance (mAP) of the proposed network by 1.8%, 2.7% and 3.8%, respectively. Our experimental results demonstrate that the proposed framework can effectively detect the surface defects of hot-rolled steel, and has potential to be used for real-time surface defect detection. Meanwhile, the versatility of the proposed network for other types of defect detection is also evaluated on the MT dataset and the DAGM dataset.},
  archive      = {J_EAAI},
  author       = {Yuzhong Zhang and Wenjing Wang and Zhaoming Li and Shuangbao Shu and Xianli Lang and Tengda Zhang and Jingtao Dong},
  doi          = {10.1016/j.engappai.2022.105628},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105628},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of a cross-scale weighted feature fusion network for hot-rolled steel surface defect detection},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EFASPP u-net for semantic segmentation of night traffic
scenes using fusion of visible and thermal images. <em>EAAI</em>,
<em>117</em>, 105627. (<a
href="https://doi.org/10.1016/j.engappai.2022.105627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of self-driving cars increases driving safety and accelerates urban transportation. These systems must have robust and real-time understanding of traffic conditions and surroundings, both at day and night. Many semantic image segmentation techniques have been proposed based on deep neural networks to partition the traffic scene images as a substantial step. However, the proposed algorithms and public datasets are mostly based on visible images during the daytime. Also, most of these algorithms are computationally intensive. However, little research has been done to date to address the application of the fusion of thermal and visible images and the high-performance low-volume deep convolutional networks. In this paper, a multispectral Encoder Fused Atrous Spatial Pyramid Pooling (EFASPP) U-Net deep network is proposed to merge the features of the visible and thermal images recorded at night traffic scenes. The proposed network is designed based on the structure of the U-Net, due to its high accuracy and speed of processing, as well as no need for large training datasets. The fusion of visible and thermal features in the encoders of EFASPP U-Net network is performed using standard and atrous convolution layers. Also, a new multispectral dataset is developed in this work for night-time traffic scenes due to the lack of sufficient public dataset in this field. The major contributions of this work include a low-volume high-performance multispectral semantic segmentation network for smart vehicles and a new dataset for this application. The experimental results show the high accuracy and speed of the proposed method.},
  archive      = {J_EAAI},
  author       = {Faegheh Shojaiee and Yasser Baleghi},
  doi          = {10.1016/j.engappai.2022.105627},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105627},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EFASPP U-net for semantic segmentation of night traffic scenes using fusion of visible and thermal images},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel failure mode and effect analysis method using a
flexible knowledge acquisition framework based on picture fuzzy sets.
<em>EAAI</em>, <em>117</em>, 105625. (<a
href="https://doi.org/10.1016/j.engappai.2022.105625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effect analysis (FMEA) is an effective reliability management tool for identifying potential failures in a system/component that has been widely utilized in various fields by combining fuzzy sets theory. However, the difficulty in assessment expression and acquisition, imprecision in assessment aggregation, and missing relationships among risk factors are prominent challenges in the existing fuzzy FMEA methods. Thus, this work employs the picture fuzzy sets (PFSs) theory to meet these challenges, allowing experts to express assessments more efficiently and accurately. Meanwhile, we propose a novel FMEA method to improve the three essential processes of FMEA, involving the following steps. Firstly, a flexible knowledge acquisition framework (FKAF) is established to simplify the expert evaluation process, allowing experts to express fuzzy information with various forms of non-fuzzy assessments. Then, a strategy-based picture fuzzy conversion (PFC) method is developed to standardize the non-fuzzy values to picture fuzzy numbers (PFNs). Secondly, to improve the assessment aggregation accuracy in uncertain environments, we suggest the picture fuzzy evidential reasoning (PFER) method that extend the existing fuzzy evidential reasoning (FER) methods. Thirdly, to completely describe the parallel and causal relationships among risk factors, four alternative models are established using picture fuzzy Petri nets (PFPNs) and risk priority rankings are determined through inference. Finally, the effectiveness and superiority of the proposed FMEA method are verified through two case studies and one extended experiment, demonstrating that it overcomes the shortcomings of the existing FMEA methods and reduces application costs while ensuring the rationality of rankings.},
  archive      = {J_EAAI},
  author       = {Xiang-Kun Zhao and Xiao-Min Zhu and Kai-Yuan Bai and Run-Tong Zhang},
  doi          = {10.1016/j.engappai.2022.105625},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105625},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel failure mode and effect analysis method using a flexible knowledge acquisition framework based on picture fuzzy sets},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label confidence-based noise correction for crowdsourcing.
<em>EAAI</em>, <em>117</em>, 105624. (<a
href="https://doi.org/10.1016/j.engappai.2022.105624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In crowdsourcing scenarios, each instance obtains multiple noisy labels from different crowd workers and then gets its integrated label via a label aggregation method. In spite of the effectiveness of label aggregation methods, a certain level of noise still remains in the integrated labels. To solve this problem, several noise correction methods have been proposed in recent years. However, to our best knowledge, these methods seldom take the label confidence of each instance into account. Therefore, we propose a label confidence-based noise correction (LCNC) method. At first, LCNC calculates the label confidence of each instance using its multiple noisy labels to filter all instances and obtains an original clean set and noise set. Second, LCNC builds multiple random trees on the original clean set to recalculate the label confidence of each instance using its predicted labels generated by these random trees and then refilters all instances to obtain a new clean set and noise set. Finally, LCNC builds two heterogeneous classifiers on the new clean set to correct the noise instances in the new noise set according to a consensus voting strategy. The experimental results on 34 simulated and two real-world crowdsourced datasets show that LCNC significantly outperforms all the other state-of-the-art noise correction methods used for comparison.},
  archive      = {J_EAAI},
  author       = {Lijuan Ren and Liangxiao Jiang and Chaoqun Li},
  doi          = {10.1016/j.engappai.2022.105624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Label confidence-based noise correction for crowdsourcing},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey of recently developed metaheuristics and their
comparative analysis. <em>EAAI</em>, <em>117</em>, 105622. (<a
href="https://doi.org/10.1016/j.engappai.2022.105622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study was to gather, discuss, and compare recently developed metaheuristics to understand the pace of development in the field of metaheuristics and make some recommendations for the research community and practitioners. By thoroughly and comprehensively searching the literature and narrowing the search results, we created with a list of 57 novel metaheuristic algorithms. Based on the availability of the source code, we reviewed and analysed the optimization capability of 26 of these algorithms through a series of experiments. We also evaluated the exploitation and exploration capabilities of these metaheuristics by using 50 unimodal functions and 50 multimodal functions, respectively. In addition, we assessed the capability of these algorithms to balance exploration and exploitation by using 29 shifted, rotated, composite, and hybrid CEC-BC-2017 benchmark functions. Moreover, we evaluated the applicability of these metaheuristics on four real-world constrained engineering optimization problems. To rank the algorithms, we performed a nonparametric statistical test, the Friedman mean rank test. Based on the statistical results for the unimodal and multimodal functions, we declared that the GBO, PO, and MRFO algorithms have better exploration and exploitation capabilities. Based on the results for the CEC-BC-2017 benchmark functions, we found the MPA, FBI, and HBO algorithms to be the most balanced. Finally, based on the results for the constrained engineering optimization problems, we declared that the HBO, GBO, and MA algorithms are the most suitable. Collectively, we confidently recommend the GBO, MPA, PO, and HBO algorithms for real-world optimization problems.},
  archive      = {J_EAAI},
  author       = {Abdulaziz Alorf},
  doi          = {10.1016/j.engappai.2022.105622},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105622},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A survey of recently developed metaheuristics and their comparative analysis},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Imbalanced data classification: Using transfer learning and
active sampling. <em>EAAI</em>, <em>117</em>, 105621. (<a
href="https://doi.org/10.1016/j.engappai.2022.105621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning models have made great breakthroughs in the field of computer vision, relying on large-scale class-balanced datasets. However, most of them do not consider the class-imbalanced data. In reality, the class-imbalanced distribution can lead to the degradation of model performance, reducing the generalization of these models. In addition, in the era of big data, many applications need to use real-time visual data. These data come from different mobile devices, which continuously generate a huge number of visual data. However, there are few studies using real-time data from information systems, real-time data is easy to capture but difficult to use. In order to solve the above problems, we propose a new model (Transfer Learning Classifier, TLC) based on transfer learning to deal with class-imbalanced data. The model includes active sampling module, real-time data augmentation module and DenseNet module. Among them, (1) the newly proposed active sampling module can dynamically adjust the number of samples with skewed distribution; (2) the data augmentation module can expand the real-time data to avoid over-fitting and insufficient data; (3) the DenseNet module is a standard DenseNet network pre-trained on the ImageNet dataset and transferred to TLC for relearning, and then we adjust the memory usage of the standard DenseNet to make it more efficient. In addition, we have applied a new end-to-end real-time data storage and analysis system. A large number of experiments have been carried out on four different long mantissa data sets. Experimental results show that the proposed TLC model can effectively deal with the static data as well as the real-time data, and the classification effect of imbalanced data is better than that of existing models.},
  archive      = {J_EAAI},
  author       = {Yang Liu and Guoping Yang and Shaojie Qiao and Meiqi Liu and Lulu Qu and Nan Han and Tao Wu and Guan Yuan and Tao Wu and Yuzhong Peng},
  doi          = {10.1016/j.engappai.2022.105621},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105621},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Imbalanced data classification: Using transfer learning and active sampling},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). An exploitation-boosted sine cosine algorithm for global
optimization. <em>EAAI</em>, <em>117</em>, 105620. (<a
href="https://doi.org/10.1016/j.engappai.2022.105620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sine cosine algorithm (SCA) has drawn significant attention from researchers in different fields because of fewer control parameters, excellent global optimization ability, and simple principles. However, there are some drawbacks of the SCA which needed immediate attention. The position-updated equation of the SCA is good at exploration but poor at exploitation, which leads to slow converging speed and low converging accuracy in some complex cases. Therefore, an exploitation-boosted sine cosine algorithm (namely, EBSCA) is proposed in this study. In order to enhance the ability of exploitation, a new position-updated equation is designed by emphasizing the position information of the best individual, thereby guiding the updating of new candidate individuals. Meanwhile, the information weights of the best individual and the current individual in the new equation are dynamically adjusted by a balance factor b to avoid over-exploitation of the information from the best individual. Furthermore, a new integration way of combining the quantization orthogonal crossover strategy with the SCA is proposed to improve the utilizing efficiency of the searching space. The performance of the EBSCA is evaluated by being tested on 13 classical benchmark functions, IEEE CEC 2015 problems, and four well-known engineering applications. The comparisons demonstrate that the EBSCA algorithm obviously improves the performance of the SCA. Additionally, the experimental results show that , the proposed EBSCA algorithm exhibits higher competitiveness compared to other algorithms participated in this research.},
  archive      = {J_EAAI},
  author       = {Changlun Li and Ke Liang and Yuan Chen and Mingzhang Pan},
  doi          = {10.1016/j.engappai.2022.105620},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105620},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An exploitation-boosted sine cosine algorithm for global optimization},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive and intelligent robot task planning for home
service: A review. <em>EAAI</em>, <em>117</em>, 105618. (<a
href="https://doi.org/10.1016/j.engappai.2022.105618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainty and dynamic of home environment present great challenges to the task planning of service robots. The nature of the home environment is highly unstructured, with a diversity of tasks and a variety of objects. In addition, human, the service principle of robots, dynamically changes the environment and shows a large number of demands in the form of commands. Therefore, interaction is necessary. Robots must have the ability to adapt to complex scenes and act intelligently. Robot task planning for serving in unstructured and dynamic home scenes has been overlooked in the existing reviews. This paper firstly explores primary sources of uncertainty in-depth and summarizes three challenges, i.e., reliable planning under uncertain and incomplete information, efficient planning for complex tasks, and scalable planning for task generalization. Secondly, key solutions to the three challenges are discovered; the advantages and limitations of various task planning techniques are assessed from the perspective of adaptability and intelligence. Finally, the promising avenues toward overcoming uncertainty, improving satisfaction and comfort of users, and enhancing learning skills and generalization are proposed.},
  archive      = {J_EAAI},
  author       = {Haizhen Li and Xilun Ding},
  doi          = {10.1016/j.engappai.2022.105618},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105618},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive and intelligent robot task planning for home service: A review},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Influence of exogenous factors on water demand forecasting
models during the COVID-19 period. <em>EAAI</em>, <em>117</em>, 105617.
(<a href="https://doi.org/10.1016/j.engappai.2022.105617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water scarcity has urged the need for adequate water demand forecasting to facilitate efficient planning of municipal infrastructure. However, the development of water consumption models is challenged by the rapid environmental and socio-economic changes, particularly during unforeseen events like the COVID-19 pandemic. This study investigated the impact of COVID-19 on the efficiency of water demand prediction models, considering the lockdown measures and various exogenous features, such as previous consumption (PC) and socio-demographic (SDF), seasonal (SF), and climatic (CF) factors. Multiple ensemble models, gradient-boosting machines (GBM), extreme-gradient-boosting (XGB), light-gradient-boosting, random forest (RF), and stack regressor (STK) were examined, compared to other machine-learning techniques, multiple-linear regression (MLR), decision trees, and neural networks. The models were tested using 3-year metering records for 128,000 consumers in Dubai. The feature importance analysis indicated that PC and SDF had a significant impact on consumption rates with correlation coefficients of 0.95 and 0.74, respectively, as opposed to SF and CF, which had negligible effect. The results showed that, before COVID, RF and STK outperformed other models with a coefficient-of-determination (R 2 ) and root-mean-squared-error (RMSE) of 0.928 and 0.039, followed by XGB at 0.923 and 0.041, respectively. However, MLR achieved the highest prediction accuracy amid COVID with R 2 and RMSE of 0.90 and 0.05, followed by GBM and XGB equally at 0.83 and 0.06, respectively. An ensemble-based error prediction model was applied, resulting in up to 9.2% improvement in predictions. Overall, this research emphasized the efficiency of ensemble models in handling fluctuating data with a high degree of nonlinearity.},
  archive      = {J_EAAI},
  author       = {Manar Abu Talib and Mohamed Abdallah and Abdulrahman Abdeljaber and Omnia Abu Waraga},
  doi          = {10.1016/j.engappai.2022.105617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Influence of exogenous factors on water demand forecasting models during the COVID-19 period},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic segmentation-based system for fall detection and
post-fall posture classification. <em>EAAI</em>, <em>117</em>, 105616.
(<a href="https://doi.org/10.1016/j.engappai.2022.105616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall is one of the most critical issues faced by elders in their daily life. The consequences of falls range from fatal injuries, severe injuries to no injuries. Therefore, an effective system for detecting falls and treating post-fall injuries is important. Unlike wearable sensors, camera-based systems seem more comfortable and flexible for daily life monitoring. However, monitoring human activities in real settings using cameras is not only challenging but also pose privacy issues. To mitigate this problem, we propose a surveillance camera-based framework for fall detection and post-fall classification where the human silhouette is extracted and used instead of raw images. The human silhouette is obtained using a pixel-level classification based on a Multi-Scale Skip Connection Segmentation Network (MSSkip), which is shown to achieve state-of-the-art performance on the validation set from PASCAL VOC 2012 dataset for the class Person with an IoU of 90%. The temporal and spatial variations of the human poses are fed to a Convolutional Long Short Term Memory (ConvLSTM) network to detect whether or not a fall has occurred. The proposed fall detection method achieved an F1-score of 97.68% on the UP Fall dataset, and state-of-art performance on the UR Fall detection database. For post-fall posture classification, the Xception network is shown to achieve an F1-score of 97.85% on our customized post-fall dataset.},
  archive      = {J_EAAI},
  author       = {Sara Mobsite and Nabih Alaoui and Mohammed Boulmalf and Mounir Ghogho},
  doi          = {10.1016/j.engappai.2022.105616},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105616},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic segmentation-based system for fall detection and post-fall posture classification},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximal margin hyper-sphere SVM for binary pattern
classification. <em>EAAI</em>, <em>117</em>, 105615. (<a
href="https://doi.org/10.1016/j.engappai.2022.105615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel maximal margin hyper-sphere support vector machine (MMHS-SVM) for binary pattern classification. Our proposed MMHS-SVM aims to find two hyper-spheres simultaneously by solving a single quadratic programming problem and is consistent between its predicting and training processes. An essential difference that distinguishes it from other hyper-sphere SVMs is that the optimization model is constructed by maximizing the sum of the square distance between centers of two hyper-spheres, but not the sum of squares distances from the center of hyper-sphere to all examples of the opposite class. Such a principle of structural risk in our MMHS-SVM not only helps us grasp the critical samples and eliminate a large number of redundant samples, but also reduces the test cost due to the sparsity. In addition, an effective SMO-typed algorithm is designed to decrease the high time complexity and storage. Finally, a large number of experiments verify the above statements again. The experimental results on several artificial and publicly available benchmark datasets show the feasibility and effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Ting Ke and Yangyang Liao and Mengyan Wu and Xuechun Ge and Xinyi Huang and Chuanlei Zhang and Jianrong Li},
  doi          = {10.1016/j.engappai.2022.105615},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105615},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maximal margin hyper-sphere SVM for binary pattern classification},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unmanned ground weapon target assignment based on deep
q-learning network with an improved multi-objective artificial bee
colony algorithm. <em>EAAI</em>, <em>117</em>, 105612. (<a
href="https://doi.org/10.1016/j.engappai.2022.105612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various objective functions in the operation process of unmanned ground combat vehicles (UGVs) have an important impact on the equilibrium of the system. Unbalanced scheduling of unmanned ground combat vehicles and poor target strikes exist in complex urban battlefields. A new multi-weapon target assignment architecture and a multi-objective artificial bee colony (MOABC) algorithm with an elite strategy are proposed to solve these problems. Considering the influence of mutation operator on multi-objective assignment, by introducing the action mechanism of the self-adaptive variation operator and combining the state representation of the nectar source with the overall allocation scheme, the deep Q-learning network with improved multi-objective artificial bee colony (MOADQN) algorithm is proposed. Through comparative analysis with multi-objective artificial bee colony algorithm, non-dominated sorting genetic algorithm-II (NSGA-II), multi-objective particle swarm optimization (MOPSO), the multi-objective evolutionary algorithm based on decomposition with electronic countermeasure (ECM-MOEA/D) and the deep Q-learning network with multi-objective artificial bee colony (MOAIQL) algorithm, the proposed MOADQN algorithm can solve the problems such as poor allocation effectiveness and low gain of traditional algorithms. The proposed MOADQN algorithm has significant advantages in solving multi-objective optimization problems and strong expansion performance in the complex urban environment.},
  archive      = {J_EAAI},
  author       = {Tong Wang and Liyue Fu and Zhengxian Wei and Yuhu Zhou and Shan Gao},
  doi          = {10.1016/j.engappai.2022.105612},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105612},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unmanned ground weapon target assignment based on deep Q-learning network with an improved multi-objective artificial bee colony algorithm},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Error-output recurrent multi-layer kernel reservoir network
for electricity load time series forecasting. <em>EAAI</em>,
<em>117</em>, 105611. (<a
href="https://doi.org/10.1016/j.engappai.2022.105611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electricity is one of the most consumed commodities in the modern world. Electricity load prediction models are used to plan distribution operations to balance the equilibrium of demand and supply. This necessity has increased the number of recent research works. They employed several learning algorithms, such as support vector regression, to predict demands. However, these algorithms have high computational cost and too many user-defined parameters that directly impact their performance. Recently, randomization-based learning algorithms have been widely tested because they performed well at a lower cost. However, still, there was a main drawback: uncertainty in approximation and learning. This work employed a kernel trick to solve the uncertainty problem. A kernel with reservoir-state layers was used to solve the problem. The kernel reservoir-state layers from the echo state network not only transformed features into high-dimensional space, but also enhanced the forecasting ability by learning temporal information. Additionally, the proposed model also had a multi-step prediction ability that used previous forecasting errors to update the output weights in the current step to prevent an accumulated error problem. We compared our proposed model with single-layer and multi-layer variants of Extreme Learning Machine, Echo State Network, and Random Vector Functional Link on ten electrical load data sets. The proposed model showed the best performance on 9/10 data sets in terms of Mean Square Error or Symmetric Mean Absolute Percentage Error. These findings implied that the proposed algorithm was superior in forecasting long-term electricity load.},
  archive      = {J_EAAI},
  author       = {Zongying Liu and Ghalib Ahmed Tahir and Naoki Masuyama and Habeebah Adamu Kakudi and Zhongyu Fu and Kitsuchart Pasupa},
  doi          = {10.1016/j.engappai.2022.105611},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105611},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Error-output recurrent multi-layer kernel reservoir network for electricity load time series forecasting},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new situation assessment method for aerial targets based
on linguistic fuzzy sets and trapezium clouds. <em>EAAI</em>,
<em>117</em>, 105610. (<a
href="https://doi.org/10.1016/j.engappai.2022.105610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Situation assessment has attracted much attention. The chief aim of this paper is to research the problem from the perspective of multicriteria group decision-making (MCGDM). First of all, this paper expresses the threat information with linguistic fuzzy sets, including Atanassov’s intuitionistic fuzzy sets (AIFSs), Atanassov’s interval-valued intuitionistic fuzzy sets (AIVIFSs), and interval intuitionistic uncertain linguistic sets (IIULSs). Then, some relevant concepts and aggregation operators of trapezium clouds are proposed, meanwhile, a new approach that calculates the weights considering subjectivity and objectivity is presented with multi-objective programming. Next, the conversion methods between AIFSs, AIVIFSs, IIULSs and trapezium clouds are derived. Finally, the algorithm process is presented and an illustrative example is employed to prove the validity. Also, the comparison analysis with other widely used methods is conducted to verify the feasibility of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Qianlei Jia and Jiayue Hu and Weiguo Zhang and Shaobo Zhai and Zhaoxing Li},
  doi          = {10.1016/j.engappai.2022.105610},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105610},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new situation assessment method for aerial targets based on linguistic fuzzy sets and trapezium clouds},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design method for polyurethane-modified asphalt by using
kriging-particle swarm optimization algorithm. <em>EAAI</em>,
<em>117</em>, 105609. (<a
href="https://doi.org/10.1016/j.engappai.2022.105609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preparation process of polyurethane (PU)-modified bitumen involves numerous design parameters and performance response indexes. Due to the variety of polyurethane modifiers, the preparation process of the polyurethane-modified bitumen is not universally applicable. However, the traditional methods such as the response surface method and orthogonal design method have some problems such as low accuracy and a large number of samples required in the preparation process design. Therefore, according to different application environments, the problem of determining the process parameters of the polyurethane-modified bitumen accurately and efficiently needs to be solved urgently. Using Kriging-Particle Swarm Optimization (PSO) algorithm, an efficient process design method for the preparation of polyurethane modified asphalt is proposed in this paper. Combined with the sensitivity analysis method, the relatively sensitive response indexes are screened out to reduce the number of samples and improve the design accuracy. Among them, the dispersion coefficient was evaluated by fluorescence microscopy test using the Christiansen coefficient method to evaluate the uniformity of the dispersed phase of the polyurethane modifier. According to the target performance, the main process parameters of PU modified asphalt were obtained by the Kriging-Particle Swarm Optimization algorithm: shear time 86 min, shear speed 2450 rpm, shear temperature 148 °C, and polyurethane content 18.6%. The polyurethane-modified bitumen prepared by this optimal process met the expected performance indicators. This study achieved the expected results with a small number of samples, indicating that this method can achieve the purpose of designing the ideal process parameters of polyurethane-modified asphalt efficiently.},
  archive      = {J_EAAI},
  author       = {Pengzhen Lu and Kai Ye and Tian Jin and Yiheng Ma and Simin Huang and Chenhao Zhou},
  doi          = {10.1016/j.engappai.2022.105609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design method for polyurethane-modified asphalt by using kriging-particle swarm optimization algorithm},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Sketch2Photo: Synthesizing photo-realistic images from
sketches via global contexts. <em>EAAI</em>, <em>117</em>, 105608. (<a
href="https://doi.org/10.1016/j.engappai.2022.105608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch-to-image synthesis aims to generate realistic images that match the input sketches or edge maps exactly. Most known sketch-to-image synthesis methods use various generative adversarial networks (GANs) that are trained with numerous pairs of sketches and real images. Because of the convolution locality, the low-level layers of the generators in these GANs lack global perception ability, causing feature maps derived from them easily to overlook global cues. Since the global receptive field is crucial for acquiring the non-local structures and features of sketches, the absence of global contexts will impact the generation of high-quality images. Some recent models turn to self-attention to construct global dependencies. However, they are not viable for large feature maps for the quadratic computational complexity concerning the size of feature maps. To address these problems, in this work, we propose Sketch2Photo — a new image synthesis approach that can capture global contexts as well as local features to generate photo-realistic images from weak or partial sketches or edge maps. We employ fast Fourier convolution (FFC) residual blocks to create global receptive fields in the bottom layers of the network and incorporate Swin Transformer block (STB) units to obtain long-range global contexts for large-size feature maps efficiently. We also present an improved spatial attention pooling (ISAP) module to relax the strict alignment requirements between incomplete sketches and generated images. Quantitative and qualitative experiments on multiple public datasets demonstrate the superiority of the proposed approach over many other sketch-to-image synthesis methods. The project code is available at https://github.com/hengliusky/Skecth2Photo .},
  archive      = {J_EAAI},
  author       = {Heng Liu and Yao Xu and Feng Chen},
  doi          = {10.1016/j.engappai.2022.105608},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105608},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sketch2Photo: Synthesizing photo-realistic images from sketches via global contexts},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiclass imbalanced and concept drift network traffic
classification framework based on online active learning. <em>EAAI</em>,
<em>117</em>, 105607. (<a
href="https://doi.org/10.1016/j.engappai.2022.105607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex problems of multiclass imbalance, virtual or real concept drift, concept evolution, high-speed traffic streams and limited label cost budgets pose severe challenges in network traffic classification tasks. In this paper, we propose a m ulticlass i mbalanced and c oncept drift network traffic classification f ramework based on o nline a ctive l earning (MicFoal), which includes a configurable supervised learner for the initialization of a network traffic classification model, an active learning method with a hybrid label request strategy, a label sliding window group, a sample training weight formula and an adaptive adjustment mechanism for the label cost budget based on a periodic performance evaluation. In addition, a novel uncertain label request strategy based on a variable least confidence threshold vector is designed to address the problems of a variable multiclass imbalance ratio or even the number of classes changing over time. Experiments performed based on eight well-known real-world network traffic datasets demonstrate that MicFoal is more effective and efficient than several state-of-the-art learning algorithms.},
  archive      = {J_EAAI},
  author       = {Weike Liu and Cheng Zhu and Zhaoyun Ding and Hang Zhang and Qingbao Liu},
  doi          = {10.1016/j.engappai.2022.105607},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105607},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiclass imbalanced and concept drift network traffic classification framework based on online active learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An analysis of explainability methods for convolutional
neural networks. <em>EAAI</em>, <em>117</em>, 105606. (<a
href="https://doi.org/10.1016/j.engappai.2022.105606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have gained a reputation of high accuracy in many domains. Convolutional Neural Networks (CNN) are specialized towards image recognition and have high accuracy in classifying objects within images. However, CNNs are an example of a black box model, meaning that experts are unsure how they work internally to reach a classification decision. Without knowing the reasoning behind a decision, there is low confidence that CNNs will continue to make accurate decisions, so it is unsafe to use them in high-risk or safety–critical​ fields without first developing methods to explain their decisions. This paper is a survey and analysis of the available explainability methods for showing the reasoning behind CNN decisions.},
  archive      = {J_EAAI},
  author       = {Lynn Vonder Haar and Timothy Elvira and Omar Ochoa},
  doi          = {10.1016/j.engappai.2022.105606},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105606},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An analysis of explainability methods for convolutional neural networks},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On some bridges to complex evidence theory. <em>EAAI</em>,
<em>117</em>, 105605. (<a
href="https://doi.org/10.1016/j.engappai.2022.105605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex evidence theory, an extension of Dempster–Shafer evidence theory, is a generalized evidence theory based on complex values, which has been widely used to solve decision making of uncertainty information. In order to make a step development based on previous researches, we set out to make a connection between CET and other uncertainty theories like possibility theory, modal logic, fuzzy set theory and probability theory. With a restricted condition of a special generalized consonant belief function, it is found that possibility and necessity measure can be regarded as generalized plausibility measure and belief measure in possibility theory, and the standard interpretation of fuzzy sets in complex evidence theory is obtained by summing up the experience of predecessors and modifying the upper bound of fuzzy sets in this paper. In addition, we established the relationship between generalized plausibility, belief function and modal logic, and elaborate how to explain the complex basic belief distribution with the general semantics of modern modal logic. Finally, the transformation algorithm between complex basic belief assignment and probability distribution is proposed by using the transformation of uncertainty invariance principle, and some properties of them are derived.},
  archive      = {J_EAAI},
  author       = {Junjie Huang and Yi Fan and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2022.105605},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105605},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On some bridges to complex evidence theory},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Benchmarking edge computing devices for grape bunches and
trunks detection using accelerated object detection single shot multibox
deep learning models. <em>EAAI</em>, <em>117</em>, 105604. (<a
href="https://doi.org/10.1016/j.engappai.2022.105604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: Visual perception enables robots to perceive the environment. Visual data is processed using computer vision algorithms that are usually time-expensive and require powerful devices to process the visual data in real-time, which is unfeasible for open-field robots with limited energy. This work benchmarks the performance of different heterogeneous platforms for object detection in real-time. This research benchmarks three architectures: embedded GPU—Graphical Processing Units (such as NVIDIA Jetson Nano 2 GB and 4 GB, and NVIDIA Jetson TX2), TPU—Tensor Processing Unit (such as Coral Dev Board TPU), and DPU—Deep Learning Processor Unit (such as in AMD/Xilinx ZCU104 Development Board, and AMD/Xilinx Kria KV260 Starter Kit). Methods: The authors used the RetinaNet ResNet-50 fine-tuned using the natural VineSet dataset. After the trained model was converted and compiled for target-specific hardware formats to improve the execution efficiency. Conclusions and Results: The platforms were assessed in terms of performance of the evaluation metrics and efficiency (time of inference). Graphical Processing Units (GPUs) were the slowest devices, running at 3 FPS to 5 FPS, and Field Programmable Gate Arrays (FPGAs) were the fastest devices, running at 14 FPS to 25 FPS. The efficiency of the Tensor Processing Unit (TPU) is irrelevant and similar to NVIDIA Jetson TX2. TPU and GPU are the most power-efficient, consuming about 5 W. The performance differences, in the evaluation metrics, across devices are irrelevant and have an F1 of about 70 % and mean Average Precision (mAP) of about 60 %.},
  archive      = {J_EAAI},
  author       = {Sandro Costa Magalhães and Filipe Neves dos Santos and Pedro Machado and António Paulo Moreira and Jorge Dias},
  doi          = {10.1016/j.engappai.2022.105604},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105604},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Benchmarking edge computing devices for grape bunches and trunks detection using accelerated object detection single shot multibox deep learning models},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation of spatial uncertainty in material property
distributions within heterogeneous structures using optimized
convolutional neural networks. <em>EAAI</em>, <em>117</em>, 105603. (<a
href="https://doi.org/10.1016/j.engappai.2022.105603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variations in material behaviors within structures built with heterogeneous materials lead to damage initiation and evolution in locally weak regions. Quantifying the property variability within the structure and forward propagation of the impact of the material property uncertainty on the structural response is critical for reliability analysis and structural performance maximization. Commonly, quantification of the variability requires either computationally expensive high-fidelity models of the underlying microstructure or extensive experimental testing. In this paper, we model the uncertainty with spatially correlated random fields and calibrate the model parameters from limited strain field observations using Neural Networks (NNs). The calibration is performed by trained NNs, which outputs best-fit parameters for the spatial correlation model by accepting filtered Digital Image Correlation (DIC) strain distributions as the input. We demonstrate that by training the NNs using simulated data, the resulting networks are able to calibrate the spatial distribution uncertainty models effectively for a set of Fused Filament Fabrication (FFF) printed structures. The methodology requires a limited number of experimental datasets and produces fast estimations of the best-fit parameters of the uncertainty model compared to optimization or inverse fitting methods. This method allows experimentalists to use the same DIC information routinely obtained during modulus or strength testing to calibrate a spatial property distribution uncertainty model for the underlying microstructure.},
  archive      = {J_EAAI},
  author       = {Emil Pitz and Sean Rooney and Kishore Pochiraju},
  doi          = {10.1016/j.engappai.2022.105603},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105603},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Estimation of spatial uncertainty in material property distributions within heterogeneous structures using optimized convolutional neural networks},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated schizophrenia detection using local descriptors
with EEG signals. <em>EAAI</em>, <em>117</em>, 105602. (<a
href="https://doi.org/10.1016/j.engappai.2022.105602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schizophrenia (SZ) is a severe mental disorder characterized by behavioral imbalance and impaired cognitive ability. This paper proposes a local descriptors-based automated approach for SZ detection using electroencephalogram (EEG) signals. Specifically, we introduce a local descriptor, histogram of local variance (HLV), for feature representation of EEG signals. The HLV is generated by using locally computed variances. In addition to HLV, symmetrically weighted-local binary patterns (SLBP)-based histogram features are also computed from the multi-channel EEG signals. Thus, obtained HLV and SLBP-based features are given to a correlation-based feature selection algorithm to reduce the length of the feature vector. Finally, the reduced feature vector is fed to an AdaBoost classifier to classify SZ and healthy EEG signals. Besides, we have tested the influence of the different lobe regions in detecting SZ. For this, we combined the features extracted from channels belonging to the same group and performed the classification. Experimental results on two publicly available datasets suggest the local descriptors computed from temporal lobe channels are very effective in capturing regional variations of EEG signals. The proposed local-descriptors-based approach obtained an average classification accuracy of 92.85% and 99.36% on Dataset-1 and Dataset-2, respectively, with only a feature vector of length 13.},
  archive      = {J_EAAI},
  author       = {T. Sunil Kumar and Kandala N.V.P.S. Rajesh and Shishir Maheswari and Vivek Kanhangad and U. Rajendra Acharya},
  doi          = {10.1016/j.engappai.2022.105602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated schizophrenia detection using local descriptors with EEG signals},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RRCNet: Refinement residual convolutional network for breast
ultrasound images segmentation. <em>EAAI</em>, <em>117</em>, 105601. (<a
href="https://doi.org/10.1016/j.engappai.2022.105601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast ultrasound images segmentation is one of the key steps in clinical auxiliary diagnosis of breast cancer, which seriously threatens women’s health. Currently, deep learning methods have been successfully applied to breast tumors segmentation. However, blurred boundaries, heterostructure and other factors can cause serious missed detections and false detections in the segmentation results. In this paper, we developed a novel refinement residual convolutional network to segment breast tumors accurately from ultrasound images, which mainly composed of SegNet with deep supervision module, missed detection residual network and false detection residual network. In SegNet, we add six side-out deep supervision modules to guide the network to learn to predict precise segmentation masks scale-by-scale. In missed detection residual network, the receptive field provided by different dilation rates can provide more global information, which is easily lost in deep convolutional layer. The introduction of false detection and missed detection residual network can promotes the network to make more efforts on those hardly-predicted pixels to help us obtain more accurate segmentation results of the breast tumor. To evaluate the segmentation performance of the network, we compared with several state-of-the-art segmentation approaches using five quantitative metrics on two public breast datasets. Experimental results demonstrate that our method achieves the best segmentation results, which indicates that our method has better adaptability on breast tumors segmentation.},
  archive      = {J_EAAI},
  author       = {Gongping Chen and Yu Dai and Jianxun Zhang},
  doi          = {10.1016/j.engappai.2022.105601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RRCNet: Refinement residual convolutional network for breast ultrasound images segmentation},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An inverse halftoning method for various types of halftone
images based on multi-scale generative adversarial network.
<em>EAAI</em>, <em>117</em>, 105600. (<a
href="https://doi.org/10.1016/j.engappai.2022.105600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse halftoning method based on deep neural network has been widely studied in last few years. However, the existing methods only apply single-size convolution kernel to extract image features and train the proposed model with only one-scale loss function, which leads to blurring details and residual halftone noise patterns in the restored continuous-tone image. To alleviate these problems, this paper proposes an inverse halftone method for various types of halftone images based on multi-scale generative adversarial network. In the generative model, an elaborated multi-scale feature extraction model is firstly designed to extract halftone image features in parallel, so as to obtain more comprehensive image information from the input halftone image and promote the effective fusion of the extracted features. Moreover, a detail enhancement subnetwork is employed to fine-tune the image details. In adversarial model, a multi-scale discriminator is used to further enhance the image details by learning the distribution characteristics of image information. The experiments on different types of halftone images show that the proposed method significantly outperforms the existing state-of-art methods.},
  archive      = {J_EAAI},
  author       = {Erhu Zhang and Mei Li and Qing Zhang and Lele Wu and Linhao Shao},
  doi          = {10.1016/j.engappai.2022.105600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An inverse halftoning method for various types of halftone images based on multi-scale generative adversarial network},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved TOPSIS-based multi-criteria decision-making
approach for evaluating the working condition of the aluminum reduction
cell. <em>EAAI</em>, <em>117</em>, 105599. (<a
href="https://doi.org/10.1016/j.engappai.2022.105599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The working condition evaluation of the aluminum reduction cell is the basis of formulating operation strategy, ensuring production safety and realizing stable and optimized operation of the aluminum electrolysis process. In this study, we deal with the cell working condition evaluation problem from a new perspective, and an improved Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) based multi-criteria decision-making approach is proposed. This approach starts from the process data and working condition standard. In order to obtain the appropriate weights to the process indicators, Criteria Importance Through Inter-criteria Correlation (CRITIC) approach is used in the proposed approach. Then the TOPSIS is used to calculate the relative closeness of the cell working condition to the working condition standard. Finally, a crisp level determination approach is used to provide a delicate level associated with the working condition standard. Two real cases demonstrated that the proposed approach is useful and effective in the working condition evaluation of the aluminum reduction cell.},
  archive      = {J_EAAI},
  author       = {Zhaoke Huang and Chunhua Yang and Xiaojun Zhou and Weihua Gui},
  doi          = {10.1016/j.engappai.2022.105599},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105599},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved TOPSIS-based multi-criteria decision-making approach for evaluating the working condition of the aluminum reduction cell},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A text mining-based approach for understanding chinese
railway incidents caused by electromagnetic interference. <em>EAAI</em>,
<em>117</em>, 105598. (<a
href="https://doi.org/10.1016/j.engappai.2022.105598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high-speed railway is a deeply coupled system with strong and weak electrical equipment, while complex electromagnetic interference (EMI) consequently brings potential risks and hazards to signaling safety. Since the incident reports on signaling failure intrinsically reflect the generation and evolution mechanism of equipment failures, relying on text mining technology, this paper tries to extract failure-related entities and constructs a knowledge graph to clarify the negative impact of the on-site electromagnetic environment. Firstly, based on convolutional neural networks (CNN), a supervised deep learning model for Chinese text classification is established to generate a corpus containing only railway failures caused by EMI. Then, the bidirectional long short-term memory (BiLSTM) and bidirectional encoder representations from transformers (BERT) algorithms are adopted to build the named entity recognition (NER) model. A NER algorithm more suitable for Chinese text features is proposed through ensemble modeling, training verification, and comparative evaluation. Finally, the knowledge storage and visualization of relational graph construction based on the Neo4j database are realized according to the obtained failure-related entities. This knowledge topology network effectively explores the inherent relationship between EMI factors and railway safety, as well as provides support for improving the safety assessment and enhancing the anti-interference performance of the equipment.},
  archive      = {J_EAAI},
  author       = {Chang Liu and Shiwu Yang},
  doi          = {10.1016/j.engappai.2022.105598},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105598},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A text mining-based approach for understanding chinese railway incidents caused by electromagnetic interference},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-tasking model of speaker-keyword classification for
keeping human in the loop of drone-assisted inspection. <em>EAAI</em>,
<em>117</em>, 105597. (<a
href="https://doi.org/10.1016/j.engappai.2022.105597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio commands are a preferred communication medium to keep inspectors in the loop of civil infrastructure inspection performed by a semi-autonomous drone. To understand job-specific commands from a group of heterogeneous and dynamic inspectors, a model must be developed cost-effectively for the group and easily adapted when the group changes. This paper is motivated to build a multi-tasking deep learning model that possesses a Share–Split–Collaborate architecture. This architecture allows the two classification tasks to share the feature extractor and then split subject-specific and keyword-specific features intertwined in the extracted features through feature projection and collaborative training. A base model for a group of five authorized subjects is trained and tested on the inspection keyword dataset collected by this study. The model achieved a 95.3% or higher mean accuracy in classifying the keywords of any authorized inspectors. Its mean accuracy in speaker classification is 99.2%. Due to the richer keyword representations that the model learns from the pooled training data Adapting the base model to a new inspector requires only a little training data from that inspector Like five utterances per keyword. Using the speaker classification scores for inspector verification can achieve a success rate of at least 93.9% in verifying authorized inspectors and 76.1% in detecting unauthorized ones. Further The paper demonstrates the applicability of the proposed model to larger-size groups on a public dataset. This paper provides a solution to addressing challenges facing AI-assisted human–robot interaction Including worker heterogeneity Worker dynamics And job heterogeneity.},
  archive      = {J_EAAI},
  author       = {Yu Li and Anisha Parsan and Bill Wang and Penghao Dong and Shanshan Yao and Ruwen Qin},
  doi          = {10.1016/j.engappai.2022.105597},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105597},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-tasking model of speaker-keyword classification for keeping human in the loop of drone-assisted inspection},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpreting the antecedents of a predicted output by
capturing the interdependencies among the system features and their
evolution over time. <em>EAAI</em>, <em>117</em>, 105596. (<a
href="https://doi.org/10.1016/j.engappai.2022.105596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision support systems (DSS) assist in a wide array of decision-making tasks in different domains. However, one of their common drawbacks is that their working is back box in nature. This means that while they recommend a decision, they cannot explain the ’why’ behind reaching that decision. In prescriptive tasks such as risk management, this does not assist the risk manager in identifying the contributing features leading to the occurrence of a risk output against which corrective action/s needs to be taken. This limitation has sparked interest in explainability, where glass-box methods interpret the contributing features leading to the recommended decision. Approaches which do that however do not model how the contributing features’ evolve over a period of time, till the predicted time period, to determine the output class before interpreting the reason for the decision output. To address these gaps, in this work we propose An Automated Interpretable Artificial Intelligence framework for Proactive Risk Management (AIAI-PRM). AIAI-PRM augments Local Interpretation-Driven Abstract Bayesian Network (LINDA-BN) with Knowledge Graph to determine the inter dependencies among the features, model how they evolve over a period of time and interpret the contributing features leading to the recommended output. In the domain of risk management, we show how this knowledge can be used by the risk manager to determine those key features against which risk management strategies need to be developed. Finally, we compare the AIAI-PRM’s output with that of the most commonly used XAI approaches, namely LIME and SHAP, to prove its superiority.},
  archive      = {J_EAAI},
  author       = {Sonia Farhana Nimmy and Omar K. Hussain and Ripon K. Chakrabortty and Farookh Khadeer Hussain and Morteza Saberi},
  doi          = {10.1016/j.engappai.2022.105596},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105596},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpreting the antecedents of a predicted output by capturing the interdependencies among the system features and their evolution over time},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Group decision making with hesitant fuzzy linguistic
preference relations based on multiplicative DEA cross-efficiency and
stochastic acceptability analysis. <em>EAAI</em>, <em>117</em>, 105595.
(<a href="https://doi.org/10.1016/j.engappai.2022.105595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to investigate a novel approach to group decision making (GDM) based on multiplicative DEA cross-efficiency and stochastic acceptability analysis with hesitant fuzzy linguistic preference relations (HFLPRs), which can avoid information distortion and obtain more credible decision-making results. First, a transform function is defined, which can extract effective information of the hesitant fuzzy linguistic term set (HFLTS) sufficiently. Then, an optimization model is proposed to derive the occurring probabilities of the elements in the HFLTS. It can avoid the normalization process of HFLPRs and simulate the element-selection process of decision makers (DMs). Moreover, a Maximum Log DEA Cross Efficiency model is proposed to evaluate the relative efficiency of each alternative from HFLPR. We further develop the stochastic weight space acceptability analysis method to solve the GDM problem and a step-by-step procedure is presented. Finally, numerical examples are given to illustrate the validity and applicability of the proposed method. This is the first attempt of employing the multiplicative DEA cross-efficiency to the GDM with HFLPRs.},
  archive      = {J_EAAI},
  author       = {Jingmiao Song and Peng Wu and Jinpei Liu and Huayou Chen},
  doi          = {10.1016/j.engappai.2022.105595},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105595},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Group decision making with hesitant fuzzy linguistic preference relations based on multiplicative DEA cross-efficiency and stochastic acceptability analysis},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Usefulness of synthetic datasets for diatom automatic
detection using a deep-learning approach. <em>EAAI</em>, <em>117</em>,
105594. (<a
href="https://doi.org/10.1016/j.engappai.2022.105594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benthic diatoms are unicellular microalgae that are routinely used as bioindicators for monitoring the ecological status of freshwater. Their identification using light microscopy is a time-consuming and labor-intensive task that could be automated using deep-learning. However, training such networks relies on the availability of labeled datasets, which are difficult to obtain for these organisms. Herein, we propose a method to generate synthetic microscopy images for training. We gathered individual objects, i.e. 9230 diatoms from publicly available taxonomic guides and 600 items of debris from available real images. We collated a comprehensive dataset of synthetic microscopy images including both diatoms and debris using seamless blending and a combination of parameters such as image scaling, rotation, overlap and diatom-debris ratio. We then performed sensitivity analysis of the impact of the synthetic data parameters for training state-of-the art networks for horizontal and rotated bounding box detection (YOLOv5). We first trained the networks using the synthetic dataset and fine-tuned it to several real image datasets. Using this approach, the performance of the detection network was improved by up to 25% for precision and 23% for recall at an Intersection-over-Union(IoU) threshold of 0.5. This method will be extended in the future for training segmentation and classification networks.},
  archive      = {J_EAAI},
  author       = {Aishwarya Venkataramanan and Pierre Faure-Giovagnoli and Cyril Regan and David Heudre and Cécile Figus and Philippe Usseglio-Polatera and Cédric Pradalier and Martin Laviale},
  doi          = {10.1016/j.engappai.2022.105594},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105594},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Usefulness of synthetic datasets for diatom automatic detection using a deep-learning approach},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive search space decomposition method for pre- and
post-buckling analyses of space truss structures. <em>EAAI</em>,
<em>117</em>, 105593. (<a
href="https://doi.org/10.1016/j.engappai.2022.105593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a novel adaptive search space decomposition method and a novel gradient-free optimization-based formulation for the pre- and post-buckling analyses of space truss structures. Space trusses are often employed in structural engineering to build large steel constructions, such as bridges and domes, whose structural response is characterized by large displacements. Therefore, these structures are vulnerable to progressive collapses due to local or global buckling effects, leading to sudden failures. The method proposed in this paper allows the analysis of the load-equilibrium path of truss structures to permanent and variable loading, including stable and unstable equilibrium stages and explicitly considering geometric nonlinearities. The goal of this work is to determine these equilibrium stages via optimization of the Lagrangian kinematic parameters of the system, determining the global equilibrium. However, this optimization problem is non-trivial due to the undefined parameter domain and the sensitivity and interaction among the Lagrangian parameters. Therefore, we propose to formulate this problem as a nonlinear, multimodal, unconstrained, continuous optimization problem and develop a novel adaptive search space decomposition method, which progressively and adaptively re-defines the search domain (hypersphere) to evaluate the equilibrium of the system using a gradient-free optimization algorithm. We tackle three benchmark problems and evaluate a medium-sized test representing a real structural problem in this paper. The results are compared to those available in the literature regarding displacement–load curves and deformed configurations. The accuracy and robustness of the adopted methodology show a high potential for gradient-free algorithms to analyze space truss structures.},
  archive      = {J_EAAI},
  author       = {Varun Ojha and Bartolomeo Pantò and Giuseppe Nicosia},
  doi          = {10.1016/j.engappai.2022.105593},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105593},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive search space decomposition method for pre- and post-buckling analyses of space truss structures},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature selection and feature learning in machine learning
applications for gas turbines: A review. <em>EAAI</em>, <em>117</em>,
105591. (<a
href="https://doi.org/10.1016/j.engappai.2022.105591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progress of machine learning (ML) in the past years has opened up new opportunities to the field of gas turbine (GT) modelling. However, successful implementation of ML algorithms remains challenging, particularly for complex problems such as multi-mode faults. An important tool for enabling applications are the feature selection and feature learning (FSFL) techniques. In particular, FL techniques have recently facilitated and improved the applicability of ML to GT modelling. This review paper conducts a review on 46 studies that utilised FSFL for GT modelling with ML. The purpose of this review is to investigate how FSFL techniques can help address GT modelling challenges and when researchers should deploy them. Therefore, the theories behind the techniques are illustrated in depth along with practical application examples from the analysed literature. The advantages and limitations of FSFL are discussed, the computational costs of different techniques are compared, and trends in the field are highlighted. Consequently, a novel categorisation framework for FSFL techniques and recommendations regarding when and how to implement them are provided. A new knowledge accumulation, extraction, and transfer concept is proposed to address GT modelling challenges.},
  archive      = {J_EAAI},
  author       = {Jiarui Xie and Manuel Sage and Yaoyao Fiona Zhao},
  doi          = {10.1016/j.engappai.2022.105591},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105591},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature selection and feature learning in machine learning applications for gas turbines: A review},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised 3D-InceptionNet for segmentation and
survival prediction of head and neck primary cancers. <em>EAAI</em>,
<em>117</em>, 105590. (<a
href="https://doi.org/10.1016/j.engappai.2022.105590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancers, known collectively as head and neck cancers, usually begin in the squamous cells that line the head and neck’s mucosal surfaces, forming a tumour mass. It usually develops in the salivary glands, nose and sinuses, voice box (larynx), throat (pharynx), or muscles or nerves in the head and neck, but these types of cancer are much less common than squamous cell carcinomas. Nearly 4% of all cancers are H&amp;N cancers with a very low survival rate (a five-year survival rate of 64.7%). The most commonly used molecular imaging procedure for diagnosing or guiding the treatment of head and neck cancer is Fluorodeoxyglucose-positron emission tomography scanning (FDG-PET/CT), which is often used in conjunction with computed tomography (CT) scanning, and sentinel node biopsy. This work presents a semi-supervised 3D Inception-Residual framework with 3D depth-wise convolution and squeeze and excitation block. In the first phase, we performed pre-training of 3D-auto-encoder using both train and test unlabelled dataset. We, then used pre-trained weight to fine-tune the later network which is aided with depth-wise convolution-inception encoder consisting of an additional 3D squeeze and excitation block and a 3D depth-wise convolution-based residual learning decoder under deep supervision ( Semi 3D-IncNet ). The proposed network not only helps to recalibrate the channel-wise features adaptively through explicit inter-dependencies modelling but also integrates the coarse and fine features resulting in accurate tumour segmentation. We further demonstrate the effectiveness of semi-supervised inception-residual encoder–decoder architecture in achieving better dice scores and the impact of depth-wise convolution in lowering the computational cost. For survival prediction, we applied random forest on deep, clinical, and radiomics features. Experiments were conducted on the benchmark HECKTOR2021 and HECKTOR2022 challenge showed significantly better performance by surpassing the state-of-the-artwork and achieved 0.824/0.836 and 0.754/0.678 Dice/Concordance index for HECKTOR2021 and HECKTOR2022 respectively. We made the model and code publicly available. 1},
  archive      = {J_EAAI},
  author       = {Abdul Qayyum and Moona Mazher and Tariq Khan and Imran Razzak},
  doi          = {10.1016/j.engappai.2022.105590},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105590},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised 3D-InceptionNet for segmentation and survival prediction of head and neck primary cancers},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A general motion controller based on deep reinforcement
learning for an autonomous underwater vehicle with unknown disturbances.
<em>EAAI</em>, <em>117</em>, 105589. (<a
href="https://doi.org/10.1016/j.engappai.2022.105589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the application of deep Reinforcement Learning (RL) in the motion control of an underactuated autonomous underwater vehicle (AUV) with unknown disturbances. Firstly, a general state space, action space and reward function are designed for motion control problems rather than each specific motion control task, which ensures the generality of our method. Furthermore, a virtual AUV model with partial random disturbances is established, and on this basis, a simulation training method is developed to solve the problems of extremely high risk and extremely low efficiency caused by training in actual experiments. Then, in order to directly deploy the optimal control policy obtained through simulation training to an actual AUV, we employ Extended State Observers (ESOs) to estimate the unknown disturbances in five degrees of freedom, and give a deployment method using the estimated values as the disturbance state vector and compensation vector. Combining the above training method and deployment method, a novel general motion controller is proposed. Finally, four different AUV motion control simulations are carried out, and the results confirm the generality and effectiveness of our proposed controller.},
  archive      = {J_EAAI},
  author       = {Fei Huang and Jian Xu and Di Wu and Yunfei Cui and Zheping Yan and Wen Xing and Xun Zhang},
  doi          = {10.1016/j.engappai.2022.105589},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105589},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A general motion controller based on deep reinforcement learning for an autonomous underwater vehicle with unknown disturbances},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IRMAC: Interpretable refined motifs in binary classification
for smart grid applications. <em>EAAI</em>, <em>117</em>, 105588. (<a
href="https://doi.org/10.1016/j.engappai.2022.105588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern power systems are experiencing the challenge of high uncertainty with the increasing penetration of renewable energy resources and the electrification of heating systems. In this paradigm shift, understanding electricity users’ demand is of utmost value to the retailers, aggregators, and policymakers. However, behind-the-meter (BTM) equipment and appliances at the household level are unknown to the other stakeholders mainly due to privacy concerns and tight regulations. In this paper, we seek to identify residential consumers based on their BTM equipment, mainly rooftop photovoltaic (PV) systems and electric heating, using imported/purchased energy data from utility meters. To solve this problem with an interpretable, fast, secure, and maintainable solution, we propose an integrated method called Interpretable Refined Motifs And binary Classification (IRMAC). The proposed method comprises a novel shape-based pattern extraction technique, called Refined Motif (RM) discovery, and a single-neuron classifier. The first part extracts a sub-pattern from the long time series considering the frequency of occurrences, average dissimilarity, and time dynamics while emphasising specific times with annotated distances. The second part identifies users’ types with linear complexity while preserving the transparency of the algorithms. With the real data from Australia and Denmark, the proposed method is tested and verified in identifying PV owners and electrical heating system users. The performance of the IRMAC is studied and compared with various state-of-the-art methods. The proposed method reached an accuracy of 96% in identifying rooftop PV users and 94.4% in identifying electric heating users, which is comparable to the best solution based on deep learning, while the speed of the inference model is a thousand times faster. Last but not least, the proposed method is a transparent algorithm, which can tackle the concerns regarding the agnostic decision-making process when policies prohibit some machine learning methods.},
  archive      = {J_EAAI},
  author       = {Rui Yuan and S. Ali Pourmousavi and Wen L. Soong and Giang Nguyen and Jon A.R. Liisberg},
  doi          = {10.1016/j.engappai.2022.105588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IRMAC: Interpretable refined motifs in binary classification for smart grid applications},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Self-supervised monocular depth estimation based on
combining convolution and multilayer perceptron. <em>EAAI</em>,
<em>117</em>, 105587. (<a
href="https://doi.org/10.1016/j.engappai.2022.105587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two mainstream approaches currently used for self-supervised monocular depth estimation. One option is to utilize a complete convolution method to construct the encoder and decoder; however, the local linear operation and the pooling method result in the loss of pixel information in each layer of the feature map, limiting the performance. Another way is to use the transformer and other methods for feature extraction on the encoder side, which are processed at a constant resolution at each stage and have a global receptive field. Therefore, more subtle depth features can be captured, and higher accuracy can be obtained. Unfortunately, the computational cost of self-attention is too large, which increases the memory overhead. With the comprehensive analysis of the advantages and disadvantages of the above two methods, this paper employs a combination of decomposed large kernel convolution and a multilayer perceptron (MLP) to design a new framework — CSMHNet (a hybrid of a Convolution, self-attention, and an MLP network). It cannot only compensate for the disadvantages of convolution static weights and locality but also significantly reduce the memory overhead compared to the transformer architecture while obtaining a more accurate and consistent depth. Experiments on the KITTI dataset demonstrate the effectiveness of our method, which significantly improves the depth prediction accuracy compared with other self-supervised methods.},
  archive      = {J_EAAI},
  author       = {Qiumei Zheng and Tao Yu and Fenghua Wang},
  doi          = {10.1016/j.engappai.2022.105587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised monocular depth estimation based on combining convolution and multilayer perceptron},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep deterministic policy gradient and active disturbance
rejection controller based coordinated control for gearshift manipulator
of driving robot. <em>EAAI</em>, <em>117</em>, 105586. (<a
href="https://doi.org/10.1016/j.engappai.2022.105586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the shift precision of the gearshift manipulator, a coordinated control method for the gearshift manipulator based on the Deep Deterministic Policy Gradient (DDPG) and Active Disturbance Rejection Controller (ADRC) is proposed. Firstly, the kinematic model and dynamics model of the gearshift manipulator are established. Secondly, a coordinated control strategy is proposed to solve the target rotation angle of the servo motor, so as to deal with the nonlinear trajectory problem caused by the mechanical decoupling strategy. Then, an ADRC-based controller and a DDPG-based parameter adjuster are proposed. A DDPG model is established to adaptively adjust the control parameters of ADRC through the target rotation angle, actual rotation angle and rotation angle error. Finally, the theoretical stability proof and experimental verification of the proposed method are conducted. The test results show that the mean absolute error of the proposed method is 34% and 18% lower than that of ADRC and fuzzy PID methods. It shows the effectiveness of the method.},
  archive      = {J_EAAI},
  author       = {Gang Chen and Zhifeng Chen and Liangmo Wang and Weigong Zhang},
  doi          = {10.1016/j.engappai.2022.105586},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105586},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep deterministic policy gradient and active disturbance rejection controller based coordinated control for gearshift manipulator of driving robot},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust multi-view subspace enhanced representation based on
collaborative constraints and HSIC induction. <em>EAAI</em>,
<em>117</em>, 105585. (<a
href="https://doi.org/10.1016/j.engappai.2022.105585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of effective multi-view subspace clustering (MSC) algorithms has recently garnered significant research attention. Herein, to effectively improve the recognition performance and anti-noise interference ability of an MSC model, we propose a novel MSC algorithm, termed as robust multi-view subspace enhancement representation, based on collaborative constraints and a Hilbert–Schmidt independence criterion (HSIC) induction method. To mine the complementary information between different views, we apply the HSIC as a diversity regularization term. Specifically, to enhance the diagonal block structure of a subspace representation, a new sparse constraint is introduced on the product of itself and the transpose of the subspace representation matrix in a multi-view subspace learning model. Furthermore, hypergraph regularization and a low-rank idea are considered to capture the local geometric structure and clean data. In addition, to optimize our model, we adopt an augmented Lagrangian multiplier method and discuss the convergence of the model. Extensive experiments on six challenging datasets reveal that the proposed method achieves a highly competent objective performance with and without noisy views, as compared with several state-of-the-art multi-view clustering methods.},
  archive      = {J_EAAI},
  author       = {Guoqing Liu and Hongwei Ge and Ting Li and Shuzhi Su and Shuangxi Wang},
  doi          = {10.1016/j.engappai.2022.105585},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105585},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust multi-view subspace enhanced representation based on collaborative constraints and HSIC induction},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heart action monitoring from pulse signals using a growing
hybrid polynomial network. <em>EAAI</em>, <em>117</em>, 105584. (<a
href="https://doi.org/10.1016/j.engappai.2022.105584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) is a common used noninvasive test to quickly detect the heart problem with high precision. However, devices used to collect continuous ECG waveforms under free-living conditions have several operational difficulties. As an alternative, photoplethysmography (PPG) signals can be conveniently collected by pulse sensors, which can be mounted onto wearable devices. In this paper, we study the relation between ECG waveforms and PPG signals by proposing a novel growing hybrid polynomial network (GHPN)). Based on the projections between adjacent layers, the network is designed to approximate the target signals with the recorded inputs and the multi-scale dynamics of the input series are explored gradually through the growth of layers. Two public datasets are employed to evaluate the performance of the proposed approach on the accuracy of waveform reconstruction and heart rate (HR) detection with the widely used metrics. Compared with the reference ECG waveforms, the normalized mean square error (NMSE) of the proposed approach is 0.248 and 0.216 for PPG-Dalia and CapnoBase datasets, which is smaller than the comparison approaches. The average absolute value (AAE) between the detected HR and reference HR is 0.93 and 1.05 for PPG-Dalia and CapnoBase datasets, which exhibit higher HR detection accuracy. Experimental results obtained from benchmark datasets clearly show that the proposed method can achieve higher similarity on the reconstructed morphology with higher HR detection accuracy. Moreover, the proposed approach make it possible to employ PPG sensors for long-term monitoring of the heart actions with higher precision.},
  archive      = {J_EAAI},
  author       = {Lu Wang and Chunhui Zhao and P. Takis Mathiopoulos and Tomoaki Ohtsuki},
  doi          = {10.1016/j.engappai.2022.105584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Heart action monitoring from pulse signals using a growing hybrid polynomial network},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Financing a two-stage sustainable supply chain using green
bonds: Preventing environmental pollution and waste generation.
<em>EAAI</em>, <em>117</em>, 105583. (<a
href="https://doi.org/10.1016/j.engappai.2022.105583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the crises of human beings today is the lack of natural resources and the increase in the production of industrial waste due to overproduction. Also, the gradual warming of the earth has become one of the most important topics of discussion today. However, the trend of increasing unnecessary production, the volume of waste, and consequently environmental pollution and damage to plants and animals is very significant. One solution to prevent this trend is to use a sustainable supply chain and encourage producers to participate in green projects. But the other important thing is that attention to the environment should not deprive decision-makers of increasing profits and returns. Therefore, it is necessary to decide on the selling price of products according to issues such as inflation, transportation costs, production costs, and other items. After entering the production field, producers may need an initial budget to continue their work. This initial budget can be repaid with green bonds. Accordingly, a sustainable supply chain is introduced in this research, and then a two-stage model is presented. In the first stage, the model calculates the optimal priced of items for the manufacturer and retailer. In the second stage, it finances the introduced sustainable supply chain using green bonds. The Benders decomposition and Meta Heuristic algorithms are used to solve the problem and several numerical examples and test problems are provided to show the applicability of the model. This study develops a new integrated model for pricing and financing a sustainable supply chain with the aim of reducing the costs of the manufacturer and due to the lack of an initial budget. The introduced model uses discounts to persuade the customers to buy again and recycle the products.},
  archive      = {J_EAAI},
  author       = {Hanieh Heydari and Ata Allah Taleizadeh and Fariborz Jolai},
  doi          = {10.1016/j.engappai.2022.105583},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105583},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Financing a two-stage sustainable supply chain using green bonds: Preventing environmental pollution and waste generation},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing health indicators and RUL prognostics for systems
with few failure instances and varying operating conditions using a LSTM
autoencoder. <em>EAAI</em>, <em>117</em>, 105582. (<a
href="https://doi.org/10.1016/j.engappai.2022.105582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most Remaining Useful Life (RUL) prognostics are obtained using supervised learning models trained with many labelled data samples (i.e., the true RUL is known). In aviation, however, aircraft systems are often preventively replaced before failure. There are thus very few labelled data samples available. We therefore propose a Long Short-Term Memory (LSTM) autoencoder with attention to develop health indicators for an aircraft system instead. This autoencoder is trained with unlabelled data samples (i.e., the true RUL is unknown). Since aircraft fly under various operating conditions (varying altitude, speed, etc.), these conditions are also integrated in the autoencoder. We show that the consideration of the operating conditions leads to robust health indicators and improves significantly the monotonicity, trendability and prognosability of these indicators. These health indicators are further used to predict the RUL of the aircraft system using a similarity-based matching approach. We illustrate our approach for turbofan engines. We show that the consideration of the operating conditions improves the monotonicity of the health indicators by 97%. Also, our approach leads to accurate RUL estimates with a Root Mean Square Error (RMSE) of 2.67 flights only. Moreover, a 19% reduction in the RMSE is obtained using our approach in comparison to existing supervised learning models.},
  archive      = {J_EAAI},
  author       = {Ingeborg de Pater and Mihaela Mitici},
  doi          = {10.1016/j.engappai.2022.105582},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105582},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Developing health indicators and RUL prognostics for systems with few failure instances and varying operating conditions using a LSTM autoencoder},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence for the metaverse: A survey.
<em>EAAI</em>, <em>117</em>, 105581. (<a
href="https://doi.org/10.1016/j.engappai.2022.105581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the massive growth of the Internet from the 1990s until now, various innovative technologies have been created to bring users breathtaking experiences with more virtual interactions in cyberspace. Many virtual environments have been developed with immersive experience and digital transformation, but most are incoherent instead of being integrated into a platform. In this context, metaverse has been introduced as a shared virtual world that is fueled by many emerging technologies. Among such technologies, artificial intelligence (AI) has shown the great importance of enhancing immersive experience and enabling human-like intelligence of virtual agents. In this survey, we make a beneficial effort to explore the role of AI, including machine learning algorithms and deep learning architectures, in the foundation and development of the metaverse. As the main contributions, we convey a comprehensive investigation of AI-based methods concerning several technical aspects (e.g., natural language processing, machine vision, blockchain, networking, digital twin, and neural interface) that have potentials to build virtual worlds in the metaverse. Furthermore, several primary AI-aided applications, including healthcare, manufacturing, smart cities, and gaming, are studied to be promisingly deployed in the virtual worlds. Finally, we conclude the key contribution and open some future research directions of AI for the metaverse. Serving as a foundational survey, this work will help researchers, including experts and non-experts in related fields, in applying, developing, and optimizing AI techniques to polish the appearance of virtual worlds and improve the quality of applications built in the metaverse.},
  archive      = {J_EAAI},
  author       = {Thien Huynh-The and Quoc-Viet Pham and Xuan-Qui Pham and Thanh Thi Nguyen and Zhu Han and Dong-Seong Kim},
  doi          = {10.1016/j.engappai.2022.105581},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105581},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence for the metaverse: A survey},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data preprocessing strategy in constructing convolutional
neural network classifier based on constrained particle swarm
optimization with fuzzy penalty function. <em>EAAI</em>, <em>117</em>,
105580. (<a
href="https://doi.org/10.1016/j.engappai.2022.105580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have attracted increasing attention in recent years because of their powerful abilities to extract and represent spatial/temporal information. However, for general data, its features are assumed to have weak or no correlation, and directly applying CNN to classify such data could result in poor classification performance. To address this problem, a combined technique of original data representation method of fuzzy penalty function-based constrained particle swarm optimization (FCPSO) and CNN, so-called FCPSO-CNN is designed to effectively solve the classification problems for generic dataset and applied to recognize (classify) black plastic wastes in recycling problems. In more detail, CPSO is introduced to optimize feature reordering matrix under constraints and the construction of this matrix is driven by fitness function of CNN that quantifies classification performance. The Mamdani type fuzzy inference system (FIS) is employed to realize the fuzzy penalty function (FPF) which is utilized to realize the constrained problems of CPSO as well as alleviate the issues of the original penalty function method suffering from the lack of robustness. Experimental results demonstrate that FCPSO-CNN achieves the best classification accuracy on 13 out of 17 datasets; the statistical analysis also confirms the superiority of FCPSO-CNN. An interesting point is worth to mention that some feature reordering matrices in the infeasible space come with better classification accuracy. It has been found that the proposed method results in more accurate solution than one-dimensional CNN, random reordering feature-based CNN and some well-known classifiers (e.g., Naive Bayes, Multilayer perceptron, Support vector machine).},
  archive      = {J_EAAI},
  author       = {Kun Zhou and Sung-Kwun Oh and Witold Pedrycz and Jianlong Qiu},
  doi          = {10.1016/j.engappai.2022.105580},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105580},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data preprocessing strategy in constructing convolutional neural network classifier based on constrained particle swarm optimization with fuzzy penalty function},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing short-term forecasting of daily precipitation
using numerical weather prediction bias correcting with XGBoost in
different regions of china. <em>EAAI</em>, <em>117</em>, 105579. (<a
href="https://doi.org/10.1016/j.engappai.2022.105579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate precipitation (P) short-term forecasts are important for engineering studies and water allocation. This study evaluated a method for bias correction of the Numerical Weather Prediction (NWP) of Global Ensemble Forecast System V2 forecasts based on the extreme gradient boosting (XGBoost) model (M3) and 689 meteorological stations in seven different climatic regions of China. The method used a common deviation correction for multiple meteorological factors to forecast P for 1–8 d ahead. It was also compared with the equidistant cumulative distribution functions matching a single weather factor (EDCDFm, M1) and the XGBoost model (M2). The M3 method had the best forecast performance. M1, M2, and M3 methods had an average root mean square error (RMSE) ranging from 2.292–17.049 mm, 1.844–18.835 mm, and 1.819–13.608 mm, respectively. The performance of each method tended to decrease as the lead time was extended. The average false alarm ratio (increased from 55.3%, 52.8% and 50.1% to 75.8%, 82.3% and 76.0%, respectively) and miss ratio (increased from 60.9%, 53.5% and 50.3% to 76.6%, 77.7% and 71.2%, respectively) also increased with an increased lead time for all methods. The forecast performance trended downwards from northwest to southeast China. However, each method’s significance in forecasting P’s determination coefficient showed a contrary pattern to the forecast accuracy. There was a general underestimation across the methods. The best performance for forecasting P was achieved in winter, with root mean square error values of 2.0–3.4 mm, followed in order by autumn &gt; spring &gt; summer. Factor P contributed the most to forecast P after bias correction of the XGBoost model (average Gain, Cover, and Frequency values of 0.55, 0.45, and 0.29, respectively). In summary, satisfactory performance could be obtained using the XGBoost model combined with multi-factor bias correction for NWP data to forecast daily P.},
  archive      = {J_EAAI},
  author       = {Jianhua Dong and Wenzhi Zeng and Lifeng Wu and Jiesheng Huang and Thomas Gaiser and Amit Kumar Srivastava},
  doi          = {10.1016/j.engappai.2022.105579},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105579},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing short-term forecasting of daily precipitation using numerical weather prediction bias correcting with XGBoost in different regions of china},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Binary particle swarm optimization with an improved genetic
algorithm to solve multi-document text summarization problem of hindi
documents. <em>EAAI</em>, <em>117</em>, 105575. (<a
href="https://doi.org/10.1016/j.engappai.2022.105575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic text summarization plays a vital role in text retrieval. However, very little interest, as well as attention to Hindi text summarization and the wide use of hybridization of an evolutionary and swarm-based method for solving optimization problems, motivates us to develop a technique for achieving better results. We have used a combination of the Title feature, Sentence length, Sentence position, Numerical Data, Thematic word, Proper Noun and Term frequency &amp; Inverse Sentence Frequency to find the results. The proposed BPSO-IGA comprising Binary Particle Swarm Optimization (BPSO) and an improved genetic algorithm finds a well-formatted summary from multiple documents. The method for calculating the score of the sentence is proposed initially. A combination of BPSO and IGA finds the features’ optimal scores and then is used to generate the final summary. The proposed method is compared with six well-known techniques, SummaRuNNer, ChunkRank, TGraph, UniRank, FF-SE, and MDS-ACS, on FIRE 2011 Hindi dataset. To strengthen the hypothesis that all seven features are required in the summary generation, the summary is also generated using only ONE and a combination of more than one feature. It is found that the best summary is generated when all seven features are considered. The BPSO-IGA performs best among all the methods for precision, recall, f-measure, cohesion, and non-redundancy. This research aims to design a multi-document extractive text summarizer for Hindi documents using a swarm intelligence and evolutionary algorithm-based hybrid approach.},
  archive      = {J_EAAI},
  author       = {Shailendra S. Aote and Anjusha Pimpalshende and Archana Potnurwar and Shantanu Lohi},
  doi          = {10.1016/j.engappai.2022.105575},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105575},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Binary particle swarm optimization with an improved genetic algorithm to solve multi-document text summarization problem of hindi documents},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatic topology optimization of echo state network based
on particle swarm optimization. <em>EAAI</em>, <em>117</em>, 105574. (<a
href="https://doi.org/10.1016/j.engappai.2022.105574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of time series forecasting is to predict the future trend of data based on the collected historical data, providing theoretical and data support for human judgment and decision making. Randomization-based echo state networks (ESNs) are widely used in the research and application field of time series analysis for their simple structure and fast training speed. The core of the ESN is its dynamic reservoir, which the original reservoir are randomly generated and controlled only by parameter sparsity, often performing poorly on complex tasks and affecting the performance of networks. Manual design of the topology of reservoir is difficult, time-consuming and inconvenient to operate, which is not conducive to the development of ESNs. The construction of a suitable reservoir topology for practical application problems to enrich reservoir dynamics is a hot research point for researchers. In this paper, an automatic optimization method is introduced into the topology optimization of ESN (TP-ESN), and the particle swarm optimization algorithm is used to optimize the topological construction of the ESN. The connection structure between the reservoir neurons is first encoded and then iteratively optimized. The optimized structure is decoded and then the reservoir is initialized for ESN training. Prediction results on Mackey–Glass benchmark time series and two electroencephalogram (EEG) datasets demonstrate that TP-ESN method can have better adaptability, stronger prediction ability and stability than several other manually designed ESN reservoir topologies in the case of relatively complex tasks.},
  archive      = {J_EAAI},
  author       = {Yu Xue and Qi Zhang and Adam Slowik},
  doi          = {10.1016/j.engappai.2022.105574},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105574},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic topology optimization of echo state network based on particle swarm optimization},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detection of zirconium hydrides in transmission electron
micrographs using deep neural networks. <em>EAAI</em>, <em>117</em>,
105573. (<a
href="https://doi.org/10.1016/j.engappai.2022.105573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zirconium alloys are commonly employed in nuclear power applications. Under typical operating conditions, hydrogen ingress can lead to the formation of brittle Zr hydrides in the alloy. To study this behavior, transmission electron microscopy (TEM) is routinely used to image hydrides in Zr-alloys. However, the analysis of these TEM micrographs is a complex time-consuming task. Here, we employed a mask region-based convolutional neural network (Mask R-CNN) to automate an essential part of the analysis process: the identification and annotation of hydrides. In addition, although training a neural network usually requires large training datasets (in the order of thousands of images), the proposed framework was developed using a limited training dataset with the recourse of transfer learning. This work shows that the Mask R-CNN is capable of correctly and quickly labeling thermo-mechanically cycled hydrides in TEM images of pressure tube material.},
  archive      = {J_EAAI},
  author       = {Yezhou Ni and Robert Topham and Travis Skippon and Jun-Tian Zhang and Sean Hanlon and Fei Long and Catalina Anghel and Edmanuel Torres and Mark R. Daymond and Laurent K. Béland},
  doi          = {10.1016/j.engappai.2022.105573},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105573},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection of zirconium hydrides in transmission electron micrographs using deep neural networks},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequency matching optimization model of ultrasonic scalpel
transducer based on neural network and reinforcement learning.
<em>EAAI</em>, <em>117</em>, 105572. (<a
href="https://doi.org/10.1016/j.engappai.2022.105572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem that the excitation frequency and resonant frequency of the transducer cannot keep synchronous, the output amplitude decreases and the vibration is unstable. In this study, the working principle of piezoelectric transducers is firstly analyzed by the equivalent circuit method and the instantaneous characteristic variables (installing preload, assembly preload, load, and other factors) that affect the frequency matching obtained to establish the equivalent relationship with the resonant frequency. Secondly, in order to make the synchronization between excitation frequency and resonance frequency, the key instantaneous characteristic variables are extracted based on Pearson correlation coefficient. Thirdly, the mathematical model of the mapping relationships between instantaneous characteristic variables and resonance frequency is established with the radial basis function neural network (RBFNN). Fourthly, for the purpose of the adaptation to the characteristics of dynamic load and real-time frequency modulation in the operation of ultrasonic scalpels, the reinforcement learning (Q-learning algorithm) and the weight vector of RBFNN are used to define the eligibility trace, which is used to dynamically adjust the RBFNN frequency matching optimization model in real time and maintain the “constant” amplitude output and stable harmonic response process. Finally, the experimental results show that, compared with the traditional methods, the frequency matching optimization model of ultrasonic scalpel transducer based on RBF neural network and Q-Learning reinforcement learning is effective, and the vibration amplitude of the transducer is increased by 15 . 25 μ m . The amplitude fluctuation is stable at 0 . 92 μ m . It can provide decision-making guidance for relevant engineering fields.},
  archive      = {J_EAAI},
  author       = {Li Gao and Sheng-long Yang and Bin Meng and Guo-xiang Tong and Hai-Ping Fan and Gui-Song Yang},
  doi          = {10.1016/j.engappai.2022.105572},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105572},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Frequency matching optimization model of ultrasonic scalpel transducer based on neural network and reinforcement learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vehicle theft detection by generative adversarial networks
on driving behavior. <em>EAAI</em>, <em>117</em>, 105571. (<a
href="https://doi.org/10.1016/j.engappai.2022.105571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human driving behavior can be a unique fingerprint to identify individual drivers and can be used for vehicle theft detection. Prior research often uses supervised learning to classify drivers’ behaviors. However, that method is not suitable for vehicle theft detection because it is not possible to derive a training dataset which comprehends all possible thieves. A few studies have instead leveraged unsupervised learning, such as k-means, but such approaches cannot achieve acceptable accuracy or provide a method of tolerating the false outcomes from classifying individual data points. Moreover, the influence of environment and road conditions on the driver classification was not included further limiting its usability. In this work, we propose a redesigned Generative Adversarial Network (GAN) model, Convolutional Long short-term GAN (CLGAN), which comprises long short-term memory (LSTM) and a convolutional neural network (CNN). This model ensures the ability of feature extraction from the convolutional layer and feature preservation from the LSTM layer, while simultaneously minimizing overfitting. It is instructive to analyze and benchmark CLGAN with the various GAN models, such as DCGAN, RNN-GAN, and AAE. Applying a public dataset which was generated by an electronic control unit (ECU) and collected through in-vehicle Controller Area Network (CAN) bus, our model achieves high accuracy of 98.5%, and is more robust against various driving conditions on multiple types of roads. In addition, we leverage threshold random walk to ensure the reliability of detection as well as adopting Principal Component Analysis (PCA) on feature pre-processing to improve the accuracy by approximately 20%. This work sheds light on a feasible and practical way of implementing vehicle theft detection.},
  archive      = {J_EAAI},
  author       = {Pei-Yu Tseng and Po-Ching Lin and Edy Kristianto},
  doi          = {10.1016/j.engappai.2022.105571},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105571},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vehicle theft detection by generative adversarial networks on driving behavior},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust lane line segmentation based on group feature
enhancement. <em>EAAI</em>, <em>117</em>, 105568. (<a
href="https://doi.org/10.1016/j.engappai.2022.105568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training a robust deep model for lane line segmentation is challenging due to the complex and changeable scenarios in autonomous driving, such as poor lighting conditions, ambiguous lane lines, and inclement weather. Without further extraction of effective deep features, such models often fail when faced with a large number of unstructured lane lines. In this article, we propose a grouped feature enhancement(GFE) method, ENet-GFE that uses the similarity between feature channels to further extract effective features while reducing noise. We group feature channels, evaluate the importance of each sub-feature in the channel and space, and learn within each group based on the relevance and similarity of the content to obtain more effective output features by using the semantic similarity between the lane line feature information and feature channels. GFE can be easily incorporated into a feedforward convolutional neural network(CNN) without adding too much computing overhead. We validated the proposed method on the widely used CULane lane line segmentation dataset and the latest autonomous driving dataset, OpenMPD. In experiments, ENet-GFE exhibited the most advanced performance. Currently, it is one of the lightest models.},
  archive      = {J_EAAI},
  author       = {Xin Gao and Hanlin Bai and Yijin Xiong and Zefeng Bao and Guoying Zhang},
  doi          = {10.1016/j.engappai.2022.105568},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105568},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust lane line segmentation based on group feature enhancement},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Power flow analysis via typed graph neural networks.
<em>EAAI</em>, <em>117</em>, 105567. (<a
href="https://doi.org/10.1016/j.engappai.2022.105567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power flow analyses are essential for the correct operation of power grids, however, electricity systems are becoming increasingly complex to analyze with the conventional numerical methods. The present work proposes a typed graph neural network based approach to solve the power flow problem. The neural networks are trained on benchmark power grid cases which are modified by varying the injections (load and generation), branch characteristics and topology. The solution to the power flow analysis is found when all voltage values are known. The proposed system infers the voltage magnitude and phase and is trained so that the obtained values minimize the violation of the physical laws that govern the system, this way the training is achieved in an unsupervised manner. The proposed solver has linear time complexity and is able to generalize to grids with considerably different conditions, including size, from the grids available during training. Though the training is unsupervised and does not suppose any ground truth data, the solutions obtained are found to have a close correlation with the conventional Newton–Raphson method. The results are additionally validated by finding the root mean square deviation from the Newton–Raphson method, and the faster, though less accurate, DC approximation method.},
  archive      = {J_EAAI},
  author       = {Tania B. Lopez-Garcia and José A. Domínguez-Navarro},
  doi          = {10.1016/j.engappai.2022.105567},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105567},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Power flow analysis via typed graph neural networks},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive teacher–student learning algorithm with
decomposed knowledge distillation for on-edge intelligence.
<em>EAAI</em>, <em>117</em>, 105560. (<a
href="https://doi.org/10.1016/j.engappai.2022.105560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In case the spatial shape of the feature maps of the teacher in feature-based knowledge distillation (KD) is significantly greater than the student model, first, they cannot be compared directly. Second, the knowledge of these complex feature maps cannot be quite apprehensible for the student. This paper proposed a new KD, in which Tucker decomposition was used to decompose the large-dimension feature maps of a teacher to obtain core tensors from the feature maps of the teacher. The knowledge of these tensors can be easily understood by students due to their low complexity. Furthermore, in the proposed KD, an adaptor function is suggested, which balances the spatial shape of the core tensors of the teacher and student and helps compare them using a convolution regressor. Finally, a hybrid loss based on adaptor function is suggested to distill the knowledge of the core tensors of the teacher to the student. Both teacher and student models were implemented on smartphones used as edge devices, and the experiments were evaluated in terms of recognition rate and complexity. According to the results, the student model designed by ResNet-18 architecture has ∼ 65.44 million fewer parameters, ∼ 6.45 GFLOPs less computational complexity, ∼ 1.12 G less GPU memory use, and ∼ 265.67 times greater compression rate than its teacher model designed by ResNet-50 architecture. While the recognition rate of the student model merely dropped down to 1.5% in the benchmark dataset.},
  archive      = {J_EAAI},
  author       = {Majid Sepahvand and Fardin Abdali-Mohammadi and Amir Taherkordi},
  doi          = {10.1016/j.engappai.2022.105560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive teacher–student learning algorithm with decomposed knowledge distillation for on-edge intelligence},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective optimization of seeding performance of a
pneumatic precision seed metering device using integrated ANN-MOPSO
approach. <em>EAAI</em>, <em>117</em>, 105559. (<a
href="https://doi.org/10.1016/j.engappai.2022.105559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uniform seed spacing within the row is the most desirable prerequisite for better crop yield. The seeding uniformity of a pneumatic seed metering device is significantly affected by its key design and operational parameters, i.e., shape and size of the suction hole, vacuum pressure, and forward speed of operation. Therefore, these parameters need to be optimized to achieve better seeding performance. In this study, A novel intelligent multi-objective optimization methodology based on artificial neural network (ANN) and multi-objective particle swarm optimization (MOPSO), named as integrated ANN-MOPSO approach, was employed to accomplish the set goal. Maximizing the quality feed index (QFI) and minimizing the precision index (PI) were chosen as two objectives. The multilayer perceptron (MLP) and radial basis function (RBF) neural network models were developed for predicting the QFI and PI. The results revealed that the RBFNN (4-15-2) model outperformed the MLPNN (4-7-2) model; hence it was further coupled with the MOPSO algorithm for retrieving the Pareto-optimal set of the design and operational parameters corresponding to the maximum QFI and minimum PI.The most appropriate optimum entry shape and size of the suction hole, vacuum pressure, and operating speed were found to be chamfered holes with 3 mm diameter, 3.5 kPa, and 2.84 km/h, respectively. The validation results showed a variation of -2.11 % and +5.398 % between the observed and predicted values of the QFI and PI, respectively, thus confirming the adequacy of the proposed approach.},
  archive      = {J_EAAI},
  author       = {C.M. Pareek and V.K. Tewari and Rajendra Machavaram},
  doi          = {10.1016/j.engappai.2022.105559},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105559},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective optimization of seeding performance of a pneumatic precision seed metering device using integrated ANN-MOPSO approach},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). D3-net: Integrated multi-task convolutional neural network
for water surface deblurring, dehazing and object detection.
<em>EAAI</em>, <em>117</em>, 105558. (<a
href="https://doi.org/10.1016/j.engappai.2022.105558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual perception is one of the key technologies for smart ships to achieve intelligent navigation in various complex water scenes, which adopts the object detection algorithm based on visible image to detect obstacles. Affected by the rolling and high-speed motion of ships and bad weather, motion blur and haze appear in the images of vision sensor, which seriously interfere with the obstacle detection. To ensure the navigation safety of smart ships, we propose the integrated multi-task deblurring, dehazing and object detection convolutional neural network (D 3 -Net). Firstly, the proposed method is able to complete deblurring, dehazing and object detection within a single network, which is more suitable to be applied in intelligent navigation. Secondly, different from traditional methods that reconstruct enhanced images first and then perform object detection, D 3 -Net combines image reconstruction and detection feature extraction to realize the integration of image enhancement and detection procedure. Finally, to improve the deblurring and dehazing performance of the network, we propose classification attention-based detection feature loss (CADF-Loss), which uses the image classification features to guide the network perform the detection feature enhancement more specifically. The experimental results in real navigation scenes show that D 3 -Net not only improves the detection accuracy of blurred and hazy images by 42%, but also has excellent detection efficiency, which is helpful to improve the navigation safety performance of smart ships.},
  archive      = {J_EAAI},
  author       = {Jundong Guo and Hui Feng and Haixiang Xu and Wenzhao Yu and Sam shuzhi Ge},
  doi          = {10.1016/j.engappai.2022.105558},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105558},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {D3-net: Integrated multi-task convolutional neural network for water surface deblurring, dehazing and object detection},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evolutionary feature selection on high dimensional data
using a search space reduction approach. <em>EAAI</em>, <em>117</em>,
105556. (<a
href="https://doi.org/10.1016/j.engappai.2022.105556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is becoming more and more a challenging task due to the increase of the dimensionality of the data. The complexity of the interactions among features and the size of the search space make it unfeasible to find the optimal subset of features. In order to reduce the search space, feature grouping has arisen as an approach that allows to cluster feature according to the shared information about the class. On the other hand, metaheuristic algorithms have proven to achieve sub-optimal solutions within a reasonable time. In this work we propose a Scatter Search (SS) strategy that uses feature grouping to generate an initial population comprised of diverse and high quality solutions. Solutions are then evolved by applying random mechanisms in combination with the feature group structure, with the objective of maintaining during the search a population of good and, at the same time, as diverse as possible solutions. Not only does the proposed strategy provide the best subset of features found but it also reduces the redundancy structure of the data. We test the strategy on high dimensional data from biomedical and text-mining domains. The results are compared with those obtained by other adaptations of SS and other popular strategies. Results show that the proposed strategy can find, on average, the smallest subsets of features without degrading the performance of the classifier.},
  archive      = {J_EAAI},
  author       = {Miguel García-Torres and Roberto Ruiz and Federico Divina},
  doi          = {10.1016/j.engappai.2022.105556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evolutionary feature selection on high dimensional data using a search space reduction approach},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AgrIntel: Spatio-temporal profiling of nationwide
plant-protection problems using helpline data. <em>EAAI</em>,
<em>117</em>, 105555. (<a
href="https://doi.org/10.1016/j.engappai.2022.105555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable development of the national food system must ensure the introduction of adequate food security interventions and policies. However, several high-end technological developments remain unexplored, which can be used to gain explicit information regarding agricultural problems. In this direction, the presented work proposes AgrIntel, a framework consisting of multiple AI-based pipelines to process nationwide farmers’ helpline data and obtain spatiotemporal insights regarding food-production problems on an extensive scale. AgrIntel overcomes several limitations of the existing methods used for similar objectives, including limited scalability, low frequency, and high cost. The call-logs dataset used in the study is obtained from the nationwide network of farmers’ helpline centers, managed by the Ministry of Agriculture &amp; Farmers’ Welfare, Government of India. The article demonstrates the Spatio-temporal profile of one of India’s highest food grain-affecting diseases, i.e., “blast in rice crop”, to demonstrate the utility of the AgrIntel pipelines. First, the proposed framework extracts and clusters the precise geographical locations of farmers calling for help corresponding to the target agricultural problem. Next, the temporal modeling of the problem helps extract the critical dates corresponding to the crop disease/pest spread. Furthermore, by incorporating the historical agroclimatological data, the article introduces a new medium to extract the favorable weather conditions corresponding to the targeted disease/pest outbreak. In addition, the study explores the potential of Deep Learning models (based on Artificial Neural Network, Convolutional Neural Network, Gated Recurrent Unit and Long short-term memory unit) to efficiently predict the futuristic demand for assistance regarding target problems (RMSE of ≈ 1.5 and MAE of ≈ 0.9 query calls). The obtained results expose unrevealed insights regarding food production problems, significantly boosting the food security policy-designing procedure.},
  archive      = {J_EAAI},
  author       = {Samarth Godara and Durga Toshniwal and Ram Swaroop Bana and Deepak Singh and Jatin Bedi and Rajender Parsad and Jai Prakash Singh Dabas and Abimanyu Jhajhria and Shruti Godara and Raju Kumar and Sudeep Marwaha},
  doi          = {10.1016/j.engappai.2022.105555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AgrIntel: Spatio-temporal profiling of nationwide plant-protection problems using helpline data},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sampling-attention deep learning network with transfer
learning for large-scale urban point cloud semantic segmentation.
<em>EAAI</em>, <em>117</em>, 105554. (<a
href="https://doi.org/10.1016/j.engappai.2022.105554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Targeting the development of smart cities to facilitate the significant analysis of large-scale urban for construction and update. This research develops a new method named transfer learning-based sampling-attention network (TSANet) to act on 3D urban point clouds for semantic segmentation. The main contributions of this research are a segmentation model and a transfer learning protocol, where the segmentation model adopts the point downsampling–upsampling structure for time efficiency, the embedding method and an attention mechanism for point cloud feature processing, and the transfer learning protocol is employed to reduce the data requirements and labeling efforts by using prior knowledge for practical application. In addition, a focal loss is designed to assist the model for feature extraction and learning with handling data imbalance. To demonstrate the efficiency and effectiveness of the developed method, a realistic point cloud dataset of Cambridge and Birmingham cities is utilized as a case study. The results demonstrate that (1) the developed method has promising performance with overall accuracy (OA) of 0.9133 and Mean Intersection over Union (MIoU) of 0.5588; (2) the proposed transfer learning protocol contributes to the core model performance by fully combining accuracy and time efficiency, offering a 74.91% improvement in time efficiency; (3) the developed TSANet outperforms other state-of-the-art models, such as PointNet++ and DGCNN, by comparing the accuracy and time efficiency. Overall, the method developed in this research is capable of great potential as a practical application tool by presenting accurate, effective, and efficient results for semantic segmentation of large-scale 3D urban point clouds.},
  archive      = {J_EAAI},
  author       = {Yunxiang Zhou and Ankang Ji and Limao Zhang and Xiaolong Xue},
  doi          = {10.1016/j.engappai.2022.105554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sampling-attention deep learning network with transfer learning for large-scale urban point cloud semantic segmentation},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On enhancing prediction abilities of vision-based metallic
surface defect classification through adversarial training.
<em>EAAI</em>, <em>117</em>, 105553. (<a
href="https://doi.org/10.1016/j.engappai.2022.105553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision is augmented in various manufacturing industries to perform automated inspection operations accurately and efficiently. It has been observed that the performance of vision-based inspection approaches degrades considerably upon utilizing images captured under shop-floor conditions. This work proposes utilizing Histogram Equalization and adversarial training through Neural Structure Learning (NSL) for developing a robust vision-based Surface Defect Classification framework. A novel deep neural network architecture obtains adversarial samples in the extracted feature space instead of obtaining the same in the original input image space. The architecture can be easily integrated and employed with various machine learning models. A commonly employed steel surface defect dataset (NEU) with practical relevance to industrial cases is selected for the model training and experimental studies. The robustness of the proposed approach is evaluated over the Extended Diversity Enhanced (ENEU) dataset derived by simulating image acquisition variations similar to shop floor conditions. The results reveal that the proposed approach enhances the recognition accuracy of the baseline method from 87.7% to 92.4% over ENEU. The prediction accuracy of the proposed approach is considerably better than the traditional methods and deep learning competitors over ENEU. The qualitative and quantitative comparison of results obtained using the present approach with methods reported in the literature demonstrates the effectiveness of adversarial training in improving the generalization abilities of machine learning models.},
  archive      = {J_EAAI},
  author       = {Vikanksh Nath and Chiranjoy Chattopadhyay and K.A. Desai},
  doi          = {10.1016/j.engappai.2022.105553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On enhancing prediction abilities of vision-based metallic surface defect classification through adversarial training},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel method for cage whirl motion capture of
high-precision bearing inspired by u-net. <em>EAAI</em>, <em>117</em>,
105552. (<a
href="https://doi.org/10.1016/j.engappai.2022.105552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem of cage whirl motion capture and evaluation, this paper developed an efficient non-contact measurement method based on semantic segmentation technology. An encoder–decoder network whose backbone is U-Net is constructed by introducing residual learning and attention mechanism for cage motion state segmentation. A random move augmentation strategy is used to simulate the random movement of cage mass center. The network is trained with 1368 high-speed cage rotational images using the augmentation strategy. Additionally, 150 images are validation set, and 5000 images under different operating conditions are test set. A trained network is applied to the cage whirl motion capture under different operating conditions by matching the suitable parameters during the training phase. The results show that our method effectively predicts the trend of cage whirl motion, with the predicted cage whirl orbit used for the accurate analysis of cage rotational stability.},
  archive      = {J_EAAI},
  author       = {Xiaoliang Niu and Zhaohui Yang ( Dr. ) and Ningning Zhou and Chonghe Li},
  doi          = {10.1016/j.engappai.2022.105552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel method for cage whirl motion capture of high-precision bearing inspired by U-net},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep reinforcement learning-PID based supervisor control
method for indirect-contact heat transfer processes in energy systems.
<em>EAAI</em>, <em>117</em>, 105551. (<a
href="https://doi.org/10.1016/j.engappai.2022.105551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indirect-contact heat exchangers have been widely used in various energy systems, and the precise tracking control of important heat transfer parameters, such as temperature, is vital for safe and efficient operation. However, the high nonlinearity of heat transfer and large disturbance brings difficulty to optimal control. Considering the strong perception and decision-making capabilities of deep reinforcement learning (DRL), this study proposed a supervisor control method combined DRL and proportional–integral–derivative (PID). A set of the fewest conveniently measurable variables was derived as agent observations to describe the heat transfer process effectively and thereby improve the control efficiency under large disturbances. In addition, the local heat transfer process was used as a training environment to reduce training costs significantly. Finally, superheat temperature control in a complex organic Rankine cycle was simulated with SIMULINK to evaluate the effectiveness of the proposed observation variables and the training and control methods. The results showed that the proposed control method achieved satisfactory performance. The average absolute tracking error was only 0.246 K under trained and untrained disturbances, whereas that of the PID control was 4.645 K. Compared with the model predictive control, the DRL-PID-based supervisory control evidently performed better under a large disturbance; the average absolute tracking errors under DRL-PID control and MPC were 0.288 K and 0.509 K, respectively.},
  archive      = {J_EAAI},
  author       = {Xuan Wang and Jinwen Cai and Rui Wang and Gequn Shu and Hua Tian and Mingtao Wang and Bowen Yan},
  doi          = {10.1016/j.engappai.2022.105551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-PID based supervisor control method for indirect-contact heat transfer processes in energy systems},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimation and prediction of the OD matrix in uncongested
urban road network based on traffic flows using deep learning.
<em>EAAI</em>, <em>117</em>, 105550. (<a
href="https://doi.org/10.1016/j.engappai.2022.105550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new method for OD (Origin–Destination)​ matrix prediction based on traffic data using deep learning. The input values of the developed model were determined based on data on the structure of the road network, origin and destination points of trips, as well as data on traffic intensity on road network sections recorded by video-sensing devices. The advantage of the method is that the complex process of data acquisition and processing is not required for the estimation and prediction of the matrix. Historical data and the iterative method of estimating a prior OD matrix were used only to generate training sequences for the neural network. The proposed method using deep learning neural networks with the long short-term memory (LSTM) or autoencoders layers (DLNa — deep learning networks with autoencoders) is characterized by relatively high accuracy and resistance to temporary missing data from several measurement points located in the urban road network. The case study was conducted for a network of a medium-sized city in Poland. The results show (average MAPE = 7.18% (LSTM), 6.80% (DLNa)) that the proposed method can have a practical implementation in real-time dynamic traffic assignment (DTA) systems for ITS applications. The proposed method of short-term forecasting the OD matrix does not require questionnaire research or detailed information on spatial development. Therefore, it is not as expensive and time-consuming as the methods based on these data.},
  archive      = {J_EAAI},
  author       = {Teresa Pamuła and Renata Żochowska},
  doi          = {10.1016/j.engappai.2022.105550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Estimation and prediction of the OD matrix in uncongested urban road network based on traffic flows using deep learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An online continual object detector on VHR remote sensing
images with class imbalance. <em>EAAI</em>, <em>117</em>, 105549. (<a
href="https://doi.org/10.1016/j.engappai.2022.105549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a great challenge for traditional offline detectors to learn from continuous data streams, remember previous tasks and adapt to new-coming tasks in dynamic environments. To meet the challenge, online continual learning has recently attracted increasing attention, while the overwhelming majority of works focus only on classification with a balanced class distribution assumption. In this paper, we propose a replay-based approach called an online continual object detector (OCOD) for very-high-resolution (VHR) remote sensing images. First, we find that rehearsal imbalance is ubiquitous, and has more important impact on experimental results than class imbalance, which is contrary to the situation of offline learning (due to the limited memory). Here, rehearsal imbalance refers to significant difference among the number of images pertaining to various classes. Second, entropy is used to measure the degree of rehearsal imbalance in the memory, and an entropy reservoir sampling (ERS) strategy is proposed to maintain rehearsal balance in the online memory. Finally, a rehearsal-balancing priority assignment network (RBPAN) is proposed to adaptively select images from the memory for a rehearsal-balancing replay procedure. The experimental results obtained on three publicly available VHR satellite images from the NWPU VHR-10, DIOR and DOTA datasets, highlight the effectiveness and practicality of developed method.},
  archive      = {J_EAAI},
  author       = {Xi Chen and Jie Jiang and Zhiqiang Li and Honggang Qi and Qingli Li and Jiapeng Liu and Laiwen Zheng and Min Liu and Yongqiang Deng},
  doi          = {10.1016/j.engappai.2022.105549},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105549},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An online continual object detector on VHR remote sensing images with class imbalance},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised LSTM with historical feature fusion
attention for temporal sequence dynamic modeling in industrial
processes. <em>EAAI</em>, <em>117</em>, 105547. (<a
href="https://doi.org/10.1016/j.engappai.2022.105547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern industrial processes, the data-driven soft sensor technology has been widely used for the prediction of key quality variables. Due to the important of dynamics and nonlinearity in industrial process data, deep learning models like long short-term memory (LSTM) network are well suited for temporal sequence dynamic modeling due to their excellent long-term memory function and feature extraction capability. Furthermore, industrial processes generate a large amount of process data with irregular sampling frequencies. However, traditional LSTM cannot fully utilize the process data with irregular sampling frequency and the guidance value of historical data samples for feature learning. To address these issues, a novel semi-supervised LSTM with history feature fusion attention (HFFA-SSLSTM) model is proposed in this paper. First, the semi-supervised learning strategy is implemented in LSTM to fully utilize the unlabeled data and mine the temporal sequence features of labeled samples and unlabeled samples with irregular sampling frequencies. Then, a novel historical feature fusion attention (HFFA) mechanism is developed, which utilizes historical hidden features to learn attention scores for obtaining weighted historical information-related features. Finally, the extracted features are combined to form the soft sensor model to perform time series prediction tasks for key quality variables in industrial processes. The experimental results on the actual industrial hydrocracking data set demonstrate the effectiveness of the proposed HFFA-SSLSTM model and its possibility of applicating in real industrial processes.},
  archive      = {J_EAAI},
  author       = {Yiyin Tang and Yalin Wang and Chenliang Liu and Xiaofeng Yuan and Kai Wang and Chunhua Yang},
  doi          = {10.1016/j.engappai.2022.105547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised LSTM with historical feature fusion attention for temporal sequence dynamic modeling in industrial processes},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven multi-objective optimization with neural
network-based sensitivity analysis for semiconductor devices.
<em>EAAI</em>, <em>117</em>, 105546. (<a
href="https://doi.org/10.1016/j.engappai.2022.105546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical modeling and optimization are critical for product quality management and technology development in the manufacturing industry. As the emerging device appears and technology advances, it consists of highly-correlated multivariate parameters and has a non-linear relationship. Moreover, technology development requires extensive cost and effort, and often it takes several years to establish a physical model after the advent of new technology. Thus, this paper presents an effective data-driven multi-objective optimization with neural network-based sensitivity analysis for semiconductor devices before explicitly developing a physical or compact model. Sensitivity analysis allows a quick search for influential parameters and selects design parameter candidates for a customized solution. Then, the selected parameters are adjusted to maintain within the set range by the scaled sensitivities and to have robustness against noise. It optimizes design variables to meet performance and variation requirements simultaneously, considering correlation between parameters. Therefore, multi-objective solutions hold physical consistency and are found with ¡ 1.7% error. The proposed method is efficient in computational time, which is significantly reduced by more than 80% compared to Bayesian optimization for process optimization. This approach is a general methodology applicable to various industries besides the semiconductor field. Finally, we expect this study to help shorten development time and improve yield through customized multi-objective solutions.},
  archive      = {J_EAAI},
  author       = {Min-Hye Oh and Kitae Lee and Sihyun Kim and Byung-Gook Park},
  doi          = {10.1016/j.engappai.2022.105546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven multi-objective optimization with neural network-based sensitivity analysis for semiconductor devices},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of wavelet-based kalman online sequential
extreme learning machine optimized with boruta-random forest for drought
index forecasting. <em>EAAI</em>, <em>117</em>, 105545. (<a
href="https://doi.org/10.1016/j.engappai.2022.105545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drought is a stochastic and recurring hydrological natural hazard that occurs due to a shortage of precipitation over a period of time. Drought forecasting in water resources systems has an important role in reducing devastating ecological and social impacts. However, due to the fluctuating nature of drought indicator time series, their forecasting on a short time scale without advanced pre-processing is extremely challenging, and little research has been presented in this field. In this study, a new complementary machine learning (ML) approach, Kalman filter regression-based Online Sequential Extreme Learning Machine and (KOSELM) coupled with the Boundary Corrected Maximal Overlap Discrete Wavelet Transform (BC-MODWT-KOSELM), was implemented for forecasting one-month/three-month ahead Standardized Precipitation Evapotranspiration Index (i.e., SPEI 12 and SPEI 24). Here, the Kalman filter regression was employed to optimize the hyper-parameters of the Online Sequential Extreme Learning Machine (OSELM). Precipitation and potential evapotranspiration data from Bandar Abbas (warm semi-humid climate) and Rasmar (humid climate) synoptic stations, Iran were used in the analysis for a period of (1987–2019). In order to validate the BC-MODWT-KOSELM model, it was compared with two other well-known ML approaches, classical Extreme Learning Machine (ELM) and Generalized Regression Neural Network (GRNN) in both standalone and BC-MODWT-based complementary frameworks (i.e., BC-MODWT-ELM and BC-MODWT-GRNN). First, the original time series of the benchmark drought index was decomposed into the wavelet and scaling coefficients based on three mother wavelets and different decomposition levels. Afterward, the most significant lags were extracted using the Boruta-random forest (B-RF) feature selection. The BC-MODWT-KOSELM was identified as the superior forecasting model for SPEI 12 (t ＋ 1) with R = 0.9511 and RMSE = 0.3318; for SPEI 12 (t ＋ 3) with R = 0.8171 and RMSE = 0.6168; for SPEI 24 (t ＋ 1) with R = 0.9710 and RMSE = 0.2156; for SPEI 24 (t ＋ 3) with R = 0.9014 and RMSE = 0.3937 in the Bandar Abbas station. Besides, the BC-MODWT-KOSELM outperformed the comparative counterpart model for SPEI 12 (t ＋ 1 with R = 0.9401 and RMSE = 0.3371; SPEI 12 (t ＋ 3) with R = 0.8266 and RMSE = 0.5723; for SPEI 24 (t ＋ 1) with R = 0.9640 and RMSE = 0.2974; for SPEI 24 (t ＋ 3) with R = 0.9063 and RMSE = 0.4874 in the Ramsar station.},
  archive      = {J_EAAI},
  author       = {Mehdi Jamei and Iman Ahmadianfar and Masoud Karbasi and Anurag Malik and Ozgur Kisi and Zaher Mundher Yaseen},
  doi          = {10.1016/j.engappai.2022.105545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development of wavelet-based kalman online sequential extreme learning machine optimized with boruta-random forest for drought index forecasting},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Affinity based fuzzy kernel ridge regression classifier for
binary class imbalance learning. <em>EAAI</em>, <em>117</em>, 105544.
(<a href="https://doi.org/10.1016/j.engappai.2022.105544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance learning (CIL) problem indicates when one class have very low proportions of samples (minority class) compared to the other class (majority class). Even though kernel ridge regression (KRR) shows high generalization ability at a considerably quicker learning speed than conventional machine learning algorithms, it fails to achieve an excellent result for CIL problems. To address this inherent limitation of KRR, a novel affinity-based fuzzy KRR (AFKRR) is proposed for dealing with the binary CIL problem. In AFKRR, an affinity-based fuzzy membership value is linked to each training sample. The affinity of the majority class datapoint is measured using the support vector data description (SVDD) trained by the majority class datapoints. The classification ability of the proposed AFKRR is calculated using the area under the receiver optimal characteristics curve (AUC), F-measure and Geometric mean. AFKRR’s performance is compared with the support vector machine (SVM), affinity and class probability-based fuzzy SVM (ACFSVM), entropy-based fuzzy SVM (EFSVM), improved density weighted least squares SVM (IDLSSVM-CIL), KRR and intuitionistic fuzzy KRR (IFKRR) models on a few real-world as well as a few artificial imbalanced datasets. Experimental outcomes reveal the usability and efficacy of the proposed AFKRR model.},
  archive      = {J_EAAI},
  author       = {Barenya Bikash Hazarika and Deepak Gupta},
  doi          = {10.1016/j.engappai.2022.105544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Affinity based fuzzy kernel ridge regression classifier for binary class imbalance learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gravity particle swarm optimization algorithm for solving
shop visit balancing problem for repairable equipment. <em>EAAI</em>,
<em>117</em>, 105543. (<a
href="https://doi.org/10.1016/j.engappai.2022.105543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The particle swarm optimization (PSO) algorithm has received much attention from engineering and scientific fields since it was proposed. Nevertheless, when solving complex combinatorial optimization tasks such as the proposed shop visit balancing problem for repairable equipment (SVBPRE), the canonical PSO is still prone to fall into the local optimal stagnation. Therefore, a novel intelligent optimization algorithm, namely gravity particle swarm optimization (GPSO) algorithm, is proposed to remedy the above defects. This algorithm improves the velocity updating strategy of particles in the population, which can effectively improve the global search ability of the algorithm without increasing the time complexity, so that it can jump out of the local optimal position and find the feasible solution in the complex solution space. To verify its performance, many experimental verifications were carried out. Firstly, the effectiveness of the proposed GPSO was verified by comparing with the PSO on the 8 benchmark functions. Secondly, the superiority and advancement of GPSO were proved by comparing with 10 state-of-the-art original optimizers and variant algorithms on 23 benchmark tasks. Finally, based on the constructed shop visit balancing problem model, a series of simulation data cases were generated according to the operation and maintenance data in engineering practice for verification. The results obtained by comparing with 4 commonly used algorithms in engineering demonstrate that the proposed GPSO is superior to other competitors in terms of quality of solutions and has important theoretical significance and application value for solving practical tasks with complex search space.},
  archive      = {J_EAAI},
  author       = {Xiangzhao Xia and Xuyun Fu and Shisheng Zhong and Zhengfeng Bai and Yanchao Wang},
  doi          = {10.1016/j.engappai.2022.105543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Gravity particle swarm optimization algorithm for solving shop visit balancing problem for repairable equipment},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ranking of advertising goals on social network sites by
pythagorean fuzzy hierarchical decision making: facebook. <em>EAAI</em>,
<em>117</em>, 105542. (<a
href="https://doi.org/10.1016/j.engappai.2022.105542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of social networking sites (SNSs), known as web-based services, has become a natural digital phenomenon, reinforcing e-commerce concepts such as business-to-consumer (B2C) and consumer-to-consumer (C2C), known as social commerce. One platform that provides end-to-end connections, from increasing brand awareness to creating new opportunities in the contemporary marketing approach, is Facebook, which reaches a broad audience of advertisers with the advantage of many users. Facebook has updated its ad targets in recent years. Choosing the right advertising target will directly affect company and campaign performance. Considering this problem structure, it is compatible with fuzzy set theory since it contains conflicting criteria and high complexity in an environment of uncertainty. As far as it is known from the literature, although there are many academic studies on Facebook ad analysis, there is no study investigating advertising targeting with fuzzy set theory. Therefore, in the decision model developed for Facebook advertising targeting, a fuzzy decision model is proposed for targeting by the campaign structure. The first stage of the model includes the combined use of AHP-TOPSIS methods by evaluating performance criteria and presenting advertising targets in social media campaigns with Pythagorean fuzzy sets. As a result, it has been reached that the awareness-raising strategy for local or global users should include campaign activities that will increase brand awareness.},
  archive      = {J_EAAI},
  author       = {Merve Bulut and Evrencan Özcan},
  doi          = {10.1016/j.engappai.2022.105542},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105542},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ranking of advertising goals on social network sites by pythagorean fuzzy hierarchical decision making: Facebook},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and fuzzy ensemble framework via spectral learning
for random projection-based fuzzy-c-means clustering. <em>EAAI</em>,
<em>117</em>, 105541. (<a
href="https://doi.org/10.1016/j.engappai.2022.105541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ensembles of random projection-based fuzzy-c-means (RP-FCM) can handle high-dimensional data efficiently. However, the performance of these ensemble frameworks is still hindered by some issues, such as misaligned membership matrices, information loss of co-similar matrices, large storage space, unstable ensemble results due to the additional re-clustering, etc. To address these issues, we propose a robust and fuzzy ensemble framework via spectral learning for RP-FCM clustering. After using random projection to generate different dimensional datasets and obtaining the membership matrices via fuzzy-c-means, we first convert these membership matrices into regularized graphs and approximates the affinity matrices of these graphs by spectral matrices. This step not only avoids the alignment problems of membership matrices but also excludes the storage of large-scale graphs. The spectral matrices of the same size are used as the features of membership matrices for the ensemble, avoiding the possible information loss by applying co-similar matrix transformations. More importantly, an optimization model is designed in our framework to learn the fusion of spectral features. In this model, the proportion of each base clustering is adjusted adaptively through a fuzzification exponent, and the effect of outliers is also suppressed by a robust norm. Finally, the Laplacian rank constraint in the model guarantees the ensemble can achieve the exact final partition. An efficient algorithm for this model is derived, and its time complexity and convergence are also analyzed. Competitive experimental results on benchmark data demonstrate the effectiveness of the proposed ensemble framework in comparison to state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Zhaoyin Shi and Long Chen and Junwei Duan and Guangyong Chen and Kai Zhao},
  doi          = {10.1016/j.engappai.2022.105541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust and fuzzy ensemble framework via spectral learning for random projection-based fuzzy-c-means clustering},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Augmented data driven self-attention deep learning method
for imbalanced fault diagnosis of the HVAC chiller. <em>EAAI</em>,
<em>117</em>, 105540. (<a
href="https://doi.org/10.1016/j.engappai.2022.105540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The chiller fault diagnosis is of great significance to maintain the normal operation of the HVAC system and indoor comfort. Due to the difficulty in collecting the chiller’s fault data, we usually face the data imbalance problem of less fault data and more normal data. To tackle this problem and further improve the fault diagnosis accuracy, this paper proposes a novel augmented data driven self-attention based deep learning model for the chiller fault diagnosis. Firstly, to solve the data imbalance problem, a stable synthetic minority oversampling technique (SSMOTE) is presented to generate the artificial fault data, which are then mixed with the raw fault data to achieve data augmentation. Further, to enhance the diagnosis accuracy, the self-attention mechanism based temporal convolutional network (STCN) is developed to classify normal and fault datasets. The developed STCN is realized by stacking the modified blocks which can dynamically pay attention to different data information through combining the self-attention mechanism and the traditional residual block together. What is more, in the STCN, the skip connection structure is added to the self-attention mechanism to solve the gradient disappearance problem. Finally, detailed experiments and comparisons are performed. Experimental results show that, compared with other data augmentation methods, the SSMOTE can complete a large scale expansion of the minority fault datasets, and its augmented data have better effect on handling the data imbalance problem. Moreover, the skip self-attention mechanism based deep learning model can achieve better diagnosis accuracy compared with some popular deep and shallow models, such as the LSTM, ELM and SVM, etc.},
  archive      = {J_EAAI},
  author       = {Cunxiao Shen and Hanyuan Zhang and Songping Meng and Chengdong Li},
  doi          = {10.1016/j.engappai.2022.105540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Augmented data driven self-attention deep learning method for imbalanced fault diagnosis of the HVAC chiller},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better utilization of materials’ compositions for predicting
their properties: Material composition visualization network.
<em>EAAI</em>, <em>117</em>, 105539. (<a
href="https://doi.org/10.1016/j.engappai.2022.105539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the complexity and diversity of advanced high-performance materials, it is challenging to comprehensively understand a material’s composition–process–structure–performance relationship. Data-driven approaches have been regarded as the fourth paradigm of new materials R&amp;D. However, the complexity of constituent elements in many material datasets leads to very sparse compositional features, posing a tremendous challenge to machine learning models. In this study, a data mapping scheme based on fundamental atomic features was used to visualize the chemical composition characteristics mapped into two-dimensional grayscale image data to solve the problem of sparse material composition matrix. Based on this, a material composition visualization network (MCVN) is proposed and applied to predict the mechanical properties of steel and classify amorphous alloy materials. We compared the MCVN to other machine learning methods. The MCVN had an average R 2 value improvement of 4% on the four targets in the National Institute for Materials Science’s (NIMS’s) steel dataset, where other models already get an average R 2 of 0.92, and it achieved an R 2 of 0.835 on the cross-sectional shrinkage target in the Shanghai Research Institute of Materials’(SRIM’s) steel dataset where the other models only had an average R 2 of 0.64. For the unbalanced amorphous alloy material dataset, the MCVN improved the average R e c a l l of the small-class crystalline alloy (CRA) from 0.58 to 0.78. The method based on expanding the material chemical composition information is universal and provides a new paradigm for material property prediction.},
  archive      = {J_EAAI},
  author       = {Yeyong Yu and Xing Wu and Quan Qian},
  doi          = {10.1016/j.engappai.2022.105539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Better utilization of materials’ compositions for predicting their properties: Material composition visualization network},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Random vector functional link forests and extreme learning
forests applied to UAV automatic target recognition. <em>EAAI</em>,
<em>117</em>, 105538. (<a
href="https://doi.org/10.1016/j.engappai.2022.105538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two novel machine learning algorithms, namely Random Vector Functional Link Forests and Extreme Learning Forests, to develop an improved unmanned aerial vehicles automatic target recognition system. Such models take advantage of the stochastic procedure followed by Random Forests, where random subsets of instances and features are selected to build diverse Decision Trees. However, different from the usual uni-variate split criterion from Decision Tree algorithms, we propose and employ the novel Random Vector Functional Link Tree or Extreme Learning Tree, where each decision split is performed using the fast non-linear mapping of multiple features provided by either Random Vector Functional Link or Extreme Learning Machines. To prove the efficacy of the novel algorithm, experiments are performed using 90 binary classification problems to compare the performance of the proposed algorithm against other state-of-the-art ensemble learning techniques. Statistical analysis indicates the success of the proposed algorithms in terms of both predictive performance and computational complexity. While the model with deeper trees outperforms classical ensembles in terms of predictive performance (1.41% error reduction) and has similar results to state-of-the-art ensemble models, the model with shallow trees outperforms all ensembles in terms of computational burden (at least 36% faster). Finally, the novel methods are applied to develop an automatic target recognition system for unmanned aerial vehicles, achieving a valuable trade-off in terms of area under receiver operating characteristic curve (0.9309), F 1 score (0.8190), accuracy (0.8646), and computational time (4.14 s).},
  archive      = {J_EAAI},
  author       = {Victor Henrique Alves Ribeiro and Roberto Santana and Gilberto Reynoso-Meza},
  doi          = {10.1016/j.engappai.2022.105538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Random vector functional link forests and extreme learning forests applied to UAV automatic target recognition},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Thermal neural networks: Lumped-parameter thermal modeling
with state-space machine learning. <em>EAAI</em>, <em>117</em>, 105537.
(<a href="https://doi.org/10.1016/j.engappai.2022.105537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With electric power systems becoming more compact with higher power density, the relevance of thermal stress and precise real-time-capable model-based thermal monitoring increases. Previous work on thermal modeling by lumped-parameter thermal networks (LPTNs) suffers from mandatory expert knowledge for their design and from uncertainty regarding the required power loss model. In contrast, deep learning-based temperature models cannot be designed with the low amount of model parameters as in a LPTN at equal estimation accuracy. In this work, the thermal neural network (TNN) is introduced, which unifies both, consolidated knowledge in the form of heat-transfer-based LPTNs, and data-driven nonlinear function approximation with supervised machine learning. The TNN approach overcomes the drawbacks of previous paradigms by having physically interpretable states through its state-space representation, is end-to-end differentiable through an automatic differentiation framework, and requires no material, geometry, nor expert knowledge for its design. Experiments on an electric motor data set show that a TNN achieves higher temperature estimation accuracies than previous white-/gray- or black-box models with a mean squared error of 3.18 K 2 and a worst-case error of 5.84 K at 64 model parameters.},
  archive      = {J_EAAI},
  author       = {Wilhelm Kirchgässner and Oliver Wallscheid and Joachim Böcker},
  doi          = {10.1016/j.engappai.2022.105537},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105537},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal neural networks: Lumped-parameter thermal modeling with state-space machine learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Damage analysis and quantification of RC beams assisted by
damage-t generative adversarial network. <em>EAAI</em>, <em>117</em>,
105536. (<a
href="https://doi.org/10.1016/j.engappai.2022.105536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Artificial Intelligence (AI) is a popular trend to make damage inspection and analysis in structural health monitoring more intelligent and automatic. However, the existing AI-based approaches, especially vision-based methods, mainly focus on damage identification and quantification from images without further analysis to obtain structural load-carrying performance. This paper proposes a Damage-T Generative Adversarial Network (Damage-T GAN) to achieve fast translation from real-world crack images to numerical damage contours. To verify its applicability and effectiveness, two datasets from different reinforced concrete beams were built, and the performance of the trained GAN model was evaluated against the metrics IS, FID, etc. After obtaining the damage contour, a purely visual approach was applied to quantify the damage. As a result, the proposed framework greatly helps field engineers to quickly judge the damage stage of beams in site scenes by simultaneous acquisition of real-world crack images and the generated damage contours of numerical model.},
  archive      = {J_EAAI},
  author       = {Yanzhi Qi and Cheng Yuan and Peizhen Li and Qingzhao Kong},
  doi          = {10.1016/j.engappai.2022.105536},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105536},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Damage analysis and quantification of RC beams assisted by damage-T generative adversarial network},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Significant wave height forecasting using hybrid ensemble
deep randomized networks with neurons pruning. <em>EAAI</em>,
<em>117</em>, 105535. (<a
href="https://doi.org/10.1016/j.engappai.2022.105535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reliable control of wave energy devices highly relies on the forecasts of wave heights. However, the dynamic characteristics and significant fluctuation of waves’ historical data pose challenges to precise predictions. Neural networks offer a promising solution to forecast the wave heights by extracting meaningful features from historical observations. This paper proposes a novel hybrid random vector functional link network with the ensemble and deep learning benefits. Hierarchical stacks of hidden layers are constructed to enforce the deep representations of the time series. Individual output layers follow all enhancement layers to adopt ensemble learning. A neuron pruning strategy is proposed to remove the noisy information from the random features and boost the network’s performance. Besides, the proposed network is further utilized to forecast the additive and multiplicative residuals from the ARIMA method. Finally, the ensemble of additive-ARIMA-edRVFL, multiplicative-ARIMA-edRVFL, and edRVFL achieves the best average rankings around two for three forecasting horizons. The proposed ensemble achieves an average ranking of 1.33 on four-hours ahead of forecasting in terms of root mean square error and mean absolute scaled error. Extensive experiments are conducted on twelve time series of the significant wave height. The comparative results demonstrate the superiority of the proposed model over other state-of-the-art methods. The source codes are available on https://github.com/P-N-Suganthan/CODES.},
  archive      = {J_EAAI},
  author       = {Ruobin Gao and Ruilin Li and Minghui Hu and Ponnuthurai Nagaratnam Suganthan and Kum Fai Yuen},
  doi          = {10.1016/j.engappai.2022.105535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Significant wave height forecasting using hybrid ensemble deep randomized networks with neurons pruning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable hierarchical symbolic regression for
safety-critical systems with an application to highway crash prediction.
<em>EAAI</em>, <em>117</em>, 105534. (<a
href="https://doi.org/10.1016/j.engappai.2022.105534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a framework to discover interpretable regression models for high-stakes decision making in the context of safety-critical systems. The core of our proposal is a multi-objective hierarchical symbolic regression algorithm able to compute cluster-specific rankings of regression models ordered by increasing complexity. We discover the hierarchical structure by clustering the features’ importances of a post-hoc explainability framework (viz., SHAP) applied to a highly flexible predictive model (viz., XGBoost). We rely on a symbolic regression algorithm based on the simulated annealing meta-heuristic to infer sparse linear models which may include non-linear effects (e.g., log-transforms, multiplicative interactions...). This search is guided by two objectives: Maximizing predictive performance and minimizing complexity. It ends on a list of Pareto-optimal models that fosters a dynamic interpretative process: the user navigates from the least to the most complex model and decides the ones he can trust depending on whether he understands them, and whether he is satisfied by the quantified uncertainty of their parameters and predictions. Our approach achieves promising results when compared to more than ten other interpretable or black-box predictive models on eleven public regression datasets of various volumes, dimensionalities or domains, and on a proprietary dataset for highway crash prediction. On this last dataset, we demonstrate the usefulness of our new ranking-by-complexity of inherently interpretable models.},
  archive      = {J_EAAI},
  author       = {Thomas Veran and Pierre-Edouard Portier and François Fouquet},
  doi          = {10.1016/j.engappai.2022.105534},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105534},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable hierarchical symbolic regression for safety-critical systems with an application to highway crash prediction},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Application of effective gravitational search algorithm with
constraint priority and expert experience in optimal allocation problems
of distribution network. <em>EAAI</em>, <em>117</em>, 105533. (<a
href="https://doi.org/10.1016/j.engappai.2022.105533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal allocation problem of distribution network (OAPDN), which attracts much attention of electric enterprise, contributes to the flexible and environmental-friendly power supply by rationally introducing distributed generations (DGs) and shunt capacitors (SCs). To smoothly solve OAPDN problems, several effective measures such as advantageous schemes guidance (ASG) mechanism are presented and integrated into the proposed modified gravitational search algorithm with expert experience (MGSA-EE). Multiple OAPDN experiments essentially indicate that the MGSA-EE with higher efficiency and stronger exploration capability reduces the power loss on 33, 69 and 119 node networks by 94.15%, 98.10% and 84.59%, which is superior to most published technologies. Furthermore, multi-objective OAPDN problem which simultaneously considers two or more goals is also studied. Compared with the single-objective one, it is more in line with the diverse demands of actual electricity market, but the difficulty is greatly increased as well. On this basis, this paper extends MGSA-EE to an innovative multi-objective MGSA-EE (MMGSA-EE) algorithm by the suggested non-inferior sorting strategy with constraints-prior. Most typically in multi-objective OAPDN experiments on large scale networks, MMGSA-EE achieves high-quality scheme that concurrently reduces power loss and voltage deviation of 69-node network by 94.07% and 98.69%. Meanwhile, several quantitative indicators also prove that the proposed MMGSA-EE has competitive advantages over the original algorithm in terms of Pareto fronts, node voltage profiles and execution time. In general, MGSA-EE and MMGSA-EE algorithms provide efficient tools for exploring superior DG/SC configuration schemes, and are of great significance to fill research gaps in multi-objective optimizations of distribution network.},
  archive      = {J_EAAI},
  author       = {Jie Qian and Ping Wang and Chenggen Pu and Xiaoli Peng and Gonggui Chen},
  doi          = {10.1016/j.engappai.2022.105533},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105533},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of effective gravitational search algorithm with constraint priority and expert experience in optimal allocation problems of distribution network},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated liver tissues delineation techniques: A systematic
survey on machine learning current trends and future orientations.
<em>EAAI</em>, <em>117</em>, 105532. (<a
href="https://doi.org/10.1016/j.engappai.2022.105532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and computer vision techniques have grown rapidly in recent years due to their automation, suitability, and ability to generate astounding results. Hence, in this paper, we survey the key studies that are published between 2014 and 2022, showcasing the different machine learning algorithms researchers have used to segment the liver, hepatic tumors, and hepatic-vasculature structures. We divide the surveyed studies based on the tissue of interest (hepatic-parenchyma, hepatic-tumors, or hepatic-vessels), highlighting the studies that tackle more than one task simultaneously. Additionally, the machine learning algorithms are classified as either supervised or unsupervised, and they are further partitioned if the amount of work that falls under a certain scheme is significant. Moreover, different datasets and challenges found in literature and websites containing masks of the aforementioned tissues are thoroughly discussed, highlighting the organizers’ original contributions and those of other researchers. Also, the metrics used excessively in the literature are mentioned in our review, stressing their relevance to the task at hand. Finally, critical challenges and future directions are emphasized for innovative researchers to tackle, exposing gaps that need addressing, such as the scarcity of many studies on the vessels’ segmentation challenge and why their absence needs to be dealt with sooner than later.},
  archive      = {J_EAAI},
  author       = {Ayman Al-Kababji and Faycal Bensaali and Sarada Prasad Dakua and Yassine Himeur},
  doi          = {10.1016/j.engappai.2022.105532},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105532},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated liver tissues delineation techniques: A systematic survey on machine learning current trends and future orientations},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The selection of appropriate ro-ro vessel in the second-hand
market using the WASPAS’ bonferroni approach in type 2 neutrosophic
fuzzy environment. <em>EAAI</em>, <em>117</em>, 105531. (<a
href="https://doi.org/10.1016/j.engappai.2022.105531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The second-hand vessel market has quite different dynamics than the market of the new-building vessel, and highly complicated and conflicting criteria and many uncertainties affect the ship selection process. Therefore, it is required to use a robust mathematical model to solve these kinds of decision-making problems. For this purpose, this paper presents an extended version of WASPAS (Weighted Aggregated Sum Product ASsessment) techniques with the help of T2NN based on the Bonferroni function (T2NN WASPAS’B). The three main focal points of the proposed approach are ( i ) setting the influential criteria to select the appropriate Ro-Ro vessel in the second-hand vessel market; and ( ii ) presenting a flexible group decision-making approach, which is proper to real decision-making problems. ( iii ) detecting the interrelations among criteria and eliminating the negative impacts of undesirable and excessive values in input variables on the results. Practical use of the proposed approach is demonstrated to select the appropriate Ro-Ro vessel in the second-hand market. The analysis results show that the most effective and determinative factor is Trailer Lane length, and the most effective alternative is GREIFSWALD. Besides, the consistency and validity of the obtained results have been verified with the help of a stability and robustness check. The results prove that the proposed novel T2NN WASPAS’B model is robust, powerful, and reliable for making rational and realistic decisions.},
  archive      = {J_EAAI},
  author       = {Ömer Faruk Görçün and Dragan Pamucar and Raghunathan Krishankumar and Hande Küçükönder},
  doi          = {10.1016/j.engappai.2022.105531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The selection of appropriate ro-ro vessel in the second-hand market using the WASPAS’ bonferroni approach in type 2 neutrosophic fuzzy environment},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-period dynamic multi-objective emergency material
distribution model under uncertain demand. <em>EAAI</em>, <em>117</em>,
105530. (<a
href="https://doi.org/10.1016/j.engappai.2022.105530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a multi-period dynamic emergency material distribution (EMD) model under uncertain demand by considering the disaster degree and demand of different affected areas to improve the reasonability of disaster relief material distribution in post-disaster emergencies. The objective is to minimize the unsatisfied demand, materials distribution cost, and the risk of choosing the path to distribute materials. The model also focuses on the heterogeneity of emergency materials, the dynamics of demand, and the diversity of transportation tools. In addition, the demands and transportation times are described by fuzzy numbers to better fit with the real situation. To solve the problem we propose a hybrid multi-objective salp swarm algorithm and sine cosine algorithm (HMSSA-SCA). Furthermore, numerical examples of different scenarios and scales are solved and compared with the multi-objective salp swarm algorithm (MSSA), multi-objective evolutionary decomposition algorithm for emergency resource scheduling (MOEA/D-mdERS), non-dominated sorting genetic algorithm II (NSGA-II), and strength pareto evolutionary algorithm 2 (SPEA2) to verify the performance of the HMSSA-SCA algorithm. Finally, the floods and landslides disaster event in 2011 in Rio de Janeiro state, Brazil is used to verify the effectiveness and accuracy of the model and algorithm in the real case.},
  archive      = {J_EAAI},
  author       = {Mengran Wan and Chunming Ye and Dajiang Peng},
  doi          = {10.1016/j.engappai.2022.105530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-period dynamic multi-objective emergency material distribution model under uncertain demand},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HM-YOLOv5: A fast and accurate network for defect detection
of hot-pressed light guide plates. <em>EAAI</em>, <em>117</em>, 105529.
(<a href="https://doi.org/10.1016/j.engappai.2022.105529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex texture background, uneven brightness, various defect sizes and types of hot-pressed light guide plate (LGP) images, the HM-YOLOv5 network for fast and accurate defect detection of hot-pressed LGPs is developed and evaluated in this paper. First, a hybrid attention module (HAM) is constructed by combining the spatial attention of the convolutional block attention module(CBAM) with the channel attention of the efficient channel attention network(ECA-Net), and is introduced behind each C3 module of the backbone network. HAM does not require dimensionality reduction processing, and can better fuse channel and spatial information to focus on defects targets. Therefore, the HAM can enhance the defect feature extraction ability of the network. Second, a multi-expansion convolution module (MCM) is constructed based on the pyramid structure of YOLOv5. MCM can improve the target receptive field, enrich contextual information, reduce loss of information during downsampling and improve the defect detection ability Finally, a self-built dataset is constructed by using the images of hot-pressed LGPs collected from industrial sites, and many experiments are performed using this database. Experimental results show that the mean average precision (mAP) of the network is 98.9%, especially for white point and dark line defects improved by 2.7% and 2.0% respectively, and that the detection speed can reach 417 frames per second(Fps). Compared with the mainstream surface defect detection algorithm, the accuracy and detection time are significantly improved. Moreover, the accuracy and real-time performance meet the industrial detection requirements.},
  archive      = {J_EAAI},
  author       = {Junfeng Li and Yuanxun Yang},
  doi          = {10.1016/j.engappai.2022.105529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HM-YOLOv5: A fast and accurate network for defect detection of hot-pressed light guide plates},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Comparative studies and performance analysis on
neural-dynamics-driven control of redundant robot manipulators with
unknown models. <em>EAAI</em>, <em>117</em>, 105528. (<a
href="https://doi.org/10.1016/j.engappai.2022.105528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an inverse-free and model-free control scheme based on gradient neural dynamics (GND), which avoids the calculation of pseudo-inverse, to achieve the tracking control of redundant robot manipulators without knowing their kinematic models. Specifically, two GND models are deployed to solve the inverse kinematics problem and to estimate the unknown Jacobian matrix of manipulators respectively. We prove that the residual tracking error associated with the proposed scheme theoretically converges to an arbitrarily small upper bound in finite-time. Besides, combining GND and zeroing neural dynamics (ZND), this paper also proposes two control schemes based on hybrid neural dynamics to further achieve better performance. Moreover, the proposed continuous-time control schemes are improved to discrete-time algorithms to facilitate the deployment. Finally, the feasibility and merits of the proposed control schemes are revealed by experiments and comparisons.},
  archive      = {J_EAAI},
  author       = {Peng Yu and Ning Tan and Zhiyan Zhong},
  doi          = {10.1016/j.engappai.2022.105528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparative studies and performance analysis on neural-dynamics-driven control of redundant robot manipulators with unknown models},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sensor fault-tolerant control for a doubly fed induction
generator in a smart grid. <em>EAAI</em>, <em>117</em>, 105527. (<a
href="https://doi.org/10.1016/j.engappai.2022.105527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a sensor fault-tolerant controller for a doubly fed induction generator connected to a smart grid. Mathematical models are the main tools for the synthesis of modern control systems; however, an accurate model for complex systems is not always available. Therefore, in this study, a recurrent high-order neural network trained with an extended Kalman filter is proposed to develop a mathematical model for a wind turbine with a doubly fed induction generator connected to a smart grid. The neural model is combined with a modified discrete-time sliding mode controller, which compensates for the presence of sensor faults on each of the state variables on both sides of the back-to-back converter. Real-time results are included to illustrate the effectiveness of the proposed scheme under five sensor faults.},
  archive      = {J_EAAI},
  author       = {Robin F. Conchas and Edgar N. Sanchez and Luis J. Ricalde and Jesus G. Alvarez and Alma Y. Alanis},
  doi          = {10.1016/j.engappai.2022.105527},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105527},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sensor fault-tolerant control for a doubly fed induction generator in a smart grid},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter identification of dual-rate hammerstein-volterra
nonlinear systems by the hybrid particle swarm-gradient algorithm based
on the auxiliary model. <em>EAAI</em>, <em>117</em>, 105526. (<a
href="https://doi.org/10.1016/j.engappai.2022.105526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at the parameter estimation of dual-rate Hammerstein-Volterra (DR-HV) systems. The auxiliary model (AM) method is applied to solve the incomplete identification data caused by the dual-rate sampling. Besides, combining the particle swarm optimization (PSO) and the gradient search principle, this paper proposes an improved algorithm — the hybrid particle swarm-gradient based on the auxiliary model (AM-HPSG) algorithm, which is employed to the DR-HV identification. The AM-HPSG method converts the nonlinear identification issue into the optimization problem in the parameter space. Moreover, the application of the gradient mutation strategy in the AM-HPSG algorithm can not only improve the optimization speed and the identification accuracy, but also solve the premature problem of the basic PSO method. To verify the feasibility of the AM-HPSG algorithm, the second-order DR-HV model and the third-order DR-HV models are considered in simulation. And it can be easy to find that the AM-HPSG performs much better than the PSO and the gradient iterative (GI) methods through algorithm comparison.},
  archive      = {J_EAAI},
  author       = {Tiancheng Zong and Junhong Li and Guoping Lu},
  doi          = {10.1016/j.engappai.2022.105526},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105526},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parameter identification of dual-rate hammerstein-volterra nonlinear systems by the hybrid particle swarm-gradient algorithm based on the auxiliary model},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring 2-rank strategic weight manipulation in multiple
attribute decision making and its applications in project review and
university ranking. <em>EAAI</em>, <em>117</em>, 105525. (<a
href="https://doi.org/10.1016/j.engappai.2022.105525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some real multiple attribute decision making (MADM) problems, sometimes, it is time-consuming and unnecessary to obtain a complete ranking of alternatives, thus, a decision maker would classify the alternatives into two ordered categories, forming a 2-rank MADM problem. Occasionally, a decision maker can manipulate the desired 2-rank results by strategically setting attribute weights. This process is called 2-rank strategic weight manipulation (2RSWM). First, this study defines the 2-rank range of alternatives. Subsequently, several mixed 0–1 linear programming models (MLPMs) are constructed to obtain the 2-rank range and the strategic attribute weight vector of the desired 2-rank result of the alternative(s) of the decision maker. Furthermore, we provide conditions for the existence of the strategic attribute weight vector based on the 2-rank range of the alternatives and the proposed MLPMs. Finally, two illustrative examples and two simulation experiments are conducted to validate the effectiveness of our proposed models. Due to the ordered weighted averaging (OWA) operator having smaller average width of the 2-rank range, and a larger minimum distance between the impersonal and strategic attribute weight vectors, we argue that the OWA operator has a better performance than the weighted averaging (WA) operator in defending against 2RSWM.},
  archive      = {J_EAAI},
  author       = {Yating Liu and Siqi Wu and Congcong Li and Yucheng Dong},
  doi          = {10.1016/j.engappai.2022.105525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring 2-rank strategic weight manipulation in multiple attribute decision making and its applications in project review and university ranking},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiple fault detection and isolation using artificial
neural networks in sensors of an internal combustion engine.
<em>EAAI</em>, <em>117</em>, 105524. (<a
href="https://doi.org/10.1016/j.engappai.2022.105524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology advances rapidly in vehicles with internal combustion engines; therefore, detecting vehicles’ faults becomes more complex, primarily due to the increased usage of sensors and actuators to improve engine performance. Specialized instruments for detecting vehicle faults can sometimes show errors in multiple sensors when there is only one issue in the system, and they are not responsible for isolating faults. Then, it must add superior algorithms for fault detection and isolation (FDI) in the Internal Combustion Engine to these diagnostic instruments. For this reason, this research focuses on designing an individual and multiple fault detection and isolation system based on artificial neural networks for an internal combustion engine. The proposed scheme detects individual and multiple faults in the throttle position sensors (TPS), mass air-flow (MAF), and manifold absolute pressure (MAP). The FDI system uses five artificial neural networks (ANN). Each ANN estimates the value of two sensors using the engine speed and the air–fuel ratio (AFR) signal to generate analytical redundancy. When a sensor fault occurs, the FDI system substitutes the faulty signal with a healthy signal estimate provided by an ANN. Suppose a second fault arises in another sensor. The FDI system can replace the faulty signal with the ANN’s estimated signal, allowing the internal combustion engine to run even with multiple faults.},
  archive      = {J_EAAI},
  author       = {M. Cervantes-Bobadilla and J. García-Morales and Y.I. Saavedra-Benítez and J.A. Hernández-Pérez and M. Adam-Medina and G.V. Guerrero-Ramírez and R.F. Escobar-Jímenez},
  doi          = {10.1016/j.engappai.2022.105524},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105524},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple fault detection and isolation using artificial neural networks in sensors of an internal combustion engine},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trajectory optimization of space vehicle in rendezvous
proximity operation with evolutionary feasibility conserving techniques.
<em>EAAI</em>, <em>117</em>, 105523. (<a
href="https://doi.org/10.1016/j.engappai.2022.105523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a direct approach is developed for discovering optimal transfer trajectories of close-range rendezvous of satellites considering disturbances in elliptical orbits. The control vector representing the inputs is parameterized via different interpolation methods, and an Estimation of Distribution Algorithm (EDA) that implements mixtures of probability models is presented. To satisfy the terminal conditions, which are represented as non-linear inequality constraints, several feasibility conserving mechanisms associated with learning and sampling methods of the EDAs are proposed, which guarantee the feasibility of the explored solutions. They include a particular implementation of a clustering algorithm, outlier detection, and several heuristic mapping methods. The combination of the proposed operators guides the optimization process in achieving the optimal solution by surfing the regions of the search domain associated with feasible solutions. Numerical simulations confirm that space transfer trajectories with minimum-fuel consumption for the chaser spacecraft can be obtained with terminal condition satisfaction in rendezvous proximity operation.},
  archive      = {J_EAAI},
  author       = {Abolfazl Shirazi and Josu Ceberio and Jose A. Lozano},
  doi          = {10.1016/j.engappai.2022.105523},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105523},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trajectory optimization of space vehicle in rendezvous proximity operation with evolutionary feasibility conserving techniques},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning based fault diagnosis of automobile dry
clutch system. <em>EAAI</em>, <em>117</em>, 105522. (<a
href="https://doi.org/10.1016/j.engappai.2022.105522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dry friction clutches are prone to fault occurrences due to their continuous exposure to thermal loading and high abrasive rate during power transmission. Fault occurrences in clutches can lead to damage in internal components, downtime and seizure of transmission system. Thus, it is necessary to detect and diagnose such fault occurrences at an early stage. In the present study, an attempt was made to diagnose various clutch faults like release fingers worn out, pressure plate broken, pressure plate worn out, friction material loss, and tangential strip bent using deep learning technique (transfer learning). Vibration signals were acquired from a test rig operated under various load conditions for different clutch conditions (5 faulty and 1 good) that were further processed and stored as vibration plots. The concept of transfer learning involving four pre-trained network models namely, AlexNet, VGG-16, GoogLenet and ResNet-50 were utilized in the present study. Various hyperparameters such as train–test split ratio, learning rate, optimizer and batch size were altered and the best hyperparameters suitable for achieving high classification accuracy for every pre-trained network was determined. Overall, VGG-16 pre-trained network performed exceptionally well among the counterparts with a classification accuracy of 100% in a computational time of 449 s.},
  archive      = {J_EAAI},
  author       = {G. Chakrapani and V. Sugumaran},
  doi          = {10.1016/j.engappai.2022.105522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transfer learning based fault diagnosis of automobile dry clutch system},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning approach for delamination identification using
animation of lamb waves. <em>EAAI</em>, <em>117</em>, 105520. (<a
href="https://doi.org/10.1016/j.engappai.2022.105520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex design of composite structures makes it very difficult for conventional visual inspection techniques to detect defects in these materials. Therefore, numerous types of nondestructive testing and structural health monitoring techniques have been developed for damage identification in composite structures, among which ultrasonic guided waves, particularly Lamb waves, have gained much popularity. In recent years, apart from piezoelectric pointwise measurements, laser Doppler vibrometry has been used for full wavefield measurements of propagating Lamb waves. Damage imaging can be done with animations of Lamb waves interacting with defects. In this work, two end-to-end deep learning-based models of many-to-one sequence prediction were developed to perform pixel-wise image segmentation. A large dataset of full wavefield images resulting from the interaction with delamination of random size, shape, and location was utilised to train the proposed deep learning models. The main goal of this work is to investigate the feasibility of implementing deep learning methods for delamination identification in composite laminates by only utilising the animations of Lamb waves. The elaborated models worked well on the numerically generated test data and have also shown good performance on the real-world experimental data. These methods can enable the automation of delamination identification and to create damage maps without the intervention of the user.},
  archive      = {J_EAAI},
  author       = {Saeed Ullah and Abdalraheem A. Ijjeh and Pawel Kudela},
  doi          = {10.1016/j.engappai.2022.105520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning approach for delamination identification using animation of lamb waves},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DFSGAN: Introducing editable and representative attributes
for few-shot image generation. <em>EAAI</em>, <em>117</em>, 105519. (<a
href="https://doi.org/10.1016/j.engappai.2022.105519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training generative adversarial networks (GANs) usually requires large-scale data and massive computation resources. The performance of GANs plummets when given limited data due to the discriminator overfitting, thus providing meaningless feedback to the generator during the adversarial training. Existing few-shot GANs are primarily concerned with transferring knowledge from models that have been pre-trained on large-scale datasets or using data augmentation to expand the training sets. However, previous methods consistently take latent codes sampled from a single distribution as the generator’s input. We contend that more complicated latent codes can provide the generator with more editable attributes. In this paper, we propose DFSGAN for few-shot image generation, which takes dynamic Gaussian mixture (DGM) latent codes as the generator’s input. Our DFSGAN can select the Gaussian components of the latent codes quantitatively. We also design two techniques to strengthen the representative ability of intermediate features of the generating process to improve the fidelity and maintain the content and layout information of the synthesized images. Our DGM and intermediate representation enhancement techniques complement each other and improve synthesis quality. We conduct extensive experiments on 15 few-shot datasets with different resolutions spanning from art paintings to realistic photos. Qualitative and quantitative results demonstrate the superiority and effectiveness of our model.},
  archive      = {J_EAAI},
  author       = {Mengping Yang and Saisai Niu and Zhe Wang and Dongdong Li and Wenli Du},
  doi          = {10.1016/j.engappai.2022.105519},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105519},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DFSGAN: Introducing editable and representative attributes for few-shot image generation},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fermatean fuzzy fine–kinney for occupational risk
evaluation using extensible MARCOS with prospect theory. <em>EAAI</em>,
<em>117</em>, 105518. (<a
href="https://doi.org/10.1016/j.engappai.2022.105518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extant Fine–Kinney frameworks are insufficient to tackle the risk evaluation problem with Fermatean fuzzy information, in which the prioritization degrees and psychological characteristics of decision-makers are considered. Hence, this study develops a hybrid Fine–Kinney-based occupational risk evaluation framework with an extended Fermatean fuzzy MARCOS method (measurement of alternatives and ranking to Compromise solution). Such a MARCOS method improves conventional MARCOS by integrating Fermatean fuzzy prioritized weighted average operator and prospect theory. This improved method has the capability to handle the occupational risk analysis problem with Fermatean fuzzy data in the risk ranking procedure considering the prioritization degrees and bounded rational behavior of decision-makers. In addition, the Fermatean fuzzy numbers-based risk rating scales are established to transform the linguistic risk scores from decision-makers, it allows for handling uncertain risk rating information from decision-makers more effectively. Further, the improved MARCOS method is incorporated into the occupational risk ranking procedure, as it considers the decision-maker’s prioritization relationships among decision-makers and their reference point effect in occupational risk priority calculation. After that, an occupational risk analysis case for construction operations is selected to test the applicability and validity of the proposed framework. The result indicates that the occupational risk OR 6 (Back injury) is the most serious risk with the lowest utility function value (-0.324), and OR 7 (Tendinitis) is the least severe risk with the highest utility function value (0.682). Finally, sensitivity exploration and comparative study are implemented to further test the advantages of the developed framework.},
  archive      = {J_EAAI},
  author       = {Weizhong Wang and Xiao Han and Weiping Ding and Qun Wu and Xiaoqing Chen and Muhammet Deveci},
  doi          = {10.1016/j.engappai.2022.105518},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105518},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fermatean fuzzy Fine–Kinney for occupational risk evaluation using extensible MARCOS with prospect theory},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient meta label correction based on meta learning and
bi-level optimization. <em>EAAI</em>, <em>117</em>, 105517. (<a
href="https://doi.org/10.1016/j.engappai.2022.105517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of highly accurate deep learning architectures is related to different parameters through different optimizations at different levels of the design. While the architectural design and the training procedure of the neural networks play significant role, the quantity and the quality of the available data remain also very important issues. This research aims to address the quality of the data issue: the data contain imprecise or noisy labels. Numerous approaches have been proposed in the literature to leverage noisy data in case of different noisy labels as well as the strategies and frameworks developed to use the data in practice. Recently, meta-learning based methods have shown good performance to optimize models that take into account the presence of noisy labels within the training dataset. In this work, we propose a new method called Meta label correction via Meta Learning and bi-level optimization (CO-META). It is based on extracting and providing only relevant features to enhance the performance of the label corrector network to tackle the raised problem. The obtained results demonstrate that the proposed method outperforms the state-of-the-art accuracy on the well-known image classification datasets.},
  archive      = {J_EAAI},
  author       = {Soufiane Mallem and Abul Hasnat and Amir Nakib},
  doi          = {10.1016/j.engappai.2022.105517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient meta label correction based on meta learning and bi-level optimization},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics-informed convolutional neural networks for
temperature field prediction of heat source layout without labeled data.
<em>EAAI</em>, <em>117</em>, 105516. (<a
href="https://doi.org/10.1016/j.engappai.2022.105516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, surrogate models based on deep learning have attracted much attention for engineering analysis and optimization. Since constructing data pairs in most engineering problems is time-consuming, data acquisition is becoming the predictive capability bottleneck of most deep surrogate models, which also exist in surrogate for thermal analysis and design. In contrast with data-driven learning, enforcing the physical laws in building surrogates has emerged as a promising alternative to reduce the dependence on annotated data. This paper develops a physics-informed convolutional neural network (CNN) for the thermal simulation surrogate without labeled data. Firstly, we leverage the finite difference method to integrate heat conduction equation and loss function construction, guiding surrogate model training to minimize the violation of physical laws. Since the solution is sensitive to boundary conditions, we properly impose hard constraints by padding in the Dirichlet and Neumann boundaries. The proposed network can learn a mapping from heat source layout to the steady-state temperature field without labeled data, which equals solving an entire family of partial difference equations (PDEs). Moreover, the neural network architecture is well-designed to improve the prediction accuracy of the problem at hand, and pixel-level online hard example mining is proposed to overcome the imbalance of optimization difficulty in the computation domain, which is beneficial to the network training of physics-informed learning. The experiments demonstrate that the proposed method can provide comparable predictions with numerical methods and data-driven deep learning models. We also conduct various ablation studies to investigate the effectiveness of the proposed network components and training methods in this paper. Furthermore, the developed methods can be applied to other design and optimization applications which need to solve parameterized PDEs.},
  archive      = {J_EAAI},
  author       = {Xiaoyu Zhao and Zhiqiang Gong and Yunyang Zhang and Wen Yao and Xiaoqian Chen},
  doi          = {10.1016/j.engappai.2022.105516},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105516},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed convolutional neural networks for temperature field prediction of heat source layout without labeled data},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An integrated approach using rough set theory, ANFIS, and
z-number in occupational risk prediction. <em>EAAI</em>, <em>117</em>,
105515. (<a
href="https://doi.org/10.1016/j.engappai.2022.105515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning (ML)-based approaches have gained increasing attention in occupational accident research. However, the challenges of data uncertainty, unstructured information handling, lower prediction power of algorithms, and crisp rule generation and its linguistic description remain predominant in ML research, particularly in occupational risk prediction. The present study aims to develop a new methodology to effectively address the aforementioned challenges. The methodology is developed for the tasks of prediction and rule generation. The predictive model, namely rough set (RS) sample-based PSO-ANFIS is developed for prediction, and then, decision rules are generated using the lower approximation of RS and Z-number. The developed methodology contributes by: (i) handling data uncertainty using lower approximation of RS, (ii) unstructured information handling using Latent Dirichlet Allocation (LDA)-based topic modeling, and (iii) prediction using an optimized ML model, (iv) extraction of crisp decision rules using the lower approximation of RS, and (v) determining reliability of the crisp decision rules using Z-number. The efficacy of the proposed method over some state-of-the-art (i.e., ANN, KNN, SVM, C4.5, C5.0, CART, RF, and RS-PSO-ANFIS) is demonstrated using some benchmark datasets acquired from the UCI ML repository, and one real-life occupational safety data acquired from an integrated steel plant in India. A total of 22 implementable crisp safety decision rules have been extracted from the predictive results based on the lower approximation of RS. Experimental results also reveal that the RS sample-based PSO-ANFIS produces minimum mean absolute error (MAE) in risk prediction and is found to be the most robust algorithm.},
  archive      = {J_EAAI},
  author       = {Sobhan Sarkar and Anima Pramanik and J. Maiti},
  doi          = {10.1016/j.engappai.2022.105515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated approach using rough set theory, ANFIS, and Z-number in occupational risk prediction},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An ensemble learning approach to condition assessment of
dissipative CLT connections based on piezoceramic sensor data.
<em>EAAI</em>, <em>117</em>, 105514. (<a
href="https://doi.org/10.1016/j.engappai.2022.105514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel dissipative connections of cross-laminated timber (CLT) structures, showing great ductility and energy dissipation capability in addition to meeting the requirement of strength and stiffness, have gained increasing attraction in CLT shear walls. As important elements of CLT structures, dissipative connections function as the main part to resist seismic loading. It often displays different mechanical behaviors and suffers stiffness degradation when subjected to external loads. Variations of mechanical behaviors would further affect structural performance during service. The traditional method of analyzing mechanical behaviors of CLT connections relies on destructive tests, which are time-consuming and irreversible. Thus, using the non-destructive method to identify the mechanical behavior of dissipative CLT connections is of great significance. An ensemble learning-aided prediction algorithm combined with piezoceramic-enabled sensing technology is proposed in this study to identify mechanical behaviors of dissipative CLT connections under external loading. The main contribution of this study is to build a bridge between the damage-sensitive feature extracted from non-destructive sensing signals and mechanical behaviors obtained by the destructive loading test through the proposed method, which can avoid the requirement of time-consuming destructive tests and the baseline signal in traditional piezoceramic-enabled sensing method. An energy dissipative hold-down connection model is established in numerical simulations to investigate stress wave propagation mechanisms via different loading conditions. In experimental studies, a reusable piezoceramic-based sensor is firstly designed, and its performance is validated through a preliminary test. Then, a loading test was conducted on a CLT joint with a dissipative hold-down connector to further verify the numerical findings and generate an intact-to-failure piezoceramic-based sensing signal dataset through all loading cases. Consequently, fuzzy entropy is extracted from the signal dataset and fed to an ensemble learning classifier to predict loading behaviors. Prediction results imply the great potential of the proposed method for predicting dissipative CLT joint life-cycle performance in field applications.},
  archive      = {J_EAAI},
  author       = {Lin Chen and Haibei Xiong and Xiuquan Li and Yurong Lu and Qingzhao Kong},
  doi          = {10.1016/j.engappai.2022.105514},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105514},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An ensemble learning approach to condition assessment of dissipative CLT connections based on piezoceramic sensor data},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A new data fusion driven-sparse representation learning
method for bearing intelligent diagnosis in small and unbalanced
samples. <em>EAAI</em>, <em>117</em>, 105513. (<a
href="https://doi.org/10.1016/j.engappai.2022.105513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dictionary learning has made enormous achievements for its powerful feature representation capabilities. For the bearing fault diagnosis, the lack of failure samples is always a problem demanding prompt solutions. Since failure samples are far less than the normal samples, the data is inevitably to be unbalanced. To solve these problems, a new data fusion driven-sparse representation learning (DFDSRL) framework is proposed for fault diagnosis in small and unbalanced samples. The proposed method first constructs different dictionaries severally from the data samples grouped according to the signal modes (for example, the signals measured from the bearing under different working conditions). To induce the dictionary discriminability, discriminative sparse codes errors, reconstruction errors and classification errors are integrated as optimization objectives. Then, a new data fusion strategy is developed to fuse the dictionaries from all signal modes in the same fault class, and a fused dictionary for each fault class is generated for the final fault identification. The fusion is performed at the feature level instead of the conventional data level, and the discriminability of the fused dictionaries are further enhanced with the fusion strategy by eliminating the insignificant features shared by the atoms in each fault class dictionaries. Experimental results show that the DFDSRL achieves high fault identification accuracy for the problems of small and unbalanced samples in comparison with several advanced methods, benefitting from its excellent capability of fusing more fault features. By transforming the data unbalanced problem into the balanced small sample problem, DFDSRL further improves the fault identification accuracy.},
  archive      = {J_EAAI},
  author       = {Yike Zhao and Xin Zhang and Jiaxu Wang and Lei Wu and Zhiwen Liu and Lei Wang},
  doi          = {10.1016/j.engappai.2022.105513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new data fusion driven-sparse representation learning method for bearing intelligent diagnosis in small and unbalanced samples},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inferable dynamic markov model to predict interference
effects. <em>EAAI</em>, <em>117</em>, 105512. (<a
href="https://doi.org/10.1016/j.engappai.2022.105512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Common decision-making models assume that the system would change over time. But when system is in a particular moment, decision-maker has to make a specific judgment which would put the system in a determined state not an uncertain state. Most decision-making models emphasize the determined state of the system after the judgment and ignore the uncertain state prior to the judgment. So, it would be biased in simulating real-life decision experiments if these uncertain information were lost. Besides, some cognitive decision-making experiments have demonstrated that the law of total probability would not be applicable in practice. What is the reason for this phenomenon? Some researchers thought that interference effects in decision-making process is the main reason, which has been verified from the mathematical proof. Moreover, the interference effects is produced due existing of uncertain information. Quantum theory uses probability amplitude to model uncertainty information of system that would exist simultaneously in multiple states. It is able to better model uncertain states before making a judgement, where judgement can be understood as measurement in quantum theory. Hence, the paper proposed an inferable dynamic Markov decision-making model to quantitatively predict and determine the value of interference effects in the decision-making process. The new model used probability amplitude to represent uncertain information in the decision process, and combined it with Markov decision-making model to study the evolution between different moments in the decision process. Additionally, based on quantum theory principles, it is possible to estimate and infer the related parameters reasonably.},
  archive      = {J_EAAI},
  author       = {Xiaozhuan Gao and Yong Deng},
  doi          = {10.1016/j.engappai.2022.105512},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105512},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inferable dynamic markov model to predict interference effects},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label consistency-based deep semisupervised NMF for tumor
recognition. <em>EAAI</em>, <em>117</em>, 105511. (<a
href="https://doi.org/10.1016/j.engappai.2022.105511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tumor has become a hot topic in the field of image processing and pattern recognition. Gene expression data is an important way to study tumor. Since gene expression data is characterized by high-dimensional small samples, it is one of the key steps to extract discriminative gene features to distinguish different tumor types. Nonnegative matrix factorization (NMF) is an unsupervised feature representation method that does not depend on the label information of data. NMF can achieve nonlinear dimension reduction and is widely used in tumor recognition. Considering that some data may carry label information, models’ feature representation capability will be improved if the label information can be used effectively. Therefore, this paper proposes a semisupervised NMF model based on label consistency (LC-NMF), which uses both labeled and unlabeled data to obtain feature representations. Furthermore, to alleviate the sensitivity of the NMF model to initial values and excavate the deep features of data, a label consistency-based deep semisupervised NMF model (LC-DNMF) is constructed, which combines the LC-NMF model with the layer-by-layer pretraining and multilayer representation strategy in deep learning. The performance of the proposed models (i.e., LC-NMF and LC-DNMF) is verified by applying them to the tumor recognition tasks. The experimental results on seven datasets show that the two models achieve good results and can obtain competitive recognition accuracies compared with the state-of-the-art methods. Furthermore, the performance of the LC-DNMF model outperforms that of the LC-NMF model, which verifies the effectiveness of introducing the layer-by-layer pretraining and multilayer representation strategy.},
  archive      = {J_EAAI},
  author       = {Lijun Yang and Lulu Yan and Xiaoge Wei and Xiaohui Yang},
  doi          = {10.1016/j.engappai.2022.105511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Label consistency-based deep semisupervised NMF for tumor recognition},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global contextually guided lightweight network for
RGB-thermal urban scene understanding. <em>EAAI</em>, <em>117</em>,
105510. (<a
href="https://doi.org/10.1016/j.engappai.2022.105510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent achievements in scene understanding have benefited considerably from the rapid development of convolutional neural networks. However, improvements of scene understanding methods have been restricted in terms of practical deployment, especially in mobile devices, owing to their high computational costs and memory consumption. Existing networks can integrate RGB and thermal (RGB-T) cues for sample fusion, resulting in insufficient exploitation of the complicated correlations between the two image modalities. Moreover, some of these methods do not consider the influence of global features on the interactions between low- and high-level features. Hence, in this study, we introduce a novel network named the global contextually guided lightweight network (GCGLNet), which has fewer parameters and higher speed, ensuring accuracy. Specifically, secondary cross-modal integration is introduced to remove redundant information while fusing and propagating effective modal information. A hybrid feature-cascaded aggregation module is also introduced to emphasize the global context along with complementation and calibration between the high- and low-level features. Extensive experiments were conducted on two benchmark RGB-T datasets to demonstrate that the proposed GCGLNet yields an accuracy comparable with those of state-of-the-art approaches when operated at 51.89 FPS for 480 × 640 pixel inputs with only 7.87 M parameters. Thus, GCGLNet is expected to open new avenues for research on urban scene understanding via RGB-T sensors.},
  archive      = {J_EAAI},
  author       = {Tingting Gong and Wujie Zhou and Xiaohong Qian and Jingsheng Lei and Lu Yu},
  doi          = {10.1016/j.engappai.2022.105510},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105510},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Global contextually guided lightweight network for RGB-thermal urban scene understanding},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EA-CNN: A smart indoor 3D positioning scheme based on wi-fi
fingerprinting and deep learning. <em>EAAI</em>, <em>117</em>, 105509.
(<a href="https://doi.org/10.1016/j.engappai.2022.105509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate indoor location information in multi-building/floor environments is essential for establishing many indoor location-based services (LBS). Wi-Fi fingerprinting with received signal strength indicators (RSSI) has become one of the most practical techniques to localize users indoors. However, the fluctuation of wireless signals caused by fading, the multipath effect, and device heterogeneity leads to considerable variations in RSSIs, which poses a challenge to accurate localization. This paper proposes an indoor positioning method, which is constructed based on a convolutional neural network (CNN) framework. Specifically, a novel model by combining an extreme learning machine autoencoder (ELM-AE) with a two-dimensional CNN is proposed. The ELM-AE extracts critical features by reducing input dimensions, while the CNN is trained to effectively achieve significant performance in the positioning phase. To increase positioning accuracy and deal with data shortages, a data augmentation strategy by frequently adding noisy data to the original fingerprint map is devised. The statistical properties namely, the RSS values of each MAC address, are utilized to adjust input noise. The performance of the proposed system is evaluated on two Tampere and UJIIndoorLoc datasets. The experimental results show that EA-CNN achieves better performance than CNN by decreasing average positioning error up to 40.95% and 43.74% in Tampere and UJIIndoorLoc datasets, respectively. Compared to state-of-the-art deep learning-based methods, the positioning performance improves up to 68.36% in Tampere and 67.56% in the UJIIndoorLoc dataset by exploiting only 25% of the training samples. Compared to several state-of-the-art deep learning models, EA-CNN achieves higher accuracy in both positioning and floor estimation.},
  archive      = {J_EAAI},
  author       = {Atefe Alitaleshi and Hamid Jazayeriy and Javad Kazemitabar},
  doi          = {10.1016/j.engappai.2022.105509},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105509},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EA-CNN: A smart indoor 3D positioning scheme based on wi-fi fingerprinting and deep learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAN-based sensor data augmentation: Application for counting
moving people and detecting directions using PIR sensors. <em>EAAI</em>,
<em>117</em>, 105508. (<a
href="https://doi.org/10.1016/j.engappai.2022.105508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In indoor environments, such as smart homes, the number of occupants within the space and their moving directions can provide a rich set of contextual information about the surroundings and occupants themselves, which can enable systems to adapt their services according to the occupants’ situation. Therefore, significant effort has been devoted to the development of variable sensing systems and learning methods. In this study, we introduce a pyroelectric infrared (PIR) sensor-based sensing system for counting moving people and detecting directions using convolutional neural networks (CNNs) and generative adversarial networks (GANs). PIR output signals were collected from four multiple-subject scenarios: single-, two-, three-, and four-subject groups in the experiments. We propose a novel time sequence sensor data augmentation algorithm, namely, auxiliary-classifier conditional GAN. This algorithm embeds the input data to reflect the condition to which the generated data should be transformed and its class information to which the generated data should be classified. The algorithm aims to build a model that works well in cases where multiple people move together (like to occur less than the cases when a single person moves alone). The experimental results show that when compared with the original model without augmentation, our multitask learning model combined with the proposed sample augmentation method increases the precision of counting moving people by 7.9%, 9.7%, 26%, and 37.5% for the one-, two-, three-, and four-subject groups, respectively, when compared with the original model without augmentation.},
  archive      = {J_EAAI},
  author       = {Jaeseok Yun and Daehee Kim and Dong Min Kim and Taewon Song and Jiyoung Woo},
  doi          = {10.1016/j.engappai.2022.105508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GAN-based sensor data augmentation: Application for counting moving people and detecting directions using PIR sensors},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A novel deep convolutional image-denoiser network for
structural vibration signal denoising. <em>EAAI</em>, <em>117</em>,
105507. (<a
href="https://doi.org/10.1016/j.engappai.2022.105507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration-based approach is of great importance for structural health monitoring and condition assessment, while inevitable noise existing in field measurement casts great obstacles in corresponding data-driven analysis. It has been a stringent prerequisite to develop effective methods to denoise vibration signal. Hence, a novel denoising approach based on deep convolutional image-denoiser networks (DCIMN) is proposed in this study, the methodology and architecture of which are elaborated. Specified avenues with novelties including noise injection in training labeling, dimension expansion in feature extraction, and optimizer embedding in encoder–decoder are utilized to enhance the denoising performance. Measured vibration data from Shanghai Tower is allocated for validation, based on which modal identifications are also conducted. Detailed evaluation confirms its powerful capability and efficiency in denoising signal. Demanding no prior information of input signal, the proposed method performs vibration signal denoising in an intelligent way, which demonstrates a vast prospect in engineering practice.},
  archive      = {J_EAAI},
  author       = {Qingsong Xiong and Haibei Xiong and Cheng Yuan and Qingzhao Kong},
  doi          = {10.1016/j.engappai.2022.105507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep convolutional image-denoiser network for structural vibration signal denoising},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Vibration suppression of ball-screw drive system based on
flexible dynamics model. <em>EAAI</em>, <em>117</em>, 105506. (<a
href="https://doi.org/10.1016/j.engappai.2022.105506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem of residual vibration of the ball-screw drive system when it stops in high-speed motion, a vibration suppression method based on the flexible dynamics model is proposed. A simplified flexible dynamics model of the ball-screw system is developed using the Lagrange method and rewritten as a parametric identification equation containing only the motor’s rotation angle. A Particle Swarm Optimization algorithm based on Recursive Least Square finite search space (RLS-PSO) is proposed for dynamic parameter identification and the results are used to design a coupled ZVD shaper to suppress residual vibration in the ball-screw drive system. The experimental results of model identification show that RLS-PSO is more accurate than WLS, PSO and GA, and the convergence speed is much higher compared to PSO and GA. The simplified dynamics model can reflect the dynamic characteristics of the system accurately. The results of the vibration experiments demonstrate the effectiveness of the input shaper designed using the identification results in suppressing residual vibration of the ball-screw drive system.},
  archive      = {J_EAAI},
  author       = {Lin Li and Qiangwei Zhang and Tie Zhang and Yanbiao Zou},
  doi          = {10.1016/j.engappai.2022.105506},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105506},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vibration suppression of ball-screw drive system based on flexible dynamics model},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Rock joint roughness determination method based on deep
learning of time–frequency​ spectrogram. <em>EAAI</em>, <em>117</em>,
105505. (<a
href="https://doi.org/10.1016/j.engappai.2022.105505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem that it is hard to fully reflect the surface morphology of rock joints with a certain feature parameter, a joint roughness determination method based on deep learning of time–frequency spectrogram was proposed. Firstly, regarding the rock joint profile as a time series signal, the time–frequency spectrogram was drawn through the Short-Time Fourier Transform (STFT) to comprehensively characterize the undulation location and degree of joint, and describe the roughness feature information of the joint profile more clearly and accurately. Then, the deep convolutional neural network was combined to extract and learn the features of the time–frequency spectrogram, and the roughness coefficient of the rock joint profile was identified, which effectively recovered the deficiency of the traditional artificial formulation feature parameters. The experimental results showed that compared with the conventional empirical regression method and machine learning (ML) models, the identified joint roughness coefficient based on deep learning of the time–frequency spectrogram was more consistent with the true value, and the calculation results were more reasonable and reliable, with higher recognition accuracy and generalization ability. It verified the feasibility and effectiveness of deep learning technology in the field of rock joint roughness identification. Finally, the influence of the sampling interval in this method was analyzed, and it suggested that the sampling interval of this method should not be longer than 0.4 mm when evaluating the joint roughness with about 10 cm in length.},
  archive      = {J_EAAI},
  author       = {Huajin Zhang and Shunchuan Wu and Zhongxin Zhang and Longqiang Han},
  doi          = {10.1016/j.engappai.2022.105505},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105505},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rock joint roughness determination method based on deep learning of time–frequency​ spectrogram},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BANet: Small and multi-object detection with a bidirectional
attention network for traffic scenes. <em>EAAI</em>, <em>117</em>,
105504. (<a
href="https://doi.org/10.1016/j.engappai.2022.105504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the detection accuracy and speed for small and multi-object detection is a hot issue in traffic environments. Despite the substantial advances in object detection algorithms based on deep neural networks, addressing the inaccuracy and low efficiency of small and multi-object detection remains challenging. In this paper, we propose a bidirectional attention network called BANet, which includes multichannel attention (MCA) blocks, alpha-effective intersection-over-union ( α -EIoU) loss, and a multiple attention fusion (MAF) module. Each MCA block consists of low-layer, medium-layer, and high-layer features to provide rich base information for feature fusion at the neck module. We introduce MAF to alleviate the spatial location loss and poor semantic performance resulting from the continuous downsampling of the path aggregation feature pyramid network (PAFPNet). Finally, α -EIoU is our regression loss module, which calculates the difference between the predicted box and the ground truth (gt) box. Our study further demonstrates that these strategies yield significant improvements in performance over some existing YOLO detectors. Compared with the performance of YOLOX, BANet demonstrates 0.39%–0.52% mAP@0.5 improvement on the PASCAL VOC 2007 (VOC 07) dataset and 0.55%–2.93% mAP@0.5 improvement on the PASCAL VOC 2012 (VOC 12) dataset. Additionally, 0.3%–1.01% improvement in the mAP@0.5 is achieved on the MS COCO 2017 (COCO 17) dataset, indicating that BANet has a significant effect on multi-object detection. Experiments to determine the approximate number of parameters with YOLOX, show that our strategy not only improves by 7.5 frames per second ( FPS ) but also reduces the Average forward time by 0.97 ms.},
  archive      = {J_EAAI},
  author       = {Sheng-ye Wang and Zhong Qu and Cui-jin Li and Le-yuan Gao},
  doi          = {10.1016/j.engappai.2022.105504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BANet: Small and multi-object detection with a bidirectional attention network for traffic scenes},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A procedure for anomaly detection and analysis.
<em>EAAI</em>, <em>117</em>, 105503. (<a
href="https://doi.org/10.1016/j.engappai.2022.105503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is often used to identify and remove outliers in datasets. However, detecting and analyzing the pattern of outliers can contribute to future business decisions or increase the accuracy of a learning algorithm. Selecting the applicable outlier detection method for a dataset requires human intervention and analysis due to the challenge of choosing an efficient technique suitable for all types of attributes. This work presents a procedure for anomaly detection and analysis. The procedure is feature-wise (i.e., processes each feature independently), uses T different anomaly detection techniques (for T &gt; 1 ), and estimates the best technique using predefined thresholds. It is a generic method that does not depend on the model type and can be applied to supervised and unsupervised learning. In addition, this method does not impute or remove the outliers, as they should be adapted according to the dataset or business requirements. The significant advantage of this method is the ability to use different techniques to detect anomalies since it is applied per feature and not per record, as in traditional anomaly detection methods. Furthermore, the method uses a new measure, Noise Ratio (NR), which describes the level of agreement between our method’s result and traditional anomaly detection techniques. The results showed that all the compared techniques identified non-anomalous features with consistent results between the various algorithms. In the proposed method, NR found up to 20% of the non-anomalous values marked as outliers and improved up to 10% in finding outliers in datasets compared to traditional anomaly detection algorithms.},
  archive      = {J_EAAI},
  author       = {Oded Koren and Michal Koren and Or Peretz},
  doi          = {10.1016/j.engappai.2022.105503},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105503},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A procedure for anomaly detection and analysis},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intelligent health indicator construction for prognostics of
composite structures utilizing a semi-supervised deep neural network and
SHM data. <em>EAAI</em>, <em>117</em>, 105502. (<a
href="https://doi.org/10.1016/j.engappai.2022.105502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A health indicator (HI) is a valuable index demonstrating the health level of an engineering system or structure, which is a direct intermediate connection between raw signals collected by structural health monitoring (SHM) methods and prognostic models for remaining useful life estimation. An appropriate HI should conform to prognostic criteria, i.e., monotonicity, trendability, and prognosability, that are commonly utilized to measure the HI’s quality. However, constructing such a HI is challenging, particularly for composite structures due to their vulnerability to complex damage scenarios. Data-driven models and deep learning are powerful mathematical tools that can be employed to achieve this purpose. Yet the availability of a large dataset with labels plays a crucial role in these fields, and the data collected by SHM methods can only be labeled after the structure fails. In this respect, semi-supervised learning can incorporate unlabeled data monitored from structures that have not yet failed. In the present work, a semi-supervised deep neural network is proposed to construct HI by SHM data fusion. For the first time, the prognostic criteria are used as targets of the network rather than employing them only as a measurement tool of HI’s quality. In this regard, the acoustic emission method was used to monitor composite panels during fatigue loading, and extracted features were used to construct an intelligent HI. Finally, the proposed roadmap is evaluated by the holdout method, which shows a 77.3% improvement in the HI’s quality, and the leave-one-out cross-validation method, which indicates the generalized model has at least an 81.77% score on the prognostic criteria. This study demonstrates that even when the true HI labels are unknown but the qualified HI pattern (according to the prognostic criteria) can be recognized, a model can still be built that provides HIs aligning with the desired degradation behavior.},
  archive      = {J_EAAI},
  author       = {Morteza Moradi and Agnes Broer and Juan Chiachío and Rinze Benedictus and Theodoros H. Loutas and Dimitrios Zarouchas},
  doi          = {10.1016/j.engappai.2022.105502},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105502},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent health indicator construction for prognostics of composite structures utilizing a semi-supervised deep neural network and SHM data},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Economical operation of modern power grids incorporating
uncertainties of renewable energy sources and load demand using the
adaptive fitness-distance balance-based stochastic fractal search
algorithm. <em>EAAI</em>, <em>117</em>, 105501. (<a
href="https://doi.org/10.1016/j.engappai.2022.105501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in the world population and the rapid developments in technology, the energy demands on modern electricity grids are also rising. In order to meet these demands, power systems are increasingly using renewable energy resources (RESs) in addition to traditional fossil fuel-powered generation units and thus, the structures being implemented in electricity grids are more complex. Consequently, the planning and operation of modern power systems presents important problems, one of which is that of the optimal power flow (OPF). With the integration of RESs, which are usually intermittent in nature, the OPF becomes a more difficult problem to solve. In this study, the OPF problem was designed under different operating cases, considering thermal, wind, solar, small-hydro, and tidal energy systems and load demand uncertainties. The adaptive fitness-distance balance selection-based stochastic fractal search ( A FDB-SFS) algorithm was proposed to solve this designed OPF problem. The results for the proposed approach from the experimental studies were statistically evaluated and compared with the results obtained from competitive optimization algorithms in the literature. The comparison demonstrated that the proposed A FDB-SFS algorithm was able to outperform the other algorithms in finding the optimal solution, and convergence speed to the optimal solution. According to the experimental study results, the proposed A FDB-SFS algorithm was able to optimize cost by 5.7362%, 0.0954%, 7.6244%, 0.17871%, 2.4307%, 0.12585%, 2.01729%, 1.7408%, 1.95317%, 3.5486%, 2.2007%, and 1.5203% better than the AO, GBO, GPC, HGS, HHO, RUN, TSO, LSHADE, LSHADE-EPSIN, LSHADE-CNEPSIN, LSHADE-SPACMA, and MadDE optimization algorithms in the proposed OPF problem. The source codes of the AFDB-SFS algorithm (proposed method) can be accessed at this link: https://ch.mathworks.com/matlabcentral/fileexchange/118485-afdb-sfs .},
  archive      = {J_EAAI},
  author       = {Serhat Duman and Hamdi Tolga Kahraman and Mehmet Kati},
  doi          = {10.1016/j.engappai.2022.105501},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105501},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Economical operation of modern power grids incorporating uncertainties of renewable energy sources and load demand using the adaptive fitness-distance balance-based stochastic fractal search algorithm},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthesis of a six-bar mechanism for generating knee and
ankle motion trajectories using deep generative neural network.
<em>EAAI</em>, <em>117</em>, 105500. (<a
href="https://doi.org/10.1016/j.engappai.2022.105500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic exoskeletons have demonstrated their effectiveness in post-stroke gait rehabilitation therapy. Nevertheless, further research is being conducted to improve existing rehabilitation exoskeletons in terms of ease-of-use and innovative design. Previously, the adaptation of linkage-based mechanisms for rehabilitation exoskeletons has been considered an option. However, finding linkage parameters that will produce the required gait trajectories using a linkage-based exoskeleton, is quite challenging. It is furthermore challenging to obtain parameters of a linkage-based mechanism designed for a gait rehabilitation task that has to produce two trajectories (for knee and ankle joints) simultaneously. In this work, we propose Deep Generative Neural Networks (DGNN) to obtain a set of optimal dimensions and parameters for the Stephenson III six-bar linkage-based gait exoskeleton. The proposed methodology demonstrates high efficacy in determining the linkage parameters for various target trajectories. The proposed framework, once trained, can accurately predict mechanism parameters to achieve two joint trajectories simultaneously. Subsequent to developing the model, walking trajectories from healthy human subjects are given to the model to determine the optimal linkage dimensions of the gait rehabilitation exoskeleton. The proposed model can be used to assist designers in quickly determining the optimized linkage dimensions of linkage-based mechanisms that can provide various target trajectories.},
  archive      = {J_EAAI},
  author       = {Akim Kapsalyamov and Shahid Hussain and Nicholas A.T. Brown and Roland Goecke and Munawar Hayat and Prashant K. Jamwal},
  doi          = {10.1016/j.engappai.2022.105500},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105500},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthesis of a six-bar mechanism for generating knee and ankle motion trajectories using deep generative neural network},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A circular intuitionistic fuzzy evaluation method based on
distances from the average solution to support multiple criteria
intelligent decisions involving uncertainty. <em>EAAI</em>,
<em>117</em>, 105499. (<a
href="https://doi.org/10.1016/j.engappai.2022.105499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to construct an evaluation method based on distances from the average solution (EDAS) based on circular intuitionistic fuzzy (C-IF) sets to support intelligent decision-making involving multiple criteria and intricate uncertainty. C-IF sets possess a resilient circular structure that can model decision-makers’ hesitancy and indecision like intuitionistic fuzzy sets and can add ambiguity to fuzzy membership and nonmembership functions like type-2 fuzzy sets. Related to the existing literature on EDAS in uncertain environments, a new interpretation is needed so that the decision assistance procedure can exploit higher-order fuzzy membership functions as well as in type-2 fuzzy settings, and can address decision hesitancy as well as in IF settings. However, EDAS has not been studied to discuss its applicability in C-IF circumstances and make headway a suitable extension model, which forms a research question worth exploring. To address this issue, this study endeavors to construct a C-IF EDAS methodology and propound novel concepts and measurements that can improve the core techniques of traditional EDAS, enabling them to handle complicated C-IF information and treat highly equivocal and indistinct decision-making tasks. The C-IF analytical procedure for decision-making is mainly built upon two representations from semantic assessments, namely C-IF assessment ratings and C-IF importance weights. This study puts forth the concept of aggressive and conservative estimates to identify anchored datum-based measurements that provide new interpretations of positive distance and negative distance concerning the C-IF average solution; besides this study evolves an extended EDAS decision rule in C-IF circumstances. Based on an aggregated operation and a membership score function, anchored datum-based (normalized) weighted sums about positive/negative distances can be rendered to produce a joint appraisal score for a compromise ranking of available alternatives. To corroborate the applicability of the established notions and measurements, this study utilizes the C-IF EDAS model and decision procedure to tackle a realistic site selection issue for a pandemic hospital within C-IF environments. The suitability, robustness, and flexibility of the developed C-IF EDAS methodology are confirmed through some comparative analyses and experimental studies. First, this study verifies the correctness and trustworthiness of the executive outcomes from the viewpoints of membership, nonmembership, and vague score functions. Next, this study confirms the effectuality and rationality of the proposed C-IF EDAS by comprehensive comparison with several related methods. Furthermore, this study suggests a flexible way of setting appraisal and distance parameters in the C-IF EDAS to facilitate intelligent decision-making in reality. Finally, some conclusive discussions of the C-IF EDAS solution are systematically investigated to reveal its practicality and application merits in the realm of multiple criteria decision analysis with information uncertainty; it is also confirmed that the C-IF set is well suited as a fundamental of problem modeling within complex decision-making environments.},
  archive      = {J_EAAI},
  author       = {Ting-Yu Chen},
  doi          = {10.1016/j.engappai.2022.105499},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105499},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A circular intuitionistic fuzzy evaluation method based on distances from the average solution to support multiple criteria intelligent decisions involving uncertainty},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal trajectory-tracking guidance for reusable launch
vehicle based on adaptive dynamic programming. <em>EAAI</em>,
<em>117</em>, 105497. (<a
href="https://doi.org/10.1016/j.engappai.2022.105497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An optimal trajectory-tracking guidance method for Reusable Launch Vehicle (RLV) based on neural Adaptive Dynamic Programming (ADP) is proposed. Firstly, a reentry reference trajectory and the corresponding steady-state control are generated based on the Gauss Pseudo-spectral Method (GPM) with saturation constraints on the amplitude, rate and acceleration of flow angles. A single-critic ADP controller is designed for optimal feedback control, which is combined with the steady-state control to realize the trajectory-tracking guidance. An innovative weight iteration algorithm for the critic neural network is proposed to reduce training computation and improve guidance accuracy. Simulation results show that with initial state errors and system uncertainty, the terminal position error is within 2.1 km in a reentry flight whose range covers more than 5500 km. Involved with the innovative weight iteration method, the training computation is reduced by 95% compared with the traditional gradient descent method and the guidance performance is also improved.},
  archive      = {J_EAAI},
  author       = {Xueyun Wang and Yifan Li and Zhiyuan Quan and Jiabao Wu},
  doi          = {10.1016/j.engappai.2022.105497},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105497},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal trajectory-tracking guidance for reusable launch vehicle based on adaptive dynamic programming},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). From numerical to heterogeneous linguistic best–worst
method: Impacts of personalized individual semantics on consistency and
consensus. <em>EAAI</em>, <em>117</em>, 105495. (<a
href="https://doi.org/10.1016/j.engappai.2022.105495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impacts of personalized individual semantics (PIS) on consistency and consensus in Best–Worst method (BWM) with heterogeneous linguistic preference information. Firstly, a PIS driven consistency measurement and information transformation method is presented to analyze the consistency level of linguistic preference information (i.e., best-to-others and others-to-worst vectors) of each decision maker, and this is conducted by maximizing the consistency level of additive preference relation that converted from linguistic preference information via personalized numerical scales. Secondly, a PIS driven maximum consensus optimization model within the BWM framework is designed to yield the maximum consensus level among the additive preference relations generated from heterogeneous linguistic preference information by means of personalized numerical scales. Thirdly, a PIS-based heterogeneous linguistic consensus reaching process is put forward to promote the consensus establishment among decision makers. Finally, the validity of the proposed BWM framework is verified by a case study, a sensitive analysis, and a comparison analysis.},
  archive      = {J_EAAI},
  author       = {Hengjie Zhang and Xiaomin Wang and Weijun Xu and Yucheng Dong},
  doi          = {10.1016/j.engappai.2022.105495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From numerical to heterogeneous linguistic best–worst method: Impacts of personalized individual semantics on consistency and consensus},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). Uncertainty-propagated cartesian coordinated human–robot
collaboration on riemannian manifold with hidden state-space model.
<em>EAAI</em>, <em>117</em>, 105491. (<a
href="https://doi.org/10.1016/j.engappai.2022.105491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel Cartesian coordinated human–robot collaboration framework derived from the hidden state-space models, which are established on the behaviour cloning of both the human and robot in a nonparametric form by using dual quaternion on Riemannian manifold. Based on the Taylor linearisation, this framework could provide an analytical approximation of the posterior distribution and hence infer six DoF Cartesian hidden state variables of the collaborative manipulator given human observation and its uncertainties. As the full Cartesian pose (special Euclidean group, SE(3)) includes translation and rotation (special orthogonal group, SO(3)), which is not Euclidean, directly encoding the Cartesian motions with nonparametric regression in Euclidean space could cause significant errors. This paper addresses this issue by defining both human and robot behaviours using modified quaternion and cloning them in the tangent space of the Riemannian manifold. Not akin to other coordinated human–robot collaboration methods, the collaboration framework not only preserves the adaptation functionalities but also propagates full Cartesian state variables and their uncertainties during real-time coordinated collaboration implementation. Leveraging on the Gaussian mixture model on the Riemannian manifold, the multiple task recognition is further addressed to enhance the generalisation capability of the framework presented. The application feasibility is demonstrated in both theoretical comparison simulation and experiments.},
  archive      = {J_EAAI},
  author       = {Likun Wang and Guoyan Wang and Zi Wang and Alison Turner and Svetan Ratchev},
  doi          = {10.1016/j.engappai.2022.105491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainty-propagated cartesian coordinated human–robot collaboration on riemannian manifold with hidden state-space model},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auxiliary algorithm to approach a near-global optimum of a
multi-objective function in acoustical topology optimization.
<em>EAAI</em>, <em>117</em>, 105488. (<a
href="https://doi.org/10.1016/j.engappai.2022.105488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an auxiliary algorithm is proposed to avoid local optima in solving an acoustical topology optimization problem by using a gradient-based optimizer. A local optimum convergence issue often occurs in the multi-objective function problem because the sub-objective functions are non-convex in general. In order to overcome this issue and find a near-global optimum, the sign change of sensitivity is heuristically conducted based on the objective function difference at every step of design variable updating. An acoustical topology optimization problem is formulated for improving a noise attenuation performance of a muffler. The heuristic-based auxiliary algorithm is combined with a well-known optimization algorithm to solve the topology optimization problem for a single target frequency as well as a multi-target frequency. Diverse optimal topologies were successfully obtained for various design conditions. Comparison of the optimized solutions by the proposed method and the previous methods strongly supported the validity of the proposed auxiliary algorithm. The application of the proposed method to a suction muffler design problem showed the industrial applicability of the method.},
  archive      = {J_EAAI},
  author       = {Kee Seung Oh and Jin Woo Lee},
  doi          = {10.1016/j.engappai.2022.105488},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105488},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Auxiliary algorithm to approach a near-global optimum of a multi-objective function in acoustical topology optimization},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The PID controller optimisation module using fuzzy
self-tuning PSO for air handling unit in continuous operation.
<em>EAAI</em>, <em>117</em>, 105485. (<a
href="https://doi.org/10.1016/j.engappai.2022.105485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current development of modern computational methods makes it possible to improve the performance of classical components and systems. The work provides a method for optimising the settings of a proportional–integral–derivative (PID) controller for an Air Handling Unit (AHU) equipped with many actuators with different parameters. The optimisation has been divided into two components: an offline optimiser consisting of Non-linear Autoregressive Modelling with Moving Average and Exogenous Input (NARMAX) and a Fuzzy Self-Tuning Particle Swarm optimisation (FST-PSO) metaheuristic algorithm and auxiliary module that automatically sends the optimised values to the controller based on information about the actuators currently operating. The solution has proven successful, making optimisation without AHU downtime and without interfering with the existing, factory-fitted control system and is implemented as one of the Building Management System (BMS) part in a real building. The described method reduced the oscillations that led to actuator failures and the need for parameter adjustments by the operator. No further failures occurred after module deployment, and the quality of control as measured by integral quality factors improved by an average of 64%. An application is possible in new and existing AHUs increasing their energy efficiency and fault-free operation time.},
  archive      = {J_EAAI},
  author       = {Arkadiusz Ambroziak and Adrian Chojecki},
  doi          = {10.1016/j.engappai.2022.105485},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105485},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The PID controller optimisation module using fuzzy self-tuning PSO for air handling unit in continuous operation},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computer vision framework for crack detection of civil
infrastructure—a review. <em>EAAI</em>, <em>117</em>, 105478. (<a
href="https://doi.org/10.1016/j.engappai.2022.105478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Civil infrastructure (e.g., buildings, roads, underground tunnels) could lose its expected physical and functional conditions after years of operation. Timely and accurate inspection and assessment of such infrastructures are essential to ensure safety and serviceability, e.g., by preventing unsafe working conditions and hazards. Cracks, which are one of the most common distress, can indicate severe structural integrity issues that threaten the safety of the structure and people in the environment. As such, accurate, fast, and automatic detection of cracks on structure surfaces is a major issue for a variety of civil engineering applications. Due to advances in hardware data acquisition systems, significant progress has been made in the automatic detection and quantification of cracks in recent decades. This paper provides a comprehensive review of the research progress and prospects in computer vision frameworks for crack detection of civil infrastructures from multiple materials, including asphalt, concrete, and metal-like materials. The review encompasses major components of typical frameworks, i.e., data acquisition techniques, publicly available datasets, detection algorithms, and evaluation metrics. In particular, we provide a taxonomy of detection algorithms with a detailed discussion of the advantages, limitations, and application scenarios of the methods in each category, as well as the relationships between methods of different categories. We also discuss unsolved issues and key challenges in crack detection that could drive future research directions.},
  archive      = {J_EAAI},
  author       = {Dihao Ai and Guiyuan Jiang and Siew-Kei Lam and Peilan He and Chengwu Li},
  doi          = {10.1016/j.engappai.2022.105478},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105478},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Computer vision framework for crack detection of civil infrastructure—A review},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated function development for emission control with
deep reinforcement learning. <em>EAAI</em>, <em>117</em>, 105477. (<a
href="https://doi.org/10.1016/j.engappai.2022.105477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional automotive development process for embedded systems today is still time- and data-inefficient, and requires highly experienced software developers and calibration engineers. Consequently, it is cost-intensive and at the same time prone to sub-optimal solutions. Reinforcement Learning offers a promising approach to address these challenges. The evolved agents have proven their ability to master complex control tasks in a close-to-optimal manner without any human intervention, but the training procedures are hardly compatible with current development processes. As a result, Reinforcement Learning has rarely been used in powertrain development until now. This work describes an integration of Reinforcement Learning in the embedded system development process to automatically train and deploy agents in transient driving cycles. Using the example of exhaust gas re-circulation control for a Diesel engine, an agent is successfully trained in a fully virtualized environment, achieving emission reductions of up to 10 % in comparison to a state-of-the-art controller. Further investigations are carried out to quantify the impact of the driving cycle and ambient conditions on the agent’s performance. To demonstrate the transferability between different levels of virtualization, the experienced agent is then tested in closed-loop with a real hardware controller to operate the physical actuator. By confirming the reproducibility of the learned strategy on real hardware, this article serves as proof-of-concept for a sustainable, Reinforcement Learning based path to automatically develop embedded controllers for complex control problems.},
  archive      = {J_EAAI},
  author       = {Lucas Koch and Mario Picerno and Kevin Badalian and Sung-Yong Lee and Jakob Andert},
  doi          = {10.1016/j.engappai.2022.105477},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105477},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated function development for emission control with deep reinforcement learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-objective optimization of explosive waste treatment
process considering environment via bayesian active learning.
<em>EAAI</em>, <em>117</em>, 105463. (<a
href="https://doi.org/10.1016/j.engappai.2022.105463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fluidized bed is a next-generation explosive waste treatment reactor that is safer and emits less pollutants (e.g., NOx) than a rotary kiln. When a fluidized bed reactor is used to treat explosive waste, the design and operating conditions significantly impact the emission of pollutants. It is possible to reduce the pollutants to below the regulation level (90 ppm) through finding ideal design and operating conditions. However, there are many practical challenges, such as cost limitations. In addition, owing to the characteristics of explosive waste, designing and optimizing the process through real experiments without any guidelines is dangerous. Therefore, a computational fluid dynamics (CFD) simulation was performed to obtain high-accuracy data on the internal phenomena of the reactor first. In this situation, since a lot of variables and combinations should be considered, it is obvious to takes very long time for finding optimal point by only using CFD simulation. Thus, based on the simulation data, efficient search space exploration was performed using multi-objective Bayesian optimization and several promising points constituting the Pareto front were derived to find optimal conditions. As a result, six optimum points of operating and design conditions were obtained considering process cost and nitrogen oxide emissions simultaneously. The six Pareto solutions through above approach reduced 47.5% of NOx emission and 10.5% of cost compared to the previous studies. In addition, it is meaningful that this study could reduce optimization time even though the design conditions of explosive waste treatment process were considered.},
  archive      = {J_EAAI},
  author       = {Sunghyun Cho and Minsu Kim and Jaewon Lee and Areum Han and Jonggeol Na and Il Moon},
  doi          = {10.1016/j.engappai.2022.105463},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105463},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective optimization of explosive waste treatment process considering environment via bayesian active learning},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). WITHDRAWN: A novel hybrid based on nature-inspired and
stochastic fractal search algorithms for optimizing of artificial neural
network model in landslide susceptibility. <em>EAAI</em>, <em>117</em>,
105457. (<a
href="https://doi.org/10.1016/j.engappai.2022.105457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article has been withdrawn: please see Elsevier Policy on Article Withdrawal ( http://www.elsevier.com/locate/withdrawalpolicy ). This article has been withdrawn at the request of the Editor-in-Chief and publisher. The Editor-in-Chief regrets that an error in the review procedure occurred, whereby the article was accepted before assignment to a handling editor. The Editor-in-Chief and Publisher wish to apologise for any confusion or inconvenience caused; and we stress that the authors are not at fault in this case.},
  archive      = {J_EAAI},
  author       = {Hossein Moayedi and Atefeh Ahmadi Dehrashid and Mohammad Hossein Gholizadeh},
  doi          = {10.1016/j.engappai.2022.105457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WITHDRAWN: A novel hybrid based on nature-inspired and stochastic fractal search algorithms for optimizing of artificial neural network model in landslide susceptibility},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature redundancy assessment framework for subject matter
experts. <em>EAAI</em>, <em>117</em>, 105456. (<a
href="https://doi.org/10.1016/j.engappai.2022.105456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional feature removal techniques focus on showing how well the selected subset of features can perform in terms of model accuracy while neglecting the aspect of eliminating redundant features and incorporating Subject Matter Experts’ (SME) prior knowledge. This is important so that SMEs can leverage their prior knowledge to incorporate actionable or controllable features to build a downstream model with confidence and practical application. Furthermore, feature removal should include evidence on how similar the redundant features are with the selected features. We proposed a framework that incorporates SME prior knowledge to assess/augment the relevancy of the features with respect to the domain-specific problem. First, we rely on the Variance Inflation Factor (VIF) to iteratively remove the redundant features and measure their information loss. The quantifying of information loss will assist the SME in determining the number of features to be selected. Next, Partitions Around Medoids (PAM) is used to cluster redundant features to the closest selected feature. These clusters guide the SME in the augmentation process where the SME can retain, add, or swap the preferred features with those deemed non-redundant by the algorithm. We compared our result based on four commonly used benchmark datasets (Alate Adelges, Sonar, Wisconsin Diagnostic Breast Cancer, and Wine) with the features selected by domain experts, how they are being grouped, and the possible options to perform feature swaps. Our results show the similarity features between redundant features and their corresponding selected features. Also, we have demonstrated that our framework is able to maintain comparable retained information with those supervised feature selection methods, and demonstrate overall higher retained information of up to 3%.},
  archive      = {J_EAAI},
  author       = {Kee Khoon Gary Lee and Henry Kasim and Weigui Jair Zhou and Rajendra Prasad Sirigina and Gih Guang Terence Hung},
  doi          = {10.1016/j.engappai.2022.105456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature redundancy assessment framework for subject matter experts},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Using deep learning for selenium web UI functional tests: A
case-study with e-commerce applications. <em>EAAI</em>, <em>117</em>,
105446. (<a
href="https://doi.org/10.1016/j.engappai.2022.105446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of test cases for detecting the faults within the software is called software testing. Manual testing is laborious and time-consuming hence automation tools to test software were introduced. Despite the use of automation tools at the User Interface (UI) level of the test pyramid, the limitations of current automation tools like automated test case generation and automated repairing of fragile tests still force us to carry out a large amount of manual testing. In this paper, we propose a novel method using AI to address the given challenges. With our proposed method test cases are automatically generated from the structure of the UI using a pipelined architecture of object detection, text detection and NLP models. We show that the test cases generated by the proposed framework can be translated into executable test scripts using a simple parser. The proposed method generates an average of 98.8% correct executable test cases for the applications under study. We also show the capability of the proposed method in generating new tests automatically when the application is modified. The proposed method generates an average of 98.605% correct executable test cases when the UI is modified for the applications under study. We also empirically prove that a GPU implementation of the proposed framework results in just an additional average runtime of 0.92 seconds per test case which is significantly low given the benefits of automated generation of test scripts and automated repairing of fragile tests.},
  archive      = {J_EAAI},
  author       = {Zubair Khaliq and Dawood Ashraf Khan and Sheikh Umar Farooq},
  doi          = {10.1016/j.engappai.2022.105446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Using deep learning for selenium web UI functional tests: A case-study with e-commerce applications},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time segmentation network for accurate weld detection
in large weldments. <em>EAAI</em>, <em>117</em>, 105008. (<a
href="https://doi.org/10.1016/j.engappai.2022.105008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the defects of inaccurate weld extraction and high matching error rate in automatic welding system of large weldments currently. We propose a multi task detection model based on CNN architecture, which integrates the semantic segmentation technology required for weldment merging as well as the edge detection technology needed for weld matching. In particular, for the purpose of predicting smoother edges and welds, we carefully construct a new segment head, which adopts the sub-pixel convolution technology for up-sampling. Furthermore, a joint optimization loss function is explored to alleviate the imbalance of category distribution in large-scale weldment datasets. To verify the effectiveness of the model, abundant groups of data are collected for training and testing. The experimental results indicate that the proposed method has achieved the optimal trade-off between detection accuracy (83.35% mIoU, 95.15% F-score of welds and edges) as well as speed (74FPS) on a 2080Ti GPU compared with other state-of-the-arts, which greatly improves the robustness of the automatic welding system for large weldments.},
  archive      = {J_EAAI},
  author       = {Zijian Wu and Peng Gao and Jing Han and Lianfa Bai and Jun Lu and Zhuang Zhao},
  doi          = {10.1016/j.engappai.2022.105008},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {105008},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time segmentation network for accurate weld detection in large weldments},
  volume       = {117},
  year         = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
